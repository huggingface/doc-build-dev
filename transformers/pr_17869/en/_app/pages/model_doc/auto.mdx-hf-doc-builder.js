import{S as vDt,i as FDt,s as TDt,e as a,k as l,w as F,t as o,M as MDt,c as n,d as t,m as i,a as s,x as T,h as r,b as c,G as e,g as b,y as M,q as E,o as C,B as w,v as EDt,L as I}from"../../chunks/vendor-hf-doc-builder.js";import{T as KYr}from"../../chunks/Tip-hf-doc-builder.js";import{D as R}from"../../chunks/Docstring-hf-doc-builder.js";import{C as P}from"../../chunks/CodeBlock-hf-doc-builder.js";import{I as re}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{E as B}from"../../chunks/ExampleCodeBlock-hf-doc-builder.js";function CDt(x){let g,v,p,m,_,d,h,Eo,Ti,yf,at,Mi,Ei,ww,xf,Oe,Qe,Ci,Rn,Aw,Pn,Bn,Lw,wi,In,yw,Ai,$f,xa;return{c(){g=a("p"),v=o("If your "),p=a("code"),m=o("NewModelConfig"),_=o(" is a subclass of "),d=a("code"),h=o("PretrainedConfig"),Eo=o(`, make sure its
`),Ti=a("code"),yf=o("model_type"),at=o(" attribute is set to the same key you use when registering the config (here "),Mi=a("code"),Ei=o('"new-model"'),ww=o(")."),xf=l(),Oe=a("p"),Qe=o("Likewise, if your "),Ci=a("code"),Rn=o("NewModel"),Aw=o(" is a subclass of "),Pn=a("a"),Bn=o("PreTrainedModel"),Lw=o(`, make sure its
`),wi=a("code"),In=o("config_class"),yw=o(` attribute is set to the same class you use when registering the model (here
`),Ai=a("code"),$f=o("NewModelConfig"),xa=o(")."),this.h()},l(We){g=n(We,"P",{});var Ae=s(g);v=r(Ae,"If your "),p=n(Ae,"CODE",{});var rS=s(p);m=r(rS,"NewModelConfig"),rS.forEach(t),_=r(Ae," is a subclass of "),d=n(Ae,"CODE",{});var Li=s(d);h=r(Li,"PretrainedConfig"),Li.forEach(t),Eo=r(Ae,`, make sure its
`),Ti=n(Ae,"CODE",{});var tS=s(Ti);yf=r(tS,"model_type"),tS.forEach(t),at=r(Ae," attribute is set to the same key you use when registering the config (here "),Mi=n(Ae,"CODE",{});var aS=s(Mi);Ei=r(aS,'"new-model"'),aS.forEach(t),ww=r(Ae,")."),Ae.forEach(t),xf=i(We),Oe=n(We,"P",{});var Co=s(Oe);Qe=r(Co,"Likewise, if your "),Ci=n(Co,"CODE",{});var $a=s(Ci);Rn=r($a,"NewModel"),$a.forEach(t),Aw=r(Co," is a subclass of "),Pn=n(Co,"A",{href:!0});var nS=s(Pn);Bn=r(nS,"PreTrainedModel"),nS.forEach(t),Lw=r(Co,`, make sure its
`),wi=n(Co,"CODE",{});var kf=s(wi);In=r(kf,"config_class"),kf.forEach(t),yw=r(Co,` attribute is set to the same class you use when registering the model (here
`),Ai=n(Co,"CODE",{});var sS=s(Ai);$f=r(sS,"NewModelConfig"),sS.forEach(t),xa=r(Co,")."),Co.forEach(t),this.h()},h(){c(Pn,"href","/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel")},m(We,Ae){b(We,g,Ae),e(g,v),e(g,p),e(p,m),e(g,_),e(g,d),e(d,h),e(g,Eo),e(g,Ti),e(Ti,yf),e(g,at),e(g,Mi),e(Mi,Ei),e(g,ww),b(We,xf,Ae),b(We,Oe,Ae),e(Oe,Qe),e(Oe,Ci),e(Ci,Rn),e(Oe,Aw),e(Oe,Pn),e(Pn,Bn),e(Oe,Lw),e(Oe,wi),e(wi,In),e(Oe,yw),e(Oe,Ai),e(Ai,$f),e(Oe,xa)},d(We){We&&t(g),We&&t(xf),We&&t(Oe)}}}function wDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-uncased")

# Download configuration from huggingface.co (user-uploaded) and cache.
config = AutoConfig.from_pretrained("dbmdz/bert-base-german-cased")

# If configuration file is in a directory (e.g., was saved using *save_pretrained('./test/saved_model/')*).
config = AutoConfig.from_pretrained("./test/bert_saved_model/")

# Load a specific configuration file.
config = AutoConfig.from_pretrained("./test/bert_saved_model/my_configuration.json")

# Change some config attributes when loading a pretrained config.
config = AutoConfig.from_pretrained("bert-base-uncased", output_attentions=True, foo=False)
config.output_attentions

config, unused_kwargs = AutoConfig.from_pretrained(
    "bert-base-uncased", output_attentions=True, foo=False, return_unused_kwargs=True
)
config.output_attentions

unused_kwargs`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If configuration file is in a directory (e.g., was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*).</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a specific configuration file.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/my_configuration.json&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Change some config attributes when loading a pretrained config.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>config, unused_kwargs = AutoConfig.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>, foo=<span class="hljs-literal">False</span>, return_unused_kwargs=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>unused_kwargs
{<span class="hljs-string">&#x27;foo&#x27;</span>: <span class="hljs-literal">False</span>}`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ADt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoTokenizer

# Download vocabulary from huggingface.co and cache.
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Download vocabulary from huggingface.co (user-uploaded) and cache.
tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-german-cased")

# If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained('./test/saved_model/')*)
tokenizer = AutoTokenizer.from_pretrained("./test/bert_saved_model/")

# Download vocabulary from huggingface.co and define model-specific arguments
tokenizer = AutoTokenizer.from_pretrained("roberta-base", add_prefix_space=True)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-uncased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co (user-uploaded) and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;dbmdz/bert-base-german-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If vocabulary files are in a directory (e.g. tokenizer was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;./test/bert_saved_model/&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download vocabulary from huggingface.co and define model-specific arguments</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;roberta-base&quot;</span>, add_prefix_space=<span class="hljs-literal">True</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LDt(x){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function yDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoFeatureExtractor

# Download feature extractor from huggingface.co and cache.
feature_extractor = AutoFeatureExtractor.from_pretrained("facebook/wav2vec2-base-960h")

# If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained('./test/saved_model/')*)
feature_extractor = AutoFeatureExtractor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download feature extractor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If feature extractor files are in a directory (e.g. feature extractor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xDt(x){let g,v,p,m,_;return{c(){g=a("p"),v=o("Passing "),p=a("code"),m=o("use_auth_token=True"),_=o(" is required when you want to use a private model.")},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Passing "),p=n(h,"CODE",{});var Eo=s(p);m=r(Eo,"use_auth_token=True"),Eo.forEach(t),_=r(h," is required when you want to use a private model."),h.forEach(t)},m(d,h){b(d,g,h),e(g,v),e(g,p),e(p,m),e(g,_)},d(d){d&&t(g)}}}function $Dt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoProcessor

# Download processor from huggingface.co and cache.
processor = AutoProcessor.from_pretrained("facebook/wav2vec2-base-960h")

# If processor files are in a directory (e.g. processor was saved using *save_pretrained('./test/saved_model/')*)
processor = AutoProcessor.from_pretrained("./test/saved_model/")`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download processor from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># If processor files are in a directory (e.g. processor was saved using *save_pretrained(&#x27;./test/saved_model/&#x27;)*)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;./test/saved_model/&quot;</span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModel

# Download model and configuration from huggingface.co and cache.
model = AutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModel.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = AutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForPreTraining.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCausalLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedLM.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = AutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = AutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/t5_tf_model_config.json")
model = AutoModelForSeq2SeqLM.from_pretrained(
    "./tf_model/t5_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/t5_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/t5_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ODt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSequenceClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMultipleChoice.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForNextSentencePrediction.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForTokenClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForQuestionAnswering.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/tapas_tf_model_config.json")
model = AutoModelForTableQuestionAnswering.from_pretrained(
    "./tf_model/tapas_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/tapas_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/tapas_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZDt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForVision2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("dandelin/vilt-b32-finetuned-vqa")
model = AutoModelForVisualQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForVisualQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa")

# Update configuration during loading
model = AutoModelForVisualQuestionAnswering.from_pretrained("dandelin/vilt-b32-finetuned-vqa", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/vilt_tf_model_config.json")
model = AutoModelForVisualQuestionAnswering.from_pretrained(
    "./tf_model/vilt_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForVisualQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;dandelin/vilt-b32-finetuned-vqa&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/vilt_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForVisualQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/vilt_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioFrameClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioFrameClassification

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioFrameClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioFrameClassification.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioFrameClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioFrameClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForCTC.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForCTC

# Download model and configuration from huggingface.co and cache.
model = AutoModelForCTC.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForCTC.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForCTC.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSpeechSeq2Seq.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForAudioXVector.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForAudioXVector

# Download model and configuration from huggingface.co and cache.
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForAudioXVector.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForAudioXVector.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForAudioXVector

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioXVector.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForMaskedImageModeling.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Gt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForMaskedImageModeling

# Download model and configuration from huggingface.co and cache.
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForMaskedImageModeling.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForMaskedImageModeling.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForMaskedImageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedImageModeling.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForObjectDetection.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForObjectDetection

# Download model and configuration from huggingface.co and cache.
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForObjectDetection.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForObjectDetection.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForObjectDetection

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForObjectDetection.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForImageSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForImageSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForImageSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForImageSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForImageSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForSemanticSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForSemanticSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForSemanticSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForSemanticSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = AutoModelForInstanceSegmentation.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function CGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, AutoModelForInstanceSegmentation

# Download model and configuration from huggingface.co and cache.
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased")

# Update configuration during loading
model = AutoModelForInstanceSegmentation.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a TF checkpoint file instead of a PyTorch model (slower)
config = AutoConfig.from_pretrained("./tf_model/bert_tf_model_config.json")
model = AutoModelForInstanceSegmentation.from_pretrained(
    "./tf_model/bert_tf_checkpoint.ckpt.index", from_tf=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModelForInstanceSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a TF checkpoint file instead of a PyTorch model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./tf_model/bert_tf_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForInstanceSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./tf_model/bert_tf_checkpoint.ckpt.index&quot;</span>, from_tf=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function wGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function AGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModel

# Download model and configuration from huggingface.co and cache.
model = TFAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function LGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function yGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function xGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function $Gt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function kGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function SGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function RGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function PGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function BGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = TFAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function IGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = TFAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = TFAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function NGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function qGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function jGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function DGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function GGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function OGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function VGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("google/tapas-base-finetuned-wtq")
model = TFAutoModelForTableQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function XGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTableQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq")

# Update configuration during loading
model = TFAutoModelForTableQuestionAnswering.from_pretrained("google/tapas-base-finetuned-wtq", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/tapas_pt_model_config.json")
model = TFAutoModelForTableQuestionAnswering.from_pretrained(
    "./pt_model/tapas_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTableQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;google/tapas-base-finetuned-wtq&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/tapas_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTableQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/tapas_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function zGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function QGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function WGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function HGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function UGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function JGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function YGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = TFAutoModelForSpeechSeq2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function KGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, TFAutoModelForSpeechSeq2Seq

# Download model and configuration from huggingface.co and cache.
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = TFAutoModelForSpeechSeq2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, TFAutoModelForSpeechSeq2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSpeechSeq2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function ZGt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModel.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function eOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModel

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModel.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModel.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModel.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function oOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForCausalLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function rOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForCausalLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForCausalLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForCausalLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function tOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForPreTraining.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function aOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForPreTraining

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForPreTraining.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForPreTraining.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForPreTraining

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForPreTraining.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function nOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMaskedLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function sOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMaskedLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMaskedLM.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMaskedLM.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMaskedLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function lOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("t5-base")
model = FlaxAutoModelForSeq2SeqLM.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function iOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSeq2SeqLM

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base")

# Update configuration during loading
model = FlaxAutoModelForSeq2SeqLM.from_pretrained("t5-base", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/t5_pt_model_config.json")
model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
    "./pt_model/t5_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;t5-base&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/t5_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSeq2SeqLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/t5_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function dOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForSequenceClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function cOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForSequenceClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForSequenceClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForSequenceClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function fOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForQuestionAnswering.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function mOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForQuestionAnswering

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForQuestionAnswering.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForQuestionAnswering.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForQuestionAnswering.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function gOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForTokenClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function hOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForTokenClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForTokenClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForTokenClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function pOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForMultipleChoice.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function _Ot(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForMultipleChoice

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForMultipleChoice.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForMultipleChoice.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForMultipleChoice.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function uOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForNextSentencePrediction.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function bOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForNextSentencePrediction

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForNextSentencePrediction.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForNextSentencePrediction

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForNextSentencePrediction.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function vOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForImageClassification.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function FOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForImageClassification

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForImageClassification.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForImageClassification.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function TOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download configuration from huggingface.co and cache.
config = AutoConfig.from_pretrained("bert-base-cased")
model = FlaxAutoModelForVision2Seq.from_config(config)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_config(config)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function MOt(x){let g,v,p,m,_;return m=new P({props:{code:`from transformers import AutoConfig, FlaxAutoModelForVision2Seq

# Download model and configuration from huggingface.co and cache.
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased")

# Update configuration during loading
model = FlaxAutoModelForVision2Seq.from_pretrained("bert-base-cased", output_attentions=True)
model.config.output_attentions

# Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)
config = AutoConfig.from_pretrained("./pt_model/bert_pt_model_config.json")
model = FlaxAutoModelForVision2Seq.from_pretrained(
    "./pt_model/bert_pytorch_model.bin", from_pt=True, config=config
)`,highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, FlaxAutoModelForVision2Seq

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Download model and configuration from huggingface.co and cache.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Update configuration during loading</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.output_attentions
<span class="hljs-literal">True</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Loading from a PyTorch checkpoint file instead of a TensorFlow model (slower)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;./pt_model/bert_pt_model_config.json&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = FlaxAutoModelForVision2Seq.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;./pt_model/bert_pytorch_model.bin&quot;</span>, from_pt=<span class="hljs-literal">True</span>, config=config
<span class="hljs-meta">... </span>)`}}),{c(){g=a("p"),v=o("Examples:"),p=l(),F(m.$$.fragment)},l(d){g=n(d,"P",{});var h=s(g);v=r(h,"Examples:"),h.forEach(t),p=i(d),T(m.$$.fragment,d)},m(d,h){b(d,g,h),e(g,v),b(d,p,h),M(m,d,h),_=!0},p:I,i(d){_||(E(m.$$.fragment,d),_=!0)},o(d){C(m.$$.fragment,d),_=!1},d(d){d&&t(g),d&&t(p),w(m,d)}}}function EOt(x){let g,v,p,m,_,d,h,Eo,Ti,yf,at,Mi,Ei,ww,xf,Oe,Qe,Ci,Rn,Aw,Pn,Bn,Lw,wi,In,yw,Ai,$f,xa,We,Ae,rS,Li,tS,aS,Co,$a,nS,kf,sS,eQe,jGe,yi,Sf,mte,xw,oQe,gte,rQe,DGe,Nn,tQe,hte,aQe,nQe,pte,sQe,lQe,GGe,$w,OGe,lS,iQe,VGe,Rf,XGe,xi,Pf,_te,kw,dQe,ute,cQe,zGe,wo,Sw,fQe,Rw,mQe,iS,gQe,hQe,pQe,Pw,_Qe,bte,uQe,bQe,vQe,Ar,Bw,FQe,vte,TQe,MQe,$i,EQe,Fte,CQe,wQe,Tte,AQe,LQe,yQe,A,Bf,Mte,xQe,$Qe,dS,kQe,SQe,RQe,If,Ete,PQe,BQe,cS,IQe,NQe,qQe,Nf,Cte,jQe,DQe,fS,GQe,OQe,VQe,qf,wte,XQe,zQe,mS,QQe,WQe,HQe,jf,Ate,UQe,JQe,gS,YQe,KQe,ZQe,Df,Lte,eWe,oWe,hS,rWe,tWe,aWe,Gf,yte,nWe,sWe,pS,lWe,iWe,dWe,Of,xte,cWe,fWe,_S,mWe,gWe,hWe,Vf,$te,pWe,_We,uS,uWe,bWe,vWe,Xf,kte,FWe,TWe,bS,MWe,EWe,CWe,zf,Ste,wWe,AWe,vS,LWe,yWe,xWe,Qf,Rte,$We,kWe,FS,SWe,RWe,PWe,Wf,Pte,BWe,IWe,TS,NWe,qWe,jWe,Hf,Bte,DWe,GWe,MS,OWe,VWe,XWe,Uf,Ite,zWe,QWe,ES,WWe,HWe,UWe,Jf,Nte,JWe,YWe,CS,KWe,ZWe,eHe,Yf,qte,oHe,rHe,wS,tHe,aHe,nHe,Kf,jte,sHe,lHe,AS,iHe,dHe,cHe,Zf,Dte,fHe,mHe,LS,gHe,hHe,pHe,em,Gte,_He,uHe,yS,bHe,vHe,FHe,om,Ote,THe,MHe,xS,EHe,CHe,wHe,rm,Vte,AHe,LHe,$S,yHe,xHe,$He,tm,Xte,kHe,SHe,kS,RHe,PHe,BHe,am,zte,IHe,NHe,SS,qHe,jHe,DHe,nm,Qte,GHe,OHe,RS,VHe,XHe,zHe,sm,Wte,QHe,WHe,PS,HHe,UHe,JHe,lm,Hte,YHe,KHe,BS,ZHe,eUe,oUe,im,Ute,rUe,tUe,IS,aUe,nUe,sUe,dm,Jte,lUe,iUe,NS,dUe,cUe,fUe,cm,Yte,mUe,gUe,qS,hUe,pUe,_Ue,fm,Kte,uUe,bUe,jS,vUe,FUe,TUe,mm,Zte,MUe,EUe,DS,CUe,wUe,AUe,gm,eae,LUe,yUe,GS,xUe,$Ue,kUe,hm,oae,SUe,RUe,OS,PUe,BUe,IUe,pm,rae,NUe,qUe,VS,jUe,DUe,GUe,_m,tae,OUe,VUe,XS,XUe,zUe,QUe,um,aae,WUe,HUe,zS,UUe,JUe,YUe,bm,nae,KUe,ZUe,QS,eJe,oJe,rJe,vm,sae,tJe,aJe,WS,nJe,sJe,lJe,Fm,lae,iJe,dJe,HS,cJe,fJe,mJe,Tm,iae,gJe,hJe,US,pJe,_Je,uJe,Mm,dae,bJe,vJe,JS,FJe,TJe,MJe,Em,cae,EJe,CJe,YS,wJe,AJe,LJe,Cm,fae,yJe,xJe,KS,$Je,kJe,SJe,wm,mae,RJe,PJe,ZS,BJe,IJe,NJe,Am,gae,qJe,jJe,eR,DJe,GJe,OJe,Lm,hae,VJe,XJe,oR,zJe,QJe,WJe,ym,pae,HJe,UJe,rR,JJe,YJe,KJe,xm,_ae,ZJe,eYe,tR,oYe,rYe,tYe,$m,uae,aYe,nYe,aR,sYe,lYe,iYe,km,bae,dYe,cYe,nR,fYe,mYe,gYe,Sm,vae,hYe,pYe,sR,_Ye,uYe,bYe,Rm,Fae,vYe,FYe,lR,TYe,MYe,EYe,Pm,Tae,CYe,wYe,iR,AYe,LYe,yYe,Bm,Mae,xYe,$Ye,dR,kYe,SYe,RYe,Im,Eae,PYe,BYe,cR,IYe,NYe,qYe,Nm,Cae,jYe,DYe,fR,GYe,OYe,VYe,qm,wae,XYe,zYe,mR,QYe,WYe,HYe,jm,Aae,UYe,JYe,gR,YYe,KYe,ZYe,Dm,Lae,eKe,oKe,hR,rKe,tKe,aKe,Gm,yae,nKe,sKe,pR,lKe,iKe,dKe,Om,xae,cKe,fKe,_R,mKe,gKe,hKe,Vm,$ae,pKe,_Ke,uR,uKe,bKe,vKe,Xm,kae,FKe,TKe,bR,MKe,EKe,CKe,zm,Sae,wKe,AKe,vR,LKe,yKe,xKe,Qm,Rae,$Ke,kKe,FR,SKe,RKe,PKe,Wm,Pae,BKe,IKe,TR,NKe,qKe,jKe,Hm,Bae,DKe,GKe,MR,OKe,VKe,XKe,Um,Iae,zKe,QKe,ER,WKe,HKe,UKe,Jm,Nae,JKe,YKe,CR,KKe,ZKe,eZe,Ym,qae,oZe,rZe,wR,tZe,aZe,nZe,Km,jae,sZe,lZe,AR,iZe,dZe,cZe,Zm,Dae,fZe,mZe,LR,gZe,hZe,pZe,eg,Gae,_Ze,uZe,yR,bZe,vZe,FZe,og,Oae,TZe,MZe,xR,EZe,CZe,wZe,rg,Vae,AZe,LZe,$R,yZe,xZe,$Ze,tg,Xae,kZe,SZe,kR,RZe,PZe,BZe,ag,zae,IZe,NZe,SR,qZe,jZe,DZe,ng,Qae,GZe,OZe,RR,VZe,XZe,zZe,sg,Wae,QZe,WZe,PR,HZe,UZe,JZe,lg,Hae,YZe,KZe,BR,ZZe,eeo,oeo,ig,Uae,reo,teo,IR,aeo,neo,seo,dg,Jae,leo,ieo,NR,deo,ceo,feo,cg,Yae,meo,geo,qR,heo,peo,_eo,fg,Kae,ueo,beo,jR,veo,Feo,Teo,mg,Zae,Meo,Eeo,DR,Ceo,weo,Aeo,gg,ene,Leo,yeo,GR,xeo,$eo,keo,hg,one,Seo,Reo,OR,Peo,Beo,Ieo,pg,rne,Neo,qeo,VR,jeo,Deo,Geo,_g,tne,Oeo,Veo,XR,Xeo,zeo,Qeo,ug,ane,Weo,Heo,zR,Ueo,Jeo,Yeo,bg,nne,Keo,Zeo,QR,eoo,ooo,roo,vg,sne,too,aoo,WR,noo,soo,loo,Fg,lne,ioo,doo,HR,coo,foo,moo,Tg,ine,goo,hoo,UR,poo,_oo,uoo,Mg,dne,boo,voo,JR,Foo,Too,Moo,Eg,cne,Eoo,Coo,YR,woo,Aoo,Loo,Cg,fne,yoo,xoo,KR,$oo,koo,Soo,wg,mne,Roo,Poo,ZR,Boo,Ioo,Noo,Ag,gne,qoo,joo,eP,Doo,Goo,Ooo,Lg,hne,Voo,Xoo,oP,zoo,Qoo,Woo,yg,pne,Hoo,Uoo,rP,Joo,Yoo,Koo,xg,_ne,Zoo,ero,tP,oro,rro,tro,$g,une,aro,nro,aP,sro,lro,iro,kg,bne,dro,cro,nP,fro,mro,gro,Sg,vne,hro,pro,sP,_ro,uro,bro,Rg,Fne,vro,Fro,lP,Tro,Mro,Ero,Pg,Tne,Cro,wro,iP,Aro,Lro,yro,Bg,Mne,xro,$ro,dP,kro,Sro,Rro,Ig,Ene,Pro,Bro,cP,Iro,Nro,qro,Ng,Cne,jro,Dro,fP,Gro,Oro,Vro,qg,wne,Xro,zro,mP,Qro,Wro,Hro,jg,Ane,Uro,Jro,gP,Yro,Kro,Zro,Dg,Lne,eto,oto,hP,rto,tto,ato,Gg,nto,Og,Iw,sto,yne,lto,QGe,ki,Vg,xne,Nw,ito,$ne,dto,WGe,Ao,qw,cto,jw,fto,pP,mto,gto,hto,Dw,pto,kne,_to,uto,bto,Lr,Gw,vto,Sne,Fto,Tto,ka,Mto,Rne,Eto,Cto,Pne,wto,Ato,Bne,Lto,yto,xto,k,qn,Ine,$to,kto,_P,Sto,Rto,uP,Pto,Bto,Ito,jn,Nne,Nto,qto,bP,jto,Dto,vP,Gto,Oto,Vto,Dn,qne,Xto,zto,FP,Qto,Wto,TP,Hto,Uto,Jto,Xg,jne,Yto,Kto,MP,Zto,eao,oao,Gn,Dne,rao,tao,EP,aao,nao,CP,sao,lao,iao,zg,Gne,dao,cao,wP,fao,mao,gao,Qg,One,hao,pao,AP,_ao,uao,bao,Wg,Vne,vao,Fao,LP,Tao,Mao,Eao,On,Xne,Cao,wao,yP,Aao,Lao,xP,yao,xao,$ao,Vn,zne,kao,Sao,$P,Rao,Pao,kP,Bao,Iao,Nao,Xn,Qne,qao,jao,SP,Dao,Gao,RP,Oao,Vao,Xao,Hg,Wne,zao,Qao,PP,Wao,Hao,Uao,Ug,Hne,Jao,Yao,BP,Kao,Zao,eno,Jg,Une,ono,rno,IP,tno,ano,nno,zn,Jne,sno,lno,NP,ino,dno,qP,cno,fno,mno,Yg,Yne,gno,hno,jP,pno,_no,uno,Qn,Kne,bno,vno,DP,Fno,Tno,GP,Mno,Eno,Cno,Wn,Zne,wno,Ano,OP,Lno,yno,VP,xno,$no,kno,Hn,ese,Sno,Rno,XP,Pno,Bno,zP,Ino,Nno,qno,Kg,ose,jno,Dno,QP,Gno,Ono,Vno,Un,rse,Xno,zno,WP,Qno,Wno,HP,Hno,Uno,Jno,Jn,tse,Yno,Kno,UP,Zno,eso,JP,oso,rso,tso,Yn,ase,aso,nso,YP,sso,lso,KP,iso,dso,cso,Kn,nse,fso,mso,ZP,gso,hso,eB,pso,_so,uso,Zn,sse,bso,vso,oB,Fso,Tso,rB,Mso,Eso,Cso,es,lse,wso,Aso,tB,Lso,yso,aB,xso,$so,kso,Zg,ise,Sso,Rso,nB,Pso,Bso,Iso,os,dse,Nso,qso,sB,jso,Dso,lB,Gso,Oso,Vso,eh,cse,Xso,zso,iB,Qso,Wso,Hso,rs,fse,Uso,Jso,dB,Yso,Kso,cB,Zso,elo,olo,ts,mse,rlo,tlo,fB,alo,nlo,mB,slo,llo,ilo,as,gse,dlo,clo,gB,flo,mlo,hB,glo,hlo,plo,oh,hse,_lo,ulo,pB,blo,vlo,Flo,ns,pse,Tlo,Mlo,_B,Elo,Clo,uB,wlo,Alo,Llo,ss,_se,ylo,xlo,bB,$lo,klo,vB,Slo,Rlo,Plo,rh,use,Blo,Ilo,FB,Nlo,qlo,jlo,ls,bse,Dlo,Glo,TB,Olo,Vlo,MB,Xlo,zlo,Qlo,is,vse,Wlo,Hlo,EB,Ulo,Jlo,CB,Ylo,Klo,Zlo,ds,Fse,eio,oio,wB,rio,tio,AB,aio,nio,sio,cs,Tse,lio,iio,LB,dio,cio,yB,fio,mio,gio,fs,Mse,hio,pio,xB,_io,uio,$B,bio,vio,Fio,ms,Ese,Tio,Mio,kB,Eio,Cio,SB,wio,Aio,Lio,gs,Cse,yio,xio,RB,$io,kio,PB,Sio,Rio,Pio,hs,wse,Bio,Iio,BB,Nio,qio,IB,jio,Dio,Gio,th,Ase,Oio,Vio,NB,Xio,zio,Qio,ps,Lse,Wio,Hio,qB,Uio,Jio,jB,Yio,Kio,Zio,ah,yse,edo,odo,DB,rdo,tdo,ado,nh,xse,ndo,sdo,GB,ldo,ido,ddo,_s,$se,cdo,fdo,OB,mdo,gdo,VB,hdo,pdo,_do,us,kse,udo,bdo,XB,vdo,Fdo,zB,Tdo,Mdo,Edo,bs,Sse,Cdo,wdo,QB,Ado,Ldo,WB,ydo,xdo,$do,sh,Rse,kdo,Sdo,HB,Rdo,Pdo,Bdo,vs,Pse,Ido,Ndo,UB,qdo,jdo,JB,Ddo,Gdo,Odo,Fs,Bse,Vdo,Xdo,YB,zdo,Qdo,KB,Wdo,Hdo,Udo,Ts,Ise,Jdo,Ydo,ZB,Kdo,Zdo,eI,eco,oco,rco,Ms,Nse,tco,aco,oI,nco,sco,rI,lco,ico,dco,Es,qse,cco,fco,tI,mco,gco,aI,hco,pco,_co,Cs,jse,uco,bco,nI,vco,Fco,sI,Tco,Mco,Eco,lh,Dse,Cco,wco,lI,Aco,Lco,yco,ws,Gse,xco,$co,iI,kco,Sco,dI,Rco,Pco,Bco,ih,Ose,Ico,Nco,cI,qco,jco,Dco,dh,Vse,Gco,Oco,fI,Vco,Xco,zco,ch,Xse,Qco,Wco,mI,Hco,Uco,Jco,fh,zse,Yco,Kco,gI,Zco,efo,ofo,As,Qse,rfo,tfo,hI,afo,nfo,pI,sfo,lfo,ifo,mh,Wse,dfo,cfo,_I,ffo,mfo,gfo,Ls,Hse,hfo,pfo,uI,_fo,ufo,bI,bfo,vfo,Ffo,ys,Use,Tfo,Mfo,vI,Efo,Cfo,FI,wfo,Afo,Lfo,xs,Jse,yfo,xfo,TI,$fo,kfo,MI,Sfo,Rfo,Pfo,$s,Yse,Bfo,Ifo,EI,Nfo,qfo,CI,jfo,Dfo,Gfo,ks,Kse,Ofo,Vfo,wI,Xfo,zfo,AI,Qfo,Wfo,Hfo,Ss,Zse,Ufo,Jfo,LI,Yfo,Kfo,yI,Zfo,emo,omo,gh,ele,rmo,tmo,xI,amo,nmo,smo,hh,ole,lmo,imo,$I,dmo,cmo,fmo,Rs,rle,mmo,gmo,kI,hmo,pmo,SI,_mo,umo,bmo,Ps,tle,vmo,Fmo,RI,Tmo,Mmo,PI,Emo,Cmo,wmo,Bs,ale,Amo,Lmo,BI,ymo,xmo,II,$mo,kmo,Smo,ph,nle,Rmo,Pmo,NI,Bmo,Imo,Nmo,_h,sle,qmo,jmo,qI,Dmo,Gmo,Omo,uh,lle,Vmo,Xmo,jI,zmo,Qmo,Wmo,Is,ile,Hmo,Umo,DI,Jmo,Ymo,GI,Kmo,Zmo,ego,Ns,dle,ogo,rgo,OI,tgo,ago,VI,ngo,sgo,lgo,bh,cle,igo,dgo,XI,cgo,fgo,mgo,vh,fle,ggo,hgo,zI,pgo,_go,ugo,Fh,mle,bgo,vgo,QI,Fgo,Tgo,Mgo,qs,gle,Ego,Cgo,WI,wgo,Ago,HI,Lgo,ygo,xgo,Th,hle,$go,kgo,UI,Sgo,Rgo,Pgo,Mh,ple,Bgo,Igo,JI,Ngo,qgo,jgo,js,_le,Dgo,Ggo,YI,Ogo,Vgo,KI,Xgo,zgo,Qgo,Ds,ule,Wgo,Hgo,ZI,Ugo,Jgo,eN,Ygo,Kgo,Zgo,Gs,ble,eho,oho,oN,rho,tho,rN,aho,nho,sho,Os,vle,lho,iho,tN,dho,cho,aN,fho,mho,gho,Eh,hho,Ch,Ow,pho,Fle,_ho,HGe,Si,wh,Tle,Vw,uho,Mle,bho,UGe,Lo,Xw,vho,zw,Fho,nN,Tho,Mho,Eho,Qw,Cho,Ele,who,Aho,Lho,He,Ww,yho,Cle,xho,$ho,Sa,kho,wle,Sho,Rho,Ale,Pho,Bho,Lle,Iho,Nho,qho,Y,Ah,yle,jho,Dho,sN,Gho,Oho,Vho,Lh,xle,Xho,zho,lN,Qho,Who,Hho,yh,$le,Uho,Jho,iN,Yho,Kho,Zho,xh,kle,epo,opo,dN,rpo,tpo,apo,$h,Sle,npo,spo,cN,lpo,ipo,dpo,kh,Rle,cpo,fpo,fN,mpo,gpo,hpo,Sh,Ple,ppo,_po,mN,upo,bpo,vpo,Rh,Ble,Fpo,Tpo,gN,Mpo,Epo,Cpo,Ph,Ile,wpo,Apo,hN,Lpo,ypo,xpo,Bh,Nle,$po,kpo,pN,Spo,Rpo,Ppo,Ih,qle,Bpo,Ipo,_N,Npo,qpo,jpo,Nh,jle,Dpo,Gpo,uN,Opo,Vpo,Xpo,qh,Dle,zpo,Qpo,bN,Wpo,Hpo,Upo,jh,Gle,Jpo,Ypo,vN,Kpo,Zpo,e_o,Dh,Ole,o_o,r_o,FN,t_o,a_o,n_o,Gh,Vle,s_o,l_o,TN,i_o,d_o,c_o,Oh,Xle,f_o,m_o,MN,g_o,h_o,p_o,Vh,zle,__o,u_o,EN,b_o,v_o,F_o,Xh,Qle,T_o,M_o,CN,E_o,C_o,w_o,zh,Wle,A_o,L_o,wN,y_o,x_o,$_o,Qh,Hle,k_o,S_o,AN,R_o,P_o,B_o,Wh,Ule,I_o,N_o,LN,q_o,j_o,D_o,Hh,Jle,G_o,O_o,yN,V_o,X_o,z_o,Uh,Yle,Q_o,W_o,xN,H_o,U_o,J_o,Jh,Kle,Y_o,K_o,$N,Z_o,euo,ouo,Yh,Zle,ruo,tuo,kN,auo,nuo,suo,Kh,eie,luo,iuo,SN,duo,cuo,fuo,Zh,oie,muo,guo,RN,huo,puo,_uo,ep,rie,uuo,buo,PN,vuo,Fuo,Tuo,op,tie,Muo,Euo,BN,Cuo,wuo,Auo,rp,aie,Luo,yuo,IN,xuo,$uo,kuo,tp,nie,Suo,Ruo,NN,Puo,Buo,Iuo,ap,Nuo,np,quo,sp,Hw,juo,sie,Duo,JGe,Ri,lp,lie,Uw,Guo,iie,Ouo,YGe,yo,Jw,Vuo,Yw,Xuo,qN,zuo,Quo,Wuo,Kw,Huo,die,Uuo,Juo,Yuo,Ue,Zw,Kuo,cie,Zuo,e1o,Pi,o1o,fie,r1o,t1o,mie,a1o,n1o,s1o,he,ip,gie,l1o,i1o,jN,d1o,c1o,f1o,dp,hie,m1o,g1o,pie,h1o,p1o,_1o,cp,_ie,u1o,b1o,DN,v1o,F1o,T1o,fp,uie,M1o,E1o,GN,C1o,w1o,A1o,mp,bie,L1o,y1o,ON,x1o,$1o,k1o,gp,vie,S1o,R1o,VN,P1o,B1o,I1o,hp,Fie,N1o,q1o,XN,j1o,D1o,G1o,pp,Tie,O1o,V1o,zN,X1o,z1o,Q1o,_p,Mie,W1o,H1o,QN,U1o,J1o,Y1o,up,Eie,K1o,Z1o,WN,e2o,o2o,r2o,bp,Cie,t2o,a2o,HN,n2o,s2o,l2o,vp,wie,i2o,d2o,UN,c2o,f2o,m2o,Fp,Aie,g2o,h2o,JN,p2o,_2o,u2o,Tp,Lie,b2o,v2o,YN,F2o,T2o,M2o,Mp,yie,E2o,C2o,KN,w2o,A2o,L2o,Ep,xie,y2o,x2o,ZN,$2o,k2o,S2o,Cp,$ie,R2o,P2o,eq,B2o,I2o,N2o,wp,q2o,Ap,j2o,Lp,eA,D2o,kie,G2o,KGe,Bi,yp,Sie,oA,O2o,Rie,V2o,ZGe,xo,rA,X2o,Ii,z2o,oq,Q2o,W2o,rq,H2o,U2o,J2o,tA,Y2o,Pie,K2o,Z2o,ebo,nt,aA,obo,Bie,rbo,tbo,Ni,abo,Iie,nbo,sbo,tq,lbo,ibo,dbo,xp,cbo,Je,nA,fbo,Nie,mbo,gbo,Ra,hbo,qie,pbo,_bo,jie,ubo,bbo,Die,vbo,Fbo,Tbo,y,$p,Gie,Mbo,Ebo,aq,Cbo,wbo,Abo,kp,Oie,Lbo,ybo,nq,xbo,$bo,kbo,Sp,Vie,Sbo,Rbo,sq,Pbo,Bbo,Ibo,Rp,Xie,Nbo,qbo,lq,jbo,Dbo,Gbo,Pp,zie,Obo,Vbo,iq,Xbo,zbo,Qbo,Bp,Qie,Wbo,Hbo,dq,Ubo,Jbo,Ybo,Ip,Wie,Kbo,Zbo,cq,evo,ovo,rvo,Np,Hie,tvo,avo,fq,nvo,svo,lvo,qp,Uie,ivo,dvo,mq,cvo,fvo,mvo,jp,Jie,gvo,hvo,gq,pvo,_vo,uvo,Dp,Yie,bvo,vvo,hq,Fvo,Tvo,Mvo,Gp,Kie,Evo,Cvo,pq,wvo,Avo,Lvo,Op,Zie,yvo,xvo,_q,$vo,kvo,Svo,Vp,ede,Rvo,Pvo,uq,Bvo,Ivo,Nvo,Xp,ode,qvo,jvo,bq,Dvo,Gvo,Ovo,zp,rde,Vvo,Xvo,vq,zvo,Qvo,Wvo,Qp,tde,Hvo,Uvo,Fq,Jvo,Yvo,Kvo,Wp,ade,Zvo,eFo,Tq,oFo,rFo,tFo,Hp,nde,aFo,nFo,Mq,sFo,lFo,iFo,Up,sde,dFo,cFo,Eq,fFo,mFo,gFo,Jp,lde,hFo,pFo,Cq,_Fo,uFo,bFo,Yp,ide,vFo,FFo,wq,TFo,MFo,EFo,Kp,dde,CFo,wFo,Aq,AFo,LFo,yFo,Zp,cde,xFo,$Fo,Lq,kFo,SFo,RFo,e_,fde,PFo,BFo,yq,IFo,NFo,qFo,o_,mde,jFo,DFo,xq,GFo,OFo,VFo,r_,gde,XFo,zFo,$q,QFo,WFo,HFo,t_,hde,UFo,JFo,kq,YFo,KFo,ZFo,a_,pde,e6o,o6o,Sq,r6o,t6o,a6o,n_,_de,n6o,s6o,Rq,l6o,i6o,d6o,s_,ude,c6o,f6o,Pq,m6o,g6o,h6o,l_,bde,p6o,_6o,Bq,u6o,b6o,v6o,i_,vde,F6o,T6o,Iq,M6o,E6o,C6o,Vs,Fde,w6o,A6o,Nq,L6o,y6o,qq,x6o,$6o,k6o,d_,Tde,S6o,R6o,jq,P6o,B6o,I6o,c_,Mde,N6o,q6o,Dq,j6o,D6o,G6o,f_,Ede,O6o,V6o,Gq,X6o,z6o,Q6o,m_,Cde,W6o,H6o,Oq,U6o,J6o,Y6o,g_,wde,K6o,Z6o,Vq,eTo,oTo,rTo,h_,Ade,tTo,aTo,Xq,nTo,sTo,lTo,p_,Lde,iTo,dTo,zq,cTo,fTo,mTo,__,yde,gTo,hTo,Qq,pTo,_To,uTo,u_,xde,bTo,vTo,Wq,FTo,TTo,MTo,b_,$de,ETo,CTo,Hq,wTo,ATo,LTo,v_,kde,yTo,xTo,Uq,$To,kTo,STo,F_,Sde,RTo,PTo,Jq,BTo,ITo,NTo,T_,Rde,qTo,jTo,Yq,DTo,GTo,OTo,M_,Pde,VTo,XTo,Kq,zTo,QTo,WTo,E_,Bde,HTo,UTo,Zq,JTo,YTo,KTo,C_,Ide,ZTo,e7o,ej,o7o,r7o,t7o,w_,Nde,a7o,n7o,oj,s7o,l7o,i7o,A_,qde,d7o,c7o,rj,f7o,m7o,g7o,L_,jde,h7o,p7o,tj,_7o,u7o,b7o,y_,Dde,v7o,F7o,aj,T7o,M7o,E7o,x_,Gde,C7o,w7o,nj,A7o,L7o,y7o,$_,Ode,x7o,$7o,sj,k7o,S7o,R7o,k_,Vde,P7o,B7o,lj,I7o,N7o,q7o,S_,Xde,j7o,D7o,ij,G7o,O7o,V7o,R_,zde,X7o,z7o,dj,Q7o,W7o,H7o,P_,Qde,U7o,J7o,cj,Y7o,K7o,Z7o,B_,Wde,e8o,o8o,fj,r8o,t8o,a8o,I_,Hde,n8o,s8o,mj,l8o,i8o,d8o,N_,Ude,c8o,f8o,gj,m8o,g8o,h8o,q_,Jde,p8o,_8o,hj,u8o,b8o,v8o,j_,Yde,F8o,T8o,pj,M8o,E8o,C8o,D_,Kde,w8o,A8o,_j,L8o,y8o,x8o,G_,Zde,$8o,k8o,uj,S8o,R8o,P8o,O_,ece,B8o,I8o,bj,N8o,q8o,j8o,V_,oce,D8o,G8o,vj,O8o,V8o,X8o,X_,rce,z8o,Q8o,Fj,W8o,H8o,U8o,z_,tce,J8o,Y8o,Tj,K8o,Z8o,e9o,Q_,ace,o9o,r9o,Mj,t9o,a9o,n9o,W_,nce,s9o,l9o,Ej,i9o,d9o,c9o,H_,sce,f9o,m9o,Cj,g9o,h9o,p9o,U_,lce,_9o,u9o,wj,b9o,v9o,F9o,J_,ice,T9o,M9o,Aj,E9o,C9o,w9o,Y_,dce,A9o,L9o,Lj,y9o,x9o,$9o,K_,cce,k9o,S9o,yj,R9o,P9o,B9o,Z_,fce,I9o,N9o,xj,q9o,j9o,D9o,eu,mce,G9o,O9o,$j,V9o,X9o,z9o,ou,gce,Q9o,W9o,kj,H9o,U9o,J9o,ru,hce,Y9o,K9o,Sj,Z9o,eMo,oMo,tu,pce,rMo,tMo,Rj,aMo,nMo,sMo,au,_ce,lMo,iMo,Pj,dMo,cMo,fMo,nu,uce,mMo,gMo,Bj,hMo,pMo,_Mo,su,bce,uMo,bMo,Ij,vMo,FMo,TMo,lu,vce,MMo,EMo,Nj,CMo,wMo,AMo,iu,Fce,LMo,yMo,qj,xMo,$Mo,kMo,du,Tce,SMo,RMo,jj,PMo,BMo,IMo,cu,Mce,NMo,qMo,Dj,jMo,DMo,GMo,fu,Ece,OMo,VMo,Gj,XMo,zMo,QMo,mu,Cce,WMo,HMo,Oj,UMo,JMo,YMo,gu,wce,KMo,ZMo,Vj,eEo,oEo,rEo,hu,Ace,tEo,aEo,Xj,nEo,sEo,lEo,pu,Lce,iEo,dEo,zj,cEo,fEo,mEo,_u,yce,gEo,hEo,Qj,pEo,_Eo,uEo,uu,xce,bEo,vEo,Wj,FEo,TEo,MEo,bu,$ce,EEo,CEo,Hj,wEo,AEo,LEo,vu,kce,yEo,xEo,Uj,$Eo,kEo,SEo,Fu,Sce,REo,PEo,Jj,BEo,IEo,NEo,Tu,Rce,qEo,jEo,Yj,DEo,GEo,OEo,Mu,Pce,VEo,XEo,Kj,zEo,QEo,WEo,Eu,Bce,HEo,UEo,Zj,JEo,YEo,KEo,Cu,Ice,ZEo,e4o,eD,o4o,r4o,t4o,wu,Nce,a4o,n4o,oD,s4o,l4o,i4o,Au,qce,d4o,c4o,rD,f4o,m4o,g4o,Lu,jce,h4o,p4o,tD,_4o,u4o,b4o,yu,v4o,Dce,F4o,T4o,Gce,M4o,E4o,xu,eOe,qi,$u,Oce,sA,C4o,Vce,w4o,oOe,$o,lA,A4o,ji,L4o,aD,y4o,x4o,nD,$4o,k4o,S4o,iA,R4o,Xce,P4o,B4o,I4o,st,dA,N4o,zce,q4o,j4o,Di,D4o,Qce,G4o,O4o,sD,V4o,X4o,z4o,ku,Q4o,Ye,cA,W4o,Wce,H4o,U4o,Pa,J4o,Hce,Y4o,K4o,Uce,Z4o,eCo,Jce,oCo,rCo,tCo,G,Su,Yce,aCo,nCo,lD,sCo,lCo,iCo,Ru,Kce,dCo,cCo,iD,fCo,mCo,gCo,Pu,Zce,hCo,pCo,dD,_Co,uCo,bCo,Bu,efe,vCo,FCo,cD,TCo,MCo,ECo,Iu,ofe,CCo,wCo,fD,ACo,LCo,yCo,Nu,rfe,xCo,$Co,mD,kCo,SCo,RCo,qu,tfe,PCo,BCo,gD,ICo,NCo,qCo,ju,afe,jCo,DCo,hD,GCo,OCo,VCo,Du,nfe,XCo,zCo,pD,QCo,WCo,HCo,Gu,sfe,UCo,JCo,_D,YCo,KCo,ZCo,Ou,lfe,e5o,o5o,uD,r5o,t5o,a5o,Vu,ife,n5o,s5o,bD,l5o,i5o,d5o,Xu,dfe,c5o,f5o,vD,m5o,g5o,h5o,zu,cfe,p5o,_5o,FD,u5o,b5o,v5o,Qu,ffe,F5o,T5o,TD,M5o,E5o,C5o,Wu,mfe,w5o,A5o,MD,L5o,y5o,x5o,Hu,gfe,$5o,k5o,ED,S5o,R5o,P5o,Uu,hfe,B5o,I5o,CD,N5o,q5o,j5o,Ju,pfe,D5o,G5o,wD,O5o,V5o,X5o,Yu,_fe,z5o,Q5o,AD,W5o,H5o,U5o,Ku,ufe,J5o,Y5o,LD,K5o,Z5o,e3o,Zu,bfe,o3o,r3o,yD,t3o,a3o,n3o,e1,vfe,s3o,l3o,xD,i3o,d3o,c3o,o1,Ffe,f3o,m3o,$D,g3o,h3o,p3o,r1,Tfe,_3o,u3o,kD,b3o,v3o,F3o,t1,Mfe,T3o,M3o,SD,E3o,C3o,w3o,a1,Efe,A3o,L3o,RD,y3o,x3o,$3o,n1,Cfe,k3o,S3o,PD,R3o,P3o,B3o,s1,wfe,I3o,N3o,BD,q3o,j3o,D3o,l1,Afe,G3o,O3o,ID,V3o,X3o,z3o,i1,Lfe,Q3o,W3o,ND,H3o,U3o,J3o,d1,yfe,Y3o,K3o,qD,Z3o,e0o,o0o,c1,xfe,r0o,t0o,jD,a0o,n0o,s0o,f1,$fe,l0o,i0o,DD,d0o,c0o,f0o,m1,kfe,m0o,g0o,GD,h0o,p0o,_0o,g1,Sfe,u0o,b0o,OD,v0o,F0o,T0o,h1,Rfe,M0o,E0o,VD,C0o,w0o,A0o,p1,Pfe,L0o,y0o,XD,x0o,$0o,k0o,_1,Bfe,S0o,R0o,zD,P0o,B0o,I0o,u1,Ife,N0o,q0o,QD,j0o,D0o,G0o,b1,Nfe,O0o,V0o,WD,X0o,z0o,Q0o,v1,qfe,W0o,H0o,HD,U0o,J0o,Y0o,F1,jfe,K0o,Z0o,UD,ewo,owo,rwo,T1,Dfe,two,awo,JD,nwo,swo,lwo,M1,iwo,Gfe,dwo,cwo,Ofe,fwo,mwo,E1,rOe,Gi,C1,Vfe,fA,gwo,Xfe,hwo,tOe,ko,mA,pwo,Oi,_wo,YD,uwo,bwo,KD,vwo,Fwo,Two,gA,Mwo,zfe,Ewo,Cwo,wwo,lt,hA,Awo,Qfe,Lwo,ywo,Vi,xwo,Wfe,$wo,kwo,ZD,Swo,Rwo,Pwo,w1,Bwo,Ke,pA,Iwo,Hfe,Nwo,qwo,Ba,jwo,Ufe,Dwo,Gwo,Jfe,Owo,Vwo,Yfe,Xwo,zwo,Qwo,z,A1,Kfe,Wwo,Hwo,eG,Uwo,Jwo,Ywo,L1,Zfe,Kwo,Zwo,oG,eAo,oAo,rAo,y1,eme,tAo,aAo,rG,nAo,sAo,lAo,x1,ome,iAo,dAo,tG,cAo,fAo,mAo,$1,rme,gAo,hAo,aG,pAo,_Ao,uAo,k1,tme,bAo,vAo,nG,FAo,TAo,MAo,S1,ame,EAo,CAo,sG,wAo,AAo,LAo,R1,nme,yAo,xAo,lG,$Ao,kAo,SAo,P1,sme,RAo,PAo,iG,BAo,IAo,NAo,B1,lme,qAo,jAo,dG,DAo,GAo,OAo,I1,ime,VAo,XAo,cG,zAo,QAo,WAo,N1,dme,HAo,UAo,fG,JAo,YAo,KAo,q1,cme,ZAo,eLo,mG,oLo,rLo,tLo,j1,fme,aLo,nLo,gG,sLo,lLo,iLo,D1,mme,dLo,cLo,hG,fLo,mLo,gLo,G1,gme,hLo,pLo,pG,_Lo,uLo,bLo,O1,hme,vLo,FLo,_G,TLo,MLo,ELo,V1,pme,CLo,wLo,uG,ALo,LLo,yLo,X1,_me,xLo,$Lo,bG,kLo,SLo,RLo,z1,ume,PLo,BLo,vG,ILo,NLo,qLo,Q1,bme,jLo,DLo,FG,GLo,OLo,VLo,W1,vme,XLo,zLo,TG,QLo,WLo,HLo,H1,Fme,ULo,JLo,MG,YLo,KLo,ZLo,U1,Tme,eyo,oyo,EG,ryo,tyo,ayo,J1,Mme,nyo,syo,CG,lyo,iyo,dyo,Y1,Eme,cyo,fyo,wG,myo,gyo,hyo,K1,Cme,pyo,_yo,AG,uyo,byo,vyo,Z1,wme,Fyo,Tyo,LG,Myo,Eyo,Cyo,e2,Ame,wyo,Ayo,yG,Lyo,yyo,xyo,o2,Lme,$yo,kyo,xG,Syo,Ryo,Pyo,r2,yme,Byo,Iyo,$G,Nyo,qyo,jyo,t2,xme,Dyo,Gyo,kG,Oyo,Vyo,Xyo,a2,$me,zyo,Qyo,SG,Wyo,Hyo,Uyo,n2,kme,Jyo,Yyo,RG,Kyo,Zyo,exo,s2,Sme,oxo,rxo,PG,txo,axo,nxo,l2,Rme,sxo,lxo,BG,ixo,dxo,cxo,i2,Pme,fxo,mxo,IG,gxo,hxo,pxo,d2,Bme,_xo,uxo,NG,bxo,vxo,Fxo,c2,Txo,Ime,Mxo,Exo,Nme,Cxo,wxo,f2,aOe,Xi,m2,qme,_A,Axo,jme,Lxo,nOe,So,uA,yxo,zi,xxo,qG,$xo,kxo,jG,Sxo,Rxo,Pxo,bA,Bxo,Dme,Ixo,Nxo,qxo,it,vA,jxo,Gme,Dxo,Gxo,Qi,Oxo,Ome,Vxo,Xxo,DG,zxo,Qxo,Wxo,g2,Hxo,Ze,FA,Uxo,Vme,Jxo,Yxo,Ia,Kxo,Xme,Zxo,e$o,zme,o$o,r$o,Qme,t$o,a$o,n$o,Q,h2,Wme,s$o,l$o,GG,i$o,d$o,c$o,p2,Hme,f$o,m$o,OG,g$o,h$o,p$o,_2,Ume,_$o,u$o,VG,b$o,v$o,F$o,u2,Jme,T$o,M$o,XG,E$o,C$o,w$o,b2,Yme,A$o,L$o,zG,y$o,x$o,$$o,v2,Kme,k$o,S$o,QG,R$o,P$o,B$o,F2,Zme,I$o,N$o,WG,q$o,j$o,D$o,T2,ege,G$o,O$o,HG,V$o,X$o,z$o,M2,oge,Q$o,W$o,UG,H$o,U$o,J$o,E2,rge,Y$o,K$o,JG,Z$o,eko,oko,C2,tge,rko,tko,YG,ako,nko,sko,w2,age,lko,iko,KG,dko,cko,fko,A2,nge,mko,gko,ZG,hko,pko,_ko,L2,sge,uko,bko,eO,vko,Fko,Tko,y2,lge,Mko,Eko,oO,Cko,wko,Ako,x2,ige,Lko,yko,rO,xko,$ko,kko,$2,dge,Sko,Rko,tO,Pko,Bko,Iko,k2,cge,Nko,qko,aO,jko,Dko,Gko,S2,fge,Oko,Vko,nO,Xko,zko,Qko,R2,mge,Wko,Hko,sO,Uko,Jko,Yko,P2,gge,Kko,Zko,lO,eSo,oSo,rSo,B2,hge,tSo,aSo,iO,nSo,sSo,lSo,I2,pge,iSo,dSo,dO,cSo,fSo,mSo,N2,_ge,gSo,hSo,cO,pSo,_So,uSo,q2,uge,bSo,vSo,fO,FSo,TSo,MSo,j2,bge,ESo,CSo,mO,wSo,ASo,LSo,D2,vge,ySo,xSo,gO,$So,kSo,SSo,G2,Fge,RSo,PSo,hO,BSo,ISo,NSo,O2,Tge,qSo,jSo,pO,DSo,GSo,OSo,V2,Mge,VSo,XSo,_O,zSo,QSo,WSo,X2,Ege,HSo,USo,uO,JSo,YSo,KSo,z2,Cge,ZSo,eRo,bO,oRo,rRo,tRo,Q2,wge,aRo,nRo,Age,sRo,lRo,iRo,W2,Lge,dRo,cRo,vO,fRo,mRo,gRo,H2,yge,hRo,pRo,FO,_Ro,uRo,bRo,U2,xge,vRo,FRo,TO,TRo,MRo,ERo,J2,$ge,CRo,wRo,MO,ARo,LRo,yRo,Y2,xRo,kge,$Ro,kRo,Sge,SRo,RRo,K2,sOe,Wi,Z2,Rge,TA,PRo,Pge,BRo,lOe,Ro,MA,IRo,Hi,NRo,EO,qRo,jRo,CO,DRo,GRo,ORo,EA,VRo,Bge,XRo,zRo,QRo,dt,CA,WRo,Ige,HRo,URo,Ui,JRo,Nge,YRo,KRo,wO,ZRo,ePo,oPo,eb,rPo,eo,wA,tPo,qge,aPo,nPo,Na,sPo,jge,lPo,iPo,Dge,dPo,cPo,Gge,fPo,mPo,gPo,pe,ob,Oge,hPo,pPo,AO,_Po,uPo,bPo,rb,Vge,vPo,FPo,LO,TPo,MPo,EPo,tb,Xge,CPo,wPo,yO,APo,LPo,yPo,ab,zge,xPo,$Po,xO,kPo,SPo,RPo,nb,Qge,PPo,BPo,$O,IPo,NPo,qPo,sb,Wge,jPo,DPo,kO,GPo,OPo,VPo,lb,Hge,XPo,zPo,SO,QPo,WPo,HPo,ib,Uge,UPo,JPo,RO,YPo,KPo,ZPo,db,Jge,eBo,oBo,PO,rBo,tBo,aBo,cb,Yge,nBo,sBo,BO,lBo,iBo,dBo,fb,Kge,cBo,fBo,IO,mBo,gBo,hBo,mb,Zge,pBo,_Bo,NO,uBo,bBo,vBo,gb,ehe,FBo,TBo,qO,MBo,EBo,CBo,hb,ohe,wBo,ABo,jO,LBo,yBo,xBo,pb,rhe,$Bo,kBo,DO,SBo,RBo,PBo,_b,the,BBo,IBo,GO,NBo,qBo,jBo,ub,ahe,DBo,GBo,OO,OBo,VBo,XBo,bb,zBo,nhe,QBo,WBo,she,HBo,UBo,vb,iOe,Ji,Fb,lhe,AA,JBo,ihe,YBo,dOe,Po,LA,KBo,Yi,ZBo,VO,eIo,oIo,XO,rIo,tIo,aIo,yA,nIo,dhe,sIo,lIo,iIo,ct,xA,dIo,che,cIo,fIo,Ki,mIo,fhe,gIo,hIo,zO,pIo,_Io,uIo,Tb,bIo,oo,$A,vIo,mhe,FIo,TIo,qa,MIo,ghe,EIo,CIo,hhe,wIo,AIo,phe,LIo,yIo,xIo,N,Mb,_he,$Io,kIo,QO,SIo,RIo,PIo,Eb,uhe,BIo,IIo,WO,NIo,qIo,jIo,Cb,bhe,DIo,GIo,HO,OIo,VIo,XIo,wb,vhe,zIo,QIo,UO,WIo,HIo,UIo,Ab,Fhe,JIo,YIo,JO,KIo,ZIo,eNo,Lb,The,oNo,rNo,YO,tNo,aNo,nNo,yb,Mhe,sNo,lNo,KO,iNo,dNo,cNo,xb,Ehe,fNo,mNo,ZO,gNo,hNo,pNo,$b,Che,_No,uNo,eV,bNo,vNo,FNo,kb,whe,TNo,MNo,oV,ENo,CNo,wNo,Sb,Ahe,ANo,LNo,rV,yNo,xNo,$No,Rb,Lhe,kNo,SNo,tV,RNo,PNo,BNo,Pb,yhe,INo,NNo,aV,qNo,jNo,DNo,Bb,xhe,GNo,ONo,nV,VNo,XNo,zNo,Ib,$he,QNo,WNo,sV,HNo,UNo,JNo,Nb,khe,YNo,KNo,lV,ZNo,eqo,oqo,qb,She,rqo,tqo,iV,aqo,nqo,sqo,jb,Rhe,lqo,iqo,dV,dqo,cqo,fqo,Db,Phe,mqo,gqo,cV,hqo,pqo,_qo,Gb,Bhe,uqo,bqo,fV,vqo,Fqo,Tqo,Ob,Ihe,Mqo,Eqo,mV,Cqo,wqo,Aqo,Vb,Nhe,Lqo,yqo,gV,xqo,$qo,kqo,Xb,qhe,Sqo,Rqo,hV,Pqo,Bqo,Iqo,zb,jhe,Nqo,qqo,pV,jqo,Dqo,Gqo,Qb,Dhe,Oqo,Vqo,_V,Xqo,zqo,Qqo,Wb,Ghe,Wqo,Hqo,uV,Uqo,Jqo,Yqo,Hb,Ohe,Kqo,Zqo,bV,ejo,ojo,rjo,Ub,Vhe,tjo,ajo,vV,njo,sjo,ljo,Jb,Xhe,ijo,djo,FV,cjo,fjo,mjo,Yb,zhe,gjo,hjo,TV,pjo,_jo,ujo,Kb,Qhe,bjo,vjo,MV,Fjo,Tjo,Mjo,Zb,Whe,Ejo,Cjo,EV,wjo,Ajo,Ljo,ev,Hhe,yjo,xjo,CV,$jo,kjo,Sjo,ov,Uhe,Rjo,Pjo,wV,Bjo,Ijo,Njo,rv,Jhe,qjo,jjo,AV,Djo,Gjo,Ojo,tv,Yhe,Vjo,Xjo,LV,zjo,Qjo,Wjo,av,Khe,Hjo,Ujo,yV,Jjo,Yjo,Kjo,nv,Zhe,Zjo,eDo,xV,oDo,rDo,tDo,sv,epe,aDo,nDo,$V,sDo,lDo,iDo,lv,ope,dDo,cDo,kV,fDo,mDo,gDo,iv,rpe,hDo,pDo,SV,_Do,uDo,bDo,dv,tpe,vDo,FDo,RV,TDo,MDo,EDo,cv,ape,CDo,wDo,PV,ADo,LDo,yDo,fv,npe,xDo,$Do,BV,kDo,SDo,RDo,mv,spe,PDo,BDo,IV,IDo,NDo,qDo,gv,lpe,jDo,DDo,NV,GDo,ODo,VDo,hv,ipe,XDo,zDo,qV,QDo,WDo,HDo,pv,dpe,UDo,JDo,jV,YDo,KDo,ZDo,_v,cpe,eGo,oGo,DV,rGo,tGo,aGo,uv,nGo,fpe,sGo,lGo,mpe,iGo,dGo,bv,cOe,Zi,vv,gpe,kA,cGo,hpe,fGo,fOe,Bo,SA,mGo,ed,gGo,GV,hGo,pGo,OV,_Go,uGo,bGo,RA,vGo,ppe,FGo,TGo,MGo,ft,PA,EGo,_pe,CGo,wGo,od,AGo,upe,LGo,yGo,VV,xGo,$Go,kGo,Fv,SGo,ro,BA,RGo,bpe,PGo,BGo,ja,IGo,vpe,NGo,qGo,Fpe,jGo,DGo,Tpe,GGo,OGo,VGo,Z,Tv,Mpe,XGo,zGo,XV,QGo,WGo,HGo,Mv,Epe,UGo,JGo,zV,YGo,KGo,ZGo,Ev,Cpe,eOo,oOo,QV,rOo,tOo,aOo,Cv,wpe,nOo,sOo,WV,lOo,iOo,dOo,wv,Ape,cOo,fOo,HV,mOo,gOo,hOo,Av,Lpe,pOo,_Oo,UV,uOo,bOo,vOo,Lv,ype,FOo,TOo,JV,MOo,EOo,COo,yv,xpe,wOo,AOo,YV,LOo,yOo,xOo,xv,$pe,$Oo,kOo,KV,SOo,ROo,POo,$v,kpe,BOo,IOo,ZV,NOo,qOo,jOo,kv,Spe,DOo,GOo,eX,OOo,VOo,XOo,Sv,Rpe,zOo,QOo,oX,WOo,HOo,UOo,Rv,Ppe,JOo,YOo,rX,KOo,ZOo,eVo,Pv,Bpe,oVo,rVo,tX,tVo,aVo,nVo,Bv,Ipe,sVo,lVo,aX,iVo,dVo,cVo,Iv,Npe,fVo,mVo,nX,gVo,hVo,pVo,Nv,qpe,_Vo,uVo,sX,bVo,vVo,FVo,qv,jpe,TVo,MVo,lX,EVo,CVo,wVo,jv,Dpe,AVo,LVo,iX,yVo,xVo,$Vo,Dv,Gpe,kVo,SVo,dX,RVo,PVo,BVo,Gv,Ope,IVo,NVo,cX,qVo,jVo,DVo,Ov,Vpe,GVo,OVo,fX,VVo,XVo,zVo,Vv,Xpe,QVo,WVo,mX,HVo,UVo,JVo,Xv,zpe,YVo,KVo,gX,ZVo,eXo,oXo,zv,Qpe,rXo,tXo,hX,aXo,nXo,sXo,Qv,Wpe,lXo,iXo,pX,dXo,cXo,fXo,Wv,Hpe,mXo,gXo,_X,hXo,pXo,_Xo,Hv,Upe,uXo,bXo,uX,vXo,FXo,TXo,Uv,Jpe,MXo,EXo,bX,CXo,wXo,AXo,Jv,Ype,LXo,yXo,vX,xXo,$Xo,kXo,Yv,SXo,Kpe,RXo,PXo,Zpe,BXo,IXo,Kv,mOe,rd,Zv,e_e,IA,NXo,o_e,qXo,gOe,Io,NA,jXo,td,DXo,FX,GXo,OXo,TX,VXo,XXo,zXo,qA,QXo,r_e,WXo,HXo,UXo,mt,jA,JXo,t_e,YXo,KXo,ad,ZXo,a_e,ezo,ozo,MX,rzo,tzo,azo,eF,nzo,to,DA,szo,n_e,lzo,izo,Da,dzo,s_e,czo,fzo,l_e,mzo,gzo,i_e,hzo,pzo,_zo,No,oF,d_e,uzo,bzo,EX,vzo,Fzo,Tzo,rF,c_e,Mzo,Ezo,CX,Czo,wzo,Azo,tF,f_e,Lzo,yzo,wX,xzo,$zo,kzo,aF,m_e,Szo,Rzo,AX,Pzo,Bzo,Izo,nF,g_e,Nzo,qzo,LX,jzo,Dzo,Gzo,sF,h_e,Ozo,Vzo,yX,Xzo,zzo,Qzo,lF,Wzo,p_e,Hzo,Uzo,__e,Jzo,Yzo,iF,hOe,nd,dF,u_e,GA,Kzo,b_e,Zzo,pOe,qo,OA,eQo,sd,oQo,xX,rQo,tQo,$X,aQo,nQo,sQo,VA,lQo,v_e,iQo,dQo,cQo,gt,XA,fQo,F_e,mQo,gQo,ld,hQo,T_e,pQo,_Qo,kX,uQo,bQo,vQo,cF,FQo,ao,zA,TQo,M_e,MQo,EQo,Ga,CQo,E_e,wQo,AQo,C_e,LQo,yQo,w_e,xQo,$Qo,kQo,H,fF,A_e,SQo,RQo,SX,PQo,BQo,IQo,mF,L_e,NQo,qQo,RX,jQo,DQo,GQo,gF,y_e,OQo,VQo,PX,XQo,zQo,QQo,hF,x_e,WQo,HQo,BX,UQo,JQo,YQo,pF,$_e,KQo,ZQo,IX,eWo,oWo,rWo,_F,k_e,tWo,aWo,NX,nWo,sWo,lWo,uF,S_e,iWo,dWo,qX,cWo,fWo,mWo,bF,R_e,gWo,hWo,jX,pWo,_Wo,uWo,vF,P_e,bWo,vWo,DX,FWo,TWo,MWo,FF,B_e,EWo,CWo,GX,wWo,AWo,LWo,TF,I_e,yWo,xWo,OX,$Wo,kWo,SWo,MF,N_e,RWo,PWo,VX,BWo,IWo,NWo,EF,q_e,qWo,jWo,XX,DWo,GWo,OWo,CF,j_e,VWo,XWo,zX,zWo,QWo,WWo,wF,D_e,HWo,UWo,QX,JWo,YWo,KWo,AF,G_e,ZWo,eHo,WX,oHo,rHo,tHo,LF,O_e,aHo,nHo,HX,sHo,lHo,iHo,yF,V_e,dHo,cHo,UX,fHo,mHo,gHo,xF,X_e,hHo,pHo,JX,_Ho,uHo,bHo,$F,z_e,vHo,FHo,YX,THo,MHo,EHo,kF,Q_e,CHo,wHo,KX,AHo,LHo,yHo,SF,W_e,xHo,$Ho,ZX,kHo,SHo,RHo,RF,H_e,PHo,BHo,ez,IHo,NHo,qHo,PF,U_e,jHo,DHo,oz,GHo,OHo,VHo,BF,J_e,XHo,zHo,rz,QHo,WHo,HHo,IF,Y_e,UHo,JHo,tz,YHo,KHo,ZHo,NF,K_e,eUo,oUo,az,rUo,tUo,aUo,qF,Z_e,nUo,sUo,nz,lUo,iUo,dUo,jF,eue,cUo,fUo,sz,mUo,gUo,hUo,DF,oue,pUo,_Uo,lz,uUo,bUo,vUo,GF,rue,FUo,TUo,iz,MUo,EUo,CUo,OF,tue,wUo,AUo,dz,LUo,yUo,xUo,VF,aue,$Uo,kUo,cz,SUo,RUo,PUo,XF,nue,BUo,IUo,fz,NUo,qUo,jUo,zF,sue,DUo,GUo,mz,OUo,VUo,XUo,QF,lue,zUo,QUo,gz,WUo,HUo,UUo,WF,JUo,iue,YUo,KUo,due,ZUo,eJo,HF,_Oe,id,UF,cue,QA,oJo,fue,rJo,uOe,jo,WA,tJo,dd,aJo,hz,nJo,sJo,pz,lJo,iJo,dJo,HA,cJo,mue,fJo,mJo,gJo,ht,UA,hJo,gue,pJo,_Jo,cd,uJo,hue,bJo,vJo,_z,FJo,TJo,MJo,JF,EJo,no,JA,CJo,pue,wJo,AJo,Oa,LJo,_ue,yJo,xJo,uue,$Jo,kJo,bue,SJo,RJo,PJo,V,YF,vue,BJo,IJo,uz,NJo,qJo,jJo,KF,Fue,DJo,GJo,bz,OJo,VJo,XJo,ZF,Tue,zJo,QJo,vz,WJo,HJo,UJo,e6,Mue,JJo,YJo,Fz,KJo,ZJo,eYo,o6,Eue,oYo,rYo,Tz,tYo,aYo,nYo,r6,Cue,sYo,lYo,Mz,iYo,dYo,cYo,t6,wue,fYo,mYo,Ez,gYo,hYo,pYo,a6,Aue,_Yo,uYo,Cz,bYo,vYo,FYo,n6,Lue,TYo,MYo,wz,EYo,CYo,wYo,s6,yue,AYo,LYo,Az,yYo,xYo,$Yo,l6,xue,kYo,SYo,Lz,RYo,PYo,BYo,i6,$ue,IYo,NYo,yz,qYo,jYo,DYo,d6,kue,GYo,OYo,xz,VYo,XYo,zYo,c6,Sue,QYo,WYo,$z,HYo,UYo,JYo,f6,Rue,YYo,KYo,kz,ZYo,eKo,oKo,m6,Pue,rKo,tKo,Sz,aKo,nKo,sKo,g6,Bue,lKo,iKo,Rz,dKo,cKo,fKo,h6,Iue,mKo,gKo,Pz,hKo,pKo,_Ko,p6,Nue,uKo,bKo,Bz,vKo,FKo,TKo,_6,que,MKo,EKo,Iz,CKo,wKo,AKo,u6,jue,LKo,yKo,Nz,xKo,$Ko,kKo,b6,Due,SKo,RKo,qz,PKo,BKo,IKo,v6,Gue,NKo,qKo,jz,jKo,DKo,GKo,F6,Oue,OKo,VKo,Dz,XKo,zKo,QKo,T6,Vue,WKo,HKo,Gz,UKo,JKo,YKo,M6,Xue,KKo,ZKo,Oz,eZo,oZo,rZo,E6,zue,tZo,aZo,Vz,nZo,sZo,lZo,C6,Que,iZo,dZo,Xz,cZo,fZo,mZo,w6,Wue,gZo,hZo,zz,pZo,_Zo,uZo,A6,Hue,bZo,vZo,Qz,FZo,TZo,MZo,L6,Uue,EZo,CZo,Wz,wZo,AZo,LZo,y6,Jue,yZo,xZo,Hz,$Zo,kZo,SZo,x6,Yue,RZo,PZo,Uz,BZo,IZo,NZo,$6,Kue,qZo,jZo,Jz,DZo,GZo,OZo,k6,Zue,VZo,XZo,Yz,zZo,QZo,WZo,S6,e1e,HZo,UZo,Kz,JZo,YZo,KZo,R6,o1e,ZZo,eer,Zz,oer,rer,ter,P6,r1e,aer,ner,eQ,ser,ler,ier,B6,t1e,der,cer,oQ,fer,mer,ger,I6,a1e,her,per,rQ,_er,uer,ber,N6,n1e,ver,Fer,tQ,Ter,Mer,Eer,q6,Cer,s1e,wer,Aer,l1e,Ler,yer,j6,bOe,fd,D6,i1e,YA,xer,d1e,$er,vOe,Do,KA,ker,md,Ser,aQ,Rer,Per,nQ,Ber,Ier,Ner,ZA,qer,c1e,jer,Der,Ger,pt,eL,Oer,f1e,Ver,Xer,gd,zer,m1e,Qer,Wer,sQ,Her,Uer,Jer,G6,Yer,so,oL,Ker,g1e,Zer,eor,Va,oor,h1e,ror,tor,p1e,aor,nor,_1e,sor,lor,ior,u1e,O6,b1e,dor,cor,lQ,mor,gor,hor,V6,por,v1e,_or,uor,F1e,bor,vor,X6,FOe,hd,z6,T1e,rL,For,M1e,Tor,TOe,Go,tL,Mor,pd,Eor,iQ,Cor,wor,dQ,Aor,Lor,yor,aL,xor,E1e,$or,kor,Sor,_t,nL,Ror,C1e,Por,Bor,_d,Ior,w1e,Nor,qor,cQ,jor,Dor,Gor,Q6,Oor,lo,sL,Vor,A1e,Xor,zor,Xa,Qor,L1e,Wor,Hor,y1e,Uor,Jor,x1e,Yor,Kor,Zor,Fe,W6,$1e,err,orr,fQ,rrr,trr,arr,H6,k1e,nrr,srr,mQ,lrr,irr,drr,U6,S1e,crr,frr,gQ,mrr,grr,hrr,J6,R1e,prr,_rr,hQ,urr,brr,vrr,Xs,P1e,Frr,Trr,pQ,Mrr,Err,_Q,Crr,wrr,Arr,Y6,B1e,Lrr,yrr,uQ,xrr,$rr,krr,zs,I1e,Srr,Rrr,bQ,Prr,Brr,vQ,Irr,Nrr,qrr,ut,N1e,jrr,Drr,FQ,Grr,Orr,TQ,Vrr,Xrr,MQ,zrr,Qrr,Wrr,K6,q1e,Hrr,Urr,EQ,Jrr,Yrr,Krr,Z6,j1e,Zrr,etr,CQ,otr,rtr,ttr,eT,D1e,atr,ntr,wQ,str,ltr,itr,oT,G1e,dtr,ctr,AQ,ftr,mtr,gtr,rT,O1e,htr,ptr,LQ,_tr,utr,btr,tT,V1e,vtr,Ftr,yQ,Ttr,Mtr,Etr,aT,X1e,Ctr,wtr,xQ,Atr,Ltr,ytr,nT,xtr,z1e,$tr,ktr,Q1e,Str,Rtr,sT,MOe,ud,lT,W1e,lL,Ptr,H1e,Btr,EOe,Oo,iL,Itr,bd,Ntr,$Q,qtr,jtr,kQ,Dtr,Gtr,Otr,dL,Vtr,U1e,Xtr,ztr,Qtr,bt,cL,Wtr,J1e,Htr,Utr,vd,Jtr,Y1e,Ytr,Ktr,SQ,Ztr,ear,oar,iT,rar,io,fL,tar,K1e,aar,nar,za,sar,Z1e,lar,iar,e2e,dar,car,o2e,far,mar,gar,r2e,dT,t2e,har,par,RQ,_ar,uar,bar,cT,Far,a2e,Tar,Mar,n2e,Ear,Car,fT,COe,Fd,mT,s2e,mL,war,l2e,Aar,wOe,Vo,gL,Lar,Td,yar,PQ,xar,$ar,BQ,kar,Sar,Rar,hL,Par,i2e,Bar,Iar,Nar,vt,pL,qar,d2e,jar,Dar,Md,Gar,c2e,Oar,Var,IQ,Xar,zar,Qar,gT,War,co,_L,Har,f2e,Uar,Jar,Qa,Yar,m2e,Kar,Zar,g2e,enr,onr,h2e,rnr,tnr,anr,p2e,hT,_2e,nnr,snr,NQ,lnr,inr,dnr,pT,cnr,u2e,fnr,mnr,b2e,gnr,hnr,_T,AOe,Ed,uT,v2e,uL,pnr,F2e,_nr,LOe,Xo,bL,unr,Cd,bnr,qQ,vnr,Fnr,jQ,Tnr,Mnr,Enr,vL,Cnr,T2e,wnr,Anr,Lnr,Ft,FL,ynr,M2e,xnr,$nr,wd,knr,E2e,Snr,Rnr,DQ,Pnr,Bnr,Inr,bT,Nnr,fo,TL,qnr,C2e,jnr,Dnr,Wa,Gnr,w2e,Onr,Vnr,A2e,Xnr,znr,L2e,Qnr,Wnr,Hnr,Pe,vT,y2e,Unr,Jnr,GQ,Ynr,Knr,Znr,FT,x2e,esr,osr,OQ,rsr,tsr,asr,TT,$2e,nsr,ssr,VQ,lsr,isr,dsr,MT,k2e,csr,fsr,XQ,msr,gsr,hsr,ET,S2e,psr,_sr,zQ,usr,bsr,vsr,CT,R2e,Fsr,Tsr,QQ,Msr,Esr,Csr,wT,P2e,wsr,Asr,WQ,Lsr,ysr,xsr,AT,B2e,$sr,ksr,HQ,Ssr,Rsr,Psr,LT,I2e,Bsr,Isr,UQ,Nsr,qsr,jsr,yT,Dsr,N2e,Gsr,Osr,q2e,Vsr,Xsr,xT,yOe,Ad,$T,j2e,ML,zsr,D2e,Qsr,xOe,zo,EL,Wsr,Ld,Hsr,JQ,Usr,Jsr,YQ,Ysr,Ksr,Zsr,CL,elr,G2e,olr,rlr,tlr,Tt,wL,alr,O2e,nlr,slr,yd,llr,V2e,ilr,dlr,KQ,clr,flr,mlr,kT,glr,mo,AL,hlr,X2e,plr,_lr,Ha,ulr,z2e,blr,vlr,Q2e,Flr,Tlr,W2e,Mlr,Elr,Clr,et,ST,H2e,wlr,Alr,ZQ,Llr,ylr,xlr,RT,U2e,$lr,klr,eW,Slr,Rlr,Plr,PT,J2e,Blr,Ilr,oW,Nlr,qlr,jlr,BT,Y2e,Dlr,Glr,rW,Olr,Vlr,Xlr,IT,K2e,zlr,Qlr,tW,Wlr,Hlr,Ulr,NT,Jlr,Z2e,Ylr,Klr,ebe,Zlr,eir,qT,$Oe,xd,jT,obe,LL,oir,rbe,rir,kOe,Qo,yL,tir,$d,air,aW,nir,sir,nW,lir,iir,dir,xL,cir,tbe,fir,mir,gir,Mt,$L,hir,abe,pir,_ir,kd,uir,nbe,bir,vir,sW,Fir,Tir,Mir,DT,Eir,go,kL,Cir,sbe,wir,Air,Ua,Lir,lbe,yir,xir,ibe,$ir,kir,dbe,Sir,Rir,Pir,Le,GT,cbe,Bir,Iir,lW,Nir,qir,jir,OT,fbe,Dir,Gir,iW,Oir,Vir,Xir,VT,mbe,zir,Qir,dW,Wir,Hir,Uir,XT,gbe,Jir,Yir,cW,Kir,Zir,edr,zT,hbe,odr,rdr,fW,tdr,adr,ndr,QT,pbe,sdr,ldr,mW,idr,ddr,cdr,WT,_be,fdr,mdr,gW,gdr,hdr,pdr,HT,ube,_dr,udr,hW,bdr,vdr,Fdr,UT,bbe,Tdr,Mdr,pW,Edr,Cdr,wdr,JT,vbe,Adr,Ldr,_W,ydr,xdr,$dr,YT,kdr,Fbe,Sdr,Rdr,Tbe,Pdr,Bdr,KT,SOe,Sd,ZT,Mbe,SL,Idr,Ebe,Ndr,ROe,Wo,RL,qdr,Rd,jdr,uW,Ddr,Gdr,bW,Odr,Vdr,Xdr,PL,zdr,Cbe,Qdr,Wdr,Hdr,Et,BL,Udr,wbe,Jdr,Ydr,Pd,Kdr,Abe,Zdr,ecr,vW,ocr,rcr,tcr,e7,acr,ho,IL,ncr,Lbe,scr,lcr,Ja,icr,ybe,dcr,ccr,xbe,fcr,mcr,$be,gcr,hcr,pcr,NL,o7,kbe,_cr,ucr,FW,bcr,vcr,Fcr,r7,Sbe,Tcr,Mcr,TW,Ecr,Ccr,wcr,t7,Acr,Rbe,Lcr,ycr,Pbe,xcr,$cr,a7,POe,Bd,n7,Bbe,qL,kcr,Ibe,Scr,BOe,Ho,jL,Rcr,Id,Pcr,MW,Bcr,Icr,EW,Ncr,qcr,jcr,DL,Dcr,Nbe,Gcr,Ocr,Vcr,Ct,GL,Xcr,qbe,zcr,Qcr,Nd,Wcr,jbe,Hcr,Ucr,CW,Jcr,Ycr,Kcr,s7,Zcr,po,OL,efr,Dbe,ofr,rfr,Ya,tfr,Gbe,afr,nfr,Obe,sfr,lfr,Vbe,ifr,dfr,cfr,ot,l7,Xbe,ffr,mfr,wW,gfr,hfr,pfr,i7,zbe,_fr,ufr,AW,bfr,vfr,Ffr,d7,Qbe,Tfr,Mfr,LW,Efr,Cfr,wfr,c7,Wbe,Afr,Lfr,yW,yfr,xfr,$fr,f7,Hbe,kfr,Sfr,xW,Rfr,Pfr,Bfr,m7,Ifr,Ube,Nfr,qfr,Jbe,jfr,Dfr,g7,IOe,qd,h7,Ybe,VL,Gfr,Kbe,Ofr,NOe,Uo,XL,Vfr,jd,Xfr,$W,zfr,Qfr,kW,Wfr,Hfr,Ufr,zL,Jfr,Zbe,Yfr,Kfr,Zfr,wt,QL,emr,eve,omr,rmr,Dd,tmr,ove,amr,nmr,SW,smr,lmr,imr,p7,dmr,_o,WL,cmr,rve,fmr,mmr,Ka,gmr,tve,hmr,pmr,ave,_mr,umr,nve,bmr,vmr,Fmr,Gd,_7,sve,Tmr,Mmr,RW,Emr,Cmr,wmr,u7,lve,Amr,Lmr,PW,ymr,xmr,$mr,b7,ive,kmr,Smr,BW,Rmr,Pmr,Bmr,v7,Imr,dve,Nmr,qmr,cve,jmr,Dmr,F7,qOe,Od,T7,fve,HL,Gmr,mve,Omr,jOe,Jo,UL,Vmr,Vd,Xmr,IW,zmr,Qmr,NW,Wmr,Hmr,Umr,JL,Jmr,gve,Ymr,Kmr,Zmr,At,YL,egr,hve,ogr,rgr,Xd,tgr,pve,agr,ngr,qW,sgr,lgr,igr,M7,dgr,uo,KL,cgr,_ve,fgr,mgr,Za,ggr,uve,hgr,pgr,bve,_gr,ugr,vve,bgr,vgr,Fgr,ZL,E7,Fve,Tgr,Mgr,jW,Egr,Cgr,wgr,C7,Tve,Agr,Lgr,DW,ygr,xgr,$gr,w7,kgr,Mve,Sgr,Rgr,Eve,Pgr,Bgr,A7,DOe,zd,L7,Cve,ey,Igr,wve,Ngr,GOe,Yo,oy,qgr,Qd,jgr,GW,Dgr,Ggr,OW,Ogr,Vgr,Xgr,ry,zgr,Ave,Qgr,Wgr,Hgr,Lt,ty,Ugr,Lve,Jgr,Ygr,Wd,Kgr,yve,Zgr,ehr,VW,ohr,rhr,thr,y7,ahr,bo,ay,nhr,xve,shr,lhr,en,ihr,$ve,dhr,chr,kve,fhr,mhr,Sve,ghr,hhr,phr,Rve,x7,Pve,_hr,uhr,XW,bhr,vhr,Fhr,$7,Thr,Bve,Mhr,Ehr,Ive,Chr,whr,k7,OOe,Hd,S7,Nve,ny,Ahr,qve,Lhr,VOe,Ko,sy,yhr,Ud,xhr,zW,$hr,khr,QW,Shr,Rhr,Phr,ly,Bhr,jve,Ihr,Nhr,qhr,yt,iy,jhr,Dve,Dhr,Ghr,Jd,Ohr,Gve,Vhr,Xhr,WW,zhr,Qhr,Whr,R7,Hhr,vo,dy,Uhr,Ove,Jhr,Yhr,on,Khr,Vve,Zhr,epr,Xve,opr,rpr,zve,tpr,apr,npr,rn,P7,Qve,spr,lpr,HW,ipr,dpr,cpr,B7,Wve,fpr,mpr,UW,gpr,hpr,ppr,I7,Hve,_pr,upr,JW,bpr,vpr,Fpr,N7,Uve,Tpr,Mpr,YW,Epr,Cpr,wpr,q7,Apr,Jve,Lpr,ypr,Yve,xpr,$pr,j7,XOe,Yd,D7,Kve,cy,kpr,Zve,Spr,zOe,Zo,fy,Rpr,Kd,Ppr,KW,Bpr,Ipr,ZW,Npr,qpr,jpr,my,Dpr,eFe,Gpr,Opr,Vpr,xt,gy,Xpr,oFe,zpr,Qpr,Zd,Wpr,rFe,Hpr,Upr,eH,Jpr,Ypr,Kpr,G7,Zpr,Fo,hy,e_r,tFe,o_r,r_r,tn,t_r,aFe,a_r,n_r,nFe,s_r,l_r,sFe,i_r,d_r,c_r,lFe,O7,iFe,f_r,m_r,oH,g_r,h_r,p_r,V7,__r,dFe,u_r,b_r,cFe,v_r,F_r,X7,QOe,ec,z7,fFe,py,T_r,mFe,M_r,WOe,er,_y,E_r,oc,C_r,rH,w_r,A_r,tH,L_r,y_r,x_r,uy,$_r,gFe,k_r,S_r,R_r,$t,by,P_r,hFe,B_r,I_r,rc,N_r,pFe,q_r,j_r,aH,D_r,G_r,O_r,Q7,V_r,yr,vy,X_r,_Fe,z_r,Q_r,an,W_r,uFe,H_r,U_r,bFe,J_r,Y_r,vFe,K_r,Z_r,eur,j,W7,FFe,our,rur,nH,tur,aur,nur,H7,TFe,sur,lur,sH,iur,dur,cur,U7,MFe,fur,mur,lH,gur,hur,pur,J7,EFe,_ur,uur,iH,bur,vur,Fur,Y7,CFe,Tur,Mur,dH,Eur,Cur,wur,K7,wFe,Aur,Lur,cH,yur,xur,$ur,Z7,AFe,kur,Sur,fH,Rur,Pur,Bur,e8,LFe,Iur,Nur,mH,qur,jur,Dur,o8,yFe,Gur,Our,gH,Vur,Xur,zur,r8,xFe,Qur,Wur,hH,Hur,Uur,Jur,t8,$Fe,Yur,Kur,pH,Zur,e1r,o1r,a8,kFe,r1r,t1r,_H,a1r,n1r,s1r,n8,SFe,l1r,i1r,uH,d1r,c1r,f1r,s8,RFe,m1r,g1r,bH,h1r,p1r,_1r,l8,PFe,u1r,b1r,vH,v1r,F1r,T1r,i8,BFe,M1r,E1r,FH,C1r,w1r,A1r,d8,IFe,L1r,y1r,TH,x1r,$1r,k1r,Qs,NFe,S1r,R1r,MH,P1r,B1r,EH,I1r,N1r,q1r,c8,qFe,j1r,D1r,CH,G1r,O1r,V1r,f8,jFe,X1r,z1r,wH,Q1r,W1r,H1r,m8,DFe,U1r,J1r,AH,Y1r,K1r,Z1r,g8,GFe,e2r,o2r,LH,r2r,t2r,a2r,h8,OFe,n2r,s2r,yH,l2r,i2r,d2r,p8,VFe,c2r,f2r,xH,m2r,g2r,h2r,_8,XFe,p2r,_2r,$H,u2r,b2r,v2r,u8,zFe,F2r,T2r,kH,M2r,E2r,C2r,b8,QFe,w2r,A2r,SH,L2r,y2r,x2r,v8,WFe,$2r,k2r,RH,S2r,R2r,P2r,F8,HFe,B2r,I2r,PH,N2r,q2r,j2r,T8,UFe,D2r,G2r,BH,O2r,V2r,X2r,M8,JFe,z2r,Q2r,IH,W2r,H2r,U2r,E8,YFe,J2r,Y2r,NH,K2r,Z2r,ebr,C8,KFe,obr,rbr,qH,tbr,abr,nbr,w8,ZFe,sbr,lbr,jH,ibr,dbr,cbr,A8,e6e,fbr,mbr,DH,gbr,hbr,pbr,L8,o6e,_br,ubr,GH,bbr,vbr,Fbr,y8,r6e,Tbr,Mbr,OH,Ebr,Cbr,wbr,x8,t6e,Abr,Lbr,VH,ybr,xbr,$br,$8,a6e,kbr,Sbr,XH,Rbr,Pbr,Bbr,k8,n6e,Ibr,Nbr,zH,qbr,jbr,Dbr,S8,s6e,Gbr,Obr,QH,Vbr,Xbr,zbr,R8,l6e,Qbr,Wbr,WH,Hbr,Ubr,Jbr,P8,i6e,Ybr,Kbr,HH,Zbr,evr,ovr,B8,d6e,rvr,tvr,UH,avr,nvr,svr,I8,c6e,lvr,ivr,JH,dvr,cvr,fvr,N8,f6e,mvr,gvr,YH,hvr,pvr,_vr,q8,m6e,uvr,bvr,KH,vvr,Fvr,Tvr,j8,HOe,tc,D8,g6e,Fy,Mvr,h6e,Evr,UOe,or,Ty,Cvr,ac,wvr,ZH,Avr,Lvr,eU,yvr,xvr,$vr,My,kvr,p6e,Svr,Rvr,Pvr,kt,Ey,Bvr,_6e,Ivr,Nvr,nc,qvr,u6e,jvr,Dvr,oU,Gvr,Ovr,Vvr,G8,Xvr,xr,Cy,zvr,b6e,Qvr,Wvr,nn,Hvr,v6e,Uvr,Jvr,F6e,Yvr,Kvr,T6e,Zvr,eFr,oFr,se,O8,M6e,rFr,tFr,rU,aFr,nFr,sFr,V8,E6e,lFr,iFr,tU,dFr,cFr,fFr,X8,C6e,mFr,gFr,aU,hFr,pFr,_Fr,z8,w6e,uFr,bFr,nU,vFr,FFr,TFr,Q8,A6e,MFr,EFr,sU,CFr,wFr,AFr,W8,L6e,LFr,yFr,lU,xFr,$Fr,kFr,H8,y6e,SFr,RFr,iU,PFr,BFr,IFr,U8,x6e,NFr,qFr,dU,jFr,DFr,GFr,J8,$6e,OFr,VFr,cU,XFr,zFr,QFr,Y8,k6e,WFr,HFr,fU,UFr,JFr,YFr,K8,S6e,KFr,ZFr,mU,e6r,o6r,r6r,Z8,R6e,t6r,a6r,gU,n6r,s6r,l6r,e9,P6e,i6r,d6r,hU,c6r,f6r,m6r,o9,B6e,g6r,h6r,pU,p6r,_6r,u6r,r9,I6e,b6r,v6r,_U,F6r,T6r,M6r,t9,N6e,E6r,C6r,uU,w6r,A6r,L6r,a9,q6e,y6r,x6r,bU,$6r,k6r,S6r,n9,j6e,R6r,P6r,vU,B6r,I6r,N6r,s9,D6e,q6r,j6r,FU,D6r,G6r,O6r,l9,G6e,V6r,X6r,TU,z6r,Q6r,W6r,i9,O6e,H6r,U6r,MU,J6r,Y6r,K6r,d9,V6e,Z6r,eTr,EU,oTr,rTr,tTr,c9,X6e,aTr,nTr,CU,sTr,lTr,iTr,f9,JOe,sc,m9,z6e,wy,dTr,Q6e,cTr,YOe,rr,Ay,fTr,lc,mTr,wU,gTr,hTr,AU,pTr,_Tr,uTr,Ly,bTr,W6e,vTr,FTr,TTr,St,yy,MTr,H6e,ETr,CTr,ic,wTr,U6e,ATr,LTr,LU,yTr,xTr,$Tr,g9,kTr,$r,xy,STr,J6e,RTr,PTr,sn,BTr,Y6e,ITr,NTr,K6e,qTr,jTr,Z6e,DTr,GTr,OTr,Me,h9,eTe,VTr,XTr,yU,zTr,QTr,WTr,p9,oTe,HTr,UTr,xU,JTr,YTr,KTr,_9,rTe,ZTr,e7r,$U,o7r,r7r,t7r,u9,tTe,a7r,n7r,kU,s7r,l7r,i7r,b9,aTe,d7r,c7r,SU,f7r,m7r,g7r,v9,nTe,h7r,p7r,RU,_7r,u7r,b7r,F9,sTe,v7r,F7r,PU,T7r,M7r,E7r,T9,lTe,C7r,w7r,BU,A7r,L7r,y7r,M9,iTe,x7r,$7r,IU,k7r,S7r,R7r,E9,dTe,P7r,B7r,NU,I7r,N7r,q7r,C9,cTe,j7r,D7r,qU,G7r,O7r,V7r,w9,fTe,X7r,z7r,jU,Q7r,W7r,H7r,A9,mTe,U7r,J7r,DU,Y7r,K7r,Z7r,L9,KOe,dc,y9,gTe,$y,e8r,hTe,o8r,ZOe,tr,ky,r8r,cc,t8r,GU,a8r,n8r,OU,s8r,l8r,i8r,Sy,d8r,pTe,c8r,f8r,m8r,Rt,Ry,g8r,_Te,h8r,p8r,fc,_8r,uTe,u8r,b8r,VU,v8r,F8r,T8r,x9,M8r,kr,Py,E8r,bTe,C8r,w8r,ln,A8r,vTe,L8r,y8r,FTe,x8r,$8r,TTe,k8r,S8r,R8r,dn,$9,MTe,P8r,B8r,XU,I8r,N8r,q8r,k9,ETe,j8r,D8r,zU,G8r,O8r,V8r,S9,CTe,X8r,z8r,QU,Q8r,W8r,H8r,R9,wTe,U8r,J8r,WU,Y8r,K8r,Z8r,P9,eVe,mc,B9,ATe,By,e9r,LTe,o9r,oVe,ar,Iy,r9r,gc,t9r,HU,a9r,n9r,UU,s9r,l9r,i9r,Ny,d9r,yTe,c9r,f9r,m9r,Pt,qy,g9r,xTe,h9r,p9r,hc,_9r,$Te,u9r,b9r,JU,v9r,F9r,T9r,I9,M9r,Sr,jy,E9r,kTe,C9r,w9r,cn,A9r,STe,L9r,y9r,RTe,x9r,$9r,PTe,k9r,S9r,R9r,ie,N9,BTe,P9r,B9r,YU,I9r,N9r,q9r,q9,ITe,j9r,D9r,KU,G9r,O9r,V9r,j9,NTe,X9r,z9r,ZU,Q9r,W9r,H9r,D9,qTe,U9r,J9r,eJ,Y9r,K9r,Z9r,G9,jTe,eMr,oMr,oJ,rMr,tMr,aMr,O9,DTe,nMr,sMr,rJ,lMr,iMr,dMr,V9,GTe,cMr,fMr,tJ,mMr,gMr,hMr,X9,OTe,pMr,_Mr,aJ,uMr,bMr,vMr,z9,VTe,FMr,TMr,nJ,MMr,EMr,CMr,Q9,XTe,wMr,AMr,sJ,LMr,yMr,xMr,W9,zTe,$Mr,kMr,lJ,SMr,RMr,PMr,H9,QTe,BMr,IMr,iJ,NMr,qMr,jMr,U9,WTe,DMr,GMr,dJ,OMr,VMr,XMr,J9,HTe,zMr,QMr,cJ,WMr,HMr,UMr,Y9,UTe,JMr,YMr,fJ,KMr,ZMr,eEr,K9,JTe,oEr,rEr,mJ,tEr,aEr,nEr,Z9,YTe,sEr,lEr,gJ,iEr,dEr,cEr,eM,KTe,fEr,mEr,hJ,gEr,hEr,pEr,oM,ZTe,_Er,uEr,pJ,bEr,vEr,FEr,rM,e7e,TEr,MEr,_J,EEr,CEr,wEr,tM,rVe,pc,aM,o7e,Dy,AEr,r7e,LEr,tVe,nr,Gy,yEr,_c,xEr,uJ,$Er,kEr,bJ,SEr,REr,PEr,Oy,BEr,t7e,IEr,NEr,qEr,Bt,Vy,jEr,a7e,DEr,GEr,uc,OEr,n7e,VEr,XEr,vJ,zEr,QEr,WEr,nM,HEr,Rr,Xy,UEr,s7e,JEr,YEr,fn,KEr,l7e,ZEr,e4r,i7e,o4r,r4r,d7e,t4r,a4r,n4r,ye,sM,c7e,s4r,l4r,FJ,i4r,d4r,c4r,lM,f7e,f4r,m4r,TJ,g4r,h4r,p4r,iM,m7e,_4r,u4r,MJ,b4r,v4r,F4r,dM,g7e,T4r,M4r,EJ,E4r,C4r,w4r,cM,h7e,A4r,L4r,CJ,y4r,x4r,$4r,fM,p7e,k4r,S4r,wJ,R4r,P4r,B4r,mM,_7e,I4r,N4r,AJ,q4r,j4r,D4r,gM,u7e,G4r,O4r,LJ,V4r,X4r,z4r,hM,b7e,Q4r,W4r,yJ,H4r,U4r,J4r,pM,v7e,Y4r,K4r,xJ,Z4r,eCr,oCr,_M,aVe,bc,uM,F7e,zy,rCr,T7e,tCr,nVe,sr,Qy,aCr,vc,nCr,$J,sCr,lCr,kJ,iCr,dCr,cCr,Wy,fCr,M7e,mCr,gCr,hCr,It,Hy,pCr,E7e,_Cr,uCr,Fc,bCr,C7e,vCr,FCr,SJ,TCr,MCr,ECr,bM,CCr,Pr,Uy,wCr,w7e,ACr,LCr,mn,yCr,A7e,xCr,$Cr,L7e,kCr,SCr,y7e,RCr,PCr,BCr,te,vM,x7e,ICr,NCr,RJ,qCr,jCr,DCr,FM,$7e,GCr,OCr,PJ,VCr,XCr,zCr,TM,k7e,QCr,WCr,BJ,HCr,UCr,JCr,MM,S7e,YCr,KCr,IJ,ZCr,e5r,o5r,EM,R7e,r5r,t5r,NJ,a5r,n5r,s5r,CM,P7e,l5r,i5r,qJ,d5r,c5r,f5r,wM,B7e,m5r,g5r,jJ,h5r,p5r,_5r,AM,I7e,u5r,b5r,DJ,v5r,F5r,T5r,LM,N7e,M5r,E5r,GJ,C5r,w5r,A5r,yM,q7e,L5r,y5r,OJ,x5r,$5r,k5r,xM,j7e,S5r,R5r,VJ,P5r,B5r,I5r,$M,D7e,N5r,q5r,XJ,j5r,D5r,G5r,kM,G7e,O5r,V5r,zJ,X5r,z5r,Q5r,SM,O7e,W5r,H5r,QJ,U5r,J5r,Y5r,RM,V7e,K5r,Z5r,WJ,e3r,o3r,r3r,PM,X7e,t3r,a3r,HJ,n3r,s3r,l3r,BM,z7e,i3r,d3r,UJ,c3r,f3r,m3r,IM,Q7e,g3r,h3r,JJ,p3r,_3r,u3r,NM,W7e,b3r,v3r,YJ,F3r,T3r,M3r,qM,H7e,E3r,C3r,KJ,w3r,A3r,L3r,jM,U7e,y3r,x3r,ZJ,$3r,k3r,S3r,DM,J7e,R3r,P3r,eY,B3r,I3r,N3r,GM,Y7e,q3r,j3r,oY,D3r,G3r,O3r,OM,K7e,V3r,X3r,rY,z3r,Q3r,W3r,VM,Z7e,H3r,U3r,tY,J3r,Y3r,K3r,XM,e8e,Z3r,e0r,aY,o0r,r0r,t0r,zM,sVe,Tc,QM,o8e,Jy,a0r,r8e,n0r,lVe,lr,Yy,s0r,Mc,l0r,nY,i0r,d0r,sY,c0r,f0r,m0r,Ky,g0r,t8e,h0r,p0r,_0r,Nt,Zy,u0r,a8e,b0r,v0r,Ec,F0r,n8e,T0r,M0r,lY,E0r,C0r,w0r,WM,A0r,Br,ex,L0r,s8e,y0r,x0r,gn,$0r,l8e,k0r,S0r,i8e,R0r,P0r,d8e,B0r,I0r,N0r,_e,HM,c8e,q0r,j0r,iY,D0r,G0r,O0r,UM,f8e,V0r,X0r,dY,z0r,Q0r,W0r,JM,m8e,H0r,U0r,cY,J0r,Y0r,K0r,YM,g8e,Z0r,ewr,fY,owr,rwr,twr,KM,h8e,awr,nwr,mY,swr,lwr,iwr,ZM,p8e,dwr,cwr,gY,fwr,mwr,gwr,eE,_8e,hwr,pwr,hY,_wr,uwr,bwr,oE,u8e,vwr,Fwr,pY,Twr,Mwr,Ewr,rE,b8e,Cwr,wwr,_Y,Awr,Lwr,ywr,tE,v8e,xwr,$wr,uY,kwr,Swr,Rwr,aE,F8e,Pwr,Bwr,bY,Iwr,Nwr,qwr,nE,T8e,jwr,Dwr,vY,Gwr,Owr,Vwr,sE,M8e,Xwr,zwr,FY,Qwr,Wwr,Hwr,lE,E8e,Uwr,Jwr,TY,Ywr,Kwr,Zwr,iE,C8e,eAr,oAr,MY,rAr,tAr,aAr,dE,w8e,nAr,sAr,EY,lAr,iAr,dAr,cE,A8e,cAr,fAr,CY,mAr,gAr,hAr,fE,iVe,Cc,mE,L8e,ox,pAr,y8e,_Ar,dVe,ir,rx,uAr,wc,bAr,wY,vAr,FAr,AY,TAr,MAr,EAr,tx,CAr,x8e,wAr,AAr,LAr,qt,ax,yAr,$8e,xAr,$Ar,Ac,kAr,k8e,SAr,RAr,LY,PAr,BAr,IAr,gE,NAr,Ir,nx,qAr,S8e,jAr,DAr,hn,GAr,R8e,OAr,VAr,P8e,XAr,zAr,B8e,QAr,WAr,HAr,sx,hE,I8e,UAr,JAr,yY,YAr,KAr,ZAr,pE,N8e,eLr,oLr,xY,rLr,tLr,aLr,_E,cVe,Lc,uE,q8e,lx,nLr,j8e,sLr,fVe,dr,ix,lLr,yc,iLr,$Y,dLr,cLr,kY,fLr,mLr,gLr,dx,hLr,D8e,pLr,_Lr,uLr,jt,cx,bLr,G8e,vLr,FLr,xc,TLr,O8e,MLr,ELr,SY,CLr,wLr,ALr,bE,LLr,Nr,fx,yLr,V8e,xLr,$Lr,pn,kLr,X8e,SLr,RLr,z8e,PLr,BLr,Q8e,ILr,NLr,qLr,W8e,vE,H8e,jLr,DLr,RY,GLr,OLr,VLr,FE,mVe,$c,TE,U8e,mx,XLr,J8e,zLr,gVe,cr,gx,QLr,kc,WLr,PY,HLr,ULr,BY,JLr,YLr,KLr,hx,ZLr,Y8e,eyr,oyr,ryr,Dt,px,tyr,K8e,ayr,nyr,Sc,syr,Z8e,lyr,iyr,IY,dyr,cyr,fyr,ME,myr,qr,_x,gyr,e9e,hyr,pyr,_n,_yr,o9e,uyr,byr,r9e,vyr,Fyr,t9e,Tyr,Myr,Eyr,de,EE,a9e,Cyr,wyr,NY,Ayr,Lyr,yyr,CE,n9e,xyr,$yr,qY,kyr,Syr,Ryr,wE,s9e,Pyr,Byr,jY,Iyr,Nyr,qyr,AE,l9e,jyr,Dyr,DY,Gyr,Oyr,Vyr,LE,i9e,Xyr,zyr,GY,Qyr,Wyr,Hyr,yE,d9e,Uyr,Jyr,OY,Yyr,Kyr,Zyr,xE,c9e,exr,oxr,VY,rxr,txr,axr,$E,f9e,nxr,sxr,XY,lxr,ixr,dxr,kE,m9e,cxr,fxr,zY,mxr,gxr,hxr,SE,g9e,pxr,_xr,QY,uxr,bxr,vxr,RE,h9e,Fxr,Txr,WY,Mxr,Exr,Cxr,PE,p9e,wxr,Axr,HY,Lxr,yxr,xxr,BE,_9e,$xr,kxr,UY,Sxr,Rxr,Pxr,IE,u9e,Bxr,Ixr,JY,Nxr,qxr,jxr,NE,b9e,Dxr,Gxr,YY,Oxr,Vxr,Xxr,qE,v9e,zxr,Qxr,KY,Wxr,Hxr,Uxr,jE,F9e,Jxr,Yxr,ZY,Kxr,Zxr,e$r,DE,T9e,o$r,r$r,eK,t$r,a$r,n$r,GE,M9e,s$r,l$r,oK,i$r,d$r,c$r,OE,E9e,f$r,m$r,rK,g$r,h$r,p$r,VE,hVe,Rc,XE,C9e,ux,_$r,w9e,u$r,pVe,fr,bx,b$r,Pc,v$r,tK,F$r,T$r,aK,M$r,E$r,C$r,vx,w$r,A9e,A$r,L$r,y$r,Gt,Fx,x$r,L9e,$$r,k$r,Bc,S$r,y9e,R$r,P$r,nK,B$r,I$r,N$r,zE,q$r,jr,Tx,j$r,x9e,D$r,G$r,un,O$r,$9e,V$r,X$r,k9e,z$r,Q$r,S9e,W$r,H$r,U$r,ce,QE,R9e,J$r,Y$r,sK,K$r,Z$r,ekr,WE,P9e,okr,rkr,lK,tkr,akr,nkr,HE,B9e,skr,lkr,iK,ikr,dkr,ckr,UE,I9e,fkr,mkr,dK,gkr,hkr,pkr,JE,N9e,_kr,ukr,cK,bkr,vkr,Fkr,YE,q9e,Tkr,Mkr,fK,Ekr,Ckr,wkr,KE,j9e,Akr,Lkr,mK,ykr,xkr,$kr,ZE,D9e,kkr,Skr,gK,Rkr,Pkr,Bkr,e4,G9e,Ikr,Nkr,hK,qkr,jkr,Dkr,o4,O9e,Gkr,Okr,pK,Vkr,Xkr,zkr,r4,V9e,Qkr,Wkr,_K,Hkr,Ukr,Jkr,t4,X9e,Ykr,Kkr,uK,Zkr,eSr,oSr,a4,z9e,rSr,tSr,bK,aSr,nSr,sSr,n4,Q9e,lSr,iSr,vK,dSr,cSr,fSr,s4,W9e,mSr,gSr,FK,hSr,pSr,_Sr,l4,H9e,uSr,bSr,TK,vSr,FSr,TSr,i4,U9e,MSr,ESr,MK,CSr,wSr,ASr,d4,J9e,LSr,ySr,EK,xSr,$Sr,kSr,c4,Y9e,SSr,RSr,CK,PSr,BSr,ISr,f4,K9e,NSr,qSr,wK,jSr,DSr,GSr,m4,_Ve,Ic,g4,Z9e,Mx,OSr,eMe,VSr,uVe,mr,Ex,XSr,Nc,zSr,AK,QSr,WSr,LK,HSr,USr,JSr,Cx,YSr,oMe,KSr,ZSr,eRr,Ot,wx,oRr,rMe,rRr,tRr,qc,aRr,tMe,nRr,sRr,yK,lRr,iRr,dRr,h4,cRr,Dr,Ax,fRr,aMe,mRr,gRr,bn,hRr,nMe,pRr,_Rr,sMe,uRr,bRr,lMe,vRr,FRr,TRr,iMe,p4,dMe,MRr,ERr,xK,CRr,wRr,ARr,_4,bVe,jc,u4,cMe,Lx,LRr,fMe,yRr,vVe,gr,yx,xRr,Dc,$Rr,$K,kRr,SRr,kK,RRr,PRr,BRr,xx,IRr,mMe,NRr,qRr,jRr,Vt,$x,DRr,gMe,GRr,ORr,Gc,VRr,hMe,XRr,zRr,SK,QRr,WRr,HRr,b4,URr,Gr,kx,JRr,pMe,YRr,KRr,vn,ZRr,_Me,ePr,oPr,uMe,rPr,tPr,bMe,aPr,nPr,sPr,vMe,v4,FMe,lPr,iPr,RK,dPr,cPr,fPr,F4,FVe,Oc,T4,TMe,Sx,mPr,MMe,gPr,TVe,hr,Rx,hPr,Vc,pPr,PK,_Pr,uPr,BK,bPr,vPr,FPr,Px,TPr,EMe,MPr,EPr,CPr,Xt,Bx,wPr,CMe,APr,LPr,Xc,yPr,wMe,xPr,$Pr,IK,kPr,SPr,RPr,M4,PPr,Or,Ix,BPr,AMe,IPr,NPr,Fn,qPr,LMe,jPr,DPr,yMe,GPr,OPr,xMe,VPr,XPr,zPr,oe,E4,$Me,QPr,WPr,NK,HPr,UPr,JPr,C4,kMe,YPr,KPr,qK,ZPr,eBr,oBr,w4,SMe,rBr,tBr,jK,aBr,nBr,sBr,A4,RMe,lBr,iBr,DK,dBr,cBr,fBr,L4,PMe,mBr,gBr,GK,hBr,pBr,_Br,y4,BMe,uBr,bBr,OK,vBr,FBr,TBr,x4,IMe,MBr,EBr,VK,CBr,wBr,ABr,$4,NMe,LBr,yBr,XK,xBr,$Br,kBr,k4,qMe,SBr,RBr,zK,PBr,BBr,IBr,S4,jMe,NBr,qBr,QK,jBr,DBr,GBr,R4,DMe,OBr,VBr,WK,XBr,zBr,QBr,P4,GMe,WBr,HBr,HK,UBr,JBr,YBr,B4,OMe,KBr,ZBr,UK,eIr,oIr,rIr,I4,VMe,tIr,aIr,JK,nIr,sIr,lIr,N4,XMe,iIr,dIr,YK,cIr,fIr,mIr,q4,zMe,gIr,hIr,KK,pIr,_Ir,uIr,j4,QMe,bIr,vIr,ZK,FIr,TIr,MIr,D4,WMe,EIr,CIr,eZ,wIr,AIr,LIr,G4,HMe,yIr,xIr,oZ,$Ir,kIr,SIr,O4,UMe,RIr,PIr,rZ,BIr,IIr,NIr,V4,JMe,qIr,jIr,tZ,DIr,GIr,OIr,X4,YMe,VIr,XIr,aZ,zIr,QIr,WIr,z4,KMe,HIr,UIr,nZ,JIr,YIr,KIr,Q4,ZMe,ZIr,eNr,sZ,oNr,rNr,tNr,W4,eEe,aNr,nNr,lZ,sNr,lNr,iNr,H4,oEe,dNr,cNr,iZ,fNr,mNr,gNr,U4,rEe,hNr,pNr,dZ,_Nr,uNr,bNr,J4,MVe,zc,Y4,tEe,Nx,vNr,aEe,FNr,EVe,pr,qx,TNr,Qc,MNr,cZ,ENr,CNr,fZ,wNr,ANr,LNr,jx,yNr,nEe,xNr,$Nr,kNr,zt,Dx,SNr,sEe,RNr,PNr,Wc,BNr,lEe,INr,NNr,mZ,qNr,jNr,DNr,K4,GNr,Vr,Gx,ONr,iEe,VNr,XNr,Tn,zNr,dEe,QNr,WNr,cEe,HNr,UNr,fEe,JNr,YNr,KNr,xe,Z4,mEe,ZNr,eqr,gZ,oqr,rqr,tqr,eC,gEe,aqr,nqr,hZ,sqr,lqr,iqr,oC,hEe,dqr,cqr,pZ,fqr,mqr,gqr,rC,pEe,hqr,pqr,_Z,_qr,uqr,bqr,tC,_Ee,vqr,Fqr,uZ,Tqr,Mqr,Eqr,aC,uEe,Cqr,wqr,bZ,Aqr,Lqr,yqr,nC,bEe,xqr,$qr,vZ,kqr,Sqr,Rqr,sC,vEe,Pqr,Bqr,FZ,Iqr,Nqr,qqr,lC,FEe,jqr,Dqr,TZ,Gqr,Oqr,Vqr,iC,TEe,Xqr,zqr,MZ,Qqr,Wqr,Hqr,dC,CVe,Hc,cC,MEe,Ox,Uqr,EEe,Jqr,wVe,_r,Vx,Yqr,Uc,Kqr,EZ,Zqr,ejr,CZ,ojr,rjr,tjr,Xx,ajr,CEe,njr,sjr,ljr,Qt,zx,ijr,wEe,djr,cjr,Jc,fjr,AEe,mjr,gjr,wZ,hjr,pjr,_jr,fC,ujr,Xr,Qx,bjr,LEe,vjr,Fjr,Mn,Tjr,yEe,Mjr,Ejr,xEe,Cjr,wjr,$Ee,Ajr,Ljr,yjr,Ee,mC,kEe,xjr,$jr,AZ,kjr,Sjr,Rjr,gC,SEe,Pjr,Bjr,LZ,Ijr,Njr,qjr,hC,REe,jjr,Djr,yZ,Gjr,Ojr,Vjr,pC,PEe,Xjr,zjr,xZ,Qjr,Wjr,Hjr,_C,BEe,Ujr,Jjr,$Z,Yjr,Kjr,Zjr,uC,IEe,eDr,oDr,kZ,rDr,tDr,aDr,bC,NEe,nDr,sDr,SZ,lDr,iDr,dDr,vC,qEe,cDr,fDr,RZ,mDr,gDr,hDr,FC,jEe,pDr,_Dr,PZ,uDr,bDr,vDr,TC,DEe,FDr,TDr,BZ,MDr,EDr,CDr,MC,GEe,wDr,ADr,IZ,LDr,yDr,xDr,EC,OEe,$Dr,kDr,NZ,SDr,RDr,PDr,CC,VEe,BDr,IDr,qZ,NDr,qDr,jDr,wC,AVe,Yc,AC,XEe,Wx,DDr,zEe,GDr,LVe,ur,Hx,ODr,Kc,VDr,jZ,XDr,zDr,DZ,QDr,WDr,HDr,Ux,UDr,QEe,JDr,YDr,KDr,Wt,Jx,ZDr,WEe,eGr,oGr,Zc,rGr,HEe,tGr,aGr,GZ,nGr,sGr,lGr,LC,iGr,zr,Yx,dGr,UEe,cGr,fGr,En,mGr,JEe,gGr,hGr,YEe,pGr,_Gr,KEe,uGr,bGr,vGr,$e,yC,ZEe,FGr,TGr,OZ,MGr,EGr,CGr,xC,e4e,wGr,AGr,VZ,LGr,yGr,xGr,$C,o4e,$Gr,kGr,XZ,SGr,RGr,PGr,kC,r4e,BGr,IGr,zZ,NGr,qGr,jGr,SC,t4e,DGr,GGr,QZ,OGr,VGr,XGr,RC,a4e,zGr,QGr,WZ,WGr,HGr,UGr,PC,n4e,JGr,YGr,HZ,KGr,ZGr,eOr,BC,s4e,oOr,rOr,UZ,tOr,aOr,nOr,IC,l4e,sOr,lOr,JZ,iOr,dOr,cOr,NC,i4e,fOr,mOr,YZ,gOr,hOr,pOr,qC,yVe,ef,jC,d4e,Kx,_Or,c4e,uOr,xVe,br,Zx,bOr,of,vOr,KZ,FOr,TOr,ZZ,MOr,EOr,COr,e$,wOr,f4e,AOr,LOr,yOr,Ht,o$,xOr,m4e,$Or,kOr,rf,SOr,g4e,ROr,POr,eee,BOr,IOr,NOr,DC,qOr,Qr,r$,jOr,h4e,DOr,GOr,Cn,OOr,p4e,VOr,XOr,_4e,zOr,QOr,u4e,WOr,HOr,UOr,ke,GC,b4e,JOr,YOr,oee,KOr,ZOr,eVr,OC,v4e,oVr,rVr,ree,tVr,aVr,nVr,VC,F4e,sVr,lVr,tee,iVr,dVr,cVr,XC,T4e,fVr,mVr,aee,gVr,hVr,pVr,zC,M4e,_Vr,uVr,nee,bVr,vVr,FVr,QC,E4e,TVr,MVr,see,EVr,CVr,wVr,WC,C4e,AVr,LVr,lee,yVr,xVr,$Vr,HC,w4e,kVr,SVr,iee,RVr,PVr,BVr,UC,A4e,IVr,NVr,dee,qVr,jVr,DVr,JC,L4e,GVr,OVr,cee,VVr,XVr,zVr,YC,$Ve,tf,KC,y4e,t$,QVr,x4e,WVr,kVe,vr,a$,HVr,af,UVr,fee,JVr,YVr,mee,KVr,ZVr,eXr,n$,oXr,$4e,rXr,tXr,aXr,Ut,s$,nXr,k4e,sXr,lXr,nf,iXr,S4e,dXr,cXr,gee,fXr,mXr,gXr,ZC,hXr,Wr,l$,pXr,R4e,_Xr,uXr,wn,bXr,P4e,vXr,FXr,B4e,TXr,MXr,I4e,EXr,CXr,wXr,Se,e5,N4e,AXr,LXr,hee,yXr,xXr,$Xr,o5,q4e,kXr,SXr,pee,RXr,PXr,BXr,r5,j4e,IXr,NXr,_ee,qXr,jXr,DXr,t5,D4e,GXr,OXr,uee,VXr,XXr,zXr,a5,G4e,QXr,WXr,bee,HXr,UXr,JXr,n5,O4e,YXr,KXr,vee,ZXr,ezr,ozr,s5,V4e,rzr,tzr,Fee,azr,nzr,szr,l5,X4e,lzr,izr,Tee,dzr,czr,fzr,i5,z4e,mzr,gzr,Mee,hzr,pzr,_zr,d5,Q4e,uzr,bzr,Eee,vzr,Fzr,Tzr,c5,SVe,sf,f5,W4e,i$,Mzr,H4e,Ezr,RVe,Fr,d$,Czr,lf,wzr,Cee,Azr,Lzr,wee,yzr,xzr,$zr,c$,kzr,U4e,Szr,Rzr,Pzr,Jt,f$,Bzr,J4e,Izr,Nzr,df,qzr,Y4e,jzr,Dzr,Aee,Gzr,Ozr,Vzr,m5,Xzr,Hr,m$,zzr,K4e,Qzr,Wzr,An,Hzr,Z4e,Uzr,Jzr,eCe,Yzr,Kzr,oCe,Zzr,eQr,oQr,Re,g5,rCe,rQr,tQr,Lee,aQr,nQr,sQr,h5,tCe,lQr,iQr,yee,dQr,cQr,fQr,p5,aCe,mQr,gQr,xee,hQr,pQr,_Qr,_5,nCe,uQr,bQr,$ee,vQr,FQr,TQr,u5,sCe,MQr,EQr,kee,CQr,wQr,AQr,b5,lCe,LQr,yQr,See,xQr,$Qr,kQr,v5,iCe,SQr,RQr,Ree,PQr,BQr,IQr,F5,dCe,NQr,qQr,Pee,jQr,DQr,GQr,T5,cCe,OQr,VQr,Bee,XQr,zQr,QQr,M5,fCe,WQr,HQr,Iee,UQr,JQr,YQr,E5,PVe,cf,C5,mCe,g$,KQr,gCe,ZQr,BVe,Tr,h$,eWr,ff,oWr,Nee,rWr,tWr,qee,aWr,nWr,sWr,p$,lWr,hCe,iWr,dWr,cWr,Yt,_$,fWr,pCe,mWr,gWr,mf,hWr,_Ce,pWr,_Wr,jee,uWr,bWr,vWr,w5,FWr,Ur,u$,TWr,uCe,MWr,EWr,Ln,CWr,bCe,wWr,AWr,vCe,LWr,yWr,FCe,xWr,$Wr,kWr,Ve,A5,TCe,SWr,RWr,Dee,PWr,BWr,IWr,L5,MCe,NWr,qWr,Gee,jWr,DWr,GWr,y5,ECe,OWr,VWr,Oee,XWr,zWr,QWr,x5,CCe,WWr,HWr,Vee,UWr,JWr,YWr,$5,wCe,KWr,ZWr,Xee,eHr,oHr,rHr,k5,ACe,tHr,aHr,zee,nHr,sHr,lHr,S5,LCe,iHr,dHr,Qee,cHr,fHr,mHr,R5,yCe,gHr,hHr,Wee,pHr,_Hr,uHr,P5,IVe,gf,B5,xCe,b$,bHr,$Ce,vHr,NVe,Mr,v$,FHr,hf,THr,Hee,MHr,EHr,Uee,CHr,wHr,AHr,F$,LHr,kCe,yHr,xHr,$Hr,Kt,T$,kHr,SCe,SHr,RHr,pf,PHr,RCe,BHr,IHr,Jee,NHr,qHr,jHr,I5,DHr,Jr,M$,GHr,PCe,OHr,VHr,yn,XHr,BCe,zHr,QHr,ICe,WHr,HHr,NCe,UHr,JHr,YHr,Xe,N5,qCe,KHr,ZHr,Yee,eUr,oUr,rUr,q5,jCe,tUr,aUr,Kee,nUr,sUr,lUr,j5,DCe,iUr,dUr,Zee,cUr,fUr,mUr,D5,GCe,gUr,hUr,eoe,pUr,_Ur,uUr,G5,OCe,bUr,vUr,ooe,FUr,TUr,MUr,O5,VCe,EUr,CUr,roe,wUr,AUr,LUr,V5,XCe,yUr,xUr,toe,$Ur,kUr,SUr,X5,zCe,RUr,PUr,aoe,BUr,IUr,NUr,z5,qVe,_f,Q5,QCe,E$,qUr,WCe,jUr,jVe,Er,C$,DUr,uf,GUr,noe,OUr,VUr,soe,XUr,zUr,QUr,w$,WUr,HCe,HUr,UUr,JUr,Zt,A$,YUr,UCe,KUr,ZUr,bf,eJr,JCe,oJr,rJr,loe,tJr,aJr,nJr,W5,sJr,Yr,L$,lJr,YCe,iJr,dJr,xn,cJr,KCe,fJr,mJr,ZCe,gJr,hJr,e5e,pJr,_Jr,uJr,o5e,H5,r5e,bJr,vJr,ioe,FJr,TJr,MJr,U5,DVe,vf,J5,t5e,y$,EJr,a5e,CJr,GVe,Cr,x$,wJr,Ff,AJr,doe,LJr,yJr,coe,xJr,$Jr,kJr,$$,SJr,n5e,RJr,PJr,BJr,ea,k$,IJr,s5e,NJr,qJr,Tf,jJr,l5e,DJr,GJr,foe,OJr,VJr,XJr,Y5,zJr,Kr,S$,QJr,i5e,WJr,HJr,$n,UJr,d5e,JJr,YJr,c5e,KJr,ZJr,f5e,eYr,oYr,rYr,R$,K5,m5e,tYr,aYr,moe,nYr,sYr,lYr,Z5,g5e,iYr,dYr,goe,cYr,fYr,mYr,e3,OVe,Mf,o3,h5e,P$,gYr,p5e,hYr,VVe,wr,B$,pYr,Ef,_Yr,hoe,uYr,bYr,poe,vYr,FYr,TYr,I$,MYr,_5e,EYr,CYr,wYr,oa,N$,AYr,u5e,LYr,yYr,Cf,xYr,b5e,$Yr,kYr,_oe,SYr,RYr,PYr,r3,BYr,Zr,q$,IYr,v5e,NYr,qYr,kn,jYr,F5e,DYr,GYr,T5e,OYr,VYr,M5e,XYr,zYr,QYr,E5e,t3,C5e,WYr,HYr,uoe,UYr,JYr,YYr,a3,XVe;return d=new re({}),xa=new P({props:{code:'model = AutoModel.from_pretrained("bert-base-cased")',highlighted:'model = AutoModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)'}}),xw=new re({}),$w=new P({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig, AutoModel

AutoConfig.register(<span class="hljs-string">&quot;new-model&quot;</span>, NewModelConfig)
AutoModel.register(NewModelConfig, NewModel)`}}),Rf=new KYr({props:{warning:!0,$$slots:{default:[CDt]},$$scope:{ctx:x}}}),kw=new re({}),Sw=new R({props:{name:"class transformers.AutoConfig",anchor:"transformers.AutoConfig",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/configuration_auto.py#L598"}}),Bw=new R({props:{name:"from_pretrained",anchor:"transformers.AutoConfig.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model configuration hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing a configuration file saved using the
<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.save_pretrained">save_pretrained()</a> method, or the <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> method,
e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a saved configuration JSON <em>file</em>, e.g.,
<code>./my_model_directory/configuration.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoConfig.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoConfig.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoConfig.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoConfig.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoConfig.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoConfig.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final configuration object.</p>
<p>If <code>True</code>, then this functions returns a <code>Tuple(config, unused_kwargs)</code> where <em>unused_kwargs</em> is a
dictionary consisting of the key/value pairs whose keys are not configuration attributes: i.e., the
part of <code>kwargs</code> which has not been used to update <code>config</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoConfig.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoConfig.from_pretrained.kwargs(additional",description:`<strong>kwargs(additional</strong> keyword arguments, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are configuration attributes will be used to override the loaded
values. Behavior concerning key/value pairs whose keys are <em>not</em> configuration attributes is controlled
by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs(additional"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/configuration_auto.py#L621"}}),Gg=new B({props:{anchor:"transformers.AutoConfig.from_pretrained.example",$$slots:{default:[wDt]},$$scope:{ctx:x}}}),Iw=new R({props:{name:"register",anchor:"transformers.AutoConfig.register",parameters:[{name:"model_type",val:""},{name:"config",val:""}],parametersDescription:[{anchor:"transformers.AutoConfig.register.model_type",description:"<strong>model_type</strong> (<code>str</code>) &#x2014; The model type like &#x201C;bert&#x201D; or &#x201C;gpt&#x201D;.",name:"model_type"},{anchor:"transformers.AutoConfig.register.config",description:'<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014; The config to register.',name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/configuration_auto.py#L744"}}),Nw=new re({}),qw=new R({props:{name:"class transformers.AutoTokenizer",anchor:"transformers.AutoTokenizer",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/tokenization_auto.py#L400"}}),Gw=new R({props:{name:"from_pretrained",anchor:"transformers.AutoTokenizer.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"*inputs",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoTokenizer.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a predefined tokenizer hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing vocabulary files required by the tokenizer, for instance saved
using the <a href="/docs/transformers/pr_17869/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.save_pretrained">save_pretrained()</a> method, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a single saved vocabulary file if and only if the tokenizer only requires a
single vocabulary file (like Bert or XLNet), e.g.: <code>./my_model_directory/vocab.txt</code>. (Not
applicable to all derived classes)</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoTokenizer.from_pretrained.inputs",description:`<strong>inputs</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the Tokenizer <code>__init__()</code> method.`,name:"inputs"},{anchor:"transformers.AutoTokenizer.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
The configuration object used to dertermine the tokenizer class to instantiate.`,name:"config"},{anchor:"transformers.AutoTokenizer.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoTokenizer.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download the model weights and configuration files and override the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoTokenizer.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoTokenizer.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoTokenizer.from_pretrained.subfolder",description:`<strong>subfolder</strong> (<code>str</code>, <em>optional</em>) &#x2014;
In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for
facebook/rag-token-base), specify it here.`,name:"subfolder"},{anchor:"transformers.AutoTokenizer.from_pretrained.use_fast",description:`<strong>use_fast</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to try to load the fast version of the tokenizer.`,name:"use_fast"},{anchor:"transformers.AutoTokenizer.from_pretrained.tokenizer_type",description:`<strong>tokenizer_type</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Tokenizer type to be loaded.`,name:"tokenizer_type"},{anchor:"transformers.AutoTokenizer.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoTokenizer.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Will be passed to the Tokenizer <code>__init__()</code> method. Can be used to set special tokens like
<code>bos_token</code>, <code>eos_token</code>, <code>unk_token</code>, <code>sep_token</code>, <code>pad_token</code>, <code>cls_token</code>, <code>mask_token</code>,
<code>additional_special_tokens</code>. See parameters in the <code>__init__()</code> for more details.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/tokenization_auto.py#L414"}}),Eh=new B({props:{anchor:"transformers.AutoTokenizer.from_pretrained.example",$$slots:{default:[ADt]},$$scope:{ctx:x}}}),Ow=new R({props:{name:"register",anchor:"transformers.AutoTokenizer.register",parameters:[{name:"config_class",val:""},{name:"slow_tokenizer_class",val:" = None"},{name:"fast_tokenizer_class",val:" = None"}],parametersDescription:[{anchor:"transformers.AutoTokenizer.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizer</code>, <em>optional</em>) &#x2014;
The slow tokenizer to register.`,name:"slow_tokenizer_class"},{anchor:"transformers.AutoTokenizer.register.slow_tokenizer_class",description:`<strong>slow_tokenizer_class</strong> (<code>PretrainedTokenizerFast</code>, <em>optional</em>) &#x2014;
The fast tokenizer to register.`,name:"slow_tokenizer_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/tokenization_auto.py#L613"}}),Vw=new re({}),Xw=new R({props:{name:"class transformers.AutoFeatureExtractor",anchor:"transformers.AutoFeatureExtractor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/feature_extraction_auto.py#L193"}}),Ww=new R({props:{name:"from_pretrained",anchor:"transformers.AutoFeatureExtractor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a feature extractor file saved using the
<a href="/docs/transformers/pr_17869/en/main_classes/feature_extractor#transformers.FeatureExtractionMixin.save_pretrained">save_pretrained()</a> method, e.g.,
<code>./my_model_directory/</code>.</li>
<li>a path or url to a saved feature extractor JSON <em>file</em>, e.g.,
<code>./my_model_directory/preprocessor_config.json</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoFeatureExtractor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/feature_extraction_auto.py#L207"}}),ap=new KYr({props:{$$slots:{default:[LDt]},$$scope:{ctx:x}}}),np=new B({props:{anchor:"transformers.AutoFeatureExtractor.from_pretrained.example",$$slots:{default:[yDt]},$$scope:{ctx:x}}}),Hw=new R({props:{name:"register",anchor:"transformers.AutoFeatureExtractor.register",parameters:[{name:"config_class",val:""},{name:"feature_extractor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoFeatureExtractor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoFeatureExtractor.register.feature_extractor_class",description:"<strong>feature_extractor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The feature extractor to register.",name:"feature_extractor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/feature_extraction_auto.py#L334"}}),Uw=new re({}),Jw=new R({props:{name:"class transformers.AutoProcessor",anchor:"transformers.AutoProcessor",parameters:[],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/processing_auto.py#L88"}}),Zw=new R({props:{name:"from_pretrained",anchor:"transformers.AutoProcessor.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
This can be either:</p>
<ul>
<li>a string, the <em>model id</em> of a pretrained feature_extractor hosted inside a model repo on
huggingface.co. Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or
namespaced under a user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>a path to a <em>directory</em> containing a processor files saved using the <code>save_pretrained()</code> method,
e.g., <code>./my_model_directory/</code>.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoProcessor.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model feature extractor should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoProcessor.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force to (re-)download the feature extractor files and override the cached versions
if they exist.`,name:"force_download"},{anchor:"transformers.AutoProcessor.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received file. Attempts to resume the download if such a file
exists.`,name:"resume_download"},{anchor:"transformers.AutoProcessor.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}.</code> The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoProcessor.from_pretrained.use_auth_token",description:`<strong>use_auth_token</strong> (<code>str</code> or <em>bool</em>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If <code>True</code>, will use the token generated
when running <code>transformers-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"use_auth_token"},{anchor:"transformers.AutoProcessor.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoProcessor.from_pretrained.return_unused_kwargs",description:`<strong>return_unused_kwargs</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
If <code>False</code>, then this function returns just the final feature extractor object. If <code>True</code>, then this
functions returns a <code>Tuple(feature_extractor, unused_kwargs)</code> where <em>unused_kwargs</em> is a dictionary
consisting of the key/value pairs whose keys are not feature extractor attributes: i.e., the part of
<code>kwargs</code> which has not been used to update <code>feature_extractor</code> and is otherwise ignored.`,name:"return_unused_kwargs"},{anchor:"transformers.AutoProcessor.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoProcessor.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
The values in kwargs of any keys which are feature extractor attributes will be used to override the
loaded values. Behavior concerning key/value pairs whose keys are <em>not</em> feature extractor attributes is
controlled by the <code>return_unused_kwargs</code> keyword parameter.`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/processing_auto.py#L102"}}),wp=new KYr({props:{$$slots:{default:[xDt]},$$scope:{ctx:x}}}),Ap=new B({props:{anchor:"transformers.AutoProcessor.from_pretrained.example",$$slots:{default:[$Dt]},$$scope:{ctx:x}}}),eA=new R({props:{name:"register",anchor:"transformers.AutoProcessor.register",parameters:[{name:"config_class",val:""},{name:"processor_class",val:""}],parametersDescription:[{anchor:"transformers.AutoProcessor.register.config_class",description:`<strong>config_class</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The configuration corresponding to the model to register.`,name:"config_class"},{anchor:"transformers.AutoProcessor.register.processor_class",description:"<strong>processor_class</strong> (<code>FeatureExtractorMixin</code>) &#x2014; The processor to register.",name:"processor_class"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/processing_auto.py#L255"}}),oA=new re({}),rA=new R({props:{name:"class transformers.AutoModel",anchor:"transformers.AutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L767"}}),aA=new R({props:{name:"from_config",anchor:"transformers.AutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertModel">AlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartModel">BartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/beit#transformers.BeitModel">BeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertModel">BertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert-generation#transformers.BertGenerationEncoder">BertGenerationEncoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdModel">BigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel">BigBirdPegasusModel</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.BlenderbotModel">BlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel">BlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomModel">BloomModel</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/clip#transformers.CLIPModel">CLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLModel">CTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertModel">CamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineModel">CanineModel</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertModel">ConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/convnext#transformers.ConvNextModel">ConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/cvt#transformers.CvtModel">CvtModel</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/dpr#transformers.DPRQuestionEncoder">DPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/dpt#transformers.DPTModel">DPTModel</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecAudioModel">Data2VecAudioModel</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextModel">Data2VecTextModel</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecVisionModel">Data2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaModel">DebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2Model">DebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig">DecisionTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/decision_transformer#transformers.DecisionTransformerModel">DecisionTransformerModel</a> (Decision Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deit#transformers.DeiTModel">DeiTModel</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/detr#transformers.DetrModel">DetrModel</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertModel">DistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraModel">ElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetModel">FNetModel</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/fsmt#transformers.FSMTModel">FSMTModel</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertModel">FlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/flava#transformers.FlavaModel">FlavaModel</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelModel">FunnelModel</a> or <a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelBaseModel">FunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/glpn#transformers.GLPNConfig">GLPNConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/glpn#transformers.GLPNModel">GLPNModel</a> (GLPN model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Model">GPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJModel">GPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt_neo#transformers.GPTNeoModel">GPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt_neox#transformers.GPTNeoXModel">GPTNeoXModel</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/hubert#transformers.HubertModel">HubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertModel">IBertModel</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/imagegpt#transformers.ImageGPTModel">ImageGPTModel</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDModel">LEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMModel">LayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model">LayoutLMv2Model</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model">LayoutLMv3Model</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/levit#transformers.LevitModel">LevitModel</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longt5#transformers.LongT5Model">LongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerModel">LongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/luke#transformers.LukeModel">LukeModel</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.LxmertModel">LxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/m2m_100#transformers.M2M100Model">M2M100Model</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartModel">MBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mctct#transformers.MCTCTModel">MCTCTModel</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetModel">MPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mt5#transformers.MT5Model">MT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/marian#transformers.MarianModel">MarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/maskformer#transformers.MaskFormerModel">MaskFormerModel</a> (MaskFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertModel">MegatronBertModel</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertModel">MobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaModel">NezhaModel</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerModel">NystromformerModel</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/opt#transformers.OPTModel">OPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTModel">OpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/plbart#transformers.PLBartModel">PLBartModel</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusModel">PegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverModel">PerceiverModel</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/poolformer#transformers.PoolFormerModel">PoolFormerModel</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/prophetnet#transformers.ProphetNetModel">ProphetNetModel</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertModel">QDQBertModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerModel">ReformerModel</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/regnet#transformers.RegNetModel">RegNetModel</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertModel">RemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/resnet#transformers.ResNetModel">ResNetModel</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerModel">RoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaModel">RobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/sew#transformers.SEWModel">SEWModel</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/sew-d#transformers.SEWDModel">SEWDModel</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/segformer#transformers.SegformerModel">SegformerModel</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/speech_to_text#transformers.Speech2TextModel">Speech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/splinter#transformers.SplinterModel">SplinterModel</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertModel">SqueezeBertModel</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/swin#transformers.SwinModel">SwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5Model">T5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasModel">TapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig">TrajectoryTransformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel">TrajectoryTransformerModel</a> (Trajectory Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLModel">TransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/unispeech#transformers.UniSpeechModel">UniSpeechModel</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel">UniSpeechSatModel</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/van#transformers.VanModel">VanModel</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTModel">ViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vit_mae#transformers.ViTMAEModel">ViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vilt#transformers.ViltModel">ViltModel</a> (ViLT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel">VisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/visual_bert#transformers.VisualBertModel">VisualBertModel</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Model">Wav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel">Wav2Vec2ConformerModel</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wavlm#transformers.WavLMModel">WavLMModel</a> (WavLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xglm#transformers.XGLMModel">XGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMModel">XLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel">XLMProphetNetModel</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaModel">XLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel">XLMRobertaXLModel</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetModel">XLNetModel</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/yolos#transformers.YolosModel">YolosModel</a> (YOLOS model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoModel">YosoModel</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),xp=new B({props:{anchor:"transformers.AutoModel.from_config.example",$$slots:{default:[kDt]},$$scope:{ctx:x}}}),nA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModel.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModel.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),xu=new B({props:{anchor:"transformers.AutoModel.from_pretrained.example",$$slots:{default:[SDt]},$$scope:{ctx:x}}}),sA=new re({}),lA=new R({props:{name:"class transformers.AutoModelForPreTraining",anchor:"transformers.AutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L774"}}),dA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertForPreTraining">AlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertForPreTraining">BertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdForPreTraining">BigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraForPreTraining">ElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetForPreTraining">FNetForPreTraining</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/flava#transformers.FlavaConfig">FlavaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/flava#transformers.FlavaForPreTraining">FlavaForPreTraining</a> (FLAVA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelForPreTraining">FunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.LxmertForPreTraining">LxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining">MegatronBertForPreTraining</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertForPreTraining">MobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaForPreTraining">NezhaForPreTraining</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/retribert#transformers.RetriBertConfig">RetriBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/retribert#transformers.RetriBertModel">RetriBertModel</a> (RetriBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/splinter#transformers.SplinterForPreTraining">SplinterForPreTraining</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/unispeech#transformers.UniSpeechForPreTraining">UniSpeechForPreTraining</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining">UniSpeechSatForPreTraining</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining">ViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/visual_bert#transformers.VisualBertConfig">VisualBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/visual_bert#transformers.VisualBertForPreTraining">VisualBertForPreTraining</a> (VisualBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining">Wav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining">Wav2Vec2ConformerForPreTraining</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),ku=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_config.example",$$slots:{default:[RDt]},$$scope:{ctx:x}}}),cA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),E1=new B({props:{anchor:"transformers.AutoModelForPreTraining.from_pretrained.example",$$slots:{default:[PDt]},$$scope:{ctx:x}}}),fA=new re({}),mA=new R({props:{name:"class transformers.AutoModelForCausalLM",anchor:"transformers.AutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L789"}}),hA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartForCausalLM">BartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertLMHeadModel">BertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert-generation#transformers.BertGenerationConfig">BertGenerationConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert-generation#transformers.BertGenerationDecoder">BertGenerationDecoder</a> (Bert Generation model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdForCausalLM">BigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM">BigBirdPegasusForCausalLM</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM">BlenderbotForCausalLM</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM">BlenderbotSmallForCausalLM</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomForCausalLM">BloomForCausalLM</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLLMHeadModel">CTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertForCausalLM">CamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM">Data2VecTextForCausalLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraForCausalLM">ElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2LMHeadModel">GPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJForCausalLM">GPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM">GPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt_neox#transformers.GPTNeoXConfig">GPTNeoXConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM">GPTNeoXForCausalLM</a> (GPT NeoX model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartForCausalLM">MBartForCausalLM</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/marian#transformers.MarianForCausalLM">MarianForCausalLM</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM">MegatronBertForCausalLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/opt#transformers.OPTForCausalLM">OPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel">OpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/plbart#transformers.PLBartForCausalLM">PLBartForCausalLM</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusForCausalLM">PegasusForCausalLM</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM">ProphetNetForCausalLM</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel">QDQBertLMHeadModel</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerModelWithLMHead">ReformerModelWithLMHead</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertForCausalLM">RemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerForCausalLM">RoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaForCausalLM">RobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config">Speech2Text2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM">Speech2Text2ForCausalLM</a> (Speech2Text2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/trocr#transformers.TrOCRConfig">TrOCRConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/trocr#transformers.TrOCRForCausalLM">TrOCRForCausalLM</a> (TrOCR model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel">TransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xglm#transformers.XGLMForCausalLM">XGLMForCausalLM</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM">XLMProphetNetForCausalLM</a> (XLM-ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM">XLMRobertaForCausalLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM">XLMRobertaXLForCausalLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetLMHeadModel">XLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),w1=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_config.example",$$slots:{default:[BDt]},$$scope:{ctx:x}}}),pA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),f2=new B({props:{anchor:"transformers.AutoModelForCausalLM.from_pretrained.example",$$slots:{default:[IDt]},$$scope:{ctx:x}}}),_A=new re({}),uA=new R({props:{name:"class transformers.AutoModelForMaskedLM",anchor:"transformers.AutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L796"}}),vA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertForMaskedLM">AlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertForMaskedLM">BertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdForMaskedLM">BigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertForMaskedLM">CamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertForMaskedLM">ConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM">Data2VecTextForMaskedLM</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaForMaskedLM">DebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM">DebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertForMaskedLM">DistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraForMaskedLM">ElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetForMaskedLM">FNetForMaskedLM</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel">FlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelForMaskedLM">FunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertForMaskedLM">IBertForMaskedLM</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM">LayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerForMaskedLM">LongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/luke#transformers.LukeConfig">LukeConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/luke#transformers.LukeForMaskedLM">LukeForMaskedLM</a> (LUKE model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetForMaskedLM">MPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM">MegatronBertForMaskedLM</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM">MobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaForMaskedLM">NezhaForMaskedLM</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM">NystromformerForMaskedLM</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverForMaskedLM">PerceiverForMaskedLM</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM">QDQBertForMaskedLM</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerForMaskedLM">ReformerForMaskedLM</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertForMaskedLM">RemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerForMaskedLM">RoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaForMaskedLM">RobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM">SqueezeBertForMaskedLM</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasForMaskedLM">TapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <code>Wav2Vec2ForMaskedLM</code> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMWithLMHeadModel">XLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM">XLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM">XLMRobertaXLForMaskedLM</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoForMaskedLM">YosoForMaskedLM</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),g2=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_config.example",$$slots:{default:[NDt]},$$scope:{ctx:x}}}),FA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),K2=new B({props:{anchor:"transformers.AutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[qDt]},$$scope:{ctx:x}}}),TA=new re({}),MA=new R({props:{name:"class transformers.AutoModelForSeq2SeqLM",anchor:"transformers.AutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L803"}}),CA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartForConditionalGeneration">BartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration">BigBirdPegasusForConditionalGeneration</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration">BlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration">BlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel">EncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/fsmt#transformers.FSMTConfig">FSMTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration">FSMTForConditionalGeneration</a> (FairSeq Machine-Translation model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDForConditionalGeneration">LEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration">LongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/m2m_100#transformers.M2M100Config">M2M100Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration">M2M100ForConditionalGeneration</a> (M2M100 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartForConditionalGeneration">MBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mt5#transformers.MT5ForConditionalGeneration">MT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/marian#transformers.MarianMTModel">MarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/plbart#transformers.PLBartForConditionalGeneration">PLBartForConditionalGeneration</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration">PegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/prophetnet#transformers.ProphetNetConfig">ProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration">ProphetNetForConditionalGeneration</a> (ProphetNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5ForConditionalGeneration">T5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig">XLMProphetNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration">XLMProphetNetForConditionalGeneration</a> (XLM-ProphetNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),eb=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[jDt]},$$scope:{ctx:x}}}),wA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),vb=new B({props:{anchor:"transformers.AutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[DDt]},$$scope:{ctx:x}}}),AA=new re({}),LA=new R({props:{name:"class transformers.AutoModelForSequenceClassification",anchor:"transformers.AutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L812"}}),xA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertForSequenceClassification">AlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartForSequenceClassification">BartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertForSequenceClassification">BertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification">BigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification">BigBirdPegasusForSequenceClassification</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomForSequenceClassification">BloomForSequenceClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLForSequenceClassification">CTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertForSequenceClassification">CamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineForSequenceClassification">CanineForSequenceClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertForSequenceClassification">ConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification">Data2VecTextForSequenceClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaForSequenceClassification">DebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification">DebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification">DistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraForSequenceClassification">ElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetForSequenceClassification">FNetForSequenceClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification">FlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelForSequenceClassification">FunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification">GPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJForSequenceClassification">GPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification">GPTNeoForSequenceClassification</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertForSequenceClassification">IBertForSequenceClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDForSequenceClassification">LEDForSequenceClassification</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification">LayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification">LayoutLMv2ForSequenceClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification">LayoutLMv3ForSequenceClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerForSequenceClassification">LongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartForSequenceClassification">MBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetForSequenceClassification">MPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification">MegatronBertForSequenceClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification">MobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaForSequenceClassification">NezhaForSequenceClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification">NystromformerForSequenceClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification">OpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/plbart#transformers.PLBartConfig">PLBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/plbart#transformers.PLBartForSequenceClassification">PLBartForSequenceClassification</a> (PLBart model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification">PerceiverForSequenceClassification</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification">QDQBertForSequenceClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerForSequenceClassification">ReformerForSequenceClassification</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertForSequenceClassification">RemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerForSequenceClassification">RoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaForSequenceClassification">RobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification">SqueezeBertForSequenceClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasForSequenceClassification">TapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification">TransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMForSequenceClassification">XLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification">XLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification">XLMRobertaXLForSequenceClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetForSequenceClassification">XLNetForSequenceClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoForSequenceClassification">YosoForSequenceClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),Tb=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_config.example",$$slots:{default:[GDt]},$$scope:{ctx:x}}}),$A=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),bv=new B({props:{anchor:"transformers.AutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[ODt]},$$scope:{ctx:x}}}),kA=new re({}),SA=new R({props:{name:"class transformers.AutoModelForMultipleChoice",anchor:"transformers.AutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L857"}}),PA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertForMultipleChoice">AlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertForMultipleChoice">BertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice">BigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertForMultipleChoice">CamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineForMultipleChoice">CanineForMultipleChoice</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertForMultipleChoice">ConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice">Data2VecTextForMultipleChoice</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice">DebertaV2ForMultipleChoice</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice">DistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraForMultipleChoice">ElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetForMultipleChoice">FNetForMultipleChoice</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice">FlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelForMultipleChoice">FunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertForMultipleChoice">IBertForMultipleChoice</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerForMultipleChoice">LongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetForMultipleChoice">MPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice">MegatronBertForMultipleChoice</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice">MobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaForMultipleChoice">NezhaForMultipleChoice</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice">NystromformerForMultipleChoice</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice">QDQBertForMultipleChoice</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertForMultipleChoice">RemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerForMultipleChoice">RoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaForMultipleChoice">RobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice">SqueezeBertForMultipleChoice</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMForMultipleChoice">XLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice">XLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice">XLMRobertaXLForMultipleChoice</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetForMultipleChoice">XLNetForMultipleChoice</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoForMultipleChoice">YosoForMultipleChoice</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),Fv=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_config.example",$$slots:{default:[VDt]},$$scope:{ctx:x}}}),BA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),Kv=new B({props:{anchor:"transformers.AutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[XDt]},$$scope:{ctx:x}}}),IA=new re({}),NA=new R({props:{name:"class transformers.AutoModelForNextSentencePrediction",anchor:"transformers.AutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L864"}}),jA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertForNextSentencePrediction">BertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetForNextSentencePrediction">FNetForNextSentencePrediction</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction">MegatronBertForNextSentencePrediction</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction">MobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction">NezhaForNextSentencePrediction</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction">QDQBertForNextSentencePrediction</a> (QDQBert model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),eF=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[zDt]},$$scope:{ctx:x}}}),DA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),iF=new B({props:{anchor:"transformers.AutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[QDt]},$$scope:{ctx:x}}}),GA=new re({}),OA=new R({props:{name:"class transformers.AutoModelForTokenClassification",anchor:"transformers.AutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L850"}}),XA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertForTokenClassification">AlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertForTokenClassification">BertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdForTokenClassification">BigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomConfig">BloomConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomForTokenClassification">BloomForTokenClassification</a> (BLOOM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertForTokenClassification">CamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineForTokenClassification">CanineForTokenClassification</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertForTokenClassification">ConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification">Data2VecTextForTokenClassification</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaForTokenClassification">DebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification">DebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertForTokenClassification">DistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraForTokenClassification">ElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetForTokenClassification">FNetForTokenClassification</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertForTokenClassification">FlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelForTokenClassification">FunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2ForTokenClassification">GPT2ForTokenClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertForTokenClassification">IBertForTokenClassification</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification">LayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification">LayoutLMv2ForTokenClassification</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification">LayoutLMv3ForTokenClassification</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerForTokenClassification">LongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetForTokenClassification">MPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification">MegatronBertForTokenClassification</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification">MobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaForTokenClassification">NezhaForTokenClassification</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification">NystromformerForTokenClassification</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification">QDQBertForTokenClassification</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertForTokenClassification">RemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerForTokenClassification">RoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaForTokenClassification">RobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification">SqueezeBertForTokenClassification</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMForTokenClassification">XLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification">XLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification">XLMRobertaXLForTokenClassification</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetForTokenClassification">XLNetForTokenClassification</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoForTokenClassification">YosoForTokenClassification</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),cF=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_config.example",$$slots:{default:[WDt]},$$scope:{ctx:x}}}),zA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),HF=new B({props:{anchor:"transformers.AutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[HDt]},$$scope:{ctx:x}}}),QA=new re({}),WA=new R({props:{name:"class transformers.AutoModelForQuestionAnswering",anchor:"transformers.AutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L821"}}),UA=new R({props:{name:"from_config",anchor:"transformers.AutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertForQuestionAnswering">AlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartForQuestionAnswering">BartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertForQuestionAnswering">BertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering">BigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig">BigBirdPegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering">BigBirdPegasusForQuestionAnswering</a> (BigBird-Pegasus model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertForQuestionAnswering">CamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineConfig">CanineConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineForQuestionAnswering">CanineForQuestionAnswering</a> (CANINE model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering">ConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextConfig">Data2VecTextConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering">Data2VecTextForQuestionAnswering</a> (Data2VecText model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaForQuestionAnswering">DebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering">DebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering">DistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraForQuestionAnswering">ElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetConfig">FNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetForQuestionAnswering">FNetForQuestionAnswering</a> (FNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple">FlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelForQuestionAnswering">FunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJForQuestionAnswering">GPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertConfig">IBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertForQuestionAnswering">IBertForQuestionAnswering</a> (I-BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDForQuestionAnswering">LEDForQuestionAnswering</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config">LayoutLMv2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering">LayoutLMv2ForQuestionAnswering</a> (LayoutLMv2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config">LayoutLMv3Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering">LayoutLMv3ForQuestionAnswering</a> (LayoutLMv3 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerForQuestionAnswering">LongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering">LxmertForQuestionAnswering</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartForQuestionAnswering">MBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering">MPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertConfig">MegatronBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering">MegatronBertForQuestionAnswering</a> (Megatron-BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering">MobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaConfig">NezhaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaForQuestionAnswering">NezhaForQuestionAnswering</a> (Nezha model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerConfig">NystromformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering">NystromformerForQuestionAnswering</a> (Nystr&#xF6;mformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertConfig">QDQBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering">QDQBertForQuestionAnswering</a> (QDQBert model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerConfig">ReformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerForQuestionAnswering">ReformerForQuestionAnswering</a> (Reformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertForQuestionAnswering">RemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering">RoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaForQuestionAnswering">RobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/splinter#transformers.SplinterConfig">SplinterConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/splinter#transformers.SplinterForQuestionAnswering">SplinterForQuestionAnswering</a> (Splinter model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertConfig">SqueezeBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering">SqueezeBertForQuestionAnswering</a> (SqueezeBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple">XLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering">XLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig">XLMRobertaXLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering">XLMRobertaXLForQuestionAnswering</a> (XLM-RoBERTa-XL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple">XLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoConfig">YosoConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoForQuestionAnswering">YosoForQuestionAnswering</a> (YOSO model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),JF=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_config.example",$$slots:{default:[UDt]},$$scope:{ctx:x}}}),JA=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),j6=new B({props:{anchor:"transformers.AutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[JDt]},$$scope:{ctx:x}}}),YA=new re({}),KA=new R({props:{name:"class transformers.AutoModelForTableQuestionAnswering",anchor:"transformers.AutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L828"}}),eL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasForQuestionAnswering">TapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),G6=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[YDt]},$$scope:{ctx:x}}}),oL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),X6=new B({props:{anchor:"transformers.AutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[KDt]},$$scope:{ctx:x}}}),rL=new re({}),tL=new R({props:{name:"class transformers.AutoModelForImageClassification",anchor:"transformers.AutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L873"}}),nL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/beit#transformers.BeitForImageClassification">BeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/convnext#transformers.ConvNextForImageClassification">ConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/cvt#transformers.CvtConfig">CvtConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/cvt#transformers.CvtForImageClassification">CvtForImageClassification</a> (CvT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification">Data2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deit#transformers.DeiTForImageClassification">DeiTForImageClassification</a> or <a href="/docs/transformers/pr_17869/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher">DeiTForImageClassificationWithTeacher</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/imagegpt#transformers.ImageGPTConfig">ImageGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification">ImageGPTForImageClassification</a> (ImageGPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/levit#transformers.LevitConfig">LevitConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/levit#transformers.LevitForImageClassification">LevitForImageClassification</a> or <a href="/docs/transformers/pr_17869/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher">LevitForImageClassificationWithTeacher</a> (LeViT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverConfig">PerceiverConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned">PerceiverForImageClassificationLearned</a> or <a href="/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier">PerceiverForImageClassificationFourier</a> or <a href="/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing">PerceiverForImageClassificationConvProcessing</a> (Perceiver model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/poolformer#transformers.PoolFormerConfig">PoolFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/poolformer#transformers.PoolFormerForImageClassification">PoolFormerForImageClassification</a> (PoolFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/regnet#transformers.RegNetConfig">RegNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/regnet#transformers.RegNetForImageClassification">RegNetForImageClassification</a> (RegNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/resnet#transformers.ResNetConfig">ResNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/resnet#transformers.ResNetForImageClassification">ResNetForImageClassification</a> (ResNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/segformer#transformers.SegformerForImageClassification">SegformerForImageClassification</a> (SegFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/swin#transformers.SwinForImageClassification">SwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/van#transformers.VanConfig">VanConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/van#transformers.VanForImageClassification">VanForImageClassification</a> (VAN model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTForImageClassification">ViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),Q6=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_config.example",$$slots:{default:[ZDt]},$$scope:{ctx:x}}}),sL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),sT=new B({props:{anchor:"transformers.AutoModelForImageClassification.from_pretrained.example",$$slots:{default:[eGt]},$$scope:{ctx:x}}}),lL=new re({}),iL=new R({props:{name:"class transformers.AutoModelForVision2Seq",anchor:"transformers.AutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L912"}}),cL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel">VisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),iT=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_config.example",$$slots:{default:[oGt]},$$scope:{ctx:x}}}),fL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),fT=new B({props:{anchor:"transformers.AutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[rGt]},$$scope:{ctx:x}}}),mL=new re({}),gL=new R({props:{name:"class transformers.AutoModelForVisualQuestionAnswering",anchor:"transformers.AutoModelForVisualQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L839"}}),pL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vilt#transformers.ViltConfig">ViltConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vilt#transformers.ViltForQuestionAnswering">ViltForQuestionAnswering</a> (ViLT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),gT=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_config.example",$$slots:{default:[tGt]},$$scope:{ctx:x}}}),_L=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),_T=new B({props:{anchor:"transformers.AutoModelForVisualQuestionAnswering.from_pretrained.example",$$slots:{default:[aGt]},$$scope:{ctx:x}}}),uL=new re({}),bL=new R({props:{name:"class transformers.AutoModelForAudioClassification",anchor:"transformers.AutoModelForAudioClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L919"}}),FL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification">Data2VecAudioForSequenceClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/hubert#transformers.HubertForSequenceClassification">HubertForSequenceClassification</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/sew#transformers.SEWForSequenceClassification">SEWForSequenceClassification</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/sew-d#transformers.SEWDForSequenceClassification">SEWDForSequenceClassification</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification">UniSpeechForSequenceClassification</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification">UniSpeechSatForSequenceClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification">Wav2Vec2ForSequenceClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification">Wav2Vec2ConformerForSequenceClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wavlm#transformers.WavLMForSequenceClassification">WavLMForSequenceClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),bT=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_config.example",$$slots:{default:[nGt]},$$scope:{ctx:x}}}),TL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),xT=new B({props:{anchor:"transformers.AutoModelForAudioClassification.from_pretrained.example",$$slots:{default:[sGt]},$$scope:{ctx:x}}}),ML=new re({}),EL=new R({props:{name:"class transformers.AutoModelForAudioFrameClassification",anchor:"transformers.AutoModelForAudioFrameClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L942"}}),wL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioFrameClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification">Data2VecAudioForAudioFrameClassification</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification">UniSpeechSatForAudioFrameClassification</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification">Wav2Vec2ForAudioFrameClassification</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification">Wav2Vec2ConformerForAudioFrameClassification</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification">WavLMForAudioFrameClassification</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),kT=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_config.example",$$slots:{default:[lGt]},$$scope:{ctx:x}}}),AL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),qT=new B({props:{anchor:"transformers.AutoModelForAudioFrameClassification.from_pretrained.example",$$slots:{default:[iGt]},$$scope:{ctx:x}}}),LL=new re({}),yL=new R({props:{name:"class transformers.AutoModelForCTC",anchor:"transformers.AutoModelForCTC",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L926"}}),$L=new R({props:{name:"from_config",anchor:"transformers.AutoModelForCTC.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecAudioForCTC">Data2VecAudioForCTC</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/hubert#transformers.HubertForCTC">HubertForCTC</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mctct#transformers.MCTCTConfig">MCTCTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mctct#transformers.MCTCTForCTC">MCTCTForCTC</a> (M-CTC-T model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/sew#transformers.SEWConfig">SEWConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/sew#transformers.SEWForCTC">SEWForCTC</a> (SEW model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/sew-d#transformers.SEWDConfig">SEWDConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/sew-d#transformers.SEWDForCTC">SEWDForCTC</a> (SEW-D model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/unispeech#transformers.UniSpeechConfig">UniSpeechConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/unispeech#transformers.UniSpeechForCTC">UniSpeechForCTC</a> (UniSpeech model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC">UniSpeechSatForCTC</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC">Wav2Vec2ForCTC</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC">Wav2Vec2ConformerForCTC</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wavlm#transformers.WavLMForCTC">WavLMForCTC</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),DT=new B({props:{anchor:"transformers.AutoModelForCTC.from_config.example",$$slots:{default:[dGt]},$$scope:{ctx:x}}}),kL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForCTC.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForCTC.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForCTC.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForCTC.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForCTC.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForCTC.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForCTC.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForCTC.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForCTC.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForCTC.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForCTC.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForCTC.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForCTC.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),KT=new B({props:{anchor:"transformers.AutoModelForCTC.from_pretrained.example",$$slots:{default:[cGt]},$$scope:{ctx:x}}}),SL=new re({}),RL=new R({props:{name:"class transformers.AutoModelForSpeechSeq2Seq",anchor:"transformers.AutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L933"}}),BL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration">Speech2TextForConditionalGeneration</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig">SpeechEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel">SpeechEncoderDecoderModel</a> (Speech Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),e7=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[fGt]},$$scope:{ctx:x}}}),IL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),a7=new B({props:{anchor:"transformers.AutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[mGt]},$$scope:{ctx:x}}}),qL=new re({}),jL=new R({props:{name:"class transformers.AutoModelForAudioXVector",anchor:"transformers.AutoModelForAudioXVector",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L951"}}),GL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForAudioXVector.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecAudioConfig">Data2VecAudioConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecAudioForXVector">Data2VecAudioForXVector</a> (Data2VecAudio model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig">UniSpeechSatConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector">UniSpeechSatForXVector</a> (UniSpeechSat model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector">Wav2Vec2ForXVector</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig">Wav2Vec2ConformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector">Wav2Vec2ConformerForXVector</a> (Wav2Vec2-Conformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wavlm#transformers.WavLMConfig">WavLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wavlm#transformers.WavLMForXVector">WavLMForXVector</a> (WavLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),s7=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_config.example",$$slots:{default:[gGt]},$$scope:{ctx:x}}}),OL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForAudioXVector.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),g7=new B({props:{anchor:"transformers.AutoModelForAudioXVector.from_pretrained.example",$$slots:{default:[hGt]},$$scope:{ctx:x}}}),VL=new re({}),XL=new R({props:{name:"class transformers.AutoModelForMaskedImageModeling",anchor:"transformers.AutoModelForMaskedImageModeling",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L958"}}),QL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForMaskedImageModeling.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deit#transformers.DeiTConfig">DeiTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deit#transformers.DeiTForMaskedImageModeling">DeiTForMaskedImageModeling</a> (DeiT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/swin#transformers.SwinForMaskedImageModeling">SwinForMaskedImageModeling</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTForMaskedImageModeling">ViTForMaskedImageModeling</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),p7=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_config.example",$$slots:{default:[pGt]},$$scope:{ctx:x}}}),WL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),F7=new B({props:{anchor:"transformers.AutoModelForMaskedImageModeling.from_pretrained.example",$$slots:{default:[_Gt]},$$scope:{ctx:x}}}),HL=new re({}),UL=new R({props:{name:"class transformers.AutoModelForObjectDetection",anchor:"transformers.AutoModelForObjectDetection",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L905"}}),YL=new R({props:{name:"from_config",anchor:"transformers.AutoModelForObjectDetection.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/detr#transformers.DetrForObjectDetection">DetrForObjectDetection</a> (DETR model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/yolos#transformers.YolosConfig">YolosConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/yolos#transformers.YolosForObjectDetection">YolosForObjectDetection</a> (YOLOS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),M7=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_config.example",$$slots:{default:[uGt]},$$scope:{ctx:x}}}),KL=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForObjectDetection.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),A7=new B({props:{anchor:"transformers.AutoModelForObjectDetection.from_pretrained.example",$$slots:{default:[bGt]},$$scope:{ctx:x}}}),ey=new re({}),oy=new R({props:{name:"class transformers.AutoModelForImageSegmentation",anchor:"transformers.AutoModelForImageSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L880"}}),ty=new R({props:{name:"from_config",anchor:"transformers.AutoModelForImageSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/detr#transformers.DetrConfig">DetrConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/detr#transformers.DetrForSegmentation">DetrForSegmentation</a> (DETR model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),y7=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_config.example",$$slots:{default:[vGt]},$$scope:{ctx:x}}}),ay=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForImageSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),k7=new B({props:{anchor:"transformers.AutoModelForImageSegmentation.from_pretrained.example",$$slots:{default:[FGt]},$$scope:{ctx:x}}}),ny=new re({}),sy=new R({props:{name:"class transformers.AutoModelForSemanticSegmentation",anchor:"transformers.AutoModelForSemanticSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L887"}}),iy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForSemanticSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/beit#transformers.BeitForSemanticSegmentation">BeitForSemanticSegmentation</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/dpt#transformers.DPTConfig">DPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/dpt#transformers.DPTForSemanticSegmentation">DPTForSemanticSegmentation</a> (DPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation">Data2VecVisionForSemanticSegmentation</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/segformer#transformers.SegformerConfig">SegformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation">SegformerForSemanticSegmentation</a> (SegFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),R7=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_config.example",$$slots:{default:[TGt]},$$scope:{ctx:x}}}),dy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),j7=new B({props:{anchor:"transformers.AutoModelForSemanticSegmentation.from_pretrained.example",$$slots:{default:[MGt]},$$scope:{ctx:x}}}),cy=new re({}),fy=new R({props:{name:"class transformers.AutoModelForInstanceSegmentation",anchor:"transformers.AutoModelForInstanceSegmentation",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_auto.py#L896"}}),gy=new R({props:{name:"from_config",anchor:"transformers.AutoModelForInstanceSegmentation.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/maskformer#transformers.MaskFormerConfig">MaskFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation">MaskFormerForInstanceSegmentation</a> (MaskFormer model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),G7=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_config.example",$$slots:{default:[EGt]},$$scope:{ctx:x}}}),hy=new R({props:{name:"from_pretrained",anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>tensorflow index checkpoint file</em> (e.g, <code>./tf_model/model.ckpt.index</code>). In
this case, <code>from_tf</code> should be set to <code>True</code> and a configuration object should be provided as
<code>config</code> argument. This loading path is slower than converting the TensorFlow checkpoint in a
PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.state_dict",description:`<strong>state_dict</strong> (<em>Dict[str, torch.Tensor]</em>, <em>optional</em>) &#x2014;
A state dictionary to use instead of a state dictionary loaded from saved weights file.</p>
<p>This option can be used if you want to create a model from a pretrained configuration but load your own
weights. In this case though, you should check if using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> is not a simpler option.`,name:"state_dict"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.from_tf",description:`<strong>from_tf</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a TensorFlow checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_tf"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),X7=new B({props:{anchor:"transformers.AutoModelForInstanceSegmentation.from_pretrained.example",$$slots:{default:[CGt]},$$scope:{ctx:x}}}),py=new re({}),_y=new R({props:{name:"class transformers.TFAutoModel",anchor:"transformers.TFAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_tf_auto.py#L406"}}),by=new R({props:{name:"from_config",anchor:"transformers.TFAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.TFAlbertModel">TFAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.TFBartModel">TFBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertModel">TFBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.TFBlenderbotModel">TFBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel">TFBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/clip#transformers.TFCLIPModel">TFCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.TFCTRLModel">TFCTRLModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.TFCamembertModel">TFCamembertModel</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.TFConvBertModel">TFConvBertModel</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/convnext#transformers.TFConvNextModel">TFConvNextModel</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/dpr#transformers.DPRConfig">DPRConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/dpr#transformers.TFDPRQuestionEncoder">TFDPRQuestionEncoder</a> (DPR model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.TFData2VecVisionModel">TFData2VecVisionModel</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.TFDebertaModel">TFDebertaModel</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.TFDebertaV2Model">TFDebertaV2Model</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.TFDistilBertModel">TFDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.TFElectraModel">TFElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.TFFlaubertModel">TFFlaubertModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.TFFunnelModel">TFFunnelModel</a> or <a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.TFFunnelBaseModel">TFFunnelBaseModel</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.TFGPT2Model">TFGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.TFGPTJModel">TFGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/hubert#transformers.HubertConfig">HubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/hubert#transformers.TFHubertModel">TFHubertModel</a> (Hubert model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/led#transformers.TFLEDModel">TFLEDModel</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.TFLayoutLMModel">TFLayoutLMModel</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.TFLongformerModel">TFLongformerModel</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.TFLxmertModel">TFLxmertModel</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.TFMBartModel">TFMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.TFMPNetModel">TFMPNetModel</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mt5#transformers.TFMT5Model">TFMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/marian#transformers.TFMarianModel">TFMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.TFMobileBertModel">TFMobileBertModel</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/opt#transformers.TFOPTModel">TFOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel">TFOpenAIGPTModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.TFPegasusModel">TFPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.TFRemBertModel">TFRemBertModel</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.TFRoFormerModel">TFRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.TFRobertaModel">TFRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel">TFSpeech2TextModel</a> (Speech2Text model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/swin#transformers.TFSwinModel">TFSwinModel</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.TFT5Model">TFT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TFTapasModel">TFTapasModel</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TFTransfoXLModel">TFTransfoXLModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vit#transformers.TFViTModel">TFViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vit_mae#transformers.TFViTMAEModel">TFViTMAEModel</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model">TFWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.TFXLMModel">TFXLMModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel">TFXLMRobertaModel</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.TFXLNetModel">TFXLNetModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),Q7=new B({props:{anchor:"transformers.TFAutoModel.from_config.example",$$slots:{default:[wGt]},$$scope:{ctx:x}}}),vy=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),j8=new B({props:{anchor:"transformers.TFAutoModel.from_pretrained.example",$$slots:{default:[AGt]},$$scope:{ctx:x}}}),Fy=new re({}),Ty=new R({props:{name:"class transformers.TFAutoModelForPreTraining",anchor:"transformers.TFAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_tf_auto.py#L413"}}),Ey=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.TFAlbertForPreTraining">TFAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertForPreTraining">TFBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.TFElectraForPreTraining">TFElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.TFFunnelForPreTraining">TFFunnelForPreTraining</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.LxmertConfig">LxmertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.TFLxmertForPreTraining">TFLxmertForPreTraining</a> (LXMERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining">TFMobileBertForPreTraining</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vit_mae#transformers.ViTMAEConfig">ViTMAEConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining">TFViTMAEForPreTraining</a> (ViTMAE model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),G8=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_config.example",$$slots:{default:[LGt]},$$scope:{ctx:x}}}),Cy=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),f9=new B({props:{anchor:"transformers.TFAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[yGt]},$$scope:{ctx:x}}}),wy=new re({}),Ay=new R({props:{name:"class transformers.TFAutoModelForCausalLM",anchor:"transformers.TFAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_tf_auto.py#L428"}}),yy=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertLMHeadModel">TFBertLMHeadModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel">TFCTRLLMHeadModel</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.TFCamembertForCausalLM">TFCamembertForCausalLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel">TFGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.TFGPTJForCausalLM">TFGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/opt#transformers.TFOPTForCausalLM">TFOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel">TFOpenAIGPTLMHeadModel</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.TFRemBertForCausalLM">TFRemBertForCausalLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.TFRoFormerForCausalLM">TFRoFormerForCausalLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.TFRobertaForCausalLM">TFRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel">TFTransfoXLLMHeadModel</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel">TFXLNetLMHeadModel</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),g9=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_config.example",$$slots:{default:[xGt]},$$scope:{ctx:x}}}),xy=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),L9=new B({props:{anchor:"transformers.TFAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[$Gt]},$$scope:{ctx:x}}}),$y=new re({}),ky=new R({props:{name:"class transformers.TFAutoModelForImageClassification",anchor:"transformers.TFAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_tf_auto.py#L444"}}),Ry=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/convnext#transformers.ConvNextConfig">ConvNextConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/convnext#transformers.TFConvNextForImageClassification">TFConvNextForImageClassification</a> (ConvNeXT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecVisionConfig">Data2VecVisionConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification">TFData2VecVisionForImageClassification</a> (Data2VecVision model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/swin#transformers.SwinConfig">SwinConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/swin#transformers.TFSwinForImageClassification">TFSwinForImageClassification</a> (Swin Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vit#transformers.TFViTForImageClassification">TFViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),x9=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_config.example",$$slots:{default:[kGt]},$$scope:{ctx:x}}}),Py=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),P9=new B({props:{anchor:"transformers.TFAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[SGt]},$$scope:{ctx:x}}}),By=new re({}),Iy=new R({props:{name:"class transformers.TFAutoModelForMaskedLM",anchor:"transformers.TFAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_tf_auto.py#L469"}}),qy=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.TFAlbertForMaskedLM">TFAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertForMaskedLM">TFBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.TFCamembertForMaskedLM">TFCamembertForMaskedLM</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.TFConvBertForMaskedLM">TFConvBertForMaskedLM</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.TFDebertaForMaskedLM">TFDebertaForMaskedLM</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM">TFDebertaV2ForMaskedLM</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM">TFDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.TFElectraForMaskedLM">TFElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel">TFFlaubertWithLMHeadModel</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.TFFunnelForMaskedLM">TFFunnelForMaskedLM</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM">TFLayoutLMForMaskedLM</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.TFLongformerForMaskedLM">TFLongformerForMaskedLM</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM">TFMPNetForMaskedLM</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM">TFMobileBertForMaskedLM</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.TFRemBertForMaskedLM">TFRemBertForMaskedLM</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM">TFRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.TFRobertaForMaskedLM">TFRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TFTapasForMaskedLM">TFTapasForMaskedLM</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel">TFXLMWithLMHeadModel</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM">TFXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),I9=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_config.example",$$slots:{default:[RGt]},$$scope:{ctx:x}}}),jy=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),tM=new B({props:{anchor:"transformers.TFAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[PGt]},$$scope:{ctx:x}}}),Dy=new re({}),Gy=new R({props:{name:"class transformers.TFAutoModelForSeq2SeqLM",anchor:"transformers.TFAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_tf_auto.py#L476"}}),Vy=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.TFBartForConditionalGeneration">TFBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration">TFBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration">TFBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel">TFEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDConfig">LEDConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/led#transformers.TFLEDForConditionalGeneration">TFLEDForConditionalGeneration</a> (LED model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration">TFMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration">TFMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/marian#transformers.TFMarianMTModel">TFMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration">TFPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.TFT5ForConditionalGeneration">TFT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),nM=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[BGt]},$$scope:{ctx:x}}}),Xy=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),_M=new B({props:{anchor:"transformers.TFAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[IGt]},$$scope:{ctx:x}}}),zy=new re({}),Qy=new R({props:{name:"class transformers.TFAutoModelForSequenceClassification",anchor:"transformers.TFAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_tf_auto.py#L485"}}),Hy=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.TFAlbertForSequenceClassification">TFAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertForSequenceClassification">TFBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLConfig">CTRLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification">TFCTRLForSequenceClassification</a> (CTRL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification">TFCamembertForSequenceClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification">TFConvBertForSequenceClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification">TFDebertaForSequenceClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification">TFDebertaV2ForSequenceClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification">TFDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.TFElectraForSequenceClassification">TFElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification">TFFlaubertForSequenceClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification">TFFunnelForSequenceClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification">TFGPT2ForSequenceClassification</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification">TFGPTJForSequenceClassification</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification">TFLayoutLMForSequenceClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification">TFLongformerForSequenceClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification">TFMPNetForSequenceClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification">TFMobileBertForSequenceClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig">OpenAIGPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification">TFOpenAIGPTForSequenceClassification</a> (OpenAI GPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification">TFRemBertForSequenceClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification">TFRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification">TFRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TFTapasForSequenceClassification">TFTapasForSequenceClassification</a> (TAPAS model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLConfig">TransfoXLConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification">TFTransfoXLForSequenceClassification</a> (Transformer-XL model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.TFXLMForSequenceClassification">TFXLMForSequenceClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification">TFXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification">TFXLNetForSequenceClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),bM=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_config.example",$$slots:{default:[NGt]},$$scope:{ctx:x}}}),Uy=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),zM=new B({props:{anchor:"transformers.TFAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[qGt]},$$scope:{ctx:x}}}),Jy=new re({}),Yy=new R({props:{name:"class transformers.TFAutoModelForMultipleChoice",anchor:"transformers.TFAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_tf_auto.py#L521"}}),Zy=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.TFAlbertForMultipleChoice">TFAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertForMultipleChoice">TFBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice">TFCamembertForMultipleChoice</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice">TFConvBertForMultipleChoice</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice">TFDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.TFElectraForMultipleChoice">TFElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice">TFFlaubertForMultipleChoice</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice">TFFunnelForMultipleChoice</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice">TFLongformerForMultipleChoice</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice">TFMPNetForMultipleChoice</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice">TFMobileBertForMultipleChoice</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice">TFRemBertForMultipleChoice</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice">TFRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice">TFRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.TFXLMForMultipleChoice">TFXLMForMultipleChoice</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice">TFXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice">TFXLNetForMultipleChoice</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),WM=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_config.example",$$slots:{default:[jGt]},$$scope:{ctx:x}}}),ex=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),fE=new B({props:{anchor:"transformers.TFAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[DGt]},$$scope:{ctx:x}}}),ox=new re({}),rx=new R({props:{name:"class transformers.TFAutoModelForNextSentencePrediction",anchor:"transformers.TFAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_tf_auto.py#L528"}}),ax=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertForNextSentencePrediction">TFBertForNextSentencePrediction</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction">TFMobileBertForNextSentencePrediction</a> (MobileBERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),gE=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[GGt]},$$scope:{ctx:x}}}),nx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),_E=new B({props:{anchor:"transformers.TFAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[OGt]},$$scope:{ctx:x}}}),lx=new re({}),ix=new R({props:{name:"class transformers.TFAutoModelForTableQuestionAnswering",anchor:"transformers.TFAutoModelForTableQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_tf_auto.py#L501"}}),cx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasConfig">TapasConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering">TFTapasForQuestionAnswering</a> (TAPAS model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),bE=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_config.example",$$slots:{default:[VGt]},$$scope:{ctx:x}}}),fx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),FE=new B({props:{anchor:"transformers.TFAutoModelForTableQuestionAnswering.from_pretrained.example",$$slots:{default:[XGt]},$$scope:{ctx:x}}}),mx=new re({}),gx=new R({props:{name:"class transformers.TFAutoModelForTokenClassification",anchor:"transformers.TFAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_tf_auto.py#L512"}}),px=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.TFAlbertForTokenClassification">TFAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertForTokenClassification">TFBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.TFCamembertForTokenClassification">TFCamembertForTokenClassification</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.TFConvBertForTokenClassification">TFConvBertForTokenClassification</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.TFDebertaForTokenClassification">TFDebertaForTokenClassification</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification">TFDebertaV2ForTokenClassification</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification">TFDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.TFElectraForTokenClassification">TFElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification">TFFlaubertForTokenClassification</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.TFFunnelForTokenClassification">TFFunnelForTokenClassification</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMConfig">LayoutLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification">TFLayoutLMForTokenClassification</a> (LayoutLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.TFLongformerForTokenClassification">TFLongformerForTokenClassification</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification">TFMPNetForTokenClassification</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification">TFMobileBertForTokenClassification</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.TFRemBertForTokenClassification">TFRemBertForTokenClassification</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification">TFRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.TFRobertaForTokenClassification">TFRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.TFXLMForTokenClassification">TFXLMForTokenClassification</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification">TFXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification">TFXLNetForTokenClassification</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),ME=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_config.example",$$slots:{default:[zGt]},$$scope:{ctx:x}}}),_x=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),VE=new B({props:{anchor:"transformers.TFAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[QGt]},$$scope:{ctx:x}}}),ux=new re({}),bx=new R({props:{name:"class transformers.TFAutoModelForQuestionAnswering",anchor:"transformers.TFAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_tf_auto.py#L494"}}),Fx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering">TFAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertForQuestionAnswering">TFBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig">CamembertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering">TFCamembertForQuestionAnswering</a> (CamemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertConfig">ConvBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering">TFConvBertForQuestionAnswering</a> (ConvBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaConfig">DebertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering">TFDebertaForQuestionAnswering</a> (DeBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2Config">DebertaV2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering">TFDebertaV2ForQuestionAnswering</a> (DeBERTa-v2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering">TFDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.TFElectraForQuestionAnswering">TFElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertConfig">FlaubertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple">TFFlaubertForQuestionAnsweringSimple</a> (FlauBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelConfig">FunnelConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering">TFFunnelForQuestionAnswering</a> (Funnel Transformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering">TFGPTJForQuestionAnswering</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerConfig">LongformerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering">TFLongformerForQuestionAnswering</a> (Longformer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetConfig">MPNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering">TFMPNetForQuestionAnswering</a> (MPNet model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig">MobileBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering">TFMobileBertForQuestionAnswering</a> (MobileBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertConfig">RemBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering">TFRemBertForQuestionAnswering</a> (RemBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering">TFRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering">TFRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig">XLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple">TFXLMForQuestionAnsweringSimple</a> (XLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering">TFXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetConfig">XLNetConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple">TFXLNetForQuestionAnsweringSimple</a> (XLNet model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),zE=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[WGt]},$$scope:{ctx:x}}}),Tx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),m4=new B({props:{anchor:"transformers.TFAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[HGt]},$$scope:{ctx:x}}}),Mx=new re({}),Ex=new R({props:{name:"class transformers.TFAutoModelForVision2Seq",anchor:"transformers.TFAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_tf_auto.py#L462"}}),wx=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel">TFVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),h4=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_config.example",$$slots:{default:[UGt]},$$scope:{ctx:x}}}),Ax=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),_4=new B({props:{anchor:"transformers.TFAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[JGt]},$$scope:{ctx:x}}}),Lx=new re({}),yx=new R({props:{name:"class transformers.TFAutoModelForSpeechSeq2Seq",anchor:"transformers.TFAutoModelForSpeechSeq2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_tf_auto.py#L537"}}),$x=new R({props:{name:"from_config",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/speech_to_text#transformers.Speech2TextConfig">Speech2TextConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration">TFSpeech2TextForConditionalGeneration</a> (Speech2Text model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),b4=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_config.example",$$slots:{default:[YGt]},$$scope:{ctx:x}}}),kx=new R({props:{name:"from_pretrained",anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),F4=new B({props:{anchor:"transformers.TFAutoModelForSpeechSeq2Seq.from_pretrained.example",$$slots:{default:[KGt]},$$scope:{ctx:x}}}),Sx=new re({}),Rx=new R({props:{name:"class transformers.FlaxAutoModel",anchor:"transformers.FlaxAutoModel",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_flax_auto.py#L246"}}),Bx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModel.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.FlaxAlbertModel">FlaxAlbertModel</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.FlaxBartModel">FlaxBartModel</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/beit#transformers.FlaxBeitModel">FlaxBeitModel</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertModel">FlaxBertModel</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.FlaxBigBirdModel">FlaxBigBirdModel</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel">FlaxBlenderbotModel</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel">FlaxBlenderbotSmallModel</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/clip#transformers.CLIPConfig">CLIPConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/clip#transformers.FlaxCLIPModel">FlaxCLIPModel</a> (CLIP model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.FlaxDistilBertModel">FlaxDistilBertModel</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.FlaxElectraModel">FlaxElectraModel</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.FlaxGPT2Model">FlaxGPT2Model</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.FlaxGPTJModel">FlaxGPTJModel</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel">FlaxGPTNeoModel</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longt5#transformers.FlaxLongT5Model">FlaxLongT5Model</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.FlaxMBartModel">FlaxMBartModel</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mt5#transformers.FlaxMT5Model">FlaxMT5Model</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/marian#transformers.FlaxMarianModel">FlaxMarianModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/opt#transformers.FlaxOPTModel">FlaxOPTModel</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.FlaxPegasusModel">FlaxPegasusModel</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.FlaxRoFormerModel">FlaxRoFormerModel</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.FlaxRobertaModel">FlaxRobertaModel</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.FlaxT5Model">FlaxT5Model</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vit#transformers.FlaxViTModel">FlaxViTModel</a> (ViT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig">VisionTextDualEncoderConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel">FlaxVisionTextDualEncoderModel</a> (VisionTextDualEncoder model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model">FlaxWav2Vec2Model</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xglm#transformers.FlaxXGLMModel">FlaxXGLMModel</a> (XGLM model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel">FlaxXLMRobertaModel</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),M4=new B({props:{anchor:"transformers.FlaxAutoModel.from_config.example",$$slots:{default:[ZGt]},$$scope:{ctx:x}}}),Ix=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModel.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModel.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModel.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModel.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModel.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModel.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModel.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModel.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModel.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModel.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModel.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModel.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),J4=new B({props:{anchor:"transformers.FlaxAutoModel.from_pretrained.example",$$slots:{default:[eOt]},$$scope:{ctx:x}}}),Nx=new re({}),qx=new R({props:{name:"class transformers.FlaxAutoModelForCausalLM",anchor:"transformers.FlaxAutoModelForCausalLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_flax_auto.py#L260"}}),Dx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForCausalLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.FlaxBartForCausalLM">FlaxBartForCausalLM</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertForCausalLM">FlaxBertForCausalLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM">FlaxBigBirdForCausalLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.FlaxElectraForCausalLM">FlaxElectraForCausalLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Config">GPT2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel">FlaxGPT2LMHeadModel</a> (OpenAI GPT-2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJConfig">GPTJConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM">FlaxGPTJForCausalLM</a> (GPT-J model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/gpt_neo#transformers.GPTNeoConfig">GPTNeoConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM">FlaxGPTNeoForCausalLM</a> (GPT Neo model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/opt#transformers.OPTConfig">OPTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/opt#transformers.FlaxOPTForCausalLM">FlaxOPTForCausalLM</a> (OPT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM">FlaxRobertaForCausalLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xglm#transformers.XGLMConfig">XGLMConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM">FlaxXGLMForCausalLM</a> (XGLM model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),K4=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_config.example",$$slots:{default:[oOt]},$$scope:{ctx:x}}}),Gx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),dC=new B({props:{anchor:"transformers.FlaxAutoModelForCausalLM.from_pretrained.example",$$slots:{default:[rOt]},$$scope:{ctx:x}}}),Ox=new re({}),Vx=new R({props:{name:"class transformers.FlaxAutoModelForPreTraining",anchor:"transformers.FlaxAutoModelForPreTraining",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_flax_auto.py#L253"}}),zx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForPreTraining.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.FlaxAlbertForPreTraining">FlaxAlbertForPreTraining</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertForPreTraining">FlaxBertForPreTraining</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining">FlaxBigBirdForPreTraining</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.FlaxElectraForPreTraining">FlaxElectraForPreTraining</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Config">Wav2Vec2Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining">FlaxWav2Vec2ForPreTraining</a> (Wav2Vec2 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),fC=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_config.example",$$slots:{default:[tOt]},$$scope:{ctx:x}}}),Qx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),wC=new B({props:{anchor:"transformers.FlaxAutoModelForPreTraining.from_pretrained.example",$$slots:{default:[aOt]},$$scope:{ctx:x}}}),Wx=new re({}),Hx=new R({props:{name:"class transformers.FlaxAutoModelForMaskedLM",anchor:"transformers.FlaxAutoModelForMaskedLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_flax_auto.py#L267"}}),Jx=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMaskedLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM">FlaxAlbertForMaskedLM</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertForMaskedLM">FlaxBertForMaskedLM</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM">FlaxBigBirdForMaskedLM</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM">FlaxDistilBertForMaskedLM</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.FlaxElectraForMaskedLM">FlaxElectraForMaskedLM</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM">FlaxRoFormerForMaskedLM</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM">FlaxRobertaForMaskedLM</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM">FlaxXLMRobertaForMaskedLM</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),LC=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_config.example",$$slots:{default:[nOt]},$$scope:{ctx:x}}}),Yx=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),qC=new B({props:{anchor:"transformers.FlaxAutoModelForMaskedLM.from_pretrained.example",$$slots:{default:[sOt]},$$scope:{ctx:x}}}),Kx=new re({}),Zx=new R({props:{name:"class transformers.FlaxAutoModelForSeq2SeqLM",anchor:"transformers.FlaxAutoModelForSeq2SeqLM",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_flax_auto.py#L274"}}),o$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration">FlaxBartForConditionalGeneration</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.BlenderbotConfig">BlenderbotConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration">FlaxBlenderbotForConditionalGeneration</a> (Blenderbot model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig">BlenderbotSmallConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration">FlaxBlenderbotSmallForConditionalGeneration</a> (BlenderbotSmall model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig">EncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel">FlaxEncoderDecoderModel</a> (Encoder decoder model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/longt5#transformers.LongT5Config">LongT5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration">FlaxLongT5ForConditionalGeneration</a> (LongT5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration">FlaxMBartForConditionalGeneration</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mt5#transformers.MT5Config">MT5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration">FlaxMT5ForConditionalGeneration</a> (MT5 model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/marian#transformers.MarianConfig">MarianConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/marian#transformers.FlaxMarianMTModel">FlaxMarianMTModel</a> (Marian model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusConfig">PegasusConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration">FlaxPegasusForConditionalGeneration</a> (Pegasus model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5Config">T5Config</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration">FlaxT5ForConditionalGeneration</a> (T5 model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),DC=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_config.example",$$slots:{default:[lOt]},$$scope:{ctx:x}}}),r$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),YC=new B({props:{anchor:"transformers.FlaxAutoModelForSeq2SeqLM.from_pretrained.example",$$slots:{default:[iOt]},$$scope:{ctx:x}}}),t$=new re({}),a$=new R({props:{name:"class transformers.FlaxAutoModelForSequenceClassification",anchor:"transformers.FlaxAutoModelForSequenceClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_flax_auto.py#L283"}}),s$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification">FlaxAlbertForSequenceClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.FlaxBartForSequenceClassification">FlaxBartForSequenceClassification</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertForSequenceClassification">FlaxBertForSequenceClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification">FlaxBigBirdForSequenceClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification">FlaxDistilBertForSequenceClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification">FlaxElectraForSequenceClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification">FlaxMBartForSequenceClassification</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification">FlaxRoFormerForSequenceClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification">FlaxRobertaForSequenceClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification">FlaxXLMRobertaForSequenceClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),ZC=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_config.example",$$slots:{default:[dOt]},$$scope:{ctx:x}}}),l$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),c5=new B({props:{anchor:"transformers.FlaxAutoModelForSequenceClassification.from_pretrained.example",$$slots:{default:[cOt]},$$scope:{ctx:x}}}),i$=new re({}),d$=new R({props:{name:"class transformers.FlaxAutoModelForQuestionAnswering",anchor:"transformers.FlaxAutoModelForQuestionAnswering",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_flax_auto.py#L292"}}),f$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering">FlaxAlbertForQuestionAnswering</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig">BartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering">FlaxBartForQuestionAnswering</a> (BART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering">FlaxBertForQuestionAnswering</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering">FlaxBigBirdForQuestionAnswering</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering">FlaxDistilBertForQuestionAnswering</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering">FlaxElectraForQuestionAnswering</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartConfig">MBartConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering">FlaxMBartForQuestionAnswering</a> (mBART model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering">FlaxRoFormerForQuestionAnswering</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering">FlaxRobertaForQuestionAnswering</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering">FlaxXLMRobertaForQuestionAnswering</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),m5=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_config.example",$$slots:{default:[fOt]},$$scope:{ctx:x}}}),m$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),E5=new B({props:{anchor:"transformers.FlaxAutoModelForQuestionAnswering.from_pretrained.example",$$slots:{default:[mOt]},$$scope:{ctx:x}}}),g$=new re({}),h$=new R({props:{name:"class transformers.FlaxAutoModelForTokenClassification",anchor:"transformers.FlaxAutoModelForTokenClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_flax_auto.py#L299"}}),_$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForTokenClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification">FlaxAlbertForTokenClassification</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertForTokenClassification">FlaxBertForTokenClassification</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification">FlaxBigBirdForTokenClassification</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification">FlaxDistilBertForTokenClassification</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.FlaxElectraForTokenClassification">FlaxElectraForTokenClassification</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification">FlaxRoFormerForTokenClassification</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification">FlaxRobertaForTokenClassification</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification">FlaxXLMRobertaForTokenClassification</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),w5=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_config.example",$$slots:{default:[gOt]},$$scope:{ctx:x}}}),u$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),P5=new B({props:{anchor:"transformers.FlaxAutoModelForTokenClassification.from_pretrained.example",$$slots:{default:[hOt]},$$scope:{ctx:x}}}),b$=new re({}),v$=new R({props:{name:"class transformers.FlaxAutoModelForMultipleChoice",anchor:"transformers.FlaxAutoModelForMultipleChoice",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_flax_auto.py#L308"}}),T$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig">AlbertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice">FlaxAlbertForMultipleChoice</a> (ALBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertForMultipleChoice">FlaxBertForMultipleChoice</a> (BERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig">BigBirdConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice">FlaxBigBirdForMultipleChoice</a> (BigBird model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig">DistilBertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice">FlaxDistilBertForMultipleChoice</a> (DistilBERT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig">ElectraConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice">FlaxElectraForMultipleChoice</a> (ELECTRA model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig">RoFormerConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice">FlaxRoFormerForMultipleChoice</a> (RoFormer model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig">RobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice">FlaxRobertaForMultipleChoice</a> (RoBERTa model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig">XLMRobertaConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice">FlaxXLMRobertaForMultipleChoice</a> (XLM-RoBERTa model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),I5=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_config.example",$$slots:{default:[pOt]},$$scope:{ctx:x}}}),M$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),z5=new B({props:{anchor:"transformers.FlaxAutoModelForMultipleChoice.from_pretrained.example",$$slots:{default:[_Ot]},$$scope:{ctx:x}}}),E$=new re({}),C$=new R({props:{name:"class transformers.FlaxAutoModelForNextSentencePrediction",anchor:"transformers.FlaxAutoModelForNextSentencePrediction",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_flax_auto.py#L315"}}),A$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig">BertConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction">FlaxBertForNextSentencePrediction</a> (BERT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),W5=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_config.example",$$slots:{default:[uOt]},$$scope:{ctx:x}}}),L$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),U5=new B({props:{anchor:"transformers.FlaxAutoModelForNextSentencePrediction.from_pretrained.example",$$slots:{default:[bOt]},$$scope:{ctx:x}}}),y$=new re({}),x$=new R({props:{name:"class transformers.FlaxAutoModelForImageClassification",anchor:"transformers.FlaxAutoModelForImageClassification",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_flax_auto.py#L324"}}),k$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForImageClassification.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/beit#transformers.BeitConfig">BeitConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/beit#transformers.FlaxBeitForImageClassification">FlaxBeitForImageClassification</a> (BEiT model)</li>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTConfig">ViTConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vit#transformers.FlaxViTForImageClassification">FlaxViTForImageClassification</a> (ViT model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),Y5=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_config.example",$$slots:{default:[vOt]},$$scope:{ctx:x}}}),S$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),e3=new B({props:{anchor:"transformers.FlaxAutoModelForImageClassification.from_pretrained.example",$$slots:{default:[FOt]},$$scope:{ctx:x}}}),P$=new re({}),B$=new R({props:{name:"class transformers.FlaxAutoModelForVision2Seq",anchor:"transformers.FlaxAutoModelForVision2Seq",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/modeling_flax_auto.py#L333"}}),N$=new R({props:{name:"from_config",anchor:"transformers.FlaxAutoModelForVision2Seq.from_config",parameters:[{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The model class to instantiate is selected based on the configuration class:</p>
<ul>
<li><a href="/docs/transformers/pr_17869/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig">VisionEncoderDecoderConfig</a> configuration class: <a href="/docs/transformers/pr_17869/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel">FlaxVisionEncoderDecoderModel</a> (Vision Encoder decoder model)</li>
</ul>`,name:"config"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L389"}}),r3=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_config.example",$$slots:{default:[TOt]},$$scope:{ctx:x}}}),q$=new R({props:{name:"from_pretrained",anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained",parameters:[{name:"*model_args",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
Can be either:</p>
<ul>
<li>A string, the <em>model id</em> of a pretrained model hosted inside a model repo on huggingface.co.
Valid model ids can be located at the root-level, like <code>bert-base-uncased</code>, or namespaced under a
user or organization name, like <code>dbmdz/bert-base-german-cased</code>.</li>
<li>A path to a <em>directory</em> containing model weights saved using
<a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>, e.g., <code>./my_model_directory/</code>.</li>
<li>A path or url to a <em>PyTorch state_dict save file</em> (e.g, <code>./pt_model/pytorch_model.bin</code>). In this
case, <code>from_pt</code> should be set to <code>True</code> and a configuration object should be provided as <code>config</code>
argument. This loading path is slower than converting the PyTorch model in a TensorFlow model
using the provided conversion scripts and loading the TensorFlow model afterwards.</li>
</ul>`,name:"pretrained_model_name_or_path"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.model_args",description:`<strong>model_args</strong> (additional positional arguments, <em>optional</em>) &#x2014;
Will be passed along to the underlying model <code>__init__()</code> method.`,name:"model_args"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.config",description:`<strong>config</strong> (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>, <em>optional</em>) &#x2014;
Configuration for the model to use instead of an automatically loaded configuration. Configuration can
be automatically loaded when:</p>
<ul>
<li>The model is a model provided by the library (loaded with the <em>model id</em> string of a pretrained
model).</li>
<li>The model was saved using <a href="/docs/transformers/pr_17869/en/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a> and is reloaded by supplying the
save directory.</li>
<li>The model is loaded by supplying a local directory as <code>pretrained_model_name_or_path</code> and a
configuration JSON file named <em>config.json</em> is found in the directory.</li>
</ul>`,name:"config"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.cache_dir",description:`<strong>cache_dir</strong> (<code>str</code> or <code>os.PathLike</code>, <em>optional</em>) &#x2014;
Path to a directory in which a downloaded pretrained model configuration should be cached if the
standard cache should not be used.`,name:"cache_dir"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.from_pt",description:`<strong>from_pt</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Load the model weights from a PyTorch checkpoint save file (see docstring of
<code>pretrained_model_name_or_path</code> argument).`,name:"from_pt"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.force_download",description:`<strong>force_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.`,name:"force_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.resume_download",description:`<strong>resume_download</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to delete incompletely received files. Will attempt to resume the download if such a
file exists.`,name:"resume_download"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.proxies",description:`<strong>proxies</strong> (<code>Dict[str, str]</code>, <em>optional</em>) &#x2014;
A dictionary of proxy servers to use by protocol or endpoint, e.g., <code>{&apos;http&apos;: &apos;foo.bar:3128&apos;, &apos;http://hostname&apos;: &apos;foo.bar:4012&apos;}</code>. The proxies are used on each request.`,name:"proxies"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.output_loading_info(bool,",description:`<strong>output_loading_info(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether ot not to also return a dictionary containing missing keys, unexpected keys and error messages.`,name:"output_loading_info(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.local_files_only(bool,",description:`<strong>local_files_only(<code>bool</code>,</strong> <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to only look at local files (e.g., not try downloading the model).`,name:"local_files_only(bool,"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.revision",description:`<strong>revision</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;main&quot;</code>) &#x2014;
The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a
git-based system for storing models and other artifacts on huggingface.co, so <code>revision</code> can be any
identifier allowed by git.`,name:"revision"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.trust_remote_code",description:`<strong>trust_remote_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to allow for custom models defined on the Hub in their own modeling files. This option
should only be set to <code>True</code> for repositories you trust and in which you have read the code, as it will
execute code present on the Hub on your local machine.`,name:"trust_remote_code"},{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Can be used to update the configuration object (after it being loaded) and initiate the model (e.g.,
<code>output_attentions=True</code>). Behaves differently depending on whether a <code>config</code> is provided or
automatically loaded:</p>
<ul>
<li>If a configuration is provided with <code>config</code>, <code>**kwargs</code> will be directly passed to the
underlying model&#x2019;s <code>__init__</code> method (we assume all relevant updates to the configuration have
already been done)</li>
<li>If a configuration is not provided, <code>kwargs</code> will be first passed to the configuration class
initialization function (<a href="/docs/transformers/pr_17869/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>). Each key of <code>kwargs</code> that
corresponds to a configuration attribute will be used to override said attribute with the
supplied <code>kwargs</code> value. Remaining keys that do not correspond to any configuration attribute
will be passed to the underlying model&#x2019;s <code>__init__</code> function.</li>
</ul>`,name:"kwargs"}],source:"https://github.com/huggingface/transformers/blob/vr_17869/src/transformers/models/auto/auto_factory.py#L417"}}),a3=new B({props:{anchor:"transformers.FlaxAutoModelForVision2Seq.from_pretrained.example",$$slots:{default:[MOt]},$$scope:{ctx:x}}}),{c(){g=a("meta"),v=l(),p=a("h1"),m=a("a"),_=a("span"),F(d.$$.fragment),h=l(),Eo=a("span"),Ti=o("Auto Classes"),yf=l(),at=a("p"),Mi=o(`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ei=a("code"),ww=o("from_pretrained()"),xf=o(` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),Oe=l(),Qe=a("p"),Ci=o("Instantiating one of "),Rn=a("a"),Aw=o("AutoConfig"),Pn=o(", "),Bn=a("a"),Lw=o("AutoModel"),wi=o(`, and
`),In=a("a"),yw=o("AutoTokenizer"),Ai=o(" will directly create a class of the relevant architecture. For instance"),$f=l(),F(xa.$$.fragment),We=l(),Ae=a("p"),rS=o("will create a model that is an instance of "),Li=a("a"),tS=o("BertModel"),aS=o("."),Co=l(),$a=a("p"),nS=o("There is one class of "),kf=a("code"),sS=o("AutoModel"),eQe=o(" for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),jGe=l(),yi=a("h2"),Sf=a("a"),mte=a("span"),F(xw.$$.fragment),oQe=l(),gte=a("span"),rQe=o("Extending the Auto Classes"),DGe=l(),Nn=a("p"),tQe=o(`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),hte=a("code"),aQe=o("NewModel"),nQe=o(", make sure you have a "),pte=a("code"),sQe=o("NewModelConfig"),lQe=o(` then you can add those to the auto
classes like this:`),GGe=l(),F($w.$$.fragment),OGe=l(),lS=a("p"),iQe=o("You will then be able to use the auto classes like you would usually do!"),VGe=l(),F(Rf.$$.fragment),XGe=l(),xi=a("h2"),Pf=a("a"),_te=a("span"),F(kw.$$.fragment),dQe=l(),ute=a("span"),cQe=o("AutoConfig"),zGe=l(),wo=a("div"),F(Sw.$$.fragment),fQe=l(),Rw=a("p"),mQe=o(`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),iS=a("a"),gQe=o("from_pretrained()"),hQe=o(" class method."),pQe=l(),Pw=a("p"),_Qe=o("This class cannot be instantiated directly using "),bte=a("code"),uQe=o("__init__()"),bQe=o(" (throws an error)."),vQe=l(),Ar=a("div"),F(Bw.$$.fragment),FQe=l(),vte=a("p"),TQe=o("Instantiate one of the configuration classes of the library from a pretrained model configuration."),MQe=l(),$i=a("p"),EQe=o("The configuration class to instantiate is selected based on the "),Fte=a("code"),CQe=o("model_type"),wQe=o(` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Tte=a("code"),AQe=o("pretrained_model_name_or_path"),LQe=o(":"),yQe=l(),A=a("ul"),Bf=a("li"),Mte=a("strong"),xQe=o("albert"),$Qe=o(" \u2014 "),dS=a("a"),kQe=o("AlbertConfig"),SQe=o(" (ALBERT model)"),RQe=l(),If=a("li"),Ete=a("strong"),PQe=o("bart"),BQe=o(" \u2014 "),cS=a("a"),IQe=o("BartConfig"),NQe=o(" (BART model)"),qQe=l(),Nf=a("li"),Cte=a("strong"),jQe=o("beit"),DQe=o(" \u2014 "),fS=a("a"),GQe=o("BeitConfig"),OQe=o(" (BEiT model)"),VQe=l(),qf=a("li"),wte=a("strong"),XQe=o("bert"),zQe=o(" \u2014 "),mS=a("a"),QQe=o("BertConfig"),WQe=o(" (BERT model)"),HQe=l(),jf=a("li"),Ate=a("strong"),UQe=o("bert-generation"),JQe=o(" \u2014 "),gS=a("a"),YQe=o("BertGenerationConfig"),KQe=o(" (Bert Generation model)"),ZQe=l(),Df=a("li"),Lte=a("strong"),eWe=o("big_bird"),oWe=o(" \u2014 "),hS=a("a"),rWe=o("BigBirdConfig"),tWe=o(" (BigBird model)"),aWe=l(),Gf=a("li"),yte=a("strong"),nWe=o("bigbird_pegasus"),sWe=o(" \u2014 "),pS=a("a"),lWe=o("BigBirdPegasusConfig"),iWe=o(" (BigBird-Pegasus model)"),dWe=l(),Of=a("li"),xte=a("strong"),cWe=o("blenderbot"),fWe=o(" \u2014 "),_S=a("a"),mWe=o("BlenderbotConfig"),gWe=o(" (Blenderbot model)"),hWe=l(),Vf=a("li"),$te=a("strong"),pWe=o("blenderbot-small"),_We=o(" \u2014 "),uS=a("a"),uWe=o("BlenderbotSmallConfig"),bWe=o(" (BlenderbotSmall model)"),vWe=l(),Xf=a("li"),kte=a("strong"),FWe=o("bloom"),TWe=o(" \u2014 "),bS=a("a"),MWe=o("BloomConfig"),EWe=o(" (BLOOM model)"),CWe=l(),zf=a("li"),Ste=a("strong"),wWe=o("camembert"),AWe=o(" \u2014 "),vS=a("a"),LWe=o("CamembertConfig"),yWe=o(" (CamemBERT model)"),xWe=l(),Qf=a("li"),Rte=a("strong"),$We=o("canine"),kWe=o(" \u2014 "),FS=a("a"),SWe=o("CanineConfig"),RWe=o(" (CANINE model)"),PWe=l(),Wf=a("li"),Pte=a("strong"),BWe=o("clip"),IWe=o(" \u2014 "),TS=a("a"),NWe=o("CLIPConfig"),qWe=o(" (CLIP model)"),jWe=l(),Hf=a("li"),Bte=a("strong"),DWe=o("convbert"),GWe=o(" \u2014 "),MS=a("a"),OWe=o("ConvBertConfig"),VWe=o(" (ConvBERT model)"),XWe=l(),Uf=a("li"),Ite=a("strong"),zWe=o("convnext"),QWe=o(" \u2014 "),ES=a("a"),WWe=o("ConvNextConfig"),HWe=o(" (ConvNeXT model)"),UWe=l(),Jf=a("li"),Nte=a("strong"),JWe=o("ctrl"),YWe=o(" \u2014 "),CS=a("a"),KWe=o("CTRLConfig"),ZWe=o(" (CTRL model)"),eHe=l(),Yf=a("li"),qte=a("strong"),oHe=o("cvt"),rHe=o(" \u2014 "),wS=a("a"),tHe=o("CvtConfig"),aHe=o(" (CvT model)"),nHe=l(),Kf=a("li"),jte=a("strong"),sHe=o("data2vec-audio"),lHe=o(" \u2014 "),AS=a("a"),iHe=o("Data2VecAudioConfig"),dHe=o(" (Data2VecAudio model)"),cHe=l(),Zf=a("li"),Dte=a("strong"),fHe=o("data2vec-text"),mHe=o(" \u2014 "),LS=a("a"),gHe=o("Data2VecTextConfig"),hHe=o(" (Data2VecText model)"),pHe=l(),em=a("li"),Gte=a("strong"),_He=o("data2vec-vision"),uHe=o(" \u2014 "),yS=a("a"),bHe=o("Data2VecVisionConfig"),vHe=o(" (Data2VecVision model)"),FHe=l(),om=a("li"),Ote=a("strong"),THe=o("deberta"),MHe=o(" \u2014 "),xS=a("a"),EHe=o("DebertaConfig"),CHe=o(" (DeBERTa model)"),wHe=l(),rm=a("li"),Vte=a("strong"),AHe=o("deberta-v2"),LHe=o(" \u2014 "),$S=a("a"),yHe=o("DebertaV2Config"),xHe=o(" (DeBERTa-v2 model)"),$He=l(),tm=a("li"),Xte=a("strong"),kHe=o("decision_transformer"),SHe=o(" \u2014 "),kS=a("a"),RHe=o("DecisionTransformerConfig"),PHe=o(" (Decision Transformer model)"),BHe=l(),am=a("li"),zte=a("strong"),IHe=o("deit"),NHe=o(" \u2014 "),SS=a("a"),qHe=o("DeiTConfig"),jHe=o(" (DeiT model)"),DHe=l(),nm=a("li"),Qte=a("strong"),GHe=o("detr"),OHe=o(" \u2014 "),RS=a("a"),VHe=o("DetrConfig"),XHe=o(" (DETR model)"),zHe=l(),sm=a("li"),Wte=a("strong"),QHe=o("distilbert"),WHe=o(" \u2014 "),PS=a("a"),HHe=o("DistilBertConfig"),UHe=o(" (DistilBERT model)"),JHe=l(),lm=a("li"),Hte=a("strong"),YHe=o("dpr"),KHe=o(" \u2014 "),BS=a("a"),ZHe=o("DPRConfig"),eUe=o(" (DPR model)"),oUe=l(),im=a("li"),Ute=a("strong"),rUe=o("dpt"),tUe=o(" \u2014 "),IS=a("a"),aUe=o("DPTConfig"),nUe=o(" (DPT model)"),sUe=l(),dm=a("li"),Jte=a("strong"),lUe=o("electra"),iUe=o(" \u2014 "),NS=a("a"),dUe=o("ElectraConfig"),cUe=o(" (ELECTRA model)"),fUe=l(),cm=a("li"),Yte=a("strong"),mUe=o("encoder-decoder"),gUe=o(" \u2014 "),qS=a("a"),hUe=o("EncoderDecoderConfig"),pUe=o(" (Encoder decoder model)"),_Ue=l(),fm=a("li"),Kte=a("strong"),uUe=o("flaubert"),bUe=o(" \u2014 "),jS=a("a"),vUe=o("FlaubertConfig"),FUe=o(" (FlauBERT model)"),TUe=l(),mm=a("li"),Zte=a("strong"),MUe=o("flava"),EUe=o(" \u2014 "),DS=a("a"),CUe=o("FlavaConfig"),wUe=o(" (FLAVA model)"),AUe=l(),gm=a("li"),eae=a("strong"),LUe=o("fnet"),yUe=o(" \u2014 "),GS=a("a"),xUe=o("FNetConfig"),$Ue=o(" (FNet model)"),kUe=l(),hm=a("li"),oae=a("strong"),SUe=o("fsmt"),RUe=o(" \u2014 "),OS=a("a"),PUe=o("FSMTConfig"),BUe=o(" (FairSeq Machine-Translation model)"),IUe=l(),pm=a("li"),rae=a("strong"),NUe=o("funnel"),qUe=o(" \u2014 "),VS=a("a"),jUe=o("FunnelConfig"),DUe=o(" (Funnel Transformer model)"),GUe=l(),_m=a("li"),tae=a("strong"),OUe=o("glpn"),VUe=o(" \u2014 "),XS=a("a"),XUe=o("GLPNConfig"),zUe=o(" (GLPN model)"),QUe=l(),um=a("li"),aae=a("strong"),WUe=o("gpt2"),HUe=o(" \u2014 "),zS=a("a"),UUe=o("GPT2Config"),JUe=o(" (OpenAI GPT-2 model)"),YUe=l(),bm=a("li"),nae=a("strong"),KUe=o("gpt_neo"),ZUe=o(" \u2014 "),QS=a("a"),eJe=o("GPTNeoConfig"),oJe=o(" (GPT Neo model)"),rJe=l(),vm=a("li"),sae=a("strong"),tJe=o("gpt_neox"),aJe=o(" \u2014 "),WS=a("a"),nJe=o("GPTNeoXConfig"),sJe=o(" (GPT NeoX model)"),lJe=l(),Fm=a("li"),lae=a("strong"),iJe=o("gptj"),dJe=o(" \u2014 "),HS=a("a"),cJe=o("GPTJConfig"),fJe=o(" (GPT-J model)"),mJe=l(),Tm=a("li"),iae=a("strong"),gJe=o("hubert"),hJe=o(" \u2014 "),US=a("a"),pJe=o("HubertConfig"),_Je=o(" (Hubert model)"),uJe=l(),Mm=a("li"),dae=a("strong"),bJe=o("ibert"),vJe=o(" \u2014 "),JS=a("a"),FJe=o("IBertConfig"),TJe=o(" (I-BERT model)"),MJe=l(),Em=a("li"),cae=a("strong"),EJe=o("imagegpt"),CJe=o(" \u2014 "),YS=a("a"),wJe=o("ImageGPTConfig"),AJe=o(" (ImageGPT model)"),LJe=l(),Cm=a("li"),fae=a("strong"),yJe=o("layoutlm"),xJe=o(" \u2014 "),KS=a("a"),$Je=o("LayoutLMConfig"),kJe=o(" (LayoutLM model)"),SJe=l(),wm=a("li"),mae=a("strong"),RJe=o("layoutlmv2"),PJe=o(" \u2014 "),ZS=a("a"),BJe=o("LayoutLMv2Config"),IJe=o(" (LayoutLMv2 model)"),NJe=l(),Am=a("li"),gae=a("strong"),qJe=o("layoutlmv3"),jJe=o(" \u2014 "),eR=a("a"),DJe=o("LayoutLMv3Config"),GJe=o(" (LayoutLMv3 model)"),OJe=l(),Lm=a("li"),hae=a("strong"),VJe=o("led"),XJe=o(" \u2014 "),oR=a("a"),zJe=o("LEDConfig"),QJe=o(" (LED model)"),WJe=l(),ym=a("li"),pae=a("strong"),HJe=o("levit"),UJe=o(" \u2014 "),rR=a("a"),JJe=o("LevitConfig"),YJe=o(" (LeViT model)"),KJe=l(),xm=a("li"),_ae=a("strong"),ZJe=o("longformer"),eYe=o(" \u2014 "),tR=a("a"),oYe=o("LongformerConfig"),rYe=o(" (Longformer model)"),tYe=l(),$m=a("li"),uae=a("strong"),aYe=o("longt5"),nYe=o(" \u2014 "),aR=a("a"),sYe=o("LongT5Config"),lYe=o(" (LongT5 model)"),iYe=l(),km=a("li"),bae=a("strong"),dYe=o("luke"),cYe=o(" \u2014 "),nR=a("a"),fYe=o("LukeConfig"),mYe=o(" (LUKE model)"),gYe=l(),Sm=a("li"),vae=a("strong"),hYe=o("lxmert"),pYe=o(" \u2014 "),sR=a("a"),_Ye=o("LxmertConfig"),uYe=o(" (LXMERT model)"),bYe=l(),Rm=a("li"),Fae=a("strong"),vYe=o("m2m_100"),FYe=o(" \u2014 "),lR=a("a"),TYe=o("M2M100Config"),MYe=o(" (M2M100 model)"),EYe=l(),Pm=a("li"),Tae=a("strong"),CYe=o("marian"),wYe=o(" \u2014 "),iR=a("a"),AYe=o("MarianConfig"),LYe=o(" (Marian model)"),yYe=l(),Bm=a("li"),Mae=a("strong"),xYe=o("maskformer"),$Ye=o(" \u2014 "),dR=a("a"),kYe=o("MaskFormerConfig"),SYe=o(" (MaskFormer model)"),RYe=l(),Im=a("li"),Eae=a("strong"),PYe=o("mbart"),BYe=o(" \u2014 "),cR=a("a"),IYe=o("MBartConfig"),NYe=o(" (mBART model)"),qYe=l(),Nm=a("li"),Cae=a("strong"),jYe=o("mctct"),DYe=o(" \u2014 "),fR=a("a"),GYe=o("MCTCTConfig"),OYe=o(" (M-CTC-T model)"),VYe=l(),qm=a("li"),wae=a("strong"),XYe=o("megatron-bert"),zYe=o(" \u2014 "),mR=a("a"),QYe=o("MegatronBertConfig"),WYe=o(" (Megatron-BERT model)"),HYe=l(),jm=a("li"),Aae=a("strong"),UYe=o("mobilebert"),JYe=o(" \u2014 "),gR=a("a"),YYe=o("MobileBertConfig"),KYe=o(" (MobileBERT model)"),ZYe=l(),Dm=a("li"),Lae=a("strong"),eKe=o("mpnet"),oKe=o(" \u2014 "),hR=a("a"),rKe=o("MPNetConfig"),tKe=o(" (MPNet model)"),aKe=l(),Gm=a("li"),yae=a("strong"),nKe=o("mt5"),sKe=o(" \u2014 "),pR=a("a"),lKe=o("MT5Config"),iKe=o(" (MT5 model)"),dKe=l(),Om=a("li"),xae=a("strong"),cKe=o("nezha"),fKe=o(" \u2014 "),_R=a("a"),mKe=o("NezhaConfig"),gKe=o(" (Nezha model)"),hKe=l(),Vm=a("li"),$ae=a("strong"),pKe=o("nystromformer"),_Ke=o(" \u2014 "),uR=a("a"),uKe=o("NystromformerConfig"),bKe=o(" (Nystr\xF6mformer model)"),vKe=l(),Xm=a("li"),kae=a("strong"),FKe=o("openai-gpt"),TKe=o(" \u2014 "),bR=a("a"),MKe=o("OpenAIGPTConfig"),EKe=o(" (OpenAI GPT model)"),CKe=l(),zm=a("li"),Sae=a("strong"),wKe=o("opt"),AKe=o(" \u2014 "),vR=a("a"),LKe=o("OPTConfig"),yKe=o(" (OPT model)"),xKe=l(),Qm=a("li"),Rae=a("strong"),$Ke=o("pegasus"),kKe=o(" \u2014 "),FR=a("a"),SKe=o("PegasusConfig"),RKe=o(" (Pegasus model)"),PKe=l(),Wm=a("li"),Pae=a("strong"),BKe=o("perceiver"),IKe=o(" \u2014 "),TR=a("a"),NKe=o("PerceiverConfig"),qKe=o(" (Perceiver model)"),jKe=l(),Hm=a("li"),Bae=a("strong"),DKe=o("plbart"),GKe=o(" \u2014 "),MR=a("a"),OKe=o("PLBartConfig"),VKe=o(" (PLBart model)"),XKe=l(),Um=a("li"),Iae=a("strong"),zKe=o("poolformer"),QKe=o(" \u2014 "),ER=a("a"),WKe=o("PoolFormerConfig"),HKe=o(" (PoolFormer model)"),UKe=l(),Jm=a("li"),Nae=a("strong"),JKe=o("prophetnet"),YKe=o(" \u2014 "),CR=a("a"),KKe=o("ProphetNetConfig"),ZKe=o(" (ProphetNet model)"),eZe=l(),Ym=a("li"),qae=a("strong"),oZe=o("qdqbert"),rZe=o(" \u2014 "),wR=a("a"),tZe=o("QDQBertConfig"),aZe=o(" (QDQBert model)"),nZe=l(),Km=a("li"),jae=a("strong"),sZe=o("rag"),lZe=o(" \u2014 "),AR=a("a"),iZe=o("RagConfig"),dZe=o(" (RAG model)"),cZe=l(),Zm=a("li"),Dae=a("strong"),fZe=o("realm"),mZe=o(" \u2014 "),LR=a("a"),gZe=o("RealmConfig"),hZe=o(" (REALM model)"),pZe=l(),eg=a("li"),Gae=a("strong"),_Ze=o("reformer"),uZe=o(" \u2014 "),yR=a("a"),bZe=o("ReformerConfig"),vZe=o(" (Reformer model)"),FZe=l(),og=a("li"),Oae=a("strong"),TZe=o("regnet"),MZe=o(" \u2014 "),xR=a("a"),EZe=o("RegNetConfig"),CZe=o(" (RegNet model)"),wZe=l(),rg=a("li"),Vae=a("strong"),AZe=o("rembert"),LZe=o(" \u2014 "),$R=a("a"),yZe=o("RemBertConfig"),xZe=o(" (RemBERT model)"),$Ze=l(),tg=a("li"),Xae=a("strong"),kZe=o("resnet"),SZe=o(" \u2014 "),kR=a("a"),RZe=o("ResNetConfig"),PZe=o(" (ResNet model)"),BZe=l(),ag=a("li"),zae=a("strong"),IZe=o("retribert"),NZe=o(" \u2014 "),SR=a("a"),qZe=o("RetriBertConfig"),jZe=o(" (RetriBERT model)"),DZe=l(),ng=a("li"),Qae=a("strong"),GZe=o("roberta"),OZe=o(" \u2014 "),RR=a("a"),VZe=o("RobertaConfig"),XZe=o(" (RoBERTa model)"),zZe=l(),sg=a("li"),Wae=a("strong"),QZe=o("roformer"),WZe=o(" \u2014 "),PR=a("a"),HZe=o("RoFormerConfig"),UZe=o(" (RoFormer model)"),JZe=l(),lg=a("li"),Hae=a("strong"),YZe=o("segformer"),KZe=o(" \u2014 "),BR=a("a"),ZZe=o("SegformerConfig"),eeo=o(" (SegFormer model)"),oeo=l(),ig=a("li"),Uae=a("strong"),reo=o("sew"),teo=o(" \u2014 "),IR=a("a"),aeo=o("SEWConfig"),neo=o(" (SEW model)"),seo=l(),dg=a("li"),Jae=a("strong"),leo=o("sew-d"),ieo=o(" \u2014 "),NR=a("a"),deo=o("SEWDConfig"),ceo=o(" (SEW-D model)"),feo=l(),cg=a("li"),Yae=a("strong"),meo=o("speech-encoder-decoder"),geo=o(" \u2014 "),qR=a("a"),heo=o("SpeechEncoderDecoderConfig"),peo=o(" (Speech Encoder decoder model)"),_eo=l(),fg=a("li"),Kae=a("strong"),ueo=o("speech_to_text"),beo=o(" \u2014 "),jR=a("a"),veo=o("Speech2TextConfig"),Feo=o(" (Speech2Text model)"),Teo=l(),mg=a("li"),Zae=a("strong"),Meo=o("speech_to_text_2"),Eeo=o(" \u2014 "),DR=a("a"),Ceo=o("Speech2Text2Config"),weo=o(" (Speech2Text2 model)"),Aeo=l(),gg=a("li"),ene=a("strong"),Leo=o("splinter"),yeo=o(" \u2014 "),GR=a("a"),xeo=o("SplinterConfig"),$eo=o(" (Splinter model)"),keo=l(),hg=a("li"),one=a("strong"),Seo=o("squeezebert"),Reo=o(" \u2014 "),OR=a("a"),Peo=o("SqueezeBertConfig"),Beo=o(" (SqueezeBERT model)"),Ieo=l(),pg=a("li"),rne=a("strong"),Neo=o("swin"),qeo=o(" \u2014 "),VR=a("a"),jeo=o("SwinConfig"),Deo=o(" (Swin Transformer model)"),Geo=l(),_g=a("li"),tne=a("strong"),Oeo=o("t5"),Veo=o(" \u2014 "),XR=a("a"),Xeo=o("T5Config"),zeo=o(" (T5 model)"),Qeo=l(),ug=a("li"),ane=a("strong"),Weo=o("tapas"),Heo=o(" \u2014 "),zR=a("a"),Ueo=o("TapasConfig"),Jeo=o(" (TAPAS model)"),Yeo=l(),bg=a("li"),nne=a("strong"),Keo=o("trajectory_transformer"),Zeo=o(" \u2014 "),QR=a("a"),eoo=o("TrajectoryTransformerConfig"),ooo=o(" (Trajectory Transformer model)"),roo=l(),vg=a("li"),sne=a("strong"),too=o("transfo-xl"),aoo=o(" \u2014 "),WR=a("a"),noo=o("TransfoXLConfig"),soo=o(" (Transformer-XL model)"),loo=l(),Fg=a("li"),lne=a("strong"),ioo=o("trocr"),doo=o(" \u2014 "),HR=a("a"),coo=o("TrOCRConfig"),foo=o(" (TrOCR model)"),moo=l(),Tg=a("li"),ine=a("strong"),goo=o("unispeech"),hoo=o(" \u2014 "),UR=a("a"),poo=o("UniSpeechConfig"),_oo=o(" (UniSpeech model)"),uoo=l(),Mg=a("li"),dne=a("strong"),boo=o("unispeech-sat"),voo=o(" \u2014 "),JR=a("a"),Foo=o("UniSpeechSatConfig"),Too=o(" (UniSpeechSat model)"),Moo=l(),Eg=a("li"),cne=a("strong"),Eoo=o("van"),Coo=o(" \u2014 "),YR=a("a"),woo=o("VanConfig"),Aoo=o(" (VAN model)"),Loo=l(),Cg=a("li"),fne=a("strong"),yoo=o("vilt"),xoo=o(" \u2014 "),KR=a("a"),$oo=o("ViltConfig"),koo=o(" (ViLT model)"),Soo=l(),wg=a("li"),mne=a("strong"),Roo=o("vision-encoder-decoder"),Poo=o(" \u2014 "),ZR=a("a"),Boo=o("VisionEncoderDecoderConfig"),Ioo=o(" (Vision Encoder decoder model)"),Noo=l(),Ag=a("li"),gne=a("strong"),qoo=o("vision-text-dual-encoder"),joo=o(" \u2014 "),eP=a("a"),Doo=o("VisionTextDualEncoderConfig"),Goo=o(" (VisionTextDualEncoder model)"),Ooo=l(),Lg=a("li"),hne=a("strong"),Voo=o("visual_bert"),Xoo=o(" \u2014 "),oP=a("a"),zoo=o("VisualBertConfig"),Qoo=o(" (VisualBERT model)"),Woo=l(),yg=a("li"),pne=a("strong"),Hoo=o("vit"),Uoo=o(" \u2014 "),rP=a("a"),Joo=o("ViTConfig"),Yoo=o(" (ViT model)"),Koo=l(),xg=a("li"),_ne=a("strong"),Zoo=o("vit_mae"),ero=o(" \u2014 "),tP=a("a"),oro=o("ViTMAEConfig"),rro=o(" (ViTMAE model)"),tro=l(),$g=a("li"),une=a("strong"),aro=o("wav2vec2"),nro=o(" \u2014 "),aP=a("a"),sro=o("Wav2Vec2Config"),lro=o(" (Wav2Vec2 model)"),iro=l(),kg=a("li"),bne=a("strong"),dro=o("wav2vec2-conformer"),cro=o(" \u2014 "),nP=a("a"),fro=o("Wav2Vec2ConformerConfig"),mro=o(" (Wav2Vec2-Conformer model)"),gro=l(),Sg=a("li"),vne=a("strong"),hro=o("wavlm"),pro=o(" \u2014 "),sP=a("a"),_ro=o("WavLMConfig"),uro=o(" (WavLM model)"),bro=l(),Rg=a("li"),Fne=a("strong"),vro=o("xglm"),Fro=o(" \u2014 "),lP=a("a"),Tro=o("XGLMConfig"),Mro=o(" (XGLM model)"),Ero=l(),Pg=a("li"),Tne=a("strong"),Cro=o("xlm"),wro=o(" \u2014 "),iP=a("a"),Aro=o("XLMConfig"),Lro=o(" (XLM model)"),yro=l(),Bg=a("li"),Mne=a("strong"),xro=o("xlm-prophetnet"),$ro=o(" \u2014 "),dP=a("a"),kro=o("XLMProphetNetConfig"),Sro=o(" (XLM-ProphetNet model)"),Rro=l(),Ig=a("li"),Ene=a("strong"),Pro=o("xlm-roberta"),Bro=o(" \u2014 "),cP=a("a"),Iro=o("XLMRobertaConfig"),Nro=o(" (XLM-RoBERTa model)"),qro=l(),Ng=a("li"),Cne=a("strong"),jro=o("xlm-roberta-xl"),Dro=o(" \u2014 "),fP=a("a"),Gro=o("XLMRobertaXLConfig"),Oro=o(" (XLM-RoBERTa-XL model)"),Vro=l(),qg=a("li"),wne=a("strong"),Xro=o("xlnet"),zro=o(" \u2014 "),mP=a("a"),Qro=o("XLNetConfig"),Wro=o(" (XLNet model)"),Hro=l(),jg=a("li"),Ane=a("strong"),Uro=o("yolos"),Jro=o(" \u2014 "),gP=a("a"),Yro=o("YolosConfig"),Kro=o(" (YOLOS model)"),Zro=l(),Dg=a("li"),Lne=a("strong"),eto=o("yoso"),oto=o(" \u2014 "),hP=a("a"),rto=o("YosoConfig"),tto=o(" (YOSO model)"),ato=l(),F(Gg.$$.fragment),nto=l(),Og=a("div"),F(Iw.$$.fragment),sto=l(),yne=a("p"),lto=o("Register a new configuration for this class."),QGe=l(),ki=a("h2"),Vg=a("a"),xne=a("span"),F(Nw.$$.fragment),ito=l(),$ne=a("span"),dto=o("AutoTokenizer"),WGe=l(),Ao=a("div"),F(qw.$$.fragment),cto=l(),jw=a("p"),fto=o(`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),pP=a("a"),mto=o("AutoTokenizer.from_pretrained()"),gto=o(" class method."),hto=l(),Dw=a("p"),pto=o("This class cannot be instantiated directly using "),kne=a("code"),_to=o("__init__()"),uto=o(" (throws an error)."),bto=l(),Lr=a("div"),F(Gw.$$.fragment),vto=l(),Sne=a("p"),Fto=o("Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Tto=l(),ka=a("p"),Mto=o("The tokenizer class to instantiate is selected based on the "),Rne=a("code"),Eto=o("model_type"),Cto=o(` property of the config object (either
passed as an argument or loaded from `),Pne=a("code"),wto=o("pretrained_model_name_or_path"),Ato=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bne=a("code"),Lto=o("pretrained_model_name_or_path"),yto=o(":"),xto=l(),k=a("ul"),qn=a("li"),Ine=a("strong"),$to=o("albert"),kto=o(" \u2014 "),_P=a("a"),Sto=o("AlbertTokenizer"),Rto=o(" or "),uP=a("a"),Pto=o("AlbertTokenizerFast"),Bto=o(" (ALBERT model)"),Ito=l(),jn=a("li"),Nne=a("strong"),Nto=o("bart"),qto=o(" \u2014 "),bP=a("a"),jto=o("BartTokenizer"),Dto=o(" or "),vP=a("a"),Gto=o("BartTokenizerFast"),Oto=o(" (BART model)"),Vto=l(),Dn=a("li"),qne=a("strong"),Xto=o("barthez"),zto=o(" \u2014 "),FP=a("a"),Qto=o("BarthezTokenizer"),Wto=o(" or "),TP=a("a"),Hto=o("BarthezTokenizerFast"),Uto=o(" (BARThez model)"),Jto=l(),Xg=a("li"),jne=a("strong"),Yto=o("bartpho"),Kto=o(" \u2014 "),MP=a("a"),Zto=o("BartphoTokenizer"),eao=o(" (BARTpho model)"),oao=l(),Gn=a("li"),Dne=a("strong"),rao=o("bert"),tao=o(" \u2014 "),EP=a("a"),aao=o("BertTokenizer"),nao=o(" or "),CP=a("a"),sao=o("BertTokenizerFast"),lao=o(" (BERT model)"),iao=l(),zg=a("li"),Gne=a("strong"),dao=o("bert-generation"),cao=o(" \u2014 "),wP=a("a"),fao=o("BertGenerationTokenizer"),mao=o(" (Bert Generation model)"),gao=l(),Qg=a("li"),One=a("strong"),hao=o("bert-japanese"),pao=o(" \u2014 "),AP=a("a"),_ao=o("BertJapaneseTokenizer"),uao=o(" (BertJapanese model)"),bao=l(),Wg=a("li"),Vne=a("strong"),vao=o("bertweet"),Fao=o(" \u2014 "),LP=a("a"),Tao=o("BertweetTokenizer"),Mao=o(" (BERTweet model)"),Eao=l(),On=a("li"),Xne=a("strong"),Cao=o("big_bird"),wao=o(" \u2014 "),yP=a("a"),Aao=o("BigBirdTokenizer"),Lao=o(" or "),xP=a("a"),yao=o("BigBirdTokenizerFast"),xao=o(" (BigBird model)"),$ao=l(),Vn=a("li"),zne=a("strong"),kao=o("bigbird_pegasus"),Sao=o(" \u2014 "),$P=a("a"),Rao=o("PegasusTokenizer"),Pao=o(" or "),kP=a("a"),Bao=o("PegasusTokenizerFast"),Iao=o(" (BigBird-Pegasus model)"),Nao=l(),Xn=a("li"),Qne=a("strong"),qao=o("blenderbot"),jao=o(" \u2014 "),SP=a("a"),Dao=o("BlenderbotTokenizer"),Gao=o(" or "),RP=a("a"),Oao=o("BlenderbotTokenizerFast"),Vao=o(" (Blenderbot model)"),Xao=l(),Hg=a("li"),Wne=a("strong"),zao=o("blenderbot-small"),Qao=o(" \u2014 "),PP=a("a"),Wao=o("BlenderbotSmallTokenizer"),Hao=o(" (BlenderbotSmall model)"),Uao=l(),Ug=a("li"),Hne=a("strong"),Jao=o("bloom"),Yao=o(" \u2014 "),BP=a("a"),Kao=o("BloomTokenizerFast"),Zao=o(" (BLOOM model)"),eno=l(),Jg=a("li"),Une=a("strong"),ono=o("byt5"),rno=o(" \u2014 "),IP=a("a"),tno=o("ByT5Tokenizer"),ano=o(" (ByT5 model)"),nno=l(),zn=a("li"),Jne=a("strong"),sno=o("camembert"),lno=o(" \u2014 "),NP=a("a"),ino=o("CamembertTokenizer"),dno=o(" or "),qP=a("a"),cno=o("CamembertTokenizerFast"),fno=o(" (CamemBERT model)"),mno=l(),Yg=a("li"),Yne=a("strong"),gno=o("canine"),hno=o(" \u2014 "),jP=a("a"),pno=o("CanineTokenizer"),_no=o(" (CANINE model)"),uno=l(),Qn=a("li"),Kne=a("strong"),bno=o("clip"),vno=o(" \u2014 "),DP=a("a"),Fno=o("CLIPTokenizer"),Tno=o(" or "),GP=a("a"),Mno=o("CLIPTokenizerFast"),Eno=o(" (CLIP model)"),Cno=l(),Wn=a("li"),Zne=a("strong"),wno=o("convbert"),Ano=o(" \u2014 "),OP=a("a"),Lno=o("ConvBertTokenizer"),yno=o(" or "),VP=a("a"),xno=o("ConvBertTokenizerFast"),$no=o(" (ConvBERT model)"),kno=l(),Hn=a("li"),ese=a("strong"),Sno=o("cpm"),Rno=o(" \u2014 "),XP=a("a"),Pno=o("CpmTokenizer"),Bno=o(" or "),zP=a("a"),Ino=o("CpmTokenizerFast"),Nno=o(" (CPM model)"),qno=l(),Kg=a("li"),ose=a("strong"),jno=o("ctrl"),Dno=o(" \u2014 "),QP=a("a"),Gno=o("CTRLTokenizer"),Ono=o(" (CTRL model)"),Vno=l(),Un=a("li"),rse=a("strong"),Xno=o("data2vec-text"),zno=o(" \u2014 "),WP=a("a"),Qno=o("RobertaTokenizer"),Wno=o(" or "),HP=a("a"),Hno=o("RobertaTokenizerFast"),Uno=o(" (Data2VecText model)"),Jno=l(),Jn=a("li"),tse=a("strong"),Yno=o("deberta"),Kno=o(" \u2014 "),UP=a("a"),Zno=o("DebertaTokenizer"),eso=o(" or "),JP=a("a"),oso=o("DebertaTokenizerFast"),rso=o(" (DeBERTa model)"),tso=l(),Yn=a("li"),ase=a("strong"),aso=o("deberta-v2"),nso=o(" \u2014 "),YP=a("a"),sso=o("DebertaV2Tokenizer"),lso=o(" or "),KP=a("a"),iso=o("DebertaV2TokenizerFast"),dso=o(" (DeBERTa-v2 model)"),cso=l(),Kn=a("li"),nse=a("strong"),fso=o("distilbert"),mso=o(" \u2014 "),ZP=a("a"),gso=o("DistilBertTokenizer"),hso=o(" or "),eB=a("a"),pso=o("DistilBertTokenizerFast"),_so=o(" (DistilBERT model)"),uso=l(),Zn=a("li"),sse=a("strong"),bso=o("dpr"),vso=o(" \u2014 "),oB=a("a"),Fso=o("DPRQuestionEncoderTokenizer"),Tso=o(" or "),rB=a("a"),Mso=o("DPRQuestionEncoderTokenizerFast"),Eso=o(" (DPR model)"),Cso=l(),es=a("li"),lse=a("strong"),wso=o("electra"),Aso=o(" \u2014 "),tB=a("a"),Lso=o("ElectraTokenizer"),yso=o(" or "),aB=a("a"),xso=o("ElectraTokenizerFast"),$so=o(" (ELECTRA model)"),kso=l(),Zg=a("li"),ise=a("strong"),Sso=o("flaubert"),Rso=o(" \u2014 "),nB=a("a"),Pso=o("FlaubertTokenizer"),Bso=o(" (FlauBERT model)"),Iso=l(),os=a("li"),dse=a("strong"),Nso=o("fnet"),qso=o(" \u2014 "),sB=a("a"),jso=o("FNetTokenizer"),Dso=o(" or "),lB=a("a"),Gso=o("FNetTokenizerFast"),Oso=o(" (FNet model)"),Vso=l(),eh=a("li"),cse=a("strong"),Xso=o("fsmt"),zso=o(" \u2014 "),iB=a("a"),Qso=o("FSMTTokenizer"),Wso=o(" (FairSeq Machine-Translation model)"),Hso=l(),rs=a("li"),fse=a("strong"),Uso=o("funnel"),Jso=o(" \u2014 "),dB=a("a"),Yso=o("FunnelTokenizer"),Kso=o(" or "),cB=a("a"),Zso=o("FunnelTokenizerFast"),elo=o(" (Funnel Transformer model)"),olo=l(),ts=a("li"),mse=a("strong"),rlo=o("gpt2"),tlo=o(" \u2014 "),fB=a("a"),alo=o("GPT2Tokenizer"),nlo=o(" or "),mB=a("a"),slo=o("GPT2TokenizerFast"),llo=o(" (OpenAI GPT-2 model)"),ilo=l(),as=a("li"),gse=a("strong"),dlo=o("gpt_neo"),clo=o(" \u2014 "),gB=a("a"),flo=o("GPT2Tokenizer"),mlo=o(" or "),hB=a("a"),glo=o("GPT2TokenizerFast"),hlo=o(" (GPT Neo model)"),plo=l(),oh=a("li"),hse=a("strong"),_lo=o("gpt_neox"),ulo=o(" \u2014 "),pB=a("a"),blo=o("GPTNeoXTokenizerFast"),vlo=o(" (GPT NeoX model)"),Flo=l(),ns=a("li"),pse=a("strong"),Tlo=o("gptj"),Mlo=o(" \u2014 "),_B=a("a"),Elo=o("GPT2Tokenizer"),Clo=o(" or "),uB=a("a"),wlo=o("GPT2TokenizerFast"),Alo=o(" (GPT-J model)"),Llo=l(),ss=a("li"),_se=a("strong"),ylo=o("herbert"),xlo=o(" \u2014 "),bB=a("a"),$lo=o("HerbertTokenizer"),klo=o(" or "),vB=a("a"),Slo=o("HerbertTokenizerFast"),Rlo=o(" (HerBERT model)"),Plo=l(),rh=a("li"),use=a("strong"),Blo=o("hubert"),Ilo=o(" \u2014 "),FB=a("a"),Nlo=o("Wav2Vec2CTCTokenizer"),qlo=o(" (Hubert model)"),jlo=l(),ls=a("li"),bse=a("strong"),Dlo=o("ibert"),Glo=o(" \u2014 "),TB=a("a"),Olo=o("RobertaTokenizer"),Vlo=o(" or "),MB=a("a"),Xlo=o("RobertaTokenizerFast"),zlo=o(" (I-BERT model)"),Qlo=l(),is=a("li"),vse=a("strong"),Wlo=o("layoutlm"),Hlo=o(" \u2014 "),EB=a("a"),Ulo=o("LayoutLMTokenizer"),Jlo=o(" or "),CB=a("a"),Ylo=o("LayoutLMTokenizerFast"),Klo=o(" (LayoutLM model)"),Zlo=l(),ds=a("li"),Fse=a("strong"),eio=o("layoutlmv2"),oio=o(" \u2014 "),wB=a("a"),rio=o("LayoutLMv2Tokenizer"),tio=o(" or "),AB=a("a"),aio=o("LayoutLMv2TokenizerFast"),nio=o(" (LayoutLMv2 model)"),sio=l(),cs=a("li"),Tse=a("strong"),lio=o("layoutlmv3"),iio=o(" \u2014 "),LB=a("a"),dio=o("LayoutLMv3Tokenizer"),cio=o(" or "),yB=a("a"),fio=o("LayoutLMv3TokenizerFast"),mio=o(" (LayoutLMv3 model)"),gio=l(),fs=a("li"),Mse=a("strong"),hio=o("layoutxlm"),pio=o(" \u2014 "),xB=a("a"),_io=o("LayoutXLMTokenizer"),uio=o(" or "),$B=a("a"),bio=o("LayoutXLMTokenizerFast"),vio=o(" (LayoutXLM model)"),Fio=l(),ms=a("li"),Ese=a("strong"),Tio=o("led"),Mio=o(" \u2014 "),kB=a("a"),Eio=o("LEDTokenizer"),Cio=o(" or "),SB=a("a"),wio=o("LEDTokenizerFast"),Aio=o(" (LED model)"),Lio=l(),gs=a("li"),Cse=a("strong"),yio=o("longformer"),xio=o(" \u2014 "),RB=a("a"),$io=o("LongformerTokenizer"),kio=o(" or "),PB=a("a"),Sio=o("LongformerTokenizerFast"),Rio=o(" (Longformer model)"),Pio=l(),hs=a("li"),wse=a("strong"),Bio=o("longt5"),Iio=o(" \u2014 "),BB=a("a"),Nio=o("T5Tokenizer"),qio=o(" or "),IB=a("a"),jio=o("T5TokenizerFast"),Dio=o(" (LongT5 model)"),Gio=l(),th=a("li"),Ase=a("strong"),Oio=o("luke"),Vio=o(" \u2014 "),NB=a("a"),Xio=o("LukeTokenizer"),zio=o(" (LUKE model)"),Qio=l(),ps=a("li"),Lse=a("strong"),Wio=o("lxmert"),Hio=o(" \u2014 "),qB=a("a"),Uio=o("LxmertTokenizer"),Jio=o(" or "),jB=a("a"),Yio=o("LxmertTokenizerFast"),Kio=o(" (LXMERT model)"),Zio=l(),ah=a("li"),yse=a("strong"),edo=o("m2m_100"),odo=o(" \u2014 "),DB=a("a"),rdo=o("M2M100Tokenizer"),tdo=o(" (M2M100 model)"),ado=l(),nh=a("li"),xse=a("strong"),ndo=o("marian"),sdo=o(" \u2014 "),GB=a("a"),ldo=o("MarianTokenizer"),ido=o(" (Marian model)"),ddo=l(),_s=a("li"),$se=a("strong"),cdo=o("mbart"),fdo=o(" \u2014 "),OB=a("a"),mdo=o("MBartTokenizer"),gdo=o(" or "),VB=a("a"),hdo=o("MBartTokenizerFast"),pdo=o(" (mBART model)"),_do=l(),us=a("li"),kse=a("strong"),udo=o("mbart50"),bdo=o(" \u2014 "),XB=a("a"),vdo=o("MBart50Tokenizer"),Fdo=o(" or "),zB=a("a"),Tdo=o("MBart50TokenizerFast"),Mdo=o(" (mBART-50 model)"),Edo=l(),bs=a("li"),Sse=a("strong"),Cdo=o("megatron-bert"),wdo=o(" \u2014 "),QB=a("a"),Ado=o("BertTokenizer"),Ldo=o(" or "),WB=a("a"),ydo=o("BertTokenizerFast"),xdo=o(" (Megatron-BERT model)"),$do=l(),sh=a("li"),Rse=a("strong"),kdo=o("mluke"),Sdo=o(" \u2014 "),HB=a("a"),Rdo=o("MLukeTokenizer"),Pdo=o(" (mLUKE model)"),Bdo=l(),vs=a("li"),Pse=a("strong"),Ido=o("mobilebert"),Ndo=o(" \u2014 "),UB=a("a"),qdo=o("MobileBertTokenizer"),jdo=o(" or "),JB=a("a"),Ddo=o("MobileBertTokenizerFast"),Gdo=o(" (MobileBERT model)"),Odo=l(),Fs=a("li"),Bse=a("strong"),Vdo=o("mpnet"),Xdo=o(" \u2014 "),YB=a("a"),zdo=o("MPNetTokenizer"),Qdo=o(" or "),KB=a("a"),Wdo=o("MPNetTokenizerFast"),Hdo=o(" (MPNet model)"),Udo=l(),Ts=a("li"),Ise=a("strong"),Jdo=o("mt5"),Ydo=o(" \u2014 "),ZB=a("a"),Kdo=o("MT5Tokenizer"),Zdo=o(" or "),eI=a("a"),eco=o("MT5TokenizerFast"),oco=o(" (MT5 model)"),rco=l(),Ms=a("li"),Nse=a("strong"),tco=o("nezha"),aco=o(" \u2014 "),oI=a("a"),nco=o("BertTokenizer"),sco=o(" or "),rI=a("a"),lco=o("BertTokenizerFast"),ico=o(" (Nezha model)"),dco=l(),Es=a("li"),qse=a("strong"),cco=o("nystromformer"),fco=o(" \u2014 "),tI=a("a"),mco=o("AlbertTokenizer"),gco=o(" or "),aI=a("a"),hco=o("AlbertTokenizerFast"),pco=o(" (Nystr\xF6mformer model)"),_co=l(),Cs=a("li"),jse=a("strong"),uco=o("openai-gpt"),bco=o(" \u2014 "),nI=a("a"),vco=o("OpenAIGPTTokenizer"),Fco=o(" or "),sI=a("a"),Tco=o("OpenAIGPTTokenizerFast"),Mco=o(" (OpenAI GPT model)"),Eco=l(),lh=a("li"),Dse=a("strong"),Cco=o("opt"),wco=o(" \u2014 "),lI=a("a"),Aco=o("GPT2Tokenizer"),Lco=o(" (OPT model)"),yco=l(),ws=a("li"),Gse=a("strong"),xco=o("pegasus"),$co=o(" \u2014 "),iI=a("a"),kco=o("PegasusTokenizer"),Sco=o(" or "),dI=a("a"),Rco=o("PegasusTokenizerFast"),Pco=o(" (Pegasus model)"),Bco=l(),ih=a("li"),Ose=a("strong"),Ico=o("perceiver"),Nco=o(" \u2014 "),cI=a("a"),qco=o("PerceiverTokenizer"),jco=o(" (Perceiver model)"),Dco=l(),dh=a("li"),Vse=a("strong"),Gco=o("phobert"),Oco=o(" \u2014 "),fI=a("a"),Vco=o("PhobertTokenizer"),Xco=o(" (PhoBERT model)"),zco=l(),ch=a("li"),Xse=a("strong"),Qco=o("plbart"),Wco=o(" \u2014 "),mI=a("a"),Hco=o("PLBartTokenizer"),Uco=o(" (PLBart model)"),Jco=l(),fh=a("li"),zse=a("strong"),Yco=o("prophetnet"),Kco=o(" \u2014 "),gI=a("a"),Zco=o("ProphetNetTokenizer"),efo=o(" (ProphetNet model)"),ofo=l(),As=a("li"),Qse=a("strong"),rfo=o("qdqbert"),tfo=o(" \u2014 "),hI=a("a"),afo=o("BertTokenizer"),nfo=o(" or "),pI=a("a"),sfo=o("BertTokenizerFast"),lfo=o(" (QDQBert model)"),ifo=l(),mh=a("li"),Wse=a("strong"),dfo=o("rag"),cfo=o(" \u2014 "),_I=a("a"),ffo=o("RagTokenizer"),mfo=o(" (RAG model)"),gfo=l(),Ls=a("li"),Hse=a("strong"),hfo=o("realm"),pfo=o(" \u2014 "),uI=a("a"),_fo=o("RealmTokenizer"),ufo=o(" or "),bI=a("a"),bfo=o("RealmTokenizerFast"),vfo=o(" (REALM model)"),Ffo=l(),ys=a("li"),Use=a("strong"),Tfo=o("reformer"),Mfo=o(" \u2014 "),vI=a("a"),Efo=o("ReformerTokenizer"),Cfo=o(" or "),FI=a("a"),wfo=o("ReformerTokenizerFast"),Afo=o(" (Reformer model)"),Lfo=l(),xs=a("li"),Jse=a("strong"),yfo=o("rembert"),xfo=o(" \u2014 "),TI=a("a"),$fo=o("RemBertTokenizer"),kfo=o(" or "),MI=a("a"),Sfo=o("RemBertTokenizerFast"),Rfo=o(" (RemBERT model)"),Pfo=l(),$s=a("li"),Yse=a("strong"),Bfo=o("retribert"),Ifo=o(" \u2014 "),EI=a("a"),Nfo=o("RetriBertTokenizer"),qfo=o(" or "),CI=a("a"),jfo=o("RetriBertTokenizerFast"),Dfo=o(" (RetriBERT model)"),Gfo=l(),ks=a("li"),Kse=a("strong"),Ofo=o("roberta"),Vfo=o(" \u2014 "),wI=a("a"),Xfo=o("RobertaTokenizer"),zfo=o(" or "),AI=a("a"),Qfo=o("RobertaTokenizerFast"),Wfo=o(" (RoBERTa model)"),Hfo=l(),Ss=a("li"),Zse=a("strong"),Ufo=o("roformer"),Jfo=o(" \u2014 "),LI=a("a"),Yfo=o("RoFormerTokenizer"),Kfo=o(" or "),yI=a("a"),Zfo=o("RoFormerTokenizerFast"),emo=o(" (RoFormer model)"),omo=l(),gh=a("li"),ele=a("strong"),rmo=o("speech_to_text"),tmo=o(" \u2014 "),xI=a("a"),amo=o("Speech2TextTokenizer"),nmo=o(" (Speech2Text model)"),smo=l(),hh=a("li"),ole=a("strong"),lmo=o("speech_to_text_2"),imo=o(" \u2014 "),$I=a("a"),dmo=o("Speech2Text2Tokenizer"),cmo=o(" (Speech2Text2 model)"),fmo=l(),Rs=a("li"),rle=a("strong"),mmo=o("splinter"),gmo=o(" \u2014 "),kI=a("a"),hmo=o("SplinterTokenizer"),pmo=o(" or "),SI=a("a"),_mo=o("SplinterTokenizerFast"),umo=o(" (Splinter model)"),bmo=l(),Ps=a("li"),tle=a("strong"),vmo=o("squeezebert"),Fmo=o(" \u2014 "),RI=a("a"),Tmo=o("SqueezeBertTokenizer"),Mmo=o(" or "),PI=a("a"),Emo=o("SqueezeBertTokenizerFast"),Cmo=o(" (SqueezeBERT model)"),wmo=l(),Bs=a("li"),ale=a("strong"),Amo=o("t5"),Lmo=o(" \u2014 "),BI=a("a"),ymo=o("T5Tokenizer"),xmo=o(" or "),II=a("a"),$mo=o("T5TokenizerFast"),kmo=o(" (T5 model)"),Smo=l(),ph=a("li"),nle=a("strong"),Rmo=o("tapas"),Pmo=o(" \u2014 "),NI=a("a"),Bmo=o("TapasTokenizer"),Imo=o(" (TAPAS model)"),Nmo=l(),_h=a("li"),sle=a("strong"),qmo=o("tapex"),jmo=o(" \u2014 "),qI=a("a"),Dmo=o("TapexTokenizer"),Gmo=o(" (TAPEX model)"),Omo=l(),uh=a("li"),lle=a("strong"),Vmo=o("transfo-xl"),Xmo=o(" \u2014 "),jI=a("a"),zmo=o("TransfoXLTokenizer"),Qmo=o(" (Transformer-XL model)"),Wmo=l(),Is=a("li"),ile=a("strong"),Hmo=o("vilt"),Umo=o(" \u2014 "),DI=a("a"),Jmo=o("BertTokenizer"),Ymo=o(" or "),GI=a("a"),Kmo=o("BertTokenizerFast"),Zmo=o(" (ViLT model)"),ego=l(),Ns=a("li"),dle=a("strong"),ogo=o("visual_bert"),rgo=o(" \u2014 "),OI=a("a"),tgo=o("BertTokenizer"),ago=o(" or "),VI=a("a"),ngo=o("BertTokenizerFast"),sgo=o(" (VisualBERT model)"),lgo=l(),bh=a("li"),cle=a("strong"),igo=o("wav2vec2"),dgo=o(" \u2014 "),XI=a("a"),cgo=o("Wav2Vec2CTCTokenizer"),fgo=o(" (Wav2Vec2 model)"),mgo=l(),vh=a("li"),fle=a("strong"),ggo=o("wav2vec2-conformer"),hgo=o(" \u2014 "),zI=a("a"),pgo=o("Wav2Vec2CTCTokenizer"),_go=o(" (Wav2Vec2-Conformer model)"),ugo=l(),Fh=a("li"),mle=a("strong"),bgo=o("wav2vec2_phoneme"),vgo=o(" \u2014 "),QI=a("a"),Fgo=o("Wav2Vec2PhonemeCTCTokenizer"),Tgo=o(" (Wav2Vec2Phoneme model)"),Mgo=l(),qs=a("li"),gle=a("strong"),Ego=o("xglm"),Cgo=o(" \u2014 "),WI=a("a"),wgo=o("XGLMTokenizer"),Ago=o(" or "),HI=a("a"),Lgo=o("XGLMTokenizerFast"),ygo=o(" (XGLM model)"),xgo=l(),Th=a("li"),hle=a("strong"),$go=o("xlm"),kgo=o(" \u2014 "),UI=a("a"),Sgo=o("XLMTokenizer"),Rgo=o(" (XLM model)"),Pgo=l(),Mh=a("li"),ple=a("strong"),Bgo=o("xlm-prophetnet"),Igo=o(" \u2014 "),JI=a("a"),Ngo=o("XLMProphetNetTokenizer"),qgo=o(" (XLM-ProphetNet model)"),jgo=l(),js=a("li"),_le=a("strong"),Dgo=o("xlm-roberta"),Ggo=o(" \u2014 "),YI=a("a"),Ogo=o("XLMRobertaTokenizer"),Vgo=o(" or "),KI=a("a"),Xgo=o("XLMRobertaTokenizerFast"),zgo=o(" (XLM-RoBERTa model)"),Qgo=l(),Ds=a("li"),ule=a("strong"),Wgo=o("xlm-roberta-xl"),Hgo=o(" \u2014 "),ZI=a("a"),Ugo=o("RobertaTokenizer"),Jgo=o(" or "),eN=a("a"),Ygo=o("RobertaTokenizerFast"),Kgo=o(" (XLM-RoBERTa-XL model)"),Zgo=l(),Gs=a("li"),ble=a("strong"),eho=o("xlnet"),oho=o(" \u2014 "),oN=a("a"),rho=o("XLNetTokenizer"),tho=o(" or "),rN=a("a"),aho=o("XLNetTokenizerFast"),nho=o(" (XLNet model)"),sho=l(),Os=a("li"),vle=a("strong"),lho=o("yoso"),iho=o(" \u2014 "),tN=a("a"),dho=o("AlbertTokenizer"),cho=o(" or "),aN=a("a"),fho=o("AlbertTokenizerFast"),mho=o(" (YOSO model)"),gho=l(),F(Eh.$$.fragment),hho=l(),Ch=a("div"),F(Ow.$$.fragment),pho=l(),Fle=a("p"),_ho=o("Register a new tokenizer in this mapping."),HGe=l(),Si=a("h2"),wh=a("a"),Tle=a("span"),F(Vw.$$.fragment),uho=l(),Mle=a("span"),bho=o("AutoFeatureExtractor"),UGe=l(),Lo=a("div"),F(Xw.$$.fragment),vho=l(),zw=a("p"),Fho=o(`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),nN=a("a"),Tho=o("AutoFeatureExtractor.from_pretrained()"),Mho=o(" class method."),Eho=l(),Qw=a("p"),Cho=o("This class cannot be instantiated directly using "),Ele=a("code"),who=o("__init__()"),Aho=o(" (throws an error)."),Lho=l(),He=a("div"),F(Ww.$$.fragment),yho=l(),Cle=a("p"),xho=o("Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),$ho=l(),Sa=a("p"),kho=o("The feature extractor class to instantiate is selected based on the "),wle=a("code"),Sho=o("model_type"),Rho=o(` property of the config object
(either passed as an argument or loaded from `),Ale=a("code"),Pho=o("pretrained_model_name_or_path"),Bho=o(` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Lle=a("code"),Iho=o("pretrained_model_name_or_path"),Nho=o(":"),qho=l(),Y=a("ul"),Ah=a("li"),yle=a("strong"),jho=o("beit"),Dho=o(" \u2014 "),sN=a("a"),Gho=o("BeitFeatureExtractor"),Oho=o(" (BEiT model)"),Vho=l(),Lh=a("li"),xle=a("strong"),Xho=o("clip"),zho=o(" \u2014 "),lN=a("a"),Qho=o("CLIPFeatureExtractor"),Who=o(" (CLIP model)"),Hho=l(),yh=a("li"),$le=a("strong"),Uho=o("convnext"),Jho=o(" \u2014 "),iN=a("a"),Yho=o("ConvNextFeatureExtractor"),Kho=o(" (ConvNeXT model)"),Zho=l(),xh=a("li"),kle=a("strong"),epo=o("cvt"),opo=o(" \u2014 "),dN=a("a"),rpo=o("ConvNextFeatureExtractor"),tpo=o(" (CvT model)"),apo=l(),$h=a("li"),Sle=a("strong"),npo=o("data2vec-audio"),spo=o(" \u2014 "),cN=a("a"),lpo=o("Wav2Vec2FeatureExtractor"),ipo=o(" (Data2VecAudio model)"),dpo=l(),kh=a("li"),Rle=a("strong"),cpo=o("data2vec-vision"),fpo=o(" \u2014 "),fN=a("a"),mpo=o("BeitFeatureExtractor"),gpo=o(" (Data2VecVision model)"),hpo=l(),Sh=a("li"),Ple=a("strong"),ppo=o("deit"),_po=o(" \u2014 "),mN=a("a"),upo=o("DeiTFeatureExtractor"),bpo=o(" (DeiT model)"),vpo=l(),Rh=a("li"),Ble=a("strong"),Fpo=o("detr"),Tpo=o(" \u2014 "),gN=a("a"),Mpo=o("DetrFeatureExtractor"),Epo=o(" (DETR model)"),Cpo=l(),Ph=a("li"),Ile=a("strong"),wpo=o("dpt"),Apo=o(" \u2014 "),hN=a("a"),Lpo=o("DPTFeatureExtractor"),ypo=o(" (DPT model)"),xpo=l(),Bh=a("li"),Nle=a("strong"),$po=o("flava"),kpo=o(" \u2014 "),pN=a("a"),Spo=o("FlavaFeatureExtractor"),Rpo=o(" (FLAVA model)"),Ppo=l(),Ih=a("li"),qle=a("strong"),Bpo=o("glpn"),Ipo=o(" \u2014 "),_N=a("a"),Npo=o("GLPNFeatureExtractor"),qpo=o(" (GLPN model)"),jpo=l(),Nh=a("li"),jle=a("strong"),Dpo=o("hubert"),Gpo=o(" \u2014 "),uN=a("a"),Opo=o("Wav2Vec2FeatureExtractor"),Vpo=o(" (Hubert model)"),Xpo=l(),qh=a("li"),Dle=a("strong"),zpo=o("imagegpt"),Qpo=o(" \u2014 "),bN=a("a"),Wpo=o("ImageGPTFeatureExtractor"),Hpo=o(" (ImageGPT model)"),Upo=l(),jh=a("li"),Gle=a("strong"),Jpo=o("layoutlmv2"),Ypo=o(" \u2014 "),vN=a("a"),Kpo=o("LayoutLMv2FeatureExtractor"),Zpo=o(" (LayoutLMv2 model)"),e_o=l(),Dh=a("li"),Ole=a("strong"),o_o=o("layoutlmv3"),r_o=o(" \u2014 "),FN=a("a"),t_o=o("LayoutLMv3FeatureExtractor"),a_o=o(" (LayoutLMv3 model)"),n_o=l(),Gh=a("li"),Vle=a("strong"),s_o=o("levit"),l_o=o(" \u2014 "),TN=a("a"),i_o=o("LevitFeatureExtractor"),d_o=o(" (LeViT model)"),c_o=l(),Oh=a("li"),Xle=a("strong"),f_o=o("maskformer"),m_o=o(" \u2014 "),MN=a("a"),g_o=o("MaskFormerFeatureExtractor"),h_o=o(" (MaskFormer model)"),p_o=l(),Vh=a("li"),zle=a("strong"),__o=o("mctct"),u_o=o(" \u2014 "),EN=a("a"),b_o=o("MCTCTFeatureExtractor"),v_o=o(" (M-CTC-T model)"),F_o=l(),Xh=a("li"),Qle=a("strong"),T_o=o("perceiver"),M_o=o(" \u2014 "),CN=a("a"),E_o=o("PerceiverFeatureExtractor"),C_o=o(" (Perceiver model)"),w_o=l(),zh=a("li"),Wle=a("strong"),A_o=o("poolformer"),L_o=o(" \u2014 "),wN=a("a"),y_o=o("PoolFormerFeatureExtractor"),x_o=o(" (PoolFormer model)"),$_o=l(),Qh=a("li"),Hle=a("strong"),k_o=o("regnet"),S_o=o(" \u2014 "),AN=a("a"),R_o=o("ConvNextFeatureExtractor"),P_o=o(" (RegNet model)"),B_o=l(),Wh=a("li"),Ule=a("strong"),I_o=o("resnet"),N_o=o(" \u2014 "),LN=a("a"),q_o=o("ConvNextFeatureExtractor"),j_o=o(" (ResNet model)"),D_o=l(),Hh=a("li"),Jle=a("strong"),G_o=o("segformer"),O_o=o(" \u2014 "),yN=a("a"),V_o=o("SegformerFeatureExtractor"),X_o=o(" (SegFormer model)"),z_o=l(),Uh=a("li"),Yle=a("strong"),Q_o=o("speech_to_text"),W_o=o(" \u2014 "),xN=a("a"),H_o=o("Speech2TextFeatureExtractor"),U_o=o(" (Speech2Text model)"),J_o=l(),Jh=a("li"),Kle=a("strong"),Y_o=o("swin"),K_o=o(" \u2014 "),$N=a("a"),Z_o=o("ViTFeatureExtractor"),euo=o(" (Swin Transformer model)"),ouo=l(),Yh=a("li"),Zle=a("strong"),ruo=o("van"),tuo=o(" \u2014 "),kN=a("a"),auo=o("ConvNextFeatureExtractor"),nuo=o(" (VAN model)"),suo=l(),Kh=a("li"),eie=a("strong"),luo=o("vilt"),iuo=o(" \u2014 "),SN=a("a"),duo=o("ViltFeatureExtractor"),cuo=o(" (ViLT model)"),fuo=l(),Zh=a("li"),oie=a("strong"),muo=o("vit"),guo=o(" \u2014 "),RN=a("a"),huo=o("ViTFeatureExtractor"),puo=o(" (ViT model)"),_uo=l(),ep=a("li"),rie=a("strong"),uuo=o("vit_mae"),buo=o(" \u2014 "),PN=a("a"),vuo=o("ViTFeatureExtractor"),Fuo=o(" (ViTMAE model)"),Tuo=l(),op=a("li"),tie=a("strong"),Muo=o("wav2vec2"),Euo=o(" \u2014 "),BN=a("a"),Cuo=o("Wav2Vec2FeatureExtractor"),wuo=o(" (Wav2Vec2 model)"),Auo=l(),rp=a("li"),aie=a("strong"),Luo=o("wav2vec2-conformer"),yuo=o(" \u2014 "),IN=a("a"),xuo=o("Wav2Vec2FeatureExtractor"),$uo=o(" (Wav2Vec2-Conformer model)"),kuo=l(),tp=a("li"),nie=a("strong"),Suo=o("yolos"),Ruo=o(" \u2014 "),NN=a("a"),Puo=o("YolosFeatureExtractor"),Buo=o(" (YOLOS model)"),Iuo=l(),F(ap.$$.fragment),Nuo=l(),F(np.$$.fragment),quo=l(),sp=a("div"),F(Hw.$$.fragment),juo=l(),sie=a("p"),Duo=o("Register a new feature extractor for this class."),JGe=l(),Ri=a("h2"),lp=a("a"),lie=a("span"),F(Uw.$$.fragment),Guo=l(),iie=a("span"),Ouo=o("AutoProcessor"),YGe=l(),yo=a("div"),F(Jw.$$.fragment),Vuo=l(),Yw=a("p"),Xuo=o(`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),qN=a("a"),zuo=o("AutoProcessor.from_pretrained()"),Quo=o(" class method."),Wuo=l(),Kw=a("p"),Huo=o("This class cannot be instantiated directly using "),die=a("code"),Uuo=o("__init__()"),Juo=o(" (throws an error)."),Yuo=l(),Ue=a("div"),F(Zw.$$.fragment),Kuo=l(),cie=a("p"),Zuo=o("Instantiate one of the processor classes of the library from a pretrained model vocabulary."),e1o=l(),Pi=a("p"),o1o=o("The processor class to instantiate is selected based on the "),fie=a("code"),r1o=o("model_type"),t1o=o(` property of the config object (either
passed as an argument or loaded from `),mie=a("code"),a1o=o("pretrained_model_name_or_path"),n1o=o(" if possible):"),s1o=l(),he=a("ul"),ip=a("li"),gie=a("strong"),l1o=o("clip"),i1o=o(" \u2014 "),jN=a("a"),d1o=o("CLIPProcessor"),c1o=o(" (CLIP model)"),f1o=l(),dp=a("li"),hie=a("strong"),m1o=o("flava"),g1o=o(" \u2014 "),pie=a("code"),h1o=o("FLAVAProcessor"),p1o=o(" (FLAVA model)"),_1o=l(),cp=a("li"),_ie=a("strong"),u1o=o("layoutlmv2"),b1o=o(" \u2014 "),DN=a("a"),v1o=o("LayoutLMv2Processor"),F1o=o(" (LayoutLMv2 model)"),T1o=l(),fp=a("li"),uie=a("strong"),M1o=o("layoutlmv3"),E1o=o(" \u2014 "),GN=a("a"),C1o=o("LayoutLMv3Processor"),w1o=o(" (LayoutLMv3 model)"),A1o=l(),mp=a("li"),bie=a("strong"),L1o=o("layoutxlm"),y1o=o(" \u2014 "),ON=a("a"),x1o=o("LayoutXLMProcessor"),$1o=o(" (LayoutXLM model)"),k1o=l(),gp=a("li"),vie=a("strong"),S1o=o("sew"),R1o=o(" \u2014 "),VN=a("a"),P1o=o("Wav2Vec2Processor"),B1o=o(" (SEW model)"),I1o=l(),hp=a("li"),Fie=a("strong"),N1o=o("sew-d"),q1o=o(" \u2014 "),XN=a("a"),j1o=o("Wav2Vec2Processor"),D1o=o(" (SEW-D model)"),G1o=l(),pp=a("li"),Tie=a("strong"),O1o=o("speech_to_text"),V1o=o(" \u2014 "),zN=a("a"),X1o=o("Speech2TextProcessor"),z1o=o(" (Speech2Text model)"),Q1o=l(),_p=a("li"),Mie=a("strong"),W1o=o("speech_to_text_2"),H1o=o(" \u2014 "),QN=a("a"),U1o=o("Speech2Text2Processor"),J1o=o(" (Speech2Text2 model)"),Y1o=l(),up=a("li"),Eie=a("strong"),K1o=o("trocr"),Z1o=o(" \u2014 "),WN=a("a"),e2o=o("TrOCRProcessor"),o2o=o(" (TrOCR model)"),r2o=l(),bp=a("li"),Cie=a("strong"),t2o=o("unispeech"),a2o=o(" \u2014 "),HN=a("a"),n2o=o("Wav2Vec2Processor"),s2o=o(" (UniSpeech model)"),l2o=l(),vp=a("li"),wie=a("strong"),i2o=o("unispeech-sat"),d2o=o(" \u2014 "),UN=a("a"),c2o=o("Wav2Vec2Processor"),f2o=o(" (UniSpeechSat model)"),m2o=l(),Fp=a("li"),Aie=a("strong"),g2o=o("vilt"),h2o=o(" \u2014 "),JN=a("a"),p2o=o("ViltProcessor"),_2o=o(" (ViLT model)"),u2o=l(),Tp=a("li"),Lie=a("strong"),b2o=o("vision-text-dual-encoder"),v2o=o(" \u2014 "),YN=a("a"),F2o=o("VisionTextDualEncoderProcessor"),T2o=o(" (VisionTextDualEncoder model)"),M2o=l(),Mp=a("li"),yie=a("strong"),E2o=o("wav2vec2"),C2o=o(" \u2014 "),KN=a("a"),w2o=o("Wav2Vec2Processor"),A2o=o(" (Wav2Vec2 model)"),L2o=l(),Ep=a("li"),xie=a("strong"),y2o=o("wav2vec2-conformer"),x2o=o(" \u2014 "),ZN=a("a"),$2o=o("Wav2Vec2Processor"),k2o=o(" (Wav2Vec2-Conformer model)"),S2o=l(),Cp=a("li"),$ie=a("strong"),R2o=o("wavlm"),P2o=o(" \u2014 "),eq=a("a"),B2o=o("Wav2Vec2Processor"),I2o=o(" (WavLM model)"),N2o=l(),F(wp.$$.fragment),q2o=l(),F(Ap.$$.fragment),j2o=l(),Lp=a("div"),F(eA.$$.fragment),D2o=l(),kie=a("p"),G2o=o("Register a new processor for this class."),KGe=l(),Bi=a("h2"),yp=a("a"),Sie=a("span"),F(oA.$$.fragment),O2o=l(),Rie=a("span"),V2o=o("AutoModel"),ZGe=l(),xo=a("div"),F(rA.$$.fragment),X2o=l(),Ii=a("p"),z2o=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),oq=a("a"),Q2o=o("from_pretrained()"),W2o=o(" class method or the "),rq=a("a"),H2o=o("from_config()"),U2o=o(` class
method.`),J2o=l(),tA=a("p"),Y2o=o("This class cannot be instantiated directly using "),Pie=a("code"),K2o=o("__init__()"),Z2o=o(" (throws an error)."),ebo=l(),nt=a("div"),F(aA.$$.fragment),obo=l(),Bie=a("p"),rbo=o("Instantiates one of the base model classes of the library from a configuration."),tbo=l(),Ni=a("p"),abo=o(`Note:
Loading a model from its configuration file does `),Iie=a("strong"),nbo=o("not"),sbo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),tq=a("a"),lbo=o("from_pretrained()"),ibo=o(" to load the model weights."),dbo=l(),F(xp.$$.fragment),cbo=l(),Je=a("div"),F(nA.$$.fragment),fbo=l(),Nie=a("p"),mbo=o("Instantiate one of the base model classes of the library from a pretrained model."),gbo=l(),Ra=a("p"),hbo=o("The model class to instantiate is selected based on the "),qie=a("code"),pbo=o("model_type"),_bo=o(` property of the config object (either
passed as an argument or loaded from `),jie=a("code"),ubo=o("pretrained_model_name_or_path"),bbo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Die=a("code"),vbo=o("pretrained_model_name_or_path"),Fbo=o(":"),Tbo=l(),y=a("ul"),$p=a("li"),Gie=a("strong"),Mbo=o("albert"),Ebo=o(" \u2014 "),aq=a("a"),Cbo=o("AlbertModel"),wbo=o(" (ALBERT model)"),Abo=l(),kp=a("li"),Oie=a("strong"),Lbo=o("bart"),ybo=o(" \u2014 "),nq=a("a"),xbo=o("BartModel"),$bo=o(" (BART model)"),kbo=l(),Sp=a("li"),Vie=a("strong"),Sbo=o("beit"),Rbo=o(" \u2014 "),sq=a("a"),Pbo=o("BeitModel"),Bbo=o(" (BEiT model)"),Ibo=l(),Rp=a("li"),Xie=a("strong"),Nbo=o("bert"),qbo=o(" \u2014 "),lq=a("a"),jbo=o("BertModel"),Dbo=o(" (BERT model)"),Gbo=l(),Pp=a("li"),zie=a("strong"),Obo=o("bert-generation"),Vbo=o(" \u2014 "),iq=a("a"),Xbo=o("BertGenerationEncoder"),zbo=o(" (Bert Generation model)"),Qbo=l(),Bp=a("li"),Qie=a("strong"),Wbo=o("big_bird"),Hbo=o(" \u2014 "),dq=a("a"),Ubo=o("BigBirdModel"),Jbo=o(" (BigBird model)"),Ybo=l(),Ip=a("li"),Wie=a("strong"),Kbo=o("bigbird_pegasus"),Zbo=o(" \u2014 "),cq=a("a"),evo=o("BigBirdPegasusModel"),ovo=o(" (BigBird-Pegasus model)"),rvo=l(),Np=a("li"),Hie=a("strong"),tvo=o("blenderbot"),avo=o(" \u2014 "),fq=a("a"),nvo=o("BlenderbotModel"),svo=o(" (Blenderbot model)"),lvo=l(),qp=a("li"),Uie=a("strong"),ivo=o("blenderbot-small"),dvo=o(" \u2014 "),mq=a("a"),cvo=o("BlenderbotSmallModel"),fvo=o(" (BlenderbotSmall model)"),mvo=l(),jp=a("li"),Jie=a("strong"),gvo=o("bloom"),hvo=o(" \u2014 "),gq=a("a"),pvo=o("BloomModel"),_vo=o(" (BLOOM model)"),uvo=l(),Dp=a("li"),Yie=a("strong"),bvo=o("camembert"),vvo=o(" \u2014 "),hq=a("a"),Fvo=o("CamembertModel"),Tvo=o(" (CamemBERT model)"),Mvo=l(),Gp=a("li"),Kie=a("strong"),Evo=o("canine"),Cvo=o(" \u2014 "),pq=a("a"),wvo=o("CanineModel"),Avo=o(" (CANINE model)"),Lvo=l(),Op=a("li"),Zie=a("strong"),yvo=o("clip"),xvo=o(" \u2014 "),_q=a("a"),$vo=o("CLIPModel"),kvo=o(" (CLIP model)"),Svo=l(),Vp=a("li"),ede=a("strong"),Rvo=o("convbert"),Pvo=o(" \u2014 "),uq=a("a"),Bvo=o("ConvBertModel"),Ivo=o(" (ConvBERT model)"),Nvo=l(),Xp=a("li"),ode=a("strong"),qvo=o("convnext"),jvo=o(" \u2014 "),bq=a("a"),Dvo=o("ConvNextModel"),Gvo=o(" (ConvNeXT model)"),Ovo=l(),zp=a("li"),rde=a("strong"),Vvo=o("ctrl"),Xvo=o(" \u2014 "),vq=a("a"),zvo=o("CTRLModel"),Qvo=o(" (CTRL model)"),Wvo=l(),Qp=a("li"),tde=a("strong"),Hvo=o("cvt"),Uvo=o(" \u2014 "),Fq=a("a"),Jvo=o("CvtModel"),Yvo=o(" (CvT model)"),Kvo=l(),Wp=a("li"),ade=a("strong"),Zvo=o("data2vec-audio"),eFo=o(" \u2014 "),Tq=a("a"),oFo=o("Data2VecAudioModel"),rFo=o(" (Data2VecAudio model)"),tFo=l(),Hp=a("li"),nde=a("strong"),aFo=o("data2vec-text"),nFo=o(" \u2014 "),Mq=a("a"),sFo=o("Data2VecTextModel"),lFo=o(" (Data2VecText model)"),iFo=l(),Up=a("li"),sde=a("strong"),dFo=o("data2vec-vision"),cFo=o(" \u2014 "),Eq=a("a"),fFo=o("Data2VecVisionModel"),mFo=o(" (Data2VecVision model)"),gFo=l(),Jp=a("li"),lde=a("strong"),hFo=o("deberta"),pFo=o(" \u2014 "),Cq=a("a"),_Fo=o("DebertaModel"),uFo=o(" (DeBERTa model)"),bFo=l(),Yp=a("li"),ide=a("strong"),vFo=o("deberta-v2"),FFo=o(" \u2014 "),wq=a("a"),TFo=o("DebertaV2Model"),MFo=o(" (DeBERTa-v2 model)"),EFo=l(),Kp=a("li"),dde=a("strong"),CFo=o("decision_transformer"),wFo=o(" \u2014 "),Aq=a("a"),AFo=o("DecisionTransformerModel"),LFo=o(" (Decision Transformer model)"),yFo=l(),Zp=a("li"),cde=a("strong"),xFo=o("deit"),$Fo=o(" \u2014 "),Lq=a("a"),kFo=o("DeiTModel"),SFo=o(" (DeiT model)"),RFo=l(),e_=a("li"),fde=a("strong"),PFo=o("detr"),BFo=o(" \u2014 "),yq=a("a"),IFo=o("DetrModel"),NFo=o(" (DETR model)"),qFo=l(),o_=a("li"),mde=a("strong"),jFo=o("distilbert"),DFo=o(" \u2014 "),xq=a("a"),GFo=o("DistilBertModel"),OFo=o(" (DistilBERT model)"),VFo=l(),r_=a("li"),gde=a("strong"),XFo=o("dpr"),zFo=o(" \u2014 "),$q=a("a"),QFo=o("DPRQuestionEncoder"),WFo=o(" (DPR model)"),HFo=l(),t_=a("li"),hde=a("strong"),UFo=o("dpt"),JFo=o(" \u2014 "),kq=a("a"),YFo=o("DPTModel"),KFo=o(" (DPT model)"),ZFo=l(),a_=a("li"),pde=a("strong"),e6o=o("electra"),o6o=o(" \u2014 "),Sq=a("a"),r6o=o("ElectraModel"),t6o=o(" (ELECTRA model)"),a6o=l(),n_=a("li"),_de=a("strong"),n6o=o("flaubert"),s6o=o(" \u2014 "),Rq=a("a"),l6o=o("FlaubertModel"),i6o=o(" (FlauBERT model)"),d6o=l(),s_=a("li"),ude=a("strong"),c6o=o("flava"),f6o=o(" \u2014 "),Pq=a("a"),m6o=o("FlavaModel"),g6o=o(" (FLAVA model)"),h6o=l(),l_=a("li"),bde=a("strong"),p6o=o("fnet"),_6o=o(" \u2014 "),Bq=a("a"),u6o=o("FNetModel"),b6o=o(" (FNet model)"),v6o=l(),i_=a("li"),vde=a("strong"),F6o=o("fsmt"),T6o=o(" \u2014 "),Iq=a("a"),M6o=o("FSMTModel"),E6o=o(" (FairSeq Machine-Translation model)"),C6o=l(),Vs=a("li"),Fde=a("strong"),w6o=o("funnel"),A6o=o(" \u2014 "),Nq=a("a"),L6o=o("FunnelModel"),y6o=o(" or "),qq=a("a"),x6o=o("FunnelBaseModel"),$6o=o(" (Funnel Transformer model)"),k6o=l(),d_=a("li"),Tde=a("strong"),S6o=o("glpn"),R6o=o(" \u2014 "),jq=a("a"),P6o=o("GLPNModel"),B6o=o(" (GLPN model)"),I6o=l(),c_=a("li"),Mde=a("strong"),N6o=o("gpt2"),q6o=o(" \u2014 "),Dq=a("a"),j6o=o("GPT2Model"),D6o=o(" (OpenAI GPT-2 model)"),G6o=l(),f_=a("li"),Ede=a("strong"),O6o=o("gpt_neo"),V6o=o(" \u2014 "),Gq=a("a"),X6o=o("GPTNeoModel"),z6o=o(" (GPT Neo model)"),Q6o=l(),m_=a("li"),Cde=a("strong"),W6o=o("gpt_neox"),H6o=o(" \u2014 "),Oq=a("a"),U6o=o("GPTNeoXModel"),J6o=o(" (GPT NeoX model)"),Y6o=l(),g_=a("li"),wde=a("strong"),K6o=o("gptj"),Z6o=o(" \u2014 "),Vq=a("a"),eTo=o("GPTJModel"),oTo=o(" (GPT-J model)"),rTo=l(),h_=a("li"),Ade=a("strong"),tTo=o("hubert"),aTo=o(" \u2014 "),Xq=a("a"),nTo=o("HubertModel"),sTo=o(" (Hubert model)"),lTo=l(),p_=a("li"),Lde=a("strong"),iTo=o("ibert"),dTo=o(" \u2014 "),zq=a("a"),cTo=o("IBertModel"),fTo=o(" (I-BERT model)"),mTo=l(),__=a("li"),yde=a("strong"),gTo=o("imagegpt"),hTo=o(" \u2014 "),Qq=a("a"),pTo=o("ImageGPTModel"),_To=o(" (ImageGPT model)"),uTo=l(),u_=a("li"),xde=a("strong"),bTo=o("layoutlm"),vTo=o(" \u2014 "),Wq=a("a"),FTo=o("LayoutLMModel"),TTo=o(" (LayoutLM model)"),MTo=l(),b_=a("li"),$de=a("strong"),ETo=o("layoutlmv2"),CTo=o(" \u2014 "),Hq=a("a"),wTo=o("LayoutLMv2Model"),ATo=o(" (LayoutLMv2 model)"),LTo=l(),v_=a("li"),kde=a("strong"),yTo=o("layoutlmv3"),xTo=o(" \u2014 "),Uq=a("a"),$To=o("LayoutLMv3Model"),kTo=o(" (LayoutLMv3 model)"),STo=l(),F_=a("li"),Sde=a("strong"),RTo=o("led"),PTo=o(" \u2014 "),Jq=a("a"),BTo=o("LEDModel"),ITo=o(" (LED model)"),NTo=l(),T_=a("li"),Rde=a("strong"),qTo=o("levit"),jTo=o(" \u2014 "),Yq=a("a"),DTo=o("LevitModel"),GTo=o(" (LeViT model)"),OTo=l(),M_=a("li"),Pde=a("strong"),VTo=o("longformer"),XTo=o(" \u2014 "),Kq=a("a"),zTo=o("LongformerModel"),QTo=o(" (Longformer model)"),WTo=l(),E_=a("li"),Bde=a("strong"),HTo=o("longt5"),UTo=o(" \u2014 "),Zq=a("a"),JTo=o("LongT5Model"),YTo=o(" (LongT5 model)"),KTo=l(),C_=a("li"),Ide=a("strong"),ZTo=o("luke"),e7o=o(" \u2014 "),ej=a("a"),o7o=o("LukeModel"),r7o=o(" (LUKE model)"),t7o=l(),w_=a("li"),Nde=a("strong"),a7o=o("lxmert"),n7o=o(" \u2014 "),oj=a("a"),s7o=o("LxmertModel"),l7o=o(" (LXMERT model)"),i7o=l(),A_=a("li"),qde=a("strong"),d7o=o("m2m_100"),c7o=o(" \u2014 "),rj=a("a"),f7o=o("M2M100Model"),m7o=o(" (M2M100 model)"),g7o=l(),L_=a("li"),jde=a("strong"),h7o=o("marian"),p7o=o(" \u2014 "),tj=a("a"),_7o=o("MarianModel"),u7o=o(" (Marian model)"),b7o=l(),y_=a("li"),Dde=a("strong"),v7o=o("maskformer"),F7o=o(" \u2014 "),aj=a("a"),T7o=o("MaskFormerModel"),M7o=o(" (MaskFormer model)"),E7o=l(),x_=a("li"),Gde=a("strong"),C7o=o("mbart"),w7o=o(" \u2014 "),nj=a("a"),A7o=o("MBartModel"),L7o=o(" (mBART model)"),y7o=l(),$_=a("li"),Ode=a("strong"),x7o=o("mctct"),$7o=o(" \u2014 "),sj=a("a"),k7o=o("MCTCTModel"),S7o=o(" (M-CTC-T model)"),R7o=l(),k_=a("li"),Vde=a("strong"),P7o=o("megatron-bert"),B7o=o(" \u2014 "),lj=a("a"),I7o=o("MegatronBertModel"),N7o=o(" (Megatron-BERT model)"),q7o=l(),S_=a("li"),Xde=a("strong"),j7o=o("mobilebert"),D7o=o(" \u2014 "),ij=a("a"),G7o=o("MobileBertModel"),O7o=o(" (MobileBERT model)"),V7o=l(),R_=a("li"),zde=a("strong"),X7o=o("mpnet"),z7o=o(" \u2014 "),dj=a("a"),Q7o=o("MPNetModel"),W7o=o(" (MPNet model)"),H7o=l(),P_=a("li"),Qde=a("strong"),U7o=o("mt5"),J7o=o(" \u2014 "),cj=a("a"),Y7o=o("MT5Model"),K7o=o(" (MT5 model)"),Z7o=l(),B_=a("li"),Wde=a("strong"),e8o=o("nezha"),o8o=o(" \u2014 "),fj=a("a"),r8o=o("NezhaModel"),t8o=o(" (Nezha model)"),a8o=l(),I_=a("li"),Hde=a("strong"),n8o=o("nystromformer"),s8o=o(" \u2014 "),mj=a("a"),l8o=o("NystromformerModel"),i8o=o(" (Nystr\xF6mformer model)"),d8o=l(),N_=a("li"),Ude=a("strong"),c8o=o("openai-gpt"),f8o=o(" \u2014 "),gj=a("a"),m8o=o("OpenAIGPTModel"),g8o=o(" (OpenAI GPT model)"),h8o=l(),q_=a("li"),Jde=a("strong"),p8o=o("opt"),_8o=o(" \u2014 "),hj=a("a"),u8o=o("OPTModel"),b8o=o(" (OPT model)"),v8o=l(),j_=a("li"),Yde=a("strong"),F8o=o("pegasus"),T8o=o(" \u2014 "),pj=a("a"),M8o=o("PegasusModel"),E8o=o(" (Pegasus model)"),C8o=l(),D_=a("li"),Kde=a("strong"),w8o=o("perceiver"),A8o=o(" \u2014 "),_j=a("a"),L8o=o("PerceiverModel"),y8o=o(" (Perceiver model)"),x8o=l(),G_=a("li"),Zde=a("strong"),$8o=o("plbart"),k8o=o(" \u2014 "),uj=a("a"),S8o=o("PLBartModel"),R8o=o(" (PLBart model)"),P8o=l(),O_=a("li"),ece=a("strong"),B8o=o("poolformer"),I8o=o(" \u2014 "),bj=a("a"),N8o=o("PoolFormerModel"),q8o=o(" (PoolFormer model)"),j8o=l(),V_=a("li"),oce=a("strong"),D8o=o("prophetnet"),G8o=o(" \u2014 "),vj=a("a"),O8o=o("ProphetNetModel"),V8o=o(" (ProphetNet model)"),X8o=l(),X_=a("li"),rce=a("strong"),z8o=o("qdqbert"),Q8o=o(" \u2014 "),Fj=a("a"),W8o=o("QDQBertModel"),H8o=o(" (QDQBert model)"),U8o=l(),z_=a("li"),tce=a("strong"),J8o=o("reformer"),Y8o=o(" \u2014 "),Tj=a("a"),K8o=o("ReformerModel"),Z8o=o(" (Reformer model)"),e9o=l(),Q_=a("li"),ace=a("strong"),o9o=o("regnet"),r9o=o(" \u2014 "),Mj=a("a"),t9o=o("RegNetModel"),a9o=o(" (RegNet model)"),n9o=l(),W_=a("li"),nce=a("strong"),s9o=o("rembert"),l9o=o(" \u2014 "),Ej=a("a"),i9o=o("RemBertModel"),d9o=o(" (RemBERT model)"),c9o=l(),H_=a("li"),sce=a("strong"),f9o=o("resnet"),m9o=o(" \u2014 "),Cj=a("a"),g9o=o("ResNetModel"),h9o=o(" (ResNet model)"),p9o=l(),U_=a("li"),lce=a("strong"),_9o=o("retribert"),u9o=o(" \u2014 "),wj=a("a"),b9o=o("RetriBertModel"),v9o=o(" (RetriBERT model)"),F9o=l(),J_=a("li"),ice=a("strong"),T9o=o("roberta"),M9o=o(" \u2014 "),Aj=a("a"),E9o=o("RobertaModel"),C9o=o(" (RoBERTa model)"),w9o=l(),Y_=a("li"),dce=a("strong"),A9o=o("roformer"),L9o=o(" \u2014 "),Lj=a("a"),y9o=o("RoFormerModel"),x9o=o(" (RoFormer model)"),$9o=l(),K_=a("li"),cce=a("strong"),k9o=o("segformer"),S9o=o(" \u2014 "),yj=a("a"),R9o=o("SegformerModel"),P9o=o(" (SegFormer model)"),B9o=l(),Z_=a("li"),fce=a("strong"),I9o=o("sew"),N9o=o(" \u2014 "),xj=a("a"),q9o=o("SEWModel"),j9o=o(" (SEW model)"),D9o=l(),eu=a("li"),mce=a("strong"),G9o=o("sew-d"),O9o=o(" \u2014 "),$j=a("a"),V9o=o("SEWDModel"),X9o=o(" (SEW-D model)"),z9o=l(),ou=a("li"),gce=a("strong"),Q9o=o("speech_to_text"),W9o=o(" \u2014 "),kj=a("a"),H9o=o("Speech2TextModel"),U9o=o(" (Speech2Text model)"),J9o=l(),ru=a("li"),hce=a("strong"),Y9o=o("splinter"),K9o=o(" \u2014 "),Sj=a("a"),Z9o=o("SplinterModel"),eMo=o(" (Splinter model)"),oMo=l(),tu=a("li"),pce=a("strong"),rMo=o("squeezebert"),tMo=o(" \u2014 "),Rj=a("a"),aMo=o("SqueezeBertModel"),nMo=o(" (SqueezeBERT model)"),sMo=l(),au=a("li"),_ce=a("strong"),lMo=o("swin"),iMo=o(" \u2014 "),Pj=a("a"),dMo=o("SwinModel"),cMo=o(" (Swin Transformer model)"),fMo=l(),nu=a("li"),uce=a("strong"),mMo=o("t5"),gMo=o(" \u2014 "),Bj=a("a"),hMo=o("T5Model"),pMo=o(" (T5 model)"),_Mo=l(),su=a("li"),bce=a("strong"),uMo=o("tapas"),bMo=o(" \u2014 "),Ij=a("a"),vMo=o("TapasModel"),FMo=o(" (TAPAS model)"),TMo=l(),lu=a("li"),vce=a("strong"),MMo=o("trajectory_transformer"),EMo=o(" \u2014 "),Nj=a("a"),CMo=o("TrajectoryTransformerModel"),wMo=o(" (Trajectory Transformer model)"),AMo=l(),iu=a("li"),Fce=a("strong"),LMo=o("transfo-xl"),yMo=o(" \u2014 "),qj=a("a"),xMo=o("TransfoXLModel"),$Mo=o(" (Transformer-XL model)"),kMo=l(),du=a("li"),Tce=a("strong"),SMo=o("unispeech"),RMo=o(" \u2014 "),jj=a("a"),PMo=o("UniSpeechModel"),BMo=o(" (UniSpeech model)"),IMo=l(),cu=a("li"),Mce=a("strong"),NMo=o("unispeech-sat"),qMo=o(" \u2014 "),Dj=a("a"),jMo=o("UniSpeechSatModel"),DMo=o(" (UniSpeechSat model)"),GMo=l(),fu=a("li"),Ece=a("strong"),OMo=o("van"),VMo=o(" \u2014 "),Gj=a("a"),XMo=o("VanModel"),zMo=o(" (VAN model)"),QMo=l(),mu=a("li"),Cce=a("strong"),WMo=o("vilt"),HMo=o(" \u2014 "),Oj=a("a"),UMo=o("ViltModel"),JMo=o(" (ViLT model)"),YMo=l(),gu=a("li"),wce=a("strong"),KMo=o("vision-text-dual-encoder"),ZMo=o(" \u2014 "),Vj=a("a"),eEo=o("VisionTextDualEncoderModel"),oEo=o(" (VisionTextDualEncoder model)"),rEo=l(),hu=a("li"),Ace=a("strong"),tEo=o("visual_bert"),aEo=o(" \u2014 "),Xj=a("a"),nEo=o("VisualBertModel"),sEo=o(" (VisualBERT model)"),lEo=l(),pu=a("li"),Lce=a("strong"),iEo=o("vit"),dEo=o(" \u2014 "),zj=a("a"),cEo=o("ViTModel"),fEo=o(" (ViT model)"),mEo=l(),_u=a("li"),yce=a("strong"),gEo=o("vit_mae"),hEo=o(" \u2014 "),Qj=a("a"),pEo=o("ViTMAEModel"),_Eo=o(" (ViTMAE model)"),uEo=l(),uu=a("li"),xce=a("strong"),bEo=o("wav2vec2"),vEo=o(" \u2014 "),Wj=a("a"),FEo=o("Wav2Vec2Model"),TEo=o(" (Wav2Vec2 model)"),MEo=l(),bu=a("li"),$ce=a("strong"),EEo=o("wav2vec2-conformer"),CEo=o(" \u2014 "),Hj=a("a"),wEo=o("Wav2Vec2ConformerModel"),AEo=o(" (Wav2Vec2-Conformer model)"),LEo=l(),vu=a("li"),kce=a("strong"),yEo=o("wavlm"),xEo=o(" \u2014 "),Uj=a("a"),$Eo=o("WavLMModel"),kEo=o(" (WavLM model)"),SEo=l(),Fu=a("li"),Sce=a("strong"),REo=o("xglm"),PEo=o(" \u2014 "),Jj=a("a"),BEo=o("XGLMModel"),IEo=o(" (XGLM model)"),NEo=l(),Tu=a("li"),Rce=a("strong"),qEo=o("xlm"),jEo=o(" \u2014 "),Yj=a("a"),DEo=o("XLMModel"),GEo=o(" (XLM model)"),OEo=l(),Mu=a("li"),Pce=a("strong"),VEo=o("xlm-prophetnet"),XEo=o(" \u2014 "),Kj=a("a"),zEo=o("XLMProphetNetModel"),QEo=o(" (XLM-ProphetNet model)"),WEo=l(),Eu=a("li"),Bce=a("strong"),HEo=o("xlm-roberta"),UEo=o(" \u2014 "),Zj=a("a"),JEo=o("XLMRobertaModel"),YEo=o(" (XLM-RoBERTa model)"),KEo=l(),Cu=a("li"),Ice=a("strong"),ZEo=o("xlm-roberta-xl"),e4o=o(" \u2014 "),eD=a("a"),o4o=o("XLMRobertaXLModel"),r4o=o(" (XLM-RoBERTa-XL model)"),t4o=l(),wu=a("li"),Nce=a("strong"),a4o=o("xlnet"),n4o=o(" \u2014 "),oD=a("a"),s4o=o("XLNetModel"),l4o=o(" (XLNet model)"),i4o=l(),Au=a("li"),qce=a("strong"),d4o=o("yolos"),c4o=o(" \u2014 "),rD=a("a"),f4o=o("YolosModel"),m4o=o(" (YOLOS model)"),g4o=l(),Lu=a("li"),jce=a("strong"),h4o=o("yoso"),p4o=o(" \u2014 "),tD=a("a"),_4o=o("YosoModel"),u4o=o(" (YOSO model)"),b4o=l(),yu=a("p"),v4o=o("The model is set in evaluation mode by default using "),Dce=a("code"),F4o=o("model.eval()"),T4o=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gce=a("code"),M4o=o("model.train()"),E4o=l(),F(xu.$$.fragment),eOe=l(),qi=a("h2"),$u=a("a"),Oce=a("span"),F(sA.$$.fragment),C4o=l(),Vce=a("span"),w4o=o("AutoModelForPreTraining"),oOe=l(),$o=a("div"),F(lA.$$.fragment),A4o=l(),ji=a("p"),L4o=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),aD=a("a"),y4o=o("from_pretrained()"),x4o=o(" class method or the "),nD=a("a"),$4o=o("from_config()"),k4o=o(` class
method.`),S4o=l(),iA=a("p"),R4o=o("This class cannot be instantiated directly using "),Xce=a("code"),P4o=o("__init__()"),B4o=o(" (throws an error)."),I4o=l(),st=a("div"),F(dA.$$.fragment),N4o=l(),zce=a("p"),q4o=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),j4o=l(),Di=a("p"),D4o=o(`Note:
Loading a model from its configuration file does `),Qce=a("strong"),G4o=o("not"),O4o=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sD=a("a"),V4o=o("from_pretrained()"),X4o=o(" to load the model weights."),z4o=l(),F(ku.$$.fragment),Q4o=l(),Ye=a("div"),F(cA.$$.fragment),W4o=l(),Wce=a("p"),H4o=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),U4o=l(),Pa=a("p"),J4o=o("The model class to instantiate is selected based on the "),Hce=a("code"),Y4o=o("model_type"),K4o=o(` property of the config object (either
passed as an argument or loaded from `),Uce=a("code"),Z4o=o("pretrained_model_name_or_path"),eCo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jce=a("code"),oCo=o("pretrained_model_name_or_path"),rCo=o(":"),tCo=l(),G=a("ul"),Su=a("li"),Yce=a("strong"),aCo=o("albert"),nCo=o(" \u2014 "),lD=a("a"),sCo=o("AlbertForPreTraining"),lCo=o(" (ALBERT model)"),iCo=l(),Ru=a("li"),Kce=a("strong"),dCo=o("bart"),cCo=o(" \u2014 "),iD=a("a"),fCo=o("BartForConditionalGeneration"),mCo=o(" (BART model)"),gCo=l(),Pu=a("li"),Zce=a("strong"),hCo=o("bert"),pCo=o(" \u2014 "),dD=a("a"),_Co=o("BertForPreTraining"),uCo=o(" (BERT model)"),bCo=l(),Bu=a("li"),efe=a("strong"),vCo=o("big_bird"),FCo=o(" \u2014 "),cD=a("a"),TCo=o("BigBirdForPreTraining"),MCo=o(" (BigBird model)"),ECo=l(),Iu=a("li"),ofe=a("strong"),CCo=o("bloom"),wCo=o(" \u2014 "),fD=a("a"),ACo=o("BloomForCausalLM"),LCo=o(" (BLOOM model)"),yCo=l(),Nu=a("li"),rfe=a("strong"),xCo=o("camembert"),$Co=o(" \u2014 "),mD=a("a"),kCo=o("CamembertForMaskedLM"),SCo=o(" (CamemBERT model)"),RCo=l(),qu=a("li"),tfe=a("strong"),PCo=o("ctrl"),BCo=o(" \u2014 "),gD=a("a"),ICo=o("CTRLLMHeadModel"),NCo=o(" (CTRL model)"),qCo=l(),ju=a("li"),afe=a("strong"),jCo=o("data2vec-text"),DCo=o(" \u2014 "),hD=a("a"),GCo=o("Data2VecTextForMaskedLM"),OCo=o(" (Data2VecText model)"),VCo=l(),Du=a("li"),nfe=a("strong"),XCo=o("deberta"),zCo=o(" \u2014 "),pD=a("a"),QCo=o("DebertaForMaskedLM"),WCo=o(" (DeBERTa model)"),HCo=l(),Gu=a("li"),sfe=a("strong"),UCo=o("deberta-v2"),JCo=o(" \u2014 "),_D=a("a"),YCo=o("DebertaV2ForMaskedLM"),KCo=o(" (DeBERTa-v2 model)"),ZCo=l(),Ou=a("li"),lfe=a("strong"),e5o=o("distilbert"),o5o=o(" \u2014 "),uD=a("a"),r5o=o("DistilBertForMaskedLM"),t5o=o(" (DistilBERT model)"),a5o=l(),Vu=a("li"),ife=a("strong"),n5o=o("electra"),s5o=o(" \u2014 "),bD=a("a"),l5o=o("ElectraForPreTraining"),i5o=o(" (ELECTRA model)"),d5o=l(),Xu=a("li"),dfe=a("strong"),c5o=o("flaubert"),f5o=o(" \u2014 "),vD=a("a"),m5o=o("FlaubertWithLMHeadModel"),g5o=o(" (FlauBERT model)"),h5o=l(),zu=a("li"),cfe=a("strong"),p5o=o("flava"),_5o=o(" \u2014 "),FD=a("a"),u5o=o("FlavaForPreTraining"),b5o=o(" (FLAVA model)"),v5o=l(),Qu=a("li"),ffe=a("strong"),F5o=o("fnet"),T5o=o(" \u2014 "),TD=a("a"),M5o=o("FNetForPreTraining"),E5o=o(" (FNet model)"),C5o=l(),Wu=a("li"),mfe=a("strong"),w5o=o("fsmt"),A5o=o(" \u2014 "),MD=a("a"),L5o=o("FSMTForConditionalGeneration"),y5o=o(" (FairSeq Machine-Translation model)"),x5o=l(),Hu=a("li"),gfe=a("strong"),$5o=o("funnel"),k5o=o(" \u2014 "),ED=a("a"),S5o=o("FunnelForPreTraining"),R5o=o(" (Funnel Transformer model)"),P5o=l(),Uu=a("li"),hfe=a("strong"),B5o=o("gpt2"),I5o=o(" \u2014 "),CD=a("a"),N5o=o("GPT2LMHeadModel"),q5o=o(" (OpenAI GPT-2 model)"),j5o=l(),Ju=a("li"),pfe=a("strong"),D5o=o("ibert"),G5o=o(" \u2014 "),wD=a("a"),O5o=o("IBertForMaskedLM"),V5o=o(" (I-BERT model)"),X5o=l(),Yu=a("li"),_fe=a("strong"),z5o=o("layoutlm"),Q5o=o(" \u2014 "),AD=a("a"),W5o=o("LayoutLMForMaskedLM"),H5o=o(" (LayoutLM model)"),U5o=l(),Ku=a("li"),ufe=a("strong"),J5o=o("longformer"),Y5o=o(" \u2014 "),LD=a("a"),K5o=o("LongformerForMaskedLM"),Z5o=o(" (Longformer model)"),e3o=l(),Zu=a("li"),bfe=a("strong"),o3o=o("lxmert"),r3o=o(" \u2014 "),yD=a("a"),t3o=o("LxmertForPreTraining"),a3o=o(" (LXMERT model)"),n3o=l(),e1=a("li"),vfe=a("strong"),s3o=o("megatron-bert"),l3o=o(" \u2014 "),xD=a("a"),i3o=o("MegatronBertForPreTraining"),d3o=o(" (Megatron-BERT model)"),c3o=l(),o1=a("li"),Ffe=a("strong"),f3o=o("mobilebert"),m3o=o(" \u2014 "),$D=a("a"),g3o=o("MobileBertForPreTraining"),h3o=o(" (MobileBERT model)"),p3o=l(),r1=a("li"),Tfe=a("strong"),_3o=o("mpnet"),u3o=o(" \u2014 "),kD=a("a"),b3o=o("MPNetForMaskedLM"),v3o=o(" (MPNet model)"),F3o=l(),t1=a("li"),Mfe=a("strong"),T3o=o("nezha"),M3o=o(" \u2014 "),SD=a("a"),E3o=o("NezhaForPreTraining"),C3o=o(" (Nezha model)"),w3o=l(),a1=a("li"),Efe=a("strong"),A3o=o("openai-gpt"),L3o=o(" \u2014 "),RD=a("a"),y3o=o("OpenAIGPTLMHeadModel"),x3o=o(" (OpenAI GPT model)"),$3o=l(),n1=a("li"),Cfe=a("strong"),k3o=o("retribert"),S3o=o(" \u2014 "),PD=a("a"),R3o=o("RetriBertModel"),P3o=o(" (RetriBERT model)"),B3o=l(),s1=a("li"),wfe=a("strong"),I3o=o("roberta"),N3o=o(" \u2014 "),BD=a("a"),q3o=o("RobertaForMaskedLM"),j3o=o(" (RoBERTa model)"),D3o=l(),l1=a("li"),Afe=a("strong"),G3o=o("splinter"),O3o=o(" \u2014 "),ID=a("a"),V3o=o("SplinterForPreTraining"),X3o=o(" (Splinter model)"),z3o=l(),i1=a("li"),Lfe=a("strong"),Q3o=o("squeezebert"),W3o=o(" \u2014 "),ND=a("a"),H3o=o("SqueezeBertForMaskedLM"),U3o=o(" (SqueezeBERT model)"),J3o=l(),d1=a("li"),yfe=a("strong"),Y3o=o("t5"),K3o=o(" \u2014 "),qD=a("a"),Z3o=o("T5ForConditionalGeneration"),e0o=o(" (T5 model)"),o0o=l(),c1=a("li"),xfe=a("strong"),r0o=o("tapas"),t0o=o(" \u2014 "),jD=a("a"),a0o=o("TapasForMaskedLM"),n0o=o(" (TAPAS model)"),s0o=l(),f1=a("li"),$fe=a("strong"),l0o=o("transfo-xl"),i0o=o(" \u2014 "),DD=a("a"),d0o=o("TransfoXLLMHeadModel"),c0o=o(" (Transformer-XL model)"),f0o=l(),m1=a("li"),kfe=a("strong"),m0o=o("unispeech"),g0o=o(" \u2014 "),GD=a("a"),h0o=o("UniSpeechForPreTraining"),p0o=o(" (UniSpeech model)"),_0o=l(),g1=a("li"),Sfe=a("strong"),u0o=o("unispeech-sat"),b0o=o(" \u2014 "),OD=a("a"),v0o=o("UniSpeechSatForPreTraining"),F0o=o(" (UniSpeechSat model)"),T0o=l(),h1=a("li"),Rfe=a("strong"),M0o=o("visual_bert"),E0o=o(" \u2014 "),VD=a("a"),C0o=o("VisualBertForPreTraining"),w0o=o(" (VisualBERT model)"),A0o=l(),p1=a("li"),Pfe=a("strong"),L0o=o("vit_mae"),y0o=o(" \u2014 "),XD=a("a"),x0o=o("ViTMAEForPreTraining"),$0o=o(" (ViTMAE model)"),k0o=l(),_1=a("li"),Bfe=a("strong"),S0o=o("wav2vec2"),R0o=o(" \u2014 "),zD=a("a"),P0o=o("Wav2Vec2ForPreTraining"),B0o=o(" (Wav2Vec2 model)"),I0o=l(),u1=a("li"),Ife=a("strong"),N0o=o("wav2vec2-conformer"),q0o=o(" \u2014 "),QD=a("a"),j0o=o("Wav2Vec2ConformerForPreTraining"),D0o=o(" (Wav2Vec2-Conformer model)"),G0o=l(),b1=a("li"),Nfe=a("strong"),O0o=o("xlm"),V0o=o(" \u2014 "),WD=a("a"),X0o=o("XLMWithLMHeadModel"),z0o=o(" (XLM model)"),Q0o=l(),v1=a("li"),qfe=a("strong"),W0o=o("xlm-roberta"),H0o=o(" \u2014 "),HD=a("a"),U0o=o("XLMRobertaForMaskedLM"),J0o=o(" (XLM-RoBERTa model)"),Y0o=l(),F1=a("li"),jfe=a("strong"),K0o=o("xlm-roberta-xl"),Z0o=o(" \u2014 "),UD=a("a"),ewo=o("XLMRobertaXLForMaskedLM"),owo=o(" (XLM-RoBERTa-XL model)"),rwo=l(),T1=a("li"),Dfe=a("strong"),two=o("xlnet"),awo=o(" \u2014 "),JD=a("a"),nwo=o("XLNetLMHeadModel"),swo=o(" (XLNet model)"),lwo=l(),M1=a("p"),iwo=o("The model is set in evaluation mode by default using "),Gfe=a("code"),dwo=o("model.eval()"),cwo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ofe=a("code"),fwo=o("model.train()"),mwo=l(),F(E1.$$.fragment),rOe=l(),Gi=a("h2"),C1=a("a"),Vfe=a("span"),F(fA.$$.fragment),gwo=l(),Xfe=a("span"),hwo=o("AutoModelForCausalLM"),tOe=l(),ko=a("div"),F(mA.$$.fragment),pwo=l(),Oi=a("p"),_wo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),YD=a("a"),uwo=o("from_pretrained()"),bwo=o(" class method or the "),KD=a("a"),vwo=o("from_config()"),Fwo=o(` class
method.`),Two=l(),gA=a("p"),Mwo=o("This class cannot be instantiated directly using "),zfe=a("code"),Ewo=o("__init__()"),Cwo=o(" (throws an error)."),wwo=l(),lt=a("div"),F(hA.$$.fragment),Awo=l(),Qfe=a("p"),Lwo=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ywo=l(),Vi=a("p"),xwo=o(`Note:
Loading a model from its configuration file does `),Wfe=a("strong"),$wo=o("not"),kwo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),ZD=a("a"),Swo=o("from_pretrained()"),Rwo=o(" to load the model weights."),Pwo=l(),F(w1.$$.fragment),Bwo=l(),Ke=a("div"),F(pA.$$.fragment),Iwo=l(),Hfe=a("p"),Nwo=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),qwo=l(),Ba=a("p"),jwo=o("The model class to instantiate is selected based on the "),Ufe=a("code"),Dwo=o("model_type"),Gwo=o(` property of the config object (either
passed as an argument or loaded from `),Jfe=a("code"),Owo=o("pretrained_model_name_or_path"),Vwo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yfe=a("code"),Xwo=o("pretrained_model_name_or_path"),zwo=o(":"),Qwo=l(),z=a("ul"),A1=a("li"),Kfe=a("strong"),Wwo=o("bart"),Hwo=o(" \u2014 "),eG=a("a"),Uwo=o("BartForCausalLM"),Jwo=o(" (BART model)"),Ywo=l(),L1=a("li"),Zfe=a("strong"),Kwo=o("bert"),Zwo=o(" \u2014 "),oG=a("a"),eAo=o("BertLMHeadModel"),oAo=o(" (BERT model)"),rAo=l(),y1=a("li"),eme=a("strong"),tAo=o("bert-generation"),aAo=o(" \u2014 "),rG=a("a"),nAo=o("BertGenerationDecoder"),sAo=o(" (Bert Generation model)"),lAo=l(),x1=a("li"),ome=a("strong"),iAo=o("big_bird"),dAo=o(" \u2014 "),tG=a("a"),cAo=o("BigBirdForCausalLM"),fAo=o(" (BigBird model)"),mAo=l(),$1=a("li"),rme=a("strong"),gAo=o("bigbird_pegasus"),hAo=o(" \u2014 "),aG=a("a"),pAo=o("BigBirdPegasusForCausalLM"),_Ao=o(" (BigBird-Pegasus model)"),uAo=l(),k1=a("li"),tme=a("strong"),bAo=o("blenderbot"),vAo=o(" \u2014 "),nG=a("a"),FAo=o("BlenderbotForCausalLM"),TAo=o(" (Blenderbot model)"),MAo=l(),S1=a("li"),ame=a("strong"),EAo=o("blenderbot-small"),CAo=o(" \u2014 "),sG=a("a"),wAo=o("BlenderbotSmallForCausalLM"),AAo=o(" (BlenderbotSmall model)"),LAo=l(),R1=a("li"),nme=a("strong"),yAo=o("bloom"),xAo=o(" \u2014 "),lG=a("a"),$Ao=o("BloomForCausalLM"),kAo=o(" (BLOOM model)"),SAo=l(),P1=a("li"),sme=a("strong"),RAo=o("camembert"),PAo=o(" \u2014 "),iG=a("a"),BAo=o("CamembertForCausalLM"),IAo=o(" (CamemBERT model)"),NAo=l(),B1=a("li"),lme=a("strong"),qAo=o("ctrl"),jAo=o(" \u2014 "),dG=a("a"),DAo=o("CTRLLMHeadModel"),GAo=o(" (CTRL model)"),OAo=l(),I1=a("li"),ime=a("strong"),VAo=o("data2vec-text"),XAo=o(" \u2014 "),cG=a("a"),zAo=o("Data2VecTextForCausalLM"),QAo=o(" (Data2VecText model)"),WAo=l(),N1=a("li"),dme=a("strong"),HAo=o("electra"),UAo=o(" \u2014 "),fG=a("a"),JAo=o("ElectraForCausalLM"),YAo=o(" (ELECTRA model)"),KAo=l(),q1=a("li"),cme=a("strong"),ZAo=o("gpt2"),eLo=o(" \u2014 "),mG=a("a"),oLo=o("GPT2LMHeadModel"),rLo=o(" (OpenAI GPT-2 model)"),tLo=l(),j1=a("li"),fme=a("strong"),aLo=o("gpt_neo"),nLo=o(" \u2014 "),gG=a("a"),sLo=o("GPTNeoForCausalLM"),lLo=o(" (GPT Neo model)"),iLo=l(),D1=a("li"),mme=a("strong"),dLo=o("gpt_neox"),cLo=o(" \u2014 "),hG=a("a"),fLo=o("GPTNeoXForCausalLM"),mLo=o(" (GPT NeoX model)"),gLo=l(),G1=a("li"),gme=a("strong"),hLo=o("gptj"),pLo=o(" \u2014 "),pG=a("a"),_Lo=o("GPTJForCausalLM"),uLo=o(" (GPT-J model)"),bLo=l(),O1=a("li"),hme=a("strong"),vLo=o("marian"),FLo=o(" \u2014 "),_G=a("a"),TLo=o("MarianForCausalLM"),MLo=o(" (Marian model)"),ELo=l(),V1=a("li"),pme=a("strong"),CLo=o("mbart"),wLo=o(" \u2014 "),uG=a("a"),ALo=o("MBartForCausalLM"),LLo=o(" (mBART model)"),yLo=l(),X1=a("li"),_me=a("strong"),xLo=o("megatron-bert"),$Lo=o(" \u2014 "),bG=a("a"),kLo=o("MegatronBertForCausalLM"),SLo=o(" (Megatron-BERT model)"),RLo=l(),z1=a("li"),ume=a("strong"),PLo=o("openai-gpt"),BLo=o(" \u2014 "),vG=a("a"),ILo=o("OpenAIGPTLMHeadModel"),NLo=o(" (OpenAI GPT model)"),qLo=l(),Q1=a("li"),bme=a("strong"),jLo=o("opt"),DLo=o(" \u2014 "),FG=a("a"),GLo=o("OPTForCausalLM"),OLo=o(" (OPT model)"),VLo=l(),W1=a("li"),vme=a("strong"),XLo=o("pegasus"),zLo=o(" \u2014 "),TG=a("a"),QLo=o("PegasusForCausalLM"),WLo=o(" (Pegasus model)"),HLo=l(),H1=a("li"),Fme=a("strong"),ULo=o("plbart"),JLo=o(" \u2014 "),MG=a("a"),YLo=o("PLBartForCausalLM"),KLo=o(" (PLBart model)"),ZLo=l(),U1=a("li"),Tme=a("strong"),eyo=o("prophetnet"),oyo=o(" \u2014 "),EG=a("a"),ryo=o("ProphetNetForCausalLM"),tyo=o(" (ProphetNet model)"),ayo=l(),J1=a("li"),Mme=a("strong"),nyo=o("qdqbert"),syo=o(" \u2014 "),CG=a("a"),lyo=o("QDQBertLMHeadModel"),iyo=o(" (QDQBert model)"),dyo=l(),Y1=a("li"),Eme=a("strong"),cyo=o("reformer"),fyo=o(" \u2014 "),wG=a("a"),myo=o("ReformerModelWithLMHead"),gyo=o(" (Reformer model)"),hyo=l(),K1=a("li"),Cme=a("strong"),pyo=o("rembert"),_yo=o(" \u2014 "),AG=a("a"),uyo=o("RemBertForCausalLM"),byo=o(" (RemBERT model)"),vyo=l(),Z1=a("li"),wme=a("strong"),Fyo=o("roberta"),Tyo=o(" \u2014 "),LG=a("a"),Myo=o("RobertaForCausalLM"),Eyo=o(" (RoBERTa model)"),Cyo=l(),e2=a("li"),Ame=a("strong"),wyo=o("roformer"),Ayo=o(" \u2014 "),yG=a("a"),Lyo=o("RoFormerForCausalLM"),yyo=o(" (RoFormer model)"),xyo=l(),o2=a("li"),Lme=a("strong"),$yo=o("speech_to_text_2"),kyo=o(" \u2014 "),xG=a("a"),Syo=o("Speech2Text2ForCausalLM"),Ryo=o(" (Speech2Text2 model)"),Pyo=l(),r2=a("li"),yme=a("strong"),Byo=o("transfo-xl"),Iyo=o(" \u2014 "),$G=a("a"),Nyo=o("TransfoXLLMHeadModel"),qyo=o(" (Transformer-XL model)"),jyo=l(),t2=a("li"),xme=a("strong"),Dyo=o("trocr"),Gyo=o(" \u2014 "),kG=a("a"),Oyo=o("TrOCRForCausalLM"),Vyo=o(" (TrOCR model)"),Xyo=l(),a2=a("li"),$me=a("strong"),zyo=o("xglm"),Qyo=o(" \u2014 "),SG=a("a"),Wyo=o("XGLMForCausalLM"),Hyo=o(" (XGLM model)"),Uyo=l(),n2=a("li"),kme=a("strong"),Jyo=o("xlm"),Yyo=o(" \u2014 "),RG=a("a"),Kyo=o("XLMWithLMHeadModel"),Zyo=o(" (XLM model)"),exo=l(),s2=a("li"),Sme=a("strong"),oxo=o("xlm-prophetnet"),rxo=o(" \u2014 "),PG=a("a"),txo=o("XLMProphetNetForCausalLM"),axo=o(" (XLM-ProphetNet model)"),nxo=l(),l2=a("li"),Rme=a("strong"),sxo=o("xlm-roberta"),lxo=o(" \u2014 "),BG=a("a"),ixo=o("XLMRobertaForCausalLM"),dxo=o(" (XLM-RoBERTa model)"),cxo=l(),i2=a("li"),Pme=a("strong"),fxo=o("xlm-roberta-xl"),mxo=o(" \u2014 "),IG=a("a"),gxo=o("XLMRobertaXLForCausalLM"),hxo=o(" (XLM-RoBERTa-XL model)"),pxo=l(),d2=a("li"),Bme=a("strong"),_xo=o("xlnet"),uxo=o(" \u2014 "),NG=a("a"),bxo=o("XLNetLMHeadModel"),vxo=o(" (XLNet model)"),Fxo=l(),c2=a("p"),Txo=o("The model is set in evaluation mode by default using "),Ime=a("code"),Mxo=o("model.eval()"),Exo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nme=a("code"),Cxo=o("model.train()"),wxo=l(),F(f2.$$.fragment),aOe=l(),Xi=a("h2"),m2=a("a"),qme=a("span"),F(_A.$$.fragment),Axo=l(),jme=a("span"),Lxo=o("AutoModelForMaskedLM"),nOe=l(),So=a("div"),F(uA.$$.fragment),yxo=l(),zi=a("p"),xxo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),qG=a("a"),$xo=o("from_pretrained()"),kxo=o(" class method or the "),jG=a("a"),Sxo=o("from_config()"),Rxo=o(` class
method.`),Pxo=l(),bA=a("p"),Bxo=o("This class cannot be instantiated directly using "),Dme=a("code"),Ixo=o("__init__()"),Nxo=o(" (throws an error)."),qxo=l(),it=a("div"),F(vA.$$.fragment),jxo=l(),Gme=a("p"),Dxo=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),Gxo=l(),Qi=a("p"),Oxo=o(`Note:
Loading a model from its configuration file does `),Ome=a("strong"),Vxo=o("not"),Xxo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DG=a("a"),zxo=o("from_pretrained()"),Qxo=o(" to load the model weights."),Wxo=l(),F(g2.$$.fragment),Hxo=l(),Ze=a("div"),F(FA.$$.fragment),Uxo=l(),Vme=a("p"),Jxo=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),Yxo=l(),Ia=a("p"),Kxo=o("The model class to instantiate is selected based on the "),Xme=a("code"),Zxo=o("model_type"),e$o=o(` property of the config object (either
passed as an argument or loaded from `),zme=a("code"),o$o=o("pretrained_model_name_or_path"),r$o=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qme=a("code"),t$o=o("pretrained_model_name_or_path"),a$o=o(":"),n$o=l(),Q=a("ul"),h2=a("li"),Wme=a("strong"),s$o=o("albert"),l$o=o(" \u2014 "),GG=a("a"),i$o=o("AlbertForMaskedLM"),d$o=o(" (ALBERT model)"),c$o=l(),p2=a("li"),Hme=a("strong"),f$o=o("bart"),m$o=o(" \u2014 "),OG=a("a"),g$o=o("BartForConditionalGeneration"),h$o=o(" (BART model)"),p$o=l(),_2=a("li"),Ume=a("strong"),_$o=o("bert"),u$o=o(" \u2014 "),VG=a("a"),b$o=o("BertForMaskedLM"),v$o=o(" (BERT model)"),F$o=l(),u2=a("li"),Jme=a("strong"),T$o=o("big_bird"),M$o=o(" \u2014 "),XG=a("a"),E$o=o("BigBirdForMaskedLM"),C$o=o(" (BigBird model)"),w$o=l(),b2=a("li"),Yme=a("strong"),A$o=o("camembert"),L$o=o(" \u2014 "),zG=a("a"),y$o=o("CamembertForMaskedLM"),x$o=o(" (CamemBERT model)"),$$o=l(),v2=a("li"),Kme=a("strong"),k$o=o("convbert"),S$o=o(" \u2014 "),QG=a("a"),R$o=o("ConvBertForMaskedLM"),P$o=o(" (ConvBERT model)"),B$o=l(),F2=a("li"),Zme=a("strong"),I$o=o("data2vec-text"),N$o=o(" \u2014 "),WG=a("a"),q$o=o("Data2VecTextForMaskedLM"),j$o=o(" (Data2VecText model)"),D$o=l(),T2=a("li"),ege=a("strong"),G$o=o("deberta"),O$o=o(" \u2014 "),HG=a("a"),V$o=o("DebertaForMaskedLM"),X$o=o(" (DeBERTa model)"),z$o=l(),M2=a("li"),oge=a("strong"),Q$o=o("deberta-v2"),W$o=o(" \u2014 "),UG=a("a"),H$o=o("DebertaV2ForMaskedLM"),U$o=o(" (DeBERTa-v2 model)"),J$o=l(),E2=a("li"),rge=a("strong"),Y$o=o("distilbert"),K$o=o(" \u2014 "),JG=a("a"),Z$o=o("DistilBertForMaskedLM"),eko=o(" (DistilBERT model)"),oko=l(),C2=a("li"),tge=a("strong"),rko=o("electra"),tko=o(" \u2014 "),YG=a("a"),ako=o("ElectraForMaskedLM"),nko=o(" (ELECTRA model)"),sko=l(),w2=a("li"),age=a("strong"),lko=o("flaubert"),iko=o(" \u2014 "),KG=a("a"),dko=o("FlaubertWithLMHeadModel"),cko=o(" (FlauBERT model)"),fko=l(),A2=a("li"),nge=a("strong"),mko=o("fnet"),gko=o(" \u2014 "),ZG=a("a"),hko=o("FNetForMaskedLM"),pko=o(" (FNet model)"),_ko=l(),L2=a("li"),sge=a("strong"),uko=o("funnel"),bko=o(" \u2014 "),eO=a("a"),vko=o("FunnelForMaskedLM"),Fko=o(" (Funnel Transformer model)"),Tko=l(),y2=a("li"),lge=a("strong"),Mko=o("ibert"),Eko=o(" \u2014 "),oO=a("a"),Cko=o("IBertForMaskedLM"),wko=o(" (I-BERT model)"),Ako=l(),x2=a("li"),ige=a("strong"),Lko=o("layoutlm"),yko=o(" \u2014 "),rO=a("a"),xko=o("LayoutLMForMaskedLM"),$ko=o(" (LayoutLM model)"),kko=l(),$2=a("li"),dge=a("strong"),Sko=o("longformer"),Rko=o(" \u2014 "),tO=a("a"),Pko=o("LongformerForMaskedLM"),Bko=o(" (Longformer model)"),Iko=l(),k2=a("li"),cge=a("strong"),Nko=o("luke"),qko=o(" \u2014 "),aO=a("a"),jko=o("LukeForMaskedLM"),Dko=o(" (LUKE model)"),Gko=l(),S2=a("li"),fge=a("strong"),Oko=o("mbart"),Vko=o(" \u2014 "),nO=a("a"),Xko=o("MBartForConditionalGeneration"),zko=o(" (mBART model)"),Qko=l(),R2=a("li"),mge=a("strong"),Wko=o("megatron-bert"),Hko=o(" \u2014 "),sO=a("a"),Uko=o("MegatronBertForMaskedLM"),Jko=o(" (Megatron-BERT model)"),Yko=l(),P2=a("li"),gge=a("strong"),Kko=o("mobilebert"),Zko=o(" \u2014 "),lO=a("a"),eSo=o("MobileBertForMaskedLM"),oSo=o(" (MobileBERT model)"),rSo=l(),B2=a("li"),hge=a("strong"),tSo=o("mpnet"),aSo=o(" \u2014 "),iO=a("a"),nSo=o("MPNetForMaskedLM"),sSo=o(" (MPNet model)"),lSo=l(),I2=a("li"),pge=a("strong"),iSo=o("nezha"),dSo=o(" \u2014 "),dO=a("a"),cSo=o("NezhaForMaskedLM"),fSo=o(" (Nezha model)"),mSo=l(),N2=a("li"),_ge=a("strong"),gSo=o("nystromformer"),hSo=o(" \u2014 "),cO=a("a"),pSo=o("NystromformerForMaskedLM"),_So=o(" (Nystr\xF6mformer model)"),uSo=l(),q2=a("li"),uge=a("strong"),bSo=o("perceiver"),vSo=o(" \u2014 "),fO=a("a"),FSo=o("PerceiverForMaskedLM"),TSo=o(" (Perceiver model)"),MSo=l(),j2=a("li"),bge=a("strong"),ESo=o("qdqbert"),CSo=o(" \u2014 "),mO=a("a"),wSo=o("QDQBertForMaskedLM"),ASo=o(" (QDQBert model)"),LSo=l(),D2=a("li"),vge=a("strong"),ySo=o("reformer"),xSo=o(" \u2014 "),gO=a("a"),$So=o("ReformerForMaskedLM"),kSo=o(" (Reformer model)"),SSo=l(),G2=a("li"),Fge=a("strong"),RSo=o("rembert"),PSo=o(" \u2014 "),hO=a("a"),BSo=o("RemBertForMaskedLM"),ISo=o(" (RemBERT model)"),NSo=l(),O2=a("li"),Tge=a("strong"),qSo=o("roberta"),jSo=o(" \u2014 "),pO=a("a"),DSo=o("RobertaForMaskedLM"),GSo=o(" (RoBERTa model)"),OSo=l(),V2=a("li"),Mge=a("strong"),VSo=o("roformer"),XSo=o(" \u2014 "),_O=a("a"),zSo=o("RoFormerForMaskedLM"),QSo=o(" (RoFormer model)"),WSo=l(),X2=a("li"),Ege=a("strong"),HSo=o("squeezebert"),USo=o(" \u2014 "),uO=a("a"),JSo=o("SqueezeBertForMaskedLM"),YSo=o(" (SqueezeBERT model)"),KSo=l(),z2=a("li"),Cge=a("strong"),ZSo=o("tapas"),eRo=o(" \u2014 "),bO=a("a"),oRo=o("TapasForMaskedLM"),rRo=o(" (TAPAS model)"),tRo=l(),Q2=a("li"),wge=a("strong"),aRo=o("wav2vec2"),nRo=o(" \u2014 "),Age=a("code"),sRo=o("Wav2Vec2ForMaskedLM"),lRo=o(" (Wav2Vec2 model)"),iRo=l(),W2=a("li"),Lge=a("strong"),dRo=o("xlm"),cRo=o(" \u2014 "),vO=a("a"),fRo=o("XLMWithLMHeadModel"),mRo=o(" (XLM model)"),gRo=l(),H2=a("li"),yge=a("strong"),hRo=o("xlm-roberta"),pRo=o(" \u2014 "),FO=a("a"),_Ro=o("XLMRobertaForMaskedLM"),uRo=o(" (XLM-RoBERTa model)"),bRo=l(),U2=a("li"),xge=a("strong"),vRo=o("xlm-roberta-xl"),FRo=o(" \u2014 "),TO=a("a"),TRo=o("XLMRobertaXLForMaskedLM"),MRo=o(" (XLM-RoBERTa-XL model)"),ERo=l(),J2=a("li"),$ge=a("strong"),CRo=o("yoso"),wRo=o(" \u2014 "),MO=a("a"),ARo=o("YosoForMaskedLM"),LRo=o(" (YOSO model)"),yRo=l(),Y2=a("p"),xRo=o("The model is set in evaluation mode by default using "),kge=a("code"),$Ro=o("model.eval()"),kRo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sge=a("code"),SRo=o("model.train()"),RRo=l(),F(K2.$$.fragment),sOe=l(),Wi=a("h2"),Z2=a("a"),Rge=a("span"),F(TA.$$.fragment),PRo=l(),Pge=a("span"),BRo=o("AutoModelForSeq2SeqLM"),lOe=l(),Ro=a("div"),F(MA.$$.fragment),IRo=l(),Hi=a("p"),NRo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),EO=a("a"),qRo=o("from_pretrained()"),jRo=o(" class method or the "),CO=a("a"),DRo=o("from_config()"),GRo=o(` class
method.`),ORo=l(),EA=a("p"),VRo=o("This class cannot be instantiated directly using "),Bge=a("code"),XRo=o("__init__()"),zRo=o(" (throws an error)."),QRo=l(),dt=a("div"),F(CA.$$.fragment),WRo=l(),Ige=a("p"),HRo=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),URo=l(),Ui=a("p"),JRo=o(`Note:
Loading a model from its configuration file does `),Nge=a("strong"),YRo=o("not"),KRo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wO=a("a"),ZRo=o("from_pretrained()"),ePo=o(" to load the model weights."),oPo=l(),F(eb.$$.fragment),rPo=l(),eo=a("div"),F(wA.$$.fragment),tPo=l(),qge=a("p"),aPo=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),nPo=l(),Na=a("p"),sPo=o("The model class to instantiate is selected based on the "),jge=a("code"),lPo=o("model_type"),iPo=o(` property of the config object (either
passed as an argument or loaded from `),Dge=a("code"),dPo=o("pretrained_model_name_or_path"),cPo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gge=a("code"),fPo=o("pretrained_model_name_or_path"),mPo=o(":"),gPo=l(),pe=a("ul"),ob=a("li"),Oge=a("strong"),hPo=o("bart"),pPo=o(" \u2014 "),AO=a("a"),_Po=o("BartForConditionalGeneration"),uPo=o(" (BART model)"),bPo=l(),rb=a("li"),Vge=a("strong"),vPo=o("bigbird_pegasus"),FPo=o(" \u2014 "),LO=a("a"),TPo=o("BigBirdPegasusForConditionalGeneration"),MPo=o(" (BigBird-Pegasus model)"),EPo=l(),tb=a("li"),Xge=a("strong"),CPo=o("blenderbot"),wPo=o(" \u2014 "),yO=a("a"),APo=o("BlenderbotForConditionalGeneration"),LPo=o(" (Blenderbot model)"),yPo=l(),ab=a("li"),zge=a("strong"),xPo=o("blenderbot-small"),$Po=o(" \u2014 "),xO=a("a"),kPo=o("BlenderbotSmallForConditionalGeneration"),SPo=o(" (BlenderbotSmall model)"),RPo=l(),nb=a("li"),Qge=a("strong"),PPo=o("encoder-decoder"),BPo=o(" \u2014 "),$O=a("a"),IPo=o("EncoderDecoderModel"),NPo=o(" (Encoder decoder model)"),qPo=l(),sb=a("li"),Wge=a("strong"),jPo=o("fsmt"),DPo=o(" \u2014 "),kO=a("a"),GPo=o("FSMTForConditionalGeneration"),OPo=o(" (FairSeq Machine-Translation model)"),VPo=l(),lb=a("li"),Hge=a("strong"),XPo=o("led"),zPo=o(" \u2014 "),SO=a("a"),QPo=o("LEDForConditionalGeneration"),WPo=o(" (LED model)"),HPo=l(),ib=a("li"),Uge=a("strong"),UPo=o("longt5"),JPo=o(" \u2014 "),RO=a("a"),YPo=o("LongT5ForConditionalGeneration"),KPo=o(" (LongT5 model)"),ZPo=l(),db=a("li"),Jge=a("strong"),eBo=o("m2m_100"),oBo=o(" \u2014 "),PO=a("a"),rBo=o("M2M100ForConditionalGeneration"),tBo=o(" (M2M100 model)"),aBo=l(),cb=a("li"),Yge=a("strong"),nBo=o("marian"),sBo=o(" \u2014 "),BO=a("a"),lBo=o("MarianMTModel"),iBo=o(" (Marian model)"),dBo=l(),fb=a("li"),Kge=a("strong"),cBo=o("mbart"),fBo=o(" \u2014 "),IO=a("a"),mBo=o("MBartForConditionalGeneration"),gBo=o(" (mBART model)"),hBo=l(),mb=a("li"),Zge=a("strong"),pBo=o("mt5"),_Bo=o(" \u2014 "),NO=a("a"),uBo=o("MT5ForConditionalGeneration"),bBo=o(" (MT5 model)"),vBo=l(),gb=a("li"),ehe=a("strong"),FBo=o("pegasus"),TBo=o(" \u2014 "),qO=a("a"),MBo=o("PegasusForConditionalGeneration"),EBo=o(" (Pegasus model)"),CBo=l(),hb=a("li"),ohe=a("strong"),wBo=o("plbart"),ABo=o(" \u2014 "),jO=a("a"),LBo=o("PLBartForConditionalGeneration"),yBo=o(" (PLBart model)"),xBo=l(),pb=a("li"),rhe=a("strong"),$Bo=o("prophetnet"),kBo=o(" \u2014 "),DO=a("a"),SBo=o("ProphetNetForConditionalGeneration"),RBo=o(" (ProphetNet model)"),PBo=l(),_b=a("li"),the=a("strong"),BBo=o("t5"),IBo=o(" \u2014 "),GO=a("a"),NBo=o("T5ForConditionalGeneration"),qBo=o(" (T5 model)"),jBo=l(),ub=a("li"),ahe=a("strong"),DBo=o("xlm-prophetnet"),GBo=o(" \u2014 "),OO=a("a"),OBo=o("XLMProphetNetForConditionalGeneration"),VBo=o(" (XLM-ProphetNet model)"),XBo=l(),bb=a("p"),zBo=o("The model is set in evaluation mode by default using "),nhe=a("code"),QBo=o("model.eval()"),WBo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),she=a("code"),HBo=o("model.train()"),UBo=l(),F(vb.$$.fragment),iOe=l(),Ji=a("h2"),Fb=a("a"),lhe=a("span"),F(AA.$$.fragment),JBo=l(),ihe=a("span"),YBo=o("AutoModelForSequenceClassification"),dOe=l(),Po=a("div"),F(LA.$$.fragment),KBo=l(),Yi=a("p"),ZBo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),VO=a("a"),eIo=o("from_pretrained()"),oIo=o(" class method or the "),XO=a("a"),rIo=o("from_config()"),tIo=o(` class
method.`),aIo=l(),yA=a("p"),nIo=o("This class cannot be instantiated directly using "),dhe=a("code"),sIo=o("__init__()"),lIo=o(" (throws an error)."),iIo=l(),ct=a("div"),F(xA.$$.fragment),dIo=l(),che=a("p"),cIo=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),fIo=l(),Ki=a("p"),mIo=o(`Note:
Loading a model from its configuration file does `),fhe=a("strong"),gIo=o("not"),hIo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),zO=a("a"),pIo=o("from_pretrained()"),_Io=o(" to load the model weights."),uIo=l(),F(Tb.$$.fragment),bIo=l(),oo=a("div"),F($A.$$.fragment),vIo=l(),mhe=a("p"),FIo=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),TIo=l(),qa=a("p"),MIo=o("The model class to instantiate is selected based on the "),ghe=a("code"),EIo=o("model_type"),CIo=o(` property of the config object (either
passed as an argument or loaded from `),hhe=a("code"),wIo=o("pretrained_model_name_or_path"),AIo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),phe=a("code"),LIo=o("pretrained_model_name_or_path"),yIo=o(":"),xIo=l(),N=a("ul"),Mb=a("li"),_he=a("strong"),$Io=o("albert"),kIo=o(" \u2014 "),QO=a("a"),SIo=o("AlbertForSequenceClassification"),RIo=o(" (ALBERT model)"),PIo=l(),Eb=a("li"),uhe=a("strong"),BIo=o("bart"),IIo=o(" \u2014 "),WO=a("a"),NIo=o("BartForSequenceClassification"),qIo=o(" (BART model)"),jIo=l(),Cb=a("li"),bhe=a("strong"),DIo=o("bert"),GIo=o(" \u2014 "),HO=a("a"),OIo=o("BertForSequenceClassification"),VIo=o(" (BERT model)"),XIo=l(),wb=a("li"),vhe=a("strong"),zIo=o("big_bird"),QIo=o(" \u2014 "),UO=a("a"),WIo=o("BigBirdForSequenceClassification"),HIo=o(" (BigBird model)"),UIo=l(),Ab=a("li"),Fhe=a("strong"),JIo=o("bigbird_pegasus"),YIo=o(" \u2014 "),JO=a("a"),KIo=o("BigBirdPegasusForSequenceClassification"),ZIo=o(" (BigBird-Pegasus model)"),eNo=l(),Lb=a("li"),The=a("strong"),oNo=o("bloom"),rNo=o(" \u2014 "),YO=a("a"),tNo=o("BloomForSequenceClassification"),aNo=o(" (BLOOM model)"),nNo=l(),yb=a("li"),Mhe=a("strong"),sNo=o("camembert"),lNo=o(" \u2014 "),KO=a("a"),iNo=o("CamembertForSequenceClassification"),dNo=o(" (CamemBERT model)"),cNo=l(),xb=a("li"),Ehe=a("strong"),fNo=o("canine"),mNo=o(" \u2014 "),ZO=a("a"),gNo=o("CanineForSequenceClassification"),hNo=o(" (CANINE model)"),pNo=l(),$b=a("li"),Che=a("strong"),_No=o("convbert"),uNo=o(" \u2014 "),eV=a("a"),bNo=o("ConvBertForSequenceClassification"),vNo=o(" (ConvBERT model)"),FNo=l(),kb=a("li"),whe=a("strong"),TNo=o("ctrl"),MNo=o(" \u2014 "),oV=a("a"),ENo=o("CTRLForSequenceClassification"),CNo=o(" (CTRL model)"),wNo=l(),Sb=a("li"),Ahe=a("strong"),ANo=o("data2vec-text"),LNo=o(" \u2014 "),rV=a("a"),yNo=o("Data2VecTextForSequenceClassification"),xNo=o(" (Data2VecText model)"),$No=l(),Rb=a("li"),Lhe=a("strong"),kNo=o("deberta"),SNo=o(" \u2014 "),tV=a("a"),RNo=o("DebertaForSequenceClassification"),PNo=o(" (DeBERTa model)"),BNo=l(),Pb=a("li"),yhe=a("strong"),INo=o("deberta-v2"),NNo=o(" \u2014 "),aV=a("a"),qNo=o("DebertaV2ForSequenceClassification"),jNo=o(" (DeBERTa-v2 model)"),DNo=l(),Bb=a("li"),xhe=a("strong"),GNo=o("distilbert"),ONo=o(" \u2014 "),nV=a("a"),VNo=o("DistilBertForSequenceClassification"),XNo=o(" (DistilBERT model)"),zNo=l(),Ib=a("li"),$he=a("strong"),QNo=o("electra"),WNo=o(" \u2014 "),sV=a("a"),HNo=o("ElectraForSequenceClassification"),UNo=o(" (ELECTRA model)"),JNo=l(),Nb=a("li"),khe=a("strong"),YNo=o("flaubert"),KNo=o(" \u2014 "),lV=a("a"),ZNo=o("FlaubertForSequenceClassification"),eqo=o(" (FlauBERT model)"),oqo=l(),qb=a("li"),She=a("strong"),rqo=o("fnet"),tqo=o(" \u2014 "),iV=a("a"),aqo=o("FNetForSequenceClassification"),nqo=o(" (FNet model)"),sqo=l(),jb=a("li"),Rhe=a("strong"),lqo=o("funnel"),iqo=o(" \u2014 "),dV=a("a"),dqo=o("FunnelForSequenceClassification"),cqo=o(" (Funnel Transformer model)"),fqo=l(),Db=a("li"),Phe=a("strong"),mqo=o("gpt2"),gqo=o(" \u2014 "),cV=a("a"),hqo=o("GPT2ForSequenceClassification"),pqo=o(" (OpenAI GPT-2 model)"),_qo=l(),Gb=a("li"),Bhe=a("strong"),uqo=o("gpt_neo"),bqo=o(" \u2014 "),fV=a("a"),vqo=o("GPTNeoForSequenceClassification"),Fqo=o(" (GPT Neo model)"),Tqo=l(),Ob=a("li"),Ihe=a("strong"),Mqo=o("gptj"),Eqo=o(" \u2014 "),mV=a("a"),Cqo=o("GPTJForSequenceClassification"),wqo=o(" (GPT-J model)"),Aqo=l(),Vb=a("li"),Nhe=a("strong"),Lqo=o("ibert"),yqo=o(" \u2014 "),gV=a("a"),xqo=o("IBertForSequenceClassification"),$qo=o(" (I-BERT model)"),kqo=l(),Xb=a("li"),qhe=a("strong"),Sqo=o("layoutlm"),Rqo=o(" \u2014 "),hV=a("a"),Pqo=o("LayoutLMForSequenceClassification"),Bqo=o(" (LayoutLM model)"),Iqo=l(),zb=a("li"),jhe=a("strong"),Nqo=o("layoutlmv2"),qqo=o(" \u2014 "),pV=a("a"),jqo=o("LayoutLMv2ForSequenceClassification"),Dqo=o(" (LayoutLMv2 model)"),Gqo=l(),Qb=a("li"),Dhe=a("strong"),Oqo=o("layoutlmv3"),Vqo=o(" \u2014 "),_V=a("a"),Xqo=o("LayoutLMv3ForSequenceClassification"),zqo=o(" (LayoutLMv3 model)"),Qqo=l(),Wb=a("li"),Ghe=a("strong"),Wqo=o("led"),Hqo=o(" \u2014 "),uV=a("a"),Uqo=o("LEDForSequenceClassification"),Jqo=o(" (LED model)"),Yqo=l(),Hb=a("li"),Ohe=a("strong"),Kqo=o("longformer"),Zqo=o(" \u2014 "),bV=a("a"),ejo=o("LongformerForSequenceClassification"),ojo=o(" (Longformer model)"),rjo=l(),Ub=a("li"),Vhe=a("strong"),tjo=o("mbart"),ajo=o(" \u2014 "),vV=a("a"),njo=o("MBartForSequenceClassification"),sjo=o(" (mBART model)"),ljo=l(),Jb=a("li"),Xhe=a("strong"),ijo=o("megatron-bert"),djo=o(" \u2014 "),FV=a("a"),cjo=o("MegatronBertForSequenceClassification"),fjo=o(" (Megatron-BERT model)"),mjo=l(),Yb=a("li"),zhe=a("strong"),gjo=o("mobilebert"),hjo=o(" \u2014 "),TV=a("a"),pjo=o("MobileBertForSequenceClassification"),_jo=o(" (MobileBERT model)"),ujo=l(),Kb=a("li"),Qhe=a("strong"),bjo=o("mpnet"),vjo=o(" \u2014 "),MV=a("a"),Fjo=o("MPNetForSequenceClassification"),Tjo=o(" (MPNet model)"),Mjo=l(),Zb=a("li"),Whe=a("strong"),Ejo=o("nezha"),Cjo=o(" \u2014 "),EV=a("a"),wjo=o("NezhaForSequenceClassification"),Ajo=o(" (Nezha model)"),Ljo=l(),ev=a("li"),Hhe=a("strong"),yjo=o("nystromformer"),xjo=o(" \u2014 "),CV=a("a"),$jo=o("NystromformerForSequenceClassification"),kjo=o(" (Nystr\xF6mformer model)"),Sjo=l(),ov=a("li"),Uhe=a("strong"),Rjo=o("openai-gpt"),Pjo=o(" \u2014 "),wV=a("a"),Bjo=o("OpenAIGPTForSequenceClassification"),Ijo=o(" (OpenAI GPT model)"),Njo=l(),rv=a("li"),Jhe=a("strong"),qjo=o("perceiver"),jjo=o(" \u2014 "),AV=a("a"),Djo=o("PerceiverForSequenceClassification"),Gjo=o(" (Perceiver model)"),Ojo=l(),tv=a("li"),Yhe=a("strong"),Vjo=o("plbart"),Xjo=o(" \u2014 "),LV=a("a"),zjo=o("PLBartForSequenceClassification"),Qjo=o(" (PLBart model)"),Wjo=l(),av=a("li"),Khe=a("strong"),Hjo=o("qdqbert"),Ujo=o(" \u2014 "),yV=a("a"),Jjo=o("QDQBertForSequenceClassification"),Yjo=o(" (QDQBert model)"),Kjo=l(),nv=a("li"),Zhe=a("strong"),Zjo=o("reformer"),eDo=o(" \u2014 "),xV=a("a"),oDo=o("ReformerForSequenceClassification"),rDo=o(" (Reformer model)"),tDo=l(),sv=a("li"),epe=a("strong"),aDo=o("rembert"),nDo=o(" \u2014 "),$V=a("a"),sDo=o("RemBertForSequenceClassification"),lDo=o(" (RemBERT model)"),iDo=l(),lv=a("li"),ope=a("strong"),dDo=o("roberta"),cDo=o(" \u2014 "),kV=a("a"),fDo=o("RobertaForSequenceClassification"),mDo=o(" (RoBERTa model)"),gDo=l(),iv=a("li"),rpe=a("strong"),hDo=o("roformer"),pDo=o(" \u2014 "),SV=a("a"),_Do=o("RoFormerForSequenceClassification"),uDo=o(" (RoFormer model)"),bDo=l(),dv=a("li"),tpe=a("strong"),vDo=o("squeezebert"),FDo=o(" \u2014 "),RV=a("a"),TDo=o("SqueezeBertForSequenceClassification"),MDo=o(" (SqueezeBERT model)"),EDo=l(),cv=a("li"),ape=a("strong"),CDo=o("tapas"),wDo=o(" \u2014 "),PV=a("a"),ADo=o("TapasForSequenceClassification"),LDo=o(" (TAPAS model)"),yDo=l(),fv=a("li"),npe=a("strong"),xDo=o("transfo-xl"),$Do=o(" \u2014 "),BV=a("a"),kDo=o("TransfoXLForSequenceClassification"),SDo=o(" (Transformer-XL model)"),RDo=l(),mv=a("li"),spe=a("strong"),PDo=o("xlm"),BDo=o(" \u2014 "),IV=a("a"),IDo=o("XLMForSequenceClassification"),NDo=o(" (XLM model)"),qDo=l(),gv=a("li"),lpe=a("strong"),jDo=o("xlm-roberta"),DDo=o(" \u2014 "),NV=a("a"),GDo=o("XLMRobertaForSequenceClassification"),ODo=o(" (XLM-RoBERTa model)"),VDo=l(),hv=a("li"),ipe=a("strong"),XDo=o("xlm-roberta-xl"),zDo=o(" \u2014 "),qV=a("a"),QDo=o("XLMRobertaXLForSequenceClassification"),WDo=o(" (XLM-RoBERTa-XL model)"),HDo=l(),pv=a("li"),dpe=a("strong"),UDo=o("xlnet"),JDo=o(" \u2014 "),jV=a("a"),YDo=o("XLNetForSequenceClassification"),KDo=o(" (XLNet model)"),ZDo=l(),_v=a("li"),cpe=a("strong"),eGo=o("yoso"),oGo=o(" \u2014 "),DV=a("a"),rGo=o("YosoForSequenceClassification"),tGo=o(" (YOSO model)"),aGo=l(),uv=a("p"),nGo=o("The model is set in evaluation mode by default using "),fpe=a("code"),sGo=o("model.eval()"),lGo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mpe=a("code"),iGo=o("model.train()"),dGo=l(),F(bv.$$.fragment),cOe=l(),Zi=a("h2"),vv=a("a"),gpe=a("span"),F(kA.$$.fragment),cGo=l(),hpe=a("span"),fGo=o("AutoModelForMultipleChoice"),fOe=l(),Bo=a("div"),F(SA.$$.fragment),mGo=l(),ed=a("p"),gGo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),GV=a("a"),hGo=o("from_pretrained()"),pGo=o(" class method or the "),OV=a("a"),_Go=o("from_config()"),uGo=o(` class
method.`),bGo=l(),RA=a("p"),vGo=o("This class cannot be instantiated directly using "),ppe=a("code"),FGo=o("__init__()"),TGo=o(" (throws an error)."),MGo=l(),ft=a("div"),F(PA.$$.fragment),EGo=l(),_pe=a("p"),CGo=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),wGo=l(),od=a("p"),AGo=o(`Note:
Loading a model from its configuration file does `),upe=a("strong"),LGo=o("not"),yGo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VV=a("a"),xGo=o("from_pretrained()"),$Go=o(" to load the model weights."),kGo=l(),F(Fv.$$.fragment),SGo=l(),ro=a("div"),F(BA.$$.fragment),RGo=l(),bpe=a("p"),PGo=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),BGo=l(),ja=a("p"),IGo=o("The model class to instantiate is selected based on the "),vpe=a("code"),NGo=o("model_type"),qGo=o(` property of the config object (either
passed as an argument or loaded from `),Fpe=a("code"),jGo=o("pretrained_model_name_or_path"),DGo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tpe=a("code"),GGo=o("pretrained_model_name_or_path"),OGo=o(":"),VGo=l(),Z=a("ul"),Tv=a("li"),Mpe=a("strong"),XGo=o("albert"),zGo=o(" \u2014 "),XV=a("a"),QGo=o("AlbertForMultipleChoice"),WGo=o(" (ALBERT model)"),HGo=l(),Mv=a("li"),Epe=a("strong"),UGo=o("bert"),JGo=o(" \u2014 "),zV=a("a"),YGo=o("BertForMultipleChoice"),KGo=o(" (BERT model)"),ZGo=l(),Ev=a("li"),Cpe=a("strong"),eOo=o("big_bird"),oOo=o(" \u2014 "),QV=a("a"),rOo=o("BigBirdForMultipleChoice"),tOo=o(" (BigBird model)"),aOo=l(),Cv=a("li"),wpe=a("strong"),nOo=o("camembert"),sOo=o(" \u2014 "),WV=a("a"),lOo=o("CamembertForMultipleChoice"),iOo=o(" (CamemBERT model)"),dOo=l(),wv=a("li"),Ape=a("strong"),cOo=o("canine"),fOo=o(" \u2014 "),HV=a("a"),mOo=o("CanineForMultipleChoice"),gOo=o(" (CANINE model)"),hOo=l(),Av=a("li"),Lpe=a("strong"),pOo=o("convbert"),_Oo=o(" \u2014 "),UV=a("a"),uOo=o("ConvBertForMultipleChoice"),bOo=o(" (ConvBERT model)"),vOo=l(),Lv=a("li"),ype=a("strong"),FOo=o("data2vec-text"),TOo=o(" \u2014 "),JV=a("a"),MOo=o("Data2VecTextForMultipleChoice"),EOo=o(" (Data2VecText model)"),COo=l(),yv=a("li"),xpe=a("strong"),wOo=o("deberta-v2"),AOo=o(" \u2014 "),YV=a("a"),LOo=o("DebertaV2ForMultipleChoice"),yOo=o(" (DeBERTa-v2 model)"),xOo=l(),xv=a("li"),$pe=a("strong"),$Oo=o("distilbert"),kOo=o(" \u2014 "),KV=a("a"),SOo=o("DistilBertForMultipleChoice"),ROo=o(" (DistilBERT model)"),POo=l(),$v=a("li"),kpe=a("strong"),BOo=o("electra"),IOo=o(" \u2014 "),ZV=a("a"),NOo=o("ElectraForMultipleChoice"),qOo=o(" (ELECTRA model)"),jOo=l(),kv=a("li"),Spe=a("strong"),DOo=o("flaubert"),GOo=o(" \u2014 "),eX=a("a"),OOo=o("FlaubertForMultipleChoice"),VOo=o(" (FlauBERT model)"),XOo=l(),Sv=a("li"),Rpe=a("strong"),zOo=o("fnet"),QOo=o(" \u2014 "),oX=a("a"),WOo=o("FNetForMultipleChoice"),HOo=o(" (FNet model)"),UOo=l(),Rv=a("li"),Ppe=a("strong"),JOo=o("funnel"),YOo=o(" \u2014 "),rX=a("a"),KOo=o("FunnelForMultipleChoice"),ZOo=o(" (Funnel Transformer model)"),eVo=l(),Pv=a("li"),Bpe=a("strong"),oVo=o("ibert"),rVo=o(" \u2014 "),tX=a("a"),tVo=o("IBertForMultipleChoice"),aVo=o(" (I-BERT model)"),nVo=l(),Bv=a("li"),Ipe=a("strong"),sVo=o("longformer"),lVo=o(" \u2014 "),aX=a("a"),iVo=o("LongformerForMultipleChoice"),dVo=o(" (Longformer model)"),cVo=l(),Iv=a("li"),Npe=a("strong"),fVo=o("megatron-bert"),mVo=o(" \u2014 "),nX=a("a"),gVo=o("MegatronBertForMultipleChoice"),hVo=o(" (Megatron-BERT model)"),pVo=l(),Nv=a("li"),qpe=a("strong"),_Vo=o("mobilebert"),uVo=o(" \u2014 "),sX=a("a"),bVo=o("MobileBertForMultipleChoice"),vVo=o(" (MobileBERT model)"),FVo=l(),qv=a("li"),jpe=a("strong"),TVo=o("mpnet"),MVo=o(" \u2014 "),lX=a("a"),EVo=o("MPNetForMultipleChoice"),CVo=o(" (MPNet model)"),wVo=l(),jv=a("li"),Dpe=a("strong"),AVo=o("nezha"),LVo=o(" \u2014 "),iX=a("a"),yVo=o("NezhaForMultipleChoice"),xVo=o(" (Nezha model)"),$Vo=l(),Dv=a("li"),Gpe=a("strong"),kVo=o("nystromformer"),SVo=o(" \u2014 "),dX=a("a"),RVo=o("NystromformerForMultipleChoice"),PVo=o(" (Nystr\xF6mformer model)"),BVo=l(),Gv=a("li"),Ope=a("strong"),IVo=o("qdqbert"),NVo=o(" \u2014 "),cX=a("a"),qVo=o("QDQBertForMultipleChoice"),jVo=o(" (QDQBert model)"),DVo=l(),Ov=a("li"),Vpe=a("strong"),GVo=o("rembert"),OVo=o(" \u2014 "),fX=a("a"),VVo=o("RemBertForMultipleChoice"),XVo=o(" (RemBERT model)"),zVo=l(),Vv=a("li"),Xpe=a("strong"),QVo=o("roberta"),WVo=o(" \u2014 "),mX=a("a"),HVo=o("RobertaForMultipleChoice"),UVo=o(" (RoBERTa model)"),JVo=l(),Xv=a("li"),zpe=a("strong"),YVo=o("roformer"),KVo=o(" \u2014 "),gX=a("a"),ZVo=o("RoFormerForMultipleChoice"),eXo=o(" (RoFormer model)"),oXo=l(),zv=a("li"),Qpe=a("strong"),rXo=o("squeezebert"),tXo=o(" \u2014 "),hX=a("a"),aXo=o("SqueezeBertForMultipleChoice"),nXo=o(" (SqueezeBERT model)"),sXo=l(),Qv=a("li"),Wpe=a("strong"),lXo=o("xlm"),iXo=o(" \u2014 "),pX=a("a"),dXo=o("XLMForMultipleChoice"),cXo=o(" (XLM model)"),fXo=l(),Wv=a("li"),Hpe=a("strong"),mXo=o("xlm-roberta"),gXo=o(" \u2014 "),_X=a("a"),hXo=o("XLMRobertaForMultipleChoice"),pXo=o(" (XLM-RoBERTa model)"),_Xo=l(),Hv=a("li"),Upe=a("strong"),uXo=o("xlm-roberta-xl"),bXo=o(" \u2014 "),uX=a("a"),vXo=o("XLMRobertaXLForMultipleChoice"),FXo=o(" (XLM-RoBERTa-XL model)"),TXo=l(),Uv=a("li"),Jpe=a("strong"),MXo=o("xlnet"),EXo=o(" \u2014 "),bX=a("a"),CXo=o("XLNetForMultipleChoice"),wXo=o(" (XLNet model)"),AXo=l(),Jv=a("li"),Ype=a("strong"),LXo=o("yoso"),yXo=o(" \u2014 "),vX=a("a"),xXo=o("YosoForMultipleChoice"),$Xo=o(" (YOSO model)"),kXo=l(),Yv=a("p"),SXo=o("The model is set in evaluation mode by default using "),Kpe=a("code"),RXo=o("model.eval()"),PXo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Zpe=a("code"),BXo=o("model.train()"),IXo=l(),F(Kv.$$.fragment),mOe=l(),rd=a("h2"),Zv=a("a"),e_e=a("span"),F(IA.$$.fragment),NXo=l(),o_e=a("span"),qXo=o("AutoModelForNextSentencePrediction"),gOe=l(),Io=a("div"),F(NA.$$.fragment),jXo=l(),td=a("p"),DXo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),FX=a("a"),GXo=o("from_pretrained()"),OXo=o(" class method or the "),TX=a("a"),VXo=o("from_config()"),XXo=o(` class
method.`),zXo=l(),qA=a("p"),QXo=o("This class cannot be instantiated directly using "),r_e=a("code"),WXo=o("__init__()"),HXo=o(" (throws an error)."),UXo=l(),mt=a("div"),F(jA.$$.fragment),JXo=l(),t_e=a("p"),YXo=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),KXo=l(),ad=a("p"),ZXo=o(`Note:
Loading a model from its configuration file does `),a_e=a("strong"),ezo=o("not"),ozo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),MX=a("a"),rzo=o("from_pretrained()"),tzo=o(" to load the model weights."),azo=l(),F(eF.$$.fragment),nzo=l(),to=a("div"),F(DA.$$.fragment),szo=l(),n_e=a("p"),lzo=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),izo=l(),Da=a("p"),dzo=o("The model class to instantiate is selected based on the "),s_e=a("code"),czo=o("model_type"),fzo=o(` property of the config object (either
passed as an argument or loaded from `),l_e=a("code"),mzo=o("pretrained_model_name_or_path"),gzo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i_e=a("code"),hzo=o("pretrained_model_name_or_path"),pzo=o(":"),_zo=l(),No=a("ul"),oF=a("li"),d_e=a("strong"),uzo=o("bert"),bzo=o(" \u2014 "),EX=a("a"),vzo=o("BertForNextSentencePrediction"),Fzo=o(" (BERT model)"),Tzo=l(),rF=a("li"),c_e=a("strong"),Mzo=o("fnet"),Ezo=o(" \u2014 "),CX=a("a"),Czo=o("FNetForNextSentencePrediction"),wzo=o(" (FNet model)"),Azo=l(),tF=a("li"),f_e=a("strong"),Lzo=o("megatron-bert"),yzo=o(" \u2014 "),wX=a("a"),xzo=o("MegatronBertForNextSentencePrediction"),$zo=o(" (Megatron-BERT model)"),kzo=l(),aF=a("li"),m_e=a("strong"),Szo=o("mobilebert"),Rzo=o(" \u2014 "),AX=a("a"),Pzo=o("MobileBertForNextSentencePrediction"),Bzo=o(" (MobileBERT model)"),Izo=l(),nF=a("li"),g_e=a("strong"),Nzo=o("nezha"),qzo=o(" \u2014 "),LX=a("a"),jzo=o("NezhaForNextSentencePrediction"),Dzo=o(" (Nezha model)"),Gzo=l(),sF=a("li"),h_e=a("strong"),Ozo=o("qdqbert"),Vzo=o(" \u2014 "),yX=a("a"),Xzo=o("QDQBertForNextSentencePrediction"),zzo=o(" (QDQBert model)"),Qzo=l(),lF=a("p"),Wzo=o("The model is set in evaluation mode by default using "),p_e=a("code"),Hzo=o("model.eval()"),Uzo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),__e=a("code"),Jzo=o("model.train()"),Yzo=l(),F(iF.$$.fragment),hOe=l(),nd=a("h2"),dF=a("a"),u_e=a("span"),F(GA.$$.fragment),Kzo=l(),b_e=a("span"),Zzo=o("AutoModelForTokenClassification"),pOe=l(),qo=a("div"),F(OA.$$.fragment),eQo=l(),sd=a("p"),oQo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),xX=a("a"),rQo=o("from_pretrained()"),tQo=o(" class method or the "),$X=a("a"),aQo=o("from_config()"),nQo=o(` class
method.`),sQo=l(),VA=a("p"),lQo=o("This class cannot be instantiated directly using "),v_e=a("code"),iQo=o("__init__()"),dQo=o(" (throws an error)."),cQo=l(),gt=a("div"),F(XA.$$.fragment),fQo=l(),F_e=a("p"),mQo=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),gQo=l(),ld=a("p"),hQo=o(`Note:
Loading a model from its configuration file does `),T_e=a("strong"),pQo=o("not"),_Qo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),kX=a("a"),uQo=o("from_pretrained()"),bQo=o(" to load the model weights."),vQo=l(),F(cF.$$.fragment),FQo=l(),ao=a("div"),F(zA.$$.fragment),TQo=l(),M_e=a("p"),MQo=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),EQo=l(),Ga=a("p"),CQo=o("The model class to instantiate is selected based on the "),E_e=a("code"),wQo=o("model_type"),AQo=o(` property of the config object (either
passed as an argument or loaded from `),C_e=a("code"),LQo=o("pretrained_model_name_or_path"),yQo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w_e=a("code"),xQo=o("pretrained_model_name_or_path"),$Qo=o(":"),kQo=l(),H=a("ul"),fF=a("li"),A_e=a("strong"),SQo=o("albert"),RQo=o(" \u2014 "),SX=a("a"),PQo=o("AlbertForTokenClassification"),BQo=o(" (ALBERT model)"),IQo=l(),mF=a("li"),L_e=a("strong"),NQo=o("bert"),qQo=o(" \u2014 "),RX=a("a"),jQo=o("BertForTokenClassification"),DQo=o(" (BERT model)"),GQo=l(),gF=a("li"),y_e=a("strong"),OQo=o("big_bird"),VQo=o(" \u2014 "),PX=a("a"),XQo=o("BigBirdForTokenClassification"),zQo=o(" (BigBird model)"),QQo=l(),hF=a("li"),x_e=a("strong"),WQo=o("bloom"),HQo=o(" \u2014 "),BX=a("a"),UQo=o("BloomForTokenClassification"),JQo=o(" (BLOOM model)"),YQo=l(),pF=a("li"),$_e=a("strong"),KQo=o("camembert"),ZQo=o(" \u2014 "),IX=a("a"),eWo=o("CamembertForTokenClassification"),oWo=o(" (CamemBERT model)"),rWo=l(),_F=a("li"),k_e=a("strong"),tWo=o("canine"),aWo=o(" \u2014 "),NX=a("a"),nWo=o("CanineForTokenClassification"),sWo=o(" (CANINE model)"),lWo=l(),uF=a("li"),S_e=a("strong"),iWo=o("convbert"),dWo=o(" \u2014 "),qX=a("a"),cWo=o("ConvBertForTokenClassification"),fWo=o(" (ConvBERT model)"),mWo=l(),bF=a("li"),R_e=a("strong"),gWo=o("data2vec-text"),hWo=o(" \u2014 "),jX=a("a"),pWo=o("Data2VecTextForTokenClassification"),_Wo=o(" (Data2VecText model)"),uWo=l(),vF=a("li"),P_e=a("strong"),bWo=o("deberta"),vWo=o(" \u2014 "),DX=a("a"),FWo=o("DebertaForTokenClassification"),TWo=o(" (DeBERTa model)"),MWo=l(),FF=a("li"),B_e=a("strong"),EWo=o("deberta-v2"),CWo=o(" \u2014 "),GX=a("a"),wWo=o("DebertaV2ForTokenClassification"),AWo=o(" (DeBERTa-v2 model)"),LWo=l(),TF=a("li"),I_e=a("strong"),yWo=o("distilbert"),xWo=o(" \u2014 "),OX=a("a"),$Wo=o("DistilBertForTokenClassification"),kWo=o(" (DistilBERT model)"),SWo=l(),MF=a("li"),N_e=a("strong"),RWo=o("electra"),PWo=o(" \u2014 "),VX=a("a"),BWo=o("ElectraForTokenClassification"),IWo=o(" (ELECTRA model)"),NWo=l(),EF=a("li"),q_e=a("strong"),qWo=o("flaubert"),jWo=o(" \u2014 "),XX=a("a"),DWo=o("FlaubertForTokenClassification"),GWo=o(" (FlauBERT model)"),OWo=l(),CF=a("li"),j_e=a("strong"),VWo=o("fnet"),XWo=o(" \u2014 "),zX=a("a"),zWo=o("FNetForTokenClassification"),QWo=o(" (FNet model)"),WWo=l(),wF=a("li"),D_e=a("strong"),HWo=o("funnel"),UWo=o(" \u2014 "),QX=a("a"),JWo=o("FunnelForTokenClassification"),YWo=o(" (Funnel Transformer model)"),KWo=l(),AF=a("li"),G_e=a("strong"),ZWo=o("gpt2"),eHo=o(" \u2014 "),WX=a("a"),oHo=o("GPT2ForTokenClassification"),rHo=o(" (OpenAI GPT-2 model)"),tHo=l(),LF=a("li"),O_e=a("strong"),aHo=o("ibert"),nHo=o(" \u2014 "),HX=a("a"),sHo=o("IBertForTokenClassification"),lHo=o(" (I-BERT model)"),iHo=l(),yF=a("li"),V_e=a("strong"),dHo=o("layoutlm"),cHo=o(" \u2014 "),UX=a("a"),fHo=o("LayoutLMForTokenClassification"),mHo=o(" (LayoutLM model)"),gHo=l(),xF=a("li"),X_e=a("strong"),hHo=o("layoutlmv2"),pHo=o(" \u2014 "),JX=a("a"),_Ho=o("LayoutLMv2ForTokenClassification"),uHo=o(" (LayoutLMv2 model)"),bHo=l(),$F=a("li"),z_e=a("strong"),vHo=o("layoutlmv3"),FHo=o(" \u2014 "),YX=a("a"),THo=o("LayoutLMv3ForTokenClassification"),MHo=o(" (LayoutLMv3 model)"),EHo=l(),kF=a("li"),Q_e=a("strong"),CHo=o("longformer"),wHo=o(" \u2014 "),KX=a("a"),AHo=o("LongformerForTokenClassification"),LHo=o(" (Longformer model)"),yHo=l(),SF=a("li"),W_e=a("strong"),xHo=o("megatron-bert"),$Ho=o(" \u2014 "),ZX=a("a"),kHo=o("MegatronBertForTokenClassification"),SHo=o(" (Megatron-BERT model)"),RHo=l(),RF=a("li"),H_e=a("strong"),PHo=o("mobilebert"),BHo=o(" \u2014 "),ez=a("a"),IHo=o("MobileBertForTokenClassification"),NHo=o(" (MobileBERT model)"),qHo=l(),PF=a("li"),U_e=a("strong"),jHo=o("mpnet"),DHo=o(" \u2014 "),oz=a("a"),GHo=o("MPNetForTokenClassification"),OHo=o(" (MPNet model)"),VHo=l(),BF=a("li"),J_e=a("strong"),XHo=o("nezha"),zHo=o(" \u2014 "),rz=a("a"),QHo=o("NezhaForTokenClassification"),WHo=o(" (Nezha model)"),HHo=l(),IF=a("li"),Y_e=a("strong"),UHo=o("nystromformer"),JHo=o(" \u2014 "),tz=a("a"),YHo=o("NystromformerForTokenClassification"),KHo=o(" (Nystr\xF6mformer model)"),ZHo=l(),NF=a("li"),K_e=a("strong"),eUo=o("qdqbert"),oUo=o(" \u2014 "),az=a("a"),rUo=o("QDQBertForTokenClassification"),tUo=o(" (QDQBert model)"),aUo=l(),qF=a("li"),Z_e=a("strong"),nUo=o("rembert"),sUo=o(" \u2014 "),nz=a("a"),lUo=o("RemBertForTokenClassification"),iUo=o(" (RemBERT model)"),dUo=l(),jF=a("li"),eue=a("strong"),cUo=o("roberta"),fUo=o(" \u2014 "),sz=a("a"),mUo=o("RobertaForTokenClassification"),gUo=o(" (RoBERTa model)"),hUo=l(),DF=a("li"),oue=a("strong"),pUo=o("roformer"),_Uo=o(" \u2014 "),lz=a("a"),uUo=o("RoFormerForTokenClassification"),bUo=o(" (RoFormer model)"),vUo=l(),GF=a("li"),rue=a("strong"),FUo=o("squeezebert"),TUo=o(" \u2014 "),iz=a("a"),MUo=o("SqueezeBertForTokenClassification"),EUo=o(" (SqueezeBERT model)"),CUo=l(),OF=a("li"),tue=a("strong"),wUo=o("xlm"),AUo=o(" \u2014 "),dz=a("a"),LUo=o("XLMForTokenClassification"),yUo=o(" (XLM model)"),xUo=l(),VF=a("li"),aue=a("strong"),$Uo=o("xlm-roberta"),kUo=o(" \u2014 "),cz=a("a"),SUo=o("XLMRobertaForTokenClassification"),RUo=o(" (XLM-RoBERTa model)"),PUo=l(),XF=a("li"),nue=a("strong"),BUo=o("xlm-roberta-xl"),IUo=o(" \u2014 "),fz=a("a"),NUo=o("XLMRobertaXLForTokenClassification"),qUo=o(" (XLM-RoBERTa-XL model)"),jUo=l(),zF=a("li"),sue=a("strong"),DUo=o("xlnet"),GUo=o(" \u2014 "),mz=a("a"),OUo=o("XLNetForTokenClassification"),VUo=o(" (XLNet model)"),XUo=l(),QF=a("li"),lue=a("strong"),zUo=o("yoso"),QUo=o(" \u2014 "),gz=a("a"),WUo=o("YosoForTokenClassification"),HUo=o(" (YOSO model)"),UUo=l(),WF=a("p"),JUo=o("The model is set in evaluation mode by default using "),iue=a("code"),YUo=o("model.eval()"),KUo=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),due=a("code"),ZUo=o("model.train()"),eJo=l(),F(HF.$$.fragment),_Oe=l(),id=a("h2"),UF=a("a"),cue=a("span"),F(QA.$$.fragment),oJo=l(),fue=a("span"),rJo=o("AutoModelForQuestionAnswering"),uOe=l(),jo=a("div"),F(WA.$$.fragment),tJo=l(),dd=a("p"),aJo=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hz=a("a"),nJo=o("from_pretrained()"),sJo=o(" class method or the "),pz=a("a"),lJo=o("from_config()"),iJo=o(` class
method.`),dJo=l(),HA=a("p"),cJo=o("This class cannot be instantiated directly using "),mue=a("code"),fJo=o("__init__()"),mJo=o(" (throws an error)."),gJo=l(),ht=a("div"),F(UA.$$.fragment),hJo=l(),gue=a("p"),pJo=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),_Jo=l(),cd=a("p"),uJo=o(`Note:
Loading a model from its configuration file does `),hue=a("strong"),bJo=o("not"),vJo=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_z=a("a"),FJo=o("from_pretrained()"),TJo=o(" to load the model weights."),MJo=l(),F(JF.$$.fragment),EJo=l(),no=a("div"),F(JA.$$.fragment),CJo=l(),pue=a("p"),wJo=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),AJo=l(),Oa=a("p"),LJo=o("The model class to instantiate is selected based on the "),_ue=a("code"),yJo=o("model_type"),xJo=o(` property of the config object (either
passed as an argument or loaded from `),uue=a("code"),$Jo=o("pretrained_model_name_or_path"),kJo=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bue=a("code"),SJo=o("pretrained_model_name_or_path"),RJo=o(":"),PJo=l(),V=a("ul"),YF=a("li"),vue=a("strong"),BJo=o("albert"),IJo=o(" \u2014 "),uz=a("a"),NJo=o("AlbertForQuestionAnswering"),qJo=o(" (ALBERT model)"),jJo=l(),KF=a("li"),Fue=a("strong"),DJo=o("bart"),GJo=o(" \u2014 "),bz=a("a"),OJo=o("BartForQuestionAnswering"),VJo=o(" (BART model)"),XJo=l(),ZF=a("li"),Tue=a("strong"),zJo=o("bert"),QJo=o(" \u2014 "),vz=a("a"),WJo=o("BertForQuestionAnswering"),HJo=o(" (BERT model)"),UJo=l(),e6=a("li"),Mue=a("strong"),JJo=o("big_bird"),YJo=o(" \u2014 "),Fz=a("a"),KJo=o("BigBirdForQuestionAnswering"),ZJo=o(" (BigBird model)"),eYo=l(),o6=a("li"),Eue=a("strong"),oYo=o("bigbird_pegasus"),rYo=o(" \u2014 "),Tz=a("a"),tYo=o("BigBirdPegasusForQuestionAnswering"),aYo=o(" (BigBird-Pegasus model)"),nYo=l(),r6=a("li"),Cue=a("strong"),sYo=o("camembert"),lYo=o(" \u2014 "),Mz=a("a"),iYo=o("CamembertForQuestionAnswering"),dYo=o(" (CamemBERT model)"),cYo=l(),t6=a("li"),wue=a("strong"),fYo=o("canine"),mYo=o(" \u2014 "),Ez=a("a"),gYo=o("CanineForQuestionAnswering"),hYo=o(" (CANINE model)"),pYo=l(),a6=a("li"),Aue=a("strong"),_Yo=o("convbert"),uYo=o(" \u2014 "),Cz=a("a"),bYo=o("ConvBertForQuestionAnswering"),vYo=o(" (ConvBERT model)"),FYo=l(),n6=a("li"),Lue=a("strong"),TYo=o("data2vec-text"),MYo=o(" \u2014 "),wz=a("a"),EYo=o("Data2VecTextForQuestionAnswering"),CYo=o(" (Data2VecText model)"),wYo=l(),s6=a("li"),yue=a("strong"),AYo=o("deberta"),LYo=o(" \u2014 "),Az=a("a"),yYo=o("DebertaForQuestionAnswering"),xYo=o(" (DeBERTa model)"),$Yo=l(),l6=a("li"),xue=a("strong"),kYo=o("deberta-v2"),SYo=o(" \u2014 "),Lz=a("a"),RYo=o("DebertaV2ForQuestionAnswering"),PYo=o(" (DeBERTa-v2 model)"),BYo=l(),i6=a("li"),$ue=a("strong"),IYo=o("distilbert"),NYo=o(" \u2014 "),yz=a("a"),qYo=o("DistilBertForQuestionAnswering"),jYo=o(" (DistilBERT model)"),DYo=l(),d6=a("li"),kue=a("strong"),GYo=o("electra"),OYo=o(" \u2014 "),xz=a("a"),VYo=o("ElectraForQuestionAnswering"),XYo=o(" (ELECTRA model)"),zYo=l(),c6=a("li"),Sue=a("strong"),QYo=o("flaubert"),WYo=o(" \u2014 "),$z=a("a"),HYo=o("FlaubertForQuestionAnsweringSimple"),UYo=o(" (FlauBERT model)"),JYo=l(),f6=a("li"),Rue=a("strong"),YYo=o("fnet"),KYo=o(" \u2014 "),kz=a("a"),ZYo=o("FNetForQuestionAnswering"),eKo=o(" (FNet model)"),oKo=l(),m6=a("li"),Pue=a("strong"),rKo=o("funnel"),tKo=o(" \u2014 "),Sz=a("a"),aKo=o("FunnelForQuestionAnswering"),nKo=o(" (Funnel Transformer model)"),sKo=l(),g6=a("li"),Bue=a("strong"),lKo=o("gptj"),iKo=o(" \u2014 "),Rz=a("a"),dKo=o("GPTJForQuestionAnswering"),cKo=o(" (GPT-J model)"),fKo=l(),h6=a("li"),Iue=a("strong"),mKo=o("ibert"),gKo=o(" \u2014 "),Pz=a("a"),hKo=o("IBertForQuestionAnswering"),pKo=o(" (I-BERT model)"),_Ko=l(),p6=a("li"),Nue=a("strong"),uKo=o("layoutlmv2"),bKo=o(" \u2014 "),Bz=a("a"),vKo=o("LayoutLMv2ForQuestionAnswering"),FKo=o(" (LayoutLMv2 model)"),TKo=l(),_6=a("li"),que=a("strong"),MKo=o("layoutlmv3"),EKo=o(" \u2014 "),Iz=a("a"),CKo=o("LayoutLMv3ForQuestionAnswering"),wKo=o(" (LayoutLMv3 model)"),AKo=l(),u6=a("li"),jue=a("strong"),LKo=o("led"),yKo=o(" \u2014 "),Nz=a("a"),xKo=o("LEDForQuestionAnswering"),$Ko=o(" (LED model)"),kKo=l(),b6=a("li"),Due=a("strong"),SKo=o("longformer"),RKo=o(" \u2014 "),qz=a("a"),PKo=o("LongformerForQuestionAnswering"),BKo=o(" (Longformer model)"),IKo=l(),v6=a("li"),Gue=a("strong"),NKo=o("lxmert"),qKo=o(" \u2014 "),jz=a("a"),jKo=o("LxmertForQuestionAnswering"),DKo=o(" (LXMERT model)"),GKo=l(),F6=a("li"),Oue=a("strong"),OKo=o("mbart"),VKo=o(" \u2014 "),Dz=a("a"),XKo=o("MBartForQuestionAnswering"),zKo=o(" (mBART model)"),QKo=l(),T6=a("li"),Vue=a("strong"),WKo=o("megatron-bert"),HKo=o(" \u2014 "),Gz=a("a"),UKo=o("MegatronBertForQuestionAnswering"),JKo=o(" (Megatron-BERT model)"),YKo=l(),M6=a("li"),Xue=a("strong"),KKo=o("mobilebert"),ZKo=o(" \u2014 "),Oz=a("a"),eZo=o("MobileBertForQuestionAnswering"),oZo=o(" (MobileBERT model)"),rZo=l(),E6=a("li"),zue=a("strong"),tZo=o("mpnet"),aZo=o(" \u2014 "),Vz=a("a"),nZo=o("MPNetForQuestionAnswering"),sZo=o(" (MPNet model)"),lZo=l(),C6=a("li"),Que=a("strong"),iZo=o("nezha"),dZo=o(" \u2014 "),Xz=a("a"),cZo=o("NezhaForQuestionAnswering"),fZo=o(" (Nezha model)"),mZo=l(),w6=a("li"),Wue=a("strong"),gZo=o("nystromformer"),hZo=o(" \u2014 "),zz=a("a"),pZo=o("NystromformerForQuestionAnswering"),_Zo=o(" (Nystr\xF6mformer model)"),uZo=l(),A6=a("li"),Hue=a("strong"),bZo=o("qdqbert"),vZo=o(" \u2014 "),Qz=a("a"),FZo=o("QDQBertForQuestionAnswering"),TZo=o(" (QDQBert model)"),MZo=l(),L6=a("li"),Uue=a("strong"),EZo=o("reformer"),CZo=o(" \u2014 "),Wz=a("a"),wZo=o("ReformerForQuestionAnswering"),AZo=o(" (Reformer model)"),LZo=l(),y6=a("li"),Jue=a("strong"),yZo=o("rembert"),xZo=o(" \u2014 "),Hz=a("a"),$Zo=o("RemBertForQuestionAnswering"),kZo=o(" (RemBERT model)"),SZo=l(),x6=a("li"),Yue=a("strong"),RZo=o("roberta"),PZo=o(" \u2014 "),Uz=a("a"),BZo=o("RobertaForQuestionAnswering"),IZo=o(" (RoBERTa model)"),NZo=l(),$6=a("li"),Kue=a("strong"),qZo=o("roformer"),jZo=o(" \u2014 "),Jz=a("a"),DZo=o("RoFormerForQuestionAnswering"),GZo=o(" (RoFormer model)"),OZo=l(),k6=a("li"),Zue=a("strong"),VZo=o("splinter"),XZo=o(" \u2014 "),Yz=a("a"),zZo=o("SplinterForQuestionAnswering"),QZo=o(" (Splinter model)"),WZo=l(),S6=a("li"),e1e=a("strong"),HZo=o("squeezebert"),UZo=o(" \u2014 "),Kz=a("a"),JZo=o("SqueezeBertForQuestionAnswering"),YZo=o(" (SqueezeBERT model)"),KZo=l(),R6=a("li"),o1e=a("strong"),ZZo=o("xlm"),eer=o(" \u2014 "),Zz=a("a"),oer=o("XLMForQuestionAnsweringSimple"),rer=o(" (XLM model)"),ter=l(),P6=a("li"),r1e=a("strong"),aer=o("xlm-roberta"),ner=o(" \u2014 "),eQ=a("a"),ser=o("XLMRobertaForQuestionAnswering"),ler=o(" (XLM-RoBERTa model)"),ier=l(),B6=a("li"),t1e=a("strong"),der=o("xlm-roberta-xl"),cer=o(" \u2014 "),oQ=a("a"),fer=o("XLMRobertaXLForQuestionAnswering"),mer=o(" (XLM-RoBERTa-XL model)"),ger=l(),I6=a("li"),a1e=a("strong"),her=o("xlnet"),per=o(" \u2014 "),rQ=a("a"),_er=o("XLNetForQuestionAnsweringSimple"),uer=o(" (XLNet model)"),ber=l(),N6=a("li"),n1e=a("strong"),ver=o("yoso"),Fer=o(" \u2014 "),tQ=a("a"),Ter=o("YosoForQuestionAnswering"),Mer=o(" (YOSO model)"),Eer=l(),q6=a("p"),Cer=o("The model is set in evaluation mode by default using "),s1e=a("code"),wer=o("model.eval()"),Aer=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l1e=a("code"),Ler=o("model.train()"),yer=l(),F(j6.$$.fragment),bOe=l(),fd=a("h2"),D6=a("a"),i1e=a("span"),F(YA.$$.fragment),xer=l(),d1e=a("span"),$er=o("AutoModelForTableQuestionAnswering"),vOe=l(),Do=a("div"),F(KA.$$.fragment),ker=l(),md=a("p"),Ser=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),aQ=a("a"),Rer=o("from_pretrained()"),Per=o(" class method or the "),nQ=a("a"),Ber=o("from_config()"),Ier=o(` class
method.`),Ner=l(),ZA=a("p"),qer=o("This class cannot be instantiated directly using "),c1e=a("code"),jer=o("__init__()"),Der=o(" (throws an error)."),Ger=l(),pt=a("div"),F(eL.$$.fragment),Oer=l(),f1e=a("p"),Ver=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),Xer=l(),gd=a("p"),zer=o(`Note:
Loading a model from its configuration file does `),m1e=a("strong"),Qer=o("not"),Wer=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sQ=a("a"),Her=o("from_pretrained()"),Uer=o(" to load the model weights."),Jer=l(),F(G6.$$.fragment),Yer=l(),so=a("div"),F(oL.$$.fragment),Ker=l(),g1e=a("p"),Zer=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),eor=l(),Va=a("p"),oor=o("The model class to instantiate is selected based on the "),h1e=a("code"),ror=o("model_type"),tor=o(` property of the config object (either
passed as an argument or loaded from `),p1e=a("code"),aor=o("pretrained_model_name_or_path"),nor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_1e=a("code"),sor=o("pretrained_model_name_or_path"),lor=o(":"),ior=l(),u1e=a("ul"),O6=a("li"),b1e=a("strong"),dor=o("tapas"),cor=o(" \u2014 "),lQ=a("a"),mor=o("TapasForQuestionAnswering"),gor=o(" (TAPAS model)"),hor=l(),V6=a("p"),por=o("The model is set in evaluation mode by default using "),v1e=a("code"),_or=o("model.eval()"),uor=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F1e=a("code"),bor=o("model.train()"),vor=l(),F(X6.$$.fragment),FOe=l(),hd=a("h2"),z6=a("a"),T1e=a("span"),F(rL.$$.fragment),For=l(),M1e=a("span"),Tor=o("AutoModelForImageClassification"),TOe=l(),Go=a("div"),F(tL.$$.fragment),Mor=l(),pd=a("p"),Eor=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),iQ=a("a"),Cor=o("from_pretrained()"),wor=o(" class method or the "),dQ=a("a"),Aor=o("from_config()"),Lor=o(` class
method.`),yor=l(),aL=a("p"),xor=o("This class cannot be instantiated directly using "),E1e=a("code"),$or=o("__init__()"),kor=o(" (throws an error)."),Sor=l(),_t=a("div"),F(nL.$$.fragment),Ror=l(),C1e=a("p"),Por=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Bor=l(),_d=a("p"),Ior=o(`Note:
Loading a model from its configuration file does `),w1e=a("strong"),Nor=o("not"),qor=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=a("a"),jor=o("from_pretrained()"),Dor=o(" to load the model weights."),Gor=l(),F(Q6.$$.fragment),Oor=l(),lo=a("div"),F(sL.$$.fragment),Vor=l(),A1e=a("p"),Xor=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),zor=l(),Xa=a("p"),Qor=o("The model class to instantiate is selected based on the "),L1e=a("code"),Wor=o("model_type"),Hor=o(` property of the config object (either
passed as an argument or loaded from `),y1e=a("code"),Uor=o("pretrained_model_name_or_path"),Jor=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x1e=a("code"),Yor=o("pretrained_model_name_or_path"),Kor=o(":"),Zor=l(),Fe=a("ul"),W6=a("li"),$1e=a("strong"),err=o("beit"),orr=o(" \u2014 "),fQ=a("a"),rrr=o("BeitForImageClassification"),trr=o(" (BEiT model)"),arr=l(),H6=a("li"),k1e=a("strong"),nrr=o("convnext"),srr=o(" \u2014 "),mQ=a("a"),lrr=o("ConvNextForImageClassification"),irr=o(" (ConvNeXT model)"),drr=l(),U6=a("li"),S1e=a("strong"),crr=o("cvt"),frr=o(" \u2014 "),gQ=a("a"),mrr=o("CvtForImageClassification"),grr=o(" (CvT model)"),hrr=l(),J6=a("li"),R1e=a("strong"),prr=o("data2vec-vision"),_rr=o(" \u2014 "),hQ=a("a"),urr=o("Data2VecVisionForImageClassification"),brr=o(" (Data2VecVision model)"),vrr=l(),Xs=a("li"),P1e=a("strong"),Frr=o("deit"),Trr=o(" \u2014 "),pQ=a("a"),Mrr=o("DeiTForImageClassification"),Err=o(" or "),_Q=a("a"),Crr=o("DeiTForImageClassificationWithTeacher"),wrr=o(" (DeiT model)"),Arr=l(),Y6=a("li"),B1e=a("strong"),Lrr=o("imagegpt"),yrr=o(" \u2014 "),uQ=a("a"),xrr=o("ImageGPTForImageClassification"),$rr=o(" (ImageGPT model)"),krr=l(),zs=a("li"),I1e=a("strong"),Srr=o("levit"),Rrr=o(" \u2014 "),bQ=a("a"),Prr=o("LevitForImageClassification"),Brr=o(" or "),vQ=a("a"),Irr=o("LevitForImageClassificationWithTeacher"),Nrr=o(" (LeViT model)"),qrr=l(),ut=a("li"),N1e=a("strong"),jrr=o("perceiver"),Drr=o(" \u2014 "),FQ=a("a"),Grr=o("PerceiverForImageClassificationLearned"),Orr=o(" or "),TQ=a("a"),Vrr=o("PerceiverForImageClassificationFourier"),Xrr=o(" or "),MQ=a("a"),zrr=o("PerceiverForImageClassificationConvProcessing"),Qrr=o(" (Perceiver model)"),Wrr=l(),K6=a("li"),q1e=a("strong"),Hrr=o("poolformer"),Urr=o(" \u2014 "),EQ=a("a"),Jrr=o("PoolFormerForImageClassification"),Yrr=o(" (PoolFormer model)"),Krr=l(),Z6=a("li"),j1e=a("strong"),Zrr=o("regnet"),etr=o(" \u2014 "),CQ=a("a"),otr=o("RegNetForImageClassification"),rtr=o(" (RegNet model)"),ttr=l(),eT=a("li"),D1e=a("strong"),atr=o("resnet"),ntr=o(" \u2014 "),wQ=a("a"),str=o("ResNetForImageClassification"),ltr=o(" (ResNet model)"),itr=l(),oT=a("li"),G1e=a("strong"),dtr=o("segformer"),ctr=o(" \u2014 "),AQ=a("a"),ftr=o("SegformerForImageClassification"),mtr=o(" (SegFormer model)"),gtr=l(),rT=a("li"),O1e=a("strong"),htr=o("swin"),ptr=o(" \u2014 "),LQ=a("a"),_tr=o("SwinForImageClassification"),utr=o(" (Swin Transformer model)"),btr=l(),tT=a("li"),V1e=a("strong"),vtr=o("van"),Ftr=o(" \u2014 "),yQ=a("a"),Ttr=o("VanForImageClassification"),Mtr=o(" (VAN model)"),Etr=l(),aT=a("li"),X1e=a("strong"),Ctr=o("vit"),wtr=o(" \u2014 "),xQ=a("a"),Atr=o("ViTForImageClassification"),Ltr=o(" (ViT model)"),ytr=l(),nT=a("p"),xtr=o("The model is set in evaluation mode by default using "),z1e=a("code"),$tr=o("model.eval()"),ktr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q1e=a("code"),Str=o("model.train()"),Rtr=l(),F(sT.$$.fragment),MOe=l(),ud=a("h2"),lT=a("a"),W1e=a("span"),F(lL.$$.fragment),Ptr=l(),H1e=a("span"),Btr=o("AutoModelForVision2Seq"),EOe=l(),Oo=a("div"),F(iL.$$.fragment),Itr=l(),bd=a("p"),Ntr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$Q=a("a"),qtr=o("from_pretrained()"),jtr=o(" class method or the "),kQ=a("a"),Dtr=o("from_config()"),Gtr=o(` class
method.`),Otr=l(),dL=a("p"),Vtr=o("This class cannot be instantiated directly using "),U1e=a("code"),Xtr=o("__init__()"),ztr=o(" (throws an error)."),Qtr=l(),bt=a("div"),F(cL.$$.fragment),Wtr=l(),J1e=a("p"),Htr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),Utr=l(),vd=a("p"),Jtr=o(`Note:
Loading a model from its configuration file does `),Y1e=a("strong"),Ytr=o("not"),Ktr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SQ=a("a"),Ztr=o("from_pretrained()"),ear=o(" to load the model weights."),oar=l(),F(iT.$$.fragment),rar=l(),io=a("div"),F(fL.$$.fragment),tar=l(),K1e=a("p"),aar=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),nar=l(),za=a("p"),sar=o("The model class to instantiate is selected based on the "),Z1e=a("code"),lar=o("model_type"),iar=o(` property of the config object (either
passed as an argument or loaded from `),e2e=a("code"),dar=o("pretrained_model_name_or_path"),car=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o2e=a("code"),far=o("pretrained_model_name_or_path"),mar=o(":"),gar=l(),r2e=a("ul"),dT=a("li"),t2e=a("strong"),har=o("vision-encoder-decoder"),par=o(" \u2014 "),RQ=a("a"),_ar=o("VisionEncoderDecoderModel"),uar=o(" (Vision Encoder decoder model)"),bar=l(),cT=a("p"),Far=o("The model is set in evaluation mode by default using "),a2e=a("code"),Tar=o("model.eval()"),Mar=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n2e=a("code"),Ear=o("model.train()"),Car=l(),F(fT.$$.fragment),COe=l(),Fd=a("h2"),mT=a("a"),s2e=a("span"),F(mL.$$.fragment),war=l(),l2e=a("span"),Aar=o("AutoModelForVisualQuestionAnswering"),wOe=l(),Vo=a("div"),F(gL.$$.fragment),Lar=l(),Td=a("p"),yar=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),PQ=a("a"),xar=o("from_pretrained()"),$ar=o(" class method or the "),BQ=a("a"),kar=o("from_config()"),Sar=o(` class
method.`),Rar=l(),hL=a("p"),Par=o("This class cannot be instantiated directly using "),i2e=a("code"),Bar=o("__init__()"),Iar=o(" (throws an error)."),Nar=l(),vt=a("div"),F(pL.$$.fragment),qar=l(),d2e=a("p"),jar=o("Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),Dar=l(),Md=a("p"),Gar=o(`Note:
Loading a model from its configuration file does `),c2e=a("strong"),Oar=o("not"),Var=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IQ=a("a"),Xar=o("from_pretrained()"),zar=o(" to load the model weights."),Qar=l(),F(gT.$$.fragment),War=l(),co=a("div"),F(_L.$$.fragment),Har=l(),f2e=a("p"),Uar=o("Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),Jar=l(),Qa=a("p"),Yar=o("The model class to instantiate is selected based on the "),m2e=a("code"),Kar=o("model_type"),Zar=o(` property of the config object (either
passed as an argument or loaded from `),g2e=a("code"),enr=o("pretrained_model_name_or_path"),onr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h2e=a("code"),rnr=o("pretrained_model_name_or_path"),tnr=o(":"),anr=l(),p2e=a("ul"),hT=a("li"),_2e=a("strong"),nnr=o("vilt"),snr=o(" \u2014 "),NQ=a("a"),lnr=o("ViltForQuestionAnswering"),inr=o(" (ViLT model)"),dnr=l(),pT=a("p"),cnr=o("The model is set in evaluation mode by default using "),u2e=a("code"),fnr=o("model.eval()"),mnr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b2e=a("code"),gnr=o("model.train()"),hnr=l(),F(_T.$$.fragment),AOe=l(),Ed=a("h2"),uT=a("a"),v2e=a("span"),F(uL.$$.fragment),pnr=l(),F2e=a("span"),_nr=o("AutoModelForAudioClassification"),LOe=l(),Xo=a("div"),F(bL.$$.fragment),unr=l(),Cd=a("p"),bnr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),qQ=a("a"),vnr=o("from_pretrained()"),Fnr=o(" class method or the "),jQ=a("a"),Tnr=o("from_config()"),Mnr=o(` class
method.`),Enr=l(),vL=a("p"),Cnr=o("This class cannot be instantiated directly using "),T2e=a("code"),wnr=o("__init__()"),Anr=o(" (throws an error)."),Lnr=l(),Ft=a("div"),F(FL.$$.fragment),ynr=l(),M2e=a("p"),xnr=o("Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),$nr=l(),wd=a("p"),knr=o(`Note:
Loading a model from its configuration file does `),E2e=a("strong"),Snr=o("not"),Rnr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),DQ=a("a"),Pnr=o("from_pretrained()"),Bnr=o(" to load the model weights."),Inr=l(),F(bT.$$.fragment),Nnr=l(),fo=a("div"),F(TL.$$.fragment),qnr=l(),C2e=a("p"),jnr=o("Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),Dnr=l(),Wa=a("p"),Gnr=o("The model class to instantiate is selected based on the "),w2e=a("code"),Onr=o("model_type"),Vnr=o(` property of the config object (either
passed as an argument or loaded from `),A2e=a("code"),Xnr=o("pretrained_model_name_or_path"),znr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L2e=a("code"),Qnr=o("pretrained_model_name_or_path"),Wnr=o(":"),Hnr=l(),Pe=a("ul"),vT=a("li"),y2e=a("strong"),Unr=o("data2vec-audio"),Jnr=o(" \u2014 "),GQ=a("a"),Ynr=o("Data2VecAudioForSequenceClassification"),Knr=o(" (Data2VecAudio model)"),Znr=l(),FT=a("li"),x2e=a("strong"),esr=o("hubert"),osr=o(" \u2014 "),OQ=a("a"),rsr=o("HubertForSequenceClassification"),tsr=o(" (Hubert model)"),asr=l(),TT=a("li"),$2e=a("strong"),nsr=o("sew"),ssr=o(" \u2014 "),VQ=a("a"),lsr=o("SEWForSequenceClassification"),isr=o(" (SEW model)"),dsr=l(),MT=a("li"),k2e=a("strong"),csr=o("sew-d"),fsr=o(" \u2014 "),XQ=a("a"),msr=o("SEWDForSequenceClassification"),gsr=o(" (SEW-D model)"),hsr=l(),ET=a("li"),S2e=a("strong"),psr=o("unispeech"),_sr=o(" \u2014 "),zQ=a("a"),usr=o("UniSpeechForSequenceClassification"),bsr=o(" (UniSpeech model)"),vsr=l(),CT=a("li"),R2e=a("strong"),Fsr=o("unispeech-sat"),Tsr=o(" \u2014 "),QQ=a("a"),Msr=o("UniSpeechSatForSequenceClassification"),Esr=o(" (UniSpeechSat model)"),Csr=l(),wT=a("li"),P2e=a("strong"),wsr=o("wav2vec2"),Asr=o(" \u2014 "),WQ=a("a"),Lsr=o("Wav2Vec2ForSequenceClassification"),ysr=o(" (Wav2Vec2 model)"),xsr=l(),AT=a("li"),B2e=a("strong"),$sr=o("wav2vec2-conformer"),ksr=o(" \u2014 "),HQ=a("a"),Ssr=o("Wav2Vec2ConformerForSequenceClassification"),Rsr=o(" (Wav2Vec2-Conformer model)"),Psr=l(),LT=a("li"),I2e=a("strong"),Bsr=o("wavlm"),Isr=o(" \u2014 "),UQ=a("a"),Nsr=o("WavLMForSequenceClassification"),qsr=o(" (WavLM model)"),jsr=l(),yT=a("p"),Dsr=o("The model is set in evaluation mode by default using "),N2e=a("code"),Gsr=o("model.eval()"),Osr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q2e=a("code"),Vsr=o("model.train()"),Xsr=l(),F(xT.$$.fragment),yOe=l(),Ad=a("h2"),$T=a("a"),j2e=a("span"),F(ML.$$.fragment),zsr=l(),D2e=a("span"),Qsr=o("AutoModelForAudioFrameClassification"),xOe=l(),zo=a("div"),F(EL.$$.fragment),Wsr=l(),Ld=a("p"),Hsr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),JQ=a("a"),Usr=o("from_pretrained()"),Jsr=o(" class method or the "),YQ=a("a"),Ysr=o("from_config()"),Ksr=o(` class
method.`),Zsr=l(),CL=a("p"),elr=o("This class cannot be instantiated directly using "),G2e=a("code"),olr=o("__init__()"),rlr=o(" (throws an error)."),tlr=l(),Tt=a("div"),F(wL.$$.fragment),alr=l(),O2e=a("p"),nlr=o("Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),slr=l(),yd=a("p"),llr=o(`Note:
Loading a model from its configuration file does `),V2e=a("strong"),ilr=o("not"),dlr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),KQ=a("a"),clr=o("from_pretrained()"),flr=o(" to load the model weights."),mlr=l(),F(kT.$$.fragment),glr=l(),mo=a("div"),F(AL.$$.fragment),hlr=l(),X2e=a("p"),plr=o("Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),_lr=l(),Ha=a("p"),ulr=o("The model class to instantiate is selected based on the "),z2e=a("code"),blr=o("model_type"),vlr=o(` property of the config object (either
passed as an argument or loaded from `),Q2e=a("code"),Flr=o("pretrained_model_name_or_path"),Tlr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W2e=a("code"),Mlr=o("pretrained_model_name_or_path"),Elr=o(":"),Clr=l(),et=a("ul"),ST=a("li"),H2e=a("strong"),wlr=o("data2vec-audio"),Alr=o(" \u2014 "),ZQ=a("a"),Llr=o("Data2VecAudioForAudioFrameClassification"),ylr=o(" (Data2VecAudio model)"),xlr=l(),RT=a("li"),U2e=a("strong"),$lr=o("unispeech-sat"),klr=o(" \u2014 "),eW=a("a"),Slr=o("UniSpeechSatForAudioFrameClassification"),Rlr=o(" (UniSpeechSat model)"),Plr=l(),PT=a("li"),J2e=a("strong"),Blr=o("wav2vec2"),Ilr=o(" \u2014 "),oW=a("a"),Nlr=o("Wav2Vec2ForAudioFrameClassification"),qlr=o(" (Wav2Vec2 model)"),jlr=l(),BT=a("li"),Y2e=a("strong"),Dlr=o("wav2vec2-conformer"),Glr=o(" \u2014 "),rW=a("a"),Olr=o("Wav2Vec2ConformerForAudioFrameClassification"),Vlr=o(" (Wav2Vec2-Conformer model)"),Xlr=l(),IT=a("li"),K2e=a("strong"),zlr=o("wavlm"),Qlr=o(" \u2014 "),tW=a("a"),Wlr=o("WavLMForAudioFrameClassification"),Hlr=o(" (WavLM model)"),Ulr=l(),NT=a("p"),Jlr=o("The model is set in evaluation mode by default using "),Z2e=a("code"),Ylr=o("model.eval()"),Klr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ebe=a("code"),Zlr=o("model.train()"),eir=l(),F(qT.$$.fragment),$Oe=l(),xd=a("h2"),jT=a("a"),obe=a("span"),F(LL.$$.fragment),oir=l(),rbe=a("span"),rir=o("AutoModelForCTC"),kOe=l(),Qo=a("div"),F(yL.$$.fragment),tir=l(),$d=a("p"),air=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),aW=a("a"),nir=o("from_pretrained()"),sir=o(" class method or the "),nW=a("a"),lir=o("from_config()"),iir=o(` class
method.`),dir=l(),xL=a("p"),cir=o("This class cannot be instantiated directly using "),tbe=a("code"),fir=o("__init__()"),mir=o(" (throws an error)."),gir=l(),Mt=a("div"),F($L.$$.fragment),hir=l(),abe=a("p"),pir=o("Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),_ir=l(),kd=a("p"),uir=o(`Note:
Loading a model from its configuration file does `),nbe=a("strong"),bir=o("not"),vir=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=a("a"),Fir=o("from_pretrained()"),Tir=o(" to load the model weights."),Mir=l(),F(DT.$$.fragment),Eir=l(),go=a("div"),F(kL.$$.fragment),Cir=l(),sbe=a("p"),wir=o("Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),Air=l(),Ua=a("p"),Lir=o("The model class to instantiate is selected based on the "),lbe=a("code"),yir=o("model_type"),xir=o(` property of the config object (either
passed as an argument or loaded from `),ibe=a("code"),$ir=o("pretrained_model_name_or_path"),kir=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dbe=a("code"),Sir=o("pretrained_model_name_or_path"),Rir=o(":"),Pir=l(),Le=a("ul"),GT=a("li"),cbe=a("strong"),Bir=o("data2vec-audio"),Iir=o(" \u2014 "),lW=a("a"),Nir=o("Data2VecAudioForCTC"),qir=o(" (Data2VecAudio model)"),jir=l(),OT=a("li"),fbe=a("strong"),Dir=o("hubert"),Gir=o(" \u2014 "),iW=a("a"),Oir=o("HubertForCTC"),Vir=o(" (Hubert model)"),Xir=l(),VT=a("li"),mbe=a("strong"),zir=o("mctct"),Qir=o(" \u2014 "),dW=a("a"),Wir=o("MCTCTForCTC"),Hir=o(" (M-CTC-T model)"),Uir=l(),XT=a("li"),gbe=a("strong"),Jir=o("sew"),Yir=o(" \u2014 "),cW=a("a"),Kir=o("SEWForCTC"),Zir=o(" (SEW model)"),edr=l(),zT=a("li"),hbe=a("strong"),odr=o("sew-d"),rdr=o(" \u2014 "),fW=a("a"),tdr=o("SEWDForCTC"),adr=o(" (SEW-D model)"),ndr=l(),QT=a("li"),pbe=a("strong"),sdr=o("unispeech"),ldr=o(" \u2014 "),mW=a("a"),idr=o("UniSpeechForCTC"),ddr=o(" (UniSpeech model)"),cdr=l(),WT=a("li"),_be=a("strong"),fdr=o("unispeech-sat"),mdr=o(" \u2014 "),gW=a("a"),gdr=o("UniSpeechSatForCTC"),hdr=o(" (UniSpeechSat model)"),pdr=l(),HT=a("li"),ube=a("strong"),_dr=o("wav2vec2"),udr=o(" \u2014 "),hW=a("a"),bdr=o("Wav2Vec2ForCTC"),vdr=o(" (Wav2Vec2 model)"),Fdr=l(),UT=a("li"),bbe=a("strong"),Tdr=o("wav2vec2-conformer"),Mdr=o(" \u2014 "),pW=a("a"),Edr=o("Wav2Vec2ConformerForCTC"),Cdr=o(" (Wav2Vec2-Conformer model)"),wdr=l(),JT=a("li"),vbe=a("strong"),Adr=o("wavlm"),Ldr=o(" \u2014 "),_W=a("a"),ydr=o("WavLMForCTC"),xdr=o(" (WavLM model)"),$dr=l(),YT=a("p"),kdr=o("The model is set in evaluation mode by default using "),Fbe=a("code"),Sdr=o("model.eval()"),Rdr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tbe=a("code"),Pdr=o("model.train()"),Bdr=l(),F(KT.$$.fragment),SOe=l(),Sd=a("h2"),ZT=a("a"),Mbe=a("span"),F(SL.$$.fragment),Idr=l(),Ebe=a("span"),Ndr=o("AutoModelForSpeechSeq2Seq"),ROe=l(),Wo=a("div"),F(RL.$$.fragment),qdr=l(),Rd=a("p"),jdr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),uW=a("a"),Ddr=o("from_pretrained()"),Gdr=o(" class method or the "),bW=a("a"),Odr=o("from_config()"),Vdr=o(` class
method.`),Xdr=l(),PL=a("p"),zdr=o("This class cannot be instantiated directly using "),Cbe=a("code"),Qdr=o("__init__()"),Wdr=o(" (throws an error)."),Hdr=l(),Et=a("div"),F(BL.$$.fragment),Udr=l(),wbe=a("p"),Jdr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),Ydr=l(),Pd=a("p"),Kdr=o(`Note:
Loading a model from its configuration file does `),Abe=a("strong"),Zdr=o("not"),ecr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vW=a("a"),ocr=o("from_pretrained()"),rcr=o(" to load the model weights."),tcr=l(),F(e7.$$.fragment),acr=l(),ho=a("div"),F(IL.$$.fragment),ncr=l(),Lbe=a("p"),scr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),lcr=l(),Ja=a("p"),icr=o("The model class to instantiate is selected based on the "),ybe=a("code"),dcr=o("model_type"),ccr=o(` property of the config object (either
passed as an argument or loaded from `),xbe=a("code"),fcr=o("pretrained_model_name_or_path"),mcr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$be=a("code"),gcr=o("pretrained_model_name_or_path"),hcr=o(":"),pcr=l(),NL=a("ul"),o7=a("li"),kbe=a("strong"),_cr=o("speech-encoder-decoder"),ucr=o(" \u2014 "),FW=a("a"),bcr=o("SpeechEncoderDecoderModel"),vcr=o(" (Speech Encoder decoder model)"),Fcr=l(),r7=a("li"),Sbe=a("strong"),Tcr=o("speech_to_text"),Mcr=o(" \u2014 "),TW=a("a"),Ecr=o("Speech2TextForConditionalGeneration"),Ccr=o(" (Speech2Text model)"),wcr=l(),t7=a("p"),Acr=o("The model is set in evaluation mode by default using "),Rbe=a("code"),Lcr=o("model.eval()"),ycr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Pbe=a("code"),xcr=o("model.train()"),$cr=l(),F(a7.$$.fragment),POe=l(),Bd=a("h2"),n7=a("a"),Bbe=a("span"),F(qL.$$.fragment),kcr=l(),Ibe=a("span"),Scr=o("AutoModelForAudioXVector"),BOe=l(),Ho=a("div"),F(jL.$$.fragment),Rcr=l(),Id=a("p"),Pcr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),MW=a("a"),Bcr=o("from_pretrained()"),Icr=o(" class method or the "),EW=a("a"),Ncr=o("from_config()"),qcr=o(` class
method.`),jcr=l(),DL=a("p"),Dcr=o("This class cannot be instantiated directly using "),Nbe=a("code"),Gcr=o("__init__()"),Ocr=o(" (throws an error)."),Vcr=l(),Ct=a("div"),F(GL.$$.fragment),Xcr=l(),qbe=a("p"),zcr=o("Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),Qcr=l(),Nd=a("p"),Wcr=o(`Note:
Loading a model from its configuration file does `),jbe=a("strong"),Hcr=o("not"),Ucr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),CW=a("a"),Jcr=o("from_pretrained()"),Ycr=o(" to load the model weights."),Kcr=l(),F(s7.$$.fragment),Zcr=l(),po=a("div"),F(OL.$$.fragment),efr=l(),Dbe=a("p"),ofr=o("Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),rfr=l(),Ya=a("p"),tfr=o("The model class to instantiate is selected based on the "),Gbe=a("code"),afr=o("model_type"),nfr=o(` property of the config object (either
passed as an argument or loaded from `),Obe=a("code"),sfr=o("pretrained_model_name_or_path"),lfr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vbe=a("code"),ifr=o("pretrained_model_name_or_path"),dfr=o(":"),cfr=l(),ot=a("ul"),l7=a("li"),Xbe=a("strong"),ffr=o("data2vec-audio"),mfr=o(" \u2014 "),wW=a("a"),gfr=o("Data2VecAudioForXVector"),hfr=o(" (Data2VecAudio model)"),pfr=l(),i7=a("li"),zbe=a("strong"),_fr=o("unispeech-sat"),ufr=o(" \u2014 "),AW=a("a"),bfr=o("UniSpeechSatForXVector"),vfr=o(" (UniSpeechSat model)"),Ffr=l(),d7=a("li"),Qbe=a("strong"),Tfr=o("wav2vec2"),Mfr=o(" \u2014 "),LW=a("a"),Efr=o("Wav2Vec2ForXVector"),Cfr=o(" (Wav2Vec2 model)"),wfr=l(),c7=a("li"),Wbe=a("strong"),Afr=o("wav2vec2-conformer"),Lfr=o(" \u2014 "),yW=a("a"),yfr=o("Wav2Vec2ConformerForXVector"),xfr=o(" (Wav2Vec2-Conformer model)"),$fr=l(),f7=a("li"),Hbe=a("strong"),kfr=o("wavlm"),Sfr=o(" \u2014 "),xW=a("a"),Rfr=o("WavLMForXVector"),Pfr=o(" (WavLM model)"),Bfr=l(),m7=a("p"),Ifr=o("The model is set in evaluation mode by default using "),Ube=a("code"),Nfr=o("model.eval()"),qfr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jbe=a("code"),jfr=o("model.train()"),Dfr=l(),F(g7.$$.fragment),IOe=l(),qd=a("h2"),h7=a("a"),Ybe=a("span"),F(VL.$$.fragment),Gfr=l(),Kbe=a("span"),Ofr=o("AutoModelForMaskedImageModeling"),NOe=l(),Uo=a("div"),F(XL.$$.fragment),Vfr=l(),jd=a("p"),Xfr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),$W=a("a"),zfr=o("from_pretrained()"),Qfr=o(" class method or the "),kW=a("a"),Wfr=o("from_config()"),Hfr=o(` class
method.`),Ufr=l(),zL=a("p"),Jfr=o("This class cannot be instantiated directly using "),Zbe=a("code"),Yfr=o("__init__()"),Kfr=o(" (throws an error)."),Zfr=l(),wt=a("div"),F(QL.$$.fragment),emr=l(),eve=a("p"),omr=o("Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),rmr=l(),Dd=a("p"),tmr=o(`Note:
Loading a model from its configuration file does `),ove=a("strong"),amr=o("not"),nmr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SW=a("a"),smr=o("from_pretrained()"),lmr=o(" to load the model weights."),imr=l(),F(p7.$$.fragment),dmr=l(),_o=a("div"),F(WL.$$.fragment),cmr=l(),rve=a("p"),fmr=o("Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),mmr=l(),Ka=a("p"),gmr=o("The model class to instantiate is selected based on the "),tve=a("code"),hmr=o("model_type"),pmr=o(` property of the config object (either
passed as an argument or loaded from `),ave=a("code"),_mr=o("pretrained_model_name_or_path"),umr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nve=a("code"),bmr=o("pretrained_model_name_or_path"),vmr=o(":"),Fmr=l(),Gd=a("ul"),_7=a("li"),sve=a("strong"),Tmr=o("deit"),Mmr=o(" \u2014 "),RW=a("a"),Emr=o("DeiTForMaskedImageModeling"),Cmr=o(" (DeiT model)"),wmr=l(),u7=a("li"),lve=a("strong"),Amr=o("swin"),Lmr=o(" \u2014 "),PW=a("a"),ymr=o("SwinForMaskedImageModeling"),xmr=o(" (Swin Transformer model)"),$mr=l(),b7=a("li"),ive=a("strong"),kmr=o("vit"),Smr=o(" \u2014 "),BW=a("a"),Rmr=o("ViTForMaskedImageModeling"),Pmr=o(" (ViT model)"),Bmr=l(),v7=a("p"),Imr=o("The model is set in evaluation mode by default using "),dve=a("code"),Nmr=o("model.eval()"),qmr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cve=a("code"),jmr=o("model.train()"),Dmr=l(),F(F7.$$.fragment),qOe=l(),Od=a("h2"),T7=a("a"),fve=a("span"),F(HL.$$.fragment),Gmr=l(),mve=a("span"),Omr=o("AutoModelForObjectDetection"),jOe=l(),Jo=a("div"),F(UL.$$.fragment),Vmr=l(),Vd=a("p"),Xmr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),IW=a("a"),zmr=o("from_pretrained()"),Qmr=o(" class method or the "),NW=a("a"),Wmr=o("from_config()"),Hmr=o(` class
method.`),Umr=l(),JL=a("p"),Jmr=o("This class cannot be instantiated directly using "),gve=a("code"),Ymr=o("__init__()"),Kmr=o(" (throws an error)."),Zmr=l(),At=a("div"),F(YL.$$.fragment),egr=l(),hve=a("p"),ogr=o("Instantiates one of the model classes of the library (with a object detection head) from a configuration."),rgr=l(),Xd=a("p"),tgr=o(`Note:
Loading a model from its configuration file does `),pve=a("strong"),agr=o("not"),ngr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),qW=a("a"),sgr=o("from_pretrained()"),lgr=o(" to load the model weights."),igr=l(),F(M7.$$.fragment),dgr=l(),uo=a("div"),F(KL.$$.fragment),cgr=l(),_ve=a("p"),fgr=o("Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),mgr=l(),Za=a("p"),ggr=o("The model class to instantiate is selected based on the "),uve=a("code"),hgr=o("model_type"),pgr=o(` property of the config object (either
passed as an argument or loaded from `),bve=a("code"),_gr=o("pretrained_model_name_or_path"),ugr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vve=a("code"),bgr=o("pretrained_model_name_or_path"),vgr=o(":"),Fgr=l(),ZL=a("ul"),E7=a("li"),Fve=a("strong"),Tgr=o("detr"),Mgr=o(" \u2014 "),jW=a("a"),Egr=o("DetrForObjectDetection"),Cgr=o(" (DETR model)"),wgr=l(),C7=a("li"),Tve=a("strong"),Agr=o("yolos"),Lgr=o(" \u2014 "),DW=a("a"),ygr=o("YolosForObjectDetection"),xgr=o(" (YOLOS model)"),$gr=l(),w7=a("p"),kgr=o("The model is set in evaluation mode by default using "),Mve=a("code"),Sgr=o("model.eval()"),Rgr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Eve=a("code"),Pgr=o("model.train()"),Bgr=l(),F(A7.$$.fragment),DOe=l(),zd=a("h2"),L7=a("a"),Cve=a("span"),F(ey.$$.fragment),Igr=l(),wve=a("span"),Ngr=o("AutoModelForImageSegmentation"),GOe=l(),Yo=a("div"),F(oy.$$.fragment),qgr=l(),Qd=a("p"),jgr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),GW=a("a"),Dgr=o("from_pretrained()"),Ggr=o(" class method or the "),OW=a("a"),Ogr=o("from_config()"),Vgr=o(` class
method.`),Xgr=l(),ry=a("p"),zgr=o("This class cannot be instantiated directly using "),Ave=a("code"),Qgr=o("__init__()"),Wgr=o(" (throws an error)."),Hgr=l(),Lt=a("div"),F(ty.$$.fragment),Ugr=l(),Lve=a("p"),Jgr=o("Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),Ygr=l(),Wd=a("p"),Kgr=o(`Note:
Loading a model from its configuration file does `),yve=a("strong"),Zgr=o("not"),ehr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VW=a("a"),ohr=o("from_pretrained()"),rhr=o(" to load the model weights."),thr=l(),F(y7.$$.fragment),ahr=l(),bo=a("div"),F(ay.$$.fragment),nhr=l(),xve=a("p"),shr=o("Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),lhr=l(),en=a("p"),ihr=o("The model class to instantiate is selected based on the "),$ve=a("code"),dhr=o("model_type"),chr=o(` property of the config object (either
passed as an argument or loaded from `),kve=a("code"),fhr=o("pretrained_model_name_or_path"),mhr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sve=a("code"),ghr=o("pretrained_model_name_or_path"),hhr=o(":"),phr=l(),Rve=a("ul"),x7=a("li"),Pve=a("strong"),_hr=o("detr"),uhr=o(" \u2014 "),XW=a("a"),bhr=o("DetrForSegmentation"),vhr=o(" (DETR model)"),Fhr=l(),$7=a("p"),Thr=o("The model is set in evaluation mode by default using "),Bve=a("code"),Mhr=o("model.eval()"),Ehr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ive=a("code"),Chr=o("model.train()"),whr=l(),F(k7.$$.fragment),OOe=l(),Hd=a("h2"),S7=a("a"),Nve=a("span"),F(ny.$$.fragment),Ahr=l(),qve=a("span"),Lhr=o("AutoModelForSemanticSegmentation"),VOe=l(),Ko=a("div"),F(sy.$$.fragment),yhr=l(),Ud=a("p"),xhr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zW=a("a"),$hr=o("from_pretrained()"),khr=o(" class method or the "),QW=a("a"),Shr=o("from_config()"),Rhr=o(` class
method.`),Phr=l(),ly=a("p"),Bhr=o("This class cannot be instantiated directly using "),jve=a("code"),Ihr=o("__init__()"),Nhr=o(" (throws an error)."),qhr=l(),yt=a("div"),F(iy.$$.fragment),jhr=l(),Dve=a("p"),Dhr=o("Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),Ghr=l(),Jd=a("p"),Ohr=o(`Note:
Loading a model from its configuration file does `),Gve=a("strong"),Vhr=o("not"),Xhr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=a("a"),zhr=o("from_pretrained()"),Qhr=o(" to load the model weights."),Whr=l(),F(R7.$$.fragment),Hhr=l(),vo=a("div"),F(dy.$$.fragment),Uhr=l(),Ove=a("p"),Jhr=o("Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),Yhr=l(),on=a("p"),Khr=o("The model class to instantiate is selected based on the "),Vve=a("code"),Zhr=o("model_type"),epr=o(` property of the config object (either
passed as an argument or loaded from `),Xve=a("code"),opr=o("pretrained_model_name_or_path"),rpr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zve=a("code"),tpr=o("pretrained_model_name_or_path"),apr=o(":"),npr=l(),rn=a("ul"),P7=a("li"),Qve=a("strong"),spr=o("beit"),lpr=o(" \u2014 "),HW=a("a"),ipr=o("BeitForSemanticSegmentation"),dpr=o(" (BEiT model)"),cpr=l(),B7=a("li"),Wve=a("strong"),fpr=o("data2vec-vision"),mpr=o(" \u2014 "),UW=a("a"),gpr=o("Data2VecVisionForSemanticSegmentation"),hpr=o(" (Data2VecVision model)"),ppr=l(),I7=a("li"),Hve=a("strong"),_pr=o("dpt"),upr=o(" \u2014 "),JW=a("a"),bpr=o("DPTForSemanticSegmentation"),vpr=o(" (DPT model)"),Fpr=l(),N7=a("li"),Uve=a("strong"),Tpr=o("segformer"),Mpr=o(" \u2014 "),YW=a("a"),Epr=o("SegformerForSemanticSegmentation"),Cpr=o(" (SegFormer model)"),wpr=l(),q7=a("p"),Apr=o("The model is set in evaluation mode by default using "),Jve=a("code"),Lpr=o("model.eval()"),ypr=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yve=a("code"),xpr=o("model.train()"),$pr=l(),F(j7.$$.fragment),XOe=l(),Yd=a("h2"),D7=a("a"),Kve=a("span"),F(cy.$$.fragment),kpr=l(),Zve=a("span"),Spr=o("AutoModelForInstanceSegmentation"),zOe=l(),Zo=a("div"),F(fy.$$.fragment),Rpr=l(),Kd=a("p"),Ppr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),KW=a("a"),Bpr=o("from_pretrained()"),Ipr=o(" class method or the "),ZW=a("a"),Npr=o("from_config()"),qpr=o(` class
method.`),jpr=l(),my=a("p"),Dpr=o("This class cannot be instantiated directly using "),eFe=a("code"),Gpr=o("__init__()"),Opr=o(" (throws an error)."),Vpr=l(),xt=a("div"),F(gy.$$.fragment),Xpr=l(),oFe=a("p"),zpr=o("Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),Qpr=l(),Zd=a("p"),Wpr=o(`Note:
Loading a model from its configuration file does `),rFe=a("strong"),Hpr=o("not"),Upr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eH=a("a"),Jpr=o("from_pretrained()"),Ypr=o(" to load the model weights."),Kpr=l(),F(G7.$$.fragment),Zpr=l(),Fo=a("div"),F(hy.$$.fragment),e_r=l(),tFe=a("p"),o_r=o("Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),r_r=l(),tn=a("p"),t_r=o("The model class to instantiate is selected based on the "),aFe=a("code"),a_r=o("model_type"),n_r=o(` property of the config object (either
passed as an argument or loaded from `),nFe=a("code"),s_r=o("pretrained_model_name_or_path"),l_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sFe=a("code"),i_r=o("pretrained_model_name_or_path"),d_r=o(":"),c_r=l(),lFe=a("ul"),O7=a("li"),iFe=a("strong"),f_r=o("maskformer"),m_r=o(" \u2014 "),oH=a("a"),g_r=o("MaskFormerForInstanceSegmentation"),h_r=o(" (MaskFormer model)"),p_r=l(),V7=a("p"),__r=o("The model is set in evaluation mode by default using "),dFe=a("code"),u_r=o("model.eval()"),b_r=o(` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cFe=a("code"),v_r=o("model.train()"),F_r=l(),F(X7.$$.fragment),QOe=l(),ec=a("h2"),z7=a("a"),fFe=a("span"),F(py.$$.fragment),T_r=l(),mFe=a("span"),M_r=o("TFAutoModel"),WOe=l(),er=a("div"),F(_y.$$.fragment),E_r=l(),oc=a("p"),C_r=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),rH=a("a"),w_r=o("from_pretrained()"),A_r=o(" class method or the "),tH=a("a"),L_r=o("from_config()"),y_r=o(` class
method.`),x_r=l(),uy=a("p"),$_r=o("This class cannot be instantiated directly using "),gFe=a("code"),k_r=o("__init__()"),S_r=o(" (throws an error)."),R_r=l(),$t=a("div"),F(by.$$.fragment),P_r=l(),hFe=a("p"),B_r=o("Instantiates one of the base model classes of the library from a configuration."),I_r=l(),rc=a("p"),N_r=o(`Note:
Loading a model from its configuration file does `),pFe=a("strong"),q_r=o("not"),j_r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),aH=a("a"),D_r=o("from_pretrained()"),G_r=o(" to load the model weights."),O_r=l(),F(Q7.$$.fragment),V_r=l(),yr=a("div"),F(vy.$$.fragment),X_r=l(),_Fe=a("p"),z_r=o("Instantiate one of the base model classes of the library from a pretrained model."),Q_r=l(),an=a("p"),W_r=o("The model class to instantiate is selected based on the "),uFe=a("code"),H_r=o("model_type"),U_r=o(` property of the config object (either
passed as an argument or loaded from `),bFe=a("code"),J_r=o("pretrained_model_name_or_path"),Y_r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vFe=a("code"),K_r=o("pretrained_model_name_or_path"),Z_r=o(":"),eur=l(),j=a("ul"),W7=a("li"),FFe=a("strong"),our=o("albert"),rur=o(" \u2014 "),nH=a("a"),tur=o("TFAlbertModel"),aur=o(" (ALBERT model)"),nur=l(),H7=a("li"),TFe=a("strong"),sur=o("bart"),lur=o(" \u2014 "),sH=a("a"),iur=o("TFBartModel"),dur=o(" (BART model)"),cur=l(),U7=a("li"),MFe=a("strong"),fur=o("bert"),mur=o(" \u2014 "),lH=a("a"),gur=o("TFBertModel"),hur=o(" (BERT model)"),pur=l(),J7=a("li"),EFe=a("strong"),_ur=o("blenderbot"),uur=o(" \u2014 "),iH=a("a"),bur=o("TFBlenderbotModel"),vur=o(" (Blenderbot model)"),Fur=l(),Y7=a("li"),CFe=a("strong"),Tur=o("blenderbot-small"),Mur=o(" \u2014 "),dH=a("a"),Eur=o("TFBlenderbotSmallModel"),Cur=o(" (BlenderbotSmall model)"),wur=l(),K7=a("li"),wFe=a("strong"),Aur=o("camembert"),Lur=o(" \u2014 "),cH=a("a"),yur=o("TFCamembertModel"),xur=o(" (CamemBERT model)"),$ur=l(),Z7=a("li"),AFe=a("strong"),kur=o("clip"),Sur=o(" \u2014 "),fH=a("a"),Rur=o("TFCLIPModel"),Pur=o(" (CLIP model)"),Bur=l(),e8=a("li"),LFe=a("strong"),Iur=o("convbert"),Nur=o(" \u2014 "),mH=a("a"),qur=o("TFConvBertModel"),jur=o(" (ConvBERT model)"),Dur=l(),o8=a("li"),yFe=a("strong"),Gur=o("convnext"),Our=o(" \u2014 "),gH=a("a"),Vur=o("TFConvNextModel"),Xur=o(" (ConvNeXT model)"),zur=l(),r8=a("li"),xFe=a("strong"),Qur=o("ctrl"),Wur=o(" \u2014 "),hH=a("a"),Hur=o("TFCTRLModel"),Uur=o(" (CTRL model)"),Jur=l(),t8=a("li"),$Fe=a("strong"),Yur=o("data2vec-vision"),Kur=o(" \u2014 "),pH=a("a"),Zur=o("TFData2VecVisionModel"),e1r=o(" (Data2VecVision model)"),o1r=l(),a8=a("li"),kFe=a("strong"),r1r=o("deberta"),t1r=o(" \u2014 "),_H=a("a"),a1r=o("TFDebertaModel"),n1r=o(" (DeBERTa model)"),s1r=l(),n8=a("li"),SFe=a("strong"),l1r=o("deberta-v2"),i1r=o(" \u2014 "),uH=a("a"),d1r=o("TFDebertaV2Model"),c1r=o(" (DeBERTa-v2 model)"),f1r=l(),s8=a("li"),RFe=a("strong"),m1r=o("distilbert"),g1r=o(" \u2014 "),bH=a("a"),h1r=o("TFDistilBertModel"),p1r=o(" (DistilBERT model)"),_1r=l(),l8=a("li"),PFe=a("strong"),u1r=o("dpr"),b1r=o(" \u2014 "),vH=a("a"),v1r=o("TFDPRQuestionEncoder"),F1r=o(" (DPR model)"),T1r=l(),i8=a("li"),BFe=a("strong"),M1r=o("electra"),E1r=o(" \u2014 "),FH=a("a"),C1r=o("TFElectraModel"),w1r=o(" (ELECTRA model)"),A1r=l(),d8=a("li"),IFe=a("strong"),L1r=o("flaubert"),y1r=o(" \u2014 "),TH=a("a"),x1r=o("TFFlaubertModel"),$1r=o(" (FlauBERT model)"),k1r=l(),Qs=a("li"),NFe=a("strong"),S1r=o("funnel"),R1r=o(" \u2014 "),MH=a("a"),P1r=o("TFFunnelModel"),B1r=o(" or "),EH=a("a"),I1r=o("TFFunnelBaseModel"),N1r=o(" (Funnel Transformer model)"),q1r=l(),c8=a("li"),qFe=a("strong"),j1r=o("gpt2"),D1r=o(" \u2014 "),CH=a("a"),G1r=o("TFGPT2Model"),O1r=o(" (OpenAI GPT-2 model)"),V1r=l(),f8=a("li"),jFe=a("strong"),X1r=o("gptj"),z1r=o(" \u2014 "),wH=a("a"),Q1r=o("TFGPTJModel"),W1r=o(" (GPT-J model)"),H1r=l(),m8=a("li"),DFe=a("strong"),U1r=o("hubert"),J1r=o(" \u2014 "),AH=a("a"),Y1r=o("TFHubertModel"),K1r=o(" (Hubert model)"),Z1r=l(),g8=a("li"),GFe=a("strong"),e2r=o("layoutlm"),o2r=o(" \u2014 "),LH=a("a"),r2r=o("TFLayoutLMModel"),t2r=o(" (LayoutLM model)"),a2r=l(),h8=a("li"),OFe=a("strong"),n2r=o("led"),s2r=o(" \u2014 "),yH=a("a"),l2r=o("TFLEDModel"),i2r=o(" (LED model)"),d2r=l(),p8=a("li"),VFe=a("strong"),c2r=o("longformer"),f2r=o(" \u2014 "),xH=a("a"),m2r=o("TFLongformerModel"),g2r=o(" (Longformer model)"),h2r=l(),_8=a("li"),XFe=a("strong"),p2r=o("lxmert"),_2r=o(" \u2014 "),$H=a("a"),u2r=o("TFLxmertModel"),b2r=o(" (LXMERT model)"),v2r=l(),u8=a("li"),zFe=a("strong"),F2r=o("marian"),T2r=o(" \u2014 "),kH=a("a"),M2r=o("TFMarianModel"),E2r=o(" (Marian model)"),C2r=l(),b8=a("li"),QFe=a("strong"),w2r=o("mbart"),A2r=o(" \u2014 "),SH=a("a"),L2r=o("TFMBartModel"),y2r=o(" (mBART model)"),x2r=l(),v8=a("li"),WFe=a("strong"),$2r=o("mobilebert"),k2r=o(" \u2014 "),RH=a("a"),S2r=o("TFMobileBertModel"),R2r=o(" (MobileBERT model)"),P2r=l(),F8=a("li"),HFe=a("strong"),B2r=o("mpnet"),I2r=o(" \u2014 "),PH=a("a"),N2r=o("TFMPNetModel"),q2r=o(" (MPNet model)"),j2r=l(),T8=a("li"),UFe=a("strong"),D2r=o("mt5"),G2r=o(" \u2014 "),BH=a("a"),O2r=o("TFMT5Model"),V2r=o(" (MT5 model)"),X2r=l(),M8=a("li"),JFe=a("strong"),z2r=o("openai-gpt"),Q2r=o(" \u2014 "),IH=a("a"),W2r=o("TFOpenAIGPTModel"),H2r=o(" (OpenAI GPT model)"),U2r=l(),E8=a("li"),YFe=a("strong"),J2r=o("opt"),Y2r=o(" \u2014 "),NH=a("a"),K2r=o("TFOPTModel"),Z2r=o(" (OPT model)"),ebr=l(),C8=a("li"),KFe=a("strong"),obr=o("pegasus"),rbr=o(" \u2014 "),qH=a("a"),tbr=o("TFPegasusModel"),abr=o(" (Pegasus model)"),nbr=l(),w8=a("li"),ZFe=a("strong"),sbr=o("rembert"),lbr=o(" \u2014 "),jH=a("a"),ibr=o("TFRemBertModel"),dbr=o(" (RemBERT model)"),cbr=l(),A8=a("li"),e6e=a("strong"),fbr=o("roberta"),mbr=o(" \u2014 "),DH=a("a"),gbr=o("TFRobertaModel"),hbr=o(" (RoBERTa model)"),pbr=l(),L8=a("li"),o6e=a("strong"),_br=o("roformer"),ubr=o(" \u2014 "),GH=a("a"),bbr=o("TFRoFormerModel"),vbr=o(" (RoFormer model)"),Fbr=l(),y8=a("li"),r6e=a("strong"),Tbr=o("speech_to_text"),Mbr=o(" \u2014 "),OH=a("a"),Ebr=o("TFSpeech2TextModel"),Cbr=o(" (Speech2Text model)"),wbr=l(),x8=a("li"),t6e=a("strong"),Abr=o("swin"),Lbr=o(" \u2014 "),VH=a("a"),ybr=o("TFSwinModel"),xbr=o(" (Swin Transformer model)"),$br=l(),$8=a("li"),a6e=a("strong"),kbr=o("t5"),Sbr=o(" \u2014 "),XH=a("a"),Rbr=o("TFT5Model"),Pbr=o(" (T5 model)"),Bbr=l(),k8=a("li"),n6e=a("strong"),Ibr=o("tapas"),Nbr=o(" \u2014 "),zH=a("a"),qbr=o("TFTapasModel"),jbr=o(" (TAPAS model)"),Dbr=l(),S8=a("li"),s6e=a("strong"),Gbr=o("transfo-xl"),Obr=o(" \u2014 "),QH=a("a"),Vbr=o("TFTransfoXLModel"),Xbr=o(" (Transformer-XL model)"),zbr=l(),R8=a("li"),l6e=a("strong"),Qbr=o("vit"),Wbr=o(" \u2014 "),WH=a("a"),Hbr=o("TFViTModel"),Ubr=o(" (ViT model)"),Jbr=l(),P8=a("li"),i6e=a("strong"),Ybr=o("vit_mae"),Kbr=o(" \u2014 "),HH=a("a"),Zbr=o("TFViTMAEModel"),evr=o(" (ViTMAE model)"),ovr=l(),B8=a("li"),d6e=a("strong"),rvr=o("wav2vec2"),tvr=o(" \u2014 "),UH=a("a"),avr=o("TFWav2Vec2Model"),nvr=o(" (Wav2Vec2 model)"),svr=l(),I8=a("li"),c6e=a("strong"),lvr=o("xlm"),ivr=o(" \u2014 "),JH=a("a"),dvr=o("TFXLMModel"),cvr=o(" (XLM model)"),fvr=l(),N8=a("li"),f6e=a("strong"),mvr=o("xlm-roberta"),gvr=o(" \u2014 "),YH=a("a"),hvr=o("TFXLMRobertaModel"),pvr=o(" (XLM-RoBERTa model)"),_vr=l(),q8=a("li"),m6e=a("strong"),uvr=o("xlnet"),bvr=o(" \u2014 "),KH=a("a"),vvr=o("TFXLNetModel"),Fvr=o(" (XLNet model)"),Tvr=l(),F(j8.$$.fragment),HOe=l(),tc=a("h2"),D8=a("a"),g6e=a("span"),F(Fy.$$.fragment),Mvr=l(),h6e=a("span"),Evr=o("TFAutoModelForPreTraining"),UOe=l(),or=a("div"),F(Ty.$$.fragment),Cvr=l(),ac=a("p"),wvr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ZH=a("a"),Avr=o("from_pretrained()"),Lvr=o(" class method or the "),eU=a("a"),yvr=o("from_config()"),xvr=o(` class
method.`),$vr=l(),My=a("p"),kvr=o("This class cannot be instantiated directly using "),p6e=a("code"),Svr=o("__init__()"),Rvr=o(" (throws an error)."),Pvr=l(),kt=a("div"),F(Ey.$$.fragment),Bvr=l(),_6e=a("p"),Ivr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Nvr=l(),nc=a("p"),qvr=o(`Note:
Loading a model from its configuration file does `),u6e=a("strong"),jvr=o("not"),Dvr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),oU=a("a"),Gvr=o("from_pretrained()"),Ovr=o(" to load the model weights."),Vvr=l(),F(G8.$$.fragment),Xvr=l(),xr=a("div"),F(Cy.$$.fragment),zvr=l(),b6e=a("p"),Qvr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Wvr=l(),nn=a("p"),Hvr=o("The model class to instantiate is selected based on the "),v6e=a("code"),Uvr=o("model_type"),Jvr=o(` property of the config object (either
passed as an argument or loaded from `),F6e=a("code"),Yvr=o("pretrained_model_name_or_path"),Kvr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T6e=a("code"),Zvr=o("pretrained_model_name_or_path"),eFr=o(":"),oFr=l(),se=a("ul"),O8=a("li"),M6e=a("strong"),rFr=o("albert"),tFr=o(" \u2014 "),rU=a("a"),aFr=o("TFAlbertForPreTraining"),nFr=o(" (ALBERT model)"),sFr=l(),V8=a("li"),E6e=a("strong"),lFr=o("bart"),iFr=o(" \u2014 "),tU=a("a"),dFr=o("TFBartForConditionalGeneration"),cFr=o(" (BART model)"),fFr=l(),X8=a("li"),C6e=a("strong"),mFr=o("bert"),gFr=o(" \u2014 "),aU=a("a"),hFr=o("TFBertForPreTraining"),pFr=o(" (BERT model)"),_Fr=l(),z8=a("li"),w6e=a("strong"),uFr=o("camembert"),bFr=o(" \u2014 "),nU=a("a"),vFr=o("TFCamembertForMaskedLM"),FFr=o(" (CamemBERT model)"),TFr=l(),Q8=a("li"),A6e=a("strong"),MFr=o("ctrl"),EFr=o(" \u2014 "),sU=a("a"),CFr=o("TFCTRLLMHeadModel"),wFr=o(" (CTRL model)"),AFr=l(),W8=a("li"),L6e=a("strong"),LFr=o("distilbert"),yFr=o(" \u2014 "),lU=a("a"),xFr=o("TFDistilBertForMaskedLM"),$Fr=o(" (DistilBERT model)"),kFr=l(),H8=a("li"),y6e=a("strong"),SFr=o("electra"),RFr=o(" \u2014 "),iU=a("a"),PFr=o("TFElectraForPreTraining"),BFr=o(" (ELECTRA model)"),IFr=l(),U8=a("li"),x6e=a("strong"),NFr=o("flaubert"),qFr=o(" \u2014 "),dU=a("a"),jFr=o("TFFlaubertWithLMHeadModel"),DFr=o(" (FlauBERT model)"),GFr=l(),J8=a("li"),$6e=a("strong"),OFr=o("funnel"),VFr=o(" \u2014 "),cU=a("a"),XFr=o("TFFunnelForPreTraining"),zFr=o(" (Funnel Transformer model)"),QFr=l(),Y8=a("li"),k6e=a("strong"),WFr=o("gpt2"),HFr=o(" \u2014 "),fU=a("a"),UFr=o("TFGPT2LMHeadModel"),JFr=o(" (OpenAI GPT-2 model)"),YFr=l(),K8=a("li"),S6e=a("strong"),KFr=o("layoutlm"),ZFr=o(" \u2014 "),mU=a("a"),e6r=o("TFLayoutLMForMaskedLM"),o6r=o(" (LayoutLM model)"),r6r=l(),Z8=a("li"),R6e=a("strong"),t6r=o("lxmert"),a6r=o(" \u2014 "),gU=a("a"),n6r=o("TFLxmertForPreTraining"),s6r=o(" (LXMERT model)"),l6r=l(),e9=a("li"),P6e=a("strong"),i6r=o("mobilebert"),d6r=o(" \u2014 "),hU=a("a"),c6r=o("TFMobileBertForPreTraining"),f6r=o(" (MobileBERT model)"),m6r=l(),o9=a("li"),B6e=a("strong"),g6r=o("mpnet"),h6r=o(" \u2014 "),pU=a("a"),p6r=o("TFMPNetForMaskedLM"),_6r=o(" (MPNet model)"),u6r=l(),r9=a("li"),I6e=a("strong"),b6r=o("openai-gpt"),v6r=o(" \u2014 "),_U=a("a"),F6r=o("TFOpenAIGPTLMHeadModel"),T6r=o(" (OpenAI GPT model)"),M6r=l(),t9=a("li"),N6e=a("strong"),E6r=o("roberta"),C6r=o(" \u2014 "),uU=a("a"),w6r=o("TFRobertaForMaskedLM"),A6r=o(" (RoBERTa model)"),L6r=l(),a9=a("li"),q6e=a("strong"),y6r=o("t5"),x6r=o(" \u2014 "),bU=a("a"),$6r=o("TFT5ForConditionalGeneration"),k6r=o(" (T5 model)"),S6r=l(),n9=a("li"),j6e=a("strong"),R6r=o("tapas"),P6r=o(" \u2014 "),vU=a("a"),B6r=o("TFTapasForMaskedLM"),I6r=o(" (TAPAS model)"),N6r=l(),s9=a("li"),D6e=a("strong"),q6r=o("transfo-xl"),j6r=o(" \u2014 "),FU=a("a"),D6r=o("TFTransfoXLLMHeadModel"),G6r=o(" (Transformer-XL model)"),O6r=l(),l9=a("li"),G6e=a("strong"),V6r=o("vit_mae"),X6r=o(" \u2014 "),TU=a("a"),z6r=o("TFViTMAEForPreTraining"),Q6r=o(" (ViTMAE model)"),W6r=l(),i9=a("li"),O6e=a("strong"),H6r=o("xlm"),U6r=o(" \u2014 "),MU=a("a"),J6r=o("TFXLMWithLMHeadModel"),Y6r=o(" (XLM model)"),K6r=l(),d9=a("li"),V6e=a("strong"),Z6r=o("xlm-roberta"),eTr=o(" \u2014 "),EU=a("a"),oTr=o("TFXLMRobertaForMaskedLM"),rTr=o(" (XLM-RoBERTa model)"),tTr=l(),c9=a("li"),X6e=a("strong"),aTr=o("xlnet"),nTr=o(" \u2014 "),CU=a("a"),sTr=o("TFXLNetLMHeadModel"),lTr=o(" (XLNet model)"),iTr=l(),F(f9.$$.fragment),JOe=l(),sc=a("h2"),m9=a("a"),z6e=a("span"),F(wy.$$.fragment),dTr=l(),Q6e=a("span"),cTr=o("TFAutoModelForCausalLM"),YOe=l(),rr=a("div"),F(Ay.$$.fragment),fTr=l(),lc=a("p"),mTr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wU=a("a"),gTr=o("from_pretrained()"),hTr=o(" class method or the "),AU=a("a"),pTr=o("from_config()"),_Tr=o(` class
method.`),uTr=l(),Ly=a("p"),bTr=o("This class cannot be instantiated directly using "),W6e=a("code"),vTr=o("__init__()"),FTr=o(" (throws an error)."),TTr=l(),St=a("div"),F(yy.$$.fragment),MTr=l(),H6e=a("p"),ETr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),CTr=l(),ic=a("p"),wTr=o(`Note:
Loading a model from its configuration file does `),U6e=a("strong"),ATr=o("not"),LTr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=a("a"),yTr=o("from_pretrained()"),xTr=o(" to load the model weights."),$Tr=l(),F(g9.$$.fragment),kTr=l(),$r=a("div"),F(xy.$$.fragment),STr=l(),J6e=a("p"),RTr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),PTr=l(),sn=a("p"),BTr=o("The model class to instantiate is selected based on the "),Y6e=a("code"),ITr=o("model_type"),NTr=o(` property of the config object (either
passed as an argument or loaded from `),K6e=a("code"),qTr=o("pretrained_model_name_or_path"),jTr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z6e=a("code"),DTr=o("pretrained_model_name_or_path"),GTr=o(":"),OTr=l(),Me=a("ul"),h9=a("li"),eTe=a("strong"),VTr=o("bert"),XTr=o(" \u2014 "),yU=a("a"),zTr=o("TFBertLMHeadModel"),QTr=o(" (BERT model)"),WTr=l(),p9=a("li"),oTe=a("strong"),HTr=o("camembert"),UTr=o(" \u2014 "),xU=a("a"),JTr=o("TFCamembertForCausalLM"),YTr=o(" (CamemBERT model)"),KTr=l(),_9=a("li"),rTe=a("strong"),ZTr=o("ctrl"),e7r=o(" \u2014 "),$U=a("a"),o7r=o("TFCTRLLMHeadModel"),r7r=o(" (CTRL model)"),t7r=l(),u9=a("li"),tTe=a("strong"),a7r=o("gpt2"),n7r=o(" \u2014 "),kU=a("a"),s7r=o("TFGPT2LMHeadModel"),l7r=o(" (OpenAI GPT-2 model)"),i7r=l(),b9=a("li"),aTe=a("strong"),d7r=o("gptj"),c7r=o(" \u2014 "),SU=a("a"),f7r=o("TFGPTJForCausalLM"),m7r=o(" (GPT-J model)"),g7r=l(),v9=a("li"),nTe=a("strong"),h7r=o("openai-gpt"),p7r=o(" \u2014 "),RU=a("a"),_7r=o("TFOpenAIGPTLMHeadModel"),u7r=o(" (OpenAI GPT model)"),b7r=l(),F9=a("li"),sTe=a("strong"),v7r=o("opt"),F7r=o(" \u2014 "),PU=a("a"),T7r=o("TFOPTForCausalLM"),M7r=o(" (OPT model)"),E7r=l(),T9=a("li"),lTe=a("strong"),C7r=o("rembert"),w7r=o(" \u2014 "),BU=a("a"),A7r=o("TFRemBertForCausalLM"),L7r=o(" (RemBERT model)"),y7r=l(),M9=a("li"),iTe=a("strong"),x7r=o("roberta"),$7r=o(" \u2014 "),IU=a("a"),k7r=o("TFRobertaForCausalLM"),S7r=o(" (RoBERTa model)"),R7r=l(),E9=a("li"),dTe=a("strong"),P7r=o("roformer"),B7r=o(" \u2014 "),NU=a("a"),I7r=o("TFRoFormerForCausalLM"),N7r=o(" (RoFormer model)"),q7r=l(),C9=a("li"),cTe=a("strong"),j7r=o("transfo-xl"),D7r=o(" \u2014 "),qU=a("a"),G7r=o("TFTransfoXLLMHeadModel"),O7r=o(" (Transformer-XL model)"),V7r=l(),w9=a("li"),fTe=a("strong"),X7r=o("xlm"),z7r=o(" \u2014 "),jU=a("a"),Q7r=o("TFXLMWithLMHeadModel"),W7r=o(" (XLM model)"),H7r=l(),A9=a("li"),mTe=a("strong"),U7r=o("xlnet"),J7r=o(" \u2014 "),DU=a("a"),Y7r=o("TFXLNetLMHeadModel"),K7r=o(" (XLNet model)"),Z7r=l(),F(L9.$$.fragment),KOe=l(),dc=a("h2"),y9=a("a"),gTe=a("span"),F($y.$$.fragment),e8r=l(),hTe=a("span"),o8r=o("TFAutoModelForImageClassification"),ZOe=l(),tr=a("div"),F(ky.$$.fragment),r8r=l(),cc=a("p"),t8r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),GU=a("a"),a8r=o("from_pretrained()"),n8r=o(" class method or the "),OU=a("a"),s8r=o("from_config()"),l8r=o(` class
method.`),i8r=l(),Sy=a("p"),d8r=o("This class cannot be instantiated directly using "),pTe=a("code"),c8r=o("__init__()"),f8r=o(" (throws an error)."),m8r=l(),Rt=a("div"),F(Ry.$$.fragment),g8r=l(),_Te=a("p"),h8r=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),p8r=l(),fc=a("p"),_8r=o(`Note:
Loading a model from its configuration file does `),uTe=a("strong"),u8r=o("not"),b8r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),VU=a("a"),v8r=o("from_pretrained()"),F8r=o(" to load the model weights."),T8r=l(),F(x9.$$.fragment),M8r=l(),kr=a("div"),F(Py.$$.fragment),E8r=l(),bTe=a("p"),C8r=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),w8r=l(),ln=a("p"),A8r=o("The model class to instantiate is selected based on the "),vTe=a("code"),L8r=o("model_type"),y8r=o(` property of the config object (either
passed as an argument or loaded from `),FTe=a("code"),x8r=o("pretrained_model_name_or_path"),$8r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TTe=a("code"),k8r=o("pretrained_model_name_or_path"),S8r=o(":"),R8r=l(),dn=a("ul"),$9=a("li"),MTe=a("strong"),P8r=o("convnext"),B8r=o(" \u2014 "),XU=a("a"),I8r=o("TFConvNextForImageClassification"),N8r=o(" (ConvNeXT model)"),q8r=l(),k9=a("li"),ETe=a("strong"),j8r=o("data2vec-vision"),D8r=o(" \u2014 "),zU=a("a"),G8r=o("TFData2VecVisionForImageClassification"),O8r=o(" (Data2VecVision model)"),V8r=l(),S9=a("li"),CTe=a("strong"),X8r=o("swin"),z8r=o(" \u2014 "),QU=a("a"),Q8r=o("TFSwinForImageClassification"),W8r=o(" (Swin Transformer model)"),H8r=l(),R9=a("li"),wTe=a("strong"),U8r=o("vit"),J8r=o(" \u2014 "),WU=a("a"),Y8r=o("TFViTForImageClassification"),K8r=o(" (ViT model)"),Z8r=l(),F(P9.$$.fragment),eVe=l(),mc=a("h2"),B9=a("a"),ATe=a("span"),F(By.$$.fragment),e9r=l(),LTe=a("span"),o9r=o("TFAutoModelForMaskedLM"),oVe=l(),ar=a("div"),F(Iy.$$.fragment),r9r=l(),gc=a("p"),t9r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),HU=a("a"),a9r=o("from_pretrained()"),n9r=o(" class method or the "),UU=a("a"),s9r=o("from_config()"),l9r=o(` class
method.`),i9r=l(),Ny=a("p"),d9r=o("This class cannot be instantiated directly using "),yTe=a("code"),c9r=o("__init__()"),f9r=o(" (throws an error)."),m9r=l(),Pt=a("div"),F(qy.$$.fragment),g9r=l(),xTe=a("p"),h9r=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),p9r=l(),hc=a("p"),_9r=o(`Note:
Loading a model from its configuration file does `),$Te=a("strong"),u9r=o("not"),b9r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),JU=a("a"),v9r=o("from_pretrained()"),F9r=o(" to load the model weights."),T9r=l(),F(I9.$$.fragment),M9r=l(),Sr=a("div"),F(jy.$$.fragment),E9r=l(),kTe=a("p"),C9r=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),w9r=l(),cn=a("p"),A9r=o("The model class to instantiate is selected based on the "),STe=a("code"),L9r=o("model_type"),y9r=o(` property of the config object (either
passed as an argument or loaded from `),RTe=a("code"),x9r=o("pretrained_model_name_or_path"),$9r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PTe=a("code"),k9r=o("pretrained_model_name_or_path"),S9r=o(":"),R9r=l(),ie=a("ul"),N9=a("li"),BTe=a("strong"),P9r=o("albert"),B9r=o(" \u2014 "),YU=a("a"),I9r=o("TFAlbertForMaskedLM"),N9r=o(" (ALBERT model)"),q9r=l(),q9=a("li"),ITe=a("strong"),j9r=o("bert"),D9r=o(" \u2014 "),KU=a("a"),G9r=o("TFBertForMaskedLM"),O9r=o(" (BERT model)"),V9r=l(),j9=a("li"),NTe=a("strong"),X9r=o("camembert"),z9r=o(" \u2014 "),ZU=a("a"),Q9r=o("TFCamembertForMaskedLM"),W9r=o(" (CamemBERT model)"),H9r=l(),D9=a("li"),qTe=a("strong"),U9r=o("convbert"),J9r=o(" \u2014 "),eJ=a("a"),Y9r=o("TFConvBertForMaskedLM"),K9r=o(" (ConvBERT model)"),Z9r=l(),G9=a("li"),jTe=a("strong"),eMr=o("deberta"),oMr=o(" \u2014 "),oJ=a("a"),rMr=o("TFDebertaForMaskedLM"),tMr=o(" (DeBERTa model)"),aMr=l(),O9=a("li"),DTe=a("strong"),nMr=o("deberta-v2"),sMr=o(" \u2014 "),rJ=a("a"),lMr=o("TFDebertaV2ForMaskedLM"),iMr=o(" (DeBERTa-v2 model)"),dMr=l(),V9=a("li"),GTe=a("strong"),cMr=o("distilbert"),fMr=o(" \u2014 "),tJ=a("a"),mMr=o("TFDistilBertForMaskedLM"),gMr=o(" (DistilBERT model)"),hMr=l(),X9=a("li"),OTe=a("strong"),pMr=o("electra"),_Mr=o(" \u2014 "),aJ=a("a"),uMr=o("TFElectraForMaskedLM"),bMr=o(" (ELECTRA model)"),vMr=l(),z9=a("li"),VTe=a("strong"),FMr=o("flaubert"),TMr=o(" \u2014 "),nJ=a("a"),MMr=o("TFFlaubertWithLMHeadModel"),EMr=o(" (FlauBERT model)"),CMr=l(),Q9=a("li"),XTe=a("strong"),wMr=o("funnel"),AMr=o(" \u2014 "),sJ=a("a"),LMr=o("TFFunnelForMaskedLM"),yMr=o(" (Funnel Transformer model)"),xMr=l(),W9=a("li"),zTe=a("strong"),$Mr=o("layoutlm"),kMr=o(" \u2014 "),lJ=a("a"),SMr=o("TFLayoutLMForMaskedLM"),RMr=o(" (LayoutLM model)"),PMr=l(),H9=a("li"),QTe=a("strong"),BMr=o("longformer"),IMr=o(" \u2014 "),iJ=a("a"),NMr=o("TFLongformerForMaskedLM"),qMr=o(" (Longformer model)"),jMr=l(),U9=a("li"),WTe=a("strong"),DMr=o("mobilebert"),GMr=o(" \u2014 "),dJ=a("a"),OMr=o("TFMobileBertForMaskedLM"),VMr=o(" (MobileBERT model)"),XMr=l(),J9=a("li"),HTe=a("strong"),zMr=o("mpnet"),QMr=o(" \u2014 "),cJ=a("a"),WMr=o("TFMPNetForMaskedLM"),HMr=o(" (MPNet model)"),UMr=l(),Y9=a("li"),UTe=a("strong"),JMr=o("rembert"),YMr=o(" \u2014 "),fJ=a("a"),KMr=o("TFRemBertForMaskedLM"),ZMr=o(" (RemBERT model)"),eEr=l(),K9=a("li"),JTe=a("strong"),oEr=o("roberta"),rEr=o(" \u2014 "),mJ=a("a"),tEr=o("TFRobertaForMaskedLM"),aEr=o(" (RoBERTa model)"),nEr=l(),Z9=a("li"),YTe=a("strong"),sEr=o("roformer"),lEr=o(" \u2014 "),gJ=a("a"),iEr=o("TFRoFormerForMaskedLM"),dEr=o(" (RoFormer model)"),cEr=l(),eM=a("li"),KTe=a("strong"),fEr=o("tapas"),mEr=o(" \u2014 "),hJ=a("a"),gEr=o("TFTapasForMaskedLM"),hEr=o(" (TAPAS model)"),pEr=l(),oM=a("li"),ZTe=a("strong"),_Er=o("xlm"),uEr=o(" \u2014 "),pJ=a("a"),bEr=o("TFXLMWithLMHeadModel"),vEr=o(" (XLM model)"),FEr=l(),rM=a("li"),e7e=a("strong"),TEr=o("xlm-roberta"),MEr=o(" \u2014 "),_J=a("a"),EEr=o("TFXLMRobertaForMaskedLM"),CEr=o(" (XLM-RoBERTa model)"),wEr=l(),F(tM.$$.fragment),rVe=l(),pc=a("h2"),aM=a("a"),o7e=a("span"),F(Dy.$$.fragment),AEr=l(),r7e=a("span"),LEr=o("TFAutoModelForSeq2SeqLM"),tVe=l(),nr=a("div"),F(Gy.$$.fragment),yEr=l(),_c=a("p"),xEr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),uJ=a("a"),$Er=o("from_pretrained()"),kEr=o(" class method or the "),bJ=a("a"),SEr=o("from_config()"),REr=o(` class
method.`),PEr=l(),Oy=a("p"),BEr=o("This class cannot be instantiated directly using "),t7e=a("code"),IEr=o("__init__()"),NEr=o(" (throws an error)."),qEr=l(),Bt=a("div"),F(Vy.$$.fragment),jEr=l(),a7e=a("p"),DEr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),GEr=l(),uc=a("p"),OEr=o(`Note:
Loading a model from its configuration file does `),n7e=a("strong"),VEr=o("not"),XEr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),vJ=a("a"),zEr=o("from_pretrained()"),QEr=o(" to load the model weights."),WEr=l(),F(nM.$$.fragment),HEr=l(),Rr=a("div"),F(Xy.$$.fragment),UEr=l(),s7e=a("p"),JEr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),YEr=l(),fn=a("p"),KEr=o("The model class to instantiate is selected based on the "),l7e=a("code"),ZEr=o("model_type"),e4r=o(` property of the config object (either
passed as an argument or loaded from `),i7e=a("code"),o4r=o("pretrained_model_name_or_path"),r4r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d7e=a("code"),t4r=o("pretrained_model_name_or_path"),a4r=o(":"),n4r=l(),ye=a("ul"),sM=a("li"),c7e=a("strong"),s4r=o("bart"),l4r=o(" \u2014 "),FJ=a("a"),i4r=o("TFBartForConditionalGeneration"),d4r=o(" (BART model)"),c4r=l(),lM=a("li"),f7e=a("strong"),f4r=o("blenderbot"),m4r=o(" \u2014 "),TJ=a("a"),g4r=o("TFBlenderbotForConditionalGeneration"),h4r=o(" (Blenderbot model)"),p4r=l(),iM=a("li"),m7e=a("strong"),_4r=o("blenderbot-small"),u4r=o(" \u2014 "),MJ=a("a"),b4r=o("TFBlenderbotSmallForConditionalGeneration"),v4r=o(" (BlenderbotSmall model)"),F4r=l(),dM=a("li"),g7e=a("strong"),T4r=o("encoder-decoder"),M4r=o(" \u2014 "),EJ=a("a"),E4r=o("TFEncoderDecoderModel"),C4r=o(" (Encoder decoder model)"),w4r=l(),cM=a("li"),h7e=a("strong"),A4r=o("led"),L4r=o(" \u2014 "),CJ=a("a"),y4r=o("TFLEDForConditionalGeneration"),x4r=o(" (LED model)"),$4r=l(),fM=a("li"),p7e=a("strong"),k4r=o("marian"),S4r=o(" \u2014 "),wJ=a("a"),R4r=o("TFMarianMTModel"),P4r=o(" (Marian model)"),B4r=l(),mM=a("li"),_7e=a("strong"),I4r=o("mbart"),N4r=o(" \u2014 "),AJ=a("a"),q4r=o("TFMBartForConditionalGeneration"),j4r=o(" (mBART model)"),D4r=l(),gM=a("li"),u7e=a("strong"),G4r=o("mt5"),O4r=o(" \u2014 "),LJ=a("a"),V4r=o("TFMT5ForConditionalGeneration"),X4r=o(" (MT5 model)"),z4r=l(),hM=a("li"),b7e=a("strong"),Q4r=o("pegasus"),W4r=o(" \u2014 "),yJ=a("a"),H4r=o("TFPegasusForConditionalGeneration"),U4r=o(" (Pegasus model)"),J4r=l(),pM=a("li"),v7e=a("strong"),Y4r=o("t5"),K4r=o(" \u2014 "),xJ=a("a"),Z4r=o("TFT5ForConditionalGeneration"),eCr=o(" (T5 model)"),oCr=l(),F(_M.$$.fragment),aVe=l(),bc=a("h2"),uM=a("a"),F7e=a("span"),F(zy.$$.fragment),rCr=l(),T7e=a("span"),tCr=o("TFAutoModelForSequenceClassification"),nVe=l(),sr=a("div"),F(Qy.$$.fragment),aCr=l(),vc=a("p"),nCr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),$J=a("a"),sCr=o("from_pretrained()"),lCr=o(" class method or the "),kJ=a("a"),iCr=o("from_config()"),dCr=o(` class
method.`),cCr=l(),Wy=a("p"),fCr=o("This class cannot be instantiated directly using "),M7e=a("code"),mCr=o("__init__()"),gCr=o(" (throws an error)."),hCr=l(),It=a("div"),F(Hy.$$.fragment),pCr=l(),E7e=a("p"),_Cr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),uCr=l(),Fc=a("p"),bCr=o(`Note:
Loading a model from its configuration file does `),C7e=a("strong"),vCr=o("not"),FCr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SJ=a("a"),TCr=o("from_pretrained()"),MCr=o(" to load the model weights."),ECr=l(),F(bM.$$.fragment),CCr=l(),Pr=a("div"),F(Uy.$$.fragment),wCr=l(),w7e=a("p"),ACr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),LCr=l(),mn=a("p"),yCr=o("The model class to instantiate is selected based on the "),A7e=a("code"),xCr=o("model_type"),$Cr=o(` property of the config object (either
passed as an argument or loaded from `),L7e=a("code"),kCr=o("pretrained_model_name_or_path"),SCr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y7e=a("code"),RCr=o("pretrained_model_name_or_path"),PCr=o(":"),BCr=l(),te=a("ul"),vM=a("li"),x7e=a("strong"),ICr=o("albert"),NCr=o(" \u2014 "),RJ=a("a"),qCr=o("TFAlbertForSequenceClassification"),jCr=o(" (ALBERT model)"),DCr=l(),FM=a("li"),$7e=a("strong"),GCr=o("bert"),OCr=o(" \u2014 "),PJ=a("a"),VCr=o("TFBertForSequenceClassification"),XCr=o(" (BERT model)"),zCr=l(),TM=a("li"),k7e=a("strong"),QCr=o("camembert"),WCr=o(" \u2014 "),BJ=a("a"),HCr=o("TFCamembertForSequenceClassification"),UCr=o(" (CamemBERT model)"),JCr=l(),MM=a("li"),S7e=a("strong"),YCr=o("convbert"),KCr=o(" \u2014 "),IJ=a("a"),ZCr=o("TFConvBertForSequenceClassification"),e5r=o(" (ConvBERT model)"),o5r=l(),EM=a("li"),R7e=a("strong"),r5r=o("ctrl"),t5r=o(" \u2014 "),NJ=a("a"),a5r=o("TFCTRLForSequenceClassification"),n5r=o(" (CTRL model)"),s5r=l(),CM=a("li"),P7e=a("strong"),l5r=o("deberta"),i5r=o(" \u2014 "),qJ=a("a"),d5r=o("TFDebertaForSequenceClassification"),c5r=o(" (DeBERTa model)"),f5r=l(),wM=a("li"),B7e=a("strong"),m5r=o("deberta-v2"),g5r=o(" \u2014 "),jJ=a("a"),h5r=o("TFDebertaV2ForSequenceClassification"),p5r=o(" (DeBERTa-v2 model)"),_5r=l(),AM=a("li"),I7e=a("strong"),u5r=o("distilbert"),b5r=o(" \u2014 "),DJ=a("a"),v5r=o("TFDistilBertForSequenceClassification"),F5r=o(" (DistilBERT model)"),T5r=l(),LM=a("li"),N7e=a("strong"),M5r=o("electra"),E5r=o(" \u2014 "),GJ=a("a"),C5r=o("TFElectraForSequenceClassification"),w5r=o(" (ELECTRA model)"),A5r=l(),yM=a("li"),q7e=a("strong"),L5r=o("flaubert"),y5r=o(" \u2014 "),OJ=a("a"),x5r=o("TFFlaubertForSequenceClassification"),$5r=o(" (FlauBERT model)"),k5r=l(),xM=a("li"),j7e=a("strong"),S5r=o("funnel"),R5r=o(" \u2014 "),VJ=a("a"),P5r=o("TFFunnelForSequenceClassification"),B5r=o(" (Funnel Transformer model)"),I5r=l(),$M=a("li"),D7e=a("strong"),N5r=o("gpt2"),q5r=o(" \u2014 "),XJ=a("a"),j5r=o("TFGPT2ForSequenceClassification"),D5r=o(" (OpenAI GPT-2 model)"),G5r=l(),kM=a("li"),G7e=a("strong"),O5r=o("gptj"),V5r=o(" \u2014 "),zJ=a("a"),X5r=o("TFGPTJForSequenceClassification"),z5r=o(" (GPT-J model)"),Q5r=l(),SM=a("li"),O7e=a("strong"),W5r=o("layoutlm"),H5r=o(" \u2014 "),QJ=a("a"),U5r=o("TFLayoutLMForSequenceClassification"),J5r=o(" (LayoutLM model)"),Y5r=l(),RM=a("li"),V7e=a("strong"),K5r=o("longformer"),Z5r=o(" \u2014 "),WJ=a("a"),e3r=o("TFLongformerForSequenceClassification"),o3r=o(" (Longformer model)"),r3r=l(),PM=a("li"),X7e=a("strong"),t3r=o("mobilebert"),a3r=o(" \u2014 "),HJ=a("a"),n3r=o("TFMobileBertForSequenceClassification"),s3r=o(" (MobileBERT model)"),l3r=l(),BM=a("li"),z7e=a("strong"),i3r=o("mpnet"),d3r=o(" \u2014 "),UJ=a("a"),c3r=o("TFMPNetForSequenceClassification"),f3r=o(" (MPNet model)"),m3r=l(),IM=a("li"),Q7e=a("strong"),g3r=o("openai-gpt"),h3r=o(" \u2014 "),JJ=a("a"),p3r=o("TFOpenAIGPTForSequenceClassification"),_3r=o(" (OpenAI GPT model)"),u3r=l(),NM=a("li"),W7e=a("strong"),b3r=o("rembert"),v3r=o(" \u2014 "),YJ=a("a"),F3r=o("TFRemBertForSequenceClassification"),T3r=o(" (RemBERT model)"),M3r=l(),qM=a("li"),H7e=a("strong"),E3r=o("roberta"),C3r=o(" \u2014 "),KJ=a("a"),w3r=o("TFRobertaForSequenceClassification"),A3r=o(" (RoBERTa model)"),L3r=l(),jM=a("li"),U7e=a("strong"),y3r=o("roformer"),x3r=o(" \u2014 "),ZJ=a("a"),$3r=o("TFRoFormerForSequenceClassification"),k3r=o(" (RoFormer model)"),S3r=l(),DM=a("li"),J7e=a("strong"),R3r=o("tapas"),P3r=o(" \u2014 "),eY=a("a"),B3r=o("TFTapasForSequenceClassification"),I3r=o(" (TAPAS model)"),N3r=l(),GM=a("li"),Y7e=a("strong"),q3r=o("transfo-xl"),j3r=o(" \u2014 "),oY=a("a"),D3r=o("TFTransfoXLForSequenceClassification"),G3r=o(" (Transformer-XL model)"),O3r=l(),OM=a("li"),K7e=a("strong"),V3r=o("xlm"),X3r=o(" \u2014 "),rY=a("a"),z3r=o("TFXLMForSequenceClassification"),Q3r=o(" (XLM model)"),W3r=l(),VM=a("li"),Z7e=a("strong"),H3r=o("xlm-roberta"),U3r=o(" \u2014 "),tY=a("a"),J3r=o("TFXLMRobertaForSequenceClassification"),Y3r=o(" (XLM-RoBERTa model)"),K3r=l(),XM=a("li"),e8e=a("strong"),Z3r=o("xlnet"),e0r=o(" \u2014 "),aY=a("a"),o0r=o("TFXLNetForSequenceClassification"),r0r=o(" (XLNet model)"),t0r=l(),F(zM.$$.fragment),sVe=l(),Tc=a("h2"),QM=a("a"),o8e=a("span"),F(Jy.$$.fragment),a0r=l(),r8e=a("span"),n0r=o("TFAutoModelForMultipleChoice"),lVe=l(),lr=a("div"),F(Yy.$$.fragment),s0r=l(),Mc=a("p"),l0r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),nY=a("a"),i0r=o("from_pretrained()"),d0r=o(" class method or the "),sY=a("a"),c0r=o("from_config()"),f0r=o(` class
method.`),m0r=l(),Ky=a("p"),g0r=o("This class cannot be instantiated directly using "),t8e=a("code"),h0r=o("__init__()"),p0r=o(" (throws an error)."),_0r=l(),Nt=a("div"),F(Zy.$$.fragment),u0r=l(),a8e=a("p"),b0r=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),v0r=l(),Ec=a("p"),F0r=o(`Note:
Loading a model from its configuration file does `),n8e=a("strong"),T0r=o("not"),M0r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),lY=a("a"),E0r=o("from_pretrained()"),C0r=o(" to load the model weights."),w0r=l(),F(WM.$$.fragment),A0r=l(),Br=a("div"),F(ex.$$.fragment),L0r=l(),s8e=a("p"),y0r=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),x0r=l(),gn=a("p"),$0r=o("The model class to instantiate is selected based on the "),l8e=a("code"),k0r=o("model_type"),S0r=o(` property of the config object (either
passed as an argument or loaded from `),i8e=a("code"),R0r=o("pretrained_model_name_or_path"),P0r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d8e=a("code"),B0r=o("pretrained_model_name_or_path"),I0r=o(":"),N0r=l(),_e=a("ul"),HM=a("li"),c8e=a("strong"),q0r=o("albert"),j0r=o(" \u2014 "),iY=a("a"),D0r=o("TFAlbertForMultipleChoice"),G0r=o(" (ALBERT model)"),O0r=l(),UM=a("li"),f8e=a("strong"),V0r=o("bert"),X0r=o(" \u2014 "),dY=a("a"),z0r=o("TFBertForMultipleChoice"),Q0r=o(" (BERT model)"),W0r=l(),JM=a("li"),m8e=a("strong"),H0r=o("camembert"),U0r=o(" \u2014 "),cY=a("a"),J0r=o("TFCamembertForMultipleChoice"),Y0r=o(" (CamemBERT model)"),K0r=l(),YM=a("li"),g8e=a("strong"),Z0r=o("convbert"),ewr=o(" \u2014 "),fY=a("a"),owr=o("TFConvBertForMultipleChoice"),rwr=o(" (ConvBERT model)"),twr=l(),KM=a("li"),h8e=a("strong"),awr=o("distilbert"),nwr=o(" \u2014 "),mY=a("a"),swr=o("TFDistilBertForMultipleChoice"),lwr=o(" (DistilBERT model)"),iwr=l(),ZM=a("li"),p8e=a("strong"),dwr=o("electra"),cwr=o(" \u2014 "),gY=a("a"),fwr=o("TFElectraForMultipleChoice"),mwr=o(" (ELECTRA model)"),gwr=l(),eE=a("li"),_8e=a("strong"),hwr=o("flaubert"),pwr=o(" \u2014 "),hY=a("a"),_wr=o("TFFlaubertForMultipleChoice"),uwr=o(" (FlauBERT model)"),bwr=l(),oE=a("li"),u8e=a("strong"),vwr=o("funnel"),Fwr=o(" \u2014 "),pY=a("a"),Twr=o("TFFunnelForMultipleChoice"),Mwr=o(" (Funnel Transformer model)"),Ewr=l(),rE=a("li"),b8e=a("strong"),Cwr=o("longformer"),wwr=o(" \u2014 "),_Y=a("a"),Awr=o("TFLongformerForMultipleChoice"),Lwr=o(" (Longformer model)"),ywr=l(),tE=a("li"),v8e=a("strong"),xwr=o("mobilebert"),$wr=o(" \u2014 "),uY=a("a"),kwr=o("TFMobileBertForMultipleChoice"),Swr=o(" (MobileBERT model)"),Rwr=l(),aE=a("li"),F8e=a("strong"),Pwr=o("mpnet"),Bwr=o(" \u2014 "),bY=a("a"),Iwr=o("TFMPNetForMultipleChoice"),Nwr=o(" (MPNet model)"),qwr=l(),nE=a("li"),T8e=a("strong"),jwr=o("rembert"),Dwr=o(" \u2014 "),vY=a("a"),Gwr=o("TFRemBertForMultipleChoice"),Owr=o(" (RemBERT model)"),Vwr=l(),sE=a("li"),M8e=a("strong"),Xwr=o("roberta"),zwr=o(" \u2014 "),FY=a("a"),Qwr=o("TFRobertaForMultipleChoice"),Wwr=o(" (RoBERTa model)"),Hwr=l(),lE=a("li"),E8e=a("strong"),Uwr=o("roformer"),Jwr=o(" \u2014 "),TY=a("a"),Ywr=o("TFRoFormerForMultipleChoice"),Kwr=o(" (RoFormer model)"),Zwr=l(),iE=a("li"),C8e=a("strong"),eAr=o("xlm"),oAr=o(" \u2014 "),MY=a("a"),rAr=o("TFXLMForMultipleChoice"),tAr=o(" (XLM model)"),aAr=l(),dE=a("li"),w8e=a("strong"),nAr=o("xlm-roberta"),sAr=o(" \u2014 "),EY=a("a"),lAr=o("TFXLMRobertaForMultipleChoice"),iAr=o(" (XLM-RoBERTa model)"),dAr=l(),cE=a("li"),A8e=a("strong"),cAr=o("xlnet"),fAr=o(" \u2014 "),CY=a("a"),mAr=o("TFXLNetForMultipleChoice"),gAr=o(" (XLNet model)"),hAr=l(),F(fE.$$.fragment),iVe=l(),Cc=a("h2"),mE=a("a"),L8e=a("span"),F(ox.$$.fragment),pAr=l(),y8e=a("span"),_Ar=o("TFAutoModelForNextSentencePrediction"),dVe=l(),ir=a("div"),F(rx.$$.fragment),uAr=l(),wc=a("p"),bAr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),wY=a("a"),vAr=o("from_pretrained()"),FAr=o(" class method or the "),AY=a("a"),TAr=o("from_config()"),MAr=o(` class
method.`),EAr=l(),tx=a("p"),CAr=o("This class cannot be instantiated directly using "),x8e=a("code"),wAr=o("__init__()"),AAr=o(" (throws an error)."),LAr=l(),qt=a("div"),F(ax.$$.fragment),yAr=l(),$8e=a("p"),xAr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),$Ar=l(),Ac=a("p"),kAr=o(`Note:
Loading a model from its configuration file does `),k8e=a("strong"),SAr=o("not"),RAr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),LY=a("a"),PAr=o("from_pretrained()"),BAr=o(" to load the model weights."),IAr=l(),F(gE.$$.fragment),NAr=l(),Ir=a("div"),F(nx.$$.fragment),qAr=l(),S8e=a("p"),jAr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),DAr=l(),hn=a("p"),GAr=o("The model class to instantiate is selected based on the "),R8e=a("code"),OAr=o("model_type"),VAr=o(` property of the config object (either
passed as an argument or loaded from `),P8e=a("code"),XAr=o("pretrained_model_name_or_path"),zAr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B8e=a("code"),QAr=o("pretrained_model_name_or_path"),WAr=o(":"),HAr=l(),sx=a("ul"),hE=a("li"),I8e=a("strong"),UAr=o("bert"),JAr=o(" \u2014 "),yY=a("a"),YAr=o("TFBertForNextSentencePrediction"),KAr=o(" (BERT model)"),ZAr=l(),pE=a("li"),N8e=a("strong"),eLr=o("mobilebert"),oLr=o(" \u2014 "),xY=a("a"),rLr=o("TFMobileBertForNextSentencePrediction"),tLr=o(" (MobileBERT model)"),aLr=l(),F(_E.$$.fragment),cVe=l(),Lc=a("h2"),uE=a("a"),q8e=a("span"),F(lx.$$.fragment),nLr=l(),j8e=a("span"),sLr=o("TFAutoModelForTableQuestionAnswering"),fVe=l(),dr=a("div"),F(ix.$$.fragment),lLr=l(),yc=a("p"),iLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),$Y=a("a"),dLr=o("from_pretrained()"),cLr=o(" class method or the "),kY=a("a"),fLr=o("from_config()"),mLr=o(` class
method.`),gLr=l(),dx=a("p"),hLr=o("This class cannot be instantiated directly using "),D8e=a("code"),pLr=o("__init__()"),_Lr=o(" (throws an error)."),uLr=l(),jt=a("div"),F(cx.$$.fragment),bLr=l(),G8e=a("p"),vLr=o("Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),FLr=l(),xc=a("p"),TLr=o(`Note:
Loading a model from its configuration file does `),O8e=a("strong"),MLr=o("not"),ELr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SY=a("a"),CLr=o("from_pretrained()"),wLr=o(" to load the model weights."),ALr=l(),F(bE.$$.fragment),LLr=l(),Nr=a("div"),F(fx.$$.fragment),yLr=l(),V8e=a("p"),xLr=o("Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),$Lr=l(),pn=a("p"),kLr=o("The model class to instantiate is selected based on the "),X8e=a("code"),SLr=o("model_type"),RLr=o(` property of the config object (either
passed as an argument or loaded from `),z8e=a("code"),PLr=o("pretrained_model_name_or_path"),BLr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q8e=a("code"),ILr=o("pretrained_model_name_or_path"),NLr=o(":"),qLr=l(),W8e=a("ul"),vE=a("li"),H8e=a("strong"),jLr=o("tapas"),DLr=o(" \u2014 "),RY=a("a"),GLr=o("TFTapasForQuestionAnswering"),OLr=o(" (TAPAS model)"),VLr=l(),F(FE.$$.fragment),mVe=l(),$c=a("h2"),TE=a("a"),U8e=a("span"),F(mx.$$.fragment),XLr=l(),J8e=a("span"),zLr=o("TFAutoModelForTokenClassification"),gVe=l(),cr=a("div"),F(gx.$$.fragment),QLr=l(),kc=a("p"),WLr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),PY=a("a"),HLr=o("from_pretrained()"),ULr=o(" class method or the "),BY=a("a"),JLr=o("from_config()"),YLr=o(` class
method.`),KLr=l(),hx=a("p"),ZLr=o("This class cannot be instantiated directly using "),Y8e=a("code"),eyr=o("__init__()"),oyr=o(" (throws an error)."),ryr=l(),Dt=a("div"),F(px.$$.fragment),tyr=l(),K8e=a("p"),ayr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),nyr=l(),Sc=a("p"),syr=o(`Note:
Loading a model from its configuration file does `),Z8e=a("strong"),lyr=o("not"),iyr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=a("a"),dyr=o("from_pretrained()"),cyr=o(" to load the model weights."),fyr=l(),F(ME.$$.fragment),myr=l(),qr=a("div"),F(_x.$$.fragment),gyr=l(),e9e=a("p"),hyr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),pyr=l(),_n=a("p"),_yr=o("The model class to instantiate is selected based on the "),o9e=a("code"),uyr=o("model_type"),byr=o(` property of the config object (either
passed as an argument or loaded from `),r9e=a("code"),vyr=o("pretrained_model_name_or_path"),Fyr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t9e=a("code"),Tyr=o("pretrained_model_name_or_path"),Myr=o(":"),Eyr=l(),de=a("ul"),EE=a("li"),a9e=a("strong"),Cyr=o("albert"),wyr=o(" \u2014 "),NY=a("a"),Ayr=o("TFAlbertForTokenClassification"),Lyr=o(" (ALBERT model)"),yyr=l(),CE=a("li"),n9e=a("strong"),xyr=o("bert"),$yr=o(" \u2014 "),qY=a("a"),kyr=o("TFBertForTokenClassification"),Syr=o(" (BERT model)"),Ryr=l(),wE=a("li"),s9e=a("strong"),Pyr=o("camembert"),Byr=o(" \u2014 "),jY=a("a"),Iyr=o("TFCamembertForTokenClassification"),Nyr=o(" (CamemBERT model)"),qyr=l(),AE=a("li"),l9e=a("strong"),jyr=o("convbert"),Dyr=o(" \u2014 "),DY=a("a"),Gyr=o("TFConvBertForTokenClassification"),Oyr=o(" (ConvBERT model)"),Vyr=l(),LE=a("li"),i9e=a("strong"),Xyr=o("deberta"),zyr=o(" \u2014 "),GY=a("a"),Qyr=o("TFDebertaForTokenClassification"),Wyr=o(" (DeBERTa model)"),Hyr=l(),yE=a("li"),d9e=a("strong"),Uyr=o("deberta-v2"),Jyr=o(" \u2014 "),OY=a("a"),Yyr=o("TFDebertaV2ForTokenClassification"),Kyr=o(" (DeBERTa-v2 model)"),Zyr=l(),xE=a("li"),c9e=a("strong"),exr=o("distilbert"),oxr=o(" \u2014 "),VY=a("a"),rxr=o("TFDistilBertForTokenClassification"),txr=o(" (DistilBERT model)"),axr=l(),$E=a("li"),f9e=a("strong"),nxr=o("electra"),sxr=o(" \u2014 "),XY=a("a"),lxr=o("TFElectraForTokenClassification"),ixr=o(" (ELECTRA model)"),dxr=l(),kE=a("li"),m9e=a("strong"),cxr=o("flaubert"),fxr=o(" \u2014 "),zY=a("a"),mxr=o("TFFlaubertForTokenClassification"),gxr=o(" (FlauBERT model)"),hxr=l(),SE=a("li"),g9e=a("strong"),pxr=o("funnel"),_xr=o(" \u2014 "),QY=a("a"),uxr=o("TFFunnelForTokenClassification"),bxr=o(" (Funnel Transformer model)"),vxr=l(),RE=a("li"),h9e=a("strong"),Fxr=o("layoutlm"),Txr=o(" \u2014 "),WY=a("a"),Mxr=o("TFLayoutLMForTokenClassification"),Exr=o(" (LayoutLM model)"),Cxr=l(),PE=a("li"),p9e=a("strong"),wxr=o("longformer"),Axr=o(" \u2014 "),HY=a("a"),Lxr=o("TFLongformerForTokenClassification"),yxr=o(" (Longformer model)"),xxr=l(),BE=a("li"),_9e=a("strong"),$xr=o("mobilebert"),kxr=o(" \u2014 "),UY=a("a"),Sxr=o("TFMobileBertForTokenClassification"),Rxr=o(" (MobileBERT model)"),Pxr=l(),IE=a("li"),u9e=a("strong"),Bxr=o("mpnet"),Ixr=o(" \u2014 "),JY=a("a"),Nxr=o("TFMPNetForTokenClassification"),qxr=o(" (MPNet model)"),jxr=l(),NE=a("li"),b9e=a("strong"),Dxr=o("rembert"),Gxr=o(" \u2014 "),YY=a("a"),Oxr=o("TFRemBertForTokenClassification"),Vxr=o(" (RemBERT model)"),Xxr=l(),qE=a("li"),v9e=a("strong"),zxr=o("roberta"),Qxr=o(" \u2014 "),KY=a("a"),Wxr=o("TFRobertaForTokenClassification"),Hxr=o(" (RoBERTa model)"),Uxr=l(),jE=a("li"),F9e=a("strong"),Jxr=o("roformer"),Yxr=o(" \u2014 "),ZY=a("a"),Kxr=o("TFRoFormerForTokenClassification"),Zxr=o(" (RoFormer model)"),e$r=l(),DE=a("li"),T9e=a("strong"),o$r=o("xlm"),r$r=o(" \u2014 "),eK=a("a"),t$r=o("TFXLMForTokenClassification"),a$r=o(" (XLM model)"),n$r=l(),GE=a("li"),M9e=a("strong"),s$r=o("xlm-roberta"),l$r=o(" \u2014 "),oK=a("a"),i$r=o("TFXLMRobertaForTokenClassification"),d$r=o(" (XLM-RoBERTa model)"),c$r=l(),OE=a("li"),E9e=a("strong"),f$r=o("xlnet"),m$r=o(" \u2014 "),rK=a("a"),g$r=o("TFXLNetForTokenClassification"),h$r=o(" (XLNet model)"),p$r=l(),F(VE.$$.fragment),hVe=l(),Rc=a("h2"),XE=a("a"),C9e=a("span"),F(ux.$$.fragment),_$r=l(),w9e=a("span"),u$r=o("TFAutoModelForQuestionAnswering"),pVe=l(),fr=a("div"),F(bx.$$.fragment),b$r=l(),Pc=a("p"),v$r=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),tK=a("a"),F$r=o("from_pretrained()"),T$r=o(" class method or the "),aK=a("a"),M$r=o("from_config()"),E$r=o(` class
method.`),C$r=l(),vx=a("p"),w$r=o("This class cannot be instantiated directly using "),A9e=a("code"),A$r=o("__init__()"),L$r=o(" (throws an error)."),y$r=l(),Gt=a("div"),F(Fx.$$.fragment),x$r=l(),L9e=a("p"),$$r=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),k$r=l(),Bc=a("p"),S$r=o(`Note:
Loading a model from its configuration file does `),y9e=a("strong"),R$r=o("not"),P$r=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=a("a"),B$r=o("from_pretrained()"),I$r=o(" to load the model weights."),N$r=l(),F(zE.$$.fragment),q$r=l(),jr=a("div"),F(Tx.$$.fragment),j$r=l(),x9e=a("p"),D$r=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),G$r=l(),un=a("p"),O$r=o("The model class to instantiate is selected based on the "),$9e=a("code"),V$r=o("model_type"),X$r=o(` property of the config object (either
passed as an argument or loaded from `),k9e=a("code"),z$r=o("pretrained_model_name_or_path"),Q$r=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S9e=a("code"),W$r=o("pretrained_model_name_or_path"),H$r=o(":"),U$r=l(),ce=a("ul"),QE=a("li"),R9e=a("strong"),J$r=o("albert"),Y$r=o(" \u2014 "),sK=a("a"),K$r=o("TFAlbertForQuestionAnswering"),Z$r=o(" (ALBERT model)"),ekr=l(),WE=a("li"),P9e=a("strong"),okr=o("bert"),rkr=o(" \u2014 "),lK=a("a"),tkr=o("TFBertForQuestionAnswering"),akr=o(" (BERT model)"),nkr=l(),HE=a("li"),B9e=a("strong"),skr=o("camembert"),lkr=o(" \u2014 "),iK=a("a"),ikr=o("TFCamembertForQuestionAnswering"),dkr=o(" (CamemBERT model)"),ckr=l(),UE=a("li"),I9e=a("strong"),fkr=o("convbert"),mkr=o(" \u2014 "),dK=a("a"),gkr=o("TFConvBertForQuestionAnswering"),hkr=o(" (ConvBERT model)"),pkr=l(),JE=a("li"),N9e=a("strong"),_kr=o("deberta"),ukr=o(" \u2014 "),cK=a("a"),bkr=o("TFDebertaForQuestionAnswering"),vkr=o(" (DeBERTa model)"),Fkr=l(),YE=a("li"),q9e=a("strong"),Tkr=o("deberta-v2"),Mkr=o(" \u2014 "),fK=a("a"),Ekr=o("TFDebertaV2ForQuestionAnswering"),Ckr=o(" (DeBERTa-v2 model)"),wkr=l(),KE=a("li"),j9e=a("strong"),Akr=o("distilbert"),Lkr=o(" \u2014 "),mK=a("a"),ykr=o("TFDistilBertForQuestionAnswering"),xkr=o(" (DistilBERT model)"),$kr=l(),ZE=a("li"),D9e=a("strong"),kkr=o("electra"),Skr=o(" \u2014 "),gK=a("a"),Rkr=o("TFElectraForQuestionAnswering"),Pkr=o(" (ELECTRA model)"),Bkr=l(),e4=a("li"),G9e=a("strong"),Ikr=o("flaubert"),Nkr=o(" \u2014 "),hK=a("a"),qkr=o("TFFlaubertForQuestionAnsweringSimple"),jkr=o(" (FlauBERT model)"),Dkr=l(),o4=a("li"),O9e=a("strong"),Gkr=o("funnel"),Okr=o(" \u2014 "),pK=a("a"),Vkr=o("TFFunnelForQuestionAnswering"),Xkr=o(" (Funnel Transformer model)"),zkr=l(),r4=a("li"),V9e=a("strong"),Qkr=o("gptj"),Wkr=o(" \u2014 "),_K=a("a"),Hkr=o("TFGPTJForQuestionAnswering"),Ukr=o(" (GPT-J model)"),Jkr=l(),t4=a("li"),X9e=a("strong"),Ykr=o("longformer"),Kkr=o(" \u2014 "),uK=a("a"),Zkr=o("TFLongformerForQuestionAnswering"),eSr=o(" (Longformer model)"),oSr=l(),a4=a("li"),z9e=a("strong"),rSr=o("mobilebert"),tSr=o(" \u2014 "),bK=a("a"),aSr=o("TFMobileBertForQuestionAnswering"),nSr=o(" (MobileBERT model)"),sSr=l(),n4=a("li"),Q9e=a("strong"),lSr=o("mpnet"),iSr=o(" \u2014 "),vK=a("a"),dSr=o("TFMPNetForQuestionAnswering"),cSr=o(" (MPNet model)"),fSr=l(),s4=a("li"),W9e=a("strong"),mSr=o("rembert"),gSr=o(" \u2014 "),FK=a("a"),hSr=o("TFRemBertForQuestionAnswering"),pSr=o(" (RemBERT model)"),_Sr=l(),l4=a("li"),H9e=a("strong"),uSr=o("roberta"),bSr=o(" \u2014 "),TK=a("a"),vSr=o("TFRobertaForQuestionAnswering"),FSr=o(" (RoBERTa model)"),TSr=l(),i4=a("li"),U9e=a("strong"),MSr=o("roformer"),ESr=o(" \u2014 "),MK=a("a"),CSr=o("TFRoFormerForQuestionAnswering"),wSr=o(" (RoFormer model)"),ASr=l(),d4=a("li"),J9e=a("strong"),LSr=o("xlm"),ySr=o(" \u2014 "),EK=a("a"),xSr=o("TFXLMForQuestionAnsweringSimple"),$Sr=o(" (XLM model)"),kSr=l(),c4=a("li"),Y9e=a("strong"),SSr=o("xlm-roberta"),RSr=o(" \u2014 "),CK=a("a"),PSr=o("TFXLMRobertaForQuestionAnswering"),BSr=o(" (XLM-RoBERTa model)"),ISr=l(),f4=a("li"),K9e=a("strong"),NSr=o("xlnet"),qSr=o(" \u2014 "),wK=a("a"),jSr=o("TFXLNetForQuestionAnsweringSimple"),DSr=o(" (XLNet model)"),GSr=l(),F(m4.$$.fragment),_Ve=l(),Ic=a("h2"),g4=a("a"),Z9e=a("span"),F(Mx.$$.fragment),OSr=l(),eMe=a("span"),VSr=o("TFAutoModelForVision2Seq"),uVe=l(),mr=a("div"),F(Ex.$$.fragment),XSr=l(),Nc=a("p"),zSr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),AK=a("a"),QSr=o("from_pretrained()"),WSr=o(" class method or the "),LK=a("a"),HSr=o("from_config()"),USr=o(` class
method.`),JSr=l(),Cx=a("p"),YSr=o("This class cannot be instantiated directly using "),oMe=a("code"),KSr=o("__init__()"),ZSr=o(" (throws an error)."),eRr=l(),Ot=a("div"),F(wx.$$.fragment),oRr=l(),rMe=a("p"),rRr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),tRr=l(),qc=a("p"),aRr=o(`Note:
Loading a model from its configuration file does `),tMe=a("strong"),nRr=o("not"),sRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),yK=a("a"),lRr=o("from_pretrained()"),iRr=o(" to load the model weights."),dRr=l(),F(h4.$$.fragment),cRr=l(),Dr=a("div"),F(Ax.$$.fragment),fRr=l(),aMe=a("p"),mRr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),gRr=l(),bn=a("p"),hRr=o("The model class to instantiate is selected based on the "),nMe=a("code"),pRr=o("model_type"),_Rr=o(` property of the config object (either
passed as an argument or loaded from `),sMe=a("code"),uRr=o("pretrained_model_name_or_path"),bRr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lMe=a("code"),vRr=o("pretrained_model_name_or_path"),FRr=o(":"),TRr=l(),iMe=a("ul"),p4=a("li"),dMe=a("strong"),MRr=o("vision-encoder-decoder"),ERr=o(" \u2014 "),xK=a("a"),CRr=o("TFVisionEncoderDecoderModel"),wRr=o(" (Vision Encoder decoder model)"),ARr=l(),F(_4.$$.fragment),bVe=l(),jc=a("h2"),u4=a("a"),cMe=a("span"),F(Lx.$$.fragment),LRr=l(),fMe=a("span"),yRr=o("TFAutoModelForSpeechSeq2Seq"),vVe=l(),gr=a("div"),F(yx.$$.fragment),xRr=l(),Dc=a("p"),$Rr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),$K=a("a"),kRr=o("from_pretrained()"),SRr=o(" class method or the "),kK=a("a"),RRr=o("from_config()"),PRr=o(` class
method.`),BRr=l(),xx=a("p"),IRr=o("This class cannot be instantiated directly using "),mMe=a("code"),NRr=o("__init__()"),qRr=o(" (throws an error)."),jRr=l(),Vt=a("div"),F($x.$$.fragment),DRr=l(),gMe=a("p"),GRr=o("Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),ORr=l(),Gc=a("p"),VRr=o(`Note:
Loading a model from its configuration file does `),hMe=a("strong"),XRr=o("not"),zRr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=a("a"),QRr=o("from_pretrained()"),WRr=o(" to load the model weights."),HRr=l(),F(b4.$$.fragment),URr=l(),Gr=a("div"),F(kx.$$.fragment),JRr=l(),pMe=a("p"),YRr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),KRr=l(),vn=a("p"),ZRr=o("The model class to instantiate is selected based on the "),_Me=a("code"),ePr=o("model_type"),oPr=o(` property of the config object (either
passed as an argument or loaded from `),uMe=a("code"),rPr=o("pretrained_model_name_or_path"),tPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bMe=a("code"),aPr=o("pretrained_model_name_or_path"),nPr=o(":"),sPr=l(),vMe=a("ul"),v4=a("li"),FMe=a("strong"),lPr=o("speech_to_text"),iPr=o(" \u2014 "),RK=a("a"),dPr=o("TFSpeech2TextForConditionalGeneration"),cPr=o(" (Speech2Text model)"),fPr=l(),F(F4.$$.fragment),FVe=l(),Oc=a("h2"),T4=a("a"),TMe=a("span"),F(Sx.$$.fragment),mPr=l(),MMe=a("span"),gPr=o("FlaxAutoModel"),TVe=l(),hr=a("div"),F(Rx.$$.fragment),hPr=l(),Vc=a("p"),pPr=o(`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),PK=a("a"),_Pr=o("from_pretrained()"),uPr=o(" class method or the "),BK=a("a"),bPr=o("from_config()"),vPr=o(` class
method.`),FPr=l(),Px=a("p"),TPr=o("This class cannot be instantiated directly using "),EMe=a("code"),MPr=o("__init__()"),EPr=o(" (throws an error)."),CPr=l(),Xt=a("div"),F(Bx.$$.fragment),wPr=l(),CMe=a("p"),APr=o("Instantiates one of the base model classes of the library from a configuration."),LPr=l(),Xc=a("p"),yPr=o(`Note:
Loading a model from its configuration file does `),wMe=a("strong"),xPr=o("not"),$Pr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=a("a"),kPr=o("from_pretrained()"),SPr=o(" to load the model weights."),RPr=l(),F(M4.$$.fragment),PPr=l(),Or=a("div"),F(Ix.$$.fragment),BPr=l(),AMe=a("p"),IPr=o("Instantiate one of the base model classes of the library from a pretrained model."),NPr=l(),Fn=a("p"),qPr=o("The model class to instantiate is selected based on the "),LMe=a("code"),jPr=o("model_type"),DPr=o(` property of the config object (either
passed as an argument or loaded from `),yMe=a("code"),GPr=o("pretrained_model_name_or_path"),OPr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xMe=a("code"),VPr=o("pretrained_model_name_or_path"),XPr=o(":"),zPr=l(),oe=a("ul"),E4=a("li"),$Me=a("strong"),QPr=o("albert"),WPr=o(" \u2014 "),NK=a("a"),HPr=o("FlaxAlbertModel"),UPr=o(" (ALBERT model)"),JPr=l(),C4=a("li"),kMe=a("strong"),YPr=o("bart"),KPr=o(" \u2014 "),qK=a("a"),ZPr=o("FlaxBartModel"),eBr=o(" (BART model)"),oBr=l(),w4=a("li"),SMe=a("strong"),rBr=o("beit"),tBr=o(" \u2014 "),jK=a("a"),aBr=o("FlaxBeitModel"),nBr=o(" (BEiT model)"),sBr=l(),A4=a("li"),RMe=a("strong"),lBr=o("bert"),iBr=o(" \u2014 "),DK=a("a"),dBr=o("FlaxBertModel"),cBr=o(" (BERT model)"),fBr=l(),L4=a("li"),PMe=a("strong"),mBr=o("big_bird"),gBr=o(" \u2014 "),GK=a("a"),hBr=o("FlaxBigBirdModel"),pBr=o(" (BigBird model)"),_Br=l(),y4=a("li"),BMe=a("strong"),uBr=o("blenderbot"),bBr=o(" \u2014 "),OK=a("a"),vBr=o("FlaxBlenderbotModel"),FBr=o(" (Blenderbot model)"),TBr=l(),x4=a("li"),IMe=a("strong"),MBr=o("blenderbot-small"),EBr=o(" \u2014 "),VK=a("a"),CBr=o("FlaxBlenderbotSmallModel"),wBr=o(" (BlenderbotSmall model)"),ABr=l(),$4=a("li"),NMe=a("strong"),LBr=o("clip"),yBr=o(" \u2014 "),XK=a("a"),xBr=o("FlaxCLIPModel"),$Br=o(" (CLIP model)"),kBr=l(),k4=a("li"),qMe=a("strong"),SBr=o("distilbert"),RBr=o(" \u2014 "),zK=a("a"),PBr=o("FlaxDistilBertModel"),BBr=o(" (DistilBERT model)"),IBr=l(),S4=a("li"),jMe=a("strong"),NBr=o("electra"),qBr=o(" \u2014 "),QK=a("a"),jBr=o("FlaxElectraModel"),DBr=o(" (ELECTRA model)"),GBr=l(),R4=a("li"),DMe=a("strong"),OBr=o("gpt2"),VBr=o(" \u2014 "),WK=a("a"),XBr=o("FlaxGPT2Model"),zBr=o(" (OpenAI GPT-2 model)"),QBr=l(),P4=a("li"),GMe=a("strong"),WBr=o("gpt_neo"),HBr=o(" \u2014 "),HK=a("a"),UBr=o("FlaxGPTNeoModel"),JBr=o(" (GPT Neo model)"),YBr=l(),B4=a("li"),OMe=a("strong"),KBr=o("gptj"),ZBr=o(" \u2014 "),UK=a("a"),eIr=o("FlaxGPTJModel"),oIr=o(" (GPT-J model)"),rIr=l(),I4=a("li"),VMe=a("strong"),tIr=o("longt5"),aIr=o(" \u2014 "),JK=a("a"),nIr=o("FlaxLongT5Model"),sIr=o(" (LongT5 model)"),lIr=l(),N4=a("li"),XMe=a("strong"),iIr=o("marian"),dIr=o(" \u2014 "),YK=a("a"),cIr=o("FlaxMarianModel"),fIr=o(" (Marian model)"),mIr=l(),q4=a("li"),zMe=a("strong"),gIr=o("mbart"),hIr=o(" \u2014 "),KK=a("a"),pIr=o("FlaxMBartModel"),_Ir=o(" (mBART model)"),uIr=l(),j4=a("li"),QMe=a("strong"),bIr=o("mt5"),vIr=o(" \u2014 "),ZK=a("a"),FIr=o("FlaxMT5Model"),TIr=o(" (MT5 model)"),MIr=l(),D4=a("li"),WMe=a("strong"),EIr=o("opt"),CIr=o(" \u2014 "),eZ=a("a"),wIr=o("FlaxOPTModel"),AIr=o(" (OPT model)"),LIr=l(),G4=a("li"),HMe=a("strong"),yIr=o("pegasus"),xIr=o(" \u2014 "),oZ=a("a"),$Ir=o("FlaxPegasusModel"),kIr=o(" (Pegasus model)"),SIr=l(),O4=a("li"),UMe=a("strong"),RIr=o("roberta"),PIr=o(" \u2014 "),rZ=a("a"),BIr=o("FlaxRobertaModel"),IIr=o(" (RoBERTa model)"),NIr=l(),V4=a("li"),JMe=a("strong"),qIr=o("roformer"),jIr=o(" \u2014 "),tZ=a("a"),DIr=o("FlaxRoFormerModel"),GIr=o(" (RoFormer model)"),OIr=l(),X4=a("li"),YMe=a("strong"),VIr=o("t5"),XIr=o(" \u2014 "),aZ=a("a"),zIr=o("FlaxT5Model"),QIr=o(" (T5 model)"),WIr=l(),z4=a("li"),KMe=a("strong"),HIr=o("vision-text-dual-encoder"),UIr=o(" \u2014 "),nZ=a("a"),JIr=o("FlaxVisionTextDualEncoderModel"),YIr=o(" (VisionTextDualEncoder model)"),KIr=l(),Q4=a("li"),ZMe=a("strong"),ZIr=o("vit"),eNr=o(" \u2014 "),sZ=a("a"),oNr=o("FlaxViTModel"),rNr=o(" (ViT model)"),tNr=l(),W4=a("li"),eEe=a("strong"),aNr=o("wav2vec2"),nNr=o(" \u2014 "),lZ=a("a"),sNr=o("FlaxWav2Vec2Model"),lNr=o(" (Wav2Vec2 model)"),iNr=l(),H4=a("li"),oEe=a("strong"),dNr=o("xglm"),cNr=o(" \u2014 "),iZ=a("a"),fNr=o("FlaxXGLMModel"),mNr=o(" (XGLM model)"),gNr=l(),U4=a("li"),rEe=a("strong"),hNr=o("xlm-roberta"),pNr=o(" \u2014 "),dZ=a("a"),_Nr=o("FlaxXLMRobertaModel"),uNr=o(" (XLM-RoBERTa model)"),bNr=l(),F(J4.$$.fragment),MVe=l(),zc=a("h2"),Y4=a("a"),tEe=a("span"),F(Nx.$$.fragment),vNr=l(),aEe=a("span"),FNr=o("FlaxAutoModelForCausalLM"),EVe=l(),pr=a("div"),F(qx.$$.fragment),TNr=l(),Qc=a("p"),MNr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),cZ=a("a"),ENr=o("from_pretrained()"),CNr=o(" class method or the "),fZ=a("a"),wNr=o("from_config()"),ANr=o(` class
method.`),LNr=l(),jx=a("p"),yNr=o("This class cannot be instantiated directly using "),nEe=a("code"),xNr=o("__init__()"),$Nr=o(" (throws an error)."),kNr=l(),zt=a("div"),F(Dx.$$.fragment),SNr=l(),sEe=a("p"),RNr=o("Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),PNr=l(),Wc=a("p"),BNr=o(`Note:
Loading a model from its configuration file does `),lEe=a("strong"),INr=o("not"),NNr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),mZ=a("a"),qNr=o("from_pretrained()"),jNr=o(" to load the model weights."),DNr=l(),F(K4.$$.fragment),GNr=l(),Vr=a("div"),F(Gx.$$.fragment),ONr=l(),iEe=a("p"),VNr=o("Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),XNr=l(),Tn=a("p"),zNr=o("The model class to instantiate is selected based on the "),dEe=a("code"),QNr=o("model_type"),WNr=o(` property of the config object (either
passed as an argument or loaded from `),cEe=a("code"),HNr=o("pretrained_model_name_or_path"),UNr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fEe=a("code"),JNr=o("pretrained_model_name_or_path"),YNr=o(":"),KNr=l(),xe=a("ul"),Z4=a("li"),mEe=a("strong"),ZNr=o("bart"),eqr=o(" \u2014 "),gZ=a("a"),oqr=o("FlaxBartForCausalLM"),rqr=o(" (BART model)"),tqr=l(),eC=a("li"),gEe=a("strong"),aqr=o("bert"),nqr=o(" \u2014 "),hZ=a("a"),sqr=o("FlaxBertForCausalLM"),lqr=o(" (BERT model)"),iqr=l(),oC=a("li"),hEe=a("strong"),dqr=o("big_bird"),cqr=o(" \u2014 "),pZ=a("a"),fqr=o("FlaxBigBirdForCausalLM"),mqr=o(" (BigBird model)"),gqr=l(),rC=a("li"),pEe=a("strong"),hqr=o("electra"),pqr=o(" \u2014 "),_Z=a("a"),_qr=o("FlaxElectraForCausalLM"),uqr=o(" (ELECTRA model)"),bqr=l(),tC=a("li"),_Ee=a("strong"),vqr=o("gpt2"),Fqr=o(" \u2014 "),uZ=a("a"),Tqr=o("FlaxGPT2LMHeadModel"),Mqr=o(" (OpenAI GPT-2 model)"),Eqr=l(),aC=a("li"),uEe=a("strong"),Cqr=o("gpt_neo"),wqr=o(" \u2014 "),bZ=a("a"),Aqr=o("FlaxGPTNeoForCausalLM"),Lqr=o(" (GPT Neo model)"),yqr=l(),nC=a("li"),bEe=a("strong"),xqr=o("gptj"),$qr=o(" \u2014 "),vZ=a("a"),kqr=o("FlaxGPTJForCausalLM"),Sqr=o(" (GPT-J model)"),Rqr=l(),sC=a("li"),vEe=a("strong"),Pqr=o("opt"),Bqr=o(" \u2014 "),FZ=a("a"),Iqr=o("FlaxOPTForCausalLM"),Nqr=o(" (OPT model)"),qqr=l(),lC=a("li"),FEe=a("strong"),jqr=o("roberta"),Dqr=o(" \u2014 "),TZ=a("a"),Gqr=o("FlaxRobertaForCausalLM"),Oqr=o(" (RoBERTa model)"),Vqr=l(),iC=a("li"),TEe=a("strong"),Xqr=o("xglm"),zqr=o(" \u2014 "),MZ=a("a"),Qqr=o("FlaxXGLMForCausalLM"),Wqr=o(" (XGLM model)"),Hqr=l(),F(dC.$$.fragment),CVe=l(),Hc=a("h2"),cC=a("a"),MEe=a("span"),F(Ox.$$.fragment),Uqr=l(),EEe=a("span"),Jqr=o("FlaxAutoModelForPreTraining"),wVe=l(),_r=a("div"),F(Vx.$$.fragment),Yqr=l(),Uc=a("p"),Kqr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),EZ=a("a"),Zqr=o("from_pretrained()"),ejr=o(" class method or the "),CZ=a("a"),ojr=o("from_config()"),rjr=o(` class
method.`),tjr=l(),Xx=a("p"),ajr=o("This class cannot be instantiated directly using "),CEe=a("code"),njr=o("__init__()"),sjr=o(" (throws an error)."),ljr=l(),Qt=a("div"),F(zx.$$.fragment),ijr=l(),wEe=a("p"),djr=o("Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),cjr=l(),Jc=a("p"),fjr=o(`Note:
Loading a model from its configuration file does `),AEe=a("strong"),mjr=o("not"),gjr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),wZ=a("a"),hjr=o("from_pretrained()"),pjr=o(" to load the model weights."),_jr=l(),F(fC.$$.fragment),ujr=l(),Xr=a("div"),F(Qx.$$.fragment),bjr=l(),LEe=a("p"),vjr=o("Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Fjr=l(),Mn=a("p"),Tjr=o("The model class to instantiate is selected based on the "),yEe=a("code"),Mjr=o("model_type"),Ejr=o(` property of the config object (either
passed as an argument or loaded from `),xEe=a("code"),Cjr=o("pretrained_model_name_or_path"),wjr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ee=a("code"),Ajr=o("pretrained_model_name_or_path"),Ljr=o(":"),yjr=l(),Ee=a("ul"),mC=a("li"),kEe=a("strong"),xjr=o("albert"),$jr=o(" \u2014 "),AZ=a("a"),kjr=o("FlaxAlbertForPreTraining"),Sjr=o(" (ALBERT model)"),Rjr=l(),gC=a("li"),SEe=a("strong"),Pjr=o("bart"),Bjr=o(" \u2014 "),LZ=a("a"),Ijr=o("FlaxBartForConditionalGeneration"),Njr=o(" (BART model)"),qjr=l(),hC=a("li"),REe=a("strong"),jjr=o("bert"),Djr=o(" \u2014 "),yZ=a("a"),Gjr=o("FlaxBertForPreTraining"),Ojr=o(" (BERT model)"),Vjr=l(),pC=a("li"),PEe=a("strong"),Xjr=o("big_bird"),zjr=o(" \u2014 "),xZ=a("a"),Qjr=o("FlaxBigBirdForPreTraining"),Wjr=o(" (BigBird model)"),Hjr=l(),_C=a("li"),BEe=a("strong"),Ujr=o("electra"),Jjr=o(" \u2014 "),$Z=a("a"),Yjr=o("FlaxElectraForPreTraining"),Kjr=o(" (ELECTRA model)"),Zjr=l(),uC=a("li"),IEe=a("strong"),eDr=o("longt5"),oDr=o(" \u2014 "),kZ=a("a"),rDr=o("FlaxLongT5ForConditionalGeneration"),tDr=o(" (LongT5 model)"),aDr=l(),bC=a("li"),NEe=a("strong"),nDr=o("mbart"),sDr=o(" \u2014 "),SZ=a("a"),lDr=o("FlaxMBartForConditionalGeneration"),iDr=o(" (mBART model)"),dDr=l(),vC=a("li"),qEe=a("strong"),cDr=o("mt5"),fDr=o(" \u2014 "),RZ=a("a"),mDr=o("FlaxMT5ForConditionalGeneration"),gDr=o(" (MT5 model)"),hDr=l(),FC=a("li"),jEe=a("strong"),pDr=o("roberta"),_Dr=o(" \u2014 "),PZ=a("a"),uDr=o("FlaxRobertaForMaskedLM"),bDr=o(" (RoBERTa model)"),vDr=l(),TC=a("li"),DEe=a("strong"),FDr=o("roformer"),TDr=o(" \u2014 "),BZ=a("a"),MDr=o("FlaxRoFormerForMaskedLM"),EDr=o(" (RoFormer model)"),CDr=l(),MC=a("li"),GEe=a("strong"),wDr=o("t5"),ADr=o(" \u2014 "),IZ=a("a"),LDr=o("FlaxT5ForConditionalGeneration"),yDr=o(" (T5 model)"),xDr=l(),EC=a("li"),OEe=a("strong"),$Dr=o("wav2vec2"),kDr=o(" \u2014 "),NZ=a("a"),SDr=o("FlaxWav2Vec2ForPreTraining"),RDr=o(" (Wav2Vec2 model)"),PDr=l(),CC=a("li"),VEe=a("strong"),BDr=o("xlm-roberta"),IDr=o(" \u2014 "),qZ=a("a"),NDr=o("FlaxXLMRobertaForMaskedLM"),qDr=o(" (XLM-RoBERTa model)"),jDr=l(),F(wC.$$.fragment),AVe=l(),Yc=a("h2"),AC=a("a"),XEe=a("span"),F(Wx.$$.fragment),DDr=l(),zEe=a("span"),GDr=o("FlaxAutoModelForMaskedLM"),LVe=l(),ur=a("div"),F(Hx.$$.fragment),ODr=l(),Kc=a("p"),VDr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jZ=a("a"),XDr=o("from_pretrained()"),zDr=o(" class method or the "),DZ=a("a"),QDr=o("from_config()"),WDr=o(` class
method.`),HDr=l(),Ux=a("p"),UDr=o("This class cannot be instantiated directly using "),QEe=a("code"),JDr=o("__init__()"),YDr=o(" (throws an error)."),KDr=l(),Wt=a("div"),F(Jx.$$.fragment),ZDr=l(),WEe=a("p"),eGr=o("Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),oGr=l(),Zc=a("p"),rGr=o(`Note:
Loading a model from its configuration file does `),HEe=a("strong"),tGr=o("not"),aGr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),GZ=a("a"),nGr=o("from_pretrained()"),sGr=o(" to load the model weights."),lGr=l(),F(LC.$$.fragment),iGr=l(),zr=a("div"),F(Yx.$$.fragment),dGr=l(),UEe=a("p"),cGr=o("Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),fGr=l(),En=a("p"),mGr=o("The model class to instantiate is selected based on the "),JEe=a("code"),gGr=o("model_type"),hGr=o(` property of the config object (either
passed as an argument or loaded from `),YEe=a("code"),pGr=o("pretrained_model_name_or_path"),_Gr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KEe=a("code"),uGr=o("pretrained_model_name_or_path"),bGr=o(":"),vGr=l(),$e=a("ul"),yC=a("li"),ZEe=a("strong"),FGr=o("albert"),TGr=o(" \u2014 "),OZ=a("a"),MGr=o("FlaxAlbertForMaskedLM"),EGr=o(" (ALBERT model)"),CGr=l(),xC=a("li"),e4e=a("strong"),wGr=o("bart"),AGr=o(" \u2014 "),VZ=a("a"),LGr=o("FlaxBartForConditionalGeneration"),yGr=o(" (BART model)"),xGr=l(),$C=a("li"),o4e=a("strong"),$Gr=o("bert"),kGr=o(" \u2014 "),XZ=a("a"),SGr=o("FlaxBertForMaskedLM"),RGr=o(" (BERT model)"),PGr=l(),kC=a("li"),r4e=a("strong"),BGr=o("big_bird"),IGr=o(" \u2014 "),zZ=a("a"),NGr=o("FlaxBigBirdForMaskedLM"),qGr=o(" (BigBird model)"),jGr=l(),SC=a("li"),t4e=a("strong"),DGr=o("distilbert"),GGr=o(" \u2014 "),QZ=a("a"),OGr=o("FlaxDistilBertForMaskedLM"),VGr=o(" (DistilBERT model)"),XGr=l(),RC=a("li"),a4e=a("strong"),zGr=o("electra"),QGr=o(" \u2014 "),WZ=a("a"),WGr=o("FlaxElectraForMaskedLM"),HGr=o(" (ELECTRA model)"),UGr=l(),PC=a("li"),n4e=a("strong"),JGr=o("mbart"),YGr=o(" \u2014 "),HZ=a("a"),KGr=o("FlaxMBartForConditionalGeneration"),ZGr=o(" (mBART model)"),eOr=l(),BC=a("li"),s4e=a("strong"),oOr=o("roberta"),rOr=o(" \u2014 "),UZ=a("a"),tOr=o("FlaxRobertaForMaskedLM"),aOr=o(" (RoBERTa model)"),nOr=l(),IC=a("li"),l4e=a("strong"),sOr=o("roformer"),lOr=o(" \u2014 "),JZ=a("a"),iOr=o("FlaxRoFormerForMaskedLM"),dOr=o(" (RoFormer model)"),cOr=l(),NC=a("li"),i4e=a("strong"),fOr=o("xlm-roberta"),mOr=o(" \u2014 "),YZ=a("a"),gOr=o("FlaxXLMRobertaForMaskedLM"),hOr=o(" (XLM-RoBERTa model)"),pOr=l(),F(qC.$$.fragment),yVe=l(),ef=a("h2"),jC=a("a"),d4e=a("span"),F(Kx.$$.fragment),_Or=l(),c4e=a("span"),uOr=o("FlaxAutoModelForSeq2SeqLM"),xVe=l(),br=a("div"),F(Zx.$$.fragment),bOr=l(),of=a("p"),vOr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),KZ=a("a"),FOr=o("from_pretrained()"),TOr=o(" class method or the "),ZZ=a("a"),MOr=o("from_config()"),EOr=o(` class
method.`),COr=l(),e$=a("p"),wOr=o("This class cannot be instantiated directly using "),f4e=a("code"),AOr=o("__init__()"),LOr=o(" (throws an error)."),yOr=l(),Ht=a("div"),F(o$.$$.fragment),xOr=l(),m4e=a("p"),$Or=o("Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),kOr=l(),rf=a("p"),SOr=o(`Note:
Loading a model from its configuration file does `),g4e=a("strong"),ROr=o("not"),POr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),eee=a("a"),BOr=o("from_pretrained()"),IOr=o(" to load the model weights."),NOr=l(),F(DC.$$.fragment),qOr=l(),Qr=a("div"),F(r$.$$.fragment),jOr=l(),h4e=a("p"),DOr=o("Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),GOr=l(),Cn=a("p"),OOr=o("The model class to instantiate is selected based on the "),p4e=a("code"),VOr=o("model_type"),XOr=o(` property of the config object (either
passed as an argument or loaded from `),_4e=a("code"),zOr=o("pretrained_model_name_or_path"),QOr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u4e=a("code"),WOr=o("pretrained_model_name_or_path"),HOr=o(":"),UOr=l(),ke=a("ul"),GC=a("li"),b4e=a("strong"),JOr=o("bart"),YOr=o(" \u2014 "),oee=a("a"),KOr=o("FlaxBartForConditionalGeneration"),ZOr=o(" (BART model)"),eVr=l(),OC=a("li"),v4e=a("strong"),oVr=o("blenderbot"),rVr=o(" \u2014 "),ree=a("a"),tVr=o("FlaxBlenderbotForConditionalGeneration"),aVr=o(" (Blenderbot model)"),nVr=l(),VC=a("li"),F4e=a("strong"),sVr=o("blenderbot-small"),lVr=o(" \u2014 "),tee=a("a"),iVr=o("FlaxBlenderbotSmallForConditionalGeneration"),dVr=o(" (BlenderbotSmall model)"),cVr=l(),XC=a("li"),T4e=a("strong"),fVr=o("encoder-decoder"),mVr=o(" \u2014 "),aee=a("a"),gVr=o("FlaxEncoderDecoderModel"),hVr=o(" (Encoder decoder model)"),pVr=l(),zC=a("li"),M4e=a("strong"),_Vr=o("longt5"),uVr=o(" \u2014 "),nee=a("a"),bVr=o("FlaxLongT5ForConditionalGeneration"),vVr=o(" (LongT5 model)"),FVr=l(),QC=a("li"),E4e=a("strong"),TVr=o("marian"),MVr=o(" \u2014 "),see=a("a"),EVr=o("FlaxMarianMTModel"),CVr=o(" (Marian model)"),wVr=l(),WC=a("li"),C4e=a("strong"),AVr=o("mbart"),LVr=o(" \u2014 "),lee=a("a"),yVr=o("FlaxMBartForConditionalGeneration"),xVr=o(" (mBART model)"),$Vr=l(),HC=a("li"),w4e=a("strong"),kVr=o("mt5"),SVr=o(" \u2014 "),iee=a("a"),RVr=o("FlaxMT5ForConditionalGeneration"),PVr=o(" (MT5 model)"),BVr=l(),UC=a("li"),A4e=a("strong"),IVr=o("pegasus"),NVr=o(" \u2014 "),dee=a("a"),qVr=o("FlaxPegasusForConditionalGeneration"),jVr=o(" (Pegasus model)"),DVr=l(),JC=a("li"),L4e=a("strong"),GVr=o("t5"),OVr=o(" \u2014 "),cee=a("a"),VVr=o("FlaxT5ForConditionalGeneration"),XVr=o(" (T5 model)"),zVr=l(),F(YC.$$.fragment),$Ve=l(),tf=a("h2"),KC=a("a"),y4e=a("span"),F(t$.$$.fragment),QVr=l(),x4e=a("span"),WVr=o("FlaxAutoModelForSequenceClassification"),kVe=l(),vr=a("div"),F(a$.$$.fragment),HVr=l(),af=a("p"),UVr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),fee=a("a"),JVr=o("from_pretrained()"),YVr=o(" class method or the "),mee=a("a"),KVr=o("from_config()"),ZVr=o(` class
method.`),eXr=l(),n$=a("p"),oXr=o("This class cannot be instantiated directly using "),$4e=a("code"),rXr=o("__init__()"),tXr=o(" (throws an error)."),aXr=l(),Ut=a("div"),F(s$.$$.fragment),nXr=l(),k4e=a("p"),sXr=o("Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),lXr=l(),nf=a("p"),iXr=o(`Note:
Loading a model from its configuration file does `),S4e=a("strong"),dXr=o("not"),cXr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),gee=a("a"),fXr=o("from_pretrained()"),mXr=o(" to load the model weights."),gXr=l(),F(ZC.$$.fragment),hXr=l(),Wr=a("div"),F(l$.$$.fragment),pXr=l(),R4e=a("p"),_Xr=o("Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),uXr=l(),wn=a("p"),bXr=o("The model class to instantiate is selected based on the "),P4e=a("code"),vXr=o("model_type"),FXr=o(` property of the config object (either
passed as an argument or loaded from `),B4e=a("code"),TXr=o("pretrained_model_name_or_path"),MXr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I4e=a("code"),EXr=o("pretrained_model_name_or_path"),CXr=o(":"),wXr=l(),Se=a("ul"),e5=a("li"),N4e=a("strong"),AXr=o("albert"),LXr=o(" \u2014 "),hee=a("a"),yXr=o("FlaxAlbertForSequenceClassification"),xXr=o(" (ALBERT model)"),$Xr=l(),o5=a("li"),q4e=a("strong"),kXr=o("bart"),SXr=o(" \u2014 "),pee=a("a"),RXr=o("FlaxBartForSequenceClassification"),PXr=o(" (BART model)"),BXr=l(),r5=a("li"),j4e=a("strong"),IXr=o("bert"),NXr=o(" \u2014 "),_ee=a("a"),qXr=o("FlaxBertForSequenceClassification"),jXr=o(" (BERT model)"),DXr=l(),t5=a("li"),D4e=a("strong"),GXr=o("big_bird"),OXr=o(" \u2014 "),uee=a("a"),VXr=o("FlaxBigBirdForSequenceClassification"),XXr=o(" (BigBird model)"),zXr=l(),a5=a("li"),G4e=a("strong"),QXr=o("distilbert"),WXr=o(" \u2014 "),bee=a("a"),HXr=o("FlaxDistilBertForSequenceClassification"),UXr=o(" (DistilBERT model)"),JXr=l(),n5=a("li"),O4e=a("strong"),YXr=o("electra"),KXr=o(" \u2014 "),vee=a("a"),ZXr=o("FlaxElectraForSequenceClassification"),ezr=o(" (ELECTRA model)"),ozr=l(),s5=a("li"),V4e=a("strong"),rzr=o("mbart"),tzr=o(" \u2014 "),Fee=a("a"),azr=o("FlaxMBartForSequenceClassification"),nzr=o(" (mBART model)"),szr=l(),l5=a("li"),X4e=a("strong"),lzr=o("roberta"),izr=o(" \u2014 "),Tee=a("a"),dzr=o("FlaxRobertaForSequenceClassification"),czr=o(" (RoBERTa model)"),fzr=l(),i5=a("li"),z4e=a("strong"),mzr=o("roformer"),gzr=o(" \u2014 "),Mee=a("a"),hzr=o("FlaxRoFormerForSequenceClassification"),pzr=o(" (RoFormer model)"),_zr=l(),d5=a("li"),Q4e=a("strong"),uzr=o("xlm-roberta"),bzr=o(" \u2014 "),Eee=a("a"),vzr=o("FlaxXLMRobertaForSequenceClassification"),Fzr=o(" (XLM-RoBERTa model)"),Tzr=l(),F(c5.$$.fragment),SVe=l(),sf=a("h2"),f5=a("a"),W4e=a("span"),F(i$.$$.fragment),Mzr=l(),H4e=a("span"),Ezr=o("FlaxAutoModelForQuestionAnswering"),RVe=l(),Fr=a("div"),F(d$.$$.fragment),Czr=l(),lf=a("p"),wzr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Cee=a("a"),Azr=o("from_pretrained()"),Lzr=o(" class method or the "),wee=a("a"),yzr=o("from_config()"),xzr=o(` class
method.`),$zr=l(),c$=a("p"),kzr=o("This class cannot be instantiated directly using "),U4e=a("code"),Szr=o("__init__()"),Rzr=o(" (throws an error)."),Pzr=l(),Jt=a("div"),F(f$.$$.fragment),Bzr=l(),J4e=a("p"),Izr=o("Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Nzr=l(),df=a("p"),qzr=o(`Note:
Loading a model from its configuration file does `),Y4e=a("strong"),jzr=o("not"),Dzr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Aee=a("a"),Gzr=o("from_pretrained()"),Ozr=o(" to load the model weights."),Vzr=l(),F(m5.$$.fragment),Xzr=l(),Hr=a("div"),F(m$.$$.fragment),zzr=l(),K4e=a("p"),Qzr=o("Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Wzr=l(),An=a("p"),Hzr=o("The model class to instantiate is selected based on the "),Z4e=a("code"),Uzr=o("model_type"),Jzr=o(` property of the config object (either
passed as an argument or loaded from `),eCe=a("code"),Yzr=o("pretrained_model_name_or_path"),Kzr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oCe=a("code"),Zzr=o("pretrained_model_name_or_path"),eQr=o(":"),oQr=l(),Re=a("ul"),g5=a("li"),rCe=a("strong"),rQr=o("albert"),tQr=o(" \u2014 "),Lee=a("a"),aQr=o("FlaxAlbertForQuestionAnswering"),nQr=o(" (ALBERT model)"),sQr=l(),h5=a("li"),tCe=a("strong"),lQr=o("bart"),iQr=o(" \u2014 "),yee=a("a"),dQr=o("FlaxBartForQuestionAnswering"),cQr=o(" (BART model)"),fQr=l(),p5=a("li"),aCe=a("strong"),mQr=o("bert"),gQr=o(" \u2014 "),xee=a("a"),hQr=o("FlaxBertForQuestionAnswering"),pQr=o(" (BERT model)"),_Qr=l(),_5=a("li"),nCe=a("strong"),uQr=o("big_bird"),bQr=o(" \u2014 "),$ee=a("a"),vQr=o("FlaxBigBirdForQuestionAnswering"),FQr=o(" (BigBird model)"),TQr=l(),u5=a("li"),sCe=a("strong"),MQr=o("distilbert"),EQr=o(" \u2014 "),kee=a("a"),CQr=o("FlaxDistilBertForQuestionAnswering"),wQr=o(" (DistilBERT model)"),AQr=l(),b5=a("li"),lCe=a("strong"),LQr=o("electra"),yQr=o(" \u2014 "),See=a("a"),xQr=o("FlaxElectraForQuestionAnswering"),$Qr=o(" (ELECTRA model)"),kQr=l(),v5=a("li"),iCe=a("strong"),SQr=o("mbart"),RQr=o(" \u2014 "),Ree=a("a"),PQr=o("FlaxMBartForQuestionAnswering"),BQr=o(" (mBART model)"),IQr=l(),F5=a("li"),dCe=a("strong"),NQr=o("roberta"),qQr=o(" \u2014 "),Pee=a("a"),jQr=o("FlaxRobertaForQuestionAnswering"),DQr=o(" (RoBERTa model)"),GQr=l(),T5=a("li"),cCe=a("strong"),OQr=o("roformer"),VQr=o(" \u2014 "),Bee=a("a"),XQr=o("FlaxRoFormerForQuestionAnswering"),zQr=o(" (RoFormer model)"),QQr=l(),M5=a("li"),fCe=a("strong"),WQr=o("xlm-roberta"),HQr=o(" \u2014 "),Iee=a("a"),UQr=o("FlaxXLMRobertaForQuestionAnswering"),JQr=o(" (XLM-RoBERTa model)"),YQr=l(),F(E5.$$.fragment),PVe=l(),cf=a("h2"),C5=a("a"),mCe=a("span"),F(g$.$$.fragment),KQr=l(),gCe=a("span"),ZQr=o("FlaxAutoModelForTokenClassification"),BVe=l(),Tr=a("div"),F(h$.$$.fragment),eWr=l(),ff=a("p"),oWr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Nee=a("a"),rWr=o("from_pretrained()"),tWr=o(" class method or the "),qee=a("a"),aWr=o("from_config()"),nWr=o(` class
method.`),sWr=l(),p$=a("p"),lWr=o("This class cannot be instantiated directly using "),hCe=a("code"),iWr=o("__init__()"),dWr=o(" (throws an error)."),cWr=l(),Yt=a("div"),F(_$.$$.fragment),fWr=l(),pCe=a("p"),mWr=o("Instantiates one of the model classes of the library (with a token classification head) from a configuration."),gWr=l(),mf=a("p"),hWr=o(`Note:
Loading a model from its configuration file does `),_Ce=a("strong"),pWr=o("not"),_Wr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),jee=a("a"),uWr=o("from_pretrained()"),bWr=o(" to load the model weights."),vWr=l(),F(w5.$$.fragment),FWr=l(),Ur=a("div"),F(u$.$$.fragment),TWr=l(),uCe=a("p"),MWr=o("Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),EWr=l(),Ln=a("p"),CWr=o("The model class to instantiate is selected based on the "),bCe=a("code"),wWr=o("model_type"),AWr=o(` property of the config object (either
passed as an argument or loaded from `),vCe=a("code"),LWr=o("pretrained_model_name_or_path"),yWr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FCe=a("code"),xWr=o("pretrained_model_name_or_path"),$Wr=o(":"),kWr=l(),Ve=a("ul"),A5=a("li"),TCe=a("strong"),SWr=o("albert"),RWr=o(" \u2014 "),Dee=a("a"),PWr=o("FlaxAlbertForTokenClassification"),BWr=o(" (ALBERT model)"),IWr=l(),L5=a("li"),MCe=a("strong"),NWr=o("bert"),qWr=o(" \u2014 "),Gee=a("a"),jWr=o("FlaxBertForTokenClassification"),DWr=o(" (BERT model)"),GWr=l(),y5=a("li"),ECe=a("strong"),OWr=o("big_bird"),VWr=o(" \u2014 "),Oee=a("a"),XWr=o("FlaxBigBirdForTokenClassification"),zWr=o(" (BigBird model)"),QWr=l(),x5=a("li"),CCe=a("strong"),WWr=o("distilbert"),HWr=o(" \u2014 "),Vee=a("a"),UWr=o("FlaxDistilBertForTokenClassification"),JWr=o(" (DistilBERT model)"),YWr=l(),$5=a("li"),wCe=a("strong"),KWr=o("electra"),ZWr=o(" \u2014 "),Xee=a("a"),eHr=o("FlaxElectraForTokenClassification"),oHr=o(" (ELECTRA model)"),rHr=l(),k5=a("li"),ACe=a("strong"),tHr=o("roberta"),aHr=o(" \u2014 "),zee=a("a"),nHr=o("FlaxRobertaForTokenClassification"),sHr=o(" (RoBERTa model)"),lHr=l(),S5=a("li"),LCe=a("strong"),iHr=o("roformer"),dHr=o(" \u2014 "),Qee=a("a"),cHr=o("FlaxRoFormerForTokenClassification"),fHr=o(" (RoFormer model)"),mHr=l(),R5=a("li"),yCe=a("strong"),gHr=o("xlm-roberta"),hHr=o(" \u2014 "),Wee=a("a"),pHr=o("FlaxXLMRobertaForTokenClassification"),_Hr=o(" (XLM-RoBERTa model)"),uHr=l(),F(P5.$$.fragment),IVe=l(),gf=a("h2"),B5=a("a"),xCe=a("span"),F(b$.$$.fragment),bHr=l(),$Ce=a("span"),vHr=o("FlaxAutoModelForMultipleChoice"),NVe=l(),Mr=a("div"),F(v$.$$.fragment),FHr=l(),hf=a("p"),THr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Hee=a("a"),MHr=o("from_pretrained()"),EHr=o(" class method or the "),Uee=a("a"),CHr=o("from_config()"),wHr=o(` class
method.`),AHr=l(),F$=a("p"),LHr=o("This class cannot be instantiated directly using "),kCe=a("code"),yHr=o("__init__()"),xHr=o(" (throws an error)."),$Hr=l(),Kt=a("div"),F(T$.$$.fragment),kHr=l(),SCe=a("p"),SHr=o("Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),RHr=l(),pf=a("p"),PHr=o(`Note:
Loading a model from its configuration file does `),RCe=a("strong"),BHr=o("not"),IHr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),Jee=a("a"),NHr=o("from_pretrained()"),qHr=o(" to load the model weights."),jHr=l(),F(I5.$$.fragment),DHr=l(),Jr=a("div"),F(M$.$$.fragment),GHr=l(),PCe=a("p"),OHr=o("Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),VHr=l(),yn=a("p"),XHr=o("The model class to instantiate is selected based on the "),BCe=a("code"),zHr=o("model_type"),QHr=o(` property of the config object (either
passed as an argument or loaded from `),ICe=a("code"),WHr=o("pretrained_model_name_or_path"),HHr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NCe=a("code"),UHr=o("pretrained_model_name_or_path"),JHr=o(":"),YHr=l(),Xe=a("ul"),N5=a("li"),qCe=a("strong"),KHr=o("albert"),ZHr=o(" \u2014 "),Yee=a("a"),eUr=o("FlaxAlbertForMultipleChoice"),oUr=o(" (ALBERT model)"),rUr=l(),q5=a("li"),jCe=a("strong"),tUr=o("bert"),aUr=o(" \u2014 "),Kee=a("a"),nUr=o("FlaxBertForMultipleChoice"),sUr=o(" (BERT model)"),lUr=l(),j5=a("li"),DCe=a("strong"),iUr=o("big_bird"),dUr=o(" \u2014 "),Zee=a("a"),cUr=o("FlaxBigBirdForMultipleChoice"),fUr=o(" (BigBird model)"),mUr=l(),D5=a("li"),GCe=a("strong"),gUr=o("distilbert"),hUr=o(" \u2014 "),eoe=a("a"),pUr=o("FlaxDistilBertForMultipleChoice"),_Ur=o(" (DistilBERT model)"),uUr=l(),G5=a("li"),OCe=a("strong"),bUr=o("electra"),vUr=o(" \u2014 "),ooe=a("a"),FUr=o("FlaxElectraForMultipleChoice"),TUr=o(" (ELECTRA model)"),MUr=l(),O5=a("li"),VCe=a("strong"),EUr=o("roberta"),CUr=o(" \u2014 "),roe=a("a"),wUr=o("FlaxRobertaForMultipleChoice"),AUr=o(" (RoBERTa model)"),LUr=l(),V5=a("li"),XCe=a("strong"),yUr=o("roformer"),xUr=o(" \u2014 "),toe=a("a"),$Ur=o("FlaxRoFormerForMultipleChoice"),kUr=o(" (RoFormer model)"),SUr=l(),X5=a("li"),zCe=a("strong"),RUr=o("xlm-roberta"),PUr=o(" \u2014 "),aoe=a("a"),BUr=o("FlaxXLMRobertaForMultipleChoice"),IUr=o(" (XLM-RoBERTa model)"),NUr=l(),F(z5.$$.fragment),qVe=l(),_f=a("h2"),Q5=a("a"),QCe=a("span"),F(E$.$$.fragment),qUr=l(),WCe=a("span"),jUr=o("FlaxAutoModelForNextSentencePrediction"),jVe=l(),Er=a("div"),F(C$.$$.fragment),DUr=l(),uf=a("p"),GUr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),noe=a("a"),OUr=o("from_pretrained()"),VUr=o(" class method or the "),soe=a("a"),XUr=o("from_config()"),zUr=o(` class
method.`),QUr=l(),w$=a("p"),WUr=o("This class cannot be instantiated directly using "),HCe=a("code"),HUr=o("__init__()"),UUr=o(" (throws an error)."),JUr=l(),Zt=a("div"),F(A$.$$.fragment),YUr=l(),UCe=a("p"),KUr=o("Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),ZUr=l(),bf=a("p"),eJr=o(`Note:
Loading a model from its configuration file does `),JCe=a("strong"),oJr=o("not"),rJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),loe=a("a"),tJr=o("from_pretrained()"),aJr=o(" to load the model weights."),nJr=l(),F(W5.$$.fragment),sJr=l(),Yr=a("div"),F(L$.$$.fragment),lJr=l(),YCe=a("p"),iJr=o("Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),dJr=l(),xn=a("p"),cJr=o("The model class to instantiate is selected based on the "),KCe=a("code"),fJr=o("model_type"),mJr=o(` property of the config object (either
passed as an argument or loaded from `),ZCe=a("code"),gJr=o("pretrained_model_name_or_path"),hJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e5e=a("code"),pJr=o("pretrained_model_name_or_path"),_Jr=o(":"),uJr=l(),o5e=a("ul"),H5=a("li"),r5e=a("strong"),bJr=o("bert"),vJr=o(" \u2014 "),ioe=a("a"),FJr=o("FlaxBertForNextSentencePrediction"),TJr=o(" (BERT model)"),MJr=l(),F(U5.$$.fragment),DVe=l(),vf=a("h2"),J5=a("a"),t5e=a("span"),F(y$.$$.fragment),EJr=l(),a5e=a("span"),CJr=o("FlaxAutoModelForImageClassification"),GVe=l(),Cr=a("div"),F(x$.$$.fragment),wJr=l(),Ff=a("p"),AJr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),doe=a("a"),LJr=o("from_pretrained()"),yJr=o(" class method or the "),coe=a("a"),xJr=o("from_config()"),$Jr=o(` class
method.`),kJr=l(),$$=a("p"),SJr=o("This class cannot be instantiated directly using "),n5e=a("code"),RJr=o("__init__()"),PJr=o(" (throws an error)."),BJr=l(),ea=a("div"),F(k$.$$.fragment),IJr=l(),s5e=a("p"),NJr=o("Instantiates one of the model classes of the library (with a image classification head) from a configuration."),qJr=l(),Tf=a("p"),jJr=o(`Note:
Loading a model from its configuration file does `),l5e=a("strong"),DJr=o("not"),GJr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),foe=a("a"),OJr=o("from_pretrained()"),VJr=o(" to load the model weights."),XJr=l(),F(Y5.$$.fragment),zJr=l(),Kr=a("div"),F(S$.$$.fragment),QJr=l(),i5e=a("p"),WJr=o("Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),HJr=l(),$n=a("p"),UJr=o("The model class to instantiate is selected based on the "),d5e=a("code"),JJr=o("model_type"),YJr=o(` property of the config object (either
passed as an argument or loaded from `),c5e=a("code"),KJr=o("pretrained_model_name_or_path"),ZJr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f5e=a("code"),eYr=o("pretrained_model_name_or_path"),oYr=o(":"),rYr=l(),R$=a("ul"),K5=a("li"),m5e=a("strong"),tYr=o("beit"),aYr=o(" \u2014 "),moe=a("a"),nYr=o("FlaxBeitForImageClassification"),sYr=o(" (BEiT model)"),lYr=l(),Z5=a("li"),g5e=a("strong"),iYr=o("vit"),dYr=o(" \u2014 "),goe=a("a"),cYr=o("FlaxViTForImageClassification"),fYr=o(" (ViT model)"),mYr=l(),F(e3.$$.fragment),OVe=l(),Mf=a("h2"),o3=a("a"),h5e=a("span"),F(P$.$$.fragment),gYr=l(),p5e=a("span"),hYr=o("FlaxAutoModelForVision2Seq"),VVe=l(),wr=a("div"),F(B$.$$.fragment),pYr=l(),Ef=a("p"),_Yr=o(`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),hoe=a("a"),uYr=o("from_pretrained()"),bYr=o(" class method or the "),poe=a("a"),vYr=o("from_config()"),FYr=o(` class
method.`),TYr=l(),I$=a("p"),MYr=o("This class cannot be instantiated directly using "),_5e=a("code"),EYr=o("__init__()"),CYr=o(" (throws an error)."),wYr=l(),oa=a("div"),F(N$.$$.fragment),AYr=l(),u5e=a("p"),LYr=o("Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),yYr=l(),Cf=a("p"),xYr=o(`Note:
Loading a model from its configuration file does `),b5e=a("strong"),$Yr=o("not"),kYr=o(` load the model weights. It only affects the
model\u2019s configuration. Use `),_oe=a("a"),SYr=o("from_pretrained()"),RYr=o(" to load the model weights."),PYr=l(),F(r3.$$.fragment),BYr=l(),Zr=a("div"),F(q$.$$.fragment),IYr=l(),v5e=a("p"),NYr=o("Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),qYr=l(),kn=a("p"),jYr=o("The model class to instantiate is selected based on the "),F5e=a("code"),DYr=o("model_type"),GYr=o(` property of the config object (either
passed as an argument or loaded from `),T5e=a("code"),OYr=o("pretrained_model_name_or_path"),VYr=o(` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M5e=a("code"),XYr=o("pretrained_model_name_or_path"),zYr=o(":"),QYr=l(),E5e=a("ul"),t3=a("li"),C5e=a("strong"),WYr=o("vision-encoder-decoder"),HYr=o(" \u2014 "),uoe=a("a"),UYr=o("FlaxVisionEncoderDecoderModel"),JYr=o(" (Vision Encoder decoder model)"),YYr=l(),F(a3.$$.fragment),this.h()},l(f){const u=MDt('[data-svelte="svelte-1phssyn"]',document.head);g=n(u,"META",{name:!0,content:!0}),u.forEach(t),v=i(f),p=n(f,"H1",{class:!0});var j$=s(p);m=n(j$,"A",{id:!0,class:!0,href:!0});var w5e=s(m);_=n(w5e,"SPAN",{});var A5e=s(_);T(d.$$.fragment,A5e),A5e.forEach(t),w5e.forEach(t),h=i(j$),Eo=n(j$,"SPAN",{});var L5e=s(Eo);Ti=r(L5e,"Auto Classes"),L5e.forEach(t),j$.forEach(t),yf=i(f),at=n(f,"P",{});var D$=s(at);Mi=r(D$,`In many cases, the architecture you want to use can be guessed from the name or the path of the pretrained model you
are supplying to the `),Ei=n(D$,"CODE",{});var y5e=s(Ei);ww=r(y5e,"from_pretrained()"),y5e.forEach(t),xf=r(D$,` method. AutoClasses are here to do this job for you so that you
automatically retrieve the relevant model given the name/path to the pretrained weights/config/vocabulary.`),D$.forEach(t),Oe=i(f),Qe=n(f,"P",{});var Sn=s(Qe);Ci=r(Sn,"Instantiating one of "),Rn=n(Sn,"A",{href:!0});var x5e=s(Rn);Aw=r(x5e,"AutoConfig"),x5e.forEach(t),Pn=r(Sn,", "),Bn=n(Sn,"A",{href:!0});var $5e=s(Bn);Lw=r($5e,"AutoModel"),$5e.forEach(t),wi=r(Sn,`, and
`),In=n(Sn,"A",{href:!0});var k5e=s(In);yw=r(k5e,"AutoTokenizer"),k5e.forEach(t),Ai=r(Sn," will directly create a class of the relevant architecture. For instance"),Sn.forEach(t),$f=i(f),T(xa.$$.fragment,f),We=i(f),Ae=n(f,"P",{});var G$=s(Ae);rS=r(G$,"will create a model that is an instance of "),Li=n(G$,"A",{href:!0});var S5e=s(Li);tS=r(S5e,"BertModel"),S5e.forEach(t),aS=r(G$,"."),G$.forEach(t),Co=i(f),$a=n(f,"P",{});var O$=s($a);nS=r(O$,"There is one class of "),kf=n(O$,"CODE",{});var R5e=s(kf);sS=r(R5e,"AutoModel"),R5e.forEach(t),eQe=r(O$," for each task, and for each backend (PyTorch, TensorFlow, or Flax)."),O$.forEach(t),jGe=i(f),yi=n(f,"H2",{class:!0});var V$=s(yi);Sf=n(V$,"A",{id:!0,class:!0,href:!0});var P5e=s(Sf);mte=n(P5e,"SPAN",{});var B5e=s(mte);T(xw.$$.fragment,B5e),B5e.forEach(t),P5e.forEach(t),oQe=i(V$),gte=n(V$,"SPAN",{});var I5e=s(gte);rQe=r(I5e,"Extending the Auto Classes"),I5e.forEach(t),V$.forEach(t),DGe=i(f),Nn=n(f,"P",{});var wf=s(Nn);tQe=r(wf,`Each of the auto classes has a method to be extended with your custom classes. For instance, if you have defined a
custom class of model `),hte=n(wf,"CODE",{});var N5e=s(hte);aQe=r(N5e,"NewModel"),N5e.forEach(t),nQe=r(wf,", make sure you have a "),pte=n(wf,"CODE",{});var q5e=s(pte);sQe=r(q5e,"NewModelConfig"),q5e.forEach(t),lQe=r(wf,` then you can add those to the auto
classes like this:`),wf.forEach(t),GGe=i(f),T($w.$$.fragment,f),OGe=i(f),lS=n(f,"P",{});var j5e=s(lS);iQe=r(j5e,"You will then be able to use the auto classes like you would usually do!"),j5e.forEach(t),VGe=i(f),T(Rf.$$.fragment,f),XGe=i(f),xi=n(f,"H2",{class:!0});var X$=s(xi);Pf=n(X$,"A",{id:!0,class:!0,href:!0});var D5e=s(Pf);_te=n(D5e,"SPAN",{});var G5e=s(_te);T(kw.$$.fragment,G5e),G5e.forEach(t),D5e.forEach(t),dQe=i(X$),ute=n(X$,"SPAN",{});var O5e=s(ute);cQe=r(O5e,"AutoConfig"),O5e.forEach(t),X$.forEach(t),zGe=i(f),wo=n(f,"DIV",{class:!0});var rt=s(wo);T(Sw.$$.fragment,rt),fQe=i(rt),Rw=n(rt,"P",{});var z$=s(Rw);mQe=r(z$,`This is a generic configuration class that will be instantiated as one of the configuration classes of the library
when created with the `),iS=n(z$,"A",{href:!0});var V5e=s(iS);gQe=r(V5e,"from_pretrained()"),V5e.forEach(t),hQe=r(z$," class method."),z$.forEach(t),pQe=i(rt),Pw=n(rt,"P",{});var Q$=s(Pw);_Qe=r(Q$,"This class cannot be instantiated directly using "),bte=n(Q$,"CODE",{});var X5e=s(bte);uQe=r(X5e,"__init__()"),X5e.forEach(t),bQe=r(Q$," (throws an error)."),Q$.forEach(t),vQe=i(rt),Ar=n(rt,"DIV",{class:!0});var tt=s(Ar);T(Bw.$$.fragment,tt),FQe=i(tt),vte=n(tt,"P",{});var z5e=s(vte);TQe=r(z5e,"Instantiate one of the configuration classes of the library from a pretrained model configuration."),z5e.forEach(t),MQe=i(tt),$i=n(tt,"P",{});var Af=s($i);EQe=r(Af,"The configuration class to instantiate is selected based on the "),Fte=n(Af,"CODE",{});var Q5e=s(Fte);CQe=r(Q5e,"model_type"),Q5e.forEach(t),wQe=r(Af,` property of the config object that
is loaded, or when it\u2019s missing, by falling back to using pattern matching on `),Tte=n(Af,"CODE",{});var W5e=s(Tte);AQe=r(W5e,"pretrained_model_name_or_path"),W5e.forEach(t),LQe=r(Af,":"),Af.forEach(t),yQe=i(tt),A=n(tt,"UL",{});var L=s(A);Bf=n(L,"LI",{});var n3=s(Bf);Mte=n(n3,"STRONG",{});var H5e=s(Mte);xQe=r(H5e,"albert"),H5e.forEach(t),$Qe=r(n3," \u2014 "),dS=n(n3,"A",{href:!0});var U5e=s(dS);kQe=r(U5e,"AlbertConfig"),U5e.forEach(t),SQe=r(n3," (ALBERT model)"),n3.forEach(t),RQe=i(L),If=n(L,"LI",{});var s3=s(If);Ete=n(s3,"STRONG",{});var J5e=s(Ete);PQe=r(J5e,"bart"),J5e.forEach(t),BQe=r(s3," \u2014 "),cS=n(s3,"A",{href:!0});var Y5e=s(cS);IQe=r(Y5e,"BartConfig"),Y5e.forEach(t),NQe=r(s3," (BART model)"),s3.forEach(t),qQe=i(L),Nf=n(L,"LI",{});var l3=s(Nf);Cte=n(l3,"STRONG",{});var K5e=s(Cte);jQe=r(K5e,"beit"),K5e.forEach(t),DQe=r(l3," \u2014 "),fS=n(l3,"A",{href:!0});var Z5e=s(fS);GQe=r(Z5e,"BeitConfig"),Z5e.forEach(t),OQe=r(l3," (BEiT model)"),l3.forEach(t),VQe=i(L),qf=n(L,"LI",{});var i3=s(qf);wte=n(i3,"STRONG",{});var e3e=s(wte);XQe=r(e3e,"bert"),e3e.forEach(t),zQe=r(i3," \u2014 "),mS=n(i3,"A",{href:!0});var o3e=s(mS);QQe=r(o3e,"BertConfig"),o3e.forEach(t),WQe=r(i3," (BERT model)"),i3.forEach(t),HQe=i(L),jf=n(L,"LI",{});var d3=s(jf);Ate=n(d3,"STRONG",{});var r3e=s(Ate);UQe=r(r3e,"bert-generation"),r3e.forEach(t),JQe=r(d3," \u2014 "),gS=n(d3,"A",{href:!0});var t3e=s(gS);YQe=r(t3e,"BertGenerationConfig"),t3e.forEach(t),KQe=r(d3," (Bert Generation model)"),d3.forEach(t),ZQe=i(L),Df=n(L,"LI",{});var c3=s(Df);Lte=n(c3,"STRONG",{});var a3e=s(Lte);eWe=r(a3e,"big_bird"),a3e.forEach(t),oWe=r(c3," \u2014 "),hS=n(c3,"A",{href:!0});var n3e=s(hS);rWe=r(n3e,"BigBirdConfig"),n3e.forEach(t),tWe=r(c3," (BigBird model)"),c3.forEach(t),aWe=i(L),Gf=n(L,"LI",{});var f3=s(Gf);yte=n(f3,"STRONG",{});var s3e=s(yte);nWe=r(s3e,"bigbird_pegasus"),s3e.forEach(t),sWe=r(f3," \u2014 "),pS=n(f3,"A",{href:!0});var l3e=s(pS);lWe=r(l3e,"BigBirdPegasusConfig"),l3e.forEach(t),iWe=r(f3," (BigBird-Pegasus model)"),f3.forEach(t),dWe=i(L),Of=n(L,"LI",{});var m3=s(Of);xte=n(m3,"STRONG",{});var i3e=s(xte);cWe=r(i3e,"blenderbot"),i3e.forEach(t),fWe=r(m3," \u2014 "),_S=n(m3,"A",{href:!0});var d3e=s(_S);mWe=r(d3e,"BlenderbotConfig"),d3e.forEach(t),gWe=r(m3," (Blenderbot model)"),m3.forEach(t),hWe=i(L),Vf=n(L,"LI",{});var g3=s(Vf);$te=n(g3,"STRONG",{});var c3e=s($te);pWe=r(c3e,"blenderbot-small"),c3e.forEach(t),_We=r(g3," \u2014 "),uS=n(g3,"A",{href:!0});var f3e=s(uS);uWe=r(f3e,"BlenderbotSmallConfig"),f3e.forEach(t),bWe=r(g3," (BlenderbotSmall model)"),g3.forEach(t),vWe=i(L),Xf=n(L,"LI",{});var h3=s(Xf);kte=n(h3,"STRONG",{});var m3e=s(kte);FWe=r(m3e,"bloom"),m3e.forEach(t),TWe=r(h3," \u2014 "),bS=n(h3,"A",{href:!0});var g3e=s(bS);MWe=r(g3e,"BloomConfig"),g3e.forEach(t),EWe=r(h3," (BLOOM model)"),h3.forEach(t),CWe=i(L),zf=n(L,"LI",{});var p3=s(zf);Ste=n(p3,"STRONG",{});var h3e=s(Ste);wWe=r(h3e,"camembert"),h3e.forEach(t),AWe=r(p3," \u2014 "),vS=n(p3,"A",{href:!0});var p3e=s(vS);LWe=r(p3e,"CamembertConfig"),p3e.forEach(t),yWe=r(p3," (CamemBERT model)"),p3.forEach(t),xWe=i(L),Qf=n(L,"LI",{});var _3=s(Qf);Rte=n(_3,"STRONG",{});var _3e=s(Rte);$We=r(_3e,"canine"),_3e.forEach(t),kWe=r(_3," \u2014 "),FS=n(_3,"A",{href:!0});var u3e=s(FS);SWe=r(u3e,"CanineConfig"),u3e.forEach(t),RWe=r(_3," (CANINE model)"),_3.forEach(t),PWe=i(L),Wf=n(L,"LI",{});var u3=s(Wf);Pte=n(u3,"STRONG",{});var b3e=s(Pte);BWe=r(b3e,"clip"),b3e.forEach(t),IWe=r(u3," \u2014 "),TS=n(u3,"A",{href:!0});var v3e=s(TS);NWe=r(v3e,"CLIPConfig"),v3e.forEach(t),qWe=r(u3," (CLIP model)"),u3.forEach(t),jWe=i(L),Hf=n(L,"LI",{});var b3=s(Hf);Bte=n(b3,"STRONG",{});var F3e=s(Bte);DWe=r(F3e,"convbert"),F3e.forEach(t),GWe=r(b3," \u2014 "),MS=n(b3,"A",{href:!0});var T3e=s(MS);OWe=r(T3e,"ConvBertConfig"),T3e.forEach(t),VWe=r(b3," (ConvBERT model)"),b3.forEach(t),XWe=i(L),Uf=n(L,"LI",{});var v3=s(Uf);Ite=n(v3,"STRONG",{});var M3e=s(Ite);zWe=r(M3e,"convnext"),M3e.forEach(t),QWe=r(v3," \u2014 "),ES=n(v3,"A",{href:!0});var E3e=s(ES);WWe=r(E3e,"ConvNextConfig"),E3e.forEach(t),HWe=r(v3," (ConvNeXT model)"),v3.forEach(t),UWe=i(L),Jf=n(L,"LI",{});var F3=s(Jf);Nte=n(F3,"STRONG",{});var C3e=s(Nte);JWe=r(C3e,"ctrl"),C3e.forEach(t),YWe=r(F3," \u2014 "),CS=n(F3,"A",{href:!0});var w3e=s(CS);KWe=r(w3e,"CTRLConfig"),w3e.forEach(t),ZWe=r(F3," (CTRL model)"),F3.forEach(t),eHe=i(L),Yf=n(L,"LI",{});var T3=s(Yf);qte=n(T3,"STRONG",{});var A3e=s(qte);oHe=r(A3e,"cvt"),A3e.forEach(t),rHe=r(T3," \u2014 "),wS=n(T3,"A",{href:!0});var L3e=s(wS);tHe=r(L3e,"CvtConfig"),L3e.forEach(t),aHe=r(T3," (CvT model)"),T3.forEach(t),nHe=i(L),Kf=n(L,"LI",{});var M3=s(Kf);jte=n(M3,"STRONG",{});var y3e=s(jte);sHe=r(y3e,"data2vec-audio"),y3e.forEach(t),lHe=r(M3," \u2014 "),AS=n(M3,"A",{href:!0});var x3e=s(AS);iHe=r(x3e,"Data2VecAudioConfig"),x3e.forEach(t),dHe=r(M3," (Data2VecAudio model)"),M3.forEach(t),cHe=i(L),Zf=n(L,"LI",{});var E3=s(Zf);Dte=n(E3,"STRONG",{});var $3e=s(Dte);fHe=r($3e,"data2vec-text"),$3e.forEach(t),mHe=r(E3," \u2014 "),LS=n(E3,"A",{href:!0});var k3e=s(LS);gHe=r(k3e,"Data2VecTextConfig"),k3e.forEach(t),hHe=r(E3," (Data2VecText model)"),E3.forEach(t),pHe=i(L),em=n(L,"LI",{});var C3=s(em);Gte=n(C3,"STRONG",{});var S3e=s(Gte);_He=r(S3e,"data2vec-vision"),S3e.forEach(t),uHe=r(C3," \u2014 "),yS=n(C3,"A",{href:!0});var R3e=s(yS);bHe=r(R3e,"Data2VecVisionConfig"),R3e.forEach(t),vHe=r(C3," (Data2VecVision model)"),C3.forEach(t),FHe=i(L),om=n(L,"LI",{});var w3=s(om);Ote=n(w3,"STRONG",{});var P3e=s(Ote);THe=r(P3e,"deberta"),P3e.forEach(t),MHe=r(w3," \u2014 "),xS=n(w3,"A",{href:!0});var B3e=s(xS);EHe=r(B3e,"DebertaConfig"),B3e.forEach(t),CHe=r(w3," (DeBERTa model)"),w3.forEach(t),wHe=i(L),rm=n(L,"LI",{});var A3=s(rm);Vte=n(A3,"STRONG",{});var I3e=s(Vte);AHe=r(I3e,"deberta-v2"),I3e.forEach(t),LHe=r(A3," \u2014 "),$S=n(A3,"A",{href:!0});var N3e=s($S);yHe=r(N3e,"DebertaV2Config"),N3e.forEach(t),xHe=r(A3," (DeBERTa-v2 model)"),A3.forEach(t),$He=i(L),tm=n(L,"LI",{});var L3=s(tm);Xte=n(L3,"STRONG",{});var q3e=s(Xte);kHe=r(q3e,"decision_transformer"),q3e.forEach(t),SHe=r(L3," \u2014 "),kS=n(L3,"A",{href:!0});var j3e=s(kS);RHe=r(j3e,"DecisionTransformerConfig"),j3e.forEach(t),PHe=r(L3," (Decision Transformer model)"),L3.forEach(t),BHe=i(L),am=n(L,"LI",{});var y3=s(am);zte=n(y3,"STRONG",{});var ZYr=s(zte);IHe=r(ZYr,"deit"),ZYr.forEach(t),NHe=r(y3," \u2014 "),SS=n(y3,"A",{href:!0});var eKr=s(SS);qHe=r(eKr,"DeiTConfig"),eKr.forEach(t),jHe=r(y3," (DeiT model)"),y3.forEach(t),DHe=i(L),nm=n(L,"LI",{});var D3e=s(nm);Qte=n(D3e,"STRONG",{});var oKr=s(Qte);GHe=r(oKr,"detr"),oKr.forEach(t),OHe=r(D3e," \u2014 "),RS=n(D3e,"A",{href:!0});var rKr=s(RS);VHe=r(rKr,"DetrConfig"),rKr.forEach(t),XHe=r(D3e," (DETR model)"),D3e.forEach(t),zHe=i(L),sm=n(L,"LI",{});var G3e=s(sm);Wte=n(G3e,"STRONG",{});var tKr=s(Wte);QHe=r(tKr,"distilbert"),tKr.forEach(t),WHe=r(G3e," \u2014 "),PS=n(G3e,"A",{href:!0});var aKr=s(PS);HHe=r(aKr,"DistilBertConfig"),aKr.forEach(t),UHe=r(G3e," (DistilBERT model)"),G3e.forEach(t),JHe=i(L),lm=n(L,"LI",{});var O3e=s(lm);Hte=n(O3e,"STRONG",{});var nKr=s(Hte);YHe=r(nKr,"dpr"),nKr.forEach(t),KHe=r(O3e," \u2014 "),BS=n(O3e,"A",{href:!0});var sKr=s(BS);ZHe=r(sKr,"DPRConfig"),sKr.forEach(t),eUe=r(O3e," (DPR model)"),O3e.forEach(t),oUe=i(L),im=n(L,"LI",{});var V3e=s(im);Ute=n(V3e,"STRONG",{});var lKr=s(Ute);rUe=r(lKr,"dpt"),lKr.forEach(t),tUe=r(V3e," \u2014 "),IS=n(V3e,"A",{href:!0});var iKr=s(IS);aUe=r(iKr,"DPTConfig"),iKr.forEach(t),nUe=r(V3e," (DPT model)"),V3e.forEach(t),sUe=i(L),dm=n(L,"LI",{});var X3e=s(dm);Jte=n(X3e,"STRONG",{});var dKr=s(Jte);lUe=r(dKr,"electra"),dKr.forEach(t),iUe=r(X3e," \u2014 "),NS=n(X3e,"A",{href:!0});var cKr=s(NS);dUe=r(cKr,"ElectraConfig"),cKr.forEach(t),cUe=r(X3e," (ELECTRA model)"),X3e.forEach(t),fUe=i(L),cm=n(L,"LI",{});var z3e=s(cm);Yte=n(z3e,"STRONG",{});var fKr=s(Yte);mUe=r(fKr,"encoder-decoder"),fKr.forEach(t),gUe=r(z3e," \u2014 "),qS=n(z3e,"A",{href:!0});var mKr=s(qS);hUe=r(mKr,"EncoderDecoderConfig"),mKr.forEach(t),pUe=r(z3e," (Encoder decoder model)"),z3e.forEach(t),_Ue=i(L),fm=n(L,"LI",{});var Q3e=s(fm);Kte=n(Q3e,"STRONG",{});var gKr=s(Kte);uUe=r(gKr,"flaubert"),gKr.forEach(t),bUe=r(Q3e," \u2014 "),jS=n(Q3e,"A",{href:!0});var hKr=s(jS);vUe=r(hKr,"FlaubertConfig"),hKr.forEach(t),FUe=r(Q3e," (FlauBERT model)"),Q3e.forEach(t),TUe=i(L),mm=n(L,"LI",{});var W3e=s(mm);Zte=n(W3e,"STRONG",{});var pKr=s(Zte);MUe=r(pKr,"flava"),pKr.forEach(t),EUe=r(W3e," \u2014 "),DS=n(W3e,"A",{href:!0});var _Kr=s(DS);CUe=r(_Kr,"FlavaConfig"),_Kr.forEach(t),wUe=r(W3e," (FLAVA model)"),W3e.forEach(t),AUe=i(L),gm=n(L,"LI",{});var H3e=s(gm);eae=n(H3e,"STRONG",{});var uKr=s(eae);LUe=r(uKr,"fnet"),uKr.forEach(t),yUe=r(H3e," \u2014 "),GS=n(H3e,"A",{href:!0});var bKr=s(GS);xUe=r(bKr,"FNetConfig"),bKr.forEach(t),$Ue=r(H3e," (FNet model)"),H3e.forEach(t),kUe=i(L),hm=n(L,"LI",{});var U3e=s(hm);oae=n(U3e,"STRONG",{});var vKr=s(oae);SUe=r(vKr,"fsmt"),vKr.forEach(t),RUe=r(U3e," \u2014 "),OS=n(U3e,"A",{href:!0});var FKr=s(OS);PUe=r(FKr,"FSMTConfig"),FKr.forEach(t),BUe=r(U3e," (FairSeq Machine-Translation model)"),U3e.forEach(t),IUe=i(L),pm=n(L,"LI",{});var J3e=s(pm);rae=n(J3e,"STRONG",{});var TKr=s(rae);NUe=r(TKr,"funnel"),TKr.forEach(t),qUe=r(J3e," \u2014 "),VS=n(J3e,"A",{href:!0});var MKr=s(VS);jUe=r(MKr,"FunnelConfig"),MKr.forEach(t),DUe=r(J3e," (Funnel Transformer model)"),J3e.forEach(t),GUe=i(L),_m=n(L,"LI",{});var Y3e=s(_m);tae=n(Y3e,"STRONG",{});var EKr=s(tae);OUe=r(EKr,"glpn"),EKr.forEach(t),VUe=r(Y3e," \u2014 "),XS=n(Y3e,"A",{href:!0});var CKr=s(XS);XUe=r(CKr,"GLPNConfig"),CKr.forEach(t),zUe=r(Y3e," (GLPN model)"),Y3e.forEach(t),QUe=i(L),um=n(L,"LI",{});var K3e=s(um);aae=n(K3e,"STRONG",{});var wKr=s(aae);WUe=r(wKr,"gpt2"),wKr.forEach(t),HUe=r(K3e," \u2014 "),zS=n(K3e,"A",{href:!0});var AKr=s(zS);UUe=r(AKr,"GPT2Config"),AKr.forEach(t),JUe=r(K3e," (OpenAI GPT-2 model)"),K3e.forEach(t),YUe=i(L),bm=n(L,"LI",{});var Z3e=s(bm);nae=n(Z3e,"STRONG",{});var LKr=s(nae);KUe=r(LKr,"gpt_neo"),LKr.forEach(t),ZUe=r(Z3e," \u2014 "),QS=n(Z3e,"A",{href:!0});var yKr=s(QS);eJe=r(yKr,"GPTNeoConfig"),yKr.forEach(t),oJe=r(Z3e," (GPT Neo model)"),Z3e.forEach(t),rJe=i(L),vm=n(L,"LI",{});var e0e=s(vm);sae=n(e0e,"STRONG",{});var xKr=s(sae);tJe=r(xKr,"gpt_neox"),xKr.forEach(t),aJe=r(e0e," \u2014 "),WS=n(e0e,"A",{href:!0});var $Kr=s(WS);nJe=r($Kr,"GPTNeoXConfig"),$Kr.forEach(t),sJe=r(e0e," (GPT NeoX model)"),e0e.forEach(t),lJe=i(L),Fm=n(L,"LI",{});var o0e=s(Fm);lae=n(o0e,"STRONG",{});var kKr=s(lae);iJe=r(kKr,"gptj"),kKr.forEach(t),dJe=r(o0e," \u2014 "),HS=n(o0e,"A",{href:!0});var SKr=s(HS);cJe=r(SKr,"GPTJConfig"),SKr.forEach(t),fJe=r(o0e," (GPT-J model)"),o0e.forEach(t),mJe=i(L),Tm=n(L,"LI",{});var r0e=s(Tm);iae=n(r0e,"STRONG",{});var RKr=s(iae);gJe=r(RKr,"hubert"),RKr.forEach(t),hJe=r(r0e," \u2014 "),US=n(r0e,"A",{href:!0});var PKr=s(US);pJe=r(PKr,"HubertConfig"),PKr.forEach(t),_Je=r(r0e," (Hubert model)"),r0e.forEach(t),uJe=i(L),Mm=n(L,"LI",{});var t0e=s(Mm);dae=n(t0e,"STRONG",{});var BKr=s(dae);bJe=r(BKr,"ibert"),BKr.forEach(t),vJe=r(t0e," \u2014 "),JS=n(t0e,"A",{href:!0});var IKr=s(JS);FJe=r(IKr,"IBertConfig"),IKr.forEach(t),TJe=r(t0e," (I-BERT model)"),t0e.forEach(t),MJe=i(L),Em=n(L,"LI",{});var a0e=s(Em);cae=n(a0e,"STRONG",{});var NKr=s(cae);EJe=r(NKr,"imagegpt"),NKr.forEach(t),CJe=r(a0e," \u2014 "),YS=n(a0e,"A",{href:!0});var qKr=s(YS);wJe=r(qKr,"ImageGPTConfig"),qKr.forEach(t),AJe=r(a0e," (ImageGPT model)"),a0e.forEach(t),LJe=i(L),Cm=n(L,"LI",{});var n0e=s(Cm);fae=n(n0e,"STRONG",{});var jKr=s(fae);yJe=r(jKr,"layoutlm"),jKr.forEach(t),xJe=r(n0e," \u2014 "),KS=n(n0e,"A",{href:!0});var DKr=s(KS);$Je=r(DKr,"LayoutLMConfig"),DKr.forEach(t),kJe=r(n0e," (LayoutLM model)"),n0e.forEach(t),SJe=i(L),wm=n(L,"LI",{});var s0e=s(wm);mae=n(s0e,"STRONG",{});var GKr=s(mae);RJe=r(GKr,"layoutlmv2"),GKr.forEach(t),PJe=r(s0e," \u2014 "),ZS=n(s0e,"A",{href:!0});var OKr=s(ZS);BJe=r(OKr,"LayoutLMv2Config"),OKr.forEach(t),IJe=r(s0e," (LayoutLMv2 model)"),s0e.forEach(t),NJe=i(L),Am=n(L,"LI",{});var l0e=s(Am);gae=n(l0e,"STRONG",{});var VKr=s(gae);qJe=r(VKr,"layoutlmv3"),VKr.forEach(t),jJe=r(l0e," \u2014 "),eR=n(l0e,"A",{href:!0});var XKr=s(eR);DJe=r(XKr,"LayoutLMv3Config"),XKr.forEach(t),GJe=r(l0e," (LayoutLMv3 model)"),l0e.forEach(t),OJe=i(L),Lm=n(L,"LI",{});var i0e=s(Lm);hae=n(i0e,"STRONG",{});var zKr=s(hae);VJe=r(zKr,"led"),zKr.forEach(t),XJe=r(i0e," \u2014 "),oR=n(i0e,"A",{href:!0});var QKr=s(oR);zJe=r(QKr,"LEDConfig"),QKr.forEach(t),QJe=r(i0e," (LED model)"),i0e.forEach(t),WJe=i(L),ym=n(L,"LI",{});var d0e=s(ym);pae=n(d0e,"STRONG",{});var WKr=s(pae);HJe=r(WKr,"levit"),WKr.forEach(t),UJe=r(d0e," \u2014 "),rR=n(d0e,"A",{href:!0});var HKr=s(rR);JJe=r(HKr,"LevitConfig"),HKr.forEach(t),YJe=r(d0e," (LeViT model)"),d0e.forEach(t),KJe=i(L),xm=n(L,"LI",{});var c0e=s(xm);_ae=n(c0e,"STRONG",{});var UKr=s(_ae);ZJe=r(UKr,"longformer"),UKr.forEach(t),eYe=r(c0e," \u2014 "),tR=n(c0e,"A",{href:!0});var JKr=s(tR);oYe=r(JKr,"LongformerConfig"),JKr.forEach(t),rYe=r(c0e," (Longformer model)"),c0e.forEach(t),tYe=i(L),$m=n(L,"LI",{});var f0e=s($m);uae=n(f0e,"STRONG",{});var YKr=s(uae);aYe=r(YKr,"longt5"),YKr.forEach(t),nYe=r(f0e," \u2014 "),aR=n(f0e,"A",{href:!0});var KKr=s(aR);sYe=r(KKr,"LongT5Config"),KKr.forEach(t),lYe=r(f0e," (LongT5 model)"),f0e.forEach(t),iYe=i(L),km=n(L,"LI",{});var m0e=s(km);bae=n(m0e,"STRONG",{});var ZKr=s(bae);dYe=r(ZKr,"luke"),ZKr.forEach(t),cYe=r(m0e," \u2014 "),nR=n(m0e,"A",{href:!0});var eZr=s(nR);fYe=r(eZr,"LukeConfig"),eZr.forEach(t),mYe=r(m0e," (LUKE model)"),m0e.forEach(t),gYe=i(L),Sm=n(L,"LI",{});var g0e=s(Sm);vae=n(g0e,"STRONG",{});var oZr=s(vae);hYe=r(oZr,"lxmert"),oZr.forEach(t),pYe=r(g0e," \u2014 "),sR=n(g0e,"A",{href:!0});var rZr=s(sR);_Ye=r(rZr,"LxmertConfig"),rZr.forEach(t),uYe=r(g0e," (LXMERT model)"),g0e.forEach(t),bYe=i(L),Rm=n(L,"LI",{});var h0e=s(Rm);Fae=n(h0e,"STRONG",{});var tZr=s(Fae);vYe=r(tZr,"m2m_100"),tZr.forEach(t),FYe=r(h0e," \u2014 "),lR=n(h0e,"A",{href:!0});var aZr=s(lR);TYe=r(aZr,"M2M100Config"),aZr.forEach(t),MYe=r(h0e," (M2M100 model)"),h0e.forEach(t),EYe=i(L),Pm=n(L,"LI",{});var p0e=s(Pm);Tae=n(p0e,"STRONG",{});var nZr=s(Tae);CYe=r(nZr,"marian"),nZr.forEach(t),wYe=r(p0e," \u2014 "),iR=n(p0e,"A",{href:!0});var sZr=s(iR);AYe=r(sZr,"MarianConfig"),sZr.forEach(t),LYe=r(p0e," (Marian model)"),p0e.forEach(t),yYe=i(L),Bm=n(L,"LI",{});var _0e=s(Bm);Mae=n(_0e,"STRONG",{});var lZr=s(Mae);xYe=r(lZr,"maskformer"),lZr.forEach(t),$Ye=r(_0e," \u2014 "),dR=n(_0e,"A",{href:!0});var iZr=s(dR);kYe=r(iZr,"MaskFormerConfig"),iZr.forEach(t),SYe=r(_0e," (MaskFormer model)"),_0e.forEach(t),RYe=i(L),Im=n(L,"LI",{});var u0e=s(Im);Eae=n(u0e,"STRONG",{});var dZr=s(Eae);PYe=r(dZr,"mbart"),dZr.forEach(t),BYe=r(u0e," \u2014 "),cR=n(u0e,"A",{href:!0});var cZr=s(cR);IYe=r(cZr,"MBartConfig"),cZr.forEach(t),NYe=r(u0e," (mBART model)"),u0e.forEach(t),qYe=i(L),Nm=n(L,"LI",{});var b0e=s(Nm);Cae=n(b0e,"STRONG",{});var fZr=s(Cae);jYe=r(fZr,"mctct"),fZr.forEach(t),DYe=r(b0e," \u2014 "),fR=n(b0e,"A",{href:!0});var mZr=s(fR);GYe=r(mZr,"MCTCTConfig"),mZr.forEach(t),OYe=r(b0e," (M-CTC-T model)"),b0e.forEach(t),VYe=i(L),qm=n(L,"LI",{});var v0e=s(qm);wae=n(v0e,"STRONG",{});var gZr=s(wae);XYe=r(gZr,"megatron-bert"),gZr.forEach(t),zYe=r(v0e," \u2014 "),mR=n(v0e,"A",{href:!0});var hZr=s(mR);QYe=r(hZr,"MegatronBertConfig"),hZr.forEach(t),WYe=r(v0e," (Megatron-BERT model)"),v0e.forEach(t),HYe=i(L),jm=n(L,"LI",{});var F0e=s(jm);Aae=n(F0e,"STRONG",{});var pZr=s(Aae);UYe=r(pZr,"mobilebert"),pZr.forEach(t),JYe=r(F0e," \u2014 "),gR=n(F0e,"A",{href:!0});var _Zr=s(gR);YYe=r(_Zr,"MobileBertConfig"),_Zr.forEach(t),KYe=r(F0e," (MobileBERT model)"),F0e.forEach(t),ZYe=i(L),Dm=n(L,"LI",{});var T0e=s(Dm);Lae=n(T0e,"STRONG",{});var uZr=s(Lae);eKe=r(uZr,"mpnet"),uZr.forEach(t),oKe=r(T0e," \u2014 "),hR=n(T0e,"A",{href:!0});var bZr=s(hR);rKe=r(bZr,"MPNetConfig"),bZr.forEach(t),tKe=r(T0e," (MPNet model)"),T0e.forEach(t),aKe=i(L),Gm=n(L,"LI",{});var M0e=s(Gm);yae=n(M0e,"STRONG",{});var vZr=s(yae);nKe=r(vZr,"mt5"),vZr.forEach(t),sKe=r(M0e," \u2014 "),pR=n(M0e,"A",{href:!0});var FZr=s(pR);lKe=r(FZr,"MT5Config"),FZr.forEach(t),iKe=r(M0e," (MT5 model)"),M0e.forEach(t),dKe=i(L),Om=n(L,"LI",{});var E0e=s(Om);xae=n(E0e,"STRONG",{});var TZr=s(xae);cKe=r(TZr,"nezha"),TZr.forEach(t),fKe=r(E0e," \u2014 "),_R=n(E0e,"A",{href:!0});var MZr=s(_R);mKe=r(MZr,"NezhaConfig"),MZr.forEach(t),gKe=r(E0e," (Nezha model)"),E0e.forEach(t),hKe=i(L),Vm=n(L,"LI",{});var C0e=s(Vm);$ae=n(C0e,"STRONG",{});var EZr=s($ae);pKe=r(EZr,"nystromformer"),EZr.forEach(t),_Ke=r(C0e," \u2014 "),uR=n(C0e,"A",{href:!0});var CZr=s(uR);uKe=r(CZr,"NystromformerConfig"),CZr.forEach(t),bKe=r(C0e," (Nystr\xF6mformer model)"),C0e.forEach(t),vKe=i(L),Xm=n(L,"LI",{});var w0e=s(Xm);kae=n(w0e,"STRONG",{});var wZr=s(kae);FKe=r(wZr,"openai-gpt"),wZr.forEach(t),TKe=r(w0e," \u2014 "),bR=n(w0e,"A",{href:!0});var AZr=s(bR);MKe=r(AZr,"OpenAIGPTConfig"),AZr.forEach(t),EKe=r(w0e," (OpenAI GPT model)"),w0e.forEach(t),CKe=i(L),zm=n(L,"LI",{});var A0e=s(zm);Sae=n(A0e,"STRONG",{});var LZr=s(Sae);wKe=r(LZr,"opt"),LZr.forEach(t),AKe=r(A0e," \u2014 "),vR=n(A0e,"A",{href:!0});var yZr=s(vR);LKe=r(yZr,"OPTConfig"),yZr.forEach(t),yKe=r(A0e," (OPT model)"),A0e.forEach(t),xKe=i(L),Qm=n(L,"LI",{});var L0e=s(Qm);Rae=n(L0e,"STRONG",{});var xZr=s(Rae);$Ke=r(xZr,"pegasus"),xZr.forEach(t),kKe=r(L0e," \u2014 "),FR=n(L0e,"A",{href:!0});var $Zr=s(FR);SKe=r($Zr,"PegasusConfig"),$Zr.forEach(t),RKe=r(L0e," (Pegasus model)"),L0e.forEach(t),PKe=i(L),Wm=n(L,"LI",{});var y0e=s(Wm);Pae=n(y0e,"STRONG",{});var kZr=s(Pae);BKe=r(kZr,"perceiver"),kZr.forEach(t),IKe=r(y0e," \u2014 "),TR=n(y0e,"A",{href:!0});var SZr=s(TR);NKe=r(SZr,"PerceiverConfig"),SZr.forEach(t),qKe=r(y0e," (Perceiver model)"),y0e.forEach(t),jKe=i(L),Hm=n(L,"LI",{});var x0e=s(Hm);Bae=n(x0e,"STRONG",{});var RZr=s(Bae);DKe=r(RZr,"plbart"),RZr.forEach(t),GKe=r(x0e," \u2014 "),MR=n(x0e,"A",{href:!0});var PZr=s(MR);OKe=r(PZr,"PLBartConfig"),PZr.forEach(t),VKe=r(x0e," (PLBart model)"),x0e.forEach(t),XKe=i(L),Um=n(L,"LI",{});var $0e=s(Um);Iae=n($0e,"STRONG",{});var BZr=s(Iae);zKe=r(BZr,"poolformer"),BZr.forEach(t),QKe=r($0e," \u2014 "),ER=n($0e,"A",{href:!0});var IZr=s(ER);WKe=r(IZr,"PoolFormerConfig"),IZr.forEach(t),HKe=r($0e," (PoolFormer model)"),$0e.forEach(t),UKe=i(L),Jm=n(L,"LI",{});var k0e=s(Jm);Nae=n(k0e,"STRONG",{});var NZr=s(Nae);JKe=r(NZr,"prophetnet"),NZr.forEach(t),YKe=r(k0e," \u2014 "),CR=n(k0e,"A",{href:!0});var qZr=s(CR);KKe=r(qZr,"ProphetNetConfig"),qZr.forEach(t),ZKe=r(k0e," (ProphetNet model)"),k0e.forEach(t),eZe=i(L),Ym=n(L,"LI",{});var S0e=s(Ym);qae=n(S0e,"STRONG",{});var jZr=s(qae);oZe=r(jZr,"qdqbert"),jZr.forEach(t),rZe=r(S0e," \u2014 "),wR=n(S0e,"A",{href:!0});var DZr=s(wR);tZe=r(DZr,"QDQBertConfig"),DZr.forEach(t),aZe=r(S0e," (QDQBert model)"),S0e.forEach(t),nZe=i(L),Km=n(L,"LI",{});var R0e=s(Km);jae=n(R0e,"STRONG",{});var GZr=s(jae);sZe=r(GZr,"rag"),GZr.forEach(t),lZe=r(R0e," \u2014 "),AR=n(R0e,"A",{href:!0});var OZr=s(AR);iZe=r(OZr,"RagConfig"),OZr.forEach(t),dZe=r(R0e," (RAG model)"),R0e.forEach(t),cZe=i(L),Zm=n(L,"LI",{});var P0e=s(Zm);Dae=n(P0e,"STRONG",{});var VZr=s(Dae);fZe=r(VZr,"realm"),VZr.forEach(t),mZe=r(P0e," \u2014 "),LR=n(P0e,"A",{href:!0});var XZr=s(LR);gZe=r(XZr,"RealmConfig"),XZr.forEach(t),hZe=r(P0e," (REALM model)"),P0e.forEach(t),pZe=i(L),eg=n(L,"LI",{});var B0e=s(eg);Gae=n(B0e,"STRONG",{});var zZr=s(Gae);_Ze=r(zZr,"reformer"),zZr.forEach(t),uZe=r(B0e," \u2014 "),yR=n(B0e,"A",{href:!0});var QZr=s(yR);bZe=r(QZr,"ReformerConfig"),QZr.forEach(t),vZe=r(B0e," (Reformer model)"),B0e.forEach(t),FZe=i(L),og=n(L,"LI",{});var I0e=s(og);Oae=n(I0e,"STRONG",{});var WZr=s(Oae);TZe=r(WZr,"regnet"),WZr.forEach(t),MZe=r(I0e," \u2014 "),xR=n(I0e,"A",{href:!0});var HZr=s(xR);EZe=r(HZr,"RegNetConfig"),HZr.forEach(t),CZe=r(I0e," (RegNet model)"),I0e.forEach(t),wZe=i(L),rg=n(L,"LI",{});var N0e=s(rg);Vae=n(N0e,"STRONG",{});var UZr=s(Vae);AZe=r(UZr,"rembert"),UZr.forEach(t),LZe=r(N0e," \u2014 "),$R=n(N0e,"A",{href:!0});var JZr=s($R);yZe=r(JZr,"RemBertConfig"),JZr.forEach(t),xZe=r(N0e," (RemBERT model)"),N0e.forEach(t),$Ze=i(L),tg=n(L,"LI",{});var q0e=s(tg);Xae=n(q0e,"STRONG",{});var YZr=s(Xae);kZe=r(YZr,"resnet"),YZr.forEach(t),SZe=r(q0e," \u2014 "),kR=n(q0e,"A",{href:!0});var KZr=s(kR);RZe=r(KZr,"ResNetConfig"),KZr.forEach(t),PZe=r(q0e," (ResNet model)"),q0e.forEach(t),BZe=i(L),ag=n(L,"LI",{});var j0e=s(ag);zae=n(j0e,"STRONG",{});var ZZr=s(zae);IZe=r(ZZr,"retribert"),ZZr.forEach(t),NZe=r(j0e," \u2014 "),SR=n(j0e,"A",{href:!0});var eet=s(SR);qZe=r(eet,"RetriBertConfig"),eet.forEach(t),jZe=r(j0e," (RetriBERT model)"),j0e.forEach(t),DZe=i(L),ng=n(L,"LI",{});var D0e=s(ng);Qae=n(D0e,"STRONG",{});var oet=s(Qae);GZe=r(oet,"roberta"),oet.forEach(t),OZe=r(D0e," \u2014 "),RR=n(D0e,"A",{href:!0});var ret=s(RR);VZe=r(ret,"RobertaConfig"),ret.forEach(t),XZe=r(D0e," (RoBERTa model)"),D0e.forEach(t),zZe=i(L),sg=n(L,"LI",{});var G0e=s(sg);Wae=n(G0e,"STRONG",{});var tet=s(Wae);QZe=r(tet,"roformer"),tet.forEach(t),WZe=r(G0e," \u2014 "),PR=n(G0e,"A",{href:!0});var aet=s(PR);HZe=r(aet,"RoFormerConfig"),aet.forEach(t),UZe=r(G0e," (RoFormer model)"),G0e.forEach(t),JZe=i(L),lg=n(L,"LI",{});var O0e=s(lg);Hae=n(O0e,"STRONG",{});var net=s(Hae);YZe=r(net,"segformer"),net.forEach(t),KZe=r(O0e," \u2014 "),BR=n(O0e,"A",{href:!0});var set=s(BR);ZZe=r(set,"SegformerConfig"),set.forEach(t),eeo=r(O0e," (SegFormer model)"),O0e.forEach(t),oeo=i(L),ig=n(L,"LI",{});var V0e=s(ig);Uae=n(V0e,"STRONG",{});var iet=s(Uae);reo=r(iet,"sew"),iet.forEach(t),teo=r(V0e," \u2014 "),IR=n(V0e,"A",{href:!0});var det=s(IR);aeo=r(det,"SEWConfig"),det.forEach(t),neo=r(V0e," (SEW model)"),V0e.forEach(t),seo=i(L),dg=n(L,"LI",{});var X0e=s(dg);Jae=n(X0e,"STRONG",{});var cet=s(Jae);leo=r(cet,"sew-d"),cet.forEach(t),ieo=r(X0e," \u2014 "),NR=n(X0e,"A",{href:!0});var fet=s(NR);deo=r(fet,"SEWDConfig"),fet.forEach(t),ceo=r(X0e," (SEW-D model)"),X0e.forEach(t),feo=i(L),cg=n(L,"LI",{});var z0e=s(cg);Yae=n(z0e,"STRONG",{});var met=s(Yae);meo=r(met,"speech-encoder-decoder"),met.forEach(t),geo=r(z0e," \u2014 "),qR=n(z0e,"A",{href:!0});var get=s(qR);heo=r(get,"SpeechEncoderDecoderConfig"),get.forEach(t),peo=r(z0e," (Speech Encoder decoder model)"),z0e.forEach(t),_eo=i(L),fg=n(L,"LI",{});var Q0e=s(fg);Kae=n(Q0e,"STRONG",{});var het=s(Kae);ueo=r(het,"speech_to_text"),het.forEach(t),beo=r(Q0e," \u2014 "),jR=n(Q0e,"A",{href:!0});var pet=s(jR);veo=r(pet,"Speech2TextConfig"),pet.forEach(t),Feo=r(Q0e," (Speech2Text model)"),Q0e.forEach(t),Teo=i(L),mg=n(L,"LI",{});var W0e=s(mg);Zae=n(W0e,"STRONG",{});var _et=s(Zae);Meo=r(_et,"speech_to_text_2"),_et.forEach(t),Eeo=r(W0e," \u2014 "),DR=n(W0e,"A",{href:!0});var uet=s(DR);Ceo=r(uet,"Speech2Text2Config"),uet.forEach(t),weo=r(W0e," (Speech2Text2 model)"),W0e.forEach(t),Aeo=i(L),gg=n(L,"LI",{});var H0e=s(gg);ene=n(H0e,"STRONG",{});var bet=s(ene);Leo=r(bet,"splinter"),bet.forEach(t),yeo=r(H0e," \u2014 "),GR=n(H0e,"A",{href:!0});var vet=s(GR);xeo=r(vet,"SplinterConfig"),vet.forEach(t),$eo=r(H0e," (Splinter model)"),H0e.forEach(t),keo=i(L),hg=n(L,"LI",{});var U0e=s(hg);one=n(U0e,"STRONG",{});var Fet=s(one);Seo=r(Fet,"squeezebert"),Fet.forEach(t),Reo=r(U0e," \u2014 "),OR=n(U0e,"A",{href:!0});var Tet=s(OR);Peo=r(Tet,"SqueezeBertConfig"),Tet.forEach(t),Beo=r(U0e," (SqueezeBERT model)"),U0e.forEach(t),Ieo=i(L),pg=n(L,"LI",{});var J0e=s(pg);rne=n(J0e,"STRONG",{});var Met=s(rne);Neo=r(Met,"swin"),Met.forEach(t),qeo=r(J0e," \u2014 "),VR=n(J0e,"A",{href:!0});var Eet=s(VR);jeo=r(Eet,"SwinConfig"),Eet.forEach(t),Deo=r(J0e," (Swin Transformer model)"),J0e.forEach(t),Geo=i(L),_g=n(L,"LI",{});var Y0e=s(_g);tne=n(Y0e,"STRONG",{});var Cet=s(tne);Oeo=r(Cet,"t5"),Cet.forEach(t),Veo=r(Y0e," \u2014 "),XR=n(Y0e,"A",{href:!0});var wet=s(XR);Xeo=r(wet,"T5Config"),wet.forEach(t),zeo=r(Y0e," (T5 model)"),Y0e.forEach(t),Qeo=i(L),ug=n(L,"LI",{});var K0e=s(ug);ane=n(K0e,"STRONG",{});var Aet=s(ane);Weo=r(Aet,"tapas"),Aet.forEach(t),Heo=r(K0e," \u2014 "),zR=n(K0e,"A",{href:!0});var Let=s(zR);Ueo=r(Let,"TapasConfig"),Let.forEach(t),Jeo=r(K0e," (TAPAS model)"),K0e.forEach(t),Yeo=i(L),bg=n(L,"LI",{});var Z0e=s(bg);nne=n(Z0e,"STRONG",{});var yet=s(nne);Keo=r(yet,"trajectory_transformer"),yet.forEach(t),Zeo=r(Z0e," \u2014 "),QR=n(Z0e,"A",{href:!0});var xet=s(QR);eoo=r(xet,"TrajectoryTransformerConfig"),xet.forEach(t),ooo=r(Z0e," (Trajectory Transformer model)"),Z0e.forEach(t),roo=i(L),vg=n(L,"LI",{});var ewe=s(vg);sne=n(ewe,"STRONG",{});var $et=s(sne);too=r($et,"transfo-xl"),$et.forEach(t),aoo=r(ewe," \u2014 "),WR=n(ewe,"A",{href:!0});var ket=s(WR);noo=r(ket,"TransfoXLConfig"),ket.forEach(t),soo=r(ewe," (Transformer-XL model)"),ewe.forEach(t),loo=i(L),Fg=n(L,"LI",{});var owe=s(Fg);lne=n(owe,"STRONG",{});var Set=s(lne);ioo=r(Set,"trocr"),Set.forEach(t),doo=r(owe," \u2014 "),HR=n(owe,"A",{href:!0});var Ret=s(HR);coo=r(Ret,"TrOCRConfig"),Ret.forEach(t),foo=r(owe," (TrOCR model)"),owe.forEach(t),moo=i(L),Tg=n(L,"LI",{});var rwe=s(Tg);ine=n(rwe,"STRONG",{});var Pet=s(ine);goo=r(Pet,"unispeech"),Pet.forEach(t),hoo=r(rwe," \u2014 "),UR=n(rwe,"A",{href:!0});var Bet=s(UR);poo=r(Bet,"UniSpeechConfig"),Bet.forEach(t),_oo=r(rwe," (UniSpeech model)"),rwe.forEach(t),uoo=i(L),Mg=n(L,"LI",{});var twe=s(Mg);dne=n(twe,"STRONG",{});var Iet=s(dne);boo=r(Iet,"unispeech-sat"),Iet.forEach(t),voo=r(twe," \u2014 "),JR=n(twe,"A",{href:!0});var Net=s(JR);Foo=r(Net,"UniSpeechSatConfig"),Net.forEach(t),Too=r(twe," (UniSpeechSat model)"),twe.forEach(t),Moo=i(L),Eg=n(L,"LI",{});var awe=s(Eg);cne=n(awe,"STRONG",{});var qet=s(cne);Eoo=r(qet,"van"),qet.forEach(t),Coo=r(awe," \u2014 "),YR=n(awe,"A",{href:!0});var jet=s(YR);woo=r(jet,"VanConfig"),jet.forEach(t),Aoo=r(awe," (VAN model)"),awe.forEach(t),Loo=i(L),Cg=n(L,"LI",{});var nwe=s(Cg);fne=n(nwe,"STRONG",{});var Det=s(fne);yoo=r(Det,"vilt"),Det.forEach(t),xoo=r(nwe," \u2014 "),KR=n(nwe,"A",{href:!0});var Get=s(KR);$oo=r(Get,"ViltConfig"),Get.forEach(t),koo=r(nwe," (ViLT model)"),nwe.forEach(t),Soo=i(L),wg=n(L,"LI",{});var swe=s(wg);mne=n(swe,"STRONG",{});var Oet=s(mne);Roo=r(Oet,"vision-encoder-decoder"),Oet.forEach(t),Poo=r(swe," \u2014 "),ZR=n(swe,"A",{href:!0});var Vet=s(ZR);Boo=r(Vet,"VisionEncoderDecoderConfig"),Vet.forEach(t),Ioo=r(swe," (Vision Encoder decoder model)"),swe.forEach(t),Noo=i(L),Ag=n(L,"LI",{});var lwe=s(Ag);gne=n(lwe,"STRONG",{});var Xet=s(gne);qoo=r(Xet,"vision-text-dual-encoder"),Xet.forEach(t),joo=r(lwe," \u2014 "),eP=n(lwe,"A",{href:!0});var zet=s(eP);Doo=r(zet,"VisionTextDualEncoderConfig"),zet.forEach(t),Goo=r(lwe," (VisionTextDualEncoder model)"),lwe.forEach(t),Ooo=i(L),Lg=n(L,"LI",{});var iwe=s(Lg);hne=n(iwe,"STRONG",{});var Qet=s(hne);Voo=r(Qet,"visual_bert"),Qet.forEach(t),Xoo=r(iwe," \u2014 "),oP=n(iwe,"A",{href:!0});var Wet=s(oP);zoo=r(Wet,"VisualBertConfig"),Wet.forEach(t),Qoo=r(iwe," (VisualBERT model)"),iwe.forEach(t),Woo=i(L),yg=n(L,"LI",{});var dwe=s(yg);pne=n(dwe,"STRONG",{});var Het=s(pne);Hoo=r(Het,"vit"),Het.forEach(t),Uoo=r(dwe," \u2014 "),rP=n(dwe,"A",{href:!0});var Uet=s(rP);Joo=r(Uet,"ViTConfig"),Uet.forEach(t),Yoo=r(dwe," (ViT model)"),dwe.forEach(t),Koo=i(L),xg=n(L,"LI",{});var cwe=s(xg);_ne=n(cwe,"STRONG",{});var Jet=s(_ne);Zoo=r(Jet,"vit_mae"),Jet.forEach(t),ero=r(cwe," \u2014 "),tP=n(cwe,"A",{href:!0});var Yet=s(tP);oro=r(Yet,"ViTMAEConfig"),Yet.forEach(t),rro=r(cwe," (ViTMAE model)"),cwe.forEach(t),tro=i(L),$g=n(L,"LI",{});var fwe=s($g);une=n(fwe,"STRONG",{});var Ket=s(une);aro=r(Ket,"wav2vec2"),Ket.forEach(t),nro=r(fwe," \u2014 "),aP=n(fwe,"A",{href:!0});var Zet=s(aP);sro=r(Zet,"Wav2Vec2Config"),Zet.forEach(t),lro=r(fwe," (Wav2Vec2 model)"),fwe.forEach(t),iro=i(L),kg=n(L,"LI",{});var mwe=s(kg);bne=n(mwe,"STRONG",{});var eot=s(bne);dro=r(eot,"wav2vec2-conformer"),eot.forEach(t),cro=r(mwe," \u2014 "),nP=n(mwe,"A",{href:!0});var oot=s(nP);fro=r(oot,"Wav2Vec2ConformerConfig"),oot.forEach(t),mro=r(mwe," (Wav2Vec2-Conformer model)"),mwe.forEach(t),gro=i(L),Sg=n(L,"LI",{});var gwe=s(Sg);vne=n(gwe,"STRONG",{});var rot=s(vne);hro=r(rot,"wavlm"),rot.forEach(t),pro=r(gwe," \u2014 "),sP=n(gwe,"A",{href:!0});var tot=s(sP);_ro=r(tot,"WavLMConfig"),tot.forEach(t),uro=r(gwe," (WavLM model)"),gwe.forEach(t),bro=i(L),Rg=n(L,"LI",{});var hwe=s(Rg);Fne=n(hwe,"STRONG",{});var aot=s(Fne);vro=r(aot,"xglm"),aot.forEach(t),Fro=r(hwe," \u2014 "),lP=n(hwe,"A",{href:!0});var not=s(lP);Tro=r(not,"XGLMConfig"),not.forEach(t),Mro=r(hwe," (XGLM model)"),hwe.forEach(t),Ero=i(L),Pg=n(L,"LI",{});var pwe=s(Pg);Tne=n(pwe,"STRONG",{});var sot=s(Tne);Cro=r(sot,"xlm"),sot.forEach(t),wro=r(pwe," \u2014 "),iP=n(pwe,"A",{href:!0});var lot=s(iP);Aro=r(lot,"XLMConfig"),lot.forEach(t),Lro=r(pwe," (XLM model)"),pwe.forEach(t),yro=i(L),Bg=n(L,"LI",{});var _we=s(Bg);Mne=n(_we,"STRONG",{});var iot=s(Mne);xro=r(iot,"xlm-prophetnet"),iot.forEach(t),$ro=r(_we," \u2014 "),dP=n(_we,"A",{href:!0});var dot=s(dP);kro=r(dot,"XLMProphetNetConfig"),dot.forEach(t),Sro=r(_we," (XLM-ProphetNet model)"),_we.forEach(t),Rro=i(L),Ig=n(L,"LI",{});var uwe=s(Ig);Ene=n(uwe,"STRONG",{});var cot=s(Ene);Pro=r(cot,"xlm-roberta"),cot.forEach(t),Bro=r(uwe," \u2014 "),cP=n(uwe,"A",{href:!0});var fot=s(cP);Iro=r(fot,"XLMRobertaConfig"),fot.forEach(t),Nro=r(uwe," (XLM-RoBERTa model)"),uwe.forEach(t),qro=i(L),Ng=n(L,"LI",{});var bwe=s(Ng);Cne=n(bwe,"STRONG",{});var mot=s(Cne);jro=r(mot,"xlm-roberta-xl"),mot.forEach(t),Dro=r(bwe," \u2014 "),fP=n(bwe,"A",{href:!0});var got=s(fP);Gro=r(got,"XLMRobertaXLConfig"),got.forEach(t),Oro=r(bwe," (XLM-RoBERTa-XL model)"),bwe.forEach(t),Vro=i(L),qg=n(L,"LI",{});var vwe=s(qg);wne=n(vwe,"STRONG",{});var hot=s(wne);Xro=r(hot,"xlnet"),hot.forEach(t),zro=r(vwe," \u2014 "),mP=n(vwe,"A",{href:!0});var pot=s(mP);Qro=r(pot,"XLNetConfig"),pot.forEach(t),Wro=r(vwe," (XLNet model)"),vwe.forEach(t),Hro=i(L),jg=n(L,"LI",{});var Fwe=s(jg);Ane=n(Fwe,"STRONG",{});var _ot=s(Ane);Uro=r(_ot,"yolos"),_ot.forEach(t),Jro=r(Fwe," \u2014 "),gP=n(Fwe,"A",{href:!0});var uot=s(gP);Yro=r(uot,"YolosConfig"),uot.forEach(t),Kro=r(Fwe," (YOLOS model)"),Fwe.forEach(t),Zro=i(L),Dg=n(L,"LI",{});var Twe=s(Dg);Lne=n(Twe,"STRONG",{});var bot=s(Lne);eto=r(bot,"yoso"),bot.forEach(t),oto=r(Twe," \u2014 "),hP=n(Twe,"A",{href:!0});var vot=s(hP);rto=r(vot,"YosoConfig"),vot.forEach(t),tto=r(Twe," (YOSO model)"),Twe.forEach(t),L.forEach(t),ato=i(tt),T(Gg.$$.fragment,tt),tt.forEach(t),nto=i(rt),Og=n(rt,"DIV",{class:!0});var zVe=s(Og);T(Iw.$$.fragment,zVe),sto=i(zVe),yne=n(zVe,"P",{});var Fot=s(yne);lto=r(Fot,"Register a new configuration for this class."),Fot.forEach(t),zVe.forEach(t),rt.forEach(t),QGe=i(f),ki=n(f,"H2",{class:!0});var QVe=s(ki);Vg=n(QVe,"A",{id:!0,class:!0,href:!0});var Tot=s(Vg);xne=n(Tot,"SPAN",{});var Mot=s(xne);T(Nw.$$.fragment,Mot),Mot.forEach(t),Tot.forEach(t),ito=i(QVe),$ne=n(QVe,"SPAN",{});var Eot=s($ne);dto=r(Eot,"AutoTokenizer"),Eot.forEach(t),QVe.forEach(t),WGe=i(f),Ao=n(f,"DIV",{class:!0});var Ws=s(Ao);T(qw.$$.fragment,Ws),cto=i(Ws),jw=n(Ws,"P",{});var WVe=s(jw);fto=r(WVe,`This is a generic tokenizer class that will be instantiated as one of the tokenizer classes of the library when
created with the `),pP=n(WVe,"A",{href:!0});var Cot=s(pP);mto=r(Cot,"AutoTokenizer.from_pretrained()"),Cot.forEach(t),gto=r(WVe," class method."),WVe.forEach(t),hto=i(Ws),Dw=n(Ws,"P",{});var HVe=s(Dw);pto=r(HVe,"This class cannot be instantiated directly using "),kne=n(HVe,"CODE",{});var wot=s(kne);_to=r(wot,"__init__()"),wot.forEach(t),uto=r(HVe," (throws an error)."),HVe.forEach(t),bto=i(Ws),Lr=n(Ws,"DIV",{class:!0});var Hs=s(Lr);T(Gw.$$.fragment,Hs),vto=i(Hs),Sne=n(Hs,"P",{});var Aot=s(Sne);Fto=r(Aot,"Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary."),Aot.forEach(t),Tto=i(Hs),ka=n(Hs,"P",{});var x3=s(ka);Mto=r(x3,"The tokenizer class to instantiate is selected based on the "),Rne=n(x3,"CODE",{});var Lot=s(Rne);Eto=r(Lot,"model_type"),Lot.forEach(t),Cto=r(x3,` property of the config object (either
passed as an argument or loaded from `),Pne=n(x3,"CODE",{});var yot=s(Pne);wto=r(yot,"pretrained_model_name_or_path"),yot.forEach(t),Ato=r(x3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Bne=n(x3,"CODE",{});var xot=s(Bne);Lto=r(xot,"pretrained_model_name_or_path"),xot.forEach(t),yto=r(x3,":"),x3.forEach(t),xto=i(Hs),k=n(Hs,"UL",{});var S=s(k);qn=n(S,"LI",{});var W$=s(qn);Ine=n(W$,"STRONG",{});var $ot=s(Ine);$to=r($ot,"albert"),$ot.forEach(t),kto=r(W$," \u2014 "),_P=n(W$,"A",{href:!0});var kot=s(_P);Sto=r(kot,"AlbertTokenizer"),kot.forEach(t),Rto=r(W$," or "),uP=n(W$,"A",{href:!0});var Sot=s(uP);Pto=r(Sot,"AlbertTokenizerFast"),Sot.forEach(t),Bto=r(W$," (ALBERT model)"),W$.forEach(t),Ito=i(S),jn=n(S,"LI",{});var H$=s(jn);Nne=n(H$,"STRONG",{});var Rot=s(Nne);Nto=r(Rot,"bart"),Rot.forEach(t),qto=r(H$," \u2014 "),bP=n(H$,"A",{href:!0});var Pot=s(bP);jto=r(Pot,"BartTokenizer"),Pot.forEach(t),Dto=r(H$," or "),vP=n(H$,"A",{href:!0});var Bot=s(vP);Gto=r(Bot,"BartTokenizerFast"),Bot.forEach(t),Oto=r(H$," (BART model)"),H$.forEach(t),Vto=i(S),Dn=n(S,"LI",{});var U$=s(Dn);qne=n(U$,"STRONG",{});var Iot=s(qne);Xto=r(Iot,"barthez"),Iot.forEach(t),zto=r(U$," \u2014 "),FP=n(U$,"A",{href:!0});var Not=s(FP);Qto=r(Not,"BarthezTokenizer"),Not.forEach(t),Wto=r(U$," or "),TP=n(U$,"A",{href:!0});var qot=s(TP);Hto=r(qot,"BarthezTokenizerFast"),qot.forEach(t),Uto=r(U$," (BARThez model)"),U$.forEach(t),Jto=i(S),Xg=n(S,"LI",{});var Mwe=s(Xg);jne=n(Mwe,"STRONG",{});var jot=s(jne);Yto=r(jot,"bartpho"),jot.forEach(t),Kto=r(Mwe," \u2014 "),MP=n(Mwe,"A",{href:!0});var Dot=s(MP);Zto=r(Dot,"BartphoTokenizer"),Dot.forEach(t),eao=r(Mwe," (BARTpho model)"),Mwe.forEach(t),oao=i(S),Gn=n(S,"LI",{});var J$=s(Gn);Dne=n(J$,"STRONG",{});var Got=s(Dne);rao=r(Got,"bert"),Got.forEach(t),tao=r(J$," \u2014 "),EP=n(J$,"A",{href:!0});var Oot=s(EP);aao=r(Oot,"BertTokenizer"),Oot.forEach(t),nao=r(J$," or "),CP=n(J$,"A",{href:!0});var Vot=s(CP);sao=r(Vot,"BertTokenizerFast"),Vot.forEach(t),lao=r(J$," (BERT model)"),J$.forEach(t),iao=i(S),zg=n(S,"LI",{});var Ewe=s(zg);Gne=n(Ewe,"STRONG",{});var Xot=s(Gne);dao=r(Xot,"bert-generation"),Xot.forEach(t),cao=r(Ewe," \u2014 "),wP=n(Ewe,"A",{href:!0});var zot=s(wP);fao=r(zot,"BertGenerationTokenizer"),zot.forEach(t),mao=r(Ewe," (Bert Generation model)"),Ewe.forEach(t),gao=i(S),Qg=n(S,"LI",{});var Cwe=s(Qg);One=n(Cwe,"STRONG",{});var Qot=s(One);hao=r(Qot,"bert-japanese"),Qot.forEach(t),pao=r(Cwe," \u2014 "),AP=n(Cwe,"A",{href:!0});var Wot=s(AP);_ao=r(Wot,"BertJapaneseTokenizer"),Wot.forEach(t),uao=r(Cwe," (BertJapanese model)"),Cwe.forEach(t),bao=i(S),Wg=n(S,"LI",{});var wwe=s(Wg);Vne=n(wwe,"STRONG",{});var Hot=s(Vne);vao=r(Hot,"bertweet"),Hot.forEach(t),Fao=r(wwe," \u2014 "),LP=n(wwe,"A",{href:!0});var Uot=s(LP);Tao=r(Uot,"BertweetTokenizer"),Uot.forEach(t),Mao=r(wwe," (BERTweet model)"),wwe.forEach(t),Eao=i(S),On=n(S,"LI",{});var Y$=s(On);Xne=n(Y$,"STRONG",{});var Jot=s(Xne);Cao=r(Jot,"big_bird"),Jot.forEach(t),wao=r(Y$," \u2014 "),yP=n(Y$,"A",{href:!0});var Yot=s(yP);Aao=r(Yot,"BigBirdTokenizer"),Yot.forEach(t),Lao=r(Y$," or "),xP=n(Y$,"A",{href:!0});var Kot=s(xP);yao=r(Kot,"BigBirdTokenizerFast"),Kot.forEach(t),xao=r(Y$," (BigBird model)"),Y$.forEach(t),$ao=i(S),Vn=n(S,"LI",{});var K$=s(Vn);zne=n(K$,"STRONG",{});var Zot=s(zne);kao=r(Zot,"bigbird_pegasus"),Zot.forEach(t),Sao=r(K$," \u2014 "),$P=n(K$,"A",{href:!0});var ert=s($P);Rao=r(ert,"PegasusTokenizer"),ert.forEach(t),Pao=r(K$," or "),kP=n(K$,"A",{href:!0});var ort=s(kP);Bao=r(ort,"PegasusTokenizerFast"),ort.forEach(t),Iao=r(K$," (BigBird-Pegasus model)"),K$.forEach(t),Nao=i(S),Xn=n(S,"LI",{});var Z$=s(Xn);Qne=n(Z$,"STRONG",{});var rrt=s(Qne);qao=r(rrt,"blenderbot"),rrt.forEach(t),jao=r(Z$," \u2014 "),SP=n(Z$,"A",{href:!0});var trt=s(SP);Dao=r(trt,"BlenderbotTokenizer"),trt.forEach(t),Gao=r(Z$," or "),RP=n(Z$,"A",{href:!0});var art=s(RP);Oao=r(art,"BlenderbotTokenizerFast"),art.forEach(t),Vao=r(Z$," (Blenderbot model)"),Z$.forEach(t),Xao=i(S),Hg=n(S,"LI",{});var Awe=s(Hg);Wne=n(Awe,"STRONG",{});var nrt=s(Wne);zao=r(nrt,"blenderbot-small"),nrt.forEach(t),Qao=r(Awe," \u2014 "),PP=n(Awe,"A",{href:!0});var srt=s(PP);Wao=r(srt,"BlenderbotSmallTokenizer"),srt.forEach(t),Hao=r(Awe," (BlenderbotSmall model)"),Awe.forEach(t),Uao=i(S),Ug=n(S,"LI",{});var Lwe=s(Ug);Hne=n(Lwe,"STRONG",{});var lrt=s(Hne);Jao=r(lrt,"bloom"),lrt.forEach(t),Yao=r(Lwe," \u2014 "),BP=n(Lwe,"A",{href:!0});var irt=s(BP);Kao=r(irt,"BloomTokenizerFast"),irt.forEach(t),Zao=r(Lwe," (BLOOM model)"),Lwe.forEach(t),eno=i(S),Jg=n(S,"LI",{});var ywe=s(Jg);Une=n(ywe,"STRONG",{});var drt=s(Une);ono=r(drt,"byt5"),drt.forEach(t),rno=r(ywe," \u2014 "),IP=n(ywe,"A",{href:!0});var crt=s(IP);tno=r(crt,"ByT5Tokenizer"),crt.forEach(t),ano=r(ywe," (ByT5 model)"),ywe.forEach(t),nno=i(S),zn=n(S,"LI",{});var ek=s(zn);Jne=n(ek,"STRONG",{});var frt=s(Jne);sno=r(frt,"camembert"),frt.forEach(t),lno=r(ek," \u2014 "),NP=n(ek,"A",{href:!0});var mrt=s(NP);ino=r(mrt,"CamembertTokenizer"),mrt.forEach(t),dno=r(ek," or "),qP=n(ek,"A",{href:!0});var grt=s(qP);cno=r(grt,"CamembertTokenizerFast"),grt.forEach(t),fno=r(ek," (CamemBERT model)"),ek.forEach(t),mno=i(S),Yg=n(S,"LI",{});var xwe=s(Yg);Yne=n(xwe,"STRONG",{});var hrt=s(Yne);gno=r(hrt,"canine"),hrt.forEach(t),hno=r(xwe," \u2014 "),jP=n(xwe,"A",{href:!0});var prt=s(jP);pno=r(prt,"CanineTokenizer"),prt.forEach(t),_no=r(xwe," (CANINE model)"),xwe.forEach(t),uno=i(S),Qn=n(S,"LI",{});var ok=s(Qn);Kne=n(ok,"STRONG",{});var _rt=s(Kne);bno=r(_rt,"clip"),_rt.forEach(t),vno=r(ok," \u2014 "),DP=n(ok,"A",{href:!0});var urt=s(DP);Fno=r(urt,"CLIPTokenizer"),urt.forEach(t),Tno=r(ok," or "),GP=n(ok,"A",{href:!0});var brt=s(GP);Mno=r(brt,"CLIPTokenizerFast"),brt.forEach(t),Eno=r(ok," (CLIP model)"),ok.forEach(t),Cno=i(S),Wn=n(S,"LI",{});var rk=s(Wn);Zne=n(rk,"STRONG",{});var vrt=s(Zne);wno=r(vrt,"convbert"),vrt.forEach(t),Ano=r(rk," \u2014 "),OP=n(rk,"A",{href:!0});var Frt=s(OP);Lno=r(Frt,"ConvBertTokenizer"),Frt.forEach(t),yno=r(rk," or "),VP=n(rk,"A",{href:!0});var Trt=s(VP);xno=r(Trt,"ConvBertTokenizerFast"),Trt.forEach(t),$no=r(rk," (ConvBERT model)"),rk.forEach(t),kno=i(S),Hn=n(S,"LI",{});var tk=s(Hn);ese=n(tk,"STRONG",{});var Mrt=s(ese);Sno=r(Mrt,"cpm"),Mrt.forEach(t),Rno=r(tk," \u2014 "),XP=n(tk,"A",{href:!0});var Ert=s(XP);Pno=r(Ert,"CpmTokenizer"),Ert.forEach(t),Bno=r(tk," or "),zP=n(tk,"A",{href:!0});var Crt=s(zP);Ino=r(Crt,"CpmTokenizerFast"),Crt.forEach(t),Nno=r(tk," (CPM model)"),tk.forEach(t),qno=i(S),Kg=n(S,"LI",{});var $we=s(Kg);ose=n($we,"STRONG",{});var wrt=s(ose);jno=r(wrt,"ctrl"),wrt.forEach(t),Dno=r($we," \u2014 "),QP=n($we,"A",{href:!0});var Art=s(QP);Gno=r(Art,"CTRLTokenizer"),Art.forEach(t),Ono=r($we," (CTRL model)"),$we.forEach(t),Vno=i(S),Un=n(S,"LI",{});var ak=s(Un);rse=n(ak,"STRONG",{});var Lrt=s(rse);Xno=r(Lrt,"data2vec-text"),Lrt.forEach(t),zno=r(ak," \u2014 "),WP=n(ak,"A",{href:!0});var yrt=s(WP);Qno=r(yrt,"RobertaTokenizer"),yrt.forEach(t),Wno=r(ak," or "),HP=n(ak,"A",{href:!0});var xrt=s(HP);Hno=r(xrt,"RobertaTokenizerFast"),xrt.forEach(t),Uno=r(ak," (Data2VecText model)"),ak.forEach(t),Jno=i(S),Jn=n(S,"LI",{});var nk=s(Jn);tse=n(nk,"STRONG",{});var $rt=s(tse);Yno=r($rt,"deberta"),$rt.forEach(t),Kno=r(nk," \u2014 "),UP=n(nk,"A",{href:!0});var krt=s(UP);Zno=r(krt,"DebertaTokenizer"),krt.forEach(t),eso=r(nk," or "),JP=n(nk,"A",{href:!0});var Srt=s(JP);oso=r(Srt,"DebertaTokenizerFast"),Srt.forEach(t),rso=r(nk," (DeBERTa model)"),nk.forEach(t),tso=i(S),Yn=n(S,"LI",{});var sk=s(Yn);ase=n(sk,"STRONG",{});var Rrt=s(ase);aso=r(Rrt,"deberta-v2"),Rrt.forEach(t),nso=r(sk," \u2014 "),YP=n(sk,"A",{href:!0});var Prt=s(YP);sso=r(Prt,"DebertaV2Tokenizer"),Prt.forEach(t),lso=r(sk," or "),KP=n(sk,"A",{href:!0});var Brt=s(KP);iso=r(Brt,"DebertaV2TokenizerFast"),Brt.forEach(t),dso=r(sk," (DeBERTa-v2 model)"),sk.forEach(t),cso=i(S),Kn=n(S,"LI",{});var lk=s(Kn);nse=n(lk,"STRONG",{});var Irt=s(nse);fso=r(Irt,"distilbert"),Irt.forEach(t),mso=r(lk," \u2014 "),ZP=n(lk,"A",{href:!0});var Nrt=s(ZP);gso=r(Nrt,"DistilBertTokenizer"),Nrt.forEach(t),hso=r(lk," or "),eB=n(lk,"A",{href:!0});var qrt=s(eB);pso=r(qrt,"DistilBertTokenizerFast"),qrt.forEach(t),_so=r(lk," (DistilBERT model)"),lk.forEach(t),uso=i(S),Zn=n(S,"LI",{});var ik=s(Zn);sse=n(ik,"STRONG",{});var jrt=s(sse);bso=r(jrt,"dpr"),jrt.forEach(t),vso=r(ik," \u2014 "),oB=n(ik,"A",{href:!0});var Drt=s(oB);Fso=r(Drt,"DPRQuestionEncoderTokenizer"),Drt.forEach(t),Tso=r(ik," or "),rB=n(ik,"A",{href:!0});var Grt=s(rB);Mso=r(Grt,"DPRQuestionEncoderTokenizerFast"),Grt.forEach(t),Eso=r(ik," (DPR model)"),ik.forEach(t),Cso=i(S),es=n(S,"LI",{});var dk=s(es);lse=n(dk,"STRONG",{});var Ort=s(lse);wso=r(Ort,"electra"),Ort.forEach(t),Aso=r(dk," \u2014 "),tB=n(dk,"A",{href:!0});var Vrt=s(tB);Lso=r(Vrt,"ElectraTokenizer"),Vrt.forEach(t),yso=r(dk," or "),aB=n(dk,"A",{href:!0});var Xrt=s(aB);xso=r(Xrt,"ElectraTokenizerFast"),Xrt.forEach(t),$so=r(dk," (ELECTRA model)"),dk.forEach(t),kso=i(S),Zg=n(S,"LI",{});var kwe=s(Zg);ise=n(kwe,"STRONG",{});var zrt=s(ise);Sso=r(zrt,"flaubert"),zrt.forEach(t),Rso=r(kwe," \u2014 "),nB=n(kwe,"A",{href:!0});var Qrt=s(nB);Pso=r(Qrt,"FlaubertTokenizer"),Qrt.forEach(t),Bso=r(kwe," (FlauBERT model)"),kwe.forEach(t),Iso=i(S),os=n(S,"LI",{});var ck=s(os);dse=n(ck,"STRONG",{});var Wrt=s(dse);Nso=r(Wrt,"fnet"),Wrt.forEach(t),qso=r(ck," \u2014 "),sB=n(ck,"A",{href:!0});var Hrt=s(sB);jso=r(Hrt,"FNetTokenizer"),Hrt.forEach(t),Dso=r(ck," or "),lB=n(ck,"A",{href:!0});var Urt=s(lB);Gso=r(Urt,"FNetTokenizerFast"),Urt.forEach(t),Oso=r(ck," (FNet model)"),ck.forEach(t),Vso=i(S),eh=n(S,"LI",{});var Swe=s(eh);cse=n(Swe,"STRONG",{});var Jrt=s(cse);Xso=r(Jrt,"fsmt"),Jrt.forEach(t),zso=r(Swe," \u2014 "),iB=n(Swe,"A",{href:!0});var Yrt=s(iB);Qso=r(Yrt,"FSMTTokenizer"),Yrt.forEach(t),Wso=r(Swe," (FairSeq Machine-Translation model)"),Swe.forEach(t),Hso=i(S),rs=n(S,"LI",{});var fk=s(rs);fse=n(fk,"STRONG",{});var Krt=s(fse);Uso=r(Krt,"funnel"),Krt.forEach(t),Jso=r(fk," \u2014 "),dB=n(fk,"A",{href:!0});var Zrt=s(dB);Yso=r(Zrt,"FunnelTokenizer"),Zrt.forEach(t),Kso=r(fk," or "),cB=n(fk,"A",{href:!0});var ett=s(cB);Zso=r(ett,"FunnelTokenizerFast"),ett.forEach(t),elo=r(fk," (Funnel Transformer model)"),fk.forEach(t),olo=i(S),ts=n(S,"LI",{});var mk=s(ts);mse=n(mk,"STRONG",{});var ott=s(mse);rlo=r(ott,"gpt2"),ott.forEach(t),tlo=r(mk," \u2014 "),fB=n(mk,"A",{href:!0});var rtt=s(fB);alo=r(rtt,"GPT2Tokenizer"),rtt.forEach(t),nlo=r(mk," or "),mB=n(mk,"A",{href:!0});var ttt=s(mB);slo=r(ttt,"GPT2TokenizerFast"),ttt.forEach(t),llo=r(mk," (OpenAI GPT-2 model)"),mk.forEach(t),ilo=i(S),as=n(S,"LI",{});var gk=s(as);gse=n(gk,"STRONG",{});var att=s(gse);dlo=r(att,"gpt_neo"),att.forEach(t),clo=r(gk," \u2014 "),gB=n(gk,"A",{href:!0});var ntt=s(gB);flo=r(ntt,"GPT2Tokenizer"),ntt.forEach(t),mlo=r(gk," or "),hB=n(gk,"A",{href:!0});var stt=s(hB);glo=r(stt,"GPT2TokenizerFast"),stt.forEach(t),hlo=r(gk," (GPT Neo model)"),gk.forEach(t),plo=i(S),oh=n(S,"LI",{});var Rwe=s(oh);hse=n(Rwe,"STRONG",{});var ltt=s(hse);_lo=r(ltt,"gpt_neox"),ltt.forEach(t),ulo=r(Rwe," \u2014 "),pB=n(Rwe,"A",{href:!0});var itt=s(pB);blo=r(itt,"GPTNeoXTokenizerFast"),itt.forEach(t),vlo=r(Rwe," (GPT NeoX model)"),Rwe.forEach(t),Flo=i(S),ns=n(S,"LI",{});var hk=s(ns);pse=n(hk,"STRONG",{});var dtt=s(pse);Tlo=r(dtt,"gptj"),dtt.forEach(t),Mlo=r(hk," \u2014 "),_B=n(hk,"A",{href:!0});var ctt=s(_B);Elo=r(ctt,"GPT2Tokenizer"),ctt.forEach(t),Clo=r(hk," or "),uB=n(hk,"A",{href:!0});var ftt=s(uB);wlo=r(ftt,"GPT2TokenizerFast"),ftt.forEach(t),Alo=r(hk," (GPT-J model)"),hk.forEach(t),Llo=i(S),ss=n(S,"LI",{});var pk=s(ss);_se=n(pk,"STRONG",{});var mtt=s(_se);ylo=r(mtt,"herbert"),mtt.forEach(t),xlo=r(pk," \u2014 "),bB=n(pk,"A",{href:!0});var gtt=s(bB);$lo=r(gtt,"HerbertTokenizer"),gtt.forEach(t),klo=r(pk," or "),vB=n(pk,"A",{href:!0});var htt=s(vB);Slo=r(htt,"HerbertTokenizerFast"),htt.forEach(t),Rlo=r(pk," (HerBERT model)"),pk.forEach(t),Plo=i(S),rh=n(S,"LI",{});var Pwe=s(rh);use=n(Pwe,"STRONG",{});var ptt=s(use);Blo=r(ptt,"hubert"),ptt.forEach(t),Ilo=r(Pwe," \u2014 "),FB=n(Pwe,"A",{href:!0});var _tt=s(FB);Nlo=r(_tt,"Wav2Vec2CTCTokenizer"),_tt.forEach(t),qlo=r(Pwe," (Hubert model)"),Pwe.forEach(t),jlo=i(S),ls=n(S,"LI",{});var _k=s(ls);bse=n(_k,"STRONG",{});var utt=s(bse);Dlo=r(utt,"ibert"),utt.forEach(t),Glo=r(_k," \u2014 "),TB=n(_k,"A",{href:!0});var btt=s(TB);Olo=r(btt,"RobertaTokenizer"),btt.forEach(t),Vlo=r(_k," or "),MB=n(_k,"A",{href:!0});var vtt=s(MB);Xlo=r(vtt,"RobertaTokenizerFast"),vtt.forEach(t),zlo=r(_k," (I-BERT model)"),_k.forEach(t),Qlo=i(S),is=n(S,"LI",{});var uk=s(is);vse=n(uk,"STRONG",{});var Ftt=s(vse);Wlo=r(Ftt,"layoutlm"),Ftt.forEach(t),Hlo=r(uk," \u2014 "),EB=n(uk,"A",{href:!0});var Ttt=s(EB);Ulo=r(Ttt,"LayoutLMTokenizer"),Ttt.forEach(t),Jlo=r(uk," or "),CB=n(uk,"A",{href:!0});var Mtt=s(CB);Ylo=r(Mtt,"LayoutLMTokenizerFast"),Mtt.forEach(t),Klo=r(uk," (LayoutLM model)"),uk.forEach(t),Zlo=i(S),ds=n(S,"LI",{});var bk=s(ds);Fse=n(bk,"STRONG",{});var Ett=s(Fse);eio=r(Ett,"layoutlmv2"),Ett.forEach(t),oio=r(bk," \u2014 "),wB=n(bk,"A",{href:!0});var Ctt=s(wB);rio=r(Ctt,"LayoutLMv2Tokenizer"),Ctt.forEach(t),tio=r(bk," or "),AB=n(bk,"A",{href:!0});var wtt=s(AB);aio=r(wtt,"LayoutLMv2TokenizerFast"),wtt.forEach(t),nio=r(bk," (LayoutLMv2 model)"),bk.forEach(t),sio=i(S),cs=n(S,"LI",{});var vk=s(cs);Tse=n(vk,"STRONG",{});var Att=s(Tse);lio=r(Att,"layoutlmv3"),Att.forEach(t),iio=r(vk," \u2014 "),LB=n(vk,"A",{href:!0});var Ltt=s(LB);dio=r(Ltt,"LayoutLMv3Tokenizer"),Ltt.forEach(t),cio=r(vk," or "),yB=n(vk,"A",{href:!0});var ytt=s(yB);fio=r(ytt,"LayoutLMv3TokenizerFast"),ytt.forEach(t),mio=r(vk," (LayoutLMv3 model)"),vk.forEach(t),gio=i(S),fs=n(S,"LI",{});var Fk=s(fs);Mse=n(Fk,"STRONG",{});var xtt=s(Mse);hio=r(xtt,"layoutxlm"),xtt.forEach(t),pio=r(Fk," \u2014 "),xB=n(Fk,"A",{href:!0});var $tt=s(xB);_io=r($tt,"LayoutXLMTokenizer"),$tt.forEach(t),uio=r(Fk," or "),$B=n(Fk,"A",{href:!0});var ktt=s($B);bio=r(ktt,"LayoutXLMTokenizerFast"),ktt.forEach(t),vio=r(Fk," (LayoutXLM model)"),Fk.forEach(t),Fio=i(S),ms=n(S,"LI",{});var Tk=s(ms);Ese=n(Tk,"STRONG",{});var Stt=s(Ese);Tio=r(Stt,"led"),Stt.forEach(t),Mio=r(Tk," \u2014 "),kB=n(Tk,"A",{href:!0});var Rtt=s(kB);Eio=r(Rtt,"LEDTokenizer"),Rtt.forEach(t),Cio=r(Tk," or "),SB=n(Tk,"A",{href:!0});var Ptt=s(SB);wio=r(Ptt,"LEDTokenizerFast"),Ptt.forEach(t),Aio=r(Tk," (LED model)"),Tk.forEach(t),Lio=i(S),gs=n(S,"LI",{});var Mk=s(gs);Cse=n(Mk,"STRONG",{});var Btt=s(Cse);yio=r(Btt,"longformer"),Btt.forEach(t),xio=r(Mk," \u2014 "),RB=n(Mk,"A",{href:!0});var Itt=s(RB);$io=r(Itt,"LongformerTokenizer"),Itt.forEach(t),kio=r(Mk," or "),PB=n(Mk,"A",{href:!0});var Ntt=s(PB);Sio=r(Ntt,"LongformerTokenizerFast"),Ntt.forEach(t),Rio=r(Mk," (Longformer model)"),Mk.forEach(t),Pio=i(S),hs=n(S,"LI",{});var Ek=s(hs);wse=n(Ek,"STRONG",{});var qtt=s(wse);Bio=r(qtt,"longt5"),qtt.forEach(t),Iio=r(Ek," \u2014 "),BB=n(Ek,"A",{href:!0});var jtt=s(BB);Nio=r(jtt,"T5Tokenizer"),jtt.forEach(t),qio=r(Ek," or "),IB=n(Ek,"A",{href:!0});var Dtt=s(IB);jio=r(Dtt,"T5TokenizerFast"),Dtt.forEach(t),Dio=r(Ek," (LongT5 model)"),Ek.forEach(t),Gio=i(S),th=n(S,"LI",{});var Bwe=s(th);Ase=n(Bwe,"STRONG",{});var Gtt=s(Ase);Oio=r(Gtt,"luke"),Gtt.forEach(t),Vio=r(Bwe," \u2014 "),NB=n(Bwe,"A",{href:!0});var Ott=s(NB);Xio=r(Ott,"LukeTokenizer"),Ott.forEach(t),zio=r(Bwe," (LUKE model)"),Bwe.forEach(t),Qio=i(S),ps=n(S,"LI",{});var Ck=s(ps);Lse=n(Ck,"STRONG",{});var Vtt=s(Lse);Wio=r(Vtt,"lxmert"),Vtt.forEach(t),Hio=r(Ck," \u2014 "),qB=n(Ck,"A",{href:!0});var Xtt=s(qB);Uio=r(Xtt,"LxmertTokenizer"),Xtt.forEach(t),Jio=r(Ck," or "),jB=n(Ck,"A",{href:!0});var ztt=s(jB);Yio=r(ztt,"LxmertTokenizerFast"),ztt.forEach(t),Kio=r(Ck," (LXMERT model)"),Ck.forEach(t),Zio=i(S),ah=n(S,"LI",{});var Iwe=s(ah);yse=n(Iwe,"STRONG",{});var Qtt=s(yse);edo=r(Qtt,"m2m_100"),Qtt.forEach(t),odo=r(Iwe," \u2014 "),DB=n(Iwe,"A",{href:!0});var Wtt=s(DB);rdo=r(Wtt,"M2M100Tokenizer"),Wtt.forEach(t),tdo=r(Iwe," (M2M100 model)"),Iwe.forEach(t),ado=i(S),nh=n(S,"LI",{});var Nwe=s(nh);xse=n(Nwe,"STRONG",{});var Htt=s(xse);ndo=r(Htt,"marian"),Htt.forEach(t),sdo=r(Nwe," \u2014 "),GB=n(Nwe,"A",{href:!0});var Utt=s(GB);ldo=r(Utt,"MarianTokenizer"),Utt.forEach(t),ido=r(Nwe," (Marian model)"),Nwe.forEach(t),ddo=i(S),_s=n(S,"LI",{});var wk=s(_s);$se=n(wk,"STRONG",{});var Jtt=s($se);cdo=r(Jtt,"mbart"),Jtt.forEach(t),fdo=r(wk," \u2014 "),OB=n(wk,"A",{href:!0});var Ytt=s(OB);mdo=r(Ytt,"MBartTokenizer"),Ytt.forEach(t),gdo=r(wk," or "),VB=n(wk,"A",{href:!0});var Ktt=s(VB);hdo=r(Ktt,"MBartTokenizerFast"),Ktt.forEach(t),pdo=r(wk," (mBART model)"),wk.forEach(t),_do=i(S),us=n(S,"LI",{});var Ak=s(us);kse=n(Ak,"STRONG",{});var Ztt=s(kse);udo=r(Ztt,"mbart50"),Ztt.forEach(t),bdo=r(Ak," \u2014 "),XB=n(Ak,"A",{href:!0});var eat=s(XB);vdo=r(eat,"MBart50Tokenizer"),eat.forEach(t),Fdo=r(Ak," or "),zB=n(Ak,"A",{href:!0});var oat=s(zB);Tdo=r(oat,"MBart50TokenizerFast"),oat.forEach(t),Mdo=r(Ak," (mBART-50 model)"),Ak.forEach(t),Edo=i(S),bs=n(S,"LI",{});var Lk=s(bs);Sse=n(Lk,"STRONG",{});var rat=s(Sse);Cdo=r(rat,"megatron-bert"),rat.forEach(t),wdo=r(Lk," \u2014 "),QB=n(Lk,"A",{href:!0});var tat=s(QB);Ado=r(tat,"BertTokenizer"),tat.forEach(t),Ldo=r(Lk," or "),WB=n(Lk,"A",{href:!0});var aat=s(WB);ydo=r(aat,"BertTokenizerFast"),aat.forEach(t),xdo=r(Lk," (Megatron-BERT model)"),Lk.forEach(t),$do=i(S),sh=n(S,"LI",{});var qwe=s(sh);Rse=n(qwe,"STRONG",{});var nat=s(Rse);kdo=r(nat,"mluke"),nat.forEach(t),Sdo=r(qwe," \u2014 "),HB=n(qwe,"A",{href:!0});var sat=s(HB);Rdo=r(sat,"MLukeTokenizer"),sat.forEach(t),Pdo=r(qwe," (mLUKE model)"),qwe.forEach(t),Bdo=i(S),vs=n(S,"LI",{});var yk=s(vs);Pse=n(yk,"STRONG",{});var lat=s(Pse);Ido=r(lat,"mobilebert"),lat.forEach(t),Ndo=r(yk," \u2014 "),UB=n(yk,"A",{href:!0});var iat=s(UB);qdo=r(iat,"MobileBertTokenizer"),iat.forEach(t),jdo=r(yk," or "),JB=n(yk,"A",{href:!0});var dat=s(JB);Ddo=r(dat,"MobileBertTokenizerFast"),dat.forEach(t),Gdo=r(yk," (MobileBERT model)"),yk.forEach(t),Odo=i(S),Fs=n(S,"LI",{});var xk=s(Fs);Bse=n(xk,"STRONG",{});var cat=s(Bse);Vdo=r(cat,"mpnet"),cat.forEach(t),Xdo=r(xk," \u2014 "),YB=n(xk,"A",{href:!0});var fat=s(YB);zdo=r(fat,"MPNetTokenizer"),fat.forEach(t),Qdo=r(xk," or "),KB=n(xk,"A",{href:!0});var mat=s(KB);Wdo=r(mat,"MPNetTokenizerFast"),mat.forEach(t),Hdo=r(xk," (MPNet model)"),xk.forEach(t),Udo=i(S),Ts=n(S,"LI",{});var $k=s(Ts);Ise=n($k,"STRONG",{});var gat=s(Ise);Jdo=r(gat,"mt5"),gat.forEach(t),Ydo=r($k," \u2014 "),ZB=n($k,"A",{href:!0});var hat=s(ZB);Kdo=r(hat,"MT5Tokenizer"),hat.forEach(t),Zdo=r($k," or "),eI=n($k,"A",{href:!0});var pat=s(eI);eco=r(pat,"MT5TokenizerFast"),pat.forEach(t),oco=r($k," (MT5 model)"),$k.forEach(t),rco=i(S),Ms=n(S,"LI",{});var kk=s(Ms);Nse=n(kk,"STRONG",{});var _at=s(Nse);tco=r(_at,"nezha"),_at.forEach(t),aco=r(kk," \u2014 "),oI=n(kk,"A",{href:!0});var uat=s(oI);nco=r(uat,"BertTokenizer"),uat.forEach(t),sco=r(kk," or "),rI=n(kk,"A",{href:!0});var bat=s(rI);lco=r(bat,"BertTokenizerFast"),bat.forEach(t),ico=r(kk," (Nezha model)"),kk.forEach(t),dco=i(S),Es=n(S,"LI",{});var Sk=s(Es);qse=n(Sk,"STRONG",{});var vat=s(qse);cco=r(vat,"nystromformer"),vat.forEach(t),fco=r(Sk," \u2014 "),tI=n(Sk,"A",{href:!0});var Fat=s(tI);mco=r(Fat,"AlbertTokenizer"),Fat.forEach(t),gco=r(Sk," or "),aI=n(Sk,"A",{href:!0});var Tat=s(aI);hco=r(Tat,"AlbertTokenizerFast"),Tat.forEach(t),pco=r(Sk," (Nystr\xF6mformer model)"),Sk.forEach(t),_co=i(S),Cs=n(S,"LI",{});var Rk=s(Cs);jse=n(Rk,"STRONG",{});var Mat=s(jse);uco=r(Mat,"openai-gpt"),Mat.forEach(t),bco=r(Rk," \u2014 "),nI=n(Rk,"A",{href:!0});var Eat=s(nI);vco=r(Eat,"OpenAIGPTTokenizer"),Eat.forEach(t),Fco=r(Rk," or "),sI=n(Rk,"A",{href:!0});var Cat=s(sI);Tco=r(Cat,"OpenAIGPTTokenizerFast"),Cat.forEach(t),Mco=r(Rk," (OpenAI GPT model)"),Rk.forEach(t),Eco=i(S),lh=n(S,"LI",{});var jwe=s(lh);Dse=n(jwe,"STRONG",{});var wat=s(Dse);Cco=r(wat,"opt"),wat.forEach(t),wco=r(jwe," \u2014 "),lI=n(jwe,"A",{href:!0});var Aat=s(lI);Aco=r(Aat,"GPT2Tokenizer"),Aat.forEach(t),Lco=r(jwe," (OPT model)"),jwe.forEach(t),yco=i(S),ws=n(S,"LI",{});var Pk=s(ws);Gse=n(Pk,"STRONG",{});var Lat=s(Gse);xco=r(Lat,"pegasus"),Lat.forEach(t),$co=r(Pk," \u2014 "),iI=n(Pk,"A",{href:!0});var yat=s(iI);kco=r(yat,"PegasusTokenizer"),yat.forEach(t),Sco=r(Pk," or "),dI=n(Pk,"A",{href:!0});var xat=s(dI);Rco=r(xat,"PegasusTokenizerFast"),xat.forEach(t),Pco=r(Pk," (Pegasus model)"),Pk.forEach(t),Bco=i(S),ih=n(S,"LI",{});var Dwe=s(ih);Ose=n(Dwe,"STRONG",{});var $at=s(Ose);Ico=r($at,"perceiver"),$at.forEach(t),Nco=r(Dwe," \u2014 "),cI=n(Dwe,"A",{href:!0});var kat=s(cI);qco=r(kat,"PerceiverTokenizer"),kat.forEach(t),jco=r(Dwe," (Perceiver model)"),Dwe.forEach(t),Dco=i(S),dh=n(S,"LI",{});var Gwe=s(dh);Vse=n(Gwe,"STRONG",{});var Sat=s(Vse);Gco=r(Sat,"phobert"),Sat.forEach(t),Oco=r(Gwe," \u2014 "),fI=n(Gwe,"A",{href:!0});var Rat=s(fI);Vco=r(Rat,"PhobertTokenizer"),Rat.forEach(t),Xco=r(Gwe," (PhoBERT model)"),Gwe.forEach(t),zco=i(S),ch=n(S,"LI",{});var Owe=s(ch);Xse=n(Owe,"STRONG",{});var Pat=s(Xse);Qco=r(Pat,"plbart"),Pat.forEach(t),Wco=r(Owe," \u2014 "),mI=n(Owe,"A",{href:!0});var Bat=s(mI);Hco=r(Bat,"PLBartTokenizer"),Bat.forEach(t),Uco=r(Owe," (PLBart model)"),Owe.forEach(t),Jco=i(S),fh=n(S,"LI",{});var Vwe=s(fh);zse=n(Vwe,"STRONG",{});var Iat=s(zse);Yco=r(Iat,"prophetnet"),Iat.forEach(t),Kco=r(Vwe," \u2014 "),gI=n(Vwe,"A",{href:!0});var Nat=s(gI);Zco=r(Nat,"ProphetNetTokenizer"),Nat.forEach(t),efo=r(Vwe," (ProphetNet model)"),Vwe.forEach(t),ofo=i(S),As=n(S,"LI",{});var Bk=s(As);Qse=n(Bk,"STRONG",{});var qat=s(Qse);rfo=r(qat,"qdqbert"),qat.forEach(t),tfo=r(Bk," \u2014 "),hI=n(Bk,"A",{href:!0});var jat=s(hI);afo=r(jat,"BertTokenizer"),jat.forEach(t),nfo=r(Bk," or "),pI=n(Bk,"A",{href:!0});var Dat=s(pI);sfo=r(Dat,"BertTokenizerFast"),Dat.forEach(t),lfo=r(Bk," (QDQBert model)"),Bk.forEach(t),ifo=i(S),mh=n(S,"LI",{});var Xwe=s(mh);Wse=n(Xwe,"STRONG",{});var Gat=s(Wse);dfo=r(Gat,"rag"),Gat.forEach(t),cfo=r(Xwe," \u2014 "),_I=n(Xwe,"A",{href:!0});var Oat=s(_I);ffo=r(Oat,"RagTokenizer"),Oat.forEach(t),mfo=r(Xwe," (RAG model)"),Xwe.forEach(t),gfo=i(S),Ls=n(S,"LI",{});var Ik=s(Ls);Hse=n(Ik,"STRONG",{});var Vat=s(Hse);hfo=r(Vat,"realm"),Vat.forEach(t),pfo=r(Ik," \u2014 "),uI=n(Ik,"A",{href:!0});var Xat=s(uI);_fo=r(Xat,"RealmTokenizer"),Xat.forEach(t),ufo=r(Ik," or "),bI=n(Ik,"A",{href:!0});var zat=s(bI);bfo=r(zat,"RealmTokenizerFast"),zat.forEach(t),vfo=r(Ik," (REALM model)"),Ik.forEach(t),Ffo=i(S),ys=n(S,"LI",{});var Nk=s(ys);Use=n(Nk,"STRONG",{});var Qat=s(Use);Tfo=r(Qat,"reformer"),Qat.forEach(t),Mfo=r(Nk," \u2014 "),vI=n(Nk,"A",{href:!0});var Wat=s(vI);Efo=r(Wat,"ReformerTokenizer"),Wat.forEach(t),Cfo=r(Nk," or "),FI=n(Nk,"A",{href:!0});var Hat=s(FI);wfo=r(Hat,"ReformerTokenizerFast"),Hat.forEach(t),Afo=r(Nk," (Reformer model)"),Nk.forEach(t),Lfo=i(S),xs=n(S,"LI",{});var qk=s(xs);Jse=n(qk,"STRONG",{});var Uat=s(Jse);yfo=r(Uat,"rembert"),Uat.forEach(t),xfo=r(qk," \u2014 "),TI=n(qk,"A",{href:!0});var Jat=s(TI);$fo=r(Jat,"RemBertTokenizer"),Jat.forEach(t),kfo=r(qk," or "),MI=n(qk,"A",{href:!0});var Yat=s(MI);Sfo=r(Yat,"RemBertTokenizerFast"),Yat.forEach(t),Rfo=r(qk," (RemBERT model)"),qk.forEach(t),Pfo=i(S),$s=n(S,"LI",{});var jk=s($s);Yse=n(jk,"STRONG",{});var Kat=s(Yse);Bfo=r(Kat,"retribert"),Kat.forEach(t),Ifo=r(jk," \u2014 "),EI=n(jk,"A",{href:!0});var Zat=s(EI);Nfo=r(Zat,"RetriBertTokenizer"),Zat.forEach(t),qfo=r(jk," or "),CI=n(jk,"A",{href:!0});var ent=s(CI);jfo=r(ent,"RetriBertTokenizerFast"),ent.forEach(t),Dfo=r(jk," (RetriBERT model)"),jk.forEach(t),Gfo=i(S),ks=n(S,"LI",{});var Dk=s(ks);Kse=n(Dk,"STRONG",{});var ont=s(Kse);Ofo=r(ont,"roberta"),ont.forEach(t),Vfo=r(Dk," \u2014 "),wI=n(Dk,"A",{href:!0});var rnt=s(wI);Xfo=r(rnt,"RobertaTokenizer"),rnt.forEach(t),zfo=r(Dk," or "),AI=n(Dk,"A",{href:!0});var tnt=s(AI);Qfo=r(tnt,"RobertaTokenizerFast"),tnt.forEach(t),Wfo=r(Dk," (RoBERTa model)"),Dk.forEach(t),Hfo=i(S),Ss=n(S,"LI",{});var Gk=s(Ss);Zse=n(Gk,"STRONG",{});var ant=s(Zse);Ufo=r(ant,"roformer"),ant.forEach(t),Jfo=r(Gk," \u2014 "),LI=n(Gk,"A",{href:!0});var nnt=s(LI);Yfo=r(nnt,"RoFormerTokenizer"),nnt.forEach(t),Kfo=r(Gk," or "),yI=n(Gk,"A",{href:!0});var snt=s(yI);Zfo=r(snt,"RoFormerTokenizerFast"),snt.forEach(t),emo=r(Gk," (RoFormer model)"),Gk.forEach(t),omo=i(S),gh=n(S,"LI",{});var zwe=s(gh);ele=n(zwe,"STRONG",{});var lnt=s(ele);rmo=r(lnt,"speech_to_text"),lnt.forEach(t),tmo=r(zwe," \u2014 "),xI=n(zwe,"A",{href:!0});var int=s(xI);amo=r(int,"Speech2TextTokenizer"),int.forEach(t),nmo=r(zwe," (Speech2Text model)"),zwe.forEach(t),smo=i(S),hh=n(S,"LI",{});var Qwe=s(hh);ole=n(Qwe,"STRONG",{});var dnt=s(ole);lmo=r(dnt,"speech_to_text_2"),dnt.forEach(t),imo=r(Qwe," \u2014 "),$I=n(Qwe,"A",{href:!0});var cnt=s($I);dmo=r(cnt,"Speech2Text2Tokenizer"),cnt.forEach(t),cmo=r(Qwe," (Speech2Text2 model)"),Qwe.forEach(t),fmo=i(S),Rs=n(S,"LI",{});var Ok=s(Rs);rle=n(Ok,"STRONG",{});var fnt=s(rle);mmo=r(fnt,"splinter"),fnt.forEach(t),gmo=r(Ok," \u2014 "),kI=n(Ok,"A",{href:!0});var mnt=s(kI);hmo=r(mnt,"SplinterTokenizer"),mnt.forEach(t),pmo=r(Ok," or "),SI=n(Ok,"A",{href:!0});var gnt=s(SI);_mo=r(gnt,"SplinterTokenizerFast"),gnt.forEach(t),umo=r(Ok," (Splinter model)"),Ok.forEach(t),bmo=i(S),Ps=n(S,"LI",{});var Vk=s(Ps);tle=n(Vk,"STRONG",{});var hnt=s(tle);vmo=r(hnt,"squeezebert"),hnt.forEach(t),Fmo=r(Vk," \u2014 "),RI=n(Vk,"A",{href:!0});var pnt=s(RI);Tmo=r(pnt,"SqueezeBertTokenizer"),pnt.forEach(t),Mmo=r(Vk," or "),PI=n(Vk,"A",{href:!0});var _nt=s(PI);Emo=r(_nt,"SqueezeBertTokenizerFast"),_nt.forEach(t),Cmo=r(Vk," (SqueezeBERT model)"),Vk.forEach(t),wmo=i(S),Bs=n(S,"LI",{});var Xk=s(Bs);ale=n(Xk,"STRONG",{});var unt=s(ale);Amo=r(unt,"t5"),unt.forEach(t),Lmo=r(Xk," \u2014 "),BI=n(Xk,"A",{href:!0});var bnt=s(BI);ymo=r(bnt,"T5Tokenizer"),bnt.forEach(t),xmo=r(Xk," or "),II=n(Xk,"A",{href:!0});var vnt=s(II);$mo=r(vnt,"T5TokenizerFast"),vnt.forEach(t),kmo=r(Xk," (T5 model)"),Xk.forEach(t),Smo=i(S),ph=n(S,"LI",{});var Wwe=s(ph);nle=n(Wwe,"STRONG",{});var Fnt=s(nle);Rmo=r(Fnt,"tapas"),Fnt.forEach(t),Pmo=r(Wwe," \u2014 "),NI=n(Wwe,"A",{href:!0});var Tnt=s(NI);Bmo=r(Tnt,"TapasTokenizer"),Tnt.forEach(t),Imo=r(Wwe," (TAPAS model)"),Wwe.forEach(t),Nmo=i(S),_h=n(S,"LI",{});var Hwe=s(_h);sle=n(Hwe,"STRONG",{});var Mnt=s(sle);qmo=r(Mnt,"tapex"),Mnt.forEach(t),jmo=r(Hwe," \u2014 "),qI=n(Hwe,"A",{href:!0});var Ent=s(qI);Dmo=r(Ent,"TapexTokenizer"),Ent.forEach(t),Gmo=r(Hwe," (TAPEX model)"),Hwe.forEach(t),Omo=i(S),uh=n(S,"LI",{});var Uwe=s(uh);lle=n(Uwe,"STRONG",{});var Cnt=s(lle);Vmo=r(Cnt,"transfo-xl"),Cnt.forEach(t),Xmo=r(Uwe," \u2014 "),jI=n(Uwe,"A",{href:!0});var wnt=s(jI);zmo=r(wnt,"TransfoXLTokenizer"),wnt.forEach(t),Qmo=r(Uwe," (Transformer-XL model)"),Uwe.forEach(t),Wmo=i(S),Is=n(S,"LI",{});var zk=s(Is);ile=n(zk,"STRONG",{});var Ant=s(ile);Hmo=r(Ant,"vilt"),Ant.forEach(t),Umo=r(zk," \u2014 "),DI=n(zk,"A",{href:!0});var Lnt=s(DI);Jmo=r(Lnt,"BertTokenizer"),Lnt.forEach(t),Ymo=r(zk," or "),GI=n(zk,"A",{href:!0});var ynt=s(GI);Kmo=r(ynt,"BertTokenizerFast"),ynt.forEach(t),Zmo=r(zk," (ViLT model)"),zk.forEach(t),ego=i(S),Ns=n(S,"LI",{});var Qk=s(Ns);dle=n(Qk,"STRONG",{});var xnt=s(dle);ogo=r(xnt,"visual_bert"),xnt.forEach(t),rgo=r(Qk," \u2014 "),OI=n(Qk,"A",{href:!0});var $nt=s(OI);tgo=r($nt,"BertTokenizer"),$nt.forEach(t),ago=r(Qk," or "),VI=n(Qk,"A",{href:!0});var knt=s(VI);ngo=r(knt,"BertTokenizerFast"),knt.forEach(t),sgo=r(Qk," (VisualBERT model)"),Qk.forEach(t),lgo=i(S),bh=n(S,"LI",{});var Jwe=s(bh);cle=n(Jwe,"STRONG",{});var Snt=s(cle);igo=r(Snt,"wav2vec2"),Snt.forEach(t),dgo=r(Jwe," \u2014 "),XI=n(Jwe,"A",{href:!0});var Rnt=s(XI);cgo=r(Rnt,"Wav2Vec2CTCTokenizer"),Rnt.forEach(t),fgo=r(Jwe," (Wav2Vec2 model)"),Jwe.forEach(t),mgo=i(S),vh=n(S,"LI",{});var Ywe=s(vh);fle=n(Ywe,"STRONG",{});var Pnt=s(fle);ggo=r(Pnt,"wav2vec2-conformer"),Pnt.forEach(t),hgo=r(Ywe," \u2014 "),zI=n(Ywe,"A",{href:!0});var Bnt=s(zI);pgo=r(Bnt,"Wav2Vec2CTCTokenizer"),Bnt.forEach(t),_go=r(Ywe," (Wav2Vec2-Conformer model)"),Ywe.forEach(t),ugo=i(S),Fh=n(S,"LI",{});var Kwe=s(Fh);mle=n(Kwe,"STRONG",{});var Int=s(mle);bgo=r(Int,"wav2vec2_phoneme"),Int.forEach(t),vgo=r(Kwe," \u2014 "),QI=n(Kwe,"A",{href:!0});var Nnt=s(QI);Fgo=r(Nnt,"Wav2Vec2PhonemeCTCTokenizer"),Nnt.forEach(t),Tgo=r(Kwe," (Wav2Vec2Phoneme model)"),Kwe.forEach(t),Mgo=i(S),qs=n(S,"LI",{});var Wk=s(qs);gle=n(Wk,"STRONG",{});var qnt=s(gle);Ego=r(qnt,"xglm"),qnt.forEach(t),Cgo=r(Wk," \u2014 "),WI=n(Wk,"A",{href:!0});var jnt=s(WI);wgo=r(jnt,"XGLMTokenizer"),jnt.forEach(t),Ago=r(Wk," or "),HI=n(Wk,"A",{href:!0});var Dnt=s(HI);Lgo=r(Dnt,"XGLMTokenizerFast"),Dnt.forEach(t),ygo=r(Wk," (XGLM model)"),Wk.forEach(t),xgo=i(S),Th=n(S,"LI",{});var Zwe=s(Th);hle=n(Zwe,"STRONG",{});var Gnt=s(hle);$go=r(Gnt,"xlm"),Gnt.forEach(t),kgo=r(Zwe," \u2014 "),UI=n(Zwe,"A",{href:!0});var Ont=s(UI);Sgo=r(Ont,"XLMTokenizer"),Ont.forEach(t),Rgo=r(Zwe," (XLM model)"),Zwe.forEach(t),Pgo=i(S),Mh=n(S,"LI",{});var eAe=s(Mh);ple=n(eAe,"STRONG",{});var Vnt=s(ple);Bgo=r(Vnt,"xlm-prophetnet"),Vnt.forEach(t),Igo=r(eAe," \u2014 "),JI=n(eAe,"A",{href:!0});var Xnt=s(JI);Ngo=r(Xnt,"XLMProphetNetTokenizer"),Xnt.forEach(t),qgo=r(eAe," (XLM-ProphetNet model)"),eAe.forEach(t),jgo=i(S),js=n(S,"LI",{});var Hk=s(js);_le=n(Hk,"STRONG",{});var znt=s(_le);Dgo=r(znt,"xlm-roberta"),znt.forEach(t),Ggo=r(Hk," \u2014 "),YI=n(Hk,"A",{href:!0});var Qnt=s(YI);Ogo=r(Qnt,"XLMRobertaTokenizer"),Qnt.forEach(t),Vgo=r(Hk," or "),KI=n(Hk,"A",{href:!0});var Wnt=s(KI);Xgo=r(Wnt,"XLMRobertaTokenizerFast"),Wnt.forEach(t),zgo=r(Hk," (XLM-RoBERTa model)"),Hk.forEach(t),Qgo=i(S),Ds=n(S,"LI",{});var Uk=s(Ds);ule=n(Uk,"STRONG",{});var Hnt=s(ule);Wgo=r(Hnt,"xlm-roberta-xl"),Hnt.forEach(t),Hgo=r(Uk," \u2014 "),ZI=n(Uk,"A",{href:!0});var Unt=s(ZI);Ugo=r(Unt,"RobertaTokenizer"),Unt.forEach(t),Jgo=r(Uk," or "),eN=n(Uk,"A",{href:!0});var Jnt=s(eN);Ygo=r(Jnt,"RobertaTokenizerFast"),Jnt.forEach(t),Kgo=r(Uk," (XLM-RoBERTa-XL model)"),Uk.forEach(t),Zgo=i(S),Gs=n(S,"LI",{});var Jk=s(Gs);ble=n(Jk,"STRONG",{});var Ynt=s(ble);eho=r(Ynt,"xlnet"),Ynt.forEach(t),oho=r(Jk," \u2014 "),oN=n(Jk,"A",{href:!0});var Knt=s(oN);rho=r(Knt,"XLNetTokenizer"),Knt.forEach(t),tho=r(Jk," or "),rN=n(Jk,"A",{href:!0});var Znt=s(rN);aho=r(Znt,"XLNetTokenizerFast"),Znt.forEach(t),nho=r(Jk," (XLNet model)"),Jk.forEach(t),sho=i(S),Os=n(S,"LI",{});var Yk=s(Os);vle=n(Yk,"STRONG",{});var est=s(vle);lho=r(est,"yoso"),est.forEach(t),iho=r(Yk," \u2014 "),tN=n(Yk,"A",{href:!0});var ost=s(tN);dho=r(ost,"AlbertTokenizer"),ost.forEach(t),cho=r(Yk," or "),aN=n(Yk,"A",{href:!0});var rst=s(aN);fho=r(rst,"AlbertTokenizerFast"),rst.forEach(t),mho=r(Yk," (YOSO model)"),Yk.forEach(t),S.forEach(t),gho=i(Hs),T(Eh.$$.fragment,Hs),Hs.forEach(t),hho=i(Ws),Ch=n(Ws,"DIV",{class:!0});var UVe=s(Ch);T(Ow.$$.fragment,UVe),pho=i(UVe),Fle=n(UVe,"P",{});var tst=s(Fle);_ho=r(tst,"Register a new tokenizer in this mapping."),tst.forEach(t),UVe.forEach(t),Ws.forEach(t),HGe=i(f),Si=n(f,"H2",{class:!0});var JVe=s(Si);wh=n(JVe,"A",{id:!0,class:!0,href:!0});var ast=s(wh);Tle=n(ast,"SPAN",{});var nst=s(Tle);T(Vw.$$.fragment,nst),nst.forEach(t),ast.forEach(t),uho=i(JVe),Mle=n(JVe,"SPAN",{});var sst=s(Mle);bho=r(sst,"AutoFeatureExtractor"),sst.forEach(t),JVe.forEach(t),UGe=i(f),Lo=n(f,"DIV",{class:!0});var Us=s(Lo);T(Xw.$$.fragment,Us),vho=i(Us),zw=n(Us,"P",{});var YVe=s(zw);Fho=r(YVe,`This is a generic feature extractor class that will be instantiated as one of the feature extractor classes of the
library when created with the `),nN=n(YVe,"A",{href:!0});var lst=s(nN);Tho=r(lst,"AutoFeatureExtractor.from_pretrained()"),lst.forEach(t),Mho=r(YVe," class method."),YVe.forEach(t),Eho=i(Us),Qw=n(Us,"P",{});var KVe=s(Qw);Cho=r(KVe,"This class cannot be instantiated directly using "),Ele=n(KVe,"CODE",{});var ist=s(Ele);who=r(ist,"__init__()"),ist.forEach(t),Aho=r(KVe," (throws an error)."),KVe.forEach(t),Lho=i(Us),He=n(Us,"DIV",{class:!0});var ra=s(He);T(Ww.$$.fragment,ra),yho=i(ra),Cle=n(ra,"P",{});var dst=s(Cle);xho=r(dst,"Instantiate one of the feature extractor classes of the library from a pretrained model vocabulary."),dst.forEach(t),$ho=i(ra),Sa=n(ra,"P",{});var $3=s(Sa);kho=r($3,"The feature extractor class to instantiate is selected based on the "),wle=n($3,"CODE",{});var cst=s(wle);Sho=r(cst,"model_type"),cst.forEach(t),Rho=r($3,` property of the config object
(either passed as an argument or loaded from `),Ale=n($3,"CODE",{});var fst=s(Ale);Pho=r(fst,"pretrained_model_name_or_path"),fst.forEach(t),Bho=r($3,` if possible), or when it\u2019s
missing, by falling back to using pattern matching on `),Lle=n($3,"CODE",{});var mst=s(Lle);Iho=r(mst,"pretrained_model_name_or_path"),mst.forEach(t),Nho=r($3,":"),$3.forEach(t),qho=i(ra),Y=n(ra,"UL",{});var K=s(Y);Ah=n(K,"LI",{});var oAe=s(Ah);yle=n(oAe,"STRONG",{});var gst=s(yle);jho=r(gst,"beit"),gst.forEach(t),Dho=r(oAe," \u2014 "),sN=n(oAe,"A",{href:!0});var hst=s(sN);Gho=r(hst,"BeitFeatureExtractor"),hst.forEach(t),Oho=r(oAe," (BEiT model)"),oAe.forEach(t),Vho=i(K),Lh=n(K,"LI",{});var rAe=s(Lh);xle=n(rAe,"STRONG",{});var pst=s(xle);Xho=r(pst,"clip"),pst.forEach(t),zho=r(rAe," \u2014 "),lN=n(rAe,"A",{href:!0});var _st=s(lN);Qho=r(_st,"CLIPFeatureExtractor"),_st.forEach(t),Who=r(rAe," (CLIP model)"),rAe.forEach(t),Hho=i(K),yh=n(K,"LI",{});var tAe=s(yh);$le=n(tAe,"STRONG",{});var ust=s($le);Uho=r(ust,"convnext"),ust.forEach(t),Jho=r(tAe," \u2014 "),iN=n(tAe,"A",{href:!0});var bst=s(iN);Yho=r(bst,"ConvNextFeatureExtractor"),bst.forEach(t),Kho=r(tAe," (ConvNeXT model)"),tAe.forEach(t),Zho=i(K),xh=n(K,"LI",{});var aAe=s(xh);kle=n(aAe,"STRONG",{});var vst=s(kle);epo=r(vst,"cvt"),vst.forEach(t),opo=r(aAe," \u2014 "),dN=n(aAe,"A",{href:!0});var Fst=s(dN);rpo=r(Fst,"ConvNextFeatureExtractor"),Fst.forEach(t),tpo=r(aAe," (CvT model)"),aAe.forEach(t),apo=i(K),$h=n(K,"LI",{});var nAe=s($h);Sle=n(nAe,"STRONG",{});var Tst=s(Sle);npo=r(Tst,"data2vec-audio"),Tst.forEach(t),spo=r(nAe," \u2014 "),cN=n(nAe,"A",{href:!0});var Mst=s(cN);lpo=r(Mst,"Wav2Vec2FeatureExtractor"),Mst.forEach(t),ipo=r(nAe," (Data2VecAudio model)"),nAe.forEach(t),dpo=i(K),kh=n(K,"LI",{});var sAe=s(kh);Rle=n(sAe,"STRONG",{});var Est=s(Rle);cpo=r(Est,"data2vec-vision"),Est.forEach(t),fpo=r(sAe," \u2014 "),fN=n(sAe,"A",{href:!0});var Cst=s(fN);mpo=r(Cst,"BeitFeatureExtractor"),Cst.forEach(t),gpo=r(sAe," (Data2VecVision model)"),sAe.forEach(t),hpo=i(K),Sh=n(K,"LI",{});var lAe=s(Sh);Ple=n(lAe,"STRONG",{});var wst=s(Ple);ppo=r(wst,"deit"),wst.forEach(t),_po=r(lAe," \u2014 "),mN=n(lAe,"A",{href:!0});var Ast=s(mN);upo=r(Ast,"DeiTFeatureExtractor"),Ast.forEach(t),bpo=r(lAe," (DeiT model)"),lAe.forEach(t),vpo=i(K),Rh=n(K,"LI",{});var iAe=s(Rh);Ble=n(iAe,"STRONG",{});var Lst=s(Ble);Fpo=r(Lst,"detr"),Lst.forEach(t),Tpo=r(iAe," \u2014 "),gN=n(iAe,"A",{href:!0});var yst=s(gN);Mpo=r(yst,"DetrFeatureExtractor"),yst.forEach(t),Epo=r(iAe," (DETR model)"),iAe.forEach(t),Cpo=i(K),Ph=n(K,"LI",{});var dAe=s(Ph);Ile=n(dAe,"STRONG",{});var xst=s(Ile);wpo=r(xst,"dpt"),xst.forEach(t),Apo=r(dAe," \u2014 "),hN=n(dAe,"A",{href:!0});var $st=s(hN);Lpo=r($st,"DPTFeatureExtractor"),$st.forEach(t),ypo=r(dAe," (DPT model)"),dAe.forEach(t),xpo=i(K),Bh=n(K,"LI",{});var cAe=s(Bh);Nle=n(cAe,"STRONG",{});var kst=s(Nle);$po=r(kst,"flava"),kst.forEach(t),kpo=r(cAe," \u2014 "),pN=n(cAe,"A",{href:!0});var Sst=s(pN);Spo=r(Sst,"FlavaFeatureExtractor"),Sst.forEach(t),Rpo=r(cAe," (FLAVA model)"),cAe.forEach(t),Ppo=i(K),Ih=n(K,"LI",{});var fAe=s(Ih);qle=n(fAe,"STRONG",{});var Rst=s(qle);Bpo=r(Rst,"glpn"),Rst.forEach(t),Ipo=r(fAe," \u2014 "),_N=n(fAe,"A",{href:!0});var Pst=s(_N);Npo=r(Pst,"GLPNFeatureExtractor"),Pst.forEach(t),qpo=r(fAe," (GLPN model)"),fAe.forEach(t),jpo=i(K),Nh=n(K,"LI",{});var mAe=s(Nh);jle=n(mAe,"STRONG",{});var Bst=s(jle);Dpo=r(Bst,"hubert"),Bst.forEach(t),Gpo=r(mAe," \u2014 "),uN=n(mAe,"A",{href:!0});var Ist=s(uN);Opo=r(Ist,"Wav2Vec2FeatureExtractor"),Ist.forEach(t),Vpo=r(mAe," (Hubert model)"),mAe.forEach(t),Xpo=i(K),qh=n(K,"LI",{});var gAe=s(qh);Dle=n(gAe,"STRONG",{});var Nst=s(Dle);zpo=r(Nst,"imagegpt"),Nst.forEach(t),Qpo=r(gAe," \u2014 "),bN=n(gAe,"A",{href:!0});var qst=s(bN);Wpo=r(qst,"ImageGPTFeatureExtractor"),qst.forEach(t),Hpo=r(gAe," (ImageGPT model)"),gAe.forEach(t),Upo=i(K),jh=n(K,"LI",{});var hAe=s(jh);Gle=n(hAe,"STRONG",{});var jst=s(Gle);Jpo=r(jst,"layoutlmv2"),jst.forEach(t),Ypo=r(hAe," \u2014 "),vN=n(hAe,"A",{href:!0});var Dst=s(vN);Kpo=r(Dst,"LayoutLMv2FeatureExtractor"),Dst.forEach(t),Zpo=r(hAe," (LayoutLMv2 model)"),hAe.forEach(t),e_o=i(K),Dh=n(K,"LI",{});var pAe=s(Dh);Ole=n(pAe,"STRONG",{});var Gst=s(Ole);o_o=r(Gst,"layoutlmv3"),Gst.forEach(t),r_o=r(pAe," \u2014 "),FN=n(pAe,"A",{href:!0});var Ost=s(FN);t_o=r(Ost,"LayoutLMv3FeatureExtractor"),Ost.forEach(t),a_o=r(pAe," (LayoutLMv3 model)"),pAe.forEach(t),n_o=i(K),Gh=n(K,"LI",{});var _Ae=s(Gh);Vle=n(_Ae,"STRONG",{});var Vst=s(Vle);s_o=r(Vst,"levit"),Vst.forEach(t),l_o=r(_Ae," \u2014 "),TN=n(_Ae,"A",{href:!0});var Xst=s(TN);i_o=r(Xst,"LevitFeatureExtractor"),Xst.forEach(t),d_o=r(_Ae," (LeViT model)"),_Ae.forEach(t),c_o=i(K),Oh=n(K,"LI",{});var uAe=s(Oh);Xle=n(uAe,"STRONG",{});var zst=s(Xle);f_o=r(zst,"maskformer"),zst.forEach(t),m_o=r(uAe," \u2014 "),MN=n(uAe,"A",{href:!0});var Qst=s(MN);g_o=r(Qst,"MaskFormerFeatureExtractor"),Qst.forEach(t),h_o=r(uAe," (MaskFormer model)"),uAe.forEach(t),p_o=i(K),Vh=n(K,"LI",{});var bAe=s(Vh);zle=n(bAe,"STRONG",{});var Wst=s(zle);__o=r(Wst,"mctct"),Wst.forEach(t),u_o=r(bAe," \u2014 "),EN=n(bAe,"A",{href:!0});var Hst=s(EN);b_o=r(Hst,"MCTCTFeatureExtractor"),Hst.forEach(t),v_o=r(bAe," (M-CTC-T model)"),bAe.forEach(t),F_o=i(K),Xh=n(K,"LI",{});var vAe=s(Xh);Qle=n(vAe,"STRONG",{});var Ust=s(Qle);T_o=r(Ust,"perceiver"),Ust.forEach(t),M_o=r(vAe," \u2014 "),CN=n(vAe,"A",{href:!0});var Jst=s(CN);E_o=r(Jst,"PerceiverFeatureExtractor"),Jst.forEach(t),C_o=r(vAe," (Perceiver model)"),vAe.forEach(t),w_o=i(K),zh=n(K,"LI",{});var FAe=s(zh);Wle=n(FAe,"STRONG",{});var Yst=s(Wle);A_o=r(Yst,"poolformer"),Yst.forEach(t),L_o=r(FAe," \u2014 "),wN=n(FAe,"A",{href:!0});var Kst=s(wN);y_o=r(Kst,"PoolFormerFeatureExtractor"),Kst.forEach(t),x_o=r(FAe," (PoolFormer model)"),FAe.forEach(t),$_o=i(K),Qh=n(K,"LI",{});var TAe=s(Qh);Hle=n(TAe,"STRONG",{});var Zst=s(Hle);k_o=r(Zst,"regnet"),Zst.forEach(t),S_o=r(TAe," \u2014 "),AN=n(TAe,"A",{href:!0});var elt=s(AN);R_o=r(elt,"ConvNextFeatureExtractor"),elt.forEach(t),P_o=r(TAe," (RegNet model)"),TAe.forEach(t),B_o=i(K),Wh=n(K,"LI",{});var MAe=s(Wh);Ule=n(MAe,"STRONG",{});var olt=s(Ule);I_o=r(olt,"resnet"),olt.forEach(t),N_o=r(MAe," \u2014 "),LN=n(MAe,"A",{href:!0});var rlt=s(LN);q_o=r(rlt,"ConvNextFeatureExtractor"),rlt.forEach(t),j_o=r(MAe," (ResNet model)"),MAe.forEach(t),D_o=i(K),Hh=n(K,"LI",{});var EAe=s(Hh);Jle=n(EAe,"STRONG",{});var tlt=s(Jle);G_o=r(tlt,"segformer"),tlt.forEach(t),O_o=r(EAe," \u2014 "),yN=n(EAe,"A",{href:!0});var alt=s(yN);V_o=r(alt,"SegformerFeatureExtractor"),alt.forEach(t),X_o=r(EAe," (SegFormer model)"),EAe.forEach(t),z_o=i(K),Uh=n(K,"LI",{});var CAe=s(Uh);Yle=n(CAe,"STRONG",{});var nlt=s(Yle);Q_o=r(nlt,"speech_to_text"),nlt.forEach(t),W_o=r(CAe," \u2014 "),xN=n(CAe,"A",{href:!0});var slt=s(xN);H_o=r(slt,"Speech2TextFeatureExtractor"),slt.forEach(t),U_o=r(CAe," (Speech2Text model)"),CAe.forEach(t),J_o=i(K),Jh=n(K,"LI",{});var wAe=s(Jh);Kle=n(wAe,"STRONG",{});var llt=s(Kle);Y_o=r(llt,"swin"),llt.forEach(t),K_o=r(wAe," \u2014 "),$N=n(wAe,"A",{href:!0});var ilt=s($N);Z_o=r(ilt,"ViTFeatureExtractor"),ilt.forEach(t),euo=r(wAe," (Swin Transformer model)"),wAe.forEach(t),ouo=i(K),Yh=n(K,"LI",{});var AAe=s(Yh);Zle=n(AAe,"STRONG",{});var dlt=s(Zle);ruo=r(dlt,"van"),dlt.forEach(t),tuo=r(AAe," \u2014 "),kN=n(AAe,"A",{href:!0});var clt=s(kN);auo=r(clt,"ConvNextFeatureExtractor"),clt.forEach(t),nuo=r(AAe," (VAN model)"),AAe.forEach(t),suo=i(K),Kh=n(K,"LI",{});var LAe=s(Kh);eie=n(LAe,"STRONG",{});var flt=s(eie);luo=r(flt,"vilt"),flt.forEach(t),iuo=r(LAe," \u2014 "),SN=n(LAe,"A",{href:!0});var mlt=s(SN);duo=r(mlt,"ViltFeatureExtractor"),mlt.forEach(t),cuo=r(LAe," (ViLT model)"),LAe.forEach(t),fuo=i(K),Zh=n(K,"LI",{});var yAe=s(Zh);oie=n(yAe,"STRONG",{});var glt=s(oie);muo=r(glt,"vit"),glt.forEach(t),guo=r(yAe," \u2014 "),RN=n(yAe,"A",{href:!0});var hlt=s(RN);huo=r(hlt,"ViTFeatureExtractor"),hlt.forEach(t),puo=r(yAe," (ViT model)"),yAe.forEach(t),_uo=i(K),ep=n(K,"LI",{});var xAe=s(ep);rie=n(xAe,"STRONG",{});var plt=s(rie);uuo=r(plt,"vit_mae"),plt.forEach(t),buo=r(xAe," \u2014 "),PN=n(xAe,"A",{href:!0});var _lt=s(PN);vuo=r(_lt,"ViTFeatureExtractor"),_lt.forEach(t),Fuo=r(xAe," (ViTMAE model)"),xAe.forEach(t),Tuo=i(K),op=n(K,"LI",{});var $Ae=s(op);tie=n($Ae,"STRONG",{});var ult=s(tie);Muo=r(ult,"wav2vec2"),ult.forEach(t),Euo=r($Ae," \u2014 "),BN=n($Ae,"A",{href:!0});var blt=s(BN);Cuo=r(blt,"Wav2Vec2FeatureExtractor"),blt.forEach(t),wuo=r($Ae," (Wav2Vec2 model)"),$Ae.forEach(t),Auo=i(K),rp=n(K,"LI",{});var kAe=s(rp);aie=n(kAe,"STRONG",{});var vlt=s(aie);Luo=r(vlt,"wav2vec2-conformer"),vlt.forEach(t),yuo=r(kAe," \u2014 "),IN=n(kAe,"A",{href:!0});var Flt=s(IN);xuo=r(Flt,"Wav2Vec2FeatureExtractor"),Flt.forEach(t),$uo=r(kAe," (Wav2Vec2-Conformer model)"),kAe.forEach(t),kuo=i(K),tp=n(K,"LI",{});var SAe=s(tp);nie=n(SAe,"STRONG",{});var Tlt=s(nie);Suo=r(Tlt,"yolos"),Tlt.forEach(t),Ruo=r(SAe," \u2014 "),NN=n(SAe,"A",{href:!0});var Mlt=s(NN);Puo=r(Mlt,"YolosFeatureExtractor"),Mlt.forEach(t),Buo=r(SAe," (YOLOS model)"),SAe.forEach(t),K.forEach(t),Iuo=i(ra),T(ap.$$.fragment,ra),Nuo=i(ra),T(np.$$.fragment,ra),ra.forEach(t),quo=i(Us),sp=n(Us,"DIV",{class:!0});var ZVe=s(sp);T(Hw.$$.fragment,ZVe),juo=i(ZVe),sie=n(ZVe,"P",{});var Elt=s(sie);Duo=r(Elt,"Register a new feature extractor for this class."),Elt.forEach(t),ZVe.forEach(t),Us.forEach(t),JGe=i(f),Ri=n(f,"H2",{class:!0});var eXe=s(Ri);lp=n(eXe,"A",{id:!0,class:!0,href:!0});var Clt=s(lp);lie=n(Clt,"SPAN",{});var wlt=s(lie);T(Uw.$$.fragment,wlt),wlt.forEach(t),Clt.forEach(t),Guo=i(eXe),iie=n(eXe,"SPAN",{});var Alt=s(iie);Ouo=r(Alt,"AutoProcessor"),Alt.forEach(t),eXe.forEach(t),YGe=i(f),yo=n(f,"DIV",{class:!0});var Js=s(yo);T(Jw.$$.fragment,Js),Vuo=i(Js),Yw=n(Js,"P",{});var oXe=s(Yw);Xuo=r(oXe,`This is a generic processor class that will be instantiated as one of the processor classes of the library when
created with the `),qN=n(oXe,"A",{href:!0});var Llt=s(qN);zuo=r(Llt,"AutoProcessor.from_pretrained()"),Llt.forEach(t),Quo=r(oXe," class method."),oXe.forEach(t),Wuo=i(Js),Kw=n(Js,"P",{});var rXe=s(Kw);Huo=r(rXe,"This class cannot be instantiated directly using "),die=n(rXe,"CODE",{});var ylt=s(die);Uuo=r(ylt,"__init__()"),ylt.forEach(t),Juo=r(rXe," (throws an error)."),rXe.forEach(t),Yuo=i(Js),Ue=n(Js,"DIV",{class:!0});var ta=s(Ue);T(Zw.$$.fragment,ta),Kuo=i(ta),cie=n(ta,"P",{});var xlt=s(cie);Zuo=r(xlt,"Instantiate one of the processor classes of the library from a pretrained model vocabulary."),xlt.forEach(t),e1o=i(ta),Pi=n(ta,"P",{});var boe=s(Pi);o1o=r(boe,"The processor class to instantiate is selected based on the "),fie=n(boe,"CODE",{});var $lt=s(fie);r1o=r($lt,"model_type"),$lt.forEach(t),t1o=r(boe,` property of the config object (either
passed as an argument or loaded from `),mie=n(boe,"CODE",{});var klt=s(mie);a1o=r(klt,"pretrained_model_name_or_path"),klt.forEach(t),n1o=r(boe," if possible):"),boe.forEach(t),s1o=i(ta),he=n(ta,"UL",{});var ue=s(he);ip=n(ue,"LI",{});var RAe=s(ip);gie=n(RAe,"STRONG",{});var Slt=s(gie);l1o=r(Slt,"clip"),Slt.forEach(t),i1o=r(RAe," \u2014 "),jN=n(RAe,"A",{href:!0});var Rlt=s(jN);d1o=r(Rlt,"CLIPProcessor"),Rlt.forEach(t),c1o=r(RAe," (CLIP model)"),RAe.forEach(t),f1o=i(ue),dp=n(ue,"LI",{});var PAe=s(dp);hie=n(PAe,"STRONG",{});var Plt=s(hie);m1o=r(Plt,"flava"),Plt.forEach(t),g1o=r(PAe," \u2014 "),pie=n(PAe,"CODE",{});var Blt=s(pie);h1o=r(Blt,"FLAVAProcessor"),Blt.forEach(t),p1o=r(PAe," (FLAVA model)"),PAe.forEach(t),_1o=i(ue),cp=n(ue,"LI",{});var BAe=s(cp);_ie=n(BAe,"STRONG",{});var Ilt=s(_ie);u1o=r(Ilt,"layoutlmv2"),Ilt.forEach(t),b1o=r(BAe," \u2014 "),DN=n(BAe,"A",{href:!0});var Nlt=s(DN);v1o=r(Nlt,"LayoutLMv2Processor"),Nlt.forEach(t),F1o=r(BAe," (LayoutLMv2 model)"),BAe.forEach(t),T1o=i(ue),fp=n(ue,"LI",{});var IAe=s(fp);uie=n(IAe,"STRONG",{});var qlt=s(uie);M1o=r(qlt,"layoutlmv3"),qlt.forEach(t),E1o=r(IAe," \u2014 "),GN=n(IAe,"A",{href:!0});var jlt=s(GN);C1o=r(jlt,"LayoutLMv3Processor"),jlt.forEach(t),w1o=r(IAe," (LayoutLMv3 model)"),IAe.forEach(t),A1o=i(ue),mp=n(ue,"LI",{});var NAe=s(mp);bie=n(NAe,"STRONG",{});var Dlt=s(bie);L1o=r(Dlt,"layoutxlm"),Dlt.forEach(t),y1o=r(NAe," \u2014 "),ON=n(NAe,"A",{href:!0});var Glt=s(ON);x1o=r(Glt,"LayoutXLMProcessor"),Glt.forEach(t),$1o=r(NAe," (LayoutXLM model)"),NAe.forEach(t),k1o=i(ue),gp=n(ue,"LI",{});var qAe=s(gp);vie=n(qAe,"STRONG",{});var Olt=s(vie);S1o=r(Olt,"sew"),Olt.forEach(t),R1o=r(qAe," \u2014 "),VN=n(qAe,"A",{href:!0});var Vlt=s(VN);P1o=r(Vlt,"Wav2Vec2Processor"),Vlt.forEach(t),B1o=r(qAe," (SEW model)"),qAe.forEach(t),I1o=i(ue),hp=n(ue,"LI",{});var jAe=s(hp);Fie=n(jAe,"STRONG",{});var Xlt=s(Fie);N1o=r(Xlt,"sew-d"),Xlt.forEach(t),q1o=r(jAe," \u2014 "),XN=n(jAe,"A",{href:!0});var zlt=s(XN);j1o=r(zlt,"Wav2Vec2Processor"),zlt.forEach(t),D1o=r(jAe," (SEW-D model)"),jAe.forEach(t),G1o=i(ue),pp=n(ue,"LI",{});var DAe=s(pp);Tie=n(DAe,"STRONG",{});var Qlt=s(Tie);O1o=r(Qlt,"speech_to_text"),Qlt.forEach(t),V1o=r(DAe," \u2014 "),zN=n(DAe,"A",{href:!0});var Wlt=s(zN);X1o=r(Wlt,"Speech2TextProcessor"),Wlt.forEach(t),z1o=r(DAe," (Speech2Text model)"),DAe.forEach(t),Q1o=i(ue),_p=n(ue,"LI",{});var GAe=s(_p);Mie=n(GAe,"STRONG",{});var Hlt=s(Mie);W1o=r(Hlt,"speech_to_text_2"),Hlt.forEach(t),H1o=r(GAe," \u2014 "),QN=n(GAe,"A",{href:!0});var Ult=s(QN);U1o=r(Ult,"Speech2Text2Processor"),Ult.forEach(t),J1o=r(GAe," (Speech2Text2 model)"),GAe.forEach(t),Y1o=i(ue),up=n(ue,"LI",{});var OAe=s(up);Eie=n(OAe,"STRONG",{});var Jlt=s(Eie);K1o=r(Jlt,"trocr"),Jlt.forEach(t),Z1o=r(OAe," \u2014 "),WN=n(OAe,"A",{href:!0});var Ylt=s(WN);e2o=r(Ylt,"TrOCRProcessor"),Ylt.forEach(t),o2o=r(OAe," (TrOCR model)"),OAe.forEach(t),r2o=i(ue),bp=n(ue,"LI",{});var VAe=s(bp);Cie=n(VAe,"STRONG",{});var Klt=s(Cie);t2o=r(Klt,"unispeech"),Klt.forEach(t),a2o=r(VAe," \u2014 "),HN=n(VAe,"A",{href:!0});var Zlt=s(HN);n2o=r(Zlt,"Wav2Vec2Processor"),Zlt.forEach(t),s2o=r(VAe," (UniSpeech model)"),VAe.forEach(t),l2o=i(ue),vp=n(ue,"LI",{});var XAe=s(vp);wie=n(XAe,"STRONG",{});var eit=s(wie);i2o=r(eit,"unispeech-sat"),eit.forEach(t),d2o=r(XAe," \u2014 "),UN=n(XAe,"A",{href:!0});var oit=s(UN);c2o=r(oit,"Wav2Vec2Processor"),oit.forEach(t),f2o=r(XAe," (UniSpeechSat model)"),XAe.forEach(t),m2o=i(ue),Fp=n(ue,"LI",{});var zAe=s(Fp);Aie=n(zAe,"STRONG",{});var rit=s(Aie);g2o=r(rit,"vilt"),rit.forEach(t),h2o=r(zAe," \u2014 "),JN=n(zAe,"A",{href:!0});var tit=s(JN);p2o=r(tit,"ViltProcessor"),tit.forEach(t),_2o=r(zAe," (ViLT model)"),zAe.forEach(t),u2o=i(ue),Tp=n(ue,"LI",{});var QAe=s(Tp);Lie=n(QAe,"STRONG",{});var ait=s(Lie);b2o=r(ait,"vision-text-dual-encoder"),ait.forEach(t),v2o=r(QAe," \u2014 "),YN=n(QAe,"A",{href:!0});var nit=s(YN);F2o=r(nit,"VisionTextDualEncoderProcessor"),nit.forEach(t),T2o=r(QAe," (VisionTextDualEncoder model)"),QAe.forEach(t),M2o=i(ue),Mp=n(ue,"LI",{});var WAe=s(Mp);yie=n(WAe,"STRONG",{});var sit=s(yie);E2o=r(sit,"wav2vec2"),sit.forEach(t),C2o=r(WAe," \u2014 "),KN=n(WAe,"A",{href:!0});var lit=s(KN);w2o=r(lit,"Wav2Vec2Processor"),lit.forEach(t),A2o=r(WAe," (Wav2Vec2 model)"),WAe.forEach(t),L2o=i(ue),Ep=n(ue,"LI",{});var HAe=s(Ep);xie=n(HAe,"STRONG",{});var iit=s(xie);y2o=r(iit,"wav2vec2-conformer"),iit.forEach(t),x2o=r(HAe," \u2014 "),ZN=n(HAe,"A",{href:!0});var dit=s(ZN);$2o=r(dit,"Wav2Vec2Processor"),dit.forEach(t),k2o=r(HAe," (Wav2Vec2-Conformer model)"),HAe.forEach(t),S2o=i(ue),Cp=n(ue,"LI",{});var UAe=s(Cp);$ie=n(UAe,"STRONG",{});var cit=s($ie);R2o=r(cit,"wavlm"),cit.forEach(t),P2o=r(UAe," \u2014 "),eq=n(UAe,"A",{href:!0});var fit=s(eq);B2o=r(fit,"Wav2Vec2Processor"),fit.forEach(t),I2o=r(UAe," (WavLM model)"),UAe.forEach(t),ue.forEach(t),N2o=i(ta),T(wp.$$.fragment,ta),q2o=i(ta),T(Ap.$$.fragment,ta),ta.forEach(t),j2o=i(Js),Lp=n(Js,"DIV",{class:!0});var tXe=s(Lp);T(eA.$$.fragment,tXe),D2o=i(tXe),kie=n(tXe,"P",{});var mit=s(kie);G2o=r(mit,"Register a new processor for this class."),mit.forEach(t),tXe.forEach(t),Js.forEach(t),KGe=i(f),Bi=n(f,"H2",{class:!0});var aXe=s(Bi);yp=n(aXe,"A",{id:!0,class:!0,href:!0});var git=s(yp);Sie=n(git,"SPAN",{});var hit=s(Sie);T(oA.$$.fragment,hit),hit.forEach(t),git.forEach(t),O2o=i(aXe),Rie=n(aXe,"SPAN",{});var pit=s(Rie);V2o=r(pit,"AutoModel"),pit.forEach(t),aXe.forEach(t),ZGe=i(f),xo=n(f,"DIV",{class:!0});var Ys=s(xo);T(rA.$$.fragment,Ys),X2o=i(Ys),Ii=n(Ys,"P",{});var voe=s(Ii);z2o=r(voe,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),oq=n(voe,"A",{href:!0});var _it=s(oq);Q2o=r(_it,"from_pretrained()"),_it.forEach(t),W2o=r(voe," class method or the "),rq=n(voe,"A",{href:!0});var uit=s(rq);H2o=r(uit,"from_config()"),uit.forEach(t),U2o=r(voe,` class
method.`),voe.forEach(t),J2o=i(Ys),tA=n(Ys,"P",{});var nXe=s(tA);Y2o=r(nXe,"This class cannot be instantiated directly using "),Pie=n(nXe,"CODE",{});var bit=s(Pie);K2o=r(bit,"__init__()"),bit.forEach(t),Z2o=r(nXe," (throws an error)."),nXe.forEach(t),ebo=i(Ys),nt=n(Ys,"DIV",{class:!0});var k3=s(nt);T(aA.$$.fragment,k3),obo=i(k3),Bie=n(k3,"P",{});var vit=s(Bie);rbo=r(vit,"Instantiates one of the base model classes of the library from a configuration."),vit.forEach(t),tbo=i(k3),Ni=n(k3,"P",{});var Foe=s(Ni);abo=r(Foe,`Note:
Loading a model from its configuration file does `),Iie=n(Foe,"STRONG",{});var Fit=s(Iie);nbo=r(Fit,"not"),Fit.forEach(t),sbo=r(Foe,` load the model weights. It only affects the
model\u2019s configuration. Use `),tq=n(Foe,"A",{href:!0});var Tit=s(tq);lbo=r(Tit,"from_pretrained()"),Tit.forEach(t),ibo=r(Foe," to load the model weights."),Foe.forEach(t),dbo=i(k3),T(xp.$$.fragment,k3),k3.forEach(t),cbo=i(Ys),Je=n(Ys,"DIV",{class:!0});var aa=s(Je);T(nA.$$.fragment,aa),fbo=i(aa),Nie=n(aa,"P",{});var Mit=s(Nie);mbo=r(Mit,"Instantiate one of the base model classes of the library from a pretrained model."),Mit.forEach(t),gbo=i(aa),Ra=n(aa,"P",{});var S3=s(Ra);hbo=r(S3,"The model class to instantiate is selected based on the "),qie=n(S3,"CODE",{});var Eit=s(qie);pbo=r(Eit,"model_type"),Eit.forEach(t),_bo=r(S3,` property of the config object (either
passed as an argument or loaded from `),jie=n(S3,"CODE",{});var Cit=s(jie);ubo=r(Cit,"pretrained_model_name_or_path"),Cit.forEach(t),bbo=r(S3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Die=n(S3,"CODE",{});var wit=s(Die);vbo=r(wit,"pretrained_model_name_or_path"),wit.forEach(t),Fbo=r(S3,":"),S3.forEach(t),Tbo=i(aa),y=n(aa,"UL",{});var $=s(y);$p=n($,"LI",{});var JAe=s($p);Gie=n(JAe,"STRONG",{});var Ait=s(Gie);Mbo=r(Ait,"albert"),Ait.forEach(t),Ebo=r(JAe," \u2014 "),aq=n(JAe,"A",{href:!0});var Lit=s(aq);Cbo=r(Lit,"AlbertModel"),Lit.forEach(t),wbo=r(JAe," (ALBERT model)"),JAe.forEach(t),Abo=i($),kp=n($,"LI",{});var YAe=s(kp);Oie=n(YAe,"STRONG",{});var yit=s(Oie);Lbo=r(yit,"bart"),yit.forEach(t),ybo=r(YAe," \u2014 "),nq=n(YAe,"A",{href:!0});var xit=s(nq);xbo=r(xit,"BartModel"),xit.forEach(t),$bo=r(YAe," (BART model)"),YAe.forEach(t),kbo=i($),Sp=n($,"LI",{});var KAe=s(Sp);Vie=n(KAe,"STRONG",{});var $it=s(Vie);Sbo=r($it,"beit"),$it.forEach(t),Rbo=r(KAe," \u2014 "),sq=n(KAe,"A",{href:!0});var kit=s(sq);Pbo=r(kit,"BeitModel"),kit.forEach(t),Bbo=r(KAe," (BEiT model)"),KAe.forEach(t),Ibo=i($),Rp=n($,"LI",{});var ZAe=s(Rp);Xie=n(ZAe,"STRONG",{});var Sit=s(Xie);Nbo=r(Sit,"bert"),Sit.forEach(t),qbo=r(ZAe," \u2014 "),lq=n(ZAe,"A",{href:!0});var Rit=s(lq);jbo=r(Rit,"BertModel"),Rit.forEach(t),Dbo=r(ZAe," (BERT model)"),ZAe.forEach(t),Gbo=i($),Pp=n($,"LI",{});var eLe=s(Pp);zie=n(eLe,"STRONG",{});var Pit=s(zie);Obo=r(Pit,"bert-generation"),Pit.forEach(t),Vbo=r(eLe," \u2014 "),iq=n(eLe,"A",{href:!0});var Bit=s(iq);Xbo=r(Bit,"BertGenerationEncoder"),Bit.forEach(t),zbo=r(eLe," (Bert Generation model)"),eLe.forEach(t),Qbo=i($),Bp=n($,"LI",{});var oLe=s(Bp);Qie=n(oLe,"STRONG",{});var Iit=s(Qie);Wbo=r(Iit,"big_bird"),Iit.forEach(t),Hbo=r(oLe," \u2014 "),dq=n(oLe,"A",{href:!0});var Nit=s(dq);Ubo=r(Nit,"BigBirdModel"),Nit.forEach(t),Jbo=r(oLe," (BigBird model)"),oLe.forEach(t),Ybo=i($),Ip=n($,"LI",{});var rLe=s(Ip);Wie=n(rLe,"STRONG",{});var qit=s(Wie);Kbo=r(qit,"bigbird_pegasus"),qit.forEach(t),Zbo=r(rLe," \u2014 "),cq=n(rLe,"A",{href:!0});var jit=s(cq);evo=r(jit,"BigBirdPegasusModel"),jit.forEach(t),ovo=r(rLe," (BigBird-Pegasus model)"),rLe.forEach(t),rvo=i($),Np=n($,"LI",{});var tLe=s(Np);Hie=n(tLe,"STRONG",{});var Dit=s(Hie);tvo=r(Dit,"blenderbot"),Dit.forEach(t),avo=r(tLe," \u2014 "),fq=n(tLe,"A",{href:!0});var Git=s(fq);nvo=r(Git,"BlenderbotModel"),Git.forEach(t),svo=r(tLe," (Blenderbot model)"),tLe.forEach(t),lvo=i($),qp=n($,"LI",{});var aLe=s(qp);Uie=n(aLe,"STRONG",{});var Oit=s(Uie);ivo=r(Oit,"blenderbot-small"),Oit.forEach(t),dvo=r(aLe," \u2014 "),mq=n(aLe,"A",{href:!0});var Vit=s(mq);cvo=r(Vit,"BlenderbotSmallModel"),Vit.forEach(t),fvo=r(aLe," (BlenderbotSmall model)"),aLe.forEach(t),mvo=i($),jp=n($,"LI",{});var nLe=s(jp);Jie=n(nLe,"STRONG",{});var Xit=s(Jie);gvo=r(Xit,"bloom"),Xit.forEach(t),hvo=r(nLe," \u2014 "),gq=n(nLe,"A",{href:!0});var zit=s(gq);pvo=r(zit,"BloomModel"),zit.forEach(t),_vo=r(nLe," (BLOOM model)"),nLe.forEach(t),uvo=i($),Dp=n($,"LI",{});var sLe=s(Dp);Yie=n(sLe,"STRONG",{});var Qit=s(Yie);bvo=r(Qit,"camembert"),Qit.forEach(t),vvo=r(sLe," \u2014 "),hq=n(sLe,"A",{href:!0});var Wit=s(hq);Fvo=r(Wit,"CamembertModel"),Wit.forEach(t),Tvo=r(sLe," (CamemBERT model)"),sLe.forEach(t),Mvo=i($),Gp=n($,"LI",{});var lLe=s(Gp);Kie=n(lLe,"STRONG",{});var Hit=s(Kie);Evo=r(Hit,"canine"),Hit.forEach(t),Cvo=r(lLe," \u2014 "),pq=n(lLe,"A",{href:!0});var Uit=s(pq);wvo=r(Uit,"CanineModel"),Uit.forEach(t),Avo=r(lLe," (CANINE model)"),lLe.forEach(t),Lvo=i($),Op=n($,"LI",{});var iLe=s(Op);Zie=n(iLe,"STRONG",{});var Jit=s(Zie);yvo=r(Jit,"clip"),Jit.forEach(t),xvo=r(iLe," \u2014 "),_q=n(iLe,"A",{href:!0});var Yit=s(_q);$vo=r(Yit,"CLIPModel"),Yit.forEach(t),kvo=r(iLe," (CLIP model)"),iLe.forEach(t),Svo=i($),Vp=n($,"LI",{});var dLe=s(Vp);ede=n(dLe,"STRONG",{});var Kit=s(ede);Rvo=r(Kit,"convbert"),Kit.forEach(t),Pvo=r(dLe," \u2014 "),uq=n(dLe,"A",{href:!0});var Zit=s(uq);Bvo=r(Zit,"ConvBertModel"),Zit.forEach(t),Ivo=r(dLe," (ConvBERT model)"),dLe.forEach(t),Nvo=i($),Xp=n($,"LI",{});var cLe=s(Xp);ode=n(cLe,"STRONG",{});var edt=s(ode);qvo=r(edt,"convnext"),edt.forEach(t),jvo=r(cLe," \u2014 "),bq=n(cLe,"A",{href:!0});var odt=s(bq);Dvo=r(odt,"ConvNextModel"),odt.forEach(t),Gvo=r(cLe," (ConvNeXT model)"),cLe.forEach(t),Ovo=i($),zp=n($,"LI",{});var fLe=s(zp);rde=n(fLe,"STRONG",{});var rdt=s(rde);Vvo=r(rdt,"ctrl"),rdt.forEach(t),Xvo=r(fLe," \u2014 "),vq=n(fLe,"A",{href:!0});var tdt=s(vq);zvo=r(tdt,"CTRLModel"),tdt.forEach(t),Qvo=r(fLe," (CTRL model)"),fLe.forEach(t),Wvo=i($),Qp=n($,"LI",{});var mLe=s(Qp);tde=n(mLe,"STRONG",{});var adt=s(tde);Hvo=r(adt,"cvt"),adt.forEach(t),Uvo=r(mLe," \u2014 "),Fq=n(mLe,"A",{href:!0});var ndt=s(Fq);Jvo=r(ndt,"CvtModel"),ndt.forEach(t),Yvo=r(mLe," (CvT model)"),mLe.forEach(t),Kvo=i($),Wp=n($,"LI",{});var gLe=s(Wp);ade=n(gLe,"STRONG",{});var sdt=s(ade);Zvo=r(sdt,"data2vec-audio"),sdt.forEach(t),eFo=r(gLe," \u2014 "),Tq=n(gLe,"A",{href:!0});var ldt=s(Tq);oFo=r(ldt,"Data2VecAudioModel"),ldt.forEach(t),rFo=r(gLe," (Data2VecAudio model)"),gLe.forEach(t),tFo=i($),Hp=n($,"LI",{});var hLe=s(Hp);nde=n(hLe,"STRONG",{});var idt=s(nde);aFo=r(idt,"data2vec-text"),idt.forEach(t),nFo=r(hLe," \u2014 "),Mq=n(hLe,"A",{href:!0});var ddt=s(Mq);sFo=r(ddt,"Data2VecTextModel"),ddt.forEach(t),lFo=r(hLe," (Data2VecText model)"),hLe.forEach(t),iFo=i($),Up=n($,"LI",{});var pLe=s(Up);sde=n(pLe,"STRONG",{});var cdt=s(sde);dFo=r(cdt,"data2vec-vision"),cdt.forEach(t),cFo=r(pLe," \u2014 "),Eq=n(pLe,"A",{href:!0});var fdt=s(Eq);fFo=r(fdt,"Data2VecVisionModel"),fdt.forEach(t),mFo=r(pLe," (Data2VecVision model)"),pLe.forEach(t),gFo=i($),Jp=n($,"LI",{});var _Le=s(Jp);lde=n(_Le,"STRONG",{});var mdt=s(lde);hFo=r(mdt,"deberta"),mdt.forEach(t),pFo=r(_Le," \u2014 "),Cq=n(_Le,"A",{href:!0});var gdt=s(Cq);_Fo=r(gdt,"DebertaModel"),gdt.forEach(t),uFo=r(_Le," (DeBERTa model)"),_Le.forEach(t),bFo=i($),Yp=n($,"LI",{});var uLe=s(Yp);ide=n(uLe,"STRONG",{});var hdt=s(ide);vFo=r(hdt,"deberta-v2"),hdt.forEach(t),FFo=r(uLe," \u2014 "),wq=n(uLe,"A",{href:!0});var pdt=s(wq);TFo=r(pdt,"DebertaV2Model"),pdt.forEach(t),MFo=r(uLe," (DeBERTa-v2 model)"),uLe.forEach(t),EFo=i($),Kp=n($,"LI",{});var bLe=s(Kp);dde=n(bLe,"STRONG",{});var _dt=s(dde);CFo=r(_dt,"decision_transformer"),_dt.forEach(t),wFo=r(bLe," \u2014 "),Aq=n(bLe,"A",{href:!0});var udt=s(Aq);AFo=r(udt,"DecisionTransformerModel"),udt.forEach(t),LFo=r(bLe," (Decision Transformer model)"),bLe.forEach(t),yFo=i($),Zp=n($,"LI",{});var vLe=s(Zp);cde=n(vLe,"STRONG",{});var bdt=s(cde);xFo=r(bdt,"deit"),bdt.forEach(t),$Fo=r(vLe," \u2014 "),Lq=n(vLe,"A",{href:!0});var vdt=s(Lq);kFo=r(vdt,"DeiTModel"),vdt.forEach(t),SFo=r(vLe," (DeiT model)"),vLe.forEach(t),RFo=i($),e_=n($,"LI",{});var FLe=s(e_);fde=n(FLe,"STRONG",{});var Fdt=s(fde);PFo=r(Fdt,"detr"),Fdt.forEach(t),BFo=r(FLe," \u2014 "),yq=n(FLe,"A",{href:!0});var Tdt=s(yq);IFo=r(Tdt,"DetrModel"),Tdt.forEach(t),NFo=r(FLe," (DETR model)"),FLe.forEach(t),qFo=i($),o_=n($,"LI",{});var TLe=s(o_);mde=n(TLe,"STRONG",{});var Mdt=s(mde);jFo=r(Mdt,"distilbert"),Mdt.forEach(t),DFo=r(TLe," \u2014 "),xq=n(TLe,"A",{href:!0});var Edt=s(xq);GFo=r(Edt,"DistilBertModel"),Edt.forEach(t),OFo=r(TLe," (DistilBERT model)"),TLe.forEach(t),VFo=i($),r_=n($,"LI",{});var MLe=s(r_);gde=n(MLe,"STRONG",{});var Cdt=s(gde);XFo=r(Cdt,"dpr"),Cdt.forEach(t),zFo=r(MLe," \u2014 "),$q=n(MLe,"A",{href:!0});var wdt=s($q);QFo=r(wdt,"DPRQuestionEncoder"),wdt.forEach(t),WFo=r(MLe," (DPR model)"),MLe.forEach(t),HFo=i($),t_=n($,"LI",{});var ELe=s(t_);hde=n(ELe,"STRONG",{});var Adt=s(hde);UFo=r(Adt,"dpt"),Adt.forEach(t),JFo=r(ELe," \u2014 "),kq=n(ELe,"A",{href:!0});var Ldt=s(kq);YFo=r(Ldt,"DPTModel"),Ldt.forEach(t),KFo=r(ELe," (DPT model)"),ELe.forEach(t),ZFo=i($),a_=n($,"LI",{});var CLe=s(a_);pde=n(CLe,"STRONG",{});var ydt=s(pde);e6o=r(ydt,"electra"),ydt.forEach(t),o6o=r(CLe," \u2014 "),Sq=n(CLe,"A",{href:!0});var xdt=s(Sq);r6o=r(xdt,"ElectraModel"),xdt.forEach(t),t6o=r(CLe," (ELECTRA model)"),CLe.forEach(t),a6o=i($),n_=n($,"LI",{});var wLe=s(n_);_de=n(wLe,"STRONG",{});var $dt=s(_de);n6o=r($dt,"flaubert"),$dt.forEach(t),s6o=r(wLe," \u2014 "),Rq=n(wLe,"A",{href:!0});var kdt=s(Rq);l6o=r(kdt,"FlaubertModel"),kdt.forEach(t),i6o=r(wLe," (FlauBERT model)"),wLe.forEach(t),d6o=i($),s_=n($,"LI",{});var ALe=s(s_);ude=n(ALe,"STRONG",{});var Sdt=s(ude);c6o=r(Sdt,"flava"),Sdt.forEach(t),f6o=r(ALe," \u2014 "),Pq=n(ALe,"A",{href:!0});var Rdt=s(Pq);m6o=r(Rdt,"FlavaModel"),Rdt.forEach(t),g6o=r(ALe," (FLAVA model)"),ALe.forEach(t),h6o=i($),l_=n($,"LI",{});var LLe=s(l_);bde=n(LLe,"STRONG",{});var Pdt=s(bde);p6o=r(Pdt,"fnet"),Pdt.forEach(t),_6o=r(LLe," \u2014 "),Bq=n(LLe,"A",{href:!0});var Bdt=s(Bq);u6o=r(Bdt,"FNetModel"),Bdt.forEach(t),b6o=r(LLe," (FNet model)"),LLe.forEach(t),v6o=i($),i_=n($,"LI",{});var yLe=s(i_);vde=n(yLe,"STRONG",{});var Idt=s(vde);F6o=r(Idt,"fsmt"),Idt.forEach(t),T6o=r(yLe," \u2014 "),Iq=n(yLe,"A",{href:!0});var Ndt=s(Iq);M6o=r(Ndt,"FSMTModel"),Ndt.forEach(t),E6o=r(yLe," (FairSeq Machine-Translation model)"),yLe.forEach(t),C6o=i($),Vs=n($,"LI",{});var Kk=s(Vs);Fde=n(Kk,"STRONG",{});var qdt=s(Fde);w6o=r(qdt,"funnel"),qdt.forEach(t),A6o=r(Kk," \u2014 "),Nq=n(Kk,"A",{href:!0});var jdt=s(Nq);L6o=r(jdt,"FunnelModel"),jdt.forEach(t),y6o=r(Kk," or "),qq=n(Kk,"A",{href:!0});var Ddt=s(qq);x6o=r(Ddt,"FunnelBaseModel"),Ddt.forEach(t),$6o=r(Kk," (Funnel Transformer model)"),Kk.forEach(t),k6o=i($),d_=n($,"LI",{});var xLe=s(d_);Tde=n(xLe,"STRONG",{});var Gdt=s(Tde);S6o=r(Gdt,"glpn"),Gdt.forEach(t),R6o=r(xLe," \u2014 "),jq=n(xLe,"A",{href:!0});var Odt=s(jq);P6o=r(Odt,"GLPNModel"),Odt.forEach(t),B6o=r(xLe," (GLPN model)"),xLe.forEach(t),I6o=i($),c_=n($,"LI",{});var $Le=s(c_);Mde=n($Le,"STRONG",{});var Vdt=s(Mde);N6o=r(Vdt,"gpt2"),Vdt.forEach(t),q6o=r($Le," \u2014 "),Dq=n($Le,"A",{href:!0});var Xdt=s(Dq);j6o=r(Xdt,"GPT2Model"),Xdt.forEach(t),D6o=r($Le," (OpenAI GPT-2 model)"),$Le.forEach(t),G6o=i($),f_=n($,"LI",{});var kLe=s(f_);Ede=n(kLe,"STRONG",{});var zdt=s(Ede);O6o=r(zdt,"gpt_neo"),zdt.forEach(t),V6o=r(kLe," \u2014 "),Gq=n(kLe,"A",{href:!0});var Qdt=s(Gq);X6o=r(Qdt,"GPTNeoModel"),Qdt.forEach(t),z6o=r(kLe," (GPT Neo model)"),kLe.forEach(t),Q6o=i($),m_=n($,"LI",{});var SLe=s(m_);Cde=n(SLe,"STRONG",{});var Wdt=s(Cde);W6o=r(Wdt,"gpt_neox"),Wdt.forEach(t),H6o=r(SLe," \u2014 "),Oq=n(SLe,"A",{href:!0});var Hdt=s(Oq);U6o=r(Hdt,"GPTNeoXModel"),Hdt.forEach(t),J6o=r(SLe," (GPT NeoX model)"),SLe.forEach(t),Y6o=i($),g_=n($,"LI",{});var RLe=s(g_);wde=n(RLe,"STRONG",{});var Udt=s(wde);K6o=r(Udt,"gptj"),Udt.forEach(t),Z6o=r(RLe," \u2014 "),Vq=n(RLe,"A",{href:!0});var Jdt=s(Vq);eTo=r(Jdt,"GPTJModel"),Jdt.forEach(t),oTo=r(RLe," (GPT-J model)"),RLe.forEach(t),rTo=i($),h_=n($,"LI",{});var PLe=s(h_);Ade=n(PLe,"STRONG",{});var Ydt=s(Ade);tTo=r(Ydt,"hubert"),Ydt.forEach(t),aTo=r(PLe," \u2014 "),Xq=n(PLe,"A",{href:!0});var Kdt=s(Xq);nTo=r(Kdt,"HubertModel"),Kdt.forEach(t),sTo=r(PLe," (Hubert model)"),PLe.forEach(t),lTo=i($),p_=n($,"LI",{});var BLe=s(p_);Lde=n(BLe,"STRONG",{});var Zdt=s(Lde);iTo=r(Zdt,"ibert"),Zdt.forEach(t),dTo=r(BLe," \u2014 "),zq=n(BLe,"A",{href:!0});var ect=s(zq);cTo=r(ect,"IBertModel"),ect.forEach(t),fTo=r(BLe," (I-BERT model)"),BLe.forEach(t),mTo=i($),__=n($,"LI",{});var ILe=s(__);yde=n(ILe,"STRONG",{});var oct=s(yde);gTo=r(oct,"imagegpt"),oct.forEach(t),hTo=r(ILe," \u2014 "),Qq=n(ILe,"A",{href:!0});var rct=s(Qq);pTo=r(rct,"ImageGPTModel"),rct.forEach(t),_To=r(ILe," (ImageGPT model)"),ILe.forEach(t),uTo=i($),u_=n($,"LI",{});var NLe=s(u_);xde=n(NLe,"STRONG",{});var tct=s(xde);bTo=r(tct,"layoutlm"),tct.forEach(t),vTo=r(NLe," \u2014 "),Wq=n(NLe,"A",{href:!0});var act=s(Wq);FTo=r(act,"LayoutLMModel"),act.forEach(t),TTo=r(NLe," (LayoutLM model)"),NLe.forEach(t),MTo=i($),b_=n($,"LI",{});var qLe=s(b_);$de=n(qLe,"STRONG",{});var nct=s($de);ETo=r(nct,"layoutlmv2"),nct.forEach(t),CTo=r(qLe," \u2014 "),Hq=n(qLe,"A",{href:!0});var sct=s(Hq);wTo=r(sct,"LayoutLMv2Model"),sct.forEach(t),ATo=r(qLe," (LayoutLMv2 model)"),qLe.forEach(t),LTo=i($),v_=n($,"LI",{});var jLe=s(v_);kde=n(jLe,"STRONG",{});var lct=s(kde);yTo=r(lct,"layoutlmv3"),lct.forEach(t),xTo=r(jLe," \u2014 "),Uq=n(jLe,"A",{href:!0});var ict=s(Uq);$To=r(ict,"LayoutLMv3Model"),ict.forEach(t),kTo=r(jLe," (LayoutLMv3 model)"),jLe.forEach(t),STo=i($),F_=n($,"LI",{});var DLe=s(F_);Sde=n(DLe,"STRONG",{});var dct=s(Sde);RTo=r(dct,"led"),dct.forEach(t),PTo=r(DLe," \u2014 "),Jq=n(DLe,"A",{href:!0});var cct=s(Jq);BTo=r(cct,"LEDModel"),cct.forEach(t),ITo=r(DLe," (LED model)"),DLe.forEach(t),NTo=i($),T_=n($,"LI",{});var GLe=s(T_);Rde=n(GLe,"STRONG",{});var fct=s(Rde);qTo=r(fct,"levit"),fct.forEach(t),jTo=r(GLe," \u2014 "),Yq=n(GLe,"A",{href:!0});var mct=s(Yq);DTo=r(mct,"LevitModel"),mct.forEach(t),GTo=r(GLe," (LeViT model)"),GLe.forEach(t),OTo=i($),M_=n($,"LI",{});var OLe=s(M_);Pde=n(OLe,"STRONG",{});var gct=s(Pde);VTo=r(gct,"longformer"),gct.forEach(t),XTo=r(OLe," \u2014 "),Kq=n(OLe,"A",{href:!0});var hct=s(Kq);zTo=r(hct,"LongformerModel"),hct.forEach(t),QTo=r(OLe," (Longformer model)"),OLe.forEach(t),WTo=i($),E_=n($,"LI",{});var VLe=s(E_);Bde=n(VLe,"STRONG",{});var pct=s(Bde);HTo=r(pct,"longt5"),pct.forEach(t),UTo=r(VLe," \u2014 "),Zq=n(VLe,"A",{href:!0});var _ct=s(Zq);JTo=r(_ct,"LongT5Model"),_ct.forEach(t),YTo=r(VLe," (LongT5 model)"),VLe.forEach(t),KTo=i($),C_=n($,"LI",{});var XLe=s(C_);Ide=n(XLe,"STRONG",{});var uct=s(Ide);ZTo=r(uct,"luke"),uct.forEach(t),e7o=r(XLe," \u2014 "),ej=n(XLe,"A",{href:!0});var bct=s(ej);o7o=r(bct,"LukeModel"),bct.forEach(t),r7o=r(XLe," (LUKE model)"),XLe.forEach(t),t7o=i($),w_=n($,"LI",{});var zLe=s(w_);Nde=n(zLe,"STRONG",{});var vct=s(Nde);a7o=r(vct,"lxmert"),vct.forEach(t),n7o=r(zLe," \u2014 "),oj=n(zLe,"A",{href:!0});var Fct=s(oj);s7o=r(Fct,"LxmertModel"),Fct.forEach(t),l7o=r(zLe," (LXMERT model)"),zLe.forEach(t),i7o=i($),A_=n($,"LI",{});var QLe=s(A_);qde=n(QLe,"STRONG",{});var Tct=s(qde);d7o=r(Tct,"m2m_100"),Tct.forEach(t),c7o=r(QLe," \u2014 "),rj=n(QLe,"A",{href:!0});var Mct=s(rj);f7o=r(Mct,"M2M100Model"),Mct.forEach(t),m7o=r(QLe," (M2M100 model)"),QLe.forEach(t),g7o=i($),L_=n($,"LI",{});var WLe=s(L_);jde=n(WLe,"STRONG",{});var Ect=s(jde);h7o=r(Ect,"marian"),Ect.forEach(t),p7o=r(WLe," \u2014 "),tj=n(WLe,"A",{href:!0});var Cct=s(tj);_7o=r(Cct,"MarianModel"),Cct.forEach(t),u7o=r(WLe," (Marian model)"),WLe.forEach(t),b7o=i($),y_=n($,"LI",{});var HLe=s(y_);Dde=n(HLe,"STRONG",{});var wct=s(Dde);v7o=r(wct,"maskformer"),wct.forEach(t),F7o=r(HLe," \u2014 "),aj=n(HLe,"A",{href:!0});var Act=s(aj);T7o=r(Act,"MaskFormerModel"),Act.forEach(t),M7o=r(HLe," (MaskFormer model)"),HLe.forEach(t),E7o=i($),x_=n($,"LI",{});var ULe=s(x_);Gde=n(ULe,"STRONG",{});var Lct=s(Gde);C7o=r(Lct,"mbart"),Lct.forEach(t),w7o=r(ULe," \u2014 "),nj=n(ULe,"A",{href:!0});var yct=s(nj);A7o=r(yct,"MBartModel"),yct.forEach(t),L7o=r(ULe," (mBART model)"),ULe.forEach(t),y7o=i($),$_=n($,"LI",{});var JLe=s($_);Ode=n(JLe,"STRONG",{});var xct=s(Ode);x7o=r(xct,"mctct"),xct.forEach(t),$7o=r(JLe," \u2014 "),sj=n(JLe,"A",{href:!0});var $ct=s(sj);k7o=r($ct,"MCTCTModel"),$ct.forEach(t),S7o=r(JLe," (M-CTC-T model)"),JLe.forEach(t),R7o=i($),k_=n($,"LI",{});var YLe=s(k_);Vde=n(YLe,"STRONG",{});var kct=s(Vde);P7o=r(kct,"megatron-bert"),kct.forEach(t),B7o=r(YLe," \u2014 "),lj=n(YLe,"A",{href:!0});var Sct=s(lj);I7o=r(Sct,"MegatronBertModel"),Sct.forEach(t),N7o=r(YLe," (Megatron-BERT model)"),YLe.forEach(t),q7o=i($),S_=n($,"LI",{});var KLe=s(S_);Xde=n(KLe,"STRONG",{});var Rct=s(Xde);j7o=r(Rct,"mobilebert"),Rct.forEach(t),D7o=r(KLe," \u2014 "),ij=n(KLe,"A",{href:!0});var Pct=s(ij);G7o=r(Pct,"MobileBertModel"),Pct.forEach(t),O7o=r(KLe," (MobileBERT model)"),KLe.forEach(t),V7o=i($),R_=n($,"LI",{});var ZLe=s(R_);zde=n(ZLe,"STRONG",{});var Bct=s(zde);X7o=r(Bct,"mpnet"),Bct.forEach(t),z7o=r(ZLe," \u2014 "),dj=n(ZLe,"A",{href:!0});var Ict=s(dj);Q7o=r(Ict,"MPNetModel"),Ict.forEach(t),W7o=r(ZLe," (MPNet model)"),ZLe.forEach(t),H7o=i($),P_=n($,"LI",{});var eye=s(P_);Qde=n(eye,"STRONG",{});var Nct=s(Qde);U7o=r(Nct,"mt5"),Nct.forEach(t),J7o=r(eye," \u2014 "),cj=n(eye,"A",{href:!0});var qct=s(cj);Y7o=r(qct,"MT5Model"),qct.forEach(t),K7o=r(eye," (MT5 model)"),eye.forEach(t),Z7o=i($),B_=n($,"LI",{});var oye=s(B_);Wde=n(oye,"STRONG",{});var jct=s(Wde);e8o=r(jct,"nezha"),jct.forEach(t),o8o=r(oye," \u2014 "),fj=n(oye,"A",{href:!0});var Dct=s(fj);r8o=r(Dct,"NezhaModel"),Dct.forEach(t),t8o=r(oye," (Nezha model)"),oye.forEach(t),a8o=i($),I_=n($,"LI",{});var rye=s(I_);Hde=n(rye,"STRONG",{});var Gct=s(Hde);n8o=r(Gct,"nystromformer"),Gct.forEach(t),s8o=r(rye," \u2014 "),mj=n(rye,"A",{href:!0});var Oct=s(mj);l8o=r(Oct,"NystromformerModel"),Oct.forEach(t),i8o=r(rye," (Nystr\xF6mformer model)"),rye.forEach(t),d8o=i($),N_=n($,"LI",{});var tye=s(N_);Ude=n(tye,"STRONG",{});var Vct=s(Ude);c8o=r(Vct,"openai-gpt"),Vct.forEach(t),f8o=r(tye," \u2014 "),gj=n(tye,"A",{href:!0});var Xct=s(gj);m8o=r(Xct,"OpenAIGPTModel"),Xct.forEach(t),g8o=r(tye," (OpenAI GPT model)"),tye.forEach(t),h8o=i($),q_=n($,"LI",{});var aye=s(q_);Jde=n(aye,"STRONG",{});var zct=s(Jde);p8o=r(zct,"opt"),zct.forEach(t),_8o=r(aye," \u2014 "),hj=n(aye,"A",{href:!0});var Qct=s(hj);u8o=r(Qct,"OPTModel"),Qct.forEach(t),b8o=r(aye," (OPT model)"),aye.forEach(t),v8o=i($),j_=n($,"LI",{});var nye=s(j_);Yde=n(nye,"STRONG",{});var Wct=s(Yde);F8o=r(Wct,"pegasus"),Wct.forEach(t),T8o=r(nye," \u2014 "),pj=n(nye,"A",{href:!0});var Hct=s(pj);M8o=r(Hct,"PegasusModel"),Hct.forEach(t),E8o=r(nye," (Pegasus model)"),nye.forEach(t),C8o=i($),D_=n($,"LI",{});var sye=s(D_);Kde=n(sye,"STRONG",{});var Uct=s(Kde);w8o=r(Uct,"perceiver"),Uct.forEach(t),A8o=r(sye," \u2014 "),_j=n(sye,"A",{href:!0});var Jct=s(_j);L8o=r(Jct,"PerceiverModel"),Jct.forEach(t),y8o=r(sye," (Perceiver model)"),sye.forEach(t),x8o=i($),G_=n($,"LI",{});var lye=s(G_);Zde=n(lye,"STRONG",{});var Yct=s(Zde);$8o=r(Yct,"plbart"),Yct.forEach(t),k8o=r(lye," \u2014 "),uj=n(lye,"A",{href:!0});var Kct=s(uj);S8o=r(Kct,"PLBartModel"),Kct.forEach(t),R8o=r(lye," (PLBart model)"),lye.forEach(t),P8o=i($),O_=n($,"LI",{});var iye=s(O_);ece=n(iye,"STRONG",{});var Zct=s(ece);B8o=r(Zct,"poolformer"),Zct.forEach(t),I8o=r(iye," \u2014 "),bj=n(iye,"A",{href:!0});var eft=s(bj);N8o=r(eft,"PoolFormerModel"),eft.forEach(t),q8o=r(iye," (PoolFormer model)"),iye.forEach(t),j8o=i($),V_=n($,"LI",{});var dye=s(V_);oce=n(dye,"STRONG",{});var oft=s(oce);D8o=r(oft,"prophetnet"),oft.forEach(t),G8o=r(dye," \u2014 "),vj=n(dye,"A",{href:!0});var rft=s(vj);O8o=r(rft,"ProphetNetModel"),rft.forEach(t),V8o=r(dye," (ProphetNet model)"),dye.forEach(t),X8o=i($),X_=n($,"LI",{});var cye=s(X_);rce=n(cye,"STRONG",{});var tft=s(rce);z8o=r(tft,"qdqbert"),tft.forEach(t),Q8o=r(cye," \u2014 "),Fj=n(cye,"A",{href:!0});var aft=s(Fj);W8o=r(aft,"QDQBertModel"),aft.forEach(t),H8o=r(cye," (QDQBert model)"),cye.forEach(t),U8o=i($),z_=n($,"LI",{});var fye=s(z_);tce=n(fye,"STRONG",{});var nft=s(tce);J8o=r(nft,"reformer"),nft.forEach(t),Y8o=r(fye," \u2014 "),Tj=n(fye,"A",{href:!0});var sft=s(Tj);K8o=r(sft,"ReformerModel"),sft.forEach(t),Z8o=r(fye," (Reformer model)"),fye.forEach(t),e9o=i($),Q_=n($,"LI",{});var mye=s(Q_);ace=n(mye,"STRONG",{});var lft=s(ace);o9o=r(lft,"regnet"),lft.forEach(t),r9o=r(mye," \u2014 "),Mj=n(mye,"A",{href:!0});var ift=s(Mj);t9o=r(ift,"RegNetModel"),ift.forEach(t),a9o=r(mye," (RegNet model)"),mye.forEach(t),n9o=i($),W_=n($,"LI",{});var gye=s(W_);nce=n(gye,"STRONG",{});var dft=s(nce);s9o=r(dft,"rembert"),dft.forEach(t),l9o=r(gye," \u2014 "),Ej=n(gye,"A",{href:!0});var cft=s(Ej);i9o=r(cft,"RemBertModel"),cft.forEach(t),d9o=r(gye," (RemBERT model)"),gye.forEach(t),c9o=i($),H_=n($,"LI",{});var hye=s(H_);sce=n(hye,"STRONG",{});var fft=s(sce);f9o=r(fft,"resnet"),fft.forEach(t),m9o=r(hye," \u2014 "),Cj=n(hye,"A",{href:!0});var mft=s(Cj);g9o=r(mft,"ResNetModel"),mft.forEach(t),h9o=r(hye," (ResNet model)"),hye.forEach(t),p9o=i($),U_=n($,"LI",{});var pye=s(U_);lce=n(pye,"STRONG",{});var gft=s(lce);_9o=r(gft,"retribert"),gft.forEach(t),u9o=r(pye," \u2014 "),wj=n(pye,"A",{href:!0});var hft=s(wj);b9o=r(hft,"RetriBertModel"),hft.forEach(t),v9o=r(pye," (RetriBERT model)"),pye.forEach(t),F9o=i($),J_=n($,"LI",{});var _ye=s(J_);ice=n(_ye,"STRONG",{});var pft=s(ice);T9o=r(pft,"roberta"),pft.forEach(t),M9o=r(_ye," \u2014 "),Aj=n(_ye,"A",{href:!0});var _ft=s(Aj);E9o=r(_ft,"RobertaModel"),_ft.forEach(t),C9o=r(_ye," (RoBERTa model)"),_ye.forEach(t),w9o=i($),Y_=n($,"LI",{});var uye=s(Y_);dce=n(uye,"STRONG",{});var uft=s(dce);A9o=r(uft,"roformer"),uft.forEach(t),L9o=r(uye," \u2014 "),Lj=n(uye,"A",{href:!0});var bft=s(Lj);y9o=r(bft,"RoFormerModel"),bft.forEach(t),x9o=r(uye," (RoFormer model)"),uye.forEach(t),$9o=i($),K_=n($,"LI",{});var bye=s(K_);cce=n(bye,"STRONG",{});var vft=s(cce);k9o=r(vft,"segformer"),vft.forEach(t),S9o=r(bye," \u2014 "),yj=n(bye,"A",{href:!0});var Fft=s(yj);R9o=r(Fft,"SegformerModel"),Fft.forEach(t),P9o=r(bye," (SegFormer model)"),bye.forEach(t),B9o=i($),Z_=n($,"LI",{});var vye=s(Z_);fce=n(vye,"STRONG",{});var Tft=s(fce);I9o=r(Tft,"sew"),Tft.forEach(t),N9o=r(vye," \u2014 "),xj=n(vye,"A",{href:!0});var Mft=s(xj);q9o=r(Mft,"SEWModel"),Mft.forEach(t),j9o=r(vye," (SEW model)"),vye.forEach(t),D9o=i($),eu=n($,"LI",{});var Fye=s(eu);mce=n(Fye,"STRONG",{});var Eft=s(mce);G9o=r(Eft,"sew-d"),Eft.forEach(t),O9o=r(Fye," \u2014 "),$j=n(Fye,"A",{href:!0});var Cft=s($j);V9o=r(Cft,"SEWDModel"),Cft.forEach(t),X9o=r(Fye," (SEW-D model)"),Fye.forEach(t),z9o=i($),ou=n($,"LI",{});var Tye=s(ou);gce=n(Tye,"STRONG",{});var wft=s(gce);Q9o=r(wft,"speech_to_text"),wft.forEach(t),W9o=r(Tye," \u2014 "),kj=n(Tye,"A",{href:!0});var Aft=s(kj);H9o=r(Aft,"Speech2TextModel"),Aft.forEach(t),U9o=r(Tye," (Speech2Text model)"),Tye.forEach(t),J9o=i($),ru=n($,"LI",{});var Mye=s(ru);hce=n(Mye,"STRONG",{});var Lft=s(hce);Y9o=r(Lft,"splinter"),Lft.forEach(t),K9o=r(Mye," \u2014 "),Sj=n(Mye,"A",{href:!0});var yft=s(Sj);Z9o=r(yft,"SplinterModel"),yft.forEach(t),eMo=r(Mye," (Splinter model)"),Mye.forEach(t),oMo=i($),tu=n($,"LI",{});var Eye=s(tu);pce=n(Eye,"STRONG",{});var xft=s(pce);rMo=r(xft,"squeezebert"),xft.forEach(t),tMo=r(Eye," \u2014 "),Rj=n(Eye,"A",{href:!0});var $ft=s(Rj);aMo=r($ft,"SqueezeBertModel"),$ft.forEach(t),nMo=r(Eye," (SqueezeBERT model)"),Eye.forEach(t),sMo=i($),au=n($,"LI",{});var Cye=s(au);_ce=n(Cye,"STRONG",{});var kft=s(_ce);lMo=r(kft,"swin"),kft.forEach(t),iMo=r(Cye," \u2014 "),Pj=n(Cye,"A",{href:!0});var Sft=s(Pj);dMo=r(Sft,"SwinModel"),Sft.forEach(t),cMo=r(Cye," (Swin Transformer model)"),Cye.forEach(t),fMo=i($),nu=n($,"LI",{});var wye=s(nu);uce=n(wye,"STRONG",{});var Rft=s(uce);mMo=r(Rft,"t5"),Rft.forEach(t),gMo=r(wye," \u2014 "),Bj=n(wye,"A",{href:!0});var Pft=s(Bj);hMo=r(Pft,"T5Model"),Pft.forEach(t),pMo=r(wye," (T5 model)"),wye.forEach(t),_Mo=i($),su=n($,"LI",{});var Aye=s(su);bce=n(Aye,"STRONG",{});var Bft=s(bce);uMo=r(Bft,"tapas"),Bft.forEach(t),bMo=r(Aye," \u2014 "),Ij=n(Aye,"A",{href:!0});var Ift=s(Ij);vMo=r(Ift,"TapasModel"),Ift.forEach(t),FMo=r(Aye," (TAPAS model)"),Aye.forEach(t),TMo=i($),lu=n($,"LI",{});var Lye=s(lu);vce=n(Lye,"STRONG",{});var Nft=s(vce);MMo=r(Nft,"trajectory_transformer"),Nft.forEach(t),EMo=r(Lye," \u2014 "),Nj=n(Lye,"A",{href:!0});var qft=s(Nj);CMo=r(qft,"TrajectoryTransformerModel"),qft.forEach(t),wMo=r(Lye," (Trajectory Transformer model)"),Lye.forEach(t),AMo=i($),iu=n($,"LI",{});var yye=s(iu);Fce=n(yye,"STRONG",{});var jft=s(Fce);LMo=r(jft,"transfo-xl"),jft.forEach(t),yMo=r(yye," \u2014 "),qj=n(yye,"A",{href:!0});var Dft=s(qj);xMo=r(Dft,"TransfoXLModel"),Dft.forEach(t),$Mo=r(yye," (Transformer-XL model)"),yye.forEach(t),kMo=i($),du=n($,"LI",{});var xye=s(du);Tce=n(xye,"STRONG",{});var Gft=s(Tce);SMo=r(Gft,"unispeech"),Gft.forEach(t),RMo=r(xye," \u2014 "),jj=n(xye,"A",{href:!0});var Oft=s(jj);PMo=r(Oft,"UniSpeechModel"),Oft.forEach(t),BMo=r(xye," (UniSpeech model)"),xye.forEach(t),IMo=i($),cu=n($,"LI",{});var $ye=s(cu);Mce=n($ye,"STRONG",{});var Vft=s(Mce);NMo=r(Vft,"unispeech-sat"),Vft.forEach(t),qMo=r($ye," \u2014 "),Dj=n($ye,"A",{href:!0});var Xft=s(Dj);jMo=r(Xft,"UniSpeechSatModel"),Xft.forEach(t),DMo=r($ye," (UniSpeechSat model)"),$ye.forEach(t),GMo=i($),fu=n($,"LI",{});var kye=s(fu);Ece=n(kye,"STRONG",{});var zft=s(Ece);OMo=r(zft,"van"),zft.forEach(t),VMo=r(kye," \u2014 "),Gj=n(kye,"A",{href:!0});var Qft=s(Gj);XMo=r(Qft,"VanModel"),Qft.forEach(t),zMo=r(kye," (VAN model)"),kye.forEach(t),QMo=i($),mu=n($,"LI",{});var Sye=s(mu);Cce=n(Sye,"STRONG",{});var Wft=s(Cce);WMo=r(Wft,"vilt"),Wft.forEach(t),HMo=r(Sye," \u2014 "),Oj=n(Sye,"A",{href:!0});var Hft=s(Oj);UMo=r(Hft,"ViltModel"),Hft.forEach(t),JMo=r(Sye," (ViLT model)"),Sye.forEach(t),YMo=i($),gu=n($,"LI",{});var Rye=s(gu);wce=n(Rye,"STRONG",{});var Uft=s(wce);KMo=r(Uft,"vision-text-dual-encoder"),Uft.forEach(t),ZMo=r(Rye," \u2014 "),Vj=n(Rye,"A",{href:!0});var Jft=s(Vj);eEo=r(Jft,"VisionTextDualEncoderModel"),Jft.forEach(t),oEo=r(Rye," (VisionTextDualEncoder model)"),Rye.forEach(t),rEo=i($),hu=n($,"LI",{});var Pye=s(hu);Ace=n(Pye,"STRONG",{});var Yft=s(Ace);tEo=r(Yft,"visual_bert"),Yft.forEach(t),aEo=r(Pye," \u2014 "),Xj=n(Pye,"A",{href:!0});var Kft=s(Xj);nEo=r(Kft,"VisualBertModel"),Kft.forEach(t),sEo=r(Pye," (VisualBERT model)"),Pye.forEach(t),lEo=i($),pu=n($,"LI",{});var Bye=s(pu);Lce=n(Bye,"STRONG",{});var Zft=s(Lce);iEo=r(Zft,"vit"),Zft.forEach(t),dEo=r(Bye," \u2014 "),zj=n(Bye,"A",{href:!0});var emt=s(zj);cEo=r(emt,"ViTModel"),emt.forEach(t),fEo=r(Bye," (ViT model)"),Bye.forEach(t),mEo=i($),_u=n($,"LI",{});var Iye=s(_u);yce=n(Iye,"STRONG",{});var omt=s(yce);gEo=r(omt,"vit_mae"),omt.forEach(t),hEo=r(Iye," \u2014 "),Qj=n(Iye,"A",{href:!0});var rmt=s(Qj);pEo=r(rmt,"ViTMAEModel"),rmt.forEach(t),_Eo=r(Iye," (ViTMAE model)"),Iye.forEach(t),uEo=i($),uu=n($,"LI",{});var Nye=s(uu);xce=n(Nye,"STRONG",{});var tmt=s(xce);bEo=r(tmt,"wav2vec2"),tmt.forEach(t),vEo=r(Nye," \u2014 "),Wj=n(Nye,"A",{href:!0});var amt=s(Wj);FEo=r(amt,"Wav2Vec2Model"),amt.forEach(t),TEo=r(Nye," (Wav2Vec2 model)"),Nye.forEach(t),MEo=i($),bu=n($,"LI",{});var qye=s(bu);$ce=n(qye,"STRONG",{});var nmt=s($ce);EEo=r(nmt,"wav2vec2-conformer"),nmt.forEach(t),CEo=r(qye," \u2014 "),Hj=n(qye,"A",{href:!0});var smt=s(Hj);wEo=r(smt,"Wav2Vec2ConformerModel"),smt.forEach(t),AEo=r(qye," (Wav2Vec2-Conformer model)"),qye.forEach(t),LEo=i($),vu=n($,"LI",{});var jye=s(vu);kce=n(jye,"STRONG",{});var lmt=s(kce);yEo=r(lmt,"wavlm"),lmt.forEach(t),xEo=r(jye," \u2014 "),Uj=n(jye,"A",{href:!0});var imt=s(Uj);$Eo=r(imt,"WavLMModel"),imt.forEach(t),kEo=r(jye," (WavLM model)"),jye.forEach(t),SEo=i($),Fu=n($,"LI",{});var Dye=s(Fu);Sce=n(Dye,"STRONG",{});var dmt=s(Sce);REo=r(dmt,"xglm"),dmt.forEach(t),PEo=r(Dye," \u2014 "),Jj=n(Dye,"A",{href:!0});var cmt=s(Jj);BEo=r(cmt,"XGLMModel"),cmt.forEach(t),IEo=r(Dye," (XGLM model)"),Dye.forEach(t),NEo=i($),Tu=n($,"LI",{});var Gye=s(Tu);Rce=n(Gye,"STRONG",{});var fmt=s(Rce);qEo=r(fmt,"xlm"),fmt.forEach(t),jEo=r(Gye," \u2014 "),Yj=n(Gye,"A",{href:!0});var mmt=s(Yj);DEo=r(mmt,"XLMModel"),mmt.forEach(t),GEo=r(Gye," (XLM model)"),Gye.forEach(t),OEo=i($),Mu=n($,"LI",{});var Oye=s(Mu);Pce=n(Oye,"STRONG",{});var gmt=s(Pce);VEo=r(gmt,"xlm-prophetnet"),gmt.forEach(t),XEo=r(Oye," \u2014 "),Kj=n(Oye,"A",{href:!0});var hmt=s(Kj);zEo=r(hmt,"XLMProphetNetModel"),hmt.forEach(t),QEo=r(Oye," (XLM-ProphetNet model)"),Oye.forEach(t),WEo=i($),Eu=n($,"LI",{});var Vye=s(Eu);Bce=n(Vye,"STRONG",{});var pmt=s(Bce);HEo=r(pmt,"xlm-roberta"),pmt.forEach(t),UEo=r(Vye," \u2014 "),Zj=n(Vye,"A",{href:!0});var _mt=s(Zj);JEo=r(_mt,"XLMRobertaModel"),_mt.forEach(t),YEo=r(Vye," (XLM-RoBERTa model)"),Vye.forEach(t),KEo=i($),Cu=n($,"LI",{});var Xye=s(Cu);Ice=n(Xye,"STRONG",{});var umt=s(Ice);ZEo=r(umt,"xlm-roberta-xl"),umt.forEach(t),e4o=r(Xye," \u2014 "),eD=n(Xye,"A",{href:!0});var bmt=s(eD);o4o=r(bmt,"XLMRobertaXLModel"),bmt.forEach(t),r4o=r(Xye," (XLM-RoBERTa-XL model)"),Xye.forEach(t),t4o=i($),wu=n($,"LI",{});var zye=s(wu);Nce=n(zye,"STRONG",{});var vmt=s(Nce);a4o=r(vmt,"xlnet"),vmt.forEach(t),n4o=r(zye," \u2014 "),oD=n(zye,"A",{href:!0});var Fmt=s(oD);s4o=r(Fmt,"XLNetModel"),Fmt.forEach(t),l4o=r(zye," (XLNet model)"),zye.forEach(t),i4o=i($),Au=n($,"LI",{});var Qye=s(Au);qce=n(Qye,"STRONG",{});var Tmt=s(qce);d4o=r(Tmt,"yolos"),Tmt.forEach(t),c4o=r(Qye," \u2014 "),rD=n(Qye,"A",{href:!0});var Mmt=s(rD);f4o=r(Mmt,"YolosModel"),Mmt.forEach(t),m4o=r(Qye," (YOLOS model)"),Qye.forEach(t),g4o=i($),Lu=n($,"LI",{});var Wye=s(Lu);jce=n(Wye,"STRONG",{});var Emt=s(jce);h4o=r(Emt,"yoso"),Emt.forEach(t),p4o=r(Wye," \u2014 "),tD=n(Wye,"A",{href:!0});var Cmt=s(tD);_4o=r(Cmt,"YosoModel"),Cmt.forEach(t),u4o=r(Wye," (YOSO model)"),Wye.forEach(t),$.forEach(t),b4o=i(aa),yu=n(aa,"P",{});var Hye=s(yu);v4o=r(Hye,"The model is set in evaluation mode by default using "),Dce=n(Hye,"CODE",{});var wmt=s(Dce);F4o=r(wmt,"model.eval()"),wmt.forEach(t),T4o=r(Hye,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Gce=n(Hye,"CODE",{});var Amt=s(Gce);M4o=r(Amt,"model.train()"),Amt.forEach(t),Hye.forEach(t),E4o=i(aa),T(xu.$$.fragment,aa),aa.forEach(t),Ys.forEach(t),eOe=i(f),qi=n(f,"H2",{class:!0});var sXe=s(qi);$u=n(sXe,"A",{id:!0,class:!0,href:!0});var Lmt=s($u);Oce=n(Lmt,"SPAN",{});var ymt=s(Oce);T(sA.$$.fragment,ymt),ymt.forEach(t),Lmt.forEach(t),C4o=i(sXe),Vce=n(sXe,"SPAN",{});var xmt=s(Vce);w4o=r(xmt,"AutoModelForPreTraining"),xmt.forEach(t),sXe.forEach(t),oOe=i(f),$o=n(f,"DIV",{class:!0});var Ks=s($o);T(lA.$$.fragment,Ks),A4o=i(Ks),ji=n(Ks,"P",{});var Toe=s(ji);L4o=r(Toe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),aD=n(Toe,"A",{href:!0});var $mt=s(aD);y4o=r($mt,"from_pretrained()"),$mt.forEach(t),x4o=r(Toe," class method or the "),nD=n(Toe,"A",{href:!0});var kmt=s(nD);$4o=r(kmt,"from_config()"),kmt.forEach(t),k4o=r(Toe,` class
method.`),Toe.forEach(t),S4o=i(Ks),iA=n(Ks,"P",{});var lXe=s(iA);R4o=r(lXe,"This class cannot be instantiated directly using "),Xce=n(lXe,"CODE",{});var Smt=s(Xce);P4o=r(Smt,"__init__()"),Smt.forEach(t),B4o=r(lXe," (throws an error)."),lXe.forEach(t),I4o=i(Ks),st=n(Ks,"DIV",{class:!0});var R3=s(st);T(dA.$$.fragment,R3),N4o=i(R3),zce=n(R3,"P",{});var Rmt=s(zce);q4o=r(Rmt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),Rmt.forEach(t),j4o=i(R3),Di=n(R3,"P",{});var Moe=s(Di);D4o=r(Moe,`Note:
Loading a model from its configuration file does `),Qce=n(Moe,"STRONG",{});var Pmt=s(Qce);G4o=r(Pmt,"not"),Pmt.forEach(t),O4o=r(Moe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sD=n(Moe,"A",{href:!0});var Bmt=s(sD);V4o=r(Bmt,"from_pretrained()"),Bmt.forEach(t),X4o=r(Moe," to load the model weights."),Moe.forEach(t),z4o=i(R3),T(ku.$$.fragment,R3),R3.forEach(t),Q4o=i(Ks),Ye=n(Ks,"DIV",{class:!0});var na=s(Ye);T(cA.$$.fragment,na),W4o=i(na),Wce=n(na,"P",{});var Imt=s(Wce);H4o=r(Imt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),Imt.forEach(t),U4o=i(na),Pa=n(na,"P",{});var P3=s(Pa);J4o=r(P3,"The model class to instantiate is selected based on the "),Hce=n(P3,"CODE",{});var Nmt=s(Hce);Y4o=r(Nmt,"model_type"),Nmt.forEach(t),K4o=r(P3,` property of the config object (either
passed as an argument or loaded from `),Uce=n(P3,"CODE",{});var qmt=s(Uce);Z4o=r(qmt,"pretrained_model_name_or_path"),qmt.forEach(t),eCo=r(P3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Jce=n(P3,"CODE",{});var jmt=s(Jce);oCo=r(jmt,"pretrained_model_name_or_path"),jmt.forEach(t),rCo=r(P3,":"),P3.forEach(t),tCo=i(na),G=n(na,"UL",{});var O=s(G);Su=n(O,"LI",{});var Uye=s(Su);Yce=n(Uye,"STRONG",{});var Dmt=s(Yce);aCo=r(Dmt,"albert"),Dmt.forEach(t),nCo=r(Uye," \u2014 "),lD=n(Uye,"A",{href:!0});var Gmt=s(lD);sCo=r(Gmt,"AlbertForPreTraining"),Gmt.forEach(t),lCo=r(Uye," (ALBERT model)"),Uye.forEach(t),iCo=i(O),Ru=n(O,"LI",{});var Jye=s(Ru);Kce=n(Jye,"STRONG",{});var Omt=s(Kce);dCo=r(Omt,"bart"),Omt.forEach(t),cCo=r(Jye," \u2014 "),iD=n(Jye,"A",{href:!0});var Vmt=s(iD);fCo=r(Vmt,"BartForConditionalGeneration"),Vmt.forEach(t),mCo=r(Jye," (BART model)"),Jye.forEach(t),gCo=i(O),Pu=n(O,"LI",{});var Yye=s(Pu);Zce=n(Yye,"STRONG",{});var Xmt=s(Zce);hCo=r(Xmt,"bert"),Xmt.forEach(t),pCo=r(Yye," \u2014 "),dD=n(Yye,"A",{href:!0});var zmt=s(dD);_Co=r(zmt,"BertForPreTraining"),zmt.forEach(t),uCo=r(Yye," (BERT model)"),Yye.forEach(t),bCo=i(O),Bu=n(O,"LI",{});var Kye=s(Bu);efe=n(Kye,"STRONG",{});var Qmt=s(efe);vCo=r(Qmt,"big_bird"),Qmt.forEach(t),FCo=r(Kye," \u2014 "),cD=n(Kye,"A",{href:!0});var Wmt=s(cD);TCo=r(Wmt,"BigBirdForPreTraining"),Wmt.forEach(t),MCo=r(Kye," (BigBird model)"),Kye.forEach(t),ECo=i(O),Iu=n(O,"LI",{});var Zye=s(Iu);ofe=n(Zye,"STRONG",{});var Hmt=s(ofe);CCo=r(Hmt,"bloom"),Hmt.forEach(t),wCo=r(Zye," \u2014 "),fD=n(Zye,"A",{href:!0});var Umt=s(fD);ACo=r(Umt,"BloomForCausalLM"),Umt.forEach(t),LCo=r(Zye," (BLOOM model)"),Zye.forEach(t),yCo=i(O),Nu=n(O,"LI",{});var exe=s(Nu);rfe=n(exe,"STRONG",{});var Jmt=s(rfe);xCo=r(Jmt,"camembert"),Jmt.forEach(t),$Co=r(exe," \u2014 "),mD=n(exe,"A",{href:!0});var Ymt=s(mD);kCo=r(Ymt,"CamembertForMaskedLM"),Ymt.forEach(t),SCo=r(exe," (CamemBERT model)"),exe.forEach(t),RCo=i(O),qu=n(O,"LI",{});var oxe=s(qu);tfe=n(oxe,"STRONG",{});var Kmt=s(tfe);PCo=r(Kmt,"ctrl"),Kmt.forEach(t),BCo=r(oxe," \u2014 "),gD=n(oxe,"A",{href:!0});var Zmt=s(gD);ICo=r(Zmt,"CTRLLMHeadModel"),Zmt.forEach(t),NCo=r(oxe," (CTRL model)"),oxe.forEach(t),qCo=i(O),ju=n(O,"LI",{});var rxe=s(ju);afe=n(rxe,"STRONG",{});var egt=s(afe);jCo=r(egt,"data2vec-text"),egt.forEach(t),DCo=r(rxe," \u2014 "),hD=n(rxe,"A",{href:!0});var ogt=s(hD);GCo=r(ogt,"Data2VecTextForMaskedLM"),ogt.forEach(t),OCo=r(rxe," (Data2VecText model)"),rxe.forEach(t),VCo=i(O),Du=n(O,"LI",{});var txe=s(Du);nfe=n(txe,"STRONG",{});var rgt=s(nfe);XCo=r(rgt,"deberta"),rgt.forEach(t),zCo=r(txe," \u2014 "),pD=n(txe,"A",{href:!0});var tgt=s(pD);QCo=r(tgt,"DebertaForMaskedLM"),tgt.forEach(t),WCo=r(txe," (DeBERTa model)"),txe.forEach(t),HCo=i(O),Gu=n(O,"LI",{});var axe=s(Gu);sfe=n(axe,"STRONG",{});var agt=s(sfe);UCo=r(agt,"deberta-v2"),agt.forEach(t),JCo=r(axe," \u2014 "),_D=n(axe,"A",{href:!0});var ngt=s(_D);YCo=r(ngt,"DebertaV2ForMaskedLM"),ngt.forEach(t),KCo=r(axe," (DeBERTa-v2 model)"),axe.forEach(t),ZCo=i(O),Ou=n(O,"LI",{});var nxe=s(Ou);lfe=n(nxe,"STRONG",{});var sgt=s(lfe);e5o=r(sgt,"distilbert"),sgt.forEach(t),o5o=r(nxe," \u2014 "),uD=n(nxe,"A",{href:!0});var lgt=s(uD);r5o=r(lgt,"DistilBertForMaskedLM"),lgt.forEach(t),t5o=r(nxe," (DistilBERT model)"),nxe.forEach(t),a5o=i(O),Vu=n(O,"LI",{});var sxe=s(Vu);ife=n(sxe,"STRONG",{});var igt=s(ife);n5o=r(igt,"electra"),igt.forEach(t),s5o=r(sxe," \u2014 "),bD=n(sxe,"A",{href:!0});var dgt=s(bD);l5o=r(dgt,"ElectraForPreTraining"),dgt.forEach(t),i5o=r(sxe," (ELECTRA model)"),sxe.forEach(t),d5o=i(O),Xu=n(O,"LI",{});var lxe=s(Xu);dfe=n(lxe,"STRONG",{});var cgt=s(dfe);c5o=r(cgt,"flaubert"),cgt.forEach(t),f5o=r(lxe," \u2014 "),vD=n(lxe,"A",{href:!0});var fgt=s(vD);m5o=r(fgt,"FlaubertWithLMHeadModel"),fgt.forEach(t),g5o=r(lxe," (FlauBERT model)"),lxe.forEach(t),h5o=i(O),zu=n(O,"LI",{});var ixe=s(zu);cfe=n(ixe,"STRONG",{});var mgt=s(cfe);p5o=r(mgt,"flava"),mgt.forEach(t),_5o=r(ixe," \u2014 "),FD=n(ixe,"A",{href:!0});var ggt=s(FD);u5o=r(ggt,"FlavaForPreTraining"),ggt.forEach(t),b5o=r(ixe," (FLAVA model)"),ixe.forEach(t),v5o=i(O),Qu=n(O,"LI",{});var dxe=s(Qu);ffe=n(dxe,"STRONG",{});var hgt=s(ffe);F5o=r(hgt,"fnet"),hgt.forEach(t),T5o=r(dxe," \u2014 "),TD=n(dxe,"A",{href:!0});var pgt=s(TD);M5o=r(pgt,"FNetForPreTraining"),pgt.forEach(t),E5o=r(dxe," (FNet model)"),dxe.forEach(t),C5o=i(O),Wu=n(O,"LI",{});var cxe=s(Wu);mfe=n(cxe,"STRONG",{});var _gt=s(mfe);w5o=r(_gt,"fsmt"),_gt.forEach(t),A5o=r(cxe," \u2014 "),MD=n(cxe,"A",{href:!0});var ugt=s(MD);L5o=r(ugt,"FSMTForConditionalGeneration"),ugt.forEach(t),y5o=r(cxe," (FairSeq Machine-Translation model)"),cxe.forEach(t),x5o=i(O),Hu=n(O,"LI",{});var fxe=s(Hu);gfe=n(fxe,"STRONG",{});var bgt=s(gfe);$5o=r(bgt,"funnel"),bgt.forEach(t),k5o=r(fxe," \u2014 "),ED=n(fxe,"A",{href:!0});var vgt=s(ED);S5o=r(vgt,"FunnelForPreTraining"),vgt.forEach(t),R5o=r(fxe," (Funnel Transformer model)"),fxe.forEach(t),P5o=i(O),Uu=n(O,"LI",{});var mxe=s(Uu);hfe=n(mxe,"STRONG",{});var Fgt=s(hfe);B5o=r(Fgt,"gpt2"),Fgt.forEach(t),I5o=r(mxe," \u2014 "),CD=n(mxe,"A",{href:!0});var Tgt=s(CD);N5o=r(Tgt,"GPT2LMHeadModel"),Tgt.forEach(t),q5o=r(mxe," (OpenAI GPT-2 model)"),mxe.forEach(t),j5o=i(O),Ju=n(O,"LI",{});var gxe=s(Ju);pfe=n(gxe,"STRONG",{});var Mgt=s(pfe);D5o=r(Mgt,"ibert"),Mgt.forEach(t),G5o=r(gxe," \u2014 "),wD=n(gxe,"A",{href:!0});var Egt=s(wD);O5o=r(Egt,"IBertForMaskedLM"),Egt.forEach(t),V5o=r(gxe," (I-BERT model)"),gxe.forEach(t),X5o=i(O),Yu=n(O,"LI",{});var hxe=s(Yu);_fe=n(hxe,"STRONG",{});var Cgt=s(_fe);z5o=r(Cgt,"layoutlm"),Cgt.forEach(t),Q5o=r(hxe," \u2014 "),AD=n(hxe,"A",{href:!0});var wgt=s(AD);W5o=r(wgt,"LayoutLMForMaskedLM"),wgt.forEach(t),H5o=r(hxe," (LayoutLM model)"),hxe.forEach(t),U5o=i(O),Ku=n(O,"LI",{});var pxe=s(Ku);ufe=n(pxe,"STRONG",{});var Agt=s(ufe);J5o=r(Agt,"longformer"),Agt.forEach(t),Y5o=r(pxe," \u2014 "),LD=n(pxe,"A",{href:!0});var Lgt=s(LD);K5o=r(Lgt,"LongformerForMaskedLM"),Lgt.forEach(t),Z5o=r(pxe," (Longformer model)"),pxe.forEach(t),e3o=i(O),Zu=n(O,"LI",{});var _xe=s(Zu);bfe=n(_xe,"STRONG",{});var ygt=s(bfe);o3o=r(ygt,"lxmert"),ygt.forEach(t),r3o=r(_xe," \u2014 "),yD=n(_xe,"A",{href:!0});var xgt=s(yD);t3o=r(xgt,"LxmertForPreTraining"),xgt.forEach(t),a3o=r(_xe," (LXMERT model)"),_xe.forEach(t),n3o=i(O),e1=n(O,"LI",{});var uxe=s(e1);vfe=n(uxe,"STRONG",{});var $gt=s(vfe);s3o=r($gt,"megatron-bert"),$gt.forEach(t),l3o=r(uxe," \u2014 "),xD=n(uxe,"A",{href:!0});var kgt=s(xD);i3o=r(kgt,"MegatronBertForPreTraining"),kgt.forEach(t),d3o=r(uxe," (Megatron-BERT model)"),uxe.forEach(t),c3o=i(O),o1=n(O,"LI",{});var bxe=s(o1);Ffe=n(bxe,"STRONG",{});var Sgt=s(Ffe);f3o=r(Sgt,"mobilebert"),Sgt.forEach(t),m3o=r(bxe," \u2014 "),$D=n(bxe,"A",{href:!0});var Rgt=s($D);g3o=r(Rgt,"MobileBertForPreTraining"),Rgt.forEach(t),h3o=r(bxe," (MobileBERT model)"),bxe.forEach(t),p3o=i(O),r1=n(O,"LI",{});var vxe=s(r1);Tfe=n(vxe,"STRONG",{});var Pgt=s(Tfe);_3o=r(Pgt,"mpnet"),Pgt.forEach(t),u3o=r(vxe," \u2014 "),kD=n(vxe,"A",{href:!0});var Bgt=s(kD);b3o=r(Bgt,"MPNetForMaskedLM"),Bgt.forEach(t),v3o=r(vxe," (MPNet model)"),vxe.forEach(t),F3o=i(O),t1=n(O,"LI",{});var Fxe=s(t1);Mfe=n(Fxe,"STRONG",{});var Igt=s(Mfe);T3o=r(Igt,"nezha"),Igt.forEach(t),M3o=r(Fxe," \u2014 "),SD=n(Fxe,"A",{href:!0});var Ngt=s(SD);E3o=r(Ngt,"NezhaForPreTraining"),Ngt.forEach(t),C3o=r(Fxe," (Nezha model)"),Fxe.forEach(t),w3o=i(O),a1=n(O,"LI",{});var Txe=s(a1);Efe=n(Txe,"STRONG",{});var qgt=s(Efe);A3o=r(qgt,"openai-gpt"),qgt.forEach(t),L3o=r(Txe," \u2014 "),RD=n(Txe,"A",{href:!0});var jgt=s(RD);y3o=r(jgt,"OpenAIGPTLMHeadModel"),jgt.forEach(t),x3o=r(Txe," (OpenAI GPT model)"),Txe.forEach(t),$3o=i(O),n1=n(O,"LI",{});var Mxe=s(n1);Cfe=n(Mxe,"STRONG",{});var Dgt=s(Cfe);k3o=r(Dgt,"retribert"),Dgt.forEach(t),S3o=r(Mxe," \u2014 "),PD=n(Mxe,"A",{href:!0});var Ggt=s(PD);R3o=r(Ggt,"RetriBertModel"),Ggt.forEach(t),P3o=r(Mxe," (RetriBERT model)"),Mxe.forEach(t),B3o=i(O),s1=n(O,"LI",{});var Exe=s(s1);wfe=n(Exe,"STRONG",{});var Ogt=s(wfe);I3o=r(Ogt,"roberta"),Ogt.forEach(t),N3o=r(Exe," \u2014 "),BD=n(Exe,"A",{href:!0});var Vgt=s(BD);q3o=r(Vgt,"RobertaForMaskedLM"),Vgt.forEach(t),j3o=r(Exe," (RoBERTa model)"),Exe.forEach(t),D3o=i(O),l1=n(O,"LI",{});var Cxe=s(l1);Afe=n(Cxe,"STRONG",{});var Xgt=s(Afe);G3o=r(Xgt,"splinter"),Xgt.forEach(t),O3o=r(Cxe," \u2014 "),ID=n(Cxe,"A",{href:!0});var zgt=s(ID);V3o=r(zgt,"SplinterForPreTraining"),zgt.forEach(t),X3o=r(Cxe," (Splinter model)"),Cxe.forEach(t),z3o=i(O),i1=n(O,"LI",{});var wxe=s(i1);Lfe=n(wxe,"STRONG",{});var Qgt=s(Lfe);Q3o=r(Qgt,"squeezebert"),Qgt.forEach(t),W3o=r(wxe," \u2014 "),ND=n(wxe,"A",{href:!0});var Wgt=s(ND);H3o=r(Wgt,"SqueezeBertForMaskedLM"),Wgt.forEach(t),U3o=r(wxe," (SqueezeBERT model)"),wxe.forEach(t),J3o=i(O),d1=n(O,"LI",{});var Axe=s(d1);yfe=n(Axe,"STRONG",{});var Hgt=s(yfe);Y3o=r(Hgt,"t5"),Hgt.forEach(t),K3o=r(Axe," \u2014 "),qD=n(Axe,"A",{href:!0});var Ugt=s(qD);Z3o=r(Ugt,"T5ForConditionalGeneration"),Ugt.forEach(t),e0o=r(Axe," (T5 model)"),Axe.forEach(t),o0o=i(O),c1=n(O,"LI",{});var Lxe=s(c1);xfe=n(Lxe,"STRONG",{});var Jgt=s(xfe);r0o=r(Jgt,"tapas"),Jgt.forEach(t),t0o=r(Lxe," \u2014 "),jD=n(Lxe,"A",{href:!0});var Ygt=s(jD);a0o=r(Ygt,"TapasForMaskedLM"),Ygt.forEach(t),n0o=r(Lxe," (TAPAS model)"),Lxe.forEach(t),s0o=i(O),f1=n(O,"LI",{});var yxe=s(f1);$fe=n(yxe,"STRONG",{});var Kgt=s($fe);l0o=r(Kgt,"transfo-xl"),Kgt.forEach(t),i0o=r(yxe," \u2014 "),DD=n(yxe,"A",{href:!0});var Zgt=s(DD);d0o=r(Zgt,"TransfoXLLMHeadModel"),Zgt.forEach(t),c0o=r(yxe," (Transformer-XL model)"),yxe.forEach(t),f0o=i(O),m1=n(O,"LI",{});var xxe=s(m1);kfe=n(xxe,"STRONG",{});var eht=s(kfe);m0o=r(eht,"unispeech"),eht.forEach(t),g0o=r(xxe," \u2014 "),GD=n(xxe,"A",{href:!0});var oht=s(GD);h0o=r(oht,"UniSpeechForPreTraining"),oht.forEach(t),p0o=r(xxe," (UniSpeech model)"),xxe.forEach(t),_0o=i(O),g1=n(O,"LI",{});var $xe=s(g1);Sfe=n($xe,"STRONG",{});var rht=s(Sfe);u0o=r(rht,"unispeech-sat"),rht.forEach(t),b0o=r($xe," \u2014 "),OD=n($xe,"A",{href:!0});var tht=s(OD);v0o=r(tht,"UniSpeechSatForPreTraining"),tht.forEach(t),F0o=r($xe," (UniSpeechSat model)"),$xe.forEach(t),T0o=i(O),h1=n(O,"LI",{});var kxe=s(h1);Rfe=n(kxe,"STRONG",{});var aht=s(Rfe);M0o=r(aht,"visual_bert"),aht.forEach(t),E0o=r(kxe," \u2014 "),VD=n(kxe,"A",{href:!0});var nht=s(VD);C0o=r(nht,"VisualBertForPreTraining"),nht.forEach(t),w0o=r(kxe," (VisualBERT model)"),kxe.forEach(t),A0o=i(O),p1=n(O,"LI",{});var Sxe=s(p1);Pfe=n(Sxe,"STRONG",{});var sht=s(Pfe);L0o=r(sht,"vit_mae"),sht.forEach(t),y0o=r(Sxe," \u2014 "),XD=n(Sxe,"A",{href:!0});var lht=s(XD);x0o=r(lht,"ViTMAEForPreTraining"),lht.forEach(t),$0o=r(Sxe," (ViTMAE model)"),Sxe.forEach(t),k0o=i(O),_1=n(O,"LI",{});var Rxe=s(_1);Bfe=n(Rxe,"STRONG",{});var iht=s(Bfe);S0o=r(iht,"wav2vec2"),iht.forEach(t),R0o=r(Rxe," \u2014 "),zD=n(Rxe,"A",{href:!0});var dht=s(zD);P0o=r(dht,"Wav2Vec2ForPreTraining"),dht.forEach(t),B0o=r(Rxe," (Wav2Vec2 model)"),Rxe.forEach(t),I0o=i(O),u1=n(O,"LI",{});var Pxe=s(u1);Ife=n(Pxe,"STRONG",{});var cht=s(Ife);N0o=r(cht,"wav2vec2-conformer"),cht.forEach(t),q0o=r(Pxe," \u2014 "),QD=n(Pxe,"A",{href:!0});var fht=s(QD);j0o=r(fht,"Wav2Vec2ConformerForPreTraining"),fht.forEach(t),D0o=r(Pxe," (Wav2Vec2-Conformer model)"),Pxe.forEach(t),G0o=i(O),b1=n(O,"LI",{});var Bxe=s(b1);Nfe=n(Bxe,"STRONG",{});var mht=s(Nfe);O0o=r(mht,"xlm"),mht.forEach(t),V0o=r(Bxe," \u2014 "),WD=n(Bxe,"A",{href:!0});var ght=s(WD);X0o=r(ght,"XLMWithLMHeadModel"),ght.forEach(t),z0o=r(Bxe," (XLM model)"),Bxe.forEach(t),Q0o=i(O),v1=n(O,"LI",{});var Ixe=s(v1);qfe=n(Ixe,"STRONG",{});var hht=s(qfe);W0o=r(hht,"xlm-roberta"),hht.forEach(t),H0o=r(Ixe," \u2014 "),HD=n(Ixe,"A",{href:!0});var pht=s(HD);U0o=r(pht,"XLMRobertaForMaskedLM"),pht.forEach(t),J0o=r(Ixe," (XLM-RoBERTa model)"),Ixe.forEach(t),Y0o=i(O),F1=n(O,"LI",{});var Nxe=s(F1);jfe=n(Nxe,"STRONG",{});var _ht=s(jfe);K0o=r(_ht,"xlm-roberta-xl"),_ht.forEach(t),Z0o=r(Nxe," \u2014 "),UD=n(Nxe,"A",{href:!0});var uht=s(UD);ewo=r(uht,"XLMRobertaXLForMaskedLM"),uht.forEach(t),owo=r(Nxe," (XLM-RoBERTa-XL model)"),Nxe.forEach(t),rwo=i(O),T1=n(O,"LI",{});var qxe=s(T1);Dfe=n(qxe,"STRONG",{});var bht=s(Dfe);two=r(bht,"xlnet"),bht.forEach(t),awo=r(qxe," \u2014 "),JD=n(qxe,"A",{href:!0});var vht=s(JD);nwo=r(vht,"XLNetLMHeadModel"),vht.forEach(t),swo=r(qxe," (XLNet model)"),qxe.forEach(t),O.forEach(t),lwo=i(na),M1=n(na,"P",{});var jxe=s(M1);iwo=r(jxe,"The model is set in evaluation mode by default using "),Gfe=n(jxe,"CODE",{});var Fht=s(Gfe);dwo=r(Fht,"model.eval()"),Fht.forEach(t),cwo=r(jxe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ofe=n(jxe,"CODE",{});var Tht=s(Ofe);fwo=r(Tht,"model.train()"),Tht.forEach(t),jxe.forEach(t),mwo=i(na),T(E1.$$.fragment,na),na.forEach(t),Ks.forEach(t),rOe=i(f),Gi=n(f,"H2",{class:!0});var iXe=s(Gi);C1=n(iXe,"A",{id:!0,class:!0,href:!0});var Mht=s(C1);Vfe=n(Mht,"SPAN",{});var Eht=s(Vfe);T(fA.$$.fragment,Eht),Eht.forEach(t),Mht.forEach(t),gwo=i(iXe),Xfe=n(iXe,"SPAN",{});var Cht=s(Xfe);hwo=r(Cht,"AutoModelForCausalLM"),Cht.forEach(t),iXe.forEach(t),tOe=i(f),ko=n(f,"DIV",{class:!0});var Zs=s(ko);T(mA.$$.fragment,Zs),pwo=i(Zs),Oi=n(Zs,"P",{});var Eoe=s(Oi);_wo=r(Eoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),YD=n(Eoe,"A",{href:!0});var wht=s(YD);uwo=r(wht,"from_pretrained()"),wht.forEach(t),bwo=r(Eoe," class method or the "),KD=n(Eoe,"A",{href:!0});var Aht=s(KD);vwo=r(Aht,"from_config()"),Aht.forEach(t),Fwo=r(Eoe,` class
method.`),Eoe.forEach(t),Two=i(Zs),gA=n(Zs,"P",{});var dXe=s(gA);Mwo=r(dXe,"This class cannot be instantiated directly using "),zfe=n(dXe,"CODE",{});var Lht=s(zfe);Ewo=r(Lht,"__init__()"),Lht.forEach(t),Cwo=r(dXe," (throws an error)."),dXe.forEach(t),wwo=i(Zs),lt=n(Zs,"DIV",{class:!0});var B3=s(lt);T(hA.$$.fragment,B3),Awo=i(B3),Qfe=n(B3,"P",{});var yht=s(Qfe);Lwo=r(yht,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),yht.forEach(t),ywo=i(B3),Vi=n(B3,"P",{});var Coe=s(Vi);xwo=r(Coe,`Note:
Loading a model from its configuration file does `),Wfe=n(Coe,"STRONG",{});var xht=s(Wfe);$wo=r(xht,"not"),xht.forEach(t),kwo=r(Coe,` load the model weights. It only affects the
model\u2019s configuration. Use `),ZD=n(Coe,"A",{href:!0});var $ht=s(ZD);Swo=r($ht,"from_pretrained()"),$ht.forEach(t),Rwo=r(Coe," to load the model weights."),Coe.forEach(t),Pwo=i(B3),T(w1.$$.fragment,B3),B3.forEach(t),Bwo=i(Zs),Ke=n(Zs,"DIV",{class:!0});var sa=s(Ke);T(pA.$$.fragment,sa),Iwo=i(sa),Hfe=n(sa,"P",{});var kht=s(Hfe);Nwo=r(kht,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),kht.forEach(t),qwo=i(sa),Ba=n(sa,"P",{});var I3=s(Ba);jwo=r(I3,"The model class to instantiate is selected based on the "),Ufe=n(I3,"CODE",{});var Sht=s(Ufe);Dwo=r(Sht,"model_type"),Sht.forEach(t),Gwo=r(I3,` property of the config object (either
passed as an argument or loaded from `),Jfe=n(I3,"CODE",{});var Rht=s(Jfe);Owo=r(Rht,"pretrained_model_name_or_path"),Rht.forEach(t),Vwo=r(I3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Yfe=n(I3,"CODE",{});var Pht=s(Yfe);Xwo=r(Pht,"pretrained_model_name_or_path"),Pht.forEach(t),zwo=r(I3,":"),I3.forEach(t),Qwo=i(sa),z=n(sa,"UL",{});var W=s(z);A1=n(W,"LI",{});var Dxe=s(A1);Kfe=n(Dxe,"STRONG",{});var Bht=s(Kfe);Wwo=r(Bht,"bart"),Bht.forEach(t),Hwo=r(Dxe," \u2014 "),eG=n(Dxe,"A",{href:!0});var Iht=s(eG);Uwo=r(Iht,"BartForCausalLM"),Iht.forEach(t),Jwo=r(Dxe," (BART model)"),Dxe.forEach(t),Ywo=i(W),L1=n(W,"LI",{});var Gxe=s(L1);Zfe=n(Gxe,"STRONG",{});var Nht=s(Zfe);Kwo=r(Nht,"bert"),Nht.forEach(t),Zwo=r(Gxe," \u2014 "),oG=n(Gxe,"A",{href:!0});var qht=s(oG);eAo=r(qht,"BertLMHeadModel"),qht.forEach(t),oAo=r(Gxe," (BERT model)"),Gxe.forEach(t),rAo=i(W),y1=n(W,"LI",{});var Oxe=s(y1);eme=n(Oxe,"STRONG",{});var jht=s(eme);tAo=r(jht,"bert-generation"),jht.forEach(t),aAo=r(Oxe," \u2014 "),rG=n(Oxe,"A",{href:!0});var Dht=s(rG);nAo=r(Dht,"BertGenerationDecoder"),Dht.forEach(t),sAo=r(Oxe," (Bert Generation model)"),Oxe.forEach(t),lAo=i(W),x1=n(W,"LI",{});var Vxe=s(x1);ome=n(Vxe,"STRONG",{});var Ght=s(ome);iAo=r(Ght,"big_bird"),Ght.forEach(t),dAo=r(Vxe," \u2014 "),tG=n(Vxe,"A",{href:!0});var Oht=s(tG);cAo=r(Oht,"BigBirdForCausalLM"),Oht.forEach(t),fAo=r(Vxe," (BigBird model)"),Vxe.forEach(t),mAo=i(W),$1=n(W,"LI",{});var Xxe=s($1);rme=n(Xxe,"STRONG",{});var Vht=s(rme);gAo=r(Vht,"bigbird_pegasus"),Vht.forEach(t),hAo=r(Xxe," \u2014 "),aG=n(Xxe,"A",{href:!0});var Xht=s(aG);pAo=r(Xht,"BigBirdPegasusForCausalLM"),Xht.forEach(t),_Ao=r(Xxe," (BigBird-Pegasus model)"),Xxe.forEach(t),uAo=i(W),k1=n(W,"LI",{});var zxe=s(k1);tme=n(zxe,"STRONG",{});var zht=s(tme);bAo=r(zht,"blenderbot"),zht.forEach(t),vAo=r(zxe," \u2014 "),nG=n(zxe,"A",{href:!0});var Qht=s(nG);FAo=r(Qht,"BlenderbotForCausalLM"),Qht.forEach(t),TAo=r(zxe," (Blenderbot model)"),zxe.forEach(t),MAo=i(W),S1=n(W,"LI",{});var Qxe=s(S1);ame=n(Qxe,"STRONG",{});var Wht=s(ame);EAo=r(Wht,"blenderbot-small"),Wht.forEach(t),CAo=r(Qxe," \u2014 "),sG=n(Qxe,"A",{href:!0});var Hht=s(sG);wAo=r(Hht,"BlenderbotSmallForCausalLM"),Hht.forEach(t),AAo=r(Qxe," (BlenderbotSmall model)"),Qxe.forEach(t),LAo=i(W),R1=n(W,"LI",{});var Wxe=s(R1);nme=n(Wxe,"STRONG",{});var Uht=s(nme);yAo=r(Uht,"bloom"),Uht.forEach(t),xAo=r(Wxe," \u2014 "),lG=n(Wxe,"A",{href:!0});var Jht=s(lG);$Ao=r(Jht,"BloomForCausalLM"),Jht.forEach(t),kAo=r(Wxe," (BLOOM model)"),Wxe.forEach(t),SAo=i(W),P1=n(W,"LI",{});var Hxe=s(P1);sme=n(Hxe,"STRONG",{});var Yht=s(sme);RAo=r(Yht,"camembert"),Yht.forEach(t),PAo=r(Hxe," \u2014 "),iG=n(Hxe,"A",{href:!0});var Kht=s(iG);BAo=r(Kht,"CamembertForCausalLM"),Kht.forEach(t),IAo=r(Hxe," (CamemBERT model)"),Hxe.forEach(t),NAo=i(W),B1=n(W,"LI",{});var Uxe=s(B1);lme=n(Uxe,"STRONG",{});var Zht=s(lme);qAo=r(Zht,"ctrl"),Zht.forEach(t),jAo=r(Uxe," \u2014 "),dG=n(Uxe,"A",{href:!0});var ept=s(dG);DAo=r(ept,"CTRLLMHeadModel"),ept.forEach(t),GAo=r(Uxe," (CTRL model)"),Uxe.forEach(t),OAo=i(W),I1=n(W,"LI",{});var Jxe=s(I1);ime=n(Jxe,"STRONG",{});var opt=s(ime);VAo=r(opt,"data2vec-text"),opt.forEach(t),XAo=r(Jxe," \u2014 "),cG=n(Jxe,"A",{href:!0});var rpt=s(cG);zAo=r(rpt,"Data2VecTextForCausalLM"),rpt.forEach(t),QAo=r(Jxe," (Data2VecText model)"),Jxe.forEach(t),WAo=i(W),N1=n(W,"LI",{});var Yxe=s(N1);dme=n(Yxe,"STRONG",{});var tpt=s(dme);HAo=r(tpt,"electra"),tpt.forEach(t),UAo=r(Yxe," \u2014 "),fG=n(Yxe,"A",{href:!0});var apt=s(fG);JAo=r(apt,"ElectraForCausalLM"),apt.forEach(t),YAo=r(Yxe," (ELECTRA model)"),Yxe.forEach(t),KAo=i(W),q1=n(W,"LI",{});var Kxe=s(q1);cme=n(Kxe,"STRONG",{});var npt=s(cme);ZAo=r(npt,"gpt2"),npt.forEach(t),eLo=r(Kxe," \u2014 "),mG=n(Kxe,"A",{href:!0});var spt=s(mG);oLo=r(spt,"GPT2LMHeadModel"),spt.forEach(t),rLo=r(Kxe," (OpenAI GPT-2 model)"),Kxe.forEach(t),tLo=i(W),j1=n(W,"LI",{});var Zxe=s(j1);fme=n(Zxe,"STRONG",{});var lpt=s(fme);aLo=r(lpt,"gpt_neo"),lpt.forEach(t),nLo=r(Zxe," \u2014 "),gG=n(Zxe,"A",{href:!0});var ipt=s(gG);sLo=r(ipt,"GPTNeoForCausalLM"),ipt.forEach(t),lLo=r(Zxe," (GPT Neo model)"),Zxe.forEach(t),iLo=i(W),D1=n(W,"LI",{});var e$e=s(D1);mme=n(e$e,"STRONG",{});var dpt=s(mme);dLo=r(dpt,"gpt_neox"),dpt.forEach(t),cLo=r(e$e," \u2014 "),hG=n(e$e,"A",{href:!0});var cpt=s(hG);fLo=r(cpt,"GPTNeoXForCausalLM"),cpt.forEach(t),mLo=r(e$e," (GPT NeoX model)"),e$e.forEach(t),gLo=i(W),G1=n(W,"LI",{});var o$e=s(G1);gme=n(o$e,"STRONG",{});var fpt=s(gme);hLo=r(fpt,"gptj"),fpt.forEach(t),pLo=r(o$e," \u2014 "),pG=n(o$e,"A",{href:!0});var mpt=s(pG);_Lo=r(mpt,"GPTJForCausalLM"),mpt.forEach(t),uLo=r(o$e," (GPT-J model)"),o$e.forEach(t),bLo=i(W),O1=n(W,"LI",{});var r$e=s(O1);hme=n(r$e,"STRONG",{});var gpt=s(hme);vLo=r(gpt,"marian"),gpt.forEach(t),FLo=r(r$e," \u2014 "),_G=n(r$e,"A",{href:!0});var hpt=s(_G);TLo=r(hpt,"MarianForCausalLM"),hpt.forEach(t),MLo=r(r$e," (Marian model)"),r$e.forEach(t),ELo=i(W),V1=n(W,"LI",{});var t$e=s(V1);pme=n(t$e,"STRONG",{});var ppt=s(pme);CLo=r(ppt,"mbart"),ppt.forEach(t),wLo=r(t$e," \u2014 "),uG=n(t$e,"A",{href:!0});var _pt=s(uG);ALo=r(_pt,"MBartForCausalLM"),_pt.forEach(t),LLo=r(t$e," (mBART model)"),t$e.forEach(t),yLo=i(W),X1=n(W,"LI",{});var a$e=s(X1);_me=n(a$e,"STRONG",{});var upt=s(_me);xLo=r(upt,"megatron-bert"),upt.forEach(t),$Lo=r(a$e," \u2014 "),bG=n(a$e,"A",{href:!0});var bpt=s(bG);kLo=r(bpt,"MegatronBertForCausalLM"),bpt.forEach(t),SLo=r(a$e," (Megatron-BERT model)"),a$e.forEach(t),RLo=i(W),z1=n(W,"LI",{});var n$e=s(z1);ume=n(n$e,"STRONG",{});var vpt=s(ume);PLo=r(vpt,"openai-gpt"),vpt.forEach(t),BLo=r(n$e," \u2014 "),vG=n(n$e,"A",{href:!0});var Fpt=s(vG);ILo=r(Fpt,"OpenAIGPTLMHeadModel"),Fpt.forEach(t),NLo=r(n$e," (OpenAI GPT model)"),n$e.forEach(t),qLo=i(W),Q1=n(W,"LI",{});var s$e=s(Q1);bme=n(s$e,"STRONG",{});var Tpt=s(bme);jLo=r(Tpt,"opt"),Tpt.forEach(t),DLo=r(s$e," \u2014 "),FG=n(s$e,"A",{href:!0});var Mpt=s(FG);GLo=r(Mpt,"OPTForCausalLM"),Mpt.forEach(t),OLo=r(s$e," (OPT model)"),s$e.forEach(t),VLo=i(W),W1=n(W,"LI",{});var l$e=s(W1);vme=n(l$e,"STRONG",{});var Ept=s(vme);XLo=r(Ept,"pegasus"),Ept.forEach(t),zLo=r(l$e," \u2014 "),TG=n(l$e,"A",{href:!0});var Cpt=s(TG);QLo=r(Cpt,"PegasusForCausalLM"),Cpt.forEach(t),WLo=r(l$e," (Pegasus model)"),l$e.forEach(t),HLo=i(W),H1=n(W,"LI",{});var i$e=s(H1);Fme=n(i$e,"STRONG",{});var wpt=s(Fme);ULo=r(wpt,"plbart"),wpt.forEach(t),JLo=r(i$e," \u2014 "),MG=n(i$e,"A",{href:!0});var Apt=s(MG);YLo=r(Apt,"PLBartForCausalLM"),Apt.forEach(t),KLo=r(i$e," (PLBart model)"),i$e.forEach(t),ZLo=i(W),U1=n(W,"LI",{});var d$e=s(U1);Tme=n(d$e,"STRONG",{});var Lpt=s(Tme);eyo=r(Lpt,"prophetnet"),Lpt.forEach(t),oyo=r(d$e," \u2014 "),EG=n(d$e,"A",{href:!0});var ypt=s(EG);ryo=r(ypt,"ProphetNetForCausalLM"),ypt.forEach(t),tyo=r(d$e," (ProphetNet model)"),d$e.forEach(t),ayo=i(W),J1=n(W,"LI",{});var c$e=s(J1);Mme=n(c$e,"STRONG",{});var xpt=s(Mme);nyo=r(xpt,"qdqbert"),xpt.forEach(t),syo=r(c$e," \u2014 "),CG=n(c$e,"A",{href:!0});var $pt=s(CG);lyo=r($pt,"QDQBertLMHeadModel"),$pt.forEach(t),iyo=r(c$e," (QDQBert model)"),c$e.forEach(t),dyo=i(W),Y1=n(W,"LI",{});var f$e=s(Y1);Eme=n(f$e,"STRONG",{});var kpt=s(Eme);cyo=r(kpt,"reformer"),kpt.forEach(t),fyo=r(f$e," \u2014 "),wG=n(f$e,"A",{href:!0});var Spt=s(wG);myo=r(Spt,"ReformerModelWithLMHead"),Spt.forEach(t),gyo=r(f$e," (Reformer model)"),f$e.forEach(t),hyo=i(W),K1=n(W,"LI",{});var m$e=s(K1);Cme=n(m$e,"STRONG",{});var Rpt=s(Cme);pyo=r(Rpt,"rembert"),Rpt.forEach(t),_yo=r(m$e," \u2014 "),AG=n(m$e,"A",{href:!0});var Ppt=s(AG);uyo=r(Ppt,"RemBertForCausalLM"),Ppt.forEach(t),byo=r(m$e," (RemBERT model)"),m$e.forEach(t),vyo=i(W),Z1=n(W,"LI",{});var g$e=s(Z1);wme=n(g$e,"STRONG",{});var Bpt=s(wme);Fyo=r(Bpt,"roberta"),Bpt.forEach(t),Tyo=r(g$e," \u2014 "),LG=n(g$e,"A",{href:!0});var Ipt=s(LG);Myo=r(Ipt,"RobertaForCausalLM"),Ipt.forEach(t),Eyo=r(g$e," (RoBERTa model)"),g$e.forEach(t),Cyo=i(W),e2=n(W,"LI",{});var h$e=s(e2);Ame=n(h$e,"STRONG",{});var Npt=s(Ame);wyo=r(Npt,"roformer"),Npt.forEach(t),Ayo=r(h$e," \u2014 "),yG=n(h$e,"A",{href:!0});var qpt=s(yG);Lyo=r(qpt,"RoFormerForCausalLM"),qpt.forEach(t),yyo=r(h$e," (RoFormer model)"),h$e.forEach(t),xyo=i(W),o2=n(W,"LI",{});var p$e=s(o2);Lme=n(p$e,"STRONG",{});var jpt=s(Lme);$yo=r(jpt,"speech_to_text_2"),jpt.forEach(t),kyo=r(p$e," \u2014 "),xG=n(p$e,"A",{href:!0});var Dpt=s(xG);Syo=r(Dpt,"Speech2Text2ForCausalLM"),Dpt.forEach(t),Ryo=r(p$e," (Speech2Text2 model)"),p$e.forEach(t),Pyo=i(W),r2=n(W,"LI",{});var _$e=s(r2);yme=n(_$e,"STRONG",{});var Gpt=s(yme);Byo=r(Gpt,"transfo-xl"),Gpt.forEach(t),Iyo=r(_$e," \u2014 "),$G=n(_$e,"A",{href:!0});var Opt=s($G);Nyo=r(Opt,"TransfoXLLMHeadModel"),Opt.forEach(t),qyo=r(_$e," (Transformer-XL model)"),_$e.forEach(t),jyo=i(W),t2=n(W,"LI",{});var u$e=s(t2);xme=n(u$e,"STRONG",{});var Vpt=s(xme);Dyo=r(Vpt,"trocr"),Vpt.forEach(t),Gyo=r(u$e," \u2014 "),kG=n(u$e,"A",{href:!0});var Xpt=s(kG);Oyo=r(Xpt,"TrOCRForCausalLM"),Xpt.forEach(t),Vyo=r(u$e," (TrOCR model)"),u$e.forEach(t),Xyo=i(W),a2=n(W,"LI",{});var b$e=s(a2);$me=n(b$e,"STRONG",{});var zpt=s($me);zyo=r(zpt,"xglm"),zpt.forEach(t),Qyo=r(b$e," \u2014 "),SG=n(b$e,"A",{href:!0});var Qpt=s(SG);Wyo=r(Qpt,"XGLMForCausalLM"),Qpt.forEach(t),Hyo=r(b$e," (XGLM model)"),b$e.forEach(t),Uyo=i(W),n2=n(W,"LI",{});var v$e=s(n2);kme=n(v$e,"STRONG",{});var Wpt=s(kme);Jyo=r(Wpt,"xlm"),Wpt.forEach(t),Yyo=r(v$e," \u2014 "),RG=n(v$e,"A",{href:!0});var Hpt=s(RG);Kyo=r(Hpt,"XLMWithLMHeadModel"),Hpt.forEach(t),Zyo=r(v$e," (XLM model)"),v$e.forEach(t),exo=i(W),s2=n(W,"LI",{});var F$e=s(s2);Sme=n(F$e,"STRONG",{});var Upt=s(Sme);oxo=r(Upt,"xlm-prophetnet"),Upt.forEach(t),rxo=r(F$e," \u2014 "),PG=n(F$e,"A",{href:!0});var Jpt=s(PG);txo=r(Jpt,"XLMProphetNetForCausalLM"),Jpt.forEach(t),axo=r(F$e," (XLM-ProphetNet model)"),F$e.forEach(t),nxo=i(W),l2=n(W,"LI",{});var T$e=s(l2);Rme=n(T$e,"STRONG",{});var Ypt=s(Rme);sxo=r(Ypt,"xlm-roberta"),Ypt.forEach(t),lxo=r(T$e," \u2014 "),BG=n(T$e,"A",{href:!0});var Kpt=s(BG);ixo=r(Kpt,"XLMRobertaForCausalLM"),Kpt.forEach(t),dxo=r(T$e," (XLM-RoBERTa model)"),T$e.forEach(t),cxo=i(W),i2=n(W,"LI",{});var M$e=s(i2);Pme=n(M$e,"STRONG",{});var Zpt=s(Pme);fxo=r(Zpt,"xlm-roberta-xl"),Zpt.forEach(t),mxo=r(M$e," \u2014 "),IG=n(M$e,"A",{href:!0});var e_t=s(IG);gxo=r(e_t,"XLMRobertaXLForCausalLM"),e_t.forEach(t),hxo=r(M$e," (XLM-RoBERTa-XL model)"),M$e.forEach(t),pxo=i(W),d2=n(W,"LI",{});var E$e=s(d2);Bme=n(E$e,"STRONG",{});var o_t=s(Bme);_xo=r(o_t,"xlnet"),o_t.forEach(t),uxo=r(E$e," \u2014 "),NG=n(E$e,"A",{href:!0});var r_t=s(NG);bxo=r(r_t,"XLNetLMHeadModel"),r_t.forEach(t),vxo=r(E$e," (XLNet model)"),E$e.forEach(t),W.forEach(t),Fxo=i(sa),c2=n(sa,"P",{});var C$e=s(c2);Txo=r(C$e,"The model is set in evaluation mode by default using "),Ime=n(C$e,"CODE",{});var t_t=s(Ime);Mxo=r(t_t,"model.eval()"),t_t.forEach(t),Exo=r(C$e,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Nme=n(C$e,"CODE",{});var a_t=s(Nme);Cxo=r(a_t,"model.train()"),a_t.forEach(t),C$e.forEach(t),wxo=i(sa),T(f2.$$.fragment,sa),sa.forEach(t),Zs.forEach(t),aOe=i(f),Xi=n(f,"H2",{class:!0});var cXe=s(Xi);m2=n(cXe,"A",{id:!0,class:!0,href:!0});var n_t=s(m2);qme=n(n_t,"SPAN",{});var s_t=s(qme);T(_A.$$.fragment,s_t),s_t.forEach(t),n_t.forEach(t),Axo=i(cXe),jme=n(cXe,"SPAN",{});var l_t=s(jme);Lxo=r(l_t,"AutoModelForMaskedLM"),l_t.forEach(t),cXe.forEach(t),nOe=i(f),So=n(f,"DIV",{class:!0});var el=s(So);T(uA.$$.fragment,el),yxo=i(el),zi=n(el,"P",{});var woe=s(zi);xxo=r(woe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),qG=n(woe,"A",{href:!0});var i_t=s(qG);$xo=r(i_t,"from_pretrained()"),i_t.forEach(t),kxo=r(woe," class method or the "),jG=n(woe,"A",{href:!0});var d_t=s(jG);Sxo=r(d_t,"from_config()"),d_t.forEach(t),Rxo=r(woe,` class
method.`),woe.forEach(t),Pxo=i(el),bA=n(el,"P",{});var fXe=s(bA);Bxo=r(fXe,"This class cannot be instantiated directly using "),Dme=n(fXe,"CODE",{});var c_t=s(Dme);Ixo=r(c_t,"__init__()"),c_t.forEach(t),Nxo=r(fXe," (throws an error)."),fXe.forEach(t),qxo=i(el),it=n(el,"DIV",{class:!0});var N3=s(it);T(vA.$$.fragment,N3),jxo=i(N3),Gme=n(N3,"P",{});var f_t=s(Gme);Dxo=r(f_t,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),f_t.forEach(t),Gxo=i(N3),Qi=n(N3,"P",{});var Aoe=s(Qi);Oxo=r(Aoe,`Note:
Loading a model from its configuration file does `),Ome=n(Aoe,"STRONG",{});var m_t=s(Ome);Vxo=r(m_t,"not"),m_t.forEach(t),Xxo=r(Aoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),DG=n(Aoe,"A",{href:!0});var g_t=s(DG);zxo=r(g_t,"from_pretrained()"),g_t.forEach(t),Qxo=r(Aoe," to load the model weights."),Aoe.forEach(t),Wxo=i(N3),T(g2.$$.fragment,N3),N3.forEach(t),Hxo=i(el),Ze=n(el,"DIV",{class:!0});var la=s(Ze);T(FA.$$.fragment,la),Uxo=i(la),Vme=n(la,"P",{});var h_t=s(Vme);Jxo=r(h_t,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),h_t.forEach(t),Yxo=i(la),Ia=n(la,"P",{});var q3=s(Ia);Kxo=r(q3,"The model class to instantiate is selected based on the "),Xme=n(q3,"CODE",{});var p_t=s(Xme);Zxo=r(p_t,"model_type"),p_t.forEach(t),e$o=r(q3,` property of the config object (either
passed as an argument or loaded from `),zme=n(q3,"CODE",{});var __t=s(zme);o$o=r(__t,"pretrained_model_name_or_path"),__t.forEach(t),r$o=r(q3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Qme=n(q3,"CODE",{});var u_t=s(Qme);t$o=r(u_t,"pretrained_model_name_or_path"),u_t.forEach(t),a$o=r(q3,":"),q3.forEach(t),n$o=i(la),Q=n(la,"UL",{});var U=s(Q);h2=n(U,"LI",{});var w$e=s(h2);Wme=n(w$e,"STRONG",{});var b_t=s(Wme);s$o=r(b_t,"albert"),b_t.forEach(t),l$o=r(w$e," \u2014 "),GG=n(w$e,"A",{href:!0});var v_t=s(GG);i$o=r(v_t,"AlbertForMaskedLM"),v_t.forEach(t),d$o=r(w$e," (ALBERT model)"),w$e.forEach(t),c$o=i(U),p2=n(U,"LI",{});var A$e=s(p2);Hme=n(A$e,"STRONG",{});var F_t=s(Hme);f$o=r(F_t,"bart"),F_t.forEach(t),m$o=r(A$e," \u2014 "),OG=n(A$e,"A",{href:!0});var T_t=s(OG);g$o=r(T_t,"BartForConditionalGeneration"),T_t.forEach(t),h$o=r(A$e," (BART model)"),A$e.forEach(t),p$o=i(U),_2=n(U,"LI",{});var L$e=s(_2);Ume=n(L$e,"STRONG",{});var M_t=s(Ume);_$o=r(M_t,"bert"),M_t.forEach(t),u$o=r(L$e," \u2014 "),VG=n(L$e,"A",{href:!0});var E_t=s(VG);b$o=r(E_t,"BertForMaskedLM"),E_t.forEach(t),v$o=r(L$e," (BERT model)"),L$e.forEach(t),F$o=i(U),u2=n(U,"LI",{});var y$e=s(u2);Jme=n(y$e,"STRONG",{});var C_t=s(Jme);T$o=r(C_t,"big_bird"),C_t.forEach(t),M$o=r(y$e," \u2014 "),XG=n(y$e,"A",{href:!0});var w_t=s(XG);E$o=r(w_t,"BigBirdForMaskedLM"),w_t.forEach(t),C$o=r(y$e," (BigBird model)"),y$e.forEach(t),w$o=i(U),b2=n(U,"LI",{});var x$e=s(b2);Yme=n(x$e,"STRONG",{});var A_t=s(Yme);A$o=r(A_t,"camembert"),A_t.forEach(t),L$o=r(x$e," \u2014 "),zG=n(x$e,"A",{href:!0});var L_t=s(zG);y$o=r(L_t,"CamembertForMaskedLM"),L_t.forEach(t),x$o=r(x$e," (CamemBERT model)"),x$e.forEach(t),$$o=i(U),v2=n(U,"LI",{});var $$e=s(v2);Kme=n($$e,"STRONG",{});var y_t=s(Kme);k$o=r(y_t,"convbert"),y_t.forEach(t),S$o=r($$e," \u2014 "),QG=n($$e,"A",{href:!0});var x_t=s(QG);R$o=r(x_t,"ConvBertForMaskedLM"),x_t.forEach(t),P$o=r($$e," (ConvBERT model)"),$$e.forEach(t),B$o=i(U),F2=n(U,"LI",{});var k$e=s(F2);Zme=n(k$e,"STRONG",{});var $_t=s(Zme);I$o=r($_t,"data2vec-text"),$_t.forEach(t),N$o=r(k$e," \u2014 "),WG=n(k$e,"A",{href:!0});var k_t=s(WG);q$o=r(k_t,"Data2VecTextForMaskedLM"),k_t.forEach(t),j$o=r(k$e," (Data2VecText model)"),k$e.forEach(t),D$o=i(U),T2=n(U,"LI",{});var S$e=s(T2);ege=n(S$e,"STRONG",{});var S_t=s(ege);G$o=r(S_t,"deberta"),S_t.forEach(t),O$o=r(S$e," \u2014 "),HG=n(S$e,"A",{href:!0});var R_t=s(HG);V$o=r(R_t,"DebertaForMaskedLM"),R_t.forEach(t),X$o=r(S$e," (DeBERTa model)"),S$e.forEach(t),z$o=i(U),M2=n(U,"LI",{});var R$e=s(M2);oge=n(R$e,"STRONG",{});var P_t=s(oge);Q$o=r(P_t,"deberta-v2"),P_t.forEach(t),W$o=r(R$e," \u2014 "),UG=n(R$e,"A",{href:!0});var B_t=s(UG);H$o=r(B_t,"DebertaV2ForMaskedLM"),B_t.forEach(t),U$o=r(R$e," (DeBERTa-v2 model)"),R$e.forEach(t),J$o=i(U),E2=n(U,"LI",{});var P$e=s(E2);rge=n(P$e,"STRONG",{});var I_t=s(rge);Y$o=r(I_t,"distilbert"),I_t.forEach(t),K$o=r(P$e," \u2014 "),JG=n(P$e,"A",{href:!0});var N_t=s(JG);Z$o=r(N_t,"DistilBertForMaskedLM"),N_t.forEach(t),eko=r(P$e," (DistilBERT model)"),P$e.forEach(t),oko=i(U),C2=n(U,"LI",{});var B$e=s(C2);tge=n(B$e,"STRONG",{});var q_t=s(tge);rko=r(q_t,"electra"),q_t.forEach(t),tko=r(B$e," \u2014 "),YG=n(B$e,"A",{href:!0});var j_t=s(YG);ako=r(j_t,"ElectraForMaskedLM"),j_t.forEach(t),nko=r(B$e," (ELECTRA model)"),B$e.forEach(t),sko=i(U),w2=n(U,"LI",{});var I$e=s(w2);age=n(I$e,"STRONG",{});var D_t=s(age);lko=r(D_t,"flaubert"),D_t.forEach(t),iko=r(I$e," \u2014 "),KG=n(I$e,"A",{href:!0});var G_t=s(KG);dko=r(G_t,"FlaubertWithLMHeadModel"),G_t.forEach(t),cko=r(I$e," (FlauBERT model)"),I$e.forEach(t),fko=i(U),A2=n(U,"LI",{});var N$e=s(A2);nge=n(N$e,"STRONG",{});var O_t=s(nge);mko=r(O_t,"fnet"),O_t.forEach(t),gko=r(N$e," \u2014 "),ZG=n(N$e,"A",{href:!0});var V_t=s(ZG);hko=r(V_t,"FNetForMaskedLM"),V_t.forEach(t),pko=r(N$e," (FNet model)"),N$e.forEach(t),_ko=i(U),L2=n(U,"LI",{});var q$e=s(L2);sge=n(q$e,"STRONG",{});var X_t=s(sge);uko=r(X_t,"funnel"),X_t.forEach(t),bko=r(q$e," \u2014 "),eO=n(q$e,"A",{href:!0});var z_t=s(eO);vko=r(z_t,"FunnelForMaskedLM"),z_t.forEach(t),Fko=r(q$e," (Funnel Transformer model)"),q$e.forEach(t),Tko=i(U),y2=n(U,"LI",{});var j$e=s(y2);lge=n(j$e,"STRONG",{});var Q_t=s(lge);Mko=r(Q_t,"ibert"),Q_t.forEach(t),Eko=r(j$e," \u2014 "),oO=n(j$e,"A",{href:!0});var W_t=s(oO);Cko=r(W_t,"IBertForMaskedLM"),W_t.forEach(t),wko=r(j$e," (I-BERT model)"),j$e.forEach(t),Ako=i(U),x2=n(U,"LI",{});var D$e=s(x2);ige=n(D$e,"STRONG",{});var H_t=s(ige);Lko=r(H_t,"layoutlm"),H_t.forEach(t),yko=r(D$e," \u2014 "),rO=n(D$e,"A",{href:!0});var U_t=s(rO);xko=r(U_t,"LayoutLMForMaskedLM"),U_t.forEach(t),$ko=r(D$e," (LayoutLM model)"),D$e.forEach(t),kko=i(U),$2=n(U,"LI",{});var G$e=s($2);dge=n(G$e,"STRONG",{});var J_t=s(dge);Sko=r(J_t,"longformer"),J_t.forEach(t),Rko=r(G$e," \u2014 "),tO=n(G$e,"A",{href:!0});var Y_t=s(tO);Pko=r(Y_t,"LongformerForMaskedLM"),Y_t.forEach(t),Bko=r(G$e," (Longformer model)"),G$e.forEach(t),Iko=i(U),k2=n(U,"LI",{});var O$e=s(k2);cge=n(O$e,"STRONG",{});var K_t=s(cge);Nko=r(K_t,"luke"),K_t.forEach(t),qko=r(O$e," \u2014 "),aO=n(O$e,"A",{href:!0});var Z_t=s(aO);jko=r(Z_t,"LukeForMaskedLM"),Z_t.forEach(t),Dko=r(O$e," (LUKE model)"),O$e.forEach(t),Gko=i(U),S2=n(U,"LI",{});var V$e=s(S2);fge=n(V$e,"STRONG",{});var eut=s(fge);Oko=r(eut,"mbart"),eut.forEach(t),Vko=r(V$e," \u2014 "),nO=n(V$e,"A",{href:!0});var out=s(nO);Xko=r(out,"MBartForConditionalGeneration"),out.forEach(t),zko=r(V$e," (mBART model)"),V$e.forEach(t),Qko=i(U),R2=n(U,"LI",{});var X$e=s(R2);mge=n(X$e,"STRONG",{});var rut=s(mge);Wko=r(rut,"megatron-bert"),rut.forEach(t),Hko=r(X$e," \u2014 "),sO=n(X$e,"A",{href:!0});var tut=s(sO);Uko=r(tut,"MegatronBertForMaskedLM"),tut.forEach(t),Jko=r(X$e," (Megatron-BERT model)"),X$e.forEach(t),Yko=i(U),P2=n(U,"LI",{});var z$e=s(P2);gge=n(z$e,"STRONG",{});var aut=s(gge);Kko=r(aut,"mobilebert"),aut.forEach(t),Zko=r(z$e," \u2014 "),lO=n(z$e,"A",{href:!0});var nut=s(lO);eSo=r(nut,"MobileBertForMaskedLM"),nut.forEach(t),oSo=r(z$e," (MobileBERT model)"),z$e.forEach(t),rSo=i(U),B2=n(U,"LI",{});var Q$e=s(B2);hge=n(Q$e,"STRONG",{});var sut=s(hge);tSo=r(sut,"mpnet"),sut.forEach(t),aSo=r(Q$e," \u2014 "),iO=n(Q$e,"A",{href:!0});var lut=s(iO);nSo=r(lut,"MPNetForMaskedLM"),lut.forEach(t),sSo=r(Q$e," (MPNet model)"),Q$e.forEach(t),lSo=i(U),I2=n(U,"LI",{});var W$e=s(I2);pge=n(W$e,"STRONG",{});var iut=s(pge);iSo=r(iut,"nezha"),iut.forEach(t),dSo=r(W$e," \u2014 "),dO=n(W$e,"A",{href:!0});var dut=s(dO);cSo=r(dut,"NezhaForMaskedLM"),dut.forEach(t),fSo=r(W$e," (Nezha model)"),W$e.forEach(t),mSo=i(U),N2=n(U,"LI",{});var H$e=s(N2);_ge=n(H$e,"STRONG",{});var cut=s(_ge);gSo=r(cut,"nystromformer"),cut.forEach(t),hSo=r(H$e," \u2014 "),cO=n(H$e,"A",{href:!0});var fut=s(cO);pSo=r(fut,"NystromformerForMaskedLM"),fut.forEach(t),_So=r(H$e," (Nystr\xF6mformer model)"),H$e.forEach(t),uSo=i(U),q2=n(U,"LI",{});var U$e=s(q2);uge=n(U$e,"STRONG",{});var mut=s(uge);bSo=r(mut,"perceiver"),mut.forEach(t),vSo=r(U$e," \u2014 "),fO=n(U$e,"A",{href:!0});var gut=s(fO);FSo=r(gut,"PerceiverForMaskedLM"),gut.forEach(t),TSo=r(U$e," (Perceiver model)"),U$e.forEach(t),MSo=i(U),j2=n(U,"LI",{});var J$e=s(j2);bge=n(J$e,"STRONG",{});var hut=s(bge);ESo=r(hut,"qdqbert"),hut.forEach(t),CSo=r(J$e," \u2014 "),mO=n(J$e,"A",{href:!0});var put=s(mO);wSo=r(put,"QDQBertForMaskedLM"),put.forEach(t),ASo=r(J$e," (QDQBert model)"),J$e.forEach(t),LSo=i(U),D2=n(U,"LI",{});var Y$e=s(D2);vge=n(Y$e,"STRONG",{});var _ut=s(vge);ySo=r(_ut,"reformer"),_ut.forEach(t),xSo=r(Y$e," \u2014 "),gO=n(Y$e,"A",{href:!0});var uut=s(gO);$So=r(uut,"ReformerForMaskedLM"),uut.forEach(t),kSo=r(Y$e," (Reformer model)"),Y$e.forEach(t),SSo=i(U),G2=n(U,"LI",{});var K$e=s(G2);Fge=n(K$e,"STRONG",{});var but=s(Fge);RSo=r(but,"rembert"),but.forEach(t),PSo=r(K$e," \u2014 "),hO=n(K$e,"A",{href:!0});var vut=s(hO);BSo=r(vut,"RemBertForMaskedLM"),vut.forEach(t),ISo=r(K$e," (RemBERT model)"),K$e.forEach(t),NSo=i(U),O2=n(U,"LI",{});var Z$e=s(O2);Tge=n(Z$e,"STRONG",{});var Fut=s(Tge);qSo=r(Fut,"roberta"),Fut.forEach(t),jSo=r(Z$e," \u2014 "),pO=n(Z$e,"A",{href:!0});var Tut=s(pO);DSo=r(Tut,"RobertaForMaskedLM"),Tut.forEach(t),GSo=r(Z$e," (RoBERTa model)"),Z$e.forEach(t),OSo=i(U),V2=n(U,"LI",{});var eke=s(V2);Mge=n(eke,"STRONG",{});var Mut=s(Mge);VSo=r(Mut,"roformer"),Mut.forEach(t),XSo=r(eke," \u2014 "),_O=n(eke,"A",{href:!0});var Eut=s(_O);zSo=r(Eut,"RoFormerForMaskedLM"),Eut.forEach(t),QSo=r(eke," (RoFormer model)"),eke.forEach(t),WSo=i(U),X2=n(U,"LI",{});var oke=s(X2);Ege=n(oke,"STRONG",{});var Cut=s(Ege);HSo=r(Cut,"squeezebert"),Cut.forEach(t),USo=r(oke," \u2014 "),uO=n(oke,"A",{href:!0});var wut=s(uO);JSo=r(wut,"SqueezeBertForMaskedLM"),wut.forEach(t),YSo=r(oke," (SqueezeBERT model)"),oke.forEach(t),KSo=i(U),z2=n(U,"LI",{});var rke=s(z2);Cge=n(rke,"STRONG",{});var Aut=s(Cge);ZSo=r(Aut,"tapas"),Aut.forEach(t),eRo=r(rke," \u2014 "),bO=n(rke,"A",{href:!0});var Lut=s(bO);oRo=r(Lut,"TapasForMaskedLM"),Lut.forEach(t),rRo=r(rke," (TAPAS model)"),rke.forEach(t),tRo=i(U),Q2=n(U,"LI",{});var tke=s(Q2);wge=n(tke,"STRONG",{});var yut=s(wge);aRo=r(yut,"wav2vec2"),yut.forEach(t),nRo=r(tke," \u2014 "),Age=n(tke,"CODE",{});var xut=s(Age);sRo=r(xut,"Wav2Vec2ForMaskedLM"),xut.forEach(t),lRo=r(tke," (Wav2Vec2 model)"),tke.forEach(t),iRo=i(U),W2=n(U,"LI",{});var ake=s(W2);Lge=n(ake,"STRONG",{});var $ut=s(Lge);dRo=r($ut,"xlm"),$ut.forEach(t),cRo=r(ake," \u2014 "),vO=n(ake,"A",{href:!0});var kut=s(vO);fRo=r(kut,"XLMWithLMHeadModel"),kut.forEach(t),mRo=r(ake," (XLM model)"),ake.forEach(t),gRo=i(U),H2=n(U,"LI",{});var nke=s(H2);yge=n(nke,"STRONG",{});var Sut=s(yge);hRo=r(Sut,"xlm-roberta"),Sut.forEach(t),pRo=r(nke," \u2014 "),FO=n(nke,"A",{href:!0});var Rut=s(FO);_Ro=r(Rut,"XLMRobertaForMaskedLM"),Rut.forEach(t),uRo=r(nke," (XLM-RoBERTa model)"),nke.forEach(t),bRo=i(U),U2=n(U,"LI",{});var ske=s(U2);xge=n(ske,"STRONG",{});var Put=s(xge);vRo=r(Put,"xlm-roberta-xl"),Put.forEach(t),FRo=r(ske," \u2014 "),TO=n(ske,"A",{href:!0});var But=s(TO);TRo=r(But,"XLMRobertaXLForMaskedLM"),But.forEach(t),MRo=r(ske," (XLM-RoBERTa-XL model)"),ske.forEach(t),ERo=i(U),J2=n(U,"LI",{});var lke=s(J2);$ge=n(lke,"STRONG",{});var Iut=s($ge);CRo=r(Iut,"yoso"),Iut.forEach(t),wRo=r(lke," \u2014 "),MO=n(lke,"A",{href:!0});var Nut=s(MO);ARo=r(Nut,"YosoForMaskedLM"),Nut.forEach(t),LRo=r(lke," (YOSO model)"),lke.forEach(t),U.forEach(t),yRo=i(la),Y2=n(la,"P",{});var ike=s(Y2);xRo=r(ike,"The model is set in evaluation mode by default using "),kge=n(ike,"CODE",{});var qut=s(kge);$Ro=r(qut,"model.eval()"),qut.forEach(t),kRo=r(ike,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Sge=n(ike,"CODE",{});var jut=s(Sge);SRo=r(jut,"model.train()"),jut.forEach(t),ike.forEach(t),RRo=i(la),T(K2.$$.fragment,la),la.forEach(t),el.forEach(t),sOe=i(f),Wi=n(f,"H2",{class:!0});var mXe=s(Wi);Z2=n(mXe,"A",{id:!0,class:!0,href:!0});var Dut=s(Z2);Rge=n(Dut,"SPAN",{});var Gut=s(Rge);T(TA.$$.fragment,Gut),Gut.forEach(t),Dut.forEach(t),PRo=i(mXe),Pge=n(mXe,"SPAN",{});var Out=s(Pge);BRo=r(Out,"AutoModelForSeq2SeqLM"),Out.forEach(t),mXe.forEach(t),lOe=i(f),Ro=n(f,"DIV",{class:!0});var ol=s(Ro);T(MA.$$.fragment,ol),IRo=i(ol),Hi=n(ol,"P",{});var Loe=s(Hi);NRo=r(Loe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),EO=n(Loe,"A",{href:!0});var Vut=s(EO);qRo=r(Vut,"from_pretrained()"),Vut.forEach(t),jRo=r(Loe," class method or the "),CO=n(Loe,"A",{href:!0});var Xut=s(CO);DRo=r(Xut,"from_config()"),Xut.forEach(t),GRo=r(Loe,` class
method.`),Loe.forEach(t),ORo=i(ol),EA=n(ol,"P",{});var gXe=s(EA);VRo=r(gXe,"This class cannot be instantiated directly using "),Bge=n(gXe,"CODE",{});var zut=s(Bge);XRo=r(zut,"__init__()"),zut.forEach(t),zRo=r(gXe," (throws an error)."),gXe.forEach(t),QRo=i(ol),dt=n(ol,"DIV",{class:!0});var j3=s(dt);T(CA.$$.fragment,j3),WRo=i(j3),Ige=n(j3,"P",{});var Qut=s(Ige);HRo=r(Qut,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),Qut.forEach(t),URo=i(j3),Ui=n(j3,"P",{});var yoe=s(Ui);JRo=r(yoe,`Note:
Loading a model from its configuration file does `),Nge=n(yoe,"STRONG",{});var Wut=s(Nge);YRo=r(Wut,"not"),Wut.forEach(t),KRo=r(yoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),wO=n(yoe,"A",{href:!0});var Hut=s(wO);ZRo=r(Hut,"from_pretrained()"),Hut.forEach(t),ePo=r(yoe," to load the model weights."),yoe.forEach(t),oPo=i(j3),T(eb.$$.fragment,j3),j3.forEach(t),rPo=i(ol),eo=n(ol,"DIV",{class:!0});var ia=s(eo);T(wA.$$.fragment,ia),tPo=i(ia),qge=n(ia,"P",{});var Uut=s(qge);aPo=r(Uut,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),Uut.forEach(t),nPo=i(ia),Na=n(ia,"P",{});var D3=s(Na);sPo=r(D3,"The model class to instantiate is selected based on the "),jge=n(D3,"CODE",{});var Jut=s(jge);lPo=r(Jut,"model_type"),Jut.forEach(t),iPo=r(D3,` property of the config object (either
passed as an argument or loaded from `),Dge=n(D3,"CODE",{});var Yut=s(Dge);dPo=r(Yut,"pretrained_model_name_or_path"),Yut.forEach(t),cPo=r(D3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Gge=n(D3,"CODE",{});var Kut=s(Gge);fPo=r(Kut,"pretrained_model_name_or_path"),Kut.forEach(t),mPo=r(D3,":"),D3.forEach(t),gPo=i(ia),pe=n(ia,"UL",{});var be=s(pe);ob=n(be,"LI",{});var dke=s(ob);Oge=n(dke,"STRONG",{});var Zut=s(Oge);hPo=r(Zut,"bart"),Zut.forEach(t),pPo=r(dke," \u2014 "),AO=n(dke,"A",{href:!0});var e1t=s(AO);_Po=r(e1t,"BartForConditionalGeneration"),e1t.forEach(t),uPo=r(dke," (BART model)"),dke.forEach(t),bPo=i(be),rb=n(be,"LI",{});var cke=s(rb);Vge=n(cke,"STRONG",{});var o1t=s(Vge);vPo=r(o1t,"bigbird_pegasus"),o1t.forEach(t),FPo=r(cke," \u2014 "),LO=n(cke,"A",{href:!0});var r1t=s(LO);TPo=r(r1t,"BigBirdPegasusForConditionalGeneration"),r1t.forEach(t),MPo=r(cke," (BigBird-Pegasus model)"),cke.forEach(t),EPo=i(be),tb=n(be,"LI",{});var fke=s(tb);Xge=n(fke,"STRONG",{});var t1t=s(Xge);CPo=r(t1t,"blenderbot"),t1t.forEach(t),wPo=r(fke," \u2014 "),yO=n(fke,"A",{href:!0});var a1t=s(yO);APo=r(a1t,"BlenderbotForConditionalGeneration"),a1t.forEach(t),LPo=r(fke," (Blenderbot model)"),fke.forEach(t),yPo=i(be),ab=n(be,"LI",{});var mke=s(ab);zge=n(mke,"STRONG",{});var n1t=s(zge);xPo=r(n1t,"blenderbot-small"),n1t.forEach(t),$Po=r(mke," \u2014 "),xO=n(mke,"A",{href:!0});var s1t=s(xO);kPo=r(s1t,"BlenderbotSmallForConditionalGeneration"),s1t.forEach(t),SPo=r(mke," (BlenderbotSmall model)"),mke.forEach(t),RPo=i(be),nb=n(be,"LI",{});var gke=s(nb);Qge=n(gke,"STRONG",{});var l1t=s(Qge);PPo=r(l1t,"encoder-decoder"),l1t.forEach(t),BPo=r(gke," \u2014 "),$O=n(gke,"A",{href:!0});var i1t=s($O);IPo=r(i1t,"EncoderDecoderModel"),i1t.forEach(t),NPo=r(gke," (Encoder decoder model)"),gke.forEach(t),qPo=i(be),sb=n(be,"LI",{});var hke=s(sb);Wge=n(hke,"STRONG",{});var d1t=s(Wge);jPo=r(d1t,"fsmt"),d1t.forEach(t),DPo=r(hke," \u2014 "),kO=n(hke,"A",{href:!0});var c1t=s(kO);GPo=r(c1t,"FSMTForConditionalGeneration"),c1t.forEach(t),OPo=r(hke," (FairSeq Machine-Translation model)"),hke.forEach(t),VPo=i(be),lb=n(be,"LI",{});var pke=s(lb);Hge=n(pke,"STRONG",{});var f1t=s(Hge);XPo=r(f1t,"led"),f1t.forEach(t),zPo=r(pke," \u2014 "),SO=n(pke,"A",{href:!0});var m1t=s(SO);QPo=r(m1t,"LEDForConditionalGeneration"),m1t.forEach(t),WPo=r(pke," (LED model)"),pke.forEach(t),HPo=i(be),ib=n(be,"LI",{});var _ke=s(ib);Uge=n(_ke,"STRONG",{});var g1t=s(Uge);UPo=r(g1t,"longt5"),g1t.forEach(t),JPo=r(_ke," \u2014 "),RO=n(_ke,"A",{href:!0});var h1t=s(RO);YPo=r(h1t,"LongT5ForConditionalGeneration"),h1t.forEach(t),KPo=r(_ke," (LongT5 model)"),_ke.forEach(t),ZPo=i(be),db=n(be,"LI",{});var uke=s(db);Jge=n(uke,"STRONG",{});var p1t=s(Jge);eBo=r(p1t,"m2m_100"),p1t.forEach(t),oBo=r(uke," \u2014 "),PO=n(uke,"A",{href:!0});var _1t=s(PO);rBo=r(_1t,"M2M100ForConditionalGeneration"),_1t.forEach(t),tBo=r(uke," (M2M100 model)"),uke.forEach(t),aBo=i(be),cb=n(be,"LI",{});var bke=s(cb);Yge=n(bke,"STRONG",{});var u1t=s(Yge);nBo=r(u1t,"marian"),u1t.forEach(t),sBo=r(bke," \u2014 "),BO=n(bke,"A",{href:!0});var b1t=s(BO);lBo=r(b1t,"MarianMTModel"),b1t.forEach(t),iBo=r(bke," (Marian model)"),bke.forEach(t),dBo=i(be),fb=n(be,"LI",{});var vke=s(fb);Kge=n(vke,"STRONG",{});var v1t=s(Kge);cBo=r(v1t,"mbart"),v1t.forEach(t),fBo=r(vke," \u2014 "),IO=n(vke,"A",{href:!0});var F1t=s(IO);mBo=r(F1t,"MBartForConditionalGeneration"),F1t.forEach(t),gBo=r(vke," (mBART model)"),vke.forEach(t),hBo=i(be),mb=n(be,"LI",{});var Fke=s(mb);Zge=n(Fke,"STRONG",{});var T1t=s(Zge);pBo=r(T1t,"mt5"),T1t.forEach(t),_Bo=r(Fke," \u2014 "),NO=n(Fke,"A",{href:!0});var M1t=s(NO);uBo=r(M1t,"MT5ForConditionalGeneration"),M1t.forEach(t),bBo=r(Fke," (MT5 model)"),Fke.forEach(t),vBo=i(be),gb=n(be,"LI",{});var Tke=s(gb);ehe=n(Tke,"STRONG",{});var E1t=s(ehe);FBo=r(E1t,"pegasus"),E1t.forEach(t),TBo=r(Tke," \u2014 "),qO=n(Tke,"A",{href:!0});var C1t=s(qO);MBo=r(C1t,"PegasusForConditionalGeneration"),C1t.forEach(t),EBo=r(Tke," (Pegasus model)"),Tke.forEach(t),CBo=i(be),hb=n(be,"LI",{});var Mke=s(hb);ohe=n(Mke,"STRONG",{});var w1t=s(ohe);wBo=r(w1t,"plbart"),w1t.forEach(t),ABo=r(Mke," \u2014 "),jO=n(Mke,"A",{href:!0});var A1t=s(jO);LBo=r(A1t,"PLBartForConditionalGeneration"),A1t.forEach(t),yBo=r(Mke," (PLBart model)"),Mke.forEach(t),xBo=i(be),pb=n(be,"LI",{});var Eke=s(pb);rhe=n(Eke,"STRONG",{});var L1t=s(rhe);$Bo=r(L1t,"prophetnet"),L1t.forEach(t),kBo=r(Eke," \u2014 "),DO=n(Eke,"A",{href:!0});var y1t=s(DO);SBo=r(y1t,"ProphetNetForConditionalGeneration"),y1t.forEach(t),RBo=r(Eke," (ProphetNet model)"),Eke.forEach(t),PBo=i(be),_b=n(be,"LI",{});var Cke=s(_b);the=n(Cke,"STRONG",{});var x1t=s(the);BBo=r(x1t,"t5"),x1t.forEach(t),IBo=r(Cke," \u2014 "),GO=n(Cke,"A",{href:!0});var $1t=s(GO);NBo=r($1t,"T5ForConditionalGeneration"),$1t.forEach(t),qBo=r(Cke," (T5 model)"),Cke.forEach(t),jBo=i(be),ub=n(be,"LI",{});var wke=s(ub);ahe=n(wke,"STRONG",{});var k1t=s(ahe);DBo=r(k1t,"xlm-prophetnet"),k1t.forEach(t),GBo=r(wke," \u2014 "),OO=n(wke,"A",{href:!0});var S1t=s(OO);OBo=r(S1t,"XLMProphetNetForConditionalGeneration"),S1t.forEach(t),VBo=r(wke," (XLM-ProphetNet model)"),wke.forEach(t),be.forEach(t),XBo=i(ia),bb=n(ia,"P",{});var Ake=s(bb);zBo=r(Ake,"The model is set in evaluation mode by default using "),nhe=n(Ake,"CODE",{});var R1t=s(nhe);QBo=r(R1t,"model.eval()"),R1t.forEach(t),WBo=r(Ake,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),she=n(Ake,"CODE",{});var P1t=s(she);HBo=r(P1t,"model.train()"),P1t.forEach(t),Ake.forEach(t),UBo=i(ia),T(vb.$$.fragment,ia),ia.forEach(t),ol.forEach(t),iOe=i(f),Ji=n(f,"H2",{class:!0});var hXe=s(Ji);Fb=n(hXe,"A",{id:!0,class:!0,href:!0});var B1t=s(Fb);lhe=n(B1t,"SPAN",{});var I1t=s(lhe);T(AA.$$.fragment,I1t),I1t.forEach(t),B1t.forEach(t),JBo=i(hXe),ihe=n(hXe,"SPAN",{});var N1t=s(ihe);YBo=r(N1t,"AutoModelForSequenceClassification"),N1t.forEach(t),hXe.forEach(t),dOe=i(f),Po=n(f,"DIV",{class:!0});var rl=s(Po);T(LA.$$.fragment,rl),KBo=i(rl),Yi=n(rl,"P",{});var xoe=s(Yi);ZBo=r(xoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),VO=n(xoe,"A",{href:!0});var q1t=s(VO);eIo=r(q1t,"from_pretrained()"),q1t.forEach(t),oIo=r(xoe," class method or the "),XO=n(xoe,"A",{href:!0});var j1t=s(XO);rIo=r(j1t,"from_config()"),j1t.forEach(t),tIo=r(xoe,` class
method.`),xoe.forEach(t),aIo=i(rl),yA=n(rl,"P",{});var pXe=s(yA);nIo=r(pXe,"This class cannot be instantiated directly using "),dhe=n(pXe,"CODE",{});var D1t=s(dhe);sIo=r(D1t,"__init__()"),D1t.forEach(t),lIo=r(pXe," (throws an error)."),pXe.forEach(t),iIo=i(rl),ct=n(rl,"DIV",{class:!0});var G3=s(ct);T(xA.$$.fragment,G3),dIo=i(G3),che=n(G3,"P",{});var G1t=s(che);cIo=r(G1t,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),G1t.forEach(t),fIo=i(G3),Ki=n(G3,"P",{});var $oe=s(Ki);mIo=r($oe,`Note:
Loading a model from its configuration file does `),fhe=n($oe,"STRONG",{});var O1t=s(fhe);gIo=r(O1t,"not"),O1t.forEach(t),hIo=r($oe,` load the model weights. It only affects the
model\u2019s configuration. Use `),zO=n($oe,"A",{href:!0});var V1t=s(zO);pIo=r(V1t,"from_pretrained()"),V1t.forEach(t),_Io=r($oe," to load the model weights."),$oe.forEach(t),uIo=i(G3),T(Tb.$$.fragment,G3),G3.forEach(t),bIo=i(rl),oo=n(rl,"DIV",{class:!0});var da=s(oo);T($A.$$.fragment,da),vIo=i(da),mhe=n(da,"P",{});var X1t=s(mhe);FIo=r(X1t,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),X1t.forEach(t),TIo=i(da),qa=n(da,"P",{});var O3=s(qa);MIo=r(O3,"The model class to instantiate is selected based on the "),ghe=n(O3,"CODE",{});var z1t=s(ghe);EIo=r(z1t,"model_type"),z1t.forEach(t),CIo=r(O3,` property of the config object (either
passed as an argument or loaded from `),hhe=n(O3,"CODE",{});var Q1t=s(hhe);wIo=r(Q1t,"pretrained_model_name_or_path"),Q1t.forEach(t),AIo=r(O3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),phe=n(O3,"CODE",{});var W1t=s(phe);LIo=r(W1t,"pretrained_model_name_or_path"),W1t.forEach(t),yIo=r(O3,":"),O3.forEach(t),xIo=i(da),N=n(da,"UL",{});var q=s(N);Mb=n(q,"LI",{});var Lke=s(Mb);_he=n(Lke,"STRONG",{});var H1t=s(_he);$Io=r(H1t,"albert"),H1t.forEach(t),kIo=r(Lke," \u2014 "),QO=n(Lke,"A",{href:!0});var U1t=s(QO);SIo=r(U1t,"AlbertForSequenceClassification"),U1t.forEach(t),RIo=r(Lke," (ALBERT model)"),Lke.forEach(t),PIo=i(q),Eb=n(q,"LI",{});var yke=s(Eb);uhe=n(yke,"STRONG",{});var J1t=s(uhe);BIo=r(J1t,"bart"),J1t.forEach(t),IIo=r(yke," \u2014 "),WO=n(yke,"A",{href:!0});var Y1t=s(WO);NIo=r(Y1t,"BartForSequenceClassification"),Y1t.forEach(t),qIo=r(yke," (BART model)"),yke.forEach(t),jIo=i(q),Cb=n(q,"LI",{});var xke=s(Cb);bhe=n(xke,"STRONG",{});var K1t=s(bhe);DIo=r(K1t,"bert"),K1t.forEach(t),GIo=r(xke," \u2014 "),HO=n(xke,"A",{href:!0});var Z1t=s(HO);OIo=r(Z1t,"BertForSequenceClassification"),Z1t.forEach(t),VIo=r(xke," (BERT model)"),xke.forEach(t),XIo=i(q),wb=n(q,"LI",{});var $ke=s(wb);vhe=n($ke,"STRONG",{});var e2t=s(vhe);zIo=r(e2t,"big_bird"),e2t.forEach(t),QIo=r($ke," \u2014 "),UO=n($ke,"A",{href:!0});var o2t=s(UO);WIo=r(o2t,"BigBirdForSequenceClassification"),o2t.forEach(t),HIo=r($ke," (BigBird model)"),$ke.forEach(t),UIo=i(q),Ab=n(q,"LI",{});var kke=s(Ab);Fhe=n(kke,"STRONG",{});var r2t=s(Fhe);JIo=r(r2t,"bigbird_pegasus"),r2t.forEach(t),YIo=r(kke," \u2014 "),JO=n(kke,"A",{href:!0});var t2t=s(JO);KIo=r(t2t,"BigBirdPegasusForSequenceClassification"),t2t.forEach(t),ZIo=r(kke," (BigBird-Pegasus model)"),kke.forEach(t),eNo=i(q),Lb=n(q,"LI",{});var Ske=s(Lb);The=n(Ske,"STRONG",{});var a2t=s(The);oNo=r(a2t,"bloom"),a2t.forEach(t),rNo=r(Ske," \u2014 "),YO=n(Ske,"A",{href:!0});var n2t=s(YO);tNo=r(n2t,"BloomForSequenceClassification"),n2t.forEach(t),aNo=r(Ske," (BLOOM model)"),Ske.forEach(t),nNo=i(q),yb=n(q,"LI",{});var Rke=s(yb);Mhe=n(Rke,"STRONG",{});var s2t=s(Mhe);sNo=r(s2t,"camembert"),s2t.forEach(t),lNo=r(Rke," \u2014 "),KO=n(Rke,"A",{href:!0});var l2t=s(KO);iNo=r(l2t,"CamembertForSequenceClassification"),l2t.forEach(t),dNo=r(Rke," (CamemBERT model)"),Rke.forEach(t),cNo=i(q),xb=n(q,"LI",{});var Pke=s(xb);Ehe=n(Pke,"STRONG",{});var i2t=s(Ehe);fNo=r(i2t,"canine"),i2t.forEach(t),mNo=r(Pke," \u2014 "),ZO=n(Pke,"A",{href:!0});var d2t=s(ZO);gNo=r(d2t,"CanineForSequenceClassification"),d2t.forEach(t),hNo=r(Pke," (CANINE model)"),Pke.forEach(t),pNo=i(q),$b=n(q,"LI",{});var Bke=s($b);Che=n(Bke,"STRONG",{});var c2t=s(Che);_No=r(c2t,"convbert"),c2t.forEach(t),uNo=r(Bke," \u2014 "),eV=n(Bke,"A",{href:!0});var f2t=s(eV);bNo=r(f2t,"ConvBertForSequenceClassification"),f2t.forEach(t),vNo=r(Bke," (ConvBERT model)"),Bke.forEach(t),FNo=i(q),kb=n(q,"LI",{});var Ike=s(kb);whe=n(Ike,"STRONG",{});var m2t=s(whe);TNo=r(m2t,"ctrl"),m2t.forEach(t),MNo=r(Ike," \u2014 "),oV=n(Ike,"A",{href:!0});var g2t=s(oV);ENo=r(g2t,"CTRLForSequenceClassification"),g2t.forEach(t),CNo=r(Ike," (CTRL model)"),Ike.forEach(t),wNo=i(q),Sb=n(q,"LI",{});var Nke=s(Sb);Ahe=n(Nke,"STRONG",{});var h2t=s(Ahe);ANo=r(h2t,"data2vec-text"),h2t.forEach(t),LNo=r(Nke," \u2014 "),rV=n(Nke,"A",{href:!0});var p2t=s(rV);yNo=r(p2t,"Data2VecTextForSequenceClassification"),p2t.forEach(t),xNo=r(Nke," (Data2VecText model)"),Nke.forEach(t),$No=i(q),Rb=n(q,"LI",{});var qke=s(Rb);Lhe=n(qke,"STRONG",{});var _2t=s(Lhe);kNo=r(_2t,"deberta"),_2t.forEach(t),SNo=r(qke," \u2014 "),tV=n(qke,"A",{href:!0});var u2t=s(tV);RNo=r(u2t,"DebertaForSequenceClassification"),u2t.forEach(t),PNo=r(qke," (DeBERTa model)"),qke.forEach(t),BNo=i(q),Pb=n(q,"LI",{});var jke=s(Pb);yhe=n(jke,"STRONG",{});var b2t=s(yhe);INo=r(b2t,"deberta-v2"),b2t.forEach(t),NNo=r(jke," \u2014 "),aV=n(jke,"A",{href:!0});var v2t=s(aV);qNo=r(v2t,"DebertaV2ForSequenceClassification"),v2t.forEach(t),jNo=r(jke," (DeBERTa-v2 model)"),jke.forEach(t),DNo=i(q),Bb=n(q,"LI",{});var Dke=s(Bb);xhe=n(Dke,"STRONG",{});var F2t=s(xhe);GNo=r(F2t,"distilbert"),F2t.forEach(t),ONo=r(Dke," \u2014 "),nV=n(Dke,"A",{href:!0});var T2t=s(nV);VNo=r(T2t,"DistilBertForSequenceClassification"),T2t.forEach(t),XNo=r(Dke," (DistilBERT model)"),Dke.forEach(t),zNo=i(q),Ib=n(q,"LI",{});var Gke=s(Ib);$he=n(Gke,"STRONG",{});var M2t=s($he);QNo=r(M2t,"electra"),M2t.forEach(t),WNo=r(Gke," \u2014 "),sV=n(Gke,"A",{href:!0});var E2t=s(sV);HNo=r(E2t,"ElectraForSequenceClassification"),E2t.forEach(t),UNo=r(Gke," (ELECTRA model)"),Gke.forEach(t),JNo=i(q),Nb=n(q,"LI",{});var Oke=s(Nb);khe=n(Oke,"STRONG",{});var C2t=s(khe);YNo=r(C2t,"flaubert"),C2t.forEach(t),KNo=r(Oke," \u2014 "),lV=n(Oke,"A",{href:!0});var w2t=s(lV);ZNo=r(w2t,"FlaubertForSequenceClassification"),w2t.forEach(t),eqo=r(Oke," (FlauBERT model)"),Oke.forEach(t),oqo=i(q),qb=n(q,"LI",{});var Vke=s(qb);She=n(Vke,"STRONG",{});var A2t=s(She);rqo=r(A2t,"fnet"),A2t.forEach(t),tqo=r(Vke," \u2014 "),iV=n(Vke,"A",{href:!0});var L2t=s(iV);aqo=r(L2t,"FNetForSequenceClassification"),L2t.forEach(t),nqo=r(Vke," (FNet model)"),Vke.forEach(t),sqo=i(q),jb=n(q,"LI",{});var Xke=s(jb);Rhe=n(Xke,"STRONG",{});var y2t=s(Rhe);lqo=r(y2t,"funnel"),y2t.forEach(t),iqo=r(Xke," \u2014 "),dV=n(Xke,"A",{href:!0});var x2t=s(dV);dqo=r(x2t,"FunnelForSequenceClassification"),x2t.forEach(t),cqo=r(Xke," (Funnel Transformer model)"),Xke.forEach(t),fqo=i(q),Db=n(q,"LI",{});var zke=s(Db);Phe=n(zke,"STRONG",{});var $2t=s(Phe);mqo=r($2t,"gpt2"),$2t.forEach(t),gqo=r(zke," \u2014 "),cV=n(zke,"A",{href:!0});var k2t=s(cV);hqo=r(k2t,"GPT2ForSequenceClassification"),k2t.forEach(t),pqo=r(zke," (OpenAI GPT-2 model)"),zke.forEach(t),_qo=i(q),Gb=n(q,"LI",{});var Qke=s(Gb);Bhe=n(Qke,"STRONG",{});var S2t=s(Bhe);uqo=r(S2t,"gpt_neo"),S2t.forEach(t),bqo=r(Qke," \u2014 "),fV=n(Qke,"A",{href:!0});var R2t=s(fV);vqo=r(R2t,"GPTNeoForSequenceClassification"),R2t.forEach(t),Fqo=r(Qke," (GPT Neo model)"),Qke.forEach(t),Tqo=i(q),Ob=n(q,"LI",{});var Wke=s(Ob);Ihe=n(Wke,"STRONG",{});var P2t=s(Ihe);Mqo=r(P2t,"gptj"),P2t.forEach(t),Eqo=r(Wke," \u2014 "),mV=n(Wke,"A",{href:!0});var B2t=s(mV);Cqo=r(B2t,"GPTJForSequenceClassification"),B2t.forEach(t),wqo=r(Wke," (GPT-J model)"),Wke.forEach(t),Aqo=i(q),Vb=n(q,"LI",{});var Hke=s(Vb);Nhe=n(Hke,"STRONG",{});var I2t=s(Nhe);Lqo=r(I2t,"ibert"),I2t.forEach(t),yqo=r(Hke," \u2014 "),gV=n(Hke,"A",{href:!0});var N2t=s(gV);xqo=r(N2t,"IBertForSequenceClassification"),N2t.forEach(t),$qo=r(Hke," (I-BERT model)"),Hke.forEach(t),kqo=i(q),Xb=n(q,"LI",{});var Uke=s(Xb);qhe=n(Uke,"STRONG",{});var q2t=s(qhe);Sqo=r(q2t,"layoutlm"),q2t.forEach(t),Rqo=r(Uke," \u2014 "),hV=n(Uke,"A",{href:!0});var j2t=s(hV);Pqo=r(j2t,"LayoutLMForSequenceClassification"),j2t.forEach(t),Bqo=r(Uke," (LayoutLM model)"),Uke.forEach(t),Iqo=i(q),zb=n(q,"LI",{});var Jke=s(zb);jhe=n(Jke,"STRONG",{});var D2t=s(jhe);Nqo=r(D2t,"layoutlmv2"),D2t.forEach(t),qqo=r(Jke," \u2014 "),pV=n(Jke,"A",{href:!0});var G2t=s(pV);jqo=r(G2t,"LayoutLMv2ForSequenceClassification"),G2t.forEach(t),Dqo=r(Jke," (LayoutLMv2 model)"),Jke.forEach(t),Gqo=i(q),Qb=n(q,"LI",{});var Yke=s(Qb);Dhe=n(Yke,"STRONG",{});var O2t=s(Dhe);Oqo=r(O2t,"layoutlmv3"),O2t.forEach(t),Vqo=r(Yke," \u2014 "),_V=n(Yke,"A",{href:!0});var V2t=s(_V);Xqo=r(V2t,"LayoutLMv3ForSequenceClassification"),V2t.forEach(t),zqo=r(Yke," (LayoutLMv3 model)"),Yke.forEach(t),Qqo=i(q),Wb=n(q,"LI",{});var Kke=s(Wb);Ghe=n(Kke,"STRONG",{});var X2t=s(Ghe);Wqo=r(X2t,"led"),X2t.forEach(t),Hqo=r(Kke," \u2014 "),uV=n(Kke,"A",{href:!0});var z2t=s(uV);Uqo=r(z2t,"LEDForSequenceClassification"),z2t.forEach(t),Jqo=r(Kke," (LED model)"),Kke.forEach(t),Yqo=i(q),Hb=n(q,"LI",{});var Zke=s(Hb);Ohe=n(Zke,"STRONG",{});var Q2t=s(Ohe);Kqo=r(Q2t,"longformer"),Q2t.forEach(t),Zqo=r(Zke," \u2014 "),bV=n(Zke,"A",{href:!0});var W2t=s(bV);ejo=r(W2t,"LongformerForSequenceClassification"),W2t.forEach(t),ojo=r(Zke," (Longformer model)"),Zke.forEach(t),rjo=i(q),Ub=n(q,"LI",{});var eSe=s(Ub);Vhe=n(eSe,"STRONG",{});var H2t=s(Vhe);tjo=r(H2t,"mbart"),H2t.forEach(t),ajo=r(eSe," \u2014 "),vV=n(eSe,"A",{href:!0});var U2t=s(vV);njo=r(U2t,"MBartForSequenceClassification"),U2t.forEach(t),sjo=r(eSe," (mBART model)"),eSe.forEach(t),ljo=i(q),Jb=n(q,"LI",{});var oSe=s(Jb);Xhe=n(oSe,"STRONG",{});var J2t=s(Xhe);ijo=r(J2t,"megatron-bert"),J2t.forEach(t),djo=r(oSe," \u2014 "),FV=n(oSe,"A",{href:!0});var Y2t=s(FV);cjo=r(Y2t,"MegatronBertForSequenceClassification"),Y2t.forEach(t),fjo=r(oSe," (Megatron-BERT model)"),oSe.forEach(t),mjo=i(q),Yb=n(q,"LI",{});var rSe=s(Yb);zhe=n(rSe,"STRONG",{});var K2t=s(zhe);gjo=r(K2t,"mobilebert"),K2t.forEach(t),hjo=r(rSe," \u2014 "),TV=n(rSe,"A",{href:!0});var Z2t=s(TV);pjo=r(Z2t,"MobileBertForSequenceClassification"),Z2t.forEach(t),_jo=r(rSe," (MobileBERT model)"),rSe.forEach(t),ujo=i(q),Kb=n(q,"LI",{});var tSe=s(Kb);Qhe=n(tSe,"STRONG",{});var ebt=s(Qhe);bjo=r(ebt,"mpnet"),ebt.forEach(t),vjo=r(tSe," \u2014 "),MV=n(tSe,"A",{href:!0});var obt=s(MV);Fjo=r(obt,"MPNetForSequenceClassification"),obt.forEach(t),Tjo=r(tSe," (MPNet model)"),tSe.forEach(t),Mjo=i(q),Zb=n(q,"LI",{});var aSe=s(Zb);Whe=n(aSe,"STRONG",{});var rbt=s(Whe);Ejo=r(rbt,"nezha"),rbt.forEach(t),Cjo=r(aSe," \u2014 "),EV=n(aSe,"A",{href:!0});var tbt=s(EV);wjo=r(tbt,"NezhaForSequenceClassification"),tbt.forEach(t),Ajo=r(aSe," (Nezha model)"),aSe.forEach(t),Ljo=i(q),ev=n(q,"LI",{});var nSe=s(ev);Hhe=n(nSe,"STRONG",{});var abt=s(Hhe);yjo=r(abt,"nystromformer"),abt.forEach(t),xjo=r(nSe," \u2014 "),CV=n(nSe,"A",{href:!0});var nbt=s(CV);$jo=r(nbt,"NystromformerForSequenceClassification"),nbt.forEach(t),kjo=r(nSe," (Nystr\xF6mformer model)"),nSe.forEach(t),Sjo=i(q),ov=n(q,"LI",{});var sSe=s(ov);Uhe=n(sSe,"STRONG",{});var sbt=s(Uhe);Rjo=r(sbt,"openai-gpt"),sbt.forEach(t),Pjo=r(sSe," \u2014 "),wV=n(sSe,"A",{href:!0});var lbt=s(wV);Bjo=r(lbt,"OpenAIGPTForSequenceClassification"),lbt.forEach(t),Ijo=r(sSe," (OpenAI GPT model)"),sSe.forEach(t),Njo=i(q),rv=n(q,"LI",{});var lSe=s(rv);Jhe=n(lSe,"STRONG",{});var ibt=s(Jhe);qjo=r(ibt,"perceiver"),ibt.forEach(t),jjo=r(lSe," \u2014 "),AV=n(lSe,"A",{href:!0});var dbt=s(AV);Djo=r(dbt,"PerceiverForSequenceClassification"),dbt.forEach(t),Gjo=r(lSe," (Perceiver model)"),lSe.forEach(t),Ojo=i(q),tv=n(q,"LI",{});var iSe=s(tv);Yhe=n(iSe,"STRONG",{});var cbt=s(Yhe);Vjo=r(cbt,"plbart"),cbt.forEach(t),Xjo=r(iSe," \u2014 "),LV=n(iSe,"A",{href:!0});var fbt=s(LV);zjo=r(fbt,"PLBartForSequenceClassification"),fbt.forEach(t),Qjo=r(iSe," (PLBart model)"),iSe.forEach(t),Wjo=i(q),av=n(q,"LI",{});var dSe=s(av);Khe=n(dSe,"STRONG",{});var mbt=s(Khe);Hjo=r(mbt,"qdqbert"),mbt.forEach(t),Ujo=r(dSe," \u2014 "),yV=n(dSe,"A",{href:!0});var gbt=s(yV);Jjo=r(gbt,"QDQBertForSequenceClassification"),gbt.forEach(t),Yjo=r(dSe," (QDQBert model)"),dSe.forEach(t),Kjo=i(q),nv=n(q,"LI",{});var cSe=s(nv);Zhe=n(cSe,"STRONG",{});var hbt=s(Zhe);Zjo=r(hbt,"reformer"),hbt.forEach(t),eDo=r(cSe," \u2014 "),xV=n(cSe,"A",{href:!0});var pbt=s(xV);oDo=r(pbt,"ReformerForSequenceClassification"),pbt.forEach(t),rDo=r(cSe," (Reformer model)"),cSe.forEach(t),tDo=i(q),sv=n(q,"LI",{});var fSe=s(sv);epe=n(fSe,"STRONG",{});var _bt=s(epe);aDo=r(_bt,"rembert"),_bt.forEach(t),nDo=r(fSe," \u2014 "),$V=n(fSe,"A",{href:!0});var ubt=s($V);sDo=r(ubt,"RemBertForSequenceClassification"),ubt.forEach(t),lDo=r(fSe," (RemBERT model)"),fSe.forEach(t),iDo=i(q),lv=n(q,"LI",{});var mSe=s(lv);ope=n(mSe,"STRONG",{});var bbt=s(ope);dDo=r(bbt,"roberta"),bbt.forEach(t),cDo=r(mSe," \u2014 "),kV=n(mSe,"A",{href:!0});var vbt=s(kV);fDo=r(vbt,"RobertaForSequenceClassification"),vbt.forEach(t),mDo=r(mSe," (RoBERTa model)"),mSe.forEach(t),gDo=i(q),iv=n(q,"LI",{});var gSe=s(iv);rpe=n(gSe,"STRONG",{});var Fbt=s(rpe);hDo=r(Fbt,"roformer"),Fbt.forEach(t),pDo=r(gSe," \u2014 "),SV=n(gSe,"A",{href:!0});var Tbt=s(SV);_Do=r(Tbt,"RoFormerForSequenceClassification"),Tbt.forEach(t),uDo=r(gSe," (RoFormer model)"),gSe.forEach(t),bDo=i(q),dv=n(q,"LI",{});var hSe=s(dv);tpe=n(hSe,"STRONG",{});var Mbt=s(tpe);vDo=r(Mbt,"squeezebert"),Mbt.forEach(t),FDo=r(hSe," \u2014 "),RV=n(hSe,"A",{href:!0});var Ebt=s(RV);TDo=r(Ebt,"SqueezeBertForSequenceClassification"),Ebt.forEach(t),MDo=r(hSe," (SqueezeBERT model)"),hSe.forEach(t),EDo=i(q),cv=n(q,"LI",{});var pSe=s(cv);ape=n(pSe,"STRONG",{});var Cbt=s(ape);CDo=r(Cbt,"tapas"),Cbt.forEach(t),wDo=r(pSe," \u2014 "),PV=n(pSe,"A",{href:!0});var wbt=s(PV);ADo=r(wbt,"TapasForSequenceClassification"),wbt.forEach(t),LDo=r(pSe," (TAPAS model)"),pSe.forEach(t),yDo=i(q),fv=n(q,"LI",{});var _Se=s(fv);npe=n(_Se,"STRONG",{});var Abt=s(npe);xDo=r(Abt,"transfo-xl"),Abt.forEach(t),$Do=r(_Se," \u2014 "),BV=n(_Se,"A",{href:!0});var Lbt=s(BV);kDo=r(Lbt,"TransfoXLForSequenceClassification"),Lbt.forEach(t),SDo=r(_Se," (Transformer-XL model)"),_Se.forEach(t),RDo=i(q),mv=n(q,"LI",{});var uSe=s(mv);spe=n(uSe,"STRONG",{});var ybt=s(spe);PDo=r(ybt,"xlm"),ybt.forEach(t),BDo=r(uSe," \u2014 "),IV=n(uSe,"A",{href:!0});var xbt=s(IV);IDo=r(xbt,"XLMForSequenceClassification"),xbt.forEach(t),NDo=r(uSe," (XLM model)"),uSe.forEach(t),qDo=i(q),gv=n(q,"LI",{});var bSe=s(gv);lpe=n(bSe,"STRONG",{});var $bt=s(lpe);jDo=r($bt,"xlm-roberta"),$bt.forEach(t),DDo=r(bSe," \u2014 "),NV=n(bSe,"A",{href:!0});var kbt=s(NV);GDo=r(kbt,"XLMRobertaForSequenceClassification"),kbt.forEach(t),ODo=r(bSe," (XLM-RoBERTa model)"),bSe.forEach(t),VDo=i(q),hv=n(q,"LI",{});var vSe=s(hv);ipe=n(vSe,"STRONG",{});var Sbt=s(ipe);XDo=r(Sbt,"xlm-roberta-xl"),Sbt.forEach(t),zDo=r(vSe," \u2014 "),qV=n(vSe,"A",{href:!0});var Rbt=s(qV);QDo=r(Rbt,"XLMRobertaXLForSequenceClassification"),Rbt.forEach(t),WDo=r(vSe," (XLM-RoBERTa-XL model)"),vSe.forEach(t),HDo=i(q),pv=n(q,"LI",{});var FSe=s(pv);dpe=n(FSe,"STRONG",{});var Pbt=s(dpe);UDo=r(Pbt,"xlnet"),Pbt.forEach(t),JDo=r(FSe," \u2014 "),jV=n(FSe,"A",{href:!0});var Bbt=s(jV);YDo=r(Bbt,"XLNetForSequenceClassification"),Bbt.forEach(t),KDo=r(FSe," (XLNet model)"),FSe.forEach(t),ZDo=i(q),_v=n(q,"LI",{});var TSe=s(_v);cpe=n(TSe,"STRONG",{});var Ibt=s(cpe);eGo=r(Ibt,"yoso"),Ibt.forEach(t),oGo=r(TSe," \u2014 "),DV=n(TSe,"A",{href:!0});var Nbt=s(DV);rGo=r(Nbt,"YosoForSequenceClassification"),Nbt.forEach(t),tGo=r(TSe," (YOSO model)"),TSe.forEach(t),q.forEach(t),aGo=i(da),uv=n(da,"P",{});var MSe=s(uv);nGo=r(MSe,"The model is set in evaluation mode by default using "),fpe=n(MSe,"CODE",{});var qbt=s(fpe);sGo=r(qbt,"model.eval()"),qbt.forEach(t),lGo=r(MSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),mpe=n(MSe,"CODE",{});var jbt=s(mpe);iGo=r(jbt,"model.train()"),jbt.forEach(t),MSe.forEach(t),dGo=i(da),T(bv.$$.fragment,da),da.forEach(t),rl.forEach(t),cOe=i(f),Zi=n(f,"H2",{class:!0});var _Xe=s(Zi);vv=n(_Xe,"A",{id:!0,class:!0,href:!0});var Dbt=s(vv);gpe=n(Dbt,"SPAN",{});var Gbt=s(gpe);T(kA.$$.fragment,Gbt),Gbt.forEach(t),Dbt.forEach(t),cGo=i(_Xe),hpe=n(_Xe,"SPAN",{});var Obt=s(hpe);fGo=r(Obt,"AutoModelForMultipleChoice"),Obt.forEach(t),_Xe.forEach(t),fOe=i(f),Bo=n(f,"DIV",{class:!0});var tl=s(Bo);T(SA.$$.fragment,tl),mGo=i(tl),ed=n(tl,"P",{});var koe=s(ed);gGo=r(koe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),GV=n(koe,"A",{href:!0});var Vbt=s(GV);hGo=r(Vbt,"from_pretrained()"),Vbt.forEach(t),pGo=r(koe," class method or the "),OV=n(koe,"A",{href:!0});var Xbt=s(OV);_Go=r(Xbt,"from_config()"),Xbt.forEach(t),uGo=r(koe,` class
method.`),koe.forEach(t),bGo=i(tl),RA=n(tl,"P",{});var uXe=s(RA);vGo=r(uXe,"This class cannot be instantiated directly using "),ppe=n(uXe,"CODE",{});var zbt=s(ppe);FGo=r(zbt,"__init__()"),zbt.forEach(t),TGo=r(uXe," (throws an error)."),uXe.forEach(t),MGo=i(tl),ft=n(tl,"DIV",{class:!0});var V3=s(ft);T(PA.$$.fragment,V3),EGo=i(V3),_pe=n(V3,"P",{});var Qbt=s(_pe);CGo=r(Qbt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Qbt.forEach(t),wGo=i(V3),od=n(V3,"P",{});var Soe=s(od);AGo=r(Soe,`Note:
Loading a model from its configuration file does `),upe=n(Soe,"STRONG",{});var Wbt=s(upe);LGo=r(Wbt,"not"),Wbt.forEach(t),yGo=r(Soe,` load the model weights. It only affects the
model\u2019s configuration. Use `),VV=n(Soe,"A",{href:!0});var Hbt=s(VV);xGo=r(Hbt,"from_pretrained()"),Hbt.forEach(t),$Go=r(Soe," to load the model weights."),Soe.forEach(t),kGo=i(V3),T(Fv.$$.fragment,V3),V3.forEach(t),SGo=i(tl),ro=n(tl,"DIV",{class:!0});var ca=s(ro);T(BA.$$.fragment,ca),RGo=i(ca),bpe=n(ca,"P",{});var Ubt=s(bpe);PGo=r(Ubt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Ubt.forEach(t),BGo=i(ca),ja=n(ca,"P",{});var X3=s(ja);IGo=r(X3,"The model class to instantiate is selected based on the "),vpe=n(X3,"CODE",{});var Jbt=s(vpe);NGo=r(Jbt,"model_type"),Jbt.forEach(t),qGo=r(X3,` property of the config object (either
passed as an argument or loaded from `),Fpe=n(X3,"CODE",{});var Ybt=s(Fpe);jGo=r(Ybt,"pretrained_model_name_or_path"),Ybt.forEach(t),DGo=r(X3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Tpe=n(X3,"CODE",{});var Kbt=s(Tpe);GGo=r(Kbt,"pretrained_model_name_or_path"),Kbt.forEach(t),OGo=r(X3,":"),X3.forEach(t),VGo=i(ca),Z=n(ca,"UL",{});var ee=s(Z);Tv=n(ee,"LI",{});var ESe=s(Tv);Mpe=n(ESe,"STRONG",{});var Zbt=s(Mpe);XGo=r(Zbt,"albert"),Zbt.forEach(t),zGo=r(ESe," \u2014 "),XV=n(ESe,"A",{href:!0});var evt=s(XV);QGo=r(evt,"AlbertForMultipleChoice"),evt.forEach(t),WGo=r(ESe," (ALBERT model)"),ESe.forEach(t),HGo=i(ee),Mv=n(ee,"LI",{});var CSe=s(Mv);Epe=n(CSe,"STRONG",{});var ovt=s(Epe);UGo=r(ovt,"bert"),ovt.forEach(t),JGo=r(CSe," \u2014 "),zV=n(CSe,"A",{href:!0});var rvt=s(zV);YGo=r(rvt,"BertForMultipleChoice"),rvt.forEach(t),KGo=r(CSe," (BERT model)"),CSe.forEach(t),ZGo=i(ee),Ev=n(ee,"LI",{});var wSe=s(Ev);Cpe=n(wSe,"STRONG",{});var tvt=s(Cpe);eOo=r(tvt,"big_bird"),tvt.forEach(t),oOo=r(wSe," \u2014 "),QV=n(wSe,"A",{href:!0});var avt=s(QV);rOo=r(avt,"BigBirdForMultipleChoice"),avt.forEach(t),tOo=r(wSe," (BigBird model)"),wSe.forEach(t),aOo=i(ee),Cv=n(ee,"LI",{});var ASe=s(Cv);wpe=n(ASe,"STRONG",{});var nvt=s(wpe);nOo=r(nvt,"camembert"),nvt.forEach(t),sOo=r(ASe," \u2014 "),WV=n(ASe,"A",{href:!0});var svt=s(WV);lOo=r(svt,"CamembertForMultipleChoice"),svt.forEach(t),iOo=r(ASe," (CamemBERT model)"),ASe.forEach(t),dOo=i(ee),wv=n(ee,"LI",{});var LSe=s(wv);Ape=n(LSe,"STRONG",{});var lvt=s(Ape);cOo=r(lvt,"canine"),lvt.forEach(t),fOo=r(LSe," \u2014 "),HV=n(LSe,"A",{href:!0});var ivt=s(HV);mOo=r(ivt,"CanineForMultipleChoice"),ivt.forEach(t),gOo=r(LSe," (CANINE model)"),LSe.forEach(t),hOo=i(ee),Av=n(ee,"LI",{});var ySe=s(Av);Lpe=n(ySe,"STRONG",{});var dvt=s(Lpe);pOo=r(dvt,"convbert"),dvt.forEach(t),_Oo=r(ySe," \u2014 "),UV=n(ySe,"A",{href:!0});var cvt=s(UV);uOo=r(cvt,"ConvBertForMultipleChoice"),cvt.forEach(t),bOo=r(ySe," (ConvBERT model)"),ySe.forEach(t),vOo=i(ee),Lv=n(ee,"LI",{});var xSe=s(Lv);ype=n(xSe,"STRONG",{});var fvt=s(ype);FOo=r(fvt,"data2vec-text"),fvt.forEach(t),TOo=r(xSe," \u2014 "),JV=n(xSe,"A",{href:!0});var mvt=s(JV);MOo=r(mvt,"Data2VecTextForMultipleChoice"),mvt.forEach(t),EOo=r(xSe," (Data2VecText model)"),xSe.forEach(t),COo=i(ee),yv=n(ee,"LI",{});var $Se=s(yv);xpe=n($Se,"STRONG",{});var gvt=s(xpe);wOo=r(gvt,"deberta-v2"),gvt.forEach(t),AOo=r($Se," \u2014 "),YV=n($Se,"A",{href:!0});var hvt=s(YV);LOo=r(hvt,"DebertaV2ForMultipleChoice"),hvt.forEach(t),yOo=r($Se," (DeBERTa-v2 model)"),$Se.forEach(t),xOo=i(ee),xv=n(ee,"LI",{});var kSe=s(xv);$pe=n(kSe,"STRONG",{});var pvt=s($pe);$Oo=r(pvt,"distilbert"),pvt.forEach(t),kOo=r(kSe," \u2014 "),KV=n(kSe,"A",{href:!0});var _vt=s(KV);SOo=r(_vt,"DistilBertForMultipleChoice"),_vt.forEach(t),ROo=r(kSe," (DistilBERT model)"),kSe.forEach(t),POo=i(ee),$v=n(ee,"LI",{});var SSe=s($v);kpe=n(SSe,"STRONG",{});var uvt=s(kpe);BOo=r(uvt,"electra"),uvt.forEach(t),IOo=r(SSe," \u2014 "),ZV=n(SSe,"A",{href:!0});var bvt=s(ZV);NOo=r(bvt,"ElectraForMultipleChoice"),bvt.forEach(t),qOo=r(SSe," (ELECTRA model)"),SSe.forEach(t),jOo=i(ee),kv=n(ee,"LI",{});var RSe=s(kv);Spe=n(RSe,"STRONG",{});var vvt=s(Spe);DOo=r(vvt,"flaubert"),vvt.forEach(t),GOo=r(RSe," \u2014 "),eX=n(RSe,"A",{href:!0});var Fvt=s(eX);OOo=r(Fvt,"FlaubertForMultipleChoice"),Fvt.forEach(t),VOo=r(RSe," (FlauBERT model)"),RSe.forEach(t),XOo=i(ee),Sv=n(ee,"LI",{});var PSe=s(Sv);Rpe=n(PSe,"STRONG",{});var Tvt=s(Rpe);zOo=r(Tvt,"fnet"),Tvt.forEach(t),QOo=r(PSe," \u2014 "),oX=n(PSe,"A",{href:!0});var Mvt=s(oX);WOo=r(Mvt,"FNetForMultipleChoice"),Mvt.forEach(t),HOo=r(PSe," (FNet model)"),PSe.forEach(t),UOo=i(ee),Rv=n(ee,"LI",{});var BSe=s(Rv);Ppe=n(BSe,"STRONG",{});var Evt=s(Ppe);JOo=r(Evt,"funnel"),Evt.forEach(t),YOo=r(BSe," \u2014 "),rX=n(BSe,"A",{href:!0});var Cvt=s(rX);KOo=r(Cvt,"FunnelForMultipleChoice"),Cvt.forEach(t),ZOo=r(BSe," (Funnel Transformer model)"),BSe.forEach(t),eVo=i(ee),Pv=n(ee,"LI",{});var ISe=s(Pv);Bpe=n(ISe,"STRONG",{});var wvt=s(Bpe);oVo=r(wvt,"ibert"),wvt.forEach(t),rVo=r(ISe," \u2014 "),tX=n(ISe,"A",{href:!0});var Avt=s(tX);tVo=r(Avt,"IBertForMultipleChoice"),Avt.forEach(t),aVo=r(ISe," (I-BERT model)"),ISe.forEach(t),nVo=i(ee),Bv=n(ee,"LI",{});var NSe=s(Bv);Ipe=n(NSe,"STRONG",{});var Lvt=s(Ipe);sVo=r(Lvt,"longformer"),Lvt.forEach(t),lVo=r(NSe," \u2014 "),aX=n(NSe,"A",{href:!0});var yvt=s(aX);iVo=r(yvt,"LongformerForMultipleChoice"),yvt.forEach(t),dVo=r(NSe," (Longformer model)"),NSe.forEach(t),cVo=i(ee),Iv=n(ee,"LI",{});var qSe=s(Iv);Npe=n(qSe,"STRONG",{});var xvt=s(Npe);fVo=r(xvt,"megatron-bert"),xvt.forEach(t),mVo=r(qSe," \u2014 "),nX=n(qSe,"A",{href:!0});var $vt=s(nX);gVo=r($vt,"MegatronBertForMultipleChoice"),$vt.forEach(t),hVo=r(qSe," (Megatron-BERT model)"),qSe.forEach(t),pVo=i(ee),Nv=n(ee,"LI",{});var jSe=s(Nv);qpe=n(jSe,"STRONG",{});var kvt=s(qpe);_Vo=r(kvt,"mobilebert"),kvt.forEach(t),uVo=r(jSe," \u2014 "),sX=n(jSe,"A",{href:!0});var Svt=s(sX);bVo=r(Svt,"MobileBertForMultipleChoice"),Svt.forEach(t),vVo=r(jSe," (MobileBERT model)"),jSe.forEach(t),FVo=i(ee),qv=n(ee,"LI",{});var DSe=s(qv);jpe=n(DSe,"STRONG",{});var Rvt=s(jpe);TVo=r(Rvt,"mpnet"),Rvt.forEach(t),MVo=r(DSe," \u2014 "),lX=n(DSe,"A",{href:!0});var Pvt=s(lX);EVo=r(Pvt,"MPNetForMultipleChoice"),Pvt.forEach(t),CVo=r(DSe," (MPNet model)"),DSe.forEach(t),wVo=i(ee),jv=n(ee,"LI",{});var GSe=s(jv);Dpe=n(GSe,"STRONG",{});var Bvt=s(Dpe);AVo=r(Bvt,"nezha"),Bvt.forEach(t),LVo=r(GSe," \u2014 "),iX=n(GSe,"A",{href:!0});var Ivt=s(iX);yVo=r(Ivt,"NezhaForMultipleChoice"),Ivt.forEach(t),xVo=r(GSe," (Nezha model)"),GSe.forEach(t),$Vo=i(ee),Dv=n(ee,"LI",{});var OSe=s(Dv);Gpe=n(OSe,"STRONG",{});var Nvt=s(Gpe);kVo=r(Nvt,"nystromformer"),Nvt.forEach(t),SVo=r(OSe," \u2014 "),dX=n(OSe,"A",{href:!0});var qvt=s(dX);RVo=r(qvt,"NystromformerForMultipleChoice"),qvt.forEach(t),PVo=r(OSe," (Nystr\xF6mformer model)"),OSe.forEach(t),BVo=i(ee),Gv=n(ee,"LI",{});var VSe=s(Gv);Ope=n(VSe,"STRONG",{});var jvt=s(Ope);IVo=r(jvt,"qdqbert"),jvt.forEach(t),NVo=r(VSe," \u2014 "),cX=n(VSe,"A",{href:!0});var Dvt=s(cX);qVo=r(Dvt,"QDQBertForMultipleChoice"),Dvt.forEach(t),jVo=r(VSe," (QDQBert model)"),VSe.forEach(t),DVo=i(ee),Ov=n(ee,"LI",{});var XSe=s(Ov);Vpe=n(XSe,"STRONG",{});var Gvt=s(Vpe);GVo=r(Gvt,"rembert"),Gvt.forEach(t),OVo=r(XSe," \u2014 "),fX=n(XSe,"A",{href:!0});var Ovt=s(fX);VVo=r(Ovt,"RemBertForMultipleChoice"),Ovt.forEach(t),XVo=r(XSe," (RemBERT model)"),XSe.forEach(t),zVo=i(ee),Vv=n(ee,"LI",{});var zSe=s(Vv);Xpe=n(zSe,"STRONG",{});var Vvt=s(Xpe);QVo=r(Vvt,"roberta"),Vvt.forEach(t),WVo=r(zSe," \u2014 "),mX=n(zSe,"A",{href:!0});var Xvt=s(mX);HVo=r(Xvt,"RobertaForMultipleChoice"),Xvt.forEach(t),UVo=r(zSe," (RoBERTa model)"),zSe.forEach(t),JVo=i(ee),Xv=n(ee,"LI",{});var QSe=s(Xv);zpe=n(QSe,"STRONG",{});var zvt=s(zpe);YVo=r(zvt,"roformer"),zvt.forEach(t),KVo=r(QSe," \u2014 "),gX=n(QSe,"A",{href:!0});var Qvt=s(gX);ZVo=r(Qvt,"RoFormerForMultipleChoice"),Qvt.forEach(t),eXo=r(QSe," (RoFormer model)"),QSe.forEach(t),oXo=i(ee),zv=n(ee,"LI",{});var WSe=s(zv);Qpe=n(WSe,"STRONG",{});var Wvt=s(Qpe);rXo=r(Wvt,"squeezebert"),Wvt.forEach(t),tXo=r(WSe," \u2014 "),hX=n(WSe,"A",{href:!0});var Hvt=s(hX);aXo=r(Hvt,"SqueezeBertForMultipleChoice"),Hvt.forEach(t),nXo=r(WSe," (SqueezeBERT model)"),WSe.forEach(t),sXo=i(ee),Qv=n(ee,"LI",{});var HSe=s(Qv);Wpe=n(HSe,"STRONG",{});var Uvt=s(Wpe);lXo=r(Uvt,"xlm"),Uvt.forEach(t),iXo=r(HSe," \u2014 "),pX=n(HSe,"A",{href:!0});var Jvt=s(pX);dXo=r(Jvt,"XLMForMultipleChoice"),Jvt.forEach(t),cXo=r(HSe," (XLM model)"),HSe.forEach(t),fXo=i(ee),Wv=n(ee,"LI",{});var USe=s(Wv);Hpe=n(USe,"STRONG",{});var Yvt=s(Hpe);mXo=r(Yvt,"xlm-roberta"),Yvt.forEach(t),gXo=r(USe," \u2014 "),_X=n(USe,"A",{href:!0});var Kvt=s(_X);hXo=r(Kvt,"XLMRobertaForMultipleChoice"),Kvt.forEach(t),pXo=r(USe," (XLM-RoBERTa model)"),USe.forEach(t),_Xo=i(ee),Hv=n(ee,"LI",{});var JSe=s(Hv);Upe=n(JSe,"STRONG",{});var Zvt=s(Upe);uXo=r(Zvt,"xlm-roberta-xl"),Zvt.forEach(t),bXo=r(JSe," \u2014 "),uX=n(JSe,"A",{href:!0});var eFt=s(uX);vXo=r(eFt,"XLMRobertaXLForMultipleChoice"),eFt.forEach(t),FXo=r(JSe," (XLM-RoBERTa-XL model)"),JSe.forEach(t),TXo=i(ee),Uv=n(ee,"LI",{});var YSe=s(Uv);Jpe=n(YSe,"STRONG",{});var oFt=s(Jpe);MXo=r(oFt,"xlnet"),oFt.forEach(t),EXo=r(YSe," \u2014 "),bX=n(YSe,"A",{href:!0});var rFt=s(bX);CXo=r(rFt,"XLNetForMultipleChoice"),rFt.forEach(t),wXo=r(YSe," (XLNet model)"),YSe.forEach(t),AXo=i(ee),Jv=n(ee,"LI",{});var KSe=s(Jv);Ype=n(KSe,"STRONG",{});var tFt=s(Ype);LXo=r(tFt,"yoso"),tFt.forEach(t),yXo=r(KSe," \u2014 "),vX=n(KSe,"A",{href:!0});var aFt=s(vX);xXo=r(aFt,"YosoForMultipleChoice"),aFt.forEach(t),$Xo=r(KSe," (YOSO model)"),KSe.forEach(t),ee.forEach(t),kXo=i(ca),Yv=n(ca,"P",{});var ZSe=s(Yv);SXo=r(ZSe,"The model is set in evaluation mode by default using "),Kpe=n(ZSe,"CODE",{});var nFt=s(Kpe);RXo=r(nFt,"model.eval()"),nFt.forEach(t),PXo=r(ZSe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Zpe=n(ZSe,"CODE",{});var sFt=s(Zpe);BXo=r(sFt,"model.train()"),sFt.forEach(t),ZSe.forEach(t),IXo=i(ca),T(Kv.$$.fragment,ca),ca.forEach(t),tl.forEach(t),mOe=i(f),rd=n(f,"H2",{class:!0});var bXe=s(rd);Zv=n(bXe,"A",{id:!0,class:!0,href:!0});var lFt=s(Zv);e_e=n(lFt,"SPAN",{});var iFt=s(e_e);T(IA.$$.fragment,iFt),iFt.forEach(t),lFt.forEach(t),NXo=i(bXe),o_e=n(bXe,"SPAN",{});var dFt=s(o_e);qXo=r(dFt,"AutoModelForNextSentencePrediction"),dFt.forEach(t),bXe.forEach(t),gOe=i(f),Io=n(f,"DIV",{class:!0});var al=s(Io);T(NA.$$.fragment,al),jXo=i(al),td=n(al,"P",{});var Roe=s(td);DXo=r(Roe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),FX=n(Roe,"A",{href:!0});var cFt=s(FX);GXo=r(cFt,"from_pretrained()"),cFt.forEach(t),OXo=r(Roe," class method or the "),TX=n(Roe,"A",{href:!0});var fFt=s(TX);VXo=r(fFt,"from_config()"),fFt.forEach(t),XXo=r(Roe,` class
method.`),Roe.forEach(t),zXo=i(al),qA=n(al,"P",{});var vXe=s(qA);QXo=r(vXe,"This class cannot be instantiated directly using "),r_e=n(vXe,"CODE",{});var mFt=s(r_e);WXo=r(mFt,"__init__()"),mFt.forEach(t),HXo=r(vXe," (throws an error)."),vXe.forEach(t),UXo=i(al),mt=n(al,"DIV",{class:!0});var z3=s(mt);T(jA.$$.fragment,z3),JXo=i(z3),t_e=n(z3,"P",{});var gFt=s(t_e);YXo=r(gFt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),gFt.forEach(t),KXo=i(z3),ad=n(z3,"P",{});var Poe=s(ad);ZXo=r(Poe,`Note:
Loading a model from its configuration file does `),a_e=n(Poe,"STRONG",{});var hFt=s(a_e);ezo=r(hFt,"not"),hFt.forEach(t),ozo=r(Poe,` load the model weights. It only affects the
model\u2019s configuration. Use `),MX=n(Poe,"A",{href:!0});var pFt=s(MX);rzo=r(pFt,"from_pretrained()"),pFt.forEach(t),tzo=r(Poe," to load the model weights."),Poe.forEach(t),azo=i(z3),T(eF.$$.fragment,z3),z3.forEach(t),nzo=i(al),to=n(al,"DIV",{class:!0});var fa=s(to);T(DA.$$.fragment,fa),szo=i(fa),n_e=n(fa,"P",{});var _Ft=s(n_e);lzo=r(_Ft,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),_Ft.forEach(t),izo=i(fa),Da=n(fa,"P",{});var Q3=s(Da);dzo=r(Q3,"The model class to instantiate is selected based on the "),s_e=n(Q3,"CODE",{});var uFt=s(s_e);czo=r(uFt,"model_type"),uFt.forEach(t),fzo=r(Q3,` property of the config object (either
passed as an argument or loaded from `),l_e=n(Q3,"CODE",{});var bFt=s(l_e);mzo=r(bFt,"pretrained_model_name_or_path"),bFt.forEach(t),gzo=r(Q3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),i_e=n(Q3,"CODE",{});var vFt=s(i_e);hzo=r(vFt,"pretrained_model_name_or_path"),vFt.forEach(t),pzo=r(Q3,":"),Q3.forEach(t),_zo=i(fa),No=n(fa,"UL",{});var ma=s(No);oF=n(ma,"LI",{});var eRe=s(oF);d_e=n(eRe,"STRONG",{});var FFt=s(d_e);uzo=r(FFt,"bert"),FFt.forEach(t),bzo=r(eRe," \u2014 "),EX=n(eRe,"A",{href:!0});var TFt=s(EX);vzo=r(TFt,"BertForNextSentencePrediction"),TFt.forEach(t),Fzo=r(eRe," (BERT model)"),eRe.forEach(t),Tzo=i(ma),rF=n(ma,"LI",{});var oRe=s(rF);c_e=n(oRe,"STRONG",{});var MFt=s(c_e);Mzo=r(MFt,"fnet"),MFt.forEach(t),Ezo=r(oRe," \u2014 "),CX=n(oRe,"A",{href:!0});var EFt=s(CX);Czo=r(EFt,"FNetForNextSentencePrediction"),EFt.forEach(t),wzo=r(oRe," (FNet model)"),oRe.forEach(t),Azo=i(ma),tF=n(ma,"LI",{});var rRe=s(tF);f_e=n(rRe,"STRONG",{});var CFt=s(f_e);Lzo=r(CFt,"megatron-bert"),CFt.forEach(t),yzo=r(rRe," \u2014 "),wX=n(rRe,"A",{href:!0});var wFt=s(wX);xzo=r(wFt,"MegatronBertForNextSentencePrediction"),wFt.forEach(t),$zo=r(rRe," (Megatron-BERT model)"),rRe.forEach(t),kzo=i(ma),aF=n(ma,"LI",{});var tRe=s(aF);m_e=n(tRe,"STRONG",{});var AFt=s(m_e);Szo=r(AFt,"mobilebert"),AFt.forEach(t),Rzo=r(tRe," \u2014 "),AX=n(tRe,"A",{href:!0});var LFt=s(AX);Pzo=r(LFt,"MobileBertForNextSentencePrediction"),LFt.forEach(t),Bzo=r(tRe," (MobileBERT model)"),tRe.forEach(t),Izo=i(ma),nF=n(ma,"LI",{});var aRe=s(nF);g_e=n(aRe,"STRONG",{});var yFt=s(g_e);Nzo=r(yFt,"nezha"),yFt.forEach(t),qzo=r(aRe," \u2014 "),LX=n(aRe,"A",{href:!0});var xFt=s(LX);jzo=r(xFt,"NezhaForNextSentencePrediction"),xFt.forEach(t),Dzo=r(aRe," (Nezha model)"),aRe.forEach(t),Gzo=i(ma),sF=n(ma,"LI",{});var nRe=s(sF);h_e=n(nRe,"STRONG",{});var $Ft=s(h_e);Ozo=r($Ft,"qdqbert"),$Ft.forEach(t),Vzo=r(nRe," \u2014 "),yX=n(nRe,"A",{href:!0});var kFt=s(yX);Xzo=r(kFt,"QDQBertForNextSentencePrediction"),kFt.forEach(t),zzo=r(nRe," (QDQBert model)"),nRe.forEach(t),ma.forEach(t),Qzo=i(fa),lF=n(fa,"P",{});var sRe=s(lF);Wzo=r(sRe,"The model is set in evaluation mode by default using "),p_e=n(sRe,"CODE",{});var SFt=s(p_e);Hzo=r(SFt,"model.eval()"),SFt.forEach(t),Uzo=r(sRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),__e=n(sRe,"CODE",{});var RFt=s(__e);Jzo=r(RFt,"model.train()"),RFt.forEach(t),sRe.forEach(t),Yzo=i(fa),T(iF.$$.fragment,fa),fa.forEach(t),al.forEach(t),hOe=i(f),nd=n(f,"H2",{class:!0});var FXe=s(nd);dF=n(FXe,"A",{id:!0,class:!0,href:!0});var PFt=s(dF);u_e=n(PFt,"SPAN",{});var BFt=s(u_e);T(GA.$$.fragment,BFt),BFt.forEach(t),PFt.forEach(t),Kzo=i(FXe),b_e=n(FXe,"SPAN",{});var IFt=s(b_e);Zzo=r(IFt,"AutoModelForTokenClassification"),IFt.forEach(t),FXe.forEach(t),pOe=i(f),qo=n(f,"DIV",{class:!0});var nl=s(qo);T(OA.$$.fragment,nl),eQo=i(nl),sd=n(nl,"P",{});var Boe=s(sd);oQo=r(Boe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),xX=n(Boe,"A",{href:!0});var NFt=s(xX);rQo=r(NFt,"from_pretrained()"),NFt.forEach(t),tQo=r(Boe," class method or the "),$X=n(Boe,"A",{href:!0});var qFt=s($X);aQo=r(qFt,"from_config()"),qFt.forEach(t),nQo=r(Boe,` class
method.`),Boe.forEach(t),sQo=i(nl),VA=n(nl,"P",{});var TXe=s(VA);lQo=r(TXe,"This class cannot be instantiated directly using "),v_e=n(TXe,"CODE",{});var jFt=s(v_e);iQo=r(jFt,"__init__()"),jFt.forEach(t),dQo=r(TXe," (throws an error)."),TXe.forEach(t),cQo=i(nl),gt=n(nl,"DIV",{class:!0});var W3=s(gt);T(XA.$$.fragment,W3),fQo=i(W3),F_e=n(W3,"P",{});var DFt=s(F_e);mQo=r(DFt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),DFt.forEach(t),gQo=i(W3),ld=n(W3,"P",{});var Ioe=s(ld);hQo=r(Ioe,`Note:
Loading a model from its configuration file does `),T_e=n(Ioe,"STRONG",{});var GFt=s(T_e);pQo=r(GFt,"not"),GFt.forEach(t),_Qo=r(Ioe,` load the model weights. It only affects the
model\u2019s configuration. Use `),kX=n(Ioe,"A",{href:!0});var OFt=s(kX);uQo=r(OFt,"from_pretrained()"),OFt.forEach(t),bQo=r(Ioe," to load the model weights."),Ioe.forEach(t),vQo=i(W3),T(cF.$$.fragment,W3),W3.forEach(t),FQo=i(nl),ao=n(nl,"DIV",{class:!0});var ga=s(ao);T(zA.$$.fragment,ga),TQo=i(ga),M_e=n(ga,"P",{});var VFt=s(M_e);MQo=r(VFt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),VFt.forEach(t),EQo=i(ga),Ga=n(ga,"P",{});var H3=s(Ga);CQo=r(H3,"The model class to instantiate is selected based on the "),E_e=n(H3,"CODE",{});var XFt=s(E_e);wQo=r(XFt,"model_type"),XFt.forEach(t),AQo=r(H3,` property of the config object (either
passed as an argument or loaded from `),C_e=n(H3,"CODE",{});var zFt=s(C_e);LQo=r(zFt,"pretrained_model_name_or_path"),zFt.forEach(t),yQo=r(H3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),w_e=n(H3,"CODE",{});var QFt=s(w_e);xQo=r(QFt,"pretrained_model_name_or_path"),QFt.forEach(t),$Qo=r(H3,":"),H3.forEach(t),kQo=i(ga),H=n(ga,"UL",{});var J=s(H);fF=n(J,"LI",{});var lRe=s(fF);A_e=n(lRe,"STRONG",{});var WFt=s(A_e);SQo=r(WFt,"albert"),WFt.forEach(t),RQo=r(lRe," \u2014 "),SX=n(lRe,"A",{href:!0});var HFt=s(SX);PQo=r(HFt,"AlbertForTokenClassification"),HFt.forEach(t),BQo=r(lRe," (ALBERT model)"),lRe.forEach(t),IQo=i(J),mF=n(J,"LI",{});var iRe=s(mF);L_e=n(iRe,"STRONG",{});var UFt=s(L_e);NQo=r(UFt,"bert"),UFt.forEach(t),qQo=r(iRe," \u2014 "),RX=n(iRe,"A",{href:!0});var JFt=s(RX);jQo=r(JFt,"BertForTokenClassification"),JFt.forEach(t),DQo=r(iRe," (BERT model)"),iRe.forEach(t),GQo=i(J),gF=n(J,"LI",{});var dRe=s(gF);y_e=n(dRe,"STRONG",{});var YFt=s(y_e);OQo=r(YFt,"big_bird"),YFt.forEach(t),VQo=r(dRe," \u2014 "),PX=n(dRe,"A",{href:!0});var KFt=s(PX);XQo=r(KFt,"BigBirdForTokenClassification"),KFt.forEach(t),zQo=r(dRe," (BigBird model)"),dRe.forEach(t),QQo=i(J),hF=n(J,"LI",{});var cRe=s(hF);x_e=n(cRe,"STRONG",{});var ZFt=s(x_e);WQo=r(ZFt,"bloom"),ZFt.forEach(t),HQo=r(cRe," \u2014 "),BX=n(cRe,"A",{href:!0});var e6t=s(BX);UQo=r(e6t,"BloomForTokenClassification"),e6t.forEach(t),JQo=r(cRe," (BLOOM model)"),cRe.forEach(t),YQo=i(J),pF=n(J,"LI",{});var fRe=s(pF);$_e=n(fRe,"STRONG",{});var o6t=s($_e);KQo=r(o6t,"camembert"),o6t.forEach(t),ZQo=r(fRe," \u2014 "),IX=n(fRe,"A",{href:!0});var r6t=s(IX);eWo=r(r6t,"CamembertForTokenClassification"),r6t.forEach(t),oWo=r(fRe," (CamemBERT model)"),fRe.forEach(t),rWo=i(J),_F=n(J,"LI",{});var mRe=s(_F);k_e=n(mRe,"STRONG",{});var t6t=s(k_e);tWo=r(t6t,"canine"),t6t.forEach(t),aWo=r(mRe," \u2014 "),NX=n(mRe,"A",{href:!0});var a6t=s(NX);nWo=r(a6t,"CanineForTokenClassification"),a6t.forEach(t),sWo=r(mRe," (CANINE model)"),mRe.forEach(t),lWo=i(J),uF=n(J,"LI",{});var gRe=s(uF);S_e=n(gRe,"STRONG",{});var n6t=s(S_e);iWo=r(n6t,"convbert"),n6t.forEach(t),dWo=r(gRe," \u2014 "),qX=n(gRe,"A",{href:!0});var s6t=s(qX);cWo=r(s6t,"ConvBertForTokenClassification"),s6t.forEach(t),fWo=r(gRe," (ConvBERT model)"),gRe.forEach(t),mWo=i(J),bF=n(J,"LI",{});var hRe=s(bF);R_e=n(hRe,"STRONG",{});var l6t=s(R_e);gWo=r(l6t,"data2vec-text"),l6t.forEach(t),hWo=r(hRe," \u2014 "),jX=n(hRe,"A",{href:!0});var i6t=s(jX);pWo=r(i6t,"Data2VecTextForTokenClassification"),i6t.forEach(t),_Wo=r(hRe," (Data2VecText model)"),hRe.forEach(t),uWo=i(J),vF=n(J,"LI",{});var pRe=s(vF);P_e=n(pRe,"STRONG",{});var d6t=s(P_e);bWo=r(d6t,"deberta"),d6t.forEach(t),vWo=r(pRe," \u2014 "),DX=n(pRe,"A",{href:!0});var c6t=s(DX);FWo=r(c6t,"DebertaForTokenClassification"),c6t.forEach(t),TWo=r(pRe," (DeBERTa model)"),pRe.forEach(t),MWo=i(J),FF=n(J,"LI",{});var _Re=s(FF);B_e=n(_Re,"STRONG",{});var f6t=s(B_e);EWo=r(f6t,"deberta-v2"),f6t.forEach(t),CWo=r(_Re," \u2014 "),GX=n(_Re,"A",{href:!0});var m6t=s(GX);wWo=r(m6t,"DebertaV2ForTokenClassification"),m6t.forEach(t),AWo=r(_Re," (DeBERTa-v2 model)"),_Re.forEach(t),LWo=i(J),TF=n(J,"LI",{});var uRe=s(TF);I_e=n(uRe,"STRONG",{});var g6t=s(I_e);yWo=r(g6t,"distilbert"),g6t.forEach(t),xWo=r(uRe," \u2014 "),OX=n(uRe,"A",{href:!0});var h6t=s(OX);$Wo=r(h6t,"DistilBertForTokenClassification"),h6t.forEach(t),kWo=r(uRe," (DistilBERT model)"),uRe.forEach(t),SWo=i(J),MF=n(J,"LI",{});var bRe=s(MF);N_e=n(bRe,"STRONG",{});var p6t=s(N_e);RWo=r(p6t,"electra"),p6t.forEach(t),PWo=r(bRe," \u2014 "),VX=n(bRe,"A",{href:!0});var _6t=s(VX);BWo=r(_6t,"ElectraForTokenClassification"),_6t.forEach(t),IWo=r(bRe," (ELECTRA model)"),bRe.forEach(t),NWo=i(J),EF=n(J,"LI",{});var vRe=s(EF);q_e=n(vRe,"STRONG",{});var u6t=s(q_e);qWo=r(u6t,"flaubert"),u6t.forEach(t),jWo=r(vRe," \u2014 "),XX=n(vRe,"A",{href:!0});var b6t=s(XX);DWo=r(b6t,"FlaubertForTokenClassification"),b6t.forEach(t),GWo=r(vRe," (FlauBERT model)"),vRe.forEach(t),OWo=i(J),CF=n(J,"LI",{});var FRe=s(CF);j_e=n(FRe,"STRONG",{});var v6t=s(j_e);VWo=r(v6t,"fnet"),v6t.forEach(t),XWo=r(FRe," \u2014 "),zX=n(FRe,"A",{href:!0});var F6t=s(zX);zWo=r(F6t,"FNetForTokenClassification"),F6t.forEach(t),QWo=r(FRe," (FNet model)"),FRe.forEach(t),WWo=i(J),wF=n(J,"LI",{});var TRe=s(wF);D_e=n(TRe,"STRONG",{});var T6t=s(D_e);HWo=r(T6t,"funnel"),T6t.forEach(t),UWo=r(TRe," \u2014 "),QX=n(TRe,"A",{href:!0});var M6t=s(QX);JWo=r(M6t,"FunnelForTokenClassification"),M6t.forEach(t),YWo=r(TRe," (Funnel Transformer model)"),TRe.forEach(t),KWo=i(J),AF=n(J,"LI",{});var MRe=s(AF);G_e=n(MRe,"STRONG",{});var E6t=s(G_e);ZWo=r(E6t,"gpt2"),E6t.forEach(t),eHo=r(MRe," \u2014 "),WX=n(MRe,"A",{href:!0});var C6t=s(WX);oHo=r(C6t,"GPT2ForTokenClassification"),C6t.forEach(t),rHo=r(MRe," (OpenAI GPT-2 model)"),MRe.forEach(t),tHo=i(J),LF=n(J,"LI",{});var ERe=s(LF);O_e=n(ERe,"STRONG",{});var w6t=s(O_e);aHo=r(w6t,"ibert"),w6t.forEach(t),nHo=r(ERe," \u2014 "),HX=n(ERe,"A",{href:!0});var A6t=s(HX);sHo=r(A6t,"IBertForTokenClassification"),A6t.forEach(t),lHo=r(ERe," (I-BERT model)"),ERe.forEach(t),iHo=i(J),yF=n(J,"LI",{});var CRe=s(yF);V_e=n(CRe,"STRONG",{});var L6t=s(V_e);dHo=r(L6t,"layoutlm"),L6t.forEach(t),cHo=r(CRe," \u2014 "),UX=n(CRe,"A",{href:!0});var y6t=s(UX);fHo=r(y6t,"LayoutLMForTokenClassification"),y6t.forEach(t),mHo=r(CRe," (LayoutLM model)"),CRe.forEach(t),gHo=i(J),xF=n(J,"LI",{});var wRe=s(xF);X_e=n(wRe,"STRONG",{});var x6t=s(X_e);hHo=r(x6t,"layoutlmv2"),x6t.forEach(t),pHo=r(wRe," \u2014 "),JX=n(wRe,"A",{href:!0});var $6t=s(JX);_Ho=r($6t,"LayoutLMv2ForTokenClassification"),$6t.forEach(t),uHo=r(wRe," (LayoutLMv2 model)"),wRe.forEach(t),bHo=i(J),$F=n(J,"LI",{});var ARe=s($F);z_e=n(ARe,"STRONG",{});var k6t=s(z_e);vHo=r(k6t,"layoutlmv3"),k6t.forEach(t),FHo=r(ARe," \u2014 "),YX=n(ARe,"A",{href:!0});var S6t=s(YX);THo=r(S6t,"LayoutLMv3ForTokenClassification"),S6t.forEach(t),MHo=r(ARe," (LayoutLMv3 model)"),ARe.forEach(t),EHo=i(J),kF=n(J,"LI",{});var LRe=s(kF);Q_e=n(LRe,"STRONG",{});var R6t=s(Q_e);CHo=r(R6t,"longformer"),R6t.forEach(t),wHo=r(LRe," \u2014 "),KX=n(LRe,"A",{href:!0});var P6t=s(KX);AHo=r(P6t,"LongformerForTokenClassification"),P6t.forEach(t),LHo=r(LRe," (Longformer model)"),LRe.forEach(t),yHo=i(J),SF=n(J,"LI",{});var yRe=s(SF);W_e=n(yRe,"STRONG",{});var B6t=s(W_e);xHo=r(B6t,"megatron-bert"),B6t.forEach(t),$Ho=r(yRe," \u2014 "),ZX=n(yRe,"A",{href:!0});var I6t=s(ZX);kHo=r(I6t,"MegatronBertForTokenClassification"),I6t.forEach(t),SHo=r(yRe," (Megatron-BERT model)"),yRe.forEach(t),RHo=i(J),RF=n(J,"LI",{});var xRe=s(RF);H_e=n(xRe,"STRONG",{});var N6t=s(H_e);PHo=r(N6t,"mobilebert"),N6t.forEach(t),BHo=r(xRe," \u2014 "),ez=n(xRe,"A",{href:!0});var q6t=s(ez);IHo=r(q6t,"MobileBertForTokenClassification"),q6t.forEach(t),NHo=r(xRe," (MobileBERT model)"),xRe.forEach(t),qHo=i(J),PF=n(J,"LI",{});var $Re=s(PF);U_e=n($Re,"STRONG",{});var j6t=s(U_e);jHo=r(j6t,"mpnet"),j6t.forEach(t),DHo=r($Re," \u2014 "),oz=n($Re,"A",{href:!0});var D6t=s(oz);GHo=r(D6t,"MPNetForTokenClassification"),D6t.forEach(t),OHo=r($Re," (MPNet model)"),$Re.forEach(t),VHo=i(J),BF=n(J,"LI",{});var kRe=s(BF);J_e=n(kRe,"STRONG",{});var G6t=s(J_e);XHo=r(G6t,"nezha"),G6t.forEach(t),zHo=r(kRe," \u2014 "),rz=n(kRe,"A",{href:!0});var O6t=s(rz);QHo=r(O6t,"NezhaForTokenClassification"),O6t.forEach(t),WHo=r(kRe," (Nezha model)"),kRe.forEach(t),HHo=i(J),IF=n(J,"LI",{});var SRe=s(IF);Y_e=n(SRe,"STRONG",{});var V6t=s(Y_e);UHo=r(V6t,"nystromformer"),V6t.forEach(t),JHo=r(SRe," \u2014 "),tz=n(SRe,"A",{href:!0});var X6t=s(tz);YHo=r(X6t,"NystromformerForTokenClassification"),X6t.forEach(t),KHo=r(SRe," (Nystr\xF6mformer model)"),SRe.forEach(t),ZHo=i(J),NF=n(J,"LI",{});var RRe=s(NF);K_e=n(RRe,"STRONG",{});var z6t=s(K_e);eUo=r(z6t,"qdqbert"),z6t.forEach(t),oUo=r(RRe," \u2014 "),az=n(RRe,"A",{href:!0});var Q6t=s(az);rUo=r(Q6t,"QDQBertForTokenClassification"),Q6t.forEach(t),tUo=r(RRe," (QDQBert model)"),RRe.forEach(t),aUo=i(J),qF=n(J,"LI",{});var PRe=s(qF);Z_e=n(PRe,"STRONG",{});var W6t=s(Z_e);nUo=r(W6t,"rembert"),W6t.forEach(t),sUo=r(PRe," \u2014 "),nz=n(PRe,"A",{href:!0});var H6t=s(nz);lUo=r(H6t,"RemBertForTokenClassification"),H6t.forEach(t),iUo=r(PRe," (RemBERT model)"),PRe.forEach(t),dUo=i(J),jF=n(J,"LI",{});var BRe=s(jF);eue=n(BRe,"STRONG",{});var U6t=s(eue);cUo=r(U6t,"roberta"),U6t.forEach(t),fUo=r(BRe," \u2014 "),sz=n(BRe,"A",{href:!0});var J6t=s(sz);mUo=r(J6t,"RobertaForTokenClassification"),J6t.forEach(t),gUo=r(BRe," (RoBERTa model)"),BRe.forEach(t),hUo=i(J),DF=n(J,"LI",{});var IRe=s(DF);oue=n(IRe,"STRONG",{});var Y6t=s(oue);pUo=r(Y6t,"roformer"),Y6t.forEach(t),_Uo=r(IRe," \u2014 "),lz=n(IRe,"A",{href:!0});var K6t=s(lz);uUo=r(K6t,"RoFormerForTokenClassification"),K6t.forEach(t),bUo=r(IRe," (RoFormer model)"),IRe.forEach(t),vUo=i(J),GF=n(J,"LI",{});var NRe=s(GF);rue=n(NRe,"STRONG",{});var Z6t=s(rue);FUo=r(Z6t,"squeezebert"),Z6t.forEach(t),TUo=r(NRe," \u2014 "),iz=n(NRe,"A",{href:!0});var eTt=s(iz);MUo=r(eTt,"SqueezeBertForTokenClassification"),eTt.forEach(t),EUo=r(NRe," (SqueezeBERT model)"),NRe.forEach(t),CUo=i(J),OF=n(J,"LI",{});var qRe=s(OF);tue=n(qRe,"STRONG",{});var oTt=s(tue);wUo=r(oTt,"xlm"),oTt.forEach(t),AUo=r(qRe," \u2014 "),dz=n(qRe,"A",{href:!0});var rTt=s(dz);LUo=r(rTt,"XLMForTokenClassification"),rTt.forEach(t),yUo=r(qRe," (XLM model)"),qRe.forEach(t),xUo=i(J),VF=n(J,"LI",{});var jRe=s(VF);aue=n(jRe,"STRONG",{});var tTt=s(aue);$Uo=r(tTt,"xlm-roberta"),tTt.forEach(t),kUo=r(jRe," \u2014 "),cz=n(jRe,"A",{href:!0});var aTt=s(cz);SUo=r(aTt,"XLMRobertaForTokenClassification"),aTt.forEach(t),RUo=r(jRe," (XLM-RoBERTa model)"),jRe.forEach(t),PUo=i(J),XF=n(J,"LI",{});var DRe=s(XF);nue=n(DRe,"STRONG",{});var nTt=s(nue);BUo=r(nTt,"xlm-roberta-xl"),nTt.forEach(t),IUo=r(DRe," \u2014 "),fz=n(DRe,"A",{href:!0});var sTt=s(fz);NUo=r(sTt,"XLMRobertaXLForTokenClassification"),sTt.forEach(t),qUo=r(DRe," (XLM-RoBERTa-XL model)"),DRe.forEach(t),jUo=i(J),zF=n(J,"LI",{});var GRe=s(zF);sue=n(GRe,"STRONG",{});var lTt=s(sue);DUo=r(lTt,"xlnet"),lTt.forEach(t),GUo=r(GRe," \u2014 "),mz=n(GRe,"A",{href:!0});var iTt=s(mz);OUo=r(iTt,"XLNetForTokenClassification"),iTt.forEach(t),VUo=r(GRe," (XLNet model)"),GRe.forEach(t),XUo=i(J),QF=n(J,"LI",{});var ORe=s(QF);lue=n(ORe,"STRONG",{});var dTt=s(lue);zUo=r(dTt,"yoso"),dTt.forEach(t),QUo=r(ORe," \u2014 "),gz=n(ORe,"A",{href:!0});var cTt=s(gz);WUo=r(cTt,"YosoForTokenClassification"),cTt.forEach(t),HUo=r(ORe," (YOSO model)"),ORe.forEach(t),J.forEach(t),UUo=i(ga),WF=n(ga,"P",{});var VRe=s(WF);JUo=r(VRe,"The model is set in evaluation mode by default using "),iue=n(VRe,"CODE",{});var fTt=s(iue);YUo=r(fTt,"model.eval()"),fTt.forEach(t),KUo=r(VRe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),due=n(VRe,"CODE",{});var mTt=s(due);ZUo=r(mTt,"model.train()"),mTt.forEach(t),VRe.forEach(t),eJo=i(ga),T(HF.$$.fragment,ga),ga.forEach(t),nl.forEach(t),_Oe=i(f),id=n(f,"H2",{class:!0});var MXe=s(id);UF=n(MXe,"A",{id:!0,class:!0,href:!0});var gTt=s(UF);cue=n(gTt,"SPAN",{});var hTt=s(cue);T(QA.$$.fragment,hTt),hTt.forEach(t),gTt.forEach(t),oJo=i(MXe),fue=n(MXe,"SPAN",{});var pTt=s(fue);rJo=r(pTt,"AutoModelForQuestionAnswering"),pTt.forEach(t),MXe.forEach(t),uOe=i(f),jo=n(f,"DIV",{class:!0});var sl=s(jo);T(WA.$$.fragment,sl),tJo=i(sl),dd=n(sl,"P",{});var Noe=s(dd);aJo=r(Noe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),hz=n(Noe,"A",{href:!0});var _Tt=s(hz);nJo=r(_Tt,"from_pretrained()"),_Tt.forEach(t),sJo=r(Noe," class method or the "),pz=n(Noe,"A",{href:!0});var uTt=s(pz);lJo=r(uTt,"from_config()"),uTt.forEach(t),iJo=r(Noe,` class
method.`),Noe.forEach(t),dJo=i(sl),HA=n(sl,"P",{});var EXe=s(HA);cJo=r(EXe,"This class cannot be instantiated directly using "),mue=n(EXe,"CODE",{});var bTt=s(mue);fJo=r(bTt,"__init__()"),bTt.forEach(t),mJo=r(EXe," (throws an error)."),EXe.forEach(t),gJo=i(sl),ht=n(sl,"DIV",{class:!0});var U3=s(ht);T(UA.$$.fragment,U3),hJo=i(U3),gue=n(U3,"P",{});var vTt=s(gue);pJo=r(vTt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),vTt.forEach(t),_Jo=i(U3),cd=n(U3,"P",{});var qoe=s(cd);uJo=r(qoe,`Note:
Loading a model from its configuration file does `),hue=n(qoe,"STRONG",{});var FTt=s(hue);bJo=r(FTt,"not"),FTt.forEach(t),vJo=r(qoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),_z=n(qoe,"A",{href:!0});var TTt=s(_z);FJo=r(TTt,"from_pretrained()"),TTt.forEach(t),TJo=r(qoe," to load the model weights."),qoe.forEach(t),MJo=i(U3),T(JF.$$.fragment,U3),U3.forEach(t),EJo=i(sl),no=n(sl,"DIV",{class:!0});var ha=s(no);T(JA.$$.fragment,ha),CJo=i(ha),pue=n(ha,"P",{});var MTt=s(pue);wJo=r(MTt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),MTt.forEach(t),AJo=i(ha),Oa=n(ha,"P",{});var J3=s(Oa);LJo=r(J3,"The model class to instantiate is selected based on the "),_ue=n(J3,"CODE",{});var ETt=s(_ue);yJo=r(ETt,"model_type"),ETt.forEach(t),xJo=r(J3,` property of the config object (either
passed as an argument or loaded from `),uue=n(J3,"CODE",{});var CTt=s(uue);$Jo=r(CTt,"pretrained_model_name_or_path"),CTt.forEach(t),kJo=r(J3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bue=n(J3,"CODE",{});var wTt=s(bue);SJo=r(wTt,"pretrained_model_name_or_path"),wTt.forEach(t),RJo=r(J3,":"),J3.forEach(t),PJo=i(ha),V=n(ha,"UL",{});var X=s(V);YF=n(X,"LI",{});var XRe=s(YF);vue=n(XRe,"STRONG",{});var ATt=s(vue);BJo=r(ATt,"albert"),ATt.forEach(t),IJo=r(XRe," \u2014 "),uz=n(XRe,"A",{href:!0});var LTt=s(uz);NJo=r(LTt,"AlbertForQuestionAnswering"),LTt.forEach(t),qJo=r(XRe," (ALBERT model)"),XRe.forEach(t),jJo=i(X),KF=n(X,"LI",{});var zRe=s(KF);Fue=n(zRe,"STRONG",{});var yTt=s(Fue);DJo=r(yTt,"bart"),yTt.forEach(t),GJo=r(zRe," \u2014 "),bz=n(zRe,"A",{href:!0});var xTt=s(bz);OJo=r(xTt,"BartForQuestionAnswering"),xTt.forEach(t),VJo=r(zRe," (BART model)"),zRe.forEach(t),XJo=i(X),ZF=n(X,"LI",{});var QRe=s(ZF);Tue=n(QRe,"STRONG",{});var $Tt=s(Tue);zJo=r($Tt,"bert"),$Tt.forEach(t),QJo=r(QRe," \u2014 "),vz=n(QRe,"A",{href:!0});var kTt=s(vz);WJo=r(kTt,"BertForQuestionAnswering"),kTt.forEach(t),HJo=r(QRe," (BERT model)"),QRe.forEach(t),UJo=i(X),e6=n(X,"LI",{});var WRe=s(e6);Mue=n(WRe,"STRONG",{});var STt=s(Mue);JJo=r(STt,"big_bird"),STt.forEach(t),YJo=r(WRe," \u2014 "),Fz=n(WRe,"A",{href:!0});var RTt=s(Fz);KJo=r(RTt,"BigBirdForQuestionAnswering"),RTt.forEach(t),ZJo=r(WRe," (BigBird model)"),WRe.forEach(t),eYo=i(X),o6=n(X,"LI",{});var HRe=s(o6);Eue=n(HRe,"STRONG",{});var PTt=s(Eue);oYo=r(PTt,"bigbird_pegasus"),PTt.forEach(t),rYo=r(HRe," \u2014 "),Tz=n(HRe,"A",{href:!0});var BTt=s(Tz);tYo=r(BTt,"BigBirdPegasusForQuestionAnswering"),BTt.forEach(t),aYo=r(HRe," (BigBird-Pegasus model)"),HRe.forEach(t),nYo=i(X),r6=n(X,"LI",{});var URe=s(r6);Cue=n(URe,"STRONG",{});var ITt=s(Cue);sYo=r(ITt,"camembert"),ITt.forEach(t),lYo=r(URe," \u2014 "),Mz=n(URe,"A",{href:!0});var NTt=s(Mz);iYo=r(NTt,"CamembertForQuestionAnswering"),NTt.forEach(t),dYo=r(URe," (CamemBERT model)"),URe.forEach(t),cYo=i(X),t6=n(X,"LI",{});var JRe=s(t6);wue=n(JRe,"STRONG",{});var qTt=s(wue);fYo=r(qTt,"canine"),qTt.forEach(t),mYo=r(JRe," \u2014 "),Ez=n(JRe,"A",{href:!0});var jTt=s(Ez);gYo=r(jTt,"CanineForQuestionAnswering"),jTt.forEach(t),hYo=r(JRe," (CANINE model)"),JRe.forEach(t),pYo=i(X),a6=n(X,"LI",{});var YRe=s(a6);Aue=n(YRe,"STRONG",{});var DTt=s(Aue);_Yo=r(DTt,"convbert"),DTt.forEach(t),uYo=r(YRe," \u2014 "),Cz=n(YRe,"A",{href:!0});var GTt=s(Cz);bYo=r(GTt,"ConvBertForQuestionAnswering"),GTt.forEach(t),vYo=r(YRe," (ConvBERT model)"),YRe.forEach(t),FYo=i(X),n6=n(X,"LI",{});var KRe=s(n6);Lue=n(KRe,"STRONG",{});var OTt=s(Lue);TYo=r(OTt,"data2vec-text"),OTt.forEach(t),MYo=r(KRe," \u2014 "),wz=n(KRe,"A",{href:!0});var VTt=s(wz);EYo=r(VTt,"Data2VecTextForQuestionAnswering"),VTt.forEach(t),CYo=r(KRe," (Data2VecText model)"),KRe.forEach(t),wYo=i(X),s6=n(X,"LI",{});var ZRe=s(s6);yue=n(ZRe,"STRONG",{});var XTt=s(yue);AYo=r(XTt,"deberta"),XTt.forEach(t),LYo=r(ZRe," \u2014 "),Az=n(ZRe,"A",{href:!0});var zTt=s(Az);yYo=r(zTt,"DebertaForQuestionAnswering"),zTt.forEach(t),xYo=r(ZRe," (DeBERTa model)"),ZRe.forEach(t),$Yo=i(X),l6=n(X,"LI",{});var ePe=s(l6);xue=n(ePe,"STRONG",{});var QTt=s(xue);kYo=r(QTt,"deberta-v2"),QTt.forEach(t),SYo=r(ePe," \u2014 "),Lz=n(ePe,"A",{href:!0});var WTt=s(Lz);RYo=r(WTt,"DebertaV2ForQuestionAnswering"),WTt.forEach(t),PYo=r(ePe," (DeBERTa-v2 model)"),ePe.forEach(t),BYo=i(X),i6=n(X,"LI",{});var oPe=s(i6);$ue=n(oPe,"STRONG",{});var HTt=s($ue);IYo=r(HTt,"distilbert"),HTt.forEach(t),NYo=r(oPe," \u2014 "),yz=n(oPe,"A",{href:!0});var UTt=s(yz);qYo=r(UTt,"DistilBertForQuestionAnswering"),UTt.forEach(t),jYo=r(oPe," (DistilBERT model)"),oPe.forEach(t),DYo=i(X),d6=n(X,"LI",{});var rPe=s(d6);kue=n(rPe,"STRONG",{});var JTt=s(kue);GYo=r(JTt,"electra"),JTt.forEach(t),OYo=r(rPe," \u2014 "),xz=n(rPe,"A",{href:!0});var YTt=s(xz);VYo=r(YTt,"ElectraForQuestionAnswering"),YTt.forEach(t),XYo=r(rPe," (ELECTRA model)"),rPe.forEach(t),zYo=i(X),c6=n(X,"LI",{});var tPe=s(c6);Sue=n(tPe,"STRONG",{});var KTt=s(Sue);QYo=r(KTt,"flaubert"),KTt.forEach(t),WYo=r(tPe," \u2014 "),$z=n(tPe,"A",{href:!0});var ZTt=s($z);HYo=r(ZTt,"FlaubertForQuestionAnsweringSimple"),ZTt.forEach(t),UYo=r(tPe," (FlauBERT model)"),tPe.forEach(t),JYo=i(X),f6=n(X,"LI",{});var aPe=s(f6);Rue=n(aPe,"STRONG",{});var e7t=s(Rue);YYo=r(e7t,"fnet"),e7t.forEach(t),KYo=r(aPe," \u2014 "),kz=n(aPe,"A",{href:!0});var o7t=s(kz);ZYo=r(o7t,"FNetForQuestionAnswering"),o7t.forEach(t),eKo=r(aPe," (FNet model)"),aPe.forEach(t),oKo=i(X),m6=n(X,"LI",{});var nPe=s(m6);Pue=n(nPe,"STRONG",{});var r7t=s(Pue);rKo=r(r7t,"funnel"),r7t.forEach(t),tKo=r(nPe," \u2014 "),Sz=n(nPe,"A",{href:!0});var t7t=s(Sz);aKo=r(t7t,"FunnelForQuestionAnswering"),t7t.forEach(t),nKo=r(nPe," (Funnel Transformer model)"),nPe.forEach(t),sKo=i(X),g6=n(X,"LI",{});var sPe=s(g6);Bue=n(sPe,"STRONG",{});var a7t=s(Bue);lKo=r(a7t,"gptj"),a7t.forEach(t),iKo=r(sPe," \u2014 "),Rz=n(sPe,"A",{href:!0});var n7t=s(Rz);dKo=r(n7t,"GPTJForQuestionAnswering"),n7t.forEach(t),cKo=r(sPe," (GPT-J model)"),sPe.forEach(t),fKo=i(X),h6=n(X,"LI",{});var lPe=s(h6);Iue=n(lPe,"STRONG",{});var s7t=s(Iue);mKo=r(s7t,"ibert"),s7t.forEach(t),gKo=r(lPe," \u2014 "),Pz=n(lPe,"A",{href:!0});var l7t=s(Pz);hKo=r(l7t,"IBertForQuestionAnswering"),l7t.forEach(t),pKo=r(lPe," (I-BERT model)"),lPe.forEach(t),_Ko=i(X),p6=n(X,"LI",{});var iPe=s(p6);Nue=n(iPe,"STRONG",{});var i7t=s(Nue);uKo=r(i7t,"layoutlmv2"),i7t.forEach(t),bKo=r(iPe," \u2014 "),Bz=n(iPe,"A",{href:!0});var d7t=s(Bz);vKo=r(d7t,"LayoutLMv2ForQuestionAnswering"),d7t.forEach(t),FKo=r(iPe," (LayoutLMv2 model)"),iPe.forEach(t),TKo=i(X),_6=n(X,"LI",{});var dPe=s(_6);que=n(dPe,"STRONG",{});var c7t=s(que);MKo=r(c7t,"layoutlmv3"),c7t.forEach(t),EKo=r(dPe," \u2014 "),Iz=n(dPe,"A",{href:!0});var f7t=s(Iz);CKo=r(f7t,"LayoutLMv3ForQuestionAnswering"),f7t.forEach(t),wKo=r(dPe," (LayoutLMv3 model)"),dPe.forEach(t),AKo=i(X),u6=n(X,"LI",{});var cPe=s(u6);jue=n(cPe,"STRONG",{});var m7t=s(jue);LKo=r(m7t,"led"),m7t.forEach(t),yKo=r(cPe," \u2014 "),Nz=n(cPe,"A",{href:!0});var g7t=s(Nz);xKo=r(g7t,"LEDForQuestionAnswering"),g7t.forEach(t),$Ko=r(cPe," (LED model)"),cPe.forEach(t),kKo=i(X),b6=n(X,"LI",{});var fPe=s(b6);Due=n(fPe,"STRONG",{});var h7t=s(Due);SKo=r(h7t,"longformer"),h7t.forEach(t),RKo=r(fPe," \u2014 "),qz=n(fPe,"A",{href:!0});var p7t=s(qz);PKo=r(p7t,"LongformerForQuestionAnswering"),p7t.forEach(t),BKo=r(fPe," (Longformer model)"),fPe.forEach(t),IKo=i(X),v6=n(X,"LI",{});var mPe=s(v6);Gue=n(mPe,"STRONG",{});var _7t=s(Gue);NKo=r(_7t,"lxmert"),_7t.forEach(t),qKo=r(mPe," \u2014 "),jz=n(mPe,"A",{href:!0});var u7t=s(jz);jKo=r(u7t,"LxmertForQuestionAnswering"),u7t.forEach(t),DKo=r(mPe," (LXMERT model)"),mPe.forEach(t),GKo=i(X),F6=n(X,"LI",{});var gPe=s(F6);Oue=n(gPe,"STRONG",{});var b7t=s(Oue);OKo=r(b7t,"mbart"),b7t.forEach(t),VKo=r(gPe," \u2014 "),Dz=n(gPe,"A",{href:!0});var v7t=s(Dz);XKo=r(v7t,"MBartForQuestionAnswering"),v7t.forEach(t),zKo=r(gPe," (mBART model)"),gPe.forEach(t),QKo=i(X),T6=n(X,"LI",{});var hPe=s(T6);Vue=n(hPe,"STRONG",{});var F7t=s(Vue);WKo=r(F7t,"megatron-bert"),F7t.forEach(t),HKo=r(hPe," \u2014 "),Gz=n(hPe,"A",{href:!0});var T7t=s(Gz);UKo=r(T7t,"MegatronBertForQuestionAnswering"),T7t.forEach(t),JKo=r(hPe," (Megatron-BERT model)"),hPe.forEach(t),YKo=i(X),M6=n(X,"LI",{});var pPe=s(M6);Xue=n(pPe,"STRONG",{});var M7t=s(Xue);KKo=r(M7t,"mobilebert"),M7t.forEach(t),ZKo=r(pPe," \u2014 "),Oz=n(pPe,"A",{href:!0});var E7t=s(Oz);eZo=r(E7t,"MobileBertForQuestionAnswering"),E7t.forEach(t),oZo=r(pPe," (MobileBERT model)"),pPe.forEach(t),rZo=i(X),E6=n(X,"LI",{});var _Pe=s(E6);zue=n(_Pe,"STRONG",{});var C7t=s(zue);tZo=r(C7t,"mpnet"),C7t.forEach(t),aZo=r(_Pe," \u2014 "),Vz=n(_Pe,"A",{href:!0});var w7t=s(Vz);nZo=r(w7t,"MPNetForQuestionAnswering"),w7t.forEach(t),sZo=r(_Pe," (MPNet model)"),_Pe.forEach(t),lZo=i(X),C6=n(X,"LI",{});var uPe=s(C6);Que=n(uPe,"STRONG",{});var A7t=s(Que);iZo=r(A7t,"nezha"),A7t.forEach(t),dZo=r(uPe," \u2014 "),Xz=n(uPe,"A",{href:!0});var L7t=s(Xz);cZo=r(L7t,"NezhaForQuestionAnswering"),L7t.forEach(t),fZo=r(uPe," (Nezha model)"),uPe.forEach(t),mZo=i(X),w6=n(X,"LI",{});var bPe=s(w6);Wue=n(bPe,"STRONG",{});var y7t=s(Wue);gZo=r(y7t,"nystromformer"),y7t.forEach(t),hZo=r(bPe," \u2014 "),zz=n(bPe,"A",{href:!0});var x7t=s(zz);pZo=r(x7t,"NystromformerForQuestionAnswering"),x7t.forEach(t),_Zo=r(bPe," (Nystr\xF6mformer model)"),bPe.forEach(t),uZo=i(X),A6=n(X,"LI",{});var vPe=s(A6);Hue=n(vPe,"STRONG",{});var $7t=s(Hue);bZo=r($7t,"qdqbert"),$7t.forEach(t),vZo=r(vPe," \u2014 "),Qz=n(vPe,"A",{href:!0});var k7t=s(Qz);FZo=r(k7t,"QDQBertForQuestionAnswering"),k7t.forEach(t),TZo=r(vPe," (QDQBert model)"),vPe.forEach(t),MZo=i(X),L6=n(X,"LI",{});var FPe=s(L6);Uue=n(FPe,"STRONG",{});var S7t=s(Uue);EZo=r(S7t,"reformer"),S7t.forEach(t),CZo=r(FPe," \u2014 "),Wz=n(FPe,"A",{href:!0});var R7t=s(Wz);wZo=r(R7t,"ReformerForQuestionAnswering"),R7t.forEach(t),AZo=r(FPe," (Reformer model)"),FPe.forEach(t),LZo=i(X),y6=n(X,"LI",{});var TPe=s(y6);Jue=n(TPe,"STRONG",{});var P7t=s(Jue);yZo=r(P7t,"rembert"),P7t.forEach(t),xZo=r(TPe," \u2014 "),Hz=n(TPe,"A",{href:!0});var B7t=s(Hz);$Zo=r(B7t,"RemBertForQuestionAnswering"),B7t.forEach(t),kZo=r(TPe," (RemBERT model)"),TPe.forEach(t),SZo=i(X),x6=n(X,"LI",{});var MPe=s(x6);Yue=n(MPe,"STRONG",{});var I7t=s(Yue);RZo=r(I7t,"roberta"),I7t.forEach(t),PZo=r(MPe," \u2014 "),Uz=n(MPe,"A",{href:!0});var N7t=s(Uz);BZo=r(N7t,"RobertaForQuestionAnswering"),N7t.forEach(t),IZo=r(MPe," (RoBERTa model)"),MPe.forEach(t),NZo=i(X),$6=n(X,"LI",{});var EPe=s($6);Kue=n(EPe,"STRONG",{});var q7t=s(Kue);qZo=r(q7t,"roformer"),q7t.forEach(t),jZo=r(EPe," \u2014 "),Jz=n(EPe,"A",{href:!0});var j7t=s(Jz);DZo=r(j7t,"RoFormerForQuestionAnswering"),j7t.forEach(t),GZo=r(EPe," (RoFormer model)"),EPe.forEach(t),OZo=i(X),k6=n(X,"LI",{});var CPe=s(k6);Zue=n(CPe,"STRONG",{});var D7t=s(Zue);VZo=r(D7t,"splinter"),D7t.forEach(t),XZo=r(CPe," \u2014 "),Yz=n(CPe,"A",{href:!0});var G7t=s(Yz);zZo=r(G7t,"SplinterForQuestionAnswering"),G7t.forEach(t),QZo=r(CPe," (Splinter model)"),CPe.forEach(t),WZo=i(X),S6=n(X,"LI",{});var wPe=s(S6);e1e=n(wPe,"STRONG",{});var O7t=s(e1e);HZo=r(O7t,"squeezebert"),O7t.forEach(t),UZo=r(wPe," \u2014 "),Kz=n(wPe,"A",{href:!0});var V7t=s(Kz);JZo=r(V7t,"SqueezeBertForQuestionAnswering"),V7t.forEach(t),YZo=r(wPe," (SqueezeBERT model)"),wPe.forEach(t),KZo=i(X),R6=n(X,"LI",{});var APe=s(R6);o1e=n(APe,"STRONG",{});var X7t=s(o1e);ZZo=r(X7t,"xlm"),X7t.forEach(t),eer=r(APe," \u2014 "),Zz=n(APe,"A",{href:!0});var z7t=s(Zz);oer=r(z7t,"XLMForQuestionAnsweringSimple"),z7t.forEach(t),rer=r(APe," (XLM model)"),APe.forEach(t),ter=i(X),P6=n(X,"LI",{});var LPe=s(P6);r1e=n(LPe,"STRONG",{});var Q7t=s(r1e);aer=r(Q7t,"xlm-roberta"),Q7t.forEach(t),ner=r(LPe," \u2014 "),eQ=n(LPe,"A",{href:!0});var W7t=s(eQ);ser=r(W7t,"XLMRobertaForQuestionAnswering"),W7t.forEach(t),ler=r(LPe," (XLM-RoBERTa model)"),LPe.forEach(t),ier=i(X),B6=n(X,"LI",{});var yPe=s(B6);t1e=n(yPe,"STRONG",{});var H7t=s(t1e);der=r(H7t,"xlm-roberta-xl"),H7t.forEach(t),cer=r(yPe," \u2014 "),oQ=n(yPe,"A",{href:!0});var U7t=s(oQ);fer=r(U7t,"XLMRobertaXLForQuestionAnswering"),U7t.forEach(t),mer=r(yPe," (XLM-RoBERTa-XL model)"),yPe.forEach(t),ger=i(X),I6=n(X,"LI",{});var xPe=s(I6);a1e=n(xPe,"STRONG",{});var J7t=s(a1e);her=r(J7t,"xlnet"),J7t.forEach(t),per=r(xPe," \u2014 "),rQ=n(xPe,"A",{href:!0});var Y7t=s(rQ);_er=r(Y7t,"XLNetForQuestionAnsweringSimple"),Y7t.forEach(t),uer=r(xPe," (XLNet model)"),xPe.forEach(t),ber=i(X),N6=n(X,"LI",{});var $Pe=s(N6);n1e=n($Pe,"STRONG",{});var K7t=s(n1e);ver=r(K7t,"yoso"),K7t.forEach(t),Fer=r($Pe," \u2014 "),tQ=n($Pe,"A",{href:!0});var Z7t=s(tQ);Ter=r(Z7t,"YosoForQuestionAnswering"),Z7t.forEach(t),Mer=r($Pe," (YOSO model)"),$Pe.forEach(t),X.forEach(t),Eer=i(ha),q6=n(ha,"P",{});var kPe=s(q6);Cer=r(kPe,"The model is set in evaluation mode by default using "),s1e=n(kPe,"CODE",{});var e8t=s(s1e);wer=r(e8t,"model.eval()"),e8t.forEach(t),Aer=r(kPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),l1e=n(kPe,"CODE",{});var o8t=s(l1e);Ler=r(o8t,"model.train()"),o8t.forEach(t),kPe.forEach(t),yer=i(ha),T(j6.$$.fragment,ha),ha.forEach(t),sl.forEach(t),bOe=i(f),fd=n(f,"H2",{class:!0});var CXe=s(fd);D6=n(CXe,"A",{id:!0,class:!0,href:!0});var r8t=s(D6);i1e=n(r8t,"SPAN",{});var t8t=s(i1e);T(YA.$$.fragment,t8t),t8t.forEach(t),r8t.forEach(t),xer=i(CXe),d1e=n(CXe,"SPAN",{});var a8t=s(d1e);$er=r(a8t,"AutoModelForTableQuestionAnswering"),a8t.forEach(t),CXe.forEach(t),vOe=i(f),Do=n(f,"DIV",{class:!0});var ll=s(Do);T(KA.$$.fragment,ll),ker=i(ll),md=n(ll,"P",{});var joe=s(md);Ser=r(joe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),aQ=n(joe,"A",{href:!0});var n8t=s(aQ);Rer=r(n8t,"from_pretrained()"),n8t.forEach(t),Per=r(joe," class method or the "),nQ=n(joe,"A",{href:!0});var s8t=s(nQ);Ber=r(s8t,"from_config()"),s8t.forEach(t),Ier=r(joe,` class
method.`),joe.forEach(t),Ner=i(ll),ZA=n(ll,"P",{});var wXe=s(ZA);qer=r(wXe,"This class cannot be instantiated directly using "),c1e=n(wXe,"CODE",{});var l8t=s(c1e);jer=r(l8t,"__init__()"),l8t.forEach(t),Der=r(wXe," (throws an error)."),wXe.forEach(t),Ger=i(ll),pt=n(ll,"DIV",{class:!0});var Y3=s(pt);T(eL.$$.fragment,Y3),Oer=i(Y3),f1e=n(Y3,"P",{});var i8t=s(f1e);Ver=r(i8t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),i8t.forEach(t),Xer=i(Y3),gd=n(Y3,"P",{});var Doe=s(gd);zer=r(Doe,`Note:
Loading a model from its configuration file does `),m1e=n(Doe,"STRONG",{});var d8t=s(m1e);Qer=r(d8t,"not"),d8t.forEach(t),Wer=r(Doe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sQ=n(Doe,"A",{href:!0});var c8t=s(sQ);Her=r(c8t,"from_pretrained()"),c8t.forEach(t),Uer=r(Doe," to load the model weights."),Doe.forEach(t),Jer=i(Y3),T(G6.$$.fragment,Y3),Y3.forEach(t),Yer=i(ll),so=n(ll,"DIV",{class:!0});var pa=s(so);T(oL.$$.fragment,pa),Ker=i(pa),g1e=n(pa,"P",{});var f8t=s(g1e);Zer=r(f8t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),f8t.forEach(t),eor=i(pa),Va=n(pa,"P",{});var K3=s(Va);oor=r(K3,"The model class to instantiate is selected based on the "),h1e=n(K3,"CODE",{});var m8t=s(h1e);ror=r(m8t,"model_type"),m8t.forEach(t),tor=r(K3,` property of the config object (either
passed as an argument or loaded from `),p1e=n(K3,"CODE",{});var g8t=s(p1e);aor=r(g8t,"pretrained_model_name_or_path"),g8t.forEach(t),nor=r(K3,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),_1e=n(K3,"CODE",{});var h8t=s(_1e);sor=r(h8t,"pretrained_model_name_or_path"),h8t.forEach(t),lor=r(K3,":"),K3.forEach(t),ior=i(pa),u1e=n(pa,"UL",{});var p8t=s(u1e);O6=n(p8t,"LI",{});var SPe=s(O6);b1e=n(SPe,"STRONG",{});var _8t=s(b1e);dor=r(_8t,"tapas"),_8t.forEach(t),cor=r(SPe," \u2014 "),lQ=n(SPe,"A",{href:!0});var u8t=s(lQ);mor=r(u8t,"TapasForQuestionAnswering"),u8t.forEach(t),gor=r(SPe," (TAPAS model)"),SPe.forEach(t),p8t.forEach(t),hor=i(pa),V6=n(pa,"P",{});var RPe=s(V6);por=r(RPe,"The model is set in evaluation mode by default using "),v1e=n(RPe,"CODE",{});var b8t=s(v1e);_or=r(b8t,"model.eval()"),b8t.forEach(t),uor=r(RPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),F1e=n(RPe,"CODE",{});var v8t=s(F1e);bor=r(v8t,"model.train()"),v8t.forEach(t),RPe.forEach(t),vor=i(pa),T(X6.$$.fragment,pa),pa.forEach(t),ll.forEach(t),FOe=i(f),hd=n(f,"H2",{class:!0});var AXe=s(hd);z6=n(AXe,"A",{id:!0,class:!0,href:!0});var F8t=s(z6);T1e=n(F8t,"SPAN",{});var T8t=s(T1e);T(rL.$$.fragment,T8t),T8t.forEach(t),F8t.forEach(t),For=i(AXe),M1e=n(AXe,"SPAN",{});var M8t=s(M1e);Tor=r(M8t,"AutoModelForImageClassification"),M8t.forEach(t),AXe.forEach(t),TOe=i(f),Go=n(f,"DIV",{class:!0});var il=s(Go);T(tL.$$.fragment,il),Mor=i(il),pd=n(il,"P",{});var Goe=s(pd);Eor=r(Goe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),iQ=n(Goe,"A",{href:!0});var E8t=s(iQ);Cor=r(E8t,"from_pretrained()"),E8t.forEach(t),wor=r(Goe," class method or the "),dQ=n(Goe,"A",{href:!0});var C8t=s(dQ);Aor=r(C8t,"from_config()"),C8t.forEach(t),Lor=r(Goe,` class
method.`),Goe.forEach(t),yor=i(il),aL=n(il,"P",{});var LXe=s(aL);xor=r(LXe,"This class cannot be instantiated directly using "),E1e=n(LXe,"CODE",{});var w8t=s(E1e);$or=r(w8t,"__init__()"),w8t.forEach(t),kor=r(LXe," (throws an error)."),LXe.forEach(t),Sor=i(il),_t=n(il,"DIV",{class:!0});var Z3=s(_t);T(nL.$$.fragment,Z3),Ror=i(Z3),C1e=n(Z3,"P",{});var A8t=s(C1e);Por=r(A8t,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),A8t.forEach(t),Bor=i(Z3),_d=n(Z3,"P",{});var Ooe=s(_d);Ior=r(Ooe,`Note:
Loading a model from its configuration file does `),w1e=n(Ooe,"STRONG",{});var L8t=s(w1e);Nor=r(L8t,"not"),L8t.forEach(t),qor=r(Ooe,` load the model weights. It only affects the
model\u2019s configuration. Use `),cQ=n(Ooe,"A",{href:!0});var y8t=s(cQ);jor=r(y8t,"from_pretrained()"),y8t.forEach(t),Dor=r(Ooe," to load the model weights."),Ooe.forEach(t),Gor=i(Z3),T(Q6.$$.fragment,Z3),Z3.forEach(t),Oor=i(il),lo=n(il,"DIV",{class:!0});var _a=s(lo);T(sL.$$.fragment,_a),Vor=i(_a),A1e=n(_a,"P",{});var x8t=s(A1e);Xor=r(x8t,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),x8t.forEach(t),zor=i(_a),Xa=n(_a,"P",{});var e0=s(Xa);Qor=r(e0,"The model class to instantiate is selected based on the "),L1e=n(e0,"CODE",{});var $8t=s(L1e);Wor=r($8t,"model_type"),$8t.forEach(t),Hor=r(e0,` property of the config object (either
passed as an argument or loaded from `),y1e=n(e0,"CODE",{});var k8t=s(y1e);Uor=r(k8t,"pretrained_model_name_or_path"),k8t.forEach(t),Jor=r(e0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),x1e=n(e0,"CODE",{});var S8t=s(x1e);Yor=r(S8t,"pretrained_model_name_or_path"),S8t.forEach(t),Kor=r(e0,":"),e0.forEach(t),Zor=i(_a),Fe=n(_a,"UL",{});var Te=s(Fe);W6=n(Te,"LI",{});var PPe=s(W6);$1e=n(PPe,"STRONG",{});var R8t=s($1e);err=r(R8t,"beit"),R8t.forEach(t),orr=r(PPe," \u2014 "),fQ=n(PPe,"A",{href:!0});var P8t=s(fQ);rrr=r(P8t,"BeitForImageClassification"),P8t.forEach(t),trr=r(PPe," (BEiT model)"),PPe.forEach(t),arr=i(Te),H6=n(Te,"LI",{});var BPe=s(H6);k1e=n(BPe,"STRONG",{});var B8t=s(k1e);nrr=r(B8t,"convnext"),B8t.forEach(t),srr=r(BPe," \u2014 "),mQ=n(BPe,"A",{href:!0});var I8t=s(mQ);lrr=r(I8t,"ConvNextForImageClassification"),I8t.forEach(t),irr=r(BPe," (ConvNeXT model)"),BPe.forEach(t),drr=i(Te),U6=n(Te,"LI",{});var IPe=s(U6);S1e=n(IPe,"STRONG",{});var N8t=s(S1e);crr=r(N8t,"cvt"),N8t.forEach(t),frr=r(IPe," \u2014 "),gQ=n(IPe,"A",{href:!0});var q8t=s(gQ);mrr=r(q8t,"CvtForImageClassification"),q8t.forEach(t),grr=r(IPe," (CvT model)"),IPe.forEach(t),hrr=i(Te),J6=n(Te,"LI",{});var NPe=s(J6);R1e=n(NPe,"STRONG",{});var j8t=s(R1e);prr=r(j8t,"data2vec-vision"),j8t.forEach(t),_rr=r(NPe," \u2014 "),hQ=n(NPe,"A",{href:!0});var D8t=s(hQ);urr=r(D8t,"Data2VecVisionForImageClassification"),D8t.forEach(t),brr=r(NPe," (Data2VecVision model)"),NPe.forEach(t),vrr=i(Te),Xs=n(Te,"LI",{});var Zk=s(Xs);P1e=n(Zk,"STRONG",{});var G8t=s(P1e);Frr=r(G8t,"deit"),G8t.forEach(t),Trr=r(Zk," \u2014 "),pQ=n(Zk,"A",{href:!0});var O8t=s(pQ);Mrr=r(O8t,"DeiTForImageClassification"),O8t.forEach(t),Err=r(Zk," or "),_Q=n(Zk,"A",{href:!0});var V8t=s(_Q);Crr=r(V8t,"DeiTForImageClassificationWithTeacher"),V8t.forEach(t),wrr=r(Zk," (DeiT model)"),Zk.forEach(t),Arr=i(Te),Y6=n(Te,"LI",{});var qPe=s(Y6);B1e=n(qPe,"STRONG",{});var X8t=s(B1e);Lrr=r(X8t,"imagegpt"),X8t.forEach(t),yrr=r(qPe," \u2014 "),uQ=n(qPe,"A",{href:!0});var z8t=s(uQ);xrr=r(z8t,"ImageGPTForImageClassification"),z8t.forEach(t),$rr=r(qPe," (ImageGPT model)"),qPe.forEach(t),krr=i(Te),zs=n(Te,"LI",{});var eS=s(zs);I1e=n(eS,"STRONG",{});var Q8t=s(I1e);Srr=r(Q8t,"levit"),Q8t.forEach(t),Rrr=r(eS," \u2014 "),bQ=n(eS,"A",{href:!0});var W8t=s(bQ);Prr=r(W8t,"LevitForImageClassification"),W8t.forEach(t),Brr=r(eS," or "),vQ=n(eS,"A",{href:!0});var H8t=s(vQ);Irr=r(H8t,"LevitForImageClassificationWithTeacher"),H8t.forEach(t),Nrr=r(eS," (LeViT model)"),eS.forEach(t),qrr=i(Te),ut=n(Te,"LI",{});var Lf=s(ut);N1e=n(Lf,"STRONG",{});var U8t=s(N1e);jrr=r(U8t,"perceiver"),U8t.forEach(t),Drr=r(Lf," \u2014 "),FQ=n(Lf,"A",{href:!0});var J8t=s(FQ);Grr=r(J8t,"PerceiverForImageClassificationLearned"),J8t.forEach(t),Orr=r(Lf," or "),TQ=n(Lf,"A",{href:!0});var Y8t=s(TQ);Vrr=r(Y8t,"PerceiverForImageClassificationFourier"),Y8t.forEach(t),Xrr=r(Lf," or "),MQ=n(Lf,"A",{href:!0});var K8t=s(MQ);zrr=r(K8t,"PerceiverForImageClassificationConvProcessing"),K8t.forEach(t),Qrr=r(Lf," (Perceiver model)"),Lf.forEach(t),Wrr=i(Te),K6=n(Te,"LI",{});var jPe=s(K6);q1e=n(jPe,"STRONG",{});var Z8t=s(q1e);Hrr=r(Z8t,"poolformer"),Z8t.forEach(t),Urr=r(jPe," \u2014 "),EQ=n(jPe,"A",{href:!0});var e9t=s(EQ);Jrr=r(e9t,"PoolFormerForImageClassification"),e9t.forEach(t),Yrr=r(jPe," (PoolFormer model)"),jPe.forEach(t),Krr=i(Te),Z6=n(Te,"LI",{});var DPe=s(Z6);j1e=n(DPe,"STRONG",{});var o9t=s(j1e);Zrr=r(o9t,"regnet"),o9t.forEach(t),etr=r(DPe," \u2014 "),CQ=n(DPe,"A",{href:!0});var r9t=s(CQ);otr=r(r9t,"RegNetForImageClassification"),r9t.forEach(t),rtr=r(DPe," (RegNet model)"),DPe.forEach(t),ttr=i(Te),eT=n(Te,"LI",{});var GPe=s(eT);D1e=n(GPe,"STRONG",{});var t9t=s(D1e);atr=r(t9t,"resnet"),t9t.forEach(t),ntr=r(GPe," \u2014 "),wQ=n(GPe,"A",{href:!0});var a9t=s(wQ);str=r(a9t,"ResNetForImageClassification"),a9t.forEach(t),ltr=r(GPe," (ResNet model)"),GPe.forEach(t),itr=i(Te),oT=n(Te,"LI",{});var OPe=s(oT);G1e=n(OPe,"STRONG",{});var n9t=s(G1e);dtr=r(n9t,"segformer"),n9t.forEach(t),ctr=r(OPe," \u2014 "),AQ=n(OPe,"A",{href:!0});var s9t=s(AQ);ftr=r(s9t,"SegformerForImageClassification"),s9t.forEach(t),mtr=r(OPe," (SegFormer model)"),OPe.forEach(t),gtr=i(Te),rT=n(Te,"LI",{});var VPe=s(rT);O1e=n(VPe,"STRONG",{});var l9t=s(O1e);htr=r(l9t,"swin"),l9t.forEach(t),ptr=r(VPe," \u2014 "),LQ=n(VPe,"A",{href:!0});var i9t=s(LQ);_tr=r(i9t,"SwinForImageClassification"),i9t.forEach(t),utr=r(VPe," (Swin Transformer model)"),VPe.forEach(t),btr=i(Te),tT=n(Te,"LI",{});var XPe=s(tT);V1e=n(XPe,"STRONG",{});var d9t=s(V1e);vtr=r(d9t,"van"),d9t.forEach(t),Ftr=r(XPe," \u2014 "),yQ=n(XPe,"A",{href:!0});var c9t=s(yQ);Ttr=r(c9t,"VanForImageClassification"),c9t.forEach(t),Mtr=r(XPe," (VAN model)"),XPe.forEach(t),Etr=i(Te),aT=n(Te,"LI",{});var zPe=s(aT);X1e=n(zPe,"STRONG",{});var f9t=s(X1e);Ctr=r(f9t,"vit"),f9t.forEach(t),wtr=r(zPe," \u2014 "),xQ=n(zPe,"A",{href:!0});var m9t=s(xQ);Atr=r(m9t,"ViTForImageClassification"),m9t.forEach(t),Ltr=r(zPe," (ViT model)"),zPe.forEach(t),Te.forEach(t),ytr=i(_a),nT=n(_a,"P",{});var QPe=s(nT);xtr=r(QPe,"The model is set in evaluation mode by default using "),z1e=n(QPe,"CODE",{});var g9t=s(z1e);$tr=r(g9t,"model.eval()"),g9t.forEach(t),ktr=r(QPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Q1e=n(QPe,"CODE",{});var h9t=s(Q1e);Str=r(h9t,"model.train()"),h9t.forEach(t),QPe.forEach(t),Rtr=i(_a),T(sT.$$.fragment,_a),_a.forEach(t),il.forEach(t),MOe=i(f),ud=n(f,"H2",{class:!0});var yXe=s(ud);lT=n(yXe,"A",{id:!0,class:!0,href:!0});var p9t=s(lT);W1e=n(p9t,"SPAN",{});var _9t=s(W1e);T(lL.$$.fragment,_9t),_9t.forEach(t),p9t.forEach(t),Ptr=i(yXe),H1e=n(yXe,"SPAN",{});var u9t=s(H1e);Btr=r(u9t,"AutoModelForVision2Seq"),u9t.forEach(t),yXe.forEach(t),EOe=i(f),Oo=n(f,"DIV",{class:!0});var dl=s(Oo);T(iL.$$.fragment,dl),Itr=i(dl),bd=n(dl,"P",{});var Voe=s(bd);Ntr=r(Voe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),$Q=n(Voe,"A",{href:!0});var b9t=s($Q);qtr=r(b9t,"from_pretrained()"),b9t.forEach(t),jtr=r(Voe," class method or the "),kQ=n(Voe,"A",{href:!0});var v9t=s(kQ);Dtr=r(v9t,"from_config()"),v9t.forEach(t),Gtr=r(Voe,` class
method.`),Voe.forEach(t),Otr=i(dl),dL=n(dl,"P",{});var xXe=s(dL);Vtr=r(xXe,"This class cannot be instantiated directly using "),U1e=n(xXe,"CODE",{});var F9t=s(U1e);Xtr=r(F9t,"__init__()"),F9t.forEach(t),ztr=r(xXe," (throws an error)."),xXe.forEach(t),Qtr=i(dl),bt=n(dl,"DIV",{class:!0});var o0=s(bt);T(cL.$$.fragment,o0),Wtr=i(o0),J1e=n(o0,"P",{});var T9t=s(J1e);Htr=r(T9t,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),T9t.forEach(t),Utr=i(o0),vd=n(o0,"P",{});var Xoe=s(vd);Jtr=r(Xoe,`Note:
Loading a model from its configuration file does `),Y1e=n(Xoe,"STRONG",{});var M9t=s(Y1e);Ytr=r(M9t,"not"),M9t.forEach(t),Ktr=r(Xoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),SQ=n(Xoe,"A",{href:!0});var E9t=s(SQ);Ztr=r(E9t,"from_pretrained()"),E9t.forEach(t),ear=r(Xoe," to load the model weights."),Xoe.forEach(t),oar=i(o0),T(iT.$$.fragment,o0),o0.forEach(t),rar=i(dl),io=n(dl,"DIV",{class:!0});var ua=s(io);T(fL.$$.fragment,ua),tar=i(ua),K1e=n(ua,"P",{});var C9t=s(K1e);aar=r(C9t,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),C9t.forEach(t),nar=i(ua),za=n(ua,"P",{});var r0=s(za);sar=r(r0,"The model class to instantiate is selected based on the "),Z1e=n(r0,"CODE",{});var w9t=s(Z1e);lar=r(w9t,"model_type"),w9t.forEach(t),iar=r(r0,` property of the config object (either
passed as an argument or loaded from `),e2e=n(r0,"CODE",{});var A9t=s(e2e);dar=r(A9t,"pretrained_model_name_or_path"),A9t.forEach(t),car=r(r0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),o2e=n(r0,"CODE",{});var L9t=s(o2e);far=r(L9t,"pretrained_model_name_or_path"),L9t.forEach(t),mar=r(r0,":"),r0.forEach(t),gar=i(ua),r2e=n(ua,"UL",{});var y9t=s(r2e);dT=n(y9t,"LI",{});var WPe=s(dT);t2e=n(WPe,"STRONG",{});var x9t=s(t2e);har=r(x9t,"vision-encoder-decoder"),x9t.forEach(t),par=r(WPe," \u2014 "),RQ=n(WPe,"A",{href:!0});var $9t=s(RQ);_ar=r($9t,"VisionEncoderDecoderModel"),$9t.forEach(t),uar=r(WPe," (Vision Encoder decoder model)"),WPe.forEach(t),y9t.forEach(t),bar=i(ua),cT=n(ua,"P",{});var HPe=s(cT);Far=r(HPe,"The model is set in evaluation mode by default using "),a2e=n(HPe,"CODE",{});var k9t=s(a2e);Tar=r(k9t,"model.eval()"),k9t.forEach(t),Mar=r(HPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),n2e=n(HPe,"CODE",{});var S9t=s(n2e);Ear=r(S9t,"model.train()"),S9t.forEach(t),HPe.forEach(t),Car=i(ua),T(fT.$$.fragment,ua),ua.forEach(t),dl.forEach(t),COe=i(f),Fd=n(f,"H2",{class:!0});var $Xe=s(Fd);mT=n($Xe,"A",{id:!0,class:!0,href:!0});var R9t=s(mT);s2e=n(R9t,"SPAN",{});var P9t=s(s2e);T(mL.$$.fragment,P9t),P9t.forEach(t),R9t.forEach(t),war=i($Xe),l2e=n($Xe,"SPAN",{});var B9t=s(l2e);Aar=r(B9t,"AutoModelForVisualQuestionAnswering"),B9t.forEach(t),$Xe.forEach(t),wOe=i(f),Vo=n(f,"DIV",{class:!0});var cl=s(Vo);T(gL.$$.fragment,cl),Lar=i(cl),Td=n(cl,"P",{});var zoe=s(Td);yar=r(zoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a visual question answering head) when created
with the `),PQ=n(zoe,"A",{href:!0});var I9t=s(PQ);xar=r(I9t,"from_pretrained()"),I9t.forEach(t),$ar=r(zoe," class method or the "),BQ=n(zoe,"A",{href:!0});var N9t=s(BQ);kar=r(N9t,"from_config()"),N9t.forEach(t),Sar=r(zoe,` class
method.`),zoe.forEach(t),Rar=i(cl),hL=n(cl,"P",{});var kXe=s(hL);Par=r(kXe,"This class cannot be instantiated directly using "),i2e=n(kXe,"CODE",{});var q9t=s(i2e);Bar=r(q9t,"__init__()"),q9t.forEach(t),Iar=r(kXe," (throws an error)."),kXe.forEach(t),Nar=i(cl),vt=n(cl,"DIV",{class:!0});var t0=s(vt);T(pL.$$.fragment,t0),qar=i(t0),d2e=n(t0,"P",{});var j9t=s(d2e);jar=r(j9t,"Instantiates one of the model classes of the library (with a visual question answering head) from a configuration."),j9t.forEach(t),Dar=i(t0),Md=n(t0,"P",{});var Qoe=s(Md);Gar=r(Qoe,`Note:
Loading a model from its configuration file does `),c2e=n(Qoe,"STRONG",{});var D9t=s(c2e);Oar=r(D9t,"not"),D9t.forEach(t),Var=r(Qoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),IQ=n(Qoe,"A",{href:!0});var G9t=s(IQ);Xar=r(G9t,"from_pretrained()"),G9t.forEach(t),zar=r(Qoe," to load the model weights."),Qoe.forEach(t),Qar=i(t0),T(gT.$$.fragment,t0),t0.forEach(t),War=i(cl),co=n(cl,"DIV",{class:!0});var ba=s(co);T(_L.$$.fragment,ba),Har=i(ba),f2e=n(ba,"P",{});var O9t=s(f2e);Uar=r(O9t,"Instantiate one of the model classes of the library (with a visual question answering head) from a pretrained model."),O9t.forEach(t),Jar=i(ba),Qa=n(ba,"P",{});var a0=s(Qa);Yar=r(a0,"The model class to instantiate is selected based on the "),m2e=n(a0,"CODE",{});var V9t=s(m2e);Kar=r(V9t,"model_type"),V9t.forEach(t),Zar=r(a0,` property of the config object (either
passed as an argument or loaded from `),g2e=n(a0,"CODE",{});var X9t=s(g2e);enr=r(X9t,"pretrained_model_name_or_path"),X9t.forEach(t),onr=r(a0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),h2e=n(a0,"CODE",{});var z9t=s(h2e);rnr=r(z9t,"pretrained_model_name_or_path"),z9t.forEach(t),tnr=r(a0,":"),a0.forEach(t),anr=i(ba),p2e=n(ba,"UL",{});var Q9t=s(p2e);hT=n(Q9t,"LI",{});var UPe=s(hT);_2e=n(UPe,"STRONG",{});var W9t=s(_2e);nnr=r(W9t,"vilt"),W9t.forEach(t),snr=r(UPe," \u2014 "),NQ=n(UPe,"A",{href:!0});var H9t=s(NQ);lnr=r(H9t,"ViltForQuestionAnswering"),H9t.forEach(t),inr=r(UPe," (ViLT model)"),UPe.forEach(t),Q9t.forEach(t),dnr=i(ba),pT=n(ba,"P",{});var JPe=s(pT);cnr=r(JPe,"The model is set in evaluation mode by default using "),u2e=n(JPe,"CODE",{});var U9t=s(u2e);fnr=r(U9t,"model.eval()"),U9t.forEach(t),mnr=r(JPe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),b2e=n(JPe,"CODE",{});var J9t=s(b2e);gnr=r(J9t,"model.train()"),J9t.forEach(t),JPe.forEach(t),hnr=i(ba),T(_T.$$.fragment,ba),ba.forEach(t),cl.forEach(t),AOe=i(f),Ed=n(f,"H2",{class:!0});var SXe=s(Ed);uT=n(SXe,"A",{id:!0,class:!0,href:!0});var Y9t=s(uT);v2e=n(Y9t,"SPAN",{});var K9t=s(v2e);T(uL.$$.fragment,K9t),K9t.forEach(t),Y9t.forEach(t),pnr=i(SXe),F2e=n(SXe,"SPAN",{});var Z9t=s(F2e);_nr=r(Z9t,"AutoModelForAudioClassification"),Z9t.forEach(t),SXe.forEach(t),LOe=i(f),Xo=n(f,"DIV",{class:!0});var fl=s(Xo);T(bL.$$.fragment,fl),unr=i(fl),Cd=n(fl,"P",{});var Woe=s(Cd);bnr=r(Woe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio classification head) when created
with the `),qQ=n(Woe,"A",{href:!0});var eMt=s(qQ);vnr=r(eMt,"from_pretrained()"),eMt.forEach(t),Fnr=r(Woe," class method or the "),jQ=n(Woe,"A",{href:!0});var oMt=s(jQ);Tnr=r(oMt,"from_config()"),oMt.forEach(t),Mnr=r(Woe,` class
method.`),Woe.forEach(t),Enr=i(fl),vL=n(fl,"P",{});var RXe=s(vL);Cnr=r(RXe,"This class cannot be instantiated directly using "),T2e=n(RXe,"CODE",{});var rMt=s(T2e);wnr=r(rMt,"__init__()"),rMt.forEach(t),Anr=r(RXe," (throws an error)."),RXe.forEach(t),Lnr=i(fl),Ft=n(fl,"DIV",{class:!0});var n0=s(Ft);T(FL.$$.fragment,n0),ynr=i(n0),M2e=n(n0,"P",{});var tMt=s(M2e);xnr=r(tMt,"Instantiates one of the model classes of the library (with a audio classification head) from a configuration."),tMt.forEach(t),$nr=i(n0),wd=n(n0,"P",{});var Hoe=s(wd);knr=r(Hoe,`Note:
Loading a model from its configuration file does `),E2e=n(Hoe,"STRONG",{});var aMt=s(E2e);Snr=r(aMt,"not"),aMt.forEach(t),Rnr=r(Hoe,` load the model weights. It only affects the
model\u2019s configuration. Use `),DQ=n(Hoe,"A",{href:!0});var nMt=s(DQ);Pnr=r(nMt,"from_pretrained()"),nMt.forEach(t),Bnr=r(Hoe," to load the model weights."),Hoe.forEach(t),Inr=i(n0),T(bT.$$.fragment,n0),n0.forEach(t),Nnr=i(fl),fo=n(fl,"DIV",{class:!0});var va=s(fo);T(TL.$$.fragment,va),qnr=i(va),C2e=n(va,"P",{});var sMt=s(C2e);jnr=r(sMt,"Instantiate one of the model classes of the library (with a audio classification head) from a pretrained model."),sMt.forEach(t),Dnr=i(va),Wa=n(va,"P",{});var s0=s(Wa);Gnr=r(s0,"The model class to instantiate is selected based on the "),w2e=n(s0,"CODE",{});var lMt=s(w2e);Onr=r(lMt,"model_type"),lMt.forEach(t),Vnr=r(s0,` property of the config object (either
passed as an argument or loaded from `),A2e=n(s0,"CODE",{});var iMt=s(A2e);Xnr=r(iMt,"pretrained_model_name_or_path"),iMt.forEach(t),znr=r(s0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),L2e=n(s0,"CODE",{});var dMt=s(L2e);Qnr=r(dMt,"pretrained_model_name_or_path"),dMt.forEach(t),Wnr=r(s0,":"),s0.forEach(t),Hnr=i(va),Pe=n(va,"UL",{});var ze=s(Pe);vT=n(ze,"LI",{});var YPe=s(vT);y2e=n(YPe,"STRONG",{});var cMt=s(y2e);Unr=r(cMt,"data2vec-audio"),cMt.forEach(t),Jnr=r(YPe," \u2014 "),GQ=n(YPe,"A",{href:!0});var fMt=s(GQ);Ynr=r(fMt,"Data2VecAudioForSequenceClassification"),fMt.forEach(t),Knr=r(YPe," (Data2VecAudio model)"),YPe.forEach(t),Znr=i(ze),FT=n(ze,"LI",{});var KPe=s(FT);x2e=n(KPe,"STRONG",{});var mMt=s(x2e);esr=r(mMt,"hubert"),mMt.forEach(t),osr=r(KPe," \u2014 "),OQ=n(KPe,"A",{href:!0});var gMt=s(OQ);rsr=r(gMt,"HubertForSequenceClassification"),gMt.forEach(t),tsr=r(KPe," (Hubert model)"),KPe.forEach(t),asr=i(ze),TT=n(ze,"LI",{});var ZPe=s(TT);$2e=n(ZPe,"STRONG",{});var hMt=s($2e);nsr=r(hMt,"sew"),hMt.forEach(t),ssr=r(ZPe," \u2014 "),VQ=n(ZPe,"A",{href:!0});var pMt=s(VQ);lsr=r(pMt,"SEWForSequenceClassification"),pMt.forEach(t),isr=r(ZPe," (SEW model)"),ZPe.forEach(t),dsr=i(ze),MT=n(ze,"LI",{});var eBe=s(MT);k2e=n(eBe,"STRONG",{});var _Mt=s(k2e);csr=r(_Mt,"sew-d"),_Mt.forEach(t),fsr=r(eBe," \u2014 "),XQ=n(eBe,"A",{href:!0});var uMt=s(XQ);msr=r(uMt,"SEWDForSequenceClassification"),uMt.forEach(t),gsr=r(eBe," (SEW-D model)"),eBe.forEach(t),hsr=i(ze),ET=n(ze,"LI",{});var oBe=s(ET);S2e=n(oBe,"STRONG",{});var bMt=s(S2e);psr=r(bMt,"unispeech"),bMt.forEach(t),_sr=r(oBe," \u2014 "),zQ=n(oBe,"A",{href:!0});var vMt=s(zQ);usr=r(vMt,"UniSpeechForSequenceClassification"),vMt.forEach(t),bsr=r(oBe," (UniSpeech model)"),oBe.forEach(t),vsr=i(ze),CT=n(ze,"LI",{});var rBe=s(CT);R2e=n(rBe,"STRONG",{});var FMt=s(R2e);Fsr=r(FMt,"unispeech-sat"),FMt.forEach(t),Tsr=r(rBe," \u2014 "),QQ=n(rBe,"A",{href:!0});var TMt=s(QQ);Msr=r(TMt,"UniSpeechSatForSequenceClassification"),TMt.forEach(t),Esr=r(rBe," (UniSpeechSat model)"),rBe.forEach(t),Csr=i(ze),wT=n(ze,"LI",{});var tBe=s(wT);P2e=n(tBe,"STRONG",{});var MMt=s(P2e);wsr=r(MMt,"wav2vec2"),MMt.forEach(t),Asr=r(tBe," \u2014 "),WQ=n(tBe,"A",{href:!0});var EMt=s(WQ);Lsr=r(EMt,"Wav2Vec2ForSequenceClassification"),EMt.forEach(t),ysr=r(tBe," (Wav2Vec2 model)"),tBe.forEach(t),xsr=i(ze),AT=n(ze,"LI",{});var aBe=s(AT);B2e=n(aBe,"STRONG",{});var CMt=s(B2e);$sr=r(CMt,"wav2vec2-conformer"),CMt.forEach(t),ksr=r(aBe," \u2014 "),HQ=n(aBe,"A",{href:!0});var wMt=s(HQ);Ssr=r(wMt,"Wav2Vec2ConformerForSequenceClassification"),wMt.forEach(t),Rsr=r(aBe," (Wav2Vec2-Conformer model)"),aBe.forEach(t),Psr=i(ze),LT=n(ze,"LI",{});var nBe=s(LT);I2e=n(nBe,"STRONG",{});var AMt=s(I2e);Bsr=r(AMt,"wavlm"),AMt.forEach(t),Isr=r(nBe," \u2014 "),UQ=n(nBe,"A",{href:!0});var LMt=s(UQ);Nsr=r(LMt,"WavLMForSequenceClassification"),LMt.forEach(t),qsr=r(nBe," (WavLM model)"),nBe.forEach(t),ze.forEach(t),jsr=i(va),yT=n(va,"P",{});var sBe=s(yT);Dsr=r(sBe,"The model is set in evaluation mode by default using "),N2e=n(sBe,"CODE",{});var yMt=s(N2e);Gsr=r(yMt,"model.eval()"),yMt.forEach(t),Osr=r(sBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),q2e=n(sBe,"CODE",{});var xMt=s(q2e);Vsr=r(xMt,"model.train()"),xMt.forEach(t),sBe.forEach(t),Xsr=i(va),T(xT.$$.fragment,va),va.forEach(t),fl.forEach(t),yOe=i(f),Ad=n(f,"H2",{class:!0});var PXe=s(Ad);$T=n(PXe,"A",{id:!0,class:!0,href:!0});var $Mt=s($T);j2e=n($Mt,"SPAN",{});var kMt=s(j2e);T(ML.$$.fragment,kMt),kMt.forEach(t),$Mt.forEach(t),zsr=i(PXe),D2e=n(PXe,"SPAN",{});var SMt=s(D2e);Qsr=r(SMt,"AutoModelForAudioFrameClassification"),SMt.forEach(t),PXe.forEach(t),xOe=i(f),zo=n(f,"DIV",{class:!0});var ml=s(zo);T(EL.$$.fragment,ml),Wsr=i(ml),Ld=n(ml,"P",{});var Uoe=s(Ld);Hsr=r(Uoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio frame (token) classification head) when created
with the `),JQ=n(Uoe,"A",{href:!0});var RMt=s(JQ);Usr=r(RMt,"from_pretrained()"),RMt.forEach(t),Jsr=r(Uoe," class method or the "),YQ=n(Uoe,"A",{href:!0});var PMt=s(YQ);Ysr=r(PMt,"from_config()"),PMt.forEach(t),Ksr=r(Uoe,` class
method.`),Uoe.forEach(t),Zsr=i(ml),CL=n(ml,"P",{});var BXe=s(CL);elr=r(BXe,"This class cannot be instantiated directly using "),G2e=n(BXe,"CODE",{});var BMt=s(G2e);olr=r(BMt,"__init__()"),BMt.forEach(t),rlr=r(BXe," (throws an error)."),BXe.forEach(t),tlr=i(ml),Tt=n(ml,"DIV",{class:!0});var l0=s(Tt);T(wL.$$.fragment,l0),alr=i(l0),O2e=n(l0,"P",{});var IMt=s(O2e);nlr=r(IMt,"Instantiates one of the model classes of the library (with a audio frame (token) classification head) from a configuration."),IMt.forEach(t),slr=i(l0),yd=n(l0,"P",{});var Joe=s(yd);llr=r(Joe,`Note:
Loading a model from its configuration file does `),V2e=n(Joe,"STRONG",{});var NMt=s(V2e);ilr=r(NMt,"not"),NMt.forEach(t),dlr=r(Joe,` load the model weights. It only affects the
model\u2019s configuration. Use `),KQ=n(Joe,"A",{href:!0});var qMt=s(KQ);clr=r(qMt,"from_pretrained()"),qMt.forEach(t),flr=r(Joe," to load the model weights."),Joe.forEach(t),mlr=i(l0),T(kT.$$.fragment,l0),l0.forEach(t),glr=i(ml),mo=n(ml,"DIV",{class:!0});var Fa=s(mo);T(AL.$$.fragment,Fa),hlr=i(Fa),X2e=n(Fa,"P",{});var jMt=s(X2e);plr=r(jMt,"Instantiate one of the model classes of the library (with a audio frame (token) classification head) from a pretrained model."),jMt.forEach(t),_lr=i(Fa),Ha=n(Fa,"P",{});var i0=s(Ha);ulr=r(i0,"The model class to instantiate is selected based on the "),z2e=n(i0,"CODE",{});var DMt=s(z2e);blr=r(DMt,"model_type"),DMt.forEach(t),vlr=r(i0,` property of the config object (either
passed as an argument or loaded from `),Q2e=n(i0,"CODE",{});var GMt=s(Q2e);Flr=r(GMt,"pretrained_model_name_or_path"),GMt.forEach(t),Tlr=r(i0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),W2e=n(i0,"CODE",{});var OMt=s(W2e);Mlr=r(OMt,"pretrained_model_name_or_path"),OMt.forEach(t),Elr=r(i0,":"),i0.forEach(t),Clr=i(Fa),et=n(Fa,"UL",{});var gl=s(et);ST=n(gl,"LI",{});var lBe=s(ST);H2e=n(lBe,"STRONG",{});var VMt=s(H2e);wlr=r(VMt,"data2vec-audio"),VMt.forEach(t),Alr=r(lBe," \u2014 "),ZQ=n(lBe,"A",{href:!0});var XMt=s(ZQ);Llr=r(XMt,"Data2VecAudioForAudioFrameClassification"),XMt.forEach(t),ylr=r(lBe," (Data2VecAudio model)"),lBe.forEach(t),xlr=i(gl),RT=n(gl,"LI",{});var iBe=s(RT);U2e=n(iBe,"STRONG",{});var zMt=s(U2e);$lr=r(zMt,"unispeech-sat"),zMt.forEach(t),klr=r(iBe," \u2014 "),eW=n(iBe,"A",{href:!0});var QMt=s(eW);Slr=r(QMt,"UniSpeechSatForAudioFrameClassification"),QMt.forEach(t),Rlr=r(iBe," (UniSpeechSat model)"),iBe.forEach(t),Plr=i(gl),PT=n(gl,"LI",{});var dBe=s(PT);J2e=n(dBe,"STRONG",{});var WMt=s(J2e);Blr=r(WMt,"wav2vec2"),WMt.forEach(t),Ilr=r(dBe," \u2014 "),oW=n(dBe,"A",{href:!0});var HMt=s(oW);Nlr=r(HMt,"Wav2Vec2ForAudioFrameClassification"),HMt.forEach(t),qlr=r(dBe," (Wav2Vec2 model)"),dBe.forEach(t),jlr=i(gl),BT=n(gl,"LI",{});var cBe=s(BT);Y2e=n(cBe,"STRONG",{});var UMt=s(Y2e);Dlr=r(UMt,"wav2vec2-conformer"),UMt.forEach(t),Glr=r(cBe," \u2014 "),rW=n(cBe,"A",{href:!0});var JMt=s(rW);Olr=r(JMt,"Wav2Vec2ConformerForAudioFrameClassification"),JMt.forEach(t),Vlr=r(cBe," (Wav2Vec2-Conformer model)"),cBe.forEach(t),Xlr=i(gl),IT=n(gl,"LI",{});var fBe=s(IT);K2e=n(fBe,"STRONG",{});var YMt=s(K2e);zlr=r(YMt,"wavlm"),YMt.forEach(t),Qlr=r(fBe," \u2014 "),tW=n(fBe,"A",{href:!0});var KMt=s(tW);Wlr=r(KMt,"WavLMForAudioFrameClassification"),KMt.forEach(t),Hlr=r(fBe," (WavLM model)"),fBe.forEach(t),gl.forEach(t),Ulr=i(Fa),NT=n(Fa,"P",{});var mBe=s(NT);Jlr=r(mBe,"The model is set in evaluation mode by default using "),Z2e=n(mBe,"CODE",{});var ZMt=s(Z2e);Ylr=r(ZMt,"model.eval()"),ZMt.forEach(t),Klr=r(mBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),ebe=n(mBe,"CODE",{});var eEt=s(ebe);Zlr=r(eEt,"model.train()"),eEt.forEach(t),mBe.forEach(t),eir=i(Fa),T(qT.$$.fragment,Fa),Fa.forEach(t),ml.forEach(t),$Oe=i(f),xd=n(f,"H2",{class:!0});var IXe=s(xd);jT=n(IXe,"A",{id:!0,class:!0,href:!0});var oEt=s(jT);obe=n(oEt,"SPAN",{});var rEt=s(obe);T(LL.$$.fragment,rEt),rEt.forEach(t),oEt.forEach(t),oir=i(IXe),rbe=n(IXe,"SPAN",{});var tEt=s(rbe);rir=r(tEt,"AutoModelForCTC"),tEt.forEach(t),IXe.forEach(t),kOe=i(f),Qo=n(f,"DIV",{class:!0});var hl=s(Qo);T(yL.$$.fragment,hl),tir=i(hl),$d=n(hl,"P",{});var Yoe=s($d);air=r(Yoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a connectionist temporal classification head) when created
with the `),aW=n(Yoe,"A",{href:!0});var aEt=s(aW);nir=r(aEt,"from_pretrained()"),aEt.forEach(t),sir=r(Yoe," class method or the "),nW=n(Yoe,"A",{href:!0});var nEt=s(nW);lir=r(nEt,"from_config()"),nEt.forEach(t),iir=r(Yoe,` class
method.`),Yoe.forEach(t),dir=i(hl),xL=n(hl,"P",{});var NXe=s(xL);cir=r(NXe,"This class cannot be instantiated directly using "),tbe=n(NXe,"CODE",{});var sEt=s(tbe);fir=r(sEt,"__init__()"),sEt.forEach(t),mir=r(NXe," (throws an error)."),NXe.forEach(t),gir=i(hl),Mt=n(hl,"DIV",{class:!0});var d0=s(Mt);T($L.$$.fragment,d0),hir=i(d0),abe=n(d0,"P",{});var lEt=s(abe);pir=r(lEt,"Instantiates one of the model classes of the library (with a connectionist temporal classification head) from a configuration."),lEt.forEach(t),_ir=i(d0),kd=n(d0,"P",{});var Koe=s(kd);uir=r(Koe,`Note:
Loading a model from its configuration file does `),nbe=n(Koe,"STRONG",{});var iEt=s(nbe);bir=r(iEt,"not"),iEt.forEach(t),vir=r(Koe,` load the model weights. It only affects the
model\u2019s configuration. Use `),sW=n(Koe,"A",{href:!0});var dEt=s(sW);Fir=r(dEt,"from_pretrained()"),dEt.forEach(t),Tir=r(Koe," to load the model weights."),Koe.forEach(t),Mir=i(d0),T(DT.$$.fragment,d0),d0.forEach(t),Eir=i(hl),go=n(hl,"DIV",{class:!0});var Ta=s(go);T(kL.$$.fragment,Ta),Cir=i(Ta),sbe=n(Ta,"P",{});var cEt=s(sbe);wir=r(cEt,"Instantiate one of the model classes of the library (with a connectionist temporal classification head) from a pretrained model."),cEt.forEach(t),Air=i(Ta),Ua=n(Ta,"P",{});var c0=s(Ua);Lir=r(c0,"The model class to instantiate is selected based on the "),lbe=n(c0,"CODE",{});var fEt=s(lbe);yir=r(fEt,"model_type"),fEt.forEach(t),xir=r(c0,` property of the config object (either
passed as an argument or loaded from `),ibe=n(c0,"CODE",{});var mEt=s(ibe);$ir=r(mEt,"pretrained_model_name_or_path"),mEt.forEach(t),kir=r(c0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),dbe=n(c0,"CODE",{});var gEt=s(dbe);Sir=r(gEt,"pretrained_model_name_or_path"),gEt.forEach(t),Rir=r(c0,":"),c0.forEach(t),Pir=i(Ta),Le=n(Ta,"UL",{});var Be=s(Le);GT=n(Be,"LI",{});var gBe=s(GT);cbe=n(gBe,"STRONG",{});var hEt=s(cbe);Bir=r(hEt,"data2vec-audio"),hEt.forEach(t),Iir=r(gBe," \u2014 "),lW=n(gBe,"A",{href:!0});var pEt=s(lW);Nir=r(pEt,"Data2VecAudioForCTC"),pEt.forEach(t),qir=r(gBe," (Data2VecAudio model)"),gBe.forEach(t),jir=i(Be),OT=n(Be,"LI",{});var hBe=s(OT);fbe=n(hBe,"STRONG",{});var _Et=s(fbe);Dir=r(_Et,"hubert"),_Et.forEach(t),Gir=r(hBe," \u2014 "),iW=n(hBe,"A",{href:!0});var uEt=s(iW);Oir=r(uEt,"HubertForCTC"),uEt.forEach(t),Vir=r(hBe," (Hubert model)"),hBe.forEach(t),Xir=i(Be),VT=n(Be,"LI",{});var pBe=s(VT);mbe=n(pBe,"STRONG",{});var bEt=s(mbe);zir=r(bEt,"mctct"),bEt.forEach(t),Qir=r(pBe," \u2014 "),dW=n(pBe,"A",{href:!0});var vEt=s(dW);Wir=r(vEt,"MCTCTForCTC"),vEt.forEach(t),Hir=r(pBe," (M-CTC-T model)"),pBe.forEach(t),Uir=i(Be),XT=n(Be,"LI",{});var _Be=s(XT);gbe=n(_Be,"STRONG",{});var FEt=s(gbe);Jir=r(FEt,"sew"),FEt.forEach(t),Yir=r(_Be," \u2014 "),cW=n(_Be,"A",{href:!0});var TEt=s(cW);Kir=r(TEt,"SEWForCTC"),TEt.forEach(t),Zir=r(_Be," (SEW model)"),_Be.forEach(t),edr=i(Be),zT=n(Be,"LI",{});var uBe=s(zT);hbe=n(uBe,"STRONG",{});var MEt=s(hbe);odr=r(MEt,"sew-d"),MEt.forEach(t),rdr=r(uBe," \u2014 "),fW=n(uBe,"A",{href:!0});var EEt=s(fW);tdr=r(EEt,"SEWDForCTC"),EEt.forEach(t),adr=r(uBe," (SEW-D model)"),uBe.forEach(t),ndr=i(Be),QT=n(Be,"LI",{});var bBe=s(QT);pbe=n(bBe,"STRONG",{});var CEt=s(pbe);sdr=r(CEt,"unispeech"),CEt.forEach(t),ldr=r(bBe," \u2014 "),mW=n(bBe,"A",{href:!0});var wEt=s(mW);idr=r(wEt,"UniSpeechForCTC"),wEt.forEach(t),ddr=r(bBe," (UniSpeech model)"),bBe.forEach(t),cdr=i(Be),WT=n(Be,"LI",{});var vBe=s(WT);_be=n(vBe,"STRONG",{});var AEt=s(_be);fdr=r(AEt,"unispeech-sat"),AEt.forEach(t),mdr=r(vBe," \u2014 "),gW=n(vBe,"A",{href:!0});var LEt=s(gW);gdr=r(LEt,"UniSpeechSatForCTC"),LEt.forEach(t),hdr=r(vBe," (UniSpeechSat model)"),vBe.forEach(t),pdr=i(Be),HT=n(Be,"LI",{});var FBe=s(HT);ube=n(FBe,"STRONG",{});var yEt=s(ube);_dr=r(yEt,"wav2vec2"),yEt.forEach(t),udr=r(FBe," \u2014 "),hW=n(FBe,"A",{href:!0});var xEt=s(hW);bdr=r(xEt,"Wav2Vec2ForCTC"),xEt.forEach(t),vdr=r(FBe," (Wav2Vec2 model)"),FBe.forEach(t),Fdr=i(Be),UT=n(Be,"LI",{});var TBe=s(UT);bbe=n(TBe,"STRONG",{});var $Et=s(bbe);Tdr=r($Et,"wav2vec2-conformer"),$Et.forEach(t),Mdr=r(TBe," \u2014 "),pW=n(TBe,"A",{href:!0});var kEt=s(pW);Edr=r(kEt,"Wav2Vec2ConformerForCTC"),kEt.forEach(t),Cdr=r(TBe," (Wav2Vec2-Conformer model)"),TBe.forEach(t),wdr=i(Be),JT=n(Be,"LI",{});var MBe=s(JT);vbe=n(MBe,"STRONG",{});var SEt=s(vbe);Adr=r(SEt,"wavlm"),SEt.forEach(t),Ldr=r(MBe," \u2014 "),_W=n(MBe,"A",{href:!0});var REt=s(_W);ydr=r(REt,"WavLMForCTC"),REt.forEach(t),xdr=r(MBe," (WavLM model)"),MBe.forEach(t),Be.forEach(t),$dr=i(Ta),YT=n(Ta,"P",{});var EBe=s(YT);kdr=r(EBe,"The model is set in evaluation mode by default using "),Fbe=n(EBe,"CODE",{});var PEt=s(Fbe);Sdr=r(PEt,"model.eval()"),PEt.forEach(t),Rdr=r(EBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Tbe=n(EBe,"CODE",{});var BEt=s(Tbe);Pdr=r(BEt,"model.train()"),BEt.forEach(t),EBe.forEach(t),Bdr=i(Ta),T(KT.$$.fragment,Ta),Ta.forEach(t),hl.forEach(t),SOe=i(f),Sd=n(f,"H2",{class:!0});var qXe=s(Sd);ZT=n(qXe,"A",{id:!0,class:!0,href:!0});var IEt=s(ZT);Mbe=n(IEt,"SPAN",{});var NEt=s(Mbe);T(SL.$$.fragment,NEt),NEt.forEach(t),IEt.forEach(t),Idr=i(qXe),Ebe=n(qXe,"SPAN",{});var qEt=s(Ebe);Ndr=r(qEt,"AutoModelForSpeechSeq2Seq"),qEt.forEach(t),qXe.forEach(t),ROe=i(f),Wo=n(f,"DIV",{class:!0});var pl=s(Wo);T(RL.$$.fragment,pl),qdr=i(pl),Rd=n(pl,"P",{});var Zoe=s(Rd);jdr=r(Zoe,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),uW=n(Zoe,"A",{href:!0});var jEt=s(uW);Ddr=r(jEt,"from_pretrained()"),jEt.forEach(t),Gdr=r(Zoe," class method or the "),bW=n(Zoe,"A",{href:!0});var DEt=s(bW);Odr=r(DEt,"from_config()"),DEt.forEach(t),Vdr=r(Zoe,` class
method.`),Zoe.forEach(t),Xdr=i(pl),PL=n(pl,"P",{});var jXe=s(PL);zdr=r(jXe,"This class cannot be instantiated directly using "),Cbe=n(jXe,"CODE",{});var GEt=s(Cbe);Qdr=r(GEt,"__init__()"),GEt.forEach(t),Wdr=r(jXe," (throws an error)."),jXe.forEach(t),Hdr=i(pl),Et=n(pl,"DIV",{class:!0});var f0=s(Et);T(BL.$$.fragment,f0),Udr=i(f0),wbe=n(f0,"P",{});var OEt=s(wbe);Jdr=r(OEt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),OEt.forEach(t),Ydr=i(f0),Pd=n(f0,"P",{});var ere=s(Pd);Kdr=r(ere,`Note:
Loading a model from its configuration file does `),Abe=n(ere,"STRONG",{});var VEt=s(Abe);Zdr=r(VEt,"not"),VEt.forEach(t),ecr=r(ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),vW=n(ere,"A",{href:!0});var XEt=s(vW);ocr=r(XEt,"from_pretrained()"),XEt.forEach(t),rcr=r(ere," to load the model weights."),ere.forEach(t),tcr=i(f0),T(e7.$$.fragment,f0),f0.forEach(t),acr=i(pl),ho=n(pl,"DIV",{class:!0});var Ma=s(ho);T(IL.$$.fragment,Ma),ncr=i(Ma),Lbe=n(Ma,"P",{});var zEt=s(Lbe);scr=r(zEt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),zEt.forEach(t),lcr=i(Ma),Ja=n(Ma,"P",{});var m0=s(Ja);icr=r(m0,"The model class to instantiate is selected based on the "),ybe=n(m0,"CODE",{});var QEt=s(ybe);dcr=r(QEt,"model_type"),QEt.forEach(t),ccr=r(m0,` property of the config object (either
passed as an argument or loaded from `),xbe=n(m0,"CODE",{});var WEt=s(xbe);fcr=r(WEt,"pretrained_model_name_or_path"),WEt.forEach(t),mcr=r(m0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$be=n(m0,"CODE",{});var HEt=s($be);gcr=r(HEt,"pretrained_model_name_or_path"),HEt.forEach(t),hcr=r(m0,":"),m0.forEach(t),pcr=i(Ma),NL=n(Ma,"UL",{});var DXe=s(NL);o7=n(DXe,"LI",{});var CBe=s(o7);kbe=n(CBe,"STRONG",{});var UEt=s(kbe);_cr=r(UEt,"speech-encoder-decoder"),UEt.forEach(t),ucr=r(CBe," \u2014 "),FW=n(CBe,"A",{href:!0});var JEt=s(FW);bcr=r(JEt,"SpeechEncoderDecoderModel"),JEt.forEach(t),vcr=r(CBe," (Speech Encoder decoder model)"),CBe.forEach(t),Fcr=i(DXe),r7=n(DXe,"LI",{});var wBe=s(r7);Sbe=n(wBe,"STRONG",{});var YEt=s(Sbe);Tcr=r(YEt,"speech_to_text"),YEt.forEach(t),Mcr=r(wBe," \u2014 "),TW=n(wBe,"A",{href:!0});var KEt=s(TW);Ecr=r(KEt,"Speech2TextForConditionalGeneration"),KEt.forEach(t),Ccr=r(wBe," (Speech2Text model)"),wBe.forEach(t),DXe.forEach(t),wcr=i(Ma),t7=n(Ma,"P",{});var ABe=s(t7);Acr=r(ABe,"The model is set in evaluation mode by default using "),Rbe=n(ABe,"CODE",{});var ZEt=s(Rbe);Lcr=r(ZEt,"model.eval()"),ZEt.forEach(t),ycr=r(ABe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Pbe=n(ABe,"CODE",{});var e4t=s(Pbe);xcr=r(e4t,"model.train()"),e4t.forEach(t),ABe.forEach(t),$cr=i(Ma),T(a7.$$.fragment,Ma),Ma.forEach(t),pl.forEach(t),POe=i(f),Bd=n(f,"H2",{class:!0});var GXe=s(Bd);n7=n(GXe,"A",{id:!0,class:!0,href:!0});var o4t=s(n7);Bbe=n(o4t,"SPAN",{});var r4t=s(Bbe);T(qL.$$.fragment,r4t),r4t.forEach(t),o4t.forEach(t),kcr=i(GXe),Ibe=n(GXe,"SPAN",{});var t4t=s(Ibe);Scr=r(t4t,"AutoModelForAudioXVector"),t4t.forEach(t),GXe.forEach(t),BOe=i(f),Ho=n(f,"DIV",{class:!0});var _l=s(Ho);T(jL.$$.fragment,_l),Rcr=i(_l),Id=n(_l,"P",{});var ore=s(Id);Pcr=r(ore,`This is a generic model class that will be instantiated as one of the model classes of the library (with a audio retrieval via x-vector head) when created
with the `),MW=n(ore,"A",{href:!0});var a4t=s(MW);Bcr=r(a4t,"from_pretrained()"),a4t.forEach(t),Icr=r(ore," class method or the "),EW=n(ore,"A",{href:!0});var n4t=s(EW);Ncr=r(n4t,"from_config()"),n4t.forEach(t),qcr=r(ore,` class
method.`),ore.forEach(t),jcr=i(_l),DL=n(_l,"P",{});var OXe=s(DL);Dcr=r(OXe,"This class cannot be instantiated directly using "),Nbe=n(OXe,"CODE",{});var s4t=s(Nbe);Gcr=r(s4t,"__init__()"),s4t.forEach(t),Ocr=r(OXe," (throws an error)."),OXe.forEach(t),Vcr=i(_l),Ct=n(_l,"DIV",{class:!0});var g0=s(Ct);T(GL.$$.fragment,g0),Xcr=i(g0),qbe=n(g0,"P",{});var l4t=s(qbe);zcr=r(l4t,"Instantiates one of the model classes of the library (with a audio retrieval via x-vector head) from a configuration."),l4t.forEach(t),Qcr=i(g0),Nd=n(g0,"P",{});var rre=s(Nd);Wcr=r(rre,`Note:
Loading a model from its configuration file does `),jbe=n(rre,"STRONG",{});var i4t=s(jbe);Hcr=r(i4t,"not"),i4t.forEach(t),Ucr=r(rre,` load the model weights. It only affects the
model\u2019s configuration. Use `),CW=n(rre,"A",{href:!0});var d4t=s(CW);Jcr=r(d4t,"from_pretrained()"),d4t.forEach(t),Ycr=r(rre," to load the model weights."),rre.forEach(t),Kcr=i(g0),T(s7.$$.fragment,g0),g0.forEach(t),Zcr=i(_l),po=n(_l,"DIV",{class:!0});var Ea=s(po);T(OL.$$.fragment,Ea),efr=i(Ea),Dbe=n(Ea,"P",{});var c4t=s(Dbe);ofr=r(c4t,"Instantiate one of the model classes of the library (with a audio retrieval via x-vector head) from a pretrained model."),c4t.forEach(t),rfr=i(Ea),Ya=n(Ea,"P",{});var h0=s(Ya);tfr=r(h0,"The model class to instantiate is selected based on the "),Gbe=n(h0,"CODE",{});var f4t=s(Gbe);afr=r(f4t,"model_type"),f4t.forEach(t),nfr=r(h0,` property of the config object (either
passed as an argument or loaded from `),Obe=n(h0,"CODE",{});var m4t=s(Obe);sfr=r(m4t,"pretrained_model_name_or_path"),m4t.forEach(t),lfr=r(h0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Vbe=n(h0,"CODE",{});var g4t=s(Vbe);ifr=r(g4t,"pretrained_model_name_or_path"),g4t.forEach(t),dfr=r(h0,":"),h0.forEach(t),cfr=i(Ea),ot=n(Ea,"UL",{});var ul=s(ot);l7=n(ul,"LI",{});var LBe=s(l7);Xbe=n(LBe,"STRONG",{});var h4t=s(Xbe);ffr=r(h4t,"data2vec-audio"),h4t.forEach(t),mfr=r(LBe," \u2014 "),wW=n(LBe,"A",{href:!0});var p4t=s(wW);gfr=r(p4t,"Data2VecAudioForXVector"),p4t.forEach(t),hfr=r(LBe," (Data2VecAudio model)"),LBe.forEach(t),pfr=i(ul),i7=n(ul,"LI",{});var yBe=s(i7);zbe=n(yBe,"STRONG",{});var _4t=s(zbe);_fr=r(_4t,"unispeech-sat"),_4t.forEach(t),ufr=r(yBe," \u2014 "),AW=n(yBe,"A",{href:!0});var u4t=s(AW);bfr=r(u4t,"UniSpeechSatForXVector"),u4t.forEach(t),vfr=r(yBe," (UniSpeechSat model)"),yBe.forEach(t),Ffr=i(ul),d7=n(ul,"LI",{});var xBe=s(d7);Qbe=n(xBe,"STRONG",{});var b4t=s(Qbe);Tfr=r(b4t,"wav2vec2"),b4t.forEach(t),Mfr=r(xBe," \u2014 "),LW=n(xBe,"A",{href:!0});var v4t=s(LW);Efr=r(v4t,"Wav2Vec2ForXVector"),v4t.forEach(t),Cfr=r(xBe," (Wav2Vec2 model)"),xBe.forEach(t),wfr=i(ul),c7=n(ul,"LI",{});var $Be=s(c7);Wbe=n($Be,"STRONG",{});var F4t=s(Wbe);Afr=r(F4t,"wav2vec2-conformer"),F4t.forEach(t),Lfr=r($Be," \u2014 "),yW=n($Be,"A",{href:!0});var T4t=s(yW);yfr=r(T4t,"Wav2Vec2ConformerForXVector"),T4t.forEach(t),xfr=r($Be," (Wav2Vec2-Conformer model)"),$Be.forEach(t),$fr=i(ul),f7=n(ul,"LI",{});var kBe=s(f7);Hbe=n(kBe,"STRONG",{});var M4t=s(Hbe);kfr=r(M4t,"wavlm"),M4t.forEach(t),Sfr=r(kBe," \u2014 "),xW=n(kBe,"A",{href:!0});var E4t=s(xW);Rfr=r(E4t,"WavLMForXVector"),E4t.forEach(t),Pfr=r(kBe," (WavLM model)"),kBe.forEach(t),ul.forEach(t),Bfr=i(Ea),m7=n(Ea,"P",{});var SBe=s(m7);Ifr=r(SBe,"The model is set in evaluation mode by default using "),Ube=n(SBe,"CODE",{});var C4t=s(Ube);Nfr=r(C4t,"model.eval()"),C4t.forEach(t),qfr=r(SBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Jbe=n(SBe,"CODE",{});var w4t=s(Jbe);jfr=r(w4t,"model.train()"),w4t.forEach(t),SBe.forEach(t),Dfr=i(Ea),T(g7.$$.fragment,Ea),Ea.forEach(t),_l.forEach(t),IOe=i(f),qd=n(f,"H2",{class:!0});var VXe=s(qd);h7=n(VXe,"A",{id:!0,class:!0,href:!0});var A4t=s(h7);Ybe=n(A4t,"SPAN",{});var L4t=s(Ybe);T(VL.$$.fragment,L4t),L4t.forEach(t),A4t.forEach(t),Gfr=i(VXe),Kbe=n(VXe,"SPAN",{});var y4t=s(Kbe);Ofr=r(y4t,"AutoModelForMaskedImageModeling"),y4t.forEach(t),VXe.forEach(t),NOe=i(f),Uo=n(f,"DIV",{class:!0});var bl=s(Uo);T(XL.$$.fragment,bl),Vfr=i(bl),jd=n(bl,"P",{});var tre=s(jd);Xfr=r(tre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked image modeling head) when created
with the `),$W=n(tre,"A",{href:!0});var x4t=s($W);zfr=r(x4t,"from_pretrained()"),x4t.forEach(t),Qfr=r(tre," class method or the "),kW=n(tre,"A",{href:!0});var $4t=s(kW);Wfr=r($4t,"from_config()"),$4t.forEach(t),Hfr=r(tre,` class
method.`),tre.forEach(t),Ufr=i(bl),zL=n(bl,"P",{});var XXe=s(zL);Jfr=r(XXe,"This class cannot be instantiated directly using "),Zbe=n(XXe,"CODE",{});var k4t=s(Zbe);Yfr=r(k4t,"__init__()"),k4t.forEach(t),Kfr=r(XXe," (throws an error)."),XXe.forEach(t),Zfr=i(bl),wt=n(bl,"DIV",{class:!0});var p0=s(wt);T(QL.$$.fragment,p0),emr=i(p0),eve=n(p0,"P",{});var S4t=s(eve);omr=r(S4t,"Instantiates one of the model classes of the library (with a masked image modeling head) from a configuration."),S4t.forEach(t),rmr=i(p0),Dd=n(p0,"P",{});var are=s(Dd);tmr=r(are,`Note:
Loading a model from its configuration file does `),ove=n(are,"STRONG",{});var R4t=s(ove);amr=r(R4t,"not"),R4t.forEach(t),nmr=r(are,` load the model weights. It only affects the
model\u2019s configuration. Use `),SW=n(are,"A",{href:!0});var P4t=s(SW);smr=r(P4t,"from_pretrained()"),P4t.forEach(t),lmr=r(are," to load the model weights."),are.forEach(t),imr=i(p0),T(p7.$$.fragment,p0),p0.forEach(t),dmr=i(bl),_o=n(bl,"DIV",{class:!0});var Ca=s(_o);T(WL.$$.fragment,Ca),cmr=i(Ca),rve=n(Ca,"P",{});var B4t=s(rve);fmr=r(B4t,"Instantiate one of the model classes of the library (with a masked image modeling head) from a pretrained model."),B4t.forEach(t),mmr=i(Ca),Ka=n(Ca,"P",{});var _0=s(Ka);gmr=r(_0,"The model class to instantiate is selected based on the "),tve=n(_0,"CODE",{});var I4t=s(tve);hmr=r(I4t,"model_type"),I4t.forEach(t),pmr=r(_0,` property of the config object (either
passed as an argument or loaded from `),ave=n(_0,"CODE",{});var N4t=s(ave);_mr=r(N4t,"pretrained_model_name_or_path"),N4t.forEach(t),umr=r(_0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),nve=n(_0,"CODE",{});var q4t=s(nve);bmr=r(q4t,"pretrained_model_name_or_path"),q4t.forEach(t),vmr=r(_0,":"),_0.forEach(t),Fmr=i(Ca),Gd=n(Ca,"UL",{});var nre=s(Gd);_7=n(nre,"LI",{});var RBe=s(_7);sve=n(RBe,"STRONG",{});var j4t=s(sve);Tmr=r(j4t,"deit"),j4t.forEach(t),Mmr=r(RBe," \u2014 "),RW=n(RBe,"A",{href:!0});var D4t=s(RW);Emr=r(D4t,"DeiTForMaskedImageModeling"),D4t.forEach(t),Cmr=r(RBe," (DeiT model)"),RBe.forEach(t),wmr=i(nre),u7=n(nre,"LI",{});var PBe=s(u7);lve=n(PBe,"STRONG",{});var G4t=s(lve);Amr=r(G4t,"swin"),G4t.forEach(t),Lmr=r(PBe," \u2014 "),PW=n(PBe,"A",{href:!0});var O4t=s(PW);ymr=r(O4t,"SwinForMaskedImageModeling"),O4t.forEach(t),xmr=r(PBe," (Swin Transformer model)"),PBe.forEach(t),$mr=i(nre),b7=n(nre,"LI",{});var BBe=s(b7);ive=n(BBe,"STRONG",{});var V4t=s(ive);kmr=r(V4t,"vit"),V4t.forEach(t),Smr=r(BBe," \u2014 "),BW=n(BBe,"A",{href:!0});var X4t=s(BW);Rmr=r(X4t,"ViTForMaskedImageModeling"),X4t.forEach(t),Pmr=r(BBe," (ViT model)"),BBe.forEach(t),nre.forEach(t),Bmr=i(Ca),v7=n(Ca,"P",{});var IBe=s(v7);Imr=r(IBe,"The model is set in evaluation mode by default using "),dve=n(IBe,"CODE",{});var z4t=s(dve);Nmr=r(z4t,"model.eval()"),z4t.forEach(t),qmr=r(IBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cve=n(IBe,"CODE",{});var Q4t=s(cve);jmr=r(Q4t,"model.train()"),Q4t.forEach(t),IBe.forEach(t),Dmr=i(Ca),T(F7.$$.fragment,Ca),Ca.forEach(t),bl.forEach(t),qOe=i(f),Od=n(f,"H2",{class:!0});var zXe=s(Od);T7=n(zXe,"A",{id:!0,class:!0,href:!0});var W4t=s(T7);fve=n(W4t,"SPAN",{});var H4t=s(fve);T(HL.$$.fragment,H4t),H4t.forEach(t),W4t.forEach(t),Gmr=i(zXe),mve=n(zXe,"SPAN",{});var U4t=s(mve);Omr=r(U4t,"AutoModelForObjectDetection"),U4t.forEach(t),zXe.forEach(t),jOe=i(f),Jo=n(f,"DIV",{class:!0});var vl=s(Jo);T(UL.$$.fragment,vl),Vmr=i(vl),Vd=n(vl,"P",{});var sre=s(Vd);Xmr=r(sre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a object detection head) when created
with the `),IW=n(sre,"A",{href:!0});var J4t=s(IW);zmr=r(J4t,"from_pretrained()"),J4t.forEach(t),Qmr=r(sre," class method or the "),NW=n(sre,"A",{href:!0});var Y4t=s(NW);Wmr=r(Y4t,"from_config()"),Y4t.forEach(t),Hmr=r(sre,` class
method.`),sre.forEach(t),Umr=i(vl),JL=n(vl,"P",{});var QXe=s(JL);Jmr=r(QXe,"This class cannot be instantiated directly using "),gve=n(QXe,"CODE",{});var K4t=s(gve);Ymr=r(K4t,"__init__()"),K4t.forEach(t),Kmr=r(QXe," (throws an error)."),QXe.forEach(t),Zmr=i(vl),At=n(vl,"DIV",{class:!0});var u0=s(At);T(YL.$$.fragment,u0),egr=i(u0),hve=n(u0,"P",{});var Z4t=s(hve);ogr=r(Z4t,"Instantiates one of the model classes of the library (with a object detection head) from a configuration."),Z4t.forEach(t),rgr=i(u0),Xd=n(u0,"P",{});var lre=s(Xd);tgr=r(lre,`Note:
Loading a model from its configuration file does `),pve=n(lre,"STRONG",{});var eCt=s(pve);agr=r(eCt,"not"),eCt.forEach(t),ngr=r(lre,` load the model weights. It only affects the
model\u2019s configuration. Use `),qW=n(lre,"A",{href:!0});var oCt=s(qW);sgr=r(oCt,"from_pretrained()"),oCt.forEach(t),lgr=r(lre," to load the model weights."),lre.forEach(t),igr=i(u0),T(M7.$$.fragment,u0),u0.forEach(t),dgr=i(vl),uo=n(vl,"DIV",{class:!0});var wa=s(uo);T(KL.$$.fragment,wa),cgr=i(wa),_ve=n(wa,"P",{});var rCt=s(_ve);fgr=r(rCt,"Instantiate one of the model classes of the library (with a object detection head) from a pretrained model."),rCt.forEach(t),mgr=i(wa),Za=n(wa,"P",{});var b0=s(Za);ggr=r(b0,"The model class to instantiate is selected based on the "),uve=n(b0,"CODE",{});var tCt=s(uve);hgr=r(tCt,"model_type"),tCt.forEach(t),pgr=r(b0,` property of the config object (either
passed as an argument or loaded from `),bve=n(b0,"CODE",{});var aCt=s(bve);_gr=r(aCt,"pretrained_model_name_or_path"),aCt.forEach(t),ugr=r(b0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vve=n(b0,"CODE",{});var nCt=s(vve);bgr=r(nCt,"pretrained_model_name_or_path"),nCt.forEach(t),vgr=r(b0,":"),b0.forEach(t),Fgr=i(wa),ZL=n(wa,"UL",{});var WXe=s(ZL);E7=n(WXe,"LI",{});var NBe=s(E7);Fve=n(NBe,"STRONG",{});var sCt=s(Fve);Tgr=r(sCt,"detr"),sCt.forEach(t),Mgr=r(NBe," \u2014 "),jW=n(NBe,"A",{href:!0});var lCt=s(jW);Egr=r(lCt,"DetrForObjectDetection"),lCt.forEach(t),Cgr=r(NBe," (DETR model)"),NBe.forEach(t),wgr=i(WXe),C7=n(WXe,"LI",{});var qBe=s(C7);Tve=n(qBe,"STRONG",{});var iCt=s(Tve);Agr=r(iCt,"yolos"),iCt.forEach(t),Lgr=r(qBe," \u2014 "),DW=n(qBe,"A",{href:!0});var dCt=s(DW);ygr=r(dCt,"YolosForObjectDetection"),dCt.forEach(t),xgr=r(qBe," (YOLOS model)"),qBe.forEach(t),WXe.forEach(t),$gr=i(wa),w7=n(wa,"P",{});var jBe=s(w7);kgr=r(jBe,"The model is set in evaluation mode by default using "),Mve=n(jBe,"CODE",{});var cCt=s(Mve);Sgr=r(cCt,"model.eval()"),cCt.forEach(t),Rgr=r(jBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Eve=n(jBe,"CODE",{});var fCt=s(Eve);Pgr=r(fCt,"model.train()"),fCt.forEach(t),jBe.forEach(t),Bgr=i(wa),T(A7.$$.fragment,wa),wa.forEach(t),vl.forEach(t),DOe=i(f),zd=n(f,"H2",{class:!0});var HXe=s(zd);L7=n(HXe,"A",{id:!0,class:!0,href:!0});var mCt=s(L7);Cve=n(mCt,"SPAN",{});var gCt=s(Cve);T(ey.$$.fragment,gCt),gCt.forEach(t),mCt.forEach(t),Igr=i(HXe),wve=n(HXe,"SPAN",{});var hCt=s(wve);Ngr=r(hCt,"AutoModelForImageSegmentation"),hCt.forEach(t),HXe.forEach(t),GOe=i(f),Yo=n(f,"DIV",{class:!0});var Fl=s(Yo);T(oy.$$.fragment,Fl),qgr=i(Fl),Qd=n(Fl,"P",{});var ire=s(Qd);jgr=r(ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image segmentation head) when created
with the `),GW=n(ire,"A",{href:!0});var pCt=s(GW);Dgr=r(pCt,"from_pretrained()"),pCt.forEach(t),Ggr=r(ire," class method or the "),OW=n(ire,"A",{href:!0});var _Ct=s(OW);Ogr=r(_Ct,"from_config()"),_Ct.forEach(t),Vgr=r(ire,` class
method.`),ire.forEach(t),Xgr=i(Fl),ry=n(Fl,"P",{});var UXe=s(ry);zgr=r(UXe,"This class cannot be instantiated directly using "),Ave=n(UXe,"CODE",{});var uCt=s(Ave);Qgr=r(uCt,"__init__()"),uCt.forEach(t),Wgr=r(UXe," (throws an error)."),UXe.forEach(t),Hgr=i(Fl),Lt=n(Fl,"DIV",{class:!0});var v0=s(Lt);T(ty.$$.fragment,v0),Ugr=i(v0),Lve=n(v0,"P",{});var bCt=s(Lve);Jgr=r(bCt,"Instantiates one of the model classes of the library (with a image segmentation head) from a configuration."),bCt.forEach(t),Ygr=i(v0),Wd=n(v0,"P",{});var dre=s(Wd);Kgr=r(dre,`Note:
Loading a model from its configuration file does `),yve=n(dre,"STRONG",{});var vCt=s(yve);Zgr=r(vCt,"not"),vCt.forEach(t),ehr=r(dre,` load the model weights. It only affects the
model\u2019s configuration. Use `),VW=n(dre,"A",{href:!0});var FCt=s(VW);ohr=r(FCt,"from_pretrained()"),FCt.forEach(t),rhr=r(dre," to load the model weights."),dre.forEach(t),thr=i(v0),T(y7.$$.fragment,v0),v0.forEach(t),ahr=i(Fl),bo=n(Fl,"DIV",{class:!0});var Aa=s(bo);T(ay.$$.fragment,Aa),nhr=i(Aa),xve=n(Aa,"P",{});var TCt=s(xve);shr=r(TCt,"Instantiate one of the model classes of the library (with a image segmentation head) from a pretrained model."),TCt.forEach(t),lhr=i(Aa),en=n(Aa,"P",{});var F0=s(en);ihr=r(F0,"The model class to instantiate is selected based on the "),$ve=n(F0,"CODE",{});var MCt=s($ve);dhr=r(MCt,"model_type"),MCt.forEach(t),chr=r(F0,` property of the config object (either
passed as an argument or loaded from `),kve=n(F0,"CODE",{});var ECt=s(kve);fhr=r(ECt,"pretrained_model_name_or_path"),ECt.forEach(t),mhr=r(F0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Sve=n(F0,"CODE",{});var CCt=s(Sve);ghr=r(CCt,"pretrained_model_name_or_path"),CCt.forEach(t),hhr=r(F0,":"),F0.forEach(t),phr=i(Aa),Rve=n(Aa,"UL",{});var wCt=s(Rve);x7=n(wCt,"LI",{});var DBe=s(x7);Pve=n(DBe,"STRONG",{});var ACt=s(Pve);_hr=r(ACt,"detr"),ACt.forEach(t),uhr=r(DBe," \u2014 "),XW=n(DBe,"A",{href:!0});var LCt=s(XW);bhr=r(LCt,"DetrForSegmentation"),LCt.forEach(t),vhr=r(DBe," (DETR model)"),DBe.forEach(t),wCt.forEach(t),Fhr=i(Aa),$7=n(Aa,"P",{});var GBe=s($7);Thr=r(GBe,"The model is set in evaluation mode by default using "),Bve=n(GBe,"CODE",{});var yCt=s(Bve);Mhr=r(yCt,"model.eval()"),yCt.forEach(t),Ehr=r(GBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Ive=n(GBe,"CODE",{});var xCt=s(Ive);Chr=r(xCt,"model.train()"),xCt.forEach(t),GBe.forEach(t),whr=i(Aa),T(k7.$$.fragment,Aa),Aa.forEach(t),Fl.forEach(t),OOe=i(f),Hd=n(f,"H2",{class:!0});var JXe=s(Hd);S7=n(JXe,"A",{id:!0,class:!0,href:!0});var $Ct=s(S7);Nve=n($Ct,"SPAN",{});var kCt=s(Nve);T(ny.$$.fragment,kCt),kCt.forEach(t),$Ct.forEach(t),Ahr=i(JXe),qve=n(JXe,"SPAN",{});var SCt=s(qve);Lhr=r(SCt,"AutoModelForSemanticSegmentation"),SCt.forEach(t),JXe.forEach(t),VOe=i(f),Ko=n(f,"DIV",{class:!0});var Tl=s(Ko);T(sy.$$.fragment,Tl),yhr=i(Tl),Ud=n(Tl,"P",{});var cre=s(Ud);xhr=r(cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a semantic segmentation head) when created
with the `),zW=n(cre,"A",{href:!0});var RCt=s(zW);$hr=r(RCt,"from_pretrained()"),RCt.forEach(t),khr=r(cre," class method or the "),QW=n(cre,"A",{href:!0});var PCt=s(QW);Shr=r(PCt,"from_config()"),PCt.forEach(t),Rhr=r(cre,` class
method.`),cre.forEach(t),Phr=i(Tl),ly=n(Tl,"P",{});var YXe=s(ly);Bhr=r(YXe,"This class cannot be instantiated directly using "),jve=n(YXe,"CODE",{});var BCt=s(jve);Ihr=r(BCt,"__init__()"),BCt.forEach(t),Nhr=r(YXe," (throws an error)."),YXe.forEach(t),qhr=i(Tl),yt=n(Tl,"DIV",{class:!0});var T0=s(yt);T(iy.$$.fragment,T0),jhr=i(T0),Dve=n(T0,"P",{});var ICt=s(Dve);Dhr=r(ICt,"Instantiates one of the model classes of the library (with a semantic segmentation head) from a configuration."),ICt.forEach(t),Ghr=i(T0),Jd=n(T0,"P",{});var fre=s(Jd);Ohr=r(fre,`Note:
Loading a model from its configuration file does `),Gve=n(fre,"STRONG",{});var NCt=s(Gve);Vhr=r(NCt,"not"),NCt.forEach(t),Xhr=r(fre,` load the model weights. It only affects the
model\u2019s configuration. Use `),WW=n(fre,"A",{href:!0});var qCt=s(WW);zhr=r(qCt,"from_pretrained()"),qCt.forEach(t),Qhr=r(fre," to load the model weights."),fre.forEach(t),Whr=i(T0),T(R7.$$.fragment,T0),T0.forEach(t),Hhr=i(Tl),vo=n(Tl,"DIV",{class:!0});var La=s(vo);T(dy.$$.fragment,La),Uhr=i(La),Ove=n(La,"P",{});var jCt=s(Ove);Jhr=r(jCt,"Instantiate one of the model classes of the library (with a semantic segmentation head) from a pretrained model."),jCt.forEach(t),Yhr=i(La),on=n(La,"P",{});var M0=s(on);Khr=r(M0,"The model class to instantiate is selected based on the "),Vve=n(M0,"CODE",{});var DCt=s(Vve);Zhr=r(DCt,"model_type"),DCt.forEach(t),epr=r(M0,` property of the config object (either
passed as an argument or loaded from `),Xve=n(M0,"CODE",{});var GCt=s(Xve);opr=r(GCt,"pretrained_model_name_or_path"),GCt.forEach(t),rpr=r(M0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),zve=n(M0,"CODE",{});var OCt=s(zve);tpr=r(OCt,"pretrained_model_name_or_path"),OCt.forEach(t),apr=r(M0,":"),M0.forEach(t),npr=i(La),rn=n(La,"UL",{});var E0=s(rn);P7=n(E0,"LI",{});var OBe=s(P7);Qve=n(OBe,"STRONG",{});var VCt=s(Qve);spr=r(VCt,"beit"),VCt.forEach(t),lpr=r(OBe," \u2014 "),HW=n(OBe,"A",{href:!0});var XCt=s(HW);ipr=r(XCt,"BeitForSemanticSegmentation"),XCt.forEach(t),dpr=r(OBe," (BEiT model)"),OBe.forEach(t),cpr=i(E0),B7=n(E0,"LI",{});var VBe=s(B7);Wve=n(VBe,"STRONG",{});var zCt=s(Wve);fpr=r(zCt,"data2vec-vision"),zCt.forEach(t),mpr=r(VBe," \u2014 "),UW=n(VBe,"A",{href:!0});var QCt=s(UW);gpr=r(QCt,"Data2VecVisionForSemanticSegmentation"),QCt.forEach(t),hpr=r(VBe," (Data2VecVision model)"),VBe.forEach(t),ppr=i(E0),I7=n(E0,"LI",{});var XBe=s(I7);Hve=n(XBe,"STRONG",{});var WCt=s(Hve);_pr=r(WCt,"dpt"),WCt.forEach(t),upr=r(XBe," \u2014 "),JW=n(XBe,"A",{href:!0});var HCt=s(JW);bpr=r(HCt,"DPTForSemanticSegmentation"),HCt.forEach(t),vpr=r(XBe," (DPT model)"),XBe.forEach(t),Fpr=i(E0),N7=n(E0,"LI",{});var zBe=s(N7);Uve=n(zBe,"STRONG",{});var UCt=s(Uve);Tpr=r(UCt,"segformer"),UCt.forEach(t),Mpr=r(zBe," \u2014 "),YW=n(zBe,"A",{href:!0});var JCt=s(YW);Epr=r(JCt,"SegformerForSemanticSegmentation"),JCt.forEach(t),Cpr=r(zBe," (SegFormer model)"),zBe.forEach(t),E0.forEach(t),wpr=i(La),q7=n(La,"P",{});var QBe=s(q7);Apr=r(QBe,"The model is set in evaluation mode by default using "),Jve=n(QBe,"CODE",{});var YCt=s(Jve);Lpr=r(YCt,"model.eval()"),YCt.forEach(t),ypr=r(QBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),Yve=n(QBe,"CODE",{});var KCt=s(Yve);xpr=r(KCt,"model.train()"),KCt.forEach(t),QBe.forEach(t),$pr=i(La),T(j7.$$.fragment,La),La.forEach(t),Tl.forEach(t),XOe=i(f),Yd=n(f,"H2",{class:!0});var KXe=s(Yd);D7=n(KXe,"A",{id:!0,class:!0,href:!0});var ZCt=s(D7);Kve=n(ZCt,"SPAN",{});var e5t=s(Kve);T(cy.$$.fragment,e5t),e5t.forEach(t),ZCt.forEach(t),kpr=i(KXe),Zve=n(KXe,"SPAN",{});var o5t=s(Zve);Spr=r(o5t,"AutoModelForInstanceSegmentation"),o5t.forEach(t),KXe.forEach(t),zOe=i(f),Zo=n(f,"DIV",{class:!0});var Ml=s(Zo);T(fy.$$.fragment,Ml),Rpr=i(Ml),Kd=n(Ml,"P",{});var mre=s(Kd);Ppr=r(mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a instance segmentation head) when created
with the `),KW=n(mre,"A",{href:!0});var r5t=s(KW);Bpr=r(r5t,"from_pretrained()"),r5t.forEach(t),Ipr=r(mre," class method or the "),ZW=n(mre,"A",{href:!0});var t5t=s(ZW);Npr=r(t5t,"from_config()"),t5t.forEach(t),qpr=r(mre,` class
method.`),mre.forEach(t),jpr=i(Ml),my=n(Ml,"P",{});var ZXe=s(my);Dpr=r(ZXe,"This class cannot be instantiated directly using "),eFe=n(ZXe,"CODE",{});var a5t=s(eFe);Gpr=r(a5t,"__init__()"),a5t.forEach(t),Opr=r(ZXe," (throws an error)."),ZXe.forEach(t),Vpr=i(Ml),xt=n(Ml,"DIV",{class:!0});var C0=s(xt);T(gy.$$.fragment,C0),Xpr=i(C0),oFe=n(C0,"P",{});var n5t=s(oFe);zpr=r(n5t,"Instantiates one of the model classes of the library (with a instance segmentation head) from a configuration."),n5t.forEach(t),Qpr=i(C0),Zd=n(C0,"P",{});var gre=s(Zd);Wpr=r(gre,`Note:
Loading a model from its configuration file does `),rFe=n(gre,"STRONG",{});var s5t=s(rFe);Hpr=r(s5t,"not"),s5t.forEach(t),Upr=r(gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),eH=n(gre,"A",{href:!0});var l5t=s(eH);Jpr=r(l5t,"from_pretrained()"),l5t.forEach(t),Ypr=r(gre," to load the model weights."),gre.forEach(t),Kpr=i(C0),T(G7.$$.fragment,C0),C0.forEach(t),Zpr=i(Ml),Fo=n(Ml,"DIV",{class:!0});var ya=s(Fo);T(hy.$$.fragment,ya),e_r=i(ya),tFe=n(ya,"P",{});var i5t=s(tFe);o_r=r(i5t,"Instantiate one of the model classes of the library (with a instance segmentation head) from a pretrained model."),i5t.forEach(t),r_r=i(ya),tn=n(ya,"P",{});var w0=s(tn);t_r=r(w0,"The model class to instantiate is selected based on the "),aFe=n(w0,"CODE",{});var d5t=s(aFe);a_r=r(d5t,"model_type"),d5t.forEach(t),n_r=r(w0,` property of the config object (either
passed as an argument or loaded from `),nFe=n(w0,"CODE",{});var c5t=s(nFe);s_r=r(c5t,"pretrained_model_name_or_path"),c5t.forEach(t),l_r=r(w0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),sFe=n(w0,"CODE",{});var f5t=s(sFe);i_r=r(f5t,"pretrained_model_name_or_path"),f5t.forEach(t),d_r=r(w0,":"),w0.forEach(t),c_r=i(ya),lFe=n(ya,"UL",{});var m5t=s(lFe);O7=n(m5t,"LI",{});var WBe=s(O7);iFe=n(WBe,"STRONG",{});var g5t=s(iFe);f_r=r(g5t,"maskformer"),g5t.forEach(t),m_r=r(WBe," \u2014 "),oH=n(WBe,"A",{href:!0});var h5t=s(oH);g_r=r(h5t,"MaskFormerForInstanceSegmentation"),h5t.forEach(t),h_r=r(WBe," (MaskFormer model)"),WBe.forEach(t),m5t.forEach(t),p_r=i(ya),V7=n(ya,"P",{});var HBe=s(V7);__r=r(HBe,"The model is set in evaluation mode by default using "),dFe=n(HBe,"CODE",{});var p5t=s(dFe);u_r=r(p5t,"model.eval()"),p5t.forEach(t),b_r=r(HBe,` (so for instance, dropout modules are
deactivated). To train the model, you should first set it back in training mode with `),cFe=n(HBe,"CODE",{});var _5t=s(cFe);v_r=r(_5t,"model.train()"),_5t.forEach(t),HBe.forEach(t),F_r=i(ya),T(X7.$$.fragment,ya),ya.forEach(t),Ml.forEach(t),QOe=i(f),ec=n(f,"H2",{class:!0});var eze=s(ec);z7=n(eze,"A",{id:!0,class:!0,href:!0});var u5t=s(z7);fFe=n(u5t,"SPAN",{});var b5t=s(fFe);T(py.$$.fragment,b5t),b5t.forEach(t),u5t.forEach(t),T_r=i(eze),mFe=n(eze,"SPAN",{});var v5t=s(mFe);M_r=r(v5t,"TFAutoModel"),v5t.forEach(t),eze.forEach(t),WOe=i(f),er=n(f,"DIV",{class:!0});var El=s(er);T(_y.$$.fragment,El),E_r=i(El),oc=n(El,"P",{});var hre=s(oc);C_r=r(hre,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),rH=n(hre,"A",{href:!0});var F5t=s(rH);w_r=r(F5t,"from_pretrained()"),F5t.forEach(t),A_r=r(hre," class method or the "),tH=n(hre,"A",{href:!0});var T5t=s(tH);L_r=r(T5t,"from_config()"),T5t.forEach(t),y_r=r(hre,` class
method.`),hre.forEach(t),x_r=i(El),uy=n(El,"P",{});var oze=s(uy);$_r=r(oze,"This class cannot be instantiated directly using "),gFe=n(oze,"CODE",{});var M5t=s(gFe);k_r=r(M5t,"__init__()"),M5t.forEach(t),S_r=r(oze," (throws an error)."),oze.forEach(t),R_r=i(El),$t=n(El,"DIV",{class:!0});var A0=s($t);T(by.$$.fragment,A0),P_r=i(A0),hFe=n(A0,"P",{});var E5t=s(hFe);B_r=r(E5t,"Instantiates one of the base model classes of the library from a configuration."),E5t.forEach(t),I_r=i(A0),rc=n(A0,"P",{});var pre=s(rc);N_r=r(pre,`Note:
Loading a model from its configuration file does `),pFe=n(pre,"STRONG",{});var C5t=s(pFe);q_r=r(C5t,"not"),C5t.forEach(t),j_r=r(pre,` load the model weights. It only affects the
model\u2019s configuration. Use `),aH=n(pre,"A",{href:!0});var w5t=s(aH);D_r=r(w5t,"from_pretrained()"),w5t.forEach(t),G_r=r(pre," to load the model weights."),pre.forEach(t),O_r=i(A0),T(Q7.$$.fragment,A0),A0.forEach(t),V_r=i(El),yr=n(El,"DIV",{class:!0});var Cl=s(yr);T(vy.$$.fragment,Cl),X_r=i(Cl),_Fe=n(Cl,"P",{});var A5t=s(_Fe);z_r=r(A5t,"Instantiate one of the base model classes of the library from a pretrained model."),A5t.forEach(t),Q_r=i(Cl),an=n(Cl,"P",{});var L0=s(an);W_r=r(L0,"The model class to instantiate is selected based on the "),uFe=n(L0,"CODE",{});var L5t=s(uFe);H_r=r(L5t,"model_type"),L5t.forEach(t),U_r=r(L0,` property of the config object (either
passed as an argument or loaded from `),bFe=n(L0,"CODE",{});var y5t=s(bFe);J_r=r(y5t,"pretrained_model_name_or_path"),y5t.forEach(t),Y_r=r(L0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),vFe=n(L0,"CODE",{});var x5t=s(vFe);K_r=r(x5t,"pretrained_model_name_or_path"),x5t.forEach(t),Z_r=r(L0,":"),L0.forEach(t),eur=i(Cl),j=n(Cl,"UL",{});var D=s(j);W7=n(D,"LI",{});var UBe=s(W7);FFe=n(UBe,"STRONG",{});var $5t=s(FFe);our=r($5t,"albert"),$5t.forEach(t),rur=r(UBe," \u2014 "),nH=n(UBe,"A",{href:!0});var k5t=s(nH);tur=r(k5t,"TFAlbertModel"),k5t.forEach(t),aur=r(UBe," (ALBERT model)"),UBe.forEach(t),nur=i(D),H7=n(D,"LI",{});var JBe=s(H7);TFe=n(JBe,"STRONG",{});var S5t=s(TFe);sur=r(S5t,"bart"),S5t.forEach(t),lur=r(JBe," \u2014 "),sH=n(JBe,"A",{href:!0});var R5t=s(sH);iur=r(R5t,"TFBartModel"),R5t.forEach(t),dur=r(JBe," (BART model)"),JBe.forEach(t),cur=i(D),U7=n(D,"LI",{});var YBe=s(U7);MFe=n(YBe,"STRONG",{});var P5t=s(MFe);fur=r(P5t,"bert"),P5t.forEach(t),mur=r(YBe," \u2014 "),lH=n(YBe,"A",{href:!0});var B5t=s(lH);gur=r(B5t,"TFBertModel"),B5t.forEach(t),hur=r(YBe," (BERT model)"),YBe.forEach(t),pur=i(D),J7=n(D,"LI",{});var KBe=s(J7);EFe=n(KBe,"STRONG",{});var I5t=s(EFe);_ur=r(I5t,"blenderbot"),I5t.forEach(t),uur=r(KBe," \u2014 "),iH=n(KBe,"A",{href:!0});var N5t=s(iH);bur=r(N5t,"TFBlenderbotModel"),N5t.forEach(t),vur=r(KBe," (Blenderbot model)"),KBe.forEach(t),Fur=i(D),Y7=n(D,"LI",{});var ZBe=s(Y7);CFe=n(ZBe,"STRONG",{});var q5t=s(CFe);Tur=r(q5t,"blenderbot-small"),q5t.forEach(t),Mur=r(ZBe," \u2014 "),dH=n(ZBe,"A",{href:!0});var j5t=s(dH);Eur=r(j5t,"TFBlenderbotSmallModel"),j5t.forEach(t),Cur=r(ZBe," (BlenderbotSmall model)"),ZBe.forEach(t),wur=i(D),K7=n(D,"LI",{});var eIe=s(K7);wFe=n(eIe,"STRONG",{});var D5t=s(wFe);Aur=r(D5t,"camembert"),D5t.forEach(t),Lur=r(eIe," \u2014 "),cH=n(eIe,"A",{href:!0});var G5t=s(cH);yur=r(G5t,"TFCamembertModel"),G5t.forEach(t),xur=r(eIe," (CamemBERT model)"),eIe.forEach(t),$ur=i(D),Z7=n(D,"LI",{});var oIe=s(Z7);AFe=n(oIe,"STRONG",{});var O5t=s(AFe);kur=r(O5t,"clip"),O5t.forEach(t),Sur=r(oIe," \u2014 "),fH=n(oIe,"A",{href:!0});var V5t=s(fH);Rur=r(V5t,"TFCLIPModel"),V5t.forEach(t),Pur=r(oIe," (CLIP model)"),oIe.forEach(t),Bur=i(D),e8=n(D,"LI",{});var rIe=s(e8);LFe=n(rIe,"STRONG",{});var X5t=s(LFe);Iur=r(X5t,"convbert"),X5t.forEach(t),Nur=r(rIe," \u2014 "),mH=n(rIe,"A",{href:!0});var z5t=s(mH);qur=r(z5t,"TFConvBertModel"),z5t.forEach(t),jur=r(rIe," (ConvBERT model)"),rIe.forEach(t),Dur=i(D),o8=n(D,"LI",{});var tIe=s(o8);yFe=n(tIe,"STRONG",{});var Q5t=s(yFe);Gur=r(Q5t,"convnext"),Q5t.forEach(t),Our=r(tIe," \u2014 "),gH=n(tIe,"A",{href:!0});var W5t=s(gH);Vur=r(W5t,"TFConvNextModel"),W5t.forEach(t),Xur=r(tIe," (ConvNeXT model)"),tIe.forEach(t),zur=i(D),r8=n(D,"LI",{});var aIe=s(r8);xFe=n(aIe,"STRONG",{});var H5t=s(xFe);Qur=r(H5t,"ctrl"),H5t.forEach(t),Wur=r(aIe," \u2014 "),hH=n(aIe,"A",{href:!0});var U5t=s(hH);Hur=r(U5t,"TFCTRLModel"),U5t.forEach(t),Uur=r(aIe," (CTRL model)"),aIe.forEach(t),Jur=i(D),t8=n(D,"LI",{});var nIe=s(t8);$Fe=n(nIe,"STRONG",{});var J5t=s($Fe);Yur=r(J5t,"data2vec-vision"),J5t.forEach(t),Kur=r(nIe," \u2014 "),pH=n(nIe,"A",{href:!0});var Y5t=s(pH);Zur=r(Y5t,"TFData2VecVisionModel"),Y5t.forEach(t),e1r=r(nIe," (Data2VecVision model)"),nIe.forEach(t),o1r=i(D),a8=n(D,"LI",{});var sIe=s(a8);kFe=n(sIe,"STRONG",{});var K5t=s(kFe);r1r=r(K5t,"deberta"),K5t.forEach(t),t1r=r(sIe," \u2014 "),_H=n(sIe,"A",{href:!0});var Z5t=s(_H);a1r=r(Z5t,"TFDebertaModel"),Z5t.forEach(t),n1r=r(sIe," (DeBERTa model)"),sIe.forEach(t),s1r=i(D),n8=n(D,"LI",{});var lIe=s(n8);SFe=n(lIe,"STRONG",{});var e3t=s(SFe);l1r=r(e3t,"deberta-v2"),e3t.forEach(t),i1r=r(lIe," \u2014 "),uH=n(lIe,"A",{href:!0});var o3t=s(uH);d1r=r(o3t,"TFDebertaV2Model"),o3t.forEach(t),c1r=r(lIe," (DeBERTa-v2 model)"),lIe.forEach(t),f1r=i(D),s8=n(D,"LI",{});var iIe=s(s8);RFe=n(iIe,"STRONG",{});var r3t=s(RFe);m1r=r(r3t,"distilbert"),r3t.forEach(t),g1r=r(iIe," \u2014 "),bH=n(iIe,"A",{href:!0});var t3t=s(bH);h1r=r(t3t,"TFDistilBertModel"),t3t.forEach(t),p1r=r(iIe," (DistilBERT model)"),iIe.forEach(t),_1r=i(D),l8=n(D,"LI",{});var dIe=s(l8);PFe=n(dIe,"STRONG",{});var a3t=s(PFe);u1r=r(a3t,"dpr"),a3t.forEach(t),b1r=r(dIe," \u2014 "),vH=n(dIe,"A",{href:!0});var n3t=s(vH);v1r=r(n3t,"TFDPRQuestionEncoder"),n3t.forEach(t),F1r=r(dIe," (DPR model)"),dIe.forEach(t),T1r=i(D),i8=n(D,"LI",{});var cIe=s(i8);BFe=n(cIe,"STRONG",{});var s3t=s(BFe);M1r=r(s3t,"electra"),s3t.forEach(t),E1r=r(cIe," \u2014 "),FH=n(cIe,"A",{href:!0});var l3t=s(FH);C1r=r(l3t,"TFElectraModel"),l3t.forEach(t),w1r=r(cIe," (ELECTRA model)"),cIe.forEach(t),A1r=i(D),d8=n(D,"LI",{});var fIe=s(d8);IFe=n(fIe,"STRONG",{});var i3t=s(IFe);L1r=r(i3t,"flaubert"),i3t.forEach(t),y1r=r(fIe," \u2014 "),TH=n(fIe,"A",{href:!0});var d3t=s(TH);x1r=r(d3t,"TFFlaubertModel"),d3t.forEach(t),$1r=r(fIe," (FlauBERT model)"),fIe.forEach(t),k1r=i(D),Qs=n(D,"LI",{});var oS=s(Qs);NFe=n(oS,"STRONG",{});var c3t=s(NFe);S1r=r(c3t,"funnel"),c3t.forEach(t),R1r=r(oS," \u2014 "),MH=n(oS,"A",{href:!0});var f3t=s(MH);P1r=r(f3t,"TFFunnelModel"),f3t.forEach(t),B1r=r(oS," or "),EH=n(oS,"A",{href:!0});var m3t=s(EH);I1r=r(m3t,"TFFunnelBaseModel"),m3t.forEach(t),N1r=r(oS," (Funnel Transformer model)"),oS.forEach(t),q1r=i(D),c8=n(D,"LI",{});var mIe=s(c8);qFe=n(mIe,"STRONG",{});var g3t=s(qFe);j1r=r(g3t,"gpt2"),g3t.forEach(t),D1r=r(mIe," \u2014 "),CH=n(mIe,"A",{href:!0});var h3t=s(CH);G1r=r(h3t,"TFGPT2Model"),h3t.forEach(t),O1r=r(mIe," (OpenAI GPT-2 model)"),mIe.forEach(t),V1r=i(D),f8=n(D,"LI",{});var gIe=s(f8);jFe=n(gIe,"STRONG",{});var p3t=s(jFe);X1r=r(p3t,"gptj"),p3t.forEach(t),z1r=r(gIe," \u2014 "),wH=n(gIe,"A",{href:!0});var _3t=s(wH);Q1r=r(_3t,"TFGPTJModel"),_3t.forEach(t),W1r=r(gIe," (GPT-J model)"),gIe.forEach(t),H1r=i(D),m8=n(D,"LI",{});var hIe=s(m8);DFe=n(hIe,"STRONG",{});var u3t=s(DFe);U1r=r(u3t,"hubert"),u3t.forEach(t),J1r=r(hIe," \u2014 "),AH=n(hIe,"A",{href:!0});var b3t=s(AH);Y1r=r(b3t,"TFHubertModel"),b3t.forEach(t),K1r=r(hIe," (Hubert model)"),hIe.forEach(t),Z1r=i(D),g8=n(D,"LI",{});var pIe=s(g8);GFe=n(pIe,"STRONG",{});var v3t=s(GFe);e2r=r(v3t,"layoutlm"),v3t.forEach(t),o2r=r(pIe," \u2014 "),LH=n(pIe,"A",{href:!0});var F3t=s(LH);r2r=r(F3t,"TFLayoutLMModel"),F3t.forEach(t),t2r=r(pIe," (LayoutLM model)"),pIe.forEach(t),a2r=i(D),h8=n(D,"LI",{});var _Ie=s(h8);OFe=n(_Ie,"STRONG",{});var T3t=s(OFe);n2r=r(T3t,"led"),T3t.forEach(t),s2r=r(_Ie," \u2014 "),yH=n(_Ie,"A",{href:!0});var M3t=s(yH);l2r=r(M3t,"TFLEDModel"),M3t.forEach(t),i2r=r(_Ie," (LED model)"),_Ie.forEach(t),d2r=i(D),p8=n(D,"LI",{});var uIe=s(p8);VFe=n(uIe,"STRONG",{});var E3t=s(VFe);c2r=r(E3t,"longformer"),E3t.forEach(t),f2r=r(uIe," \u2014 "),xH=n(uIe,"A",{href:!0});var C3t=s(xH);m2r=r(C3t,"TFLongformerModel"),C3t.forEach(t),g2r=r(uIe," (Longformer model)"),uIe.forEach(t),h2r=i(D),_8=n(D,"LI",{});var bIe=s(_8);XFe=n(bIe,"STRONG",{});var w3t=s(XFe);p2r=r(w3t,"lxmert"),w3t.forEach(t),_2r=r(bIe," \u2014 "),$H=n(bIe,"A",{href:!0});var A3t=s($H);u2r=r(A3t,"TFLxmertModel"),A3t.forEach(t),b2r=r(bIe," (LXMERT model)"),bIe.forEach(t),v2r=i(D),u8=n(D,"LI",{});var vIe=s(u8);zFe=n(vIe,"STRONG",{});var L3t=s(zFe);F2r=r(L3t,"marian"),L3t.forEach(t),T2r=r(vIe," \u2014 "),kH=n(vIe,"A",{href:!0});var y3t=s(kH);M2r=r(y3t,"TFMarianModel"),y3t.forEach(t),E2r=r(vIe," (Marian model)"),vIe.forEach(t),C2r=i(D),b8=n(D,"LI",{});var FIe=s(b8);QFe=n(FIe,"STRONG",{});var x3t=s(QFe);w2r=r(x3t,"mbart"),x3t.forEach(t),A2r=r(FIe," \u2014 "),SH=n(FIe,"A",{href:!0});var $3t=s(SH);L2r=r($3t,"TFMBartModel"),$3t.forEach(t),y2r=r(FIe," (mBART model)"),FIe.forEach(t),x2r=i(D),v8=n(D,"LI",{});var TIe=s(v8);WFe=n(TIe,"STRONG",{});var k3t=s(WFe);$2r=r(k3t,"mobilebert"),k3t.forEach(t),k2r=r(TIe," \u2014 "),RH=n(TIe,"A",{href:!0});var S3t=s(RH);S2r=r(S3t,"TFMobileBertModel"),S3t.forEach(t),R2r=r(TIe," (MobileBERT model)"),TIe.forEach(t),P2r=i(D),F8=n(D,"LI",{});var MIe=s(F8);HFe=n(MIe,"STRONG",{});var R3t=s(HFe);B2r=r(R3t,"mpnet"),R3t.forEach(t),I2r=r(MIe," \u2014 "),PH=n(MIe,"A",{href:!0});var P3t=s(PH);N2r=r(P3t,"TFMPNetModel"),P3t.forEach(t),q2r=r(MIe," (MPNet model)"),MIe.forEach(t),j2r=i(D),T8=n(D,"LI",{});var EIe=s(T8);UFe=n(EIe,"STRONG",{});var B3t=s(UFe);D2r=r(B3t,"mt5"),B3t.forEach(t),G2r=r(EIe," \u2014 "),BH=n(EIe,"A",{href:!0});var I3t=s(BH);O2r=r(I3t,"TFMT5Model"),I3t.forEach(t),V2r=r(EIe," (MT5 model)"),EIe.forEach(t),X2r=i(D),M8=n(D,"LI",{});var CIe=s(M8);JFe=n(CIe,"STRONG",{});var N3t=s(JFe);z2r=r(N3t,"openai-gpt"),N3t.forEach(t),Q2r=r(CIe," \u2014 "),IH=n(CIe,"A",{href:!0});var q3t=s(IH);W2r=r(q3t,"TFOpenAIGPTModel"),q3t.forEach(t),H2r=r(CIe," (OpenAI GPT model)"),CIe.forEach(t),U2r=i(D),E8=n(D,"LI",{});var wIe=s(E8);YFe=n(wIe,"STRONG",{});var j3t=s(YFe);J2r=r(j3t,"opt"),j3t.forEach(t),Y2r=r(wIe," \u2014 "),NH=n(wIe,"A",{href:!0});var D3t=s(NH);K2r=r(D3t,"TFOPTModel"),D3t.forEach(t),Z2r=r(wIe," (OPT model)"),wIe.forEach(t),ebr=i(D),C8=n(D,"LI",{});var AIe=s(C8);KFe=n(AIe,"STRONG",{});var G3t=s(KFe);obr=r(G3t,"pegasus"),G3t.forEach(t),rbr=r(AIe," \u2014 "),qH=n(AIe,"A",{href:!0});var O3t=s(qH);tbr=r(O3t,"TFPegasusModel"),O3t.forEach(t),abr=r(AIe," (Pegasus model)"),AIe.forEach(t),nbr=i(D),w8=n(D,"LI",{});var LIe=s(w8);ZFe=n(LIe,"STRONG",{});var V3t=s(ZFe);sbr=r(V3t,"rembert"),V3t.forEach(t),lbr=r(LIe," \u2014 "),jH=n(LIe,"A",{href:!0});var X3t=s(jH);ibr=r(X3t,"TFRemBertModel"),X3t.forEach(t),dbr=r(LIe," (RemBERT model)"),LIe.forEach(t),cbr=i(D),A8=n(D,"LI",{});var yIe=s(A8);e6e=n(yIe,"STRONG",{});var z3t=s(e6e);fbr=r(z3t,"roberta"),z3t.forEach(t),mbr=r(yIe," \u2014 "),DH=n(yIe,"A",{href:!0});var Q3t=s(DH);gbr=r(Q3t,"TFRobertaModel"),Q3t.forEach(t),hbr=r(yIe," (RoBERTa model)"),yIe.forEach(t),pbr=i(D),L8=n(D,"LI",{});var xIe=s(L8);o6e=n(xIe,"STRONG",{});var W3t=s(o6e);_br=r(W3t,"roformer"),W3t.forEach(t),ubr=r(xIe," \u2014 "),GH=n(xIe,"A",{href:!0});var H3t=s(GH);bbr=r(H3t,"TFRoFormerModel"),H3t.forEach(t),vbr=r(xIe," (RoFormer model)"),xIe.forEach(t),Fbr=i(D),y8=n(D,"LI",{});var $Ie=s(y8);r6e=n($Ie,"STRONG",{});var U3t=s(r6e);Tbr=r(U3t,"speech_to_text"),U3t.forEach(t),Mbr=r($Ie," \u2014 "),OH=n($Ie,"A",{href:!0});var J3t=s(OH);Ebr=r(J3t,"TFSpeech2TextModel"),J3t.forEach(t),Cbr=r($Ie," (Speech2Text model)"),$Ie.forEach(t),wbr=i(D),x8=n(D,"LI",{});var kIe=s(x8);t6e=n(kIe,"STRONG",{});var Y3t=s(t6e);Abr=r(Y3t,"swin"),Y3t.forEach(t),Lbr=r(kIe," \u2014 "),VH=n(kIe,"A",{href:!0});var K3t=s(VH);ybr=r(K3t,"TFSwinModel"),K3t.forEach(t),xbr=r(kIe," (Swin Transformer model)"),kIe.forEach(t),$br=i(D),$8=n(D,"LI",{});var SIe=s($8);a6e=n(SIe,"STRONG",{});var Z3t=s(a6e);kbr=r(Z3t,"t5"),Z3t.forEach(t),Sbr=r(SIe," \u2014 "),XH=n(SIe,"A",{href:!0});var e0t=s(XH);Rbr=r(e0t,"TFT5Model"),e0t.forEach(t),Pbr=r(SIe," (T5 model)"),SIe.forEach(t),Bbr=i(D),k8=n(D,"LI",{});var RIe=s(k8);n6e=n(RIe,"STRONG",{});var o0t=s(n6e);Ibr=r(o0t,"tapas"),o0t.forEach(t),Nbr=r(RIe," \u2014 "),zH=n(RIe,"A",{href:!0});var r0t=s(zH);qbr=r(r0t,"TFTapasModel"),r0t.forEach(t),jbr=r(RIe," (TAPAS model)"),RIe.forEach(t),Dbr=i(D),S8=n(D,"LI",{});var PIe=s(S8);s6e=n(PIe,"STRONG",{});var t0t=s(s6e);Gbr=r(t0t,"transfo-xl"),t0t.forEach(t),Obr=r(PIe," \u2014 "),QH=n(PIe,"A",{href:!0});var a0t=s(QH);Vbr=r(a0t,"TFTransfoXLModel"),a0t.forEach(t),Xbr=r(PIe," (Transformer-XL model)"),PIe.forEach(t),zbr=i(D),R8=n(D,"LI",{});var BIe=s(R8);l6e=n(BIe,"STRONG",{});var n0t=s(l6e);Qbr=r(n0t,"vit"),n0t.forEach(t),Wbr=r(BIe," \u2014 "),WH=n(BIe,"A",{href:!0});var s0t=s(WH);Hbr=r(s0t,"TFViTModel"),s0t.forEach(t),Ubr=r(BIe," (ViT model)"),BIe.forEach(t),Jbr=i(D),P8=n(D,"LI",{});var IIe=s(P8);i6e=n(IIe,"STRONG",{});var l0t=s(i6e);Ybr=r(l0t,"vit_mae"),l0t.forEach(t),Kbr=r(IIe," \u2014 "),HH=n(IIe,"A",{href:!0});var i0t=s(HH);Zbr=r(i0t,"TFViTMAEModel"),i0t.forEach(t),evr=r(IIe," (ViTMAE model)"),IIe.forEach(t),ovr=i(D),B8=n(D,"LI",{});var NIe=s(B8);d6e=n(NIe,"STRONG",{});var d0t=s(d6e);rvr=r(d0t,"wav2vec2"),d0t.forEach(t),tvr=r(NIe," \u2014 "),UH=n(NIe,"A",{href:!0});var c0t=s(UH);avr=r(c0t,"TFWav2Vec2Model"),c0t.forEach(t),nvr=r(NIe," (Wav2Vec2 model)"),NIe.forEach(t),svr=i(D),I8=n(D,"LI",{});var qIe=s(I8);c6e=n(qIe,"STRONG",{});var f0t=s(c6e);lvr=r(f0t,"xlm"),f0t.forEach(t),ivr=r(qIe," \u2014 "),JH=n(qIe,"A",{href:!0});var m0t=s(JH);dvr=r(m0t,"TFXLMModel"),m0t.forEach(t),cvr=r(qIe," (XLM model)"),qIe.forEach(t),fvr=i(D),N8=n(D,"LI",{});var jIe=s(N8);f6e=n(jIe,"STRONG",{});var g0t=s(f6e);mvr=r(g0t,"xlm-roberta"),g0t.forEach(t),gvr=r(jIe," \u2014 "),YH=n(jIe,"A",{href:!0});var h0t=s(YH);hvr=r(h0t,"TFXLMRobertaModel"),h0t.forEach(t),pvr=r(jIe," (XLM-RoBERTa model)"),jIe.forEach(t),_vr=i(D),q8=n(D,"LI",{});var DIe=s(q8);m6e=n(DIe,"STRONG",{});var p0t=s(m6e);uvr=r(p0t,"xlnet"),p0t.forEach(t),bvr=r(DIe," \u2014 "),KH=n(DIe,"A",{href:!0});var _0t=s(KH);vvr=r(_0t,"TFXLNetModel"),_0t.forEach(t),Fvr=r(DIe," (XLNet model)"),DIe.forEach(t),D.forEach(t),Tvr=i(Cl),T(j8.$$.fragment,Cl),Cl.forEach(t),El.forEach(t),HOe=i(f),tc=n(f,"H2",{class:!0});var rze=s(tc);D8=n(rze,"A",{id:!0,class:!0,href:!0});var u0t=s(D8);g6e=n(u0t,"SPAN",{});var b0t=s(g6e);T(Fy.$$.fragment,b0t),b0t.forEach(t),u0t.forEach(t),Mvr=i(rze),h6e=n(rze,"SPAN",{});var v0t=s(h6e);Evr=r(v0t,"TFAutoModelForPreTraining"),v0t.forEach(t),rze.forEach(t),UOe=i(f),or=n(f,"DIV",{class:!0});var wl=s(or);T(Ty.$$.fragment,wl),Cvr=i(wl),ac=n(wl,"P",{});var _re=s(ac);wvr=r(_re,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),ZH=n(_re,"A",{href:!0});var F0t=s(ZH);Avr=r(F0t,"from_pretrained()"),F0t.forEach(t),Lvr=r(_re," class method or the "),eU=n(_re,"A",{href:!0});var T0t=s(eU);yvr=r(T0t,"from_config()"),T0t.forEach(t),xvr=r(_re,` class
method.`),_re.forEach(t),$vr=i(wl),My=n(wl,"P",{});var tze=s(My);kvr=r(tze,"This class cannot be instantiated directly using "),p6e=n(tze,"CODE",{});var M0t=s(p6e);Svr=r(M0t,"__init__()"),M0t.forEach(t),Rvr=r(tze," (throws an error)."),tze.forEach(t),Pvr=i(wl),kt=n(wl,"DIV",{class:!0});var y0=s(kt);T(Ey.$$.fragment,y0),Bvr=i(y0),_6e=n(y0,"P",{});var E0t=s(_6e);Ivr=r(E0t,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),E0t.forEach(t),Nvr=i(y0),nc=n(y0,"P",{});var ure=s(nc);qvr=r(ure,`Note:
Loading a model from its configuration file does `),u6e=n(ure,"STRONG",{});var C0t=s(u6e);jvr=r(C0t,"not"),C0t.forEach(t),Dvr=r(ure,` load the model weights. It only affects the
model\u2019s configuration. Use `),oU=n(ure,"A",{href:!0});var w0t=s(oU);Gvr=r(w0t,"from_pretrained()"),w0t.forEach(t),Ovr=r(ure," to load the model weights."),ure.forEach(t),Vvr=i(y0),T(G8.$$.fragment,y0),y0.forEach(t),Xvr=i(wl),xr=n(wl,"DIV",{class:!0});var Al=s(xr);T(Cy.$$.fragment,Al),zvr=i(Al),b6e=n(Al,"P",{});var A0t=s(b6e);Qvr=r(A0t,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),A0t.forEach(t),Wvr=i(Al),nn=n(Al,"P",{});var x0=s(nn);Hvr=r(x0,"The model class to instantiate is selected based on the "),v6e=n(x0,"CODE",{});var L0t=s(v6e);Uvr=r(L0t,"model_type"),L0t.forEach(t),Jvr=r(x0,` property of the config object (either
passed as an argument or loaded from `),F6e=n(x0,"CODE",{});var y0t=s(F6e);Yvr=r(y0t,"pretrained_model_name_or_path"),y0t.forEach(t),Kvr=r(x0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),T6e=n(x0,"CODE",{});var x0t=s(T6e);Zvr=r(x0t,"pretrained_model_name_or_path"),x0t.forEach(t),eFr=r(x0,":"),x0.forEach(t),oFr=i(Al),se=n(Al,"UL",{});var le=s(se);O8=n(le,"LI",{});var GIe=s(O8);M6e=n(GIe,"STRONG",{});var $0t=s(M6e);rFr=r($0t,"albert"),$0t.forEach(t),tFr=r(GIe," \u2014 "),rU=n(GIe,"A",{href:!0});var k0t=s(rU);aFr=r(k0t,"TFAlbertForPreTraining"),k0t.forEach(t),nFr=r(GIe," (ALBERT model)"),GIe.forEach(t),sFr=i(le),V8=n(le,"LI",{});var OIe=s(V8);E6e=n(OIe,"STRONG",{});var S0t=s(E6e);lFr=r(S0t,"bart"),S0t.forEach(t),iFr=r(OIe," \u2014 "),tU=n(OIe,"A",{href:!0});var R0t=s(tU);dFr=r(R0t,"TFBartForConditionalGeneration"),R0t.forEach(t),cFr=r(OIe," (BART model)"),OIe.forEach(t),fFr=i(le),X8=n(le,"LI",{});var VIe=s(X8);C6e=n(VIe,"STRONG",{});var P0t=s(C6e);mFr=r(P0t,"bert"),P0t.forEach(t),gFr=r(VIe," \u2014 "),aU=n(VIe,"A",{href:!0});var B0t=s(aU);hFr=r(B0t,"TFBertForPreTraining"),B0t.forEach(t),pFr=r(VIe," (BERT model)"),VIe.forEach(t),_Fr=i(le),z8=n(le,"LI",{});var XIe=s(z8);w6e=n(XIe,"STRONG",{});var I0t=s(w6e);uFr=r(I0t,"camembert"),I0t.forEach(t),bFr=r(XIe," \u2014 "),nU=n(XIe,"A",{href:!0});var N0t=s(nU);vFr=r(N0t,"TFCamembertForMaskedLM"),N0t.forEach(t),FFr=r(XIe," (CamemBERT model)"),XIe.forEach(t),TFr=i(le),Q8=n(le,"LI",{});var zIe=s(Q8);A6e=n(zIe,"STRONG",{});var q0t=s(A6e);MFr=r(q0t,"ctrl"),q0t.forEach(t),EFr=r(zIe," \u2014 "),sU=n(zIe,"A",{href:!0});var j0t=s(sU);CFr=r(j0t,"TFCTRLLMHeadModel"),j0t.forEach(t),wFr=r(zIe," (CTRL model)"),zIe.forEach(t),AFr=i(le),W8=n(le,"LI",{});var QIe=s(W8);L6e=n(QIe,"STRONG",{});var D0t=s(L6e);LFr=r(D0t,"distilbert"),D0t.forEach(t),yFr=r(QIe," \u2014 "),lU=n(QIe,"A",{href:!0});var G0t=s(lU);xFr=r(G0t,"TFDistilBertForMaskedLM"),G0t.forEach(t),$Fr=r(QIe," (DistilBERT model)"),QIe.forEach(t),kFr=i(le),H8=n(le,"LI",{});var WIe=s(H8);y6e=n(WIe,"STRONG",{});var O0t=s(y6e);SFr=r(O0t,"electra"),O0t.forEach(t),RFr=r(WIe," \u2014 "),iU=n(WIe,"A",{href:!0});var V0t=s(iU);PFr=r(V0t,"TFElectraForPreTraining"),V0t.forEach(t),BFr=r(WIe," (ELECTRA model)"),WIe.forEach(t),IFr=i(le),U8=n(le,"LI",{});var HIe=s(U8);x6e=n(HIe,"STRONG",{});var X0t=s(x6e);NFr=r(X0t,"flaubert"),X0t.forEach(t),qFr=r(HIe," \u2014 "),dU=n(HIe,"A",{href:!0});var z0t=s(dU);jFr=r(z0t,"TFFlaubertWithLMHeadModel"),z0t.forEach(t),DFr=r(HIe," (FlauBERT model)"),HIe.forEach(t),GFr=i(le),J8=n(le,"LI",{});var UIe=s(J8);$6e=n(UIe,"STRONG",{});var Q0t=s($6e);OFr=r(Q0t,"funnel"),Q0t.forEach(t),VFr=r(UIe," \u2014 "),cU=n(UIe,"A",{href:!0});var W0t=s(cU);XFr=r(W0t,"TFFunnelForPreTraining"),W0t.forEach(t),zFr=r(UIe," (Funnel Transformer model)"),UIe.forEach(t),QFr=i(le),Y8=n(le,"LI",{});var JIe=s(Y8);k6e=n(JIe,"STRONG",{});var H0t=s(k6e);WFr=r(H0t,"gpt2"),H0t.forEach(t),HFr=r(JIe," \u2014 "),fU=n(JIe,"A",{href:!0});var U0t=s(fU);UFr=r(U0t,"TFGPT2LMHeadModel"),U0t.forEach(t),JFr=r(JIe," (OpenAI GPT-2 model)"),JIe.forEach(t),YFr=i(le),K8=n(le,"LI",{});var YIe=s(K8);S6e=n(YIe,"STRONG",{});var J0t=s(S6e);KFr=r(J0t,"layoutlm"),J0t.forEach(t),ZFr=r(YIe," \u2014 "),mU=n(YIe,"A",{href:!0});var Y0t=s(mU);e6r=r(Y0t,"TFLayoutLMForMaskedLM"),Y0t.forEach(t),o6r=r(YIe," (LayoutLM model)"),YIe.forEach(t),r6r=i(le),Z8=n(le,"LI",{});var KIe=s(Z8);R6e=n(KIe,"STRONG",{});var K0t=s(R6e);t6r=r(K0t,"lxmert"),K0t.forEach(t),a6r=r(KIe," \u2014 "),gU=n(KIe,"A",{href:!0});var Z0t=s(gU);n6r=r(Z0t,"TFLxmertForPreTraining"),Z0t.forEach(t),s6r=r(KIe," (LXMERT model)"),KIe.forEach(t),l6r=i(le),e9=n(le,"LI",{});var ZIe=s(e9);P6e=n(ZIe,"STRONG",{});var ewt=s(P6e);i6r=r(ewt,"mobilebert"),ewt.forEach(t),d6r=r(ZIe," \u2014 "),hU=n(ZIe,"A",{href:!0});var owt=s(hU);c6r=r(owt,"TFMobileBertForPreTraining"),owt.forEach(t),f6r=r(ZIe," (MobileBERT model)"),ZIe.forEach(t),m6r=i(le),o9=n(le,"LI",{});var eNe=s(o9);B6e=n(eNe,"STRONG",{});var rwt=s(B6e);g6r=r(rwt,"mpnet"),rwt.forEach(t),h6r=r(eNe," \u2014 "),pU=n(eNe,"A",{href:!0});var twt=s(pU);p6r=r(twt,"TFMPNetForMaskedLM"),twt.forEach(t),_6r=r(eNe," (MPNet model)"),eNe.forEach(t),u6r=i(le),r9=n(le,"LI",{});var oNe=s(r9);I6e=n(oNe,"STRONG",{});var awt=s(I6e);b6r=r(awt,"openai-gpt"),awt.forEach(t),v6r=r(oNe," \u2014 "),_U=n(oNe,"A",{href:!0});var nwt=s(_U);F6r=r(nwt,"TFOpenAIGPTLMHeadModel"),nwt.forEach(t),T6r=r(oNe," (OpenAI GPT model)"),oNe.forEach(t),M6r=i(le),t9=n(le,"LI",{});var rNe=s(t9);N6e=n(rNe,"STRONG",{});var swt=s(N6e);E6r=r(swt,"roberta"),swt.forEach(t),C6r=r(rNe," \u2014 "),uU=n(rNe,"A",{href:!0});var lwt=s(uU);w6r=r(lwt,"TFRobertaForMaskedLM"),lwt.forEach(t),A6r=r(rNe," (RoBERTa model)"),rNe.forEach(t),L6r=i(le),a9=n(le,"LI",{});var tNe=s(a9);q6e=n(tNe,"STRONG",{});var iwt=s(q6e);y6r=r(iwt,"t5"),iwt.forEach(t),x6r=r(tNe," \u2014 "),bU=n(tNe,"A",{href:!0});var dwt=s(bU);$6r=r(dwt,"TFT5ForConditionalGeneration"),dwt.forEach(t),k6r=r(tNe," (T5 model)"),tNe.forEach(t),S6r=i(le),n9=n(le,"LI",{});var aNe=s(n9);j6e=n(aNe,"STRONG",{});var cwt=s(j6e);R6r=r(cwt,"tapas"),cwt.forEach(t),P6r=r(aNe," \u2014 "),vU=n(aNe,"A",{href:!0});var fwt=s(vU);B6r=r(fwt,"TFTapasForMaskedLM"),fwt.forEach(t),I6r=r(aNe," (TAPAS model)"),aNe.forEach(t),N6r=i(le),s9=n(le,"LI",{});var nNe=s(s9);D6e=n(nNe,"STRONG",{});var mwt=s(D6e);q6r=r(mwt,"transfo-xl"),mwt.forEach(t),j6r=r(nNe," \u2014 "),FU=n(nNe,"A",{href:!0});var gwt=s(FU);D6r=r(gwt,"TFTransfoXLLMHeadModel"),gwt.forEach(t),G6r=r(nNe," (Transformer-XL model)"),nNe.forEach(t),O6r=i(le),l9=n(le,"LI",{});var sNe=s(l9);G6e=n(sNe,"STRONG",{});var hwt=s(G6e);V6r=r(hwt,"vit_mae"),hwt.forEach(t),X6r=r(sNe," \u2014 "),TU=n(sNe,"A",{href:!0});var pwt=s(TU);z6r=r(pwt,"TFViTMAEForPreTraining"),pwt.forEach(t),Q6r=r(sNe," (ViTMAE model)"),sNe.forEach(t),W6r=i(le),i9=n(le,"LI",{});var lNe=s(i9);O6e=n(lNe,"STRONG",{});var _wt=s(O6e);H6r=r(_wt,"xlm"),_wt.forEach(t),U6r=r(lNe," \u2014 "),MU=n(lNe,"A",{href:!0});var uwt=s(MU);J6r=r(uwt,"TFXLMWithLMHeadModel"),uwt.forEach(t),Y6r=r(lNe," (XLM model)"),lNe.forEach(t),K6r=i(le),d9=n(le,"LI",{});var iNe=s(d9);V6e=n(iNe,"STRONG",{});var bwt=s(V6e);Z6r=r(bwt,"xlm-roberta"),bwt.forEach(t),eTr=r(iNe," \u2014 "),EU=n(iNe,"A",{href:!0});var vwt=s(EU);oTr=r(vwt,"TFXLMRobertaForMaskedLM"),vwt.forEach(t),rTr=r(iNe," (XLM-RoBERTa model)"),iNe.forEach(t),tTr=i(le),c9=n(le,"LI",{});var dNe=s(c9);X6e=n(dNe,"STRONG",{});var Fwt=s(X6e);aTr=r(Fwt,"xlnet"),Fwt.forEach(t),nTr=r(dNe," \u2014 "),CU=n(dNe,"A",{href:!0});var Twt=s(CU);sTr=r(Twt,"TFXLNetLMHeadModel"),Twt.forEach(t),lTr=r(dNe," (XLNet model)"),dNe.forEach(t),le.forEach(t),iTr=i(Al),T(f9.$$.fragment,Al),Al.forEach(t),wl.forEach(t),JOe=i(f),sc=n(f,"H2",{class:!0});var aze=s(sc);m9=n(aze,"A",{id:!0,class:!0,href:!0});var Mwt=s(m9);z6e=n(Mwt,"SPAN",{});var Ewt=s(z6e);T(wy.$$.fragment,Ewt),Ewt.forEach(t),Mwt.forEach(t),dTr=i(aze),Q6e=n(aze,"SPAN",{});var Cwt=s(Q6e);cTr=r(Cwt,"TFAutoModelForCausalLM"),Cwt.forEach(t),aze.forEach(t),YOe=i(f),rr=n(f,"DIV",{class:!0});var Ll=s(rr);T(Ay.$$.fragment,Ll),fTr=i(Ll),lc=n(Ll,"P",{});var bre=s(lc);mTr=r(bre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),wU=n(bre,"A",{href:!0});var wwt=s(wU);gTr=r(wwt,"from_pretrained()"),wwt.forEach(t),hTr=r(bre," class method or the "),AU=n(bre,"A",{href:!0});var Awt=s(AU);pTr=r(Awt,"from_config()"),Awt.forEach(t),_Tr=r(bre,` class
method.`),bre.forEach(t),uTr=i(Ll),Ly=n(Ll,"P",{});var nze=s(Ly);bTr=r(nze,"This class cannot be instantiated directly using "),W6e=n(nze,"CODE",{});var Lwt=s(W6e);vTr=r(Lwt,"__init__()"),Lwt.forEach(t),FTr=r(nze," (throws an error)."),nze.forEach(t),TTr=i(Ll),St=n(Ll,"DIV",{class:!0});var $0=s(St);T(yy.$$.fragment,$0),MTr=i($0),H6e=n($0,"P",{});var ywt=s(H6e);ETr=r(ywt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),ywt.forEach(t),CTr=i($0),ic=n($0,"P",{});var vre=s(ic);wTr=r(vre,`Note:
Loading a model from its configuration file does `),U6e=n(vre,"STRONG",{});var xwt=s(U6e);ATr=r(xwt,"not"),xwt.forEach(t),LTr=r(vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),LU=n(vre,"A",{href:!0});var $wt=s(LU);yTr=r($wt,"from_pretrained()"),$wt.forEach(t),xTr=r(vre," to load the model weights."),vre.forEach(t),$Tr=i($0),T(g9.$$.fragment,$0),$0.forEach(t),kTr=i(Ll),$r=n(Ll,"DIV",{class:!0});var yl=s($r);T(xy.$$.fragment,yl),STr=i(yl),J6e=n(yl,"P",{});var kwt=s(J6e);RTr=r(kwt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),kwt.forEach(t),PTr=i(yl),sn=n(yl,"P",{});var k0=s(sn);BTr=r(k0,"The model class to instantiate is selected based on the "),Y6e=n(k0,"CODE",{});var Swt=s(Y6e);ITr=r(Swt,"model_type"),Swt.forEach(t),NTr=r(k0,` property of the config object (either
passed as an argument or loaded from `),K6e=n(k0,"CODE",{});var Rwt=s(K6e);qTr=r(Rwt,"pretrained_model_name_or_path"),Rwt.forEach(t),jTr=r(k0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Z6e=n(k0,"CODE",{});var Pwt=s(Z6e);DTr=r(Pwt,"pretrained_model_name_or_path"),Pwt.forEach(t),GTr=r(k0,":"),k0.forEach(t),OTr=i(yl),Me=n(yl,"UL",{});var Ce=s(Me);h9=n(Ce,"LI",{});var cNe=s(h9);eTe=n(cNe,"STRONG",{});var Bwt=s(eTe);VTr=r(Bwt,"bert"),Bwt.forEach(t),XTr=r(cNe," \u2014 "),yU=n(cNe,"A",{href:!0});var Iwt=s(yU);zTr=r(Iwt,"TFBertLMHeadModel"),Iwt.forEach(t),QTr=r(cNe," (BERT model)"),cNe.forEach(t),WTr=i(Ce),p9=n(Ce,"LI",{});var fNe=s(p9);oTe=n(fNe,"STRONG",{});var Nwt=s(oTe);HTr=r(Nwt,"camembert"),Nwt.forEach(t),UTr=r(fNe," \u2014 "),xU=n(fNe,"A",{href:!0});var qwt=s(xU);JTr=r(qwt,"TFCamembertForCausalLM"),qwt.forEach(t),YTr=r(fNe," (CamemBERT model)"),fNe.forEach(t),KTr=i(Ce),_9=n(Ce,"LI",{});var mNe=s(_9);rTe=n(mNe,"STRONG",{});var jwt=s(rTe);ZTr=r(jwt,"ctrl"),jwt.forEach(t),e7r=r(mNe," \u2014 "),$U=n(mNe,"A",{href:!0});var Dwt=s($U);o7r=r(Dwt,"TFCTRLLMHeadModel"),Dwt.forEach(t),r7r=r(mNe," (CTRL model)"),mNe.forEach(t),t7r=i(Ce),u9=n(Ce,"LI",{});var gNe=s(u9);tTe=n(gNe,"STRONG",{});var Gwt=s(tTe);a7r=r(Gwt,"gpt2"),Gwt.forEach(t),n7r=r(gNe," \u2014 "),kU=n(gNe,"A",{href:!0});var Owt=s(kU);s7r=r(Owt,"TFGPT2LMHeadModel"),Owt.forEach(t),l7r=r(gNe," (OpenAI GPT-2 model)"),gNe.forEach(t),i7r=i(Ce),b9=n(Ce,"LI",{});var hNe=s(b9);aTe=n(hNe,"STRONG",{});var Vwt=s(aTe);d7r=r(Vwt,"gptj"),Vwt.forEach(t),c7r=r(hNe," \u2014 "),SU=n(hNe,"A",{href:!0});var Xwt=s(SU);f7r=r(Xwt,"TFGPTJForCausalLM"),Xwt.forEach(t),m7r=r(hNe," (GPT-J model)"),hNe.forEach(t),g7r=i(Ce),v9=n(Ce,"LI",{});var pNe=s(v9);nTe=n(pNe,"STRONG",{});var zwt=s(nTe);h7r=r(zwt,"openai-gpt"),zwt.forEach(t),p7r=r(pNe," \u2014 "),RU=n(pNe,"A",{href:!0});var Qwt=s(RU);_7r=r(Qwt,"TFOpenAIGPTLMHeadModel"),Qwt.forEach(t),u7r=r(pNe," (OpenAI GPT model)"),pNe.forEach(t),b7r=i(Ce),F9=n(Ce,"LI",{});var _Ne=s(F9);sTe=n(_Ne,"STRONG",{});var Wwt=s(sTe);v7r=r(Wwt,"opt"),Wwt.forEach(t),F7r=r(_Ne," \u2014 "),PU=n(_Ne,"A",{href:!0});var Hwt=s(PU);T7r=r(Hwt,"TFOPTForCausalLM"),Hwt.forEach(t),M7r=r(_Ne," (OPT model)"),_Ne.forEach(t),E7r=i(Ce),T9=n(Ce,"LI",{});var uNe=s(T9);lTe=n(uNe,"STRONG",{});var Uwt=s(lTe);C7r=r(Uwt,"rembert"),Uwt.forEach(t),w7r=r(uNe," \u2014 "),BU=n(uNe,"A",{href:!0});var Jwt=s(BU);A7r=r(Jwt,"TFRemBertForCausalLM"),Jwt.forEach(t),L7r=r(uNe," (RemBERT model)"),uNe.forEach(t),y7r=i(Ce),M9=n(Ce,"LI",{});var bNe=s(M9);iTe=n(bNe,"STRONG",{});var Ywt=s(iTe);x7r=r(Ywt,"roberta"),Ywt.forEach(t),$7r=r(bNe," \u2014 "),IU=n(bNe,"A",{href:!0});var Kwt=s(IU);k7r=r(Kwt,"TFRobertaForCausalLM"),Kwt.forEach(t),S7r=r(bNe," (RoBERTa model)"),bNe.forEach(t),R7r=i(Ce),E9=n(Ce,"LI",{});var vNe=s(E9);dTe=n(vNe,"STRONG",{});var Zwt=s(dTe);P7r=r(Zwt,"roformer"),Zwt.forEach(t),B7r=r(vNe," \u2014 "),NU=n(vNe,"A",{href:!0});var eAt=s(NU);I7r=r(eAt,"TFRoFormerForCausalLM"),eAt.forEach(t),N7r=r(vNe," (RoFormer model)"),vNe.forEach(t),q7r=i(Ce),C9=n(Ce,"LI",{});var FNe=s(C9);cTe=n(FNe,"STRONG",{});var oAt=s(cTe);j7r=r(oAt,"transfo-xl"),oAt.forEach(t),D7r=r(FNe," \u2014 "),qU=n(FNe,"A",{href:!0});var rAt=s(qU);G7r=r(rAt,"TFTransfoXLLMHeadModel"),rAt.forEach(t),O7r=r(FNe," (Transformer-XL model)"),FNe.forEach(t),V7r=i(Ce),w9=n(Ce,"LI",{});var TNe=s(w9);fTe=n(TNe,"STRONG",{});var tAt=s(fTe);X7r=r(tAt,"xlm"),tAt.forEach(t),z7r=r(TNe," \u2014 "),jU=n(TNe,"A",{href:!0});var aAt=s(jU);Q7r=r(aAt,"TFXLMWithLMHeadModel"),aAt.forEach(t),W7r=r(TNe," (XLM model)"),TNe.forEach(t),H7r=i(Ce),A9=n(Ce,"LI",{});var MNe=s(A9);mTe=n(MNe,"STRONG",{});var nAt=s(mTe);U7r=r(nAt,"xlnet"),nAt.forEach(t),J7r=r(MNe," \u2014 "),DU=n(MNe,"A",{href:!0});var sAt=s(DU);Y7r=r(sAt,"TFXLNetLMHeadModel"),sAt.forEach(t),K7r=r(MNe," (XLNet model)"),MNe.forEach(t),Ce.forEach(t),Z7r=i(yl),T(L9.$$.fragment,yl),yl.forEach(t),Ll.forEach(t),KOe=i(f),dc=n(f,"H2",{class:!0});var sze=s(dc);y9=n(sze,"A",{id:!0,class:!0,href:!0});var lAt=s(y9);gTe=n(lAt,"SPAN",{});var iAt=s(gTe);T($y.$$.fragment,iAt),iAt.forEach(t),lAt.forEach(t),e8r=i(sze),hTe=n(sze,"SPAN",{});var dAt=s(hTe);o8r=r(dAt,"TFAutoModelForImageClassification"),dAt.forEach(t),sze.forEach(t),ZOe=i(f),tr=n(f,"DIV",{class:!0});var xl=s(tr);T(ky.$$.fragment,xl),r8r=i(xl),cc=n(xl,"P",{});var Fre=s(cc);t8r=r(Fre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),GU=n(Fre,"A",{href:!0});var cAt=s(GU);a8r=r(cAt,"from_pretrained()"),cAt.forEach(t),n8r=r(Fre," class method or the "),OU=n(Fre,"A",{href:!0});var fAt=s(OU);s8r=r(fAt,"from_config()"),fAt.forEach(t),l8r=r(Fre,` class
method.`),Fre.forEach(t),i8r=i(xl),Sy=n(xl,"P",{});var lze=s(Sy);d8r=r(lze,"This class cannot be instantiated directly using "),pTe=n(lze,"CODE",{});var mAt=s(pTe);c8r=r(mAt,"__init__()"),mAt.forEach(t),f8r=r(lze," (throws an error)."),lze.forEach(t),m8r=i(xl),Rt=n(xl,"DIV",{class:!0});var S0=s(Rt);T(Ry.$$.fragment,S0),g8r=i(S0),_Te=n(S0,"P",{});var gAt=s(_Te);h8r=r(gAt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),gAt.forEach(t),p8r=i(S0),fc=n(S0,"P",{});var Tre=s(fc);_8r=r(Tre,`Note:
Loading a model from its configuration file does `),uTe=n(Tre,"STRONG",{});var hAt=s(uTe);u8r=r(hAt,"not"),hAt.forEach(t),b8r=r(Tre,` load the model weights. It only affects the
model\u2019s configuration. Use `),VU=n(Tre,"A",{href:!0});var pAt=s(VU);v8r=r(pAt,"from_pretrained()"),pAt.forEach(t),F8r=r(Tre," to load the model weights."),Tre.forEach(t),T8r=i(S0),T(x9.$$.fragment,S0),S0.forEach(t),M8r=i(xl),kr=n(xl,"DIV",{class:!0});var $l=s(kr);T(Py.$$.fragment,$l),E8r=i($l),bTe=n($l,"P",{});var _At=s(bTe);C8r=r(_At,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),_At.forEach(t),w8r=i($l),ln=n($l,"P",{});var R0=s(ln);A8r=r(R0,"The model class to instantiate is selected based on the "),vTe=n(R0,"CODE",{});var uAt=s(vTe);L8r=r(uAt,"model_type"),uAt.forEach(t),y8r=r(R0,` property of the config object (either
passed as an argument or loaded from `),FTe=n(R0,"CODE",{});var bAt=s(FTe);x8r=r(bAt,"pretrained_model_name_or_path"),bAt.forEach(t),$8r=r(R0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),TTe=n(R0,"CODE",{});var vAt=s(TTe);k8r=r(vAt,"pretrained_model_name_or_path"),vAt.forEach(t),S8r=r(R0,":"),R0.forEach(t),R8r=i($l),dn=n($l,"UL",{});var P0=s(dn);$9=n(P0,"LI",{});var ENe=s($9);MTe=n(ENe,"STRONG",{});var FAt=s(MTe);P8r=r(FAt,"convnext"),FAt.forEach(t),B8r=r(ENe," \u2014 "),XU=n(ENe,"A",{href:!0});var TAt=s(XU);I8r=r(TAt,"TFConvNextForImageClassification"),TAt.forEach(t),N8r=r(ENe," (ConvNeXT model)"),ENe.forEach(t),q8r=i(P0),k9=n(P0,"LI",{});var CNe=s(k9);ETe=n(CNe,"STRONG",{});var MAt=s(ETe);j8r=r(MAt,"data2vec-vision"),MAt.forEach(t),D8r=r(CNe," \u2014 "),zU=n(CNe,"A",{href:!0});var EAt=s(zU);G8r=r(EAt,"TFData2VecVisionForImageClassification"),EAt.forEach(t),O8r=r(CNe," (Data2VecVision model)"),CNe.forEach(t),V8r=i(P0),S9=n(P0,"LI",{});var wNe=s(S9);CTe=n(wNe,"STRONG",{});var CAt=s(CTe);X8r=r(CAt,"swin"),CAt.forEach(t),z8r=r(wNe," \u2014 "),QU=n(wNe,"A",{href:!0});var wAt=s(QU);Q8r=r(wAt,"TFSwinForImageClassification"),wAt.forEach(t),W8r=r(wNe," (Swin Transformer model)"),wNe.forEach(t),H8r=i(P0),R9=n(P0,"LI",{});var ANe=s(R9);wTe=n(ANe,"STRONG",{});var AAt=s(wTe);U8r=r(AAt,"vit"),AAt.forEach(t),J8r=r(ANe," \u2014 "),WU=n(ANe,"A",{href:!0});var LAt=s(WU);Y8r=r(LAt,"TFViTForImageClassification"),LAt.forEach(t),K8r=r(ANe," (ViT model)"),ANe.forEach(t),P0.forEach(t),Z8r=i($l),T(P9.$$.fragment,$l),$l.forEach(t),xl.forEach(t),eVe=i(f),mc=n(f,"H2",{class:!0});var ize=s(mc);B9=n(ize,"A",{id:!0,class:!0,href:!0});var yAt=s(B9);ATe=n(yAt,"SPAN",{});var xAt=s(ATe);T(By.$$.fragment,xAt),xAt.forEach(t),yAt.forEach(t),e9r=i(ize),LTe=n(ize,"SPAN",{});var $At=s(LTe);o9r=r($At,"TFAutoModelForMaskedLM"),$At.forEach(t),ize.forEach(t),oVe=i(f),ar=n(f,"DIV",{class:!0});var kl=s(ar);T(Iy.$$.fragment,kl),r9r=i(kl),gc=n(kl,"P",{});var Mre=s(gc);t9r=r(Mre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),HU=n(Mre,"A",{href:!0});var kAt=s(HU);a9r=r(kAt,"from_pretrained()"),kAt.forEach(t),n9r=r(Mre," class method or the "),UU=n(Mre,"A",{href:!0});var SAt=s(UU);s9r=r(SAt,"from_config()"),SAt.forEach(t),l9r=r(Mre,` class
method.`),Mre.forEach(t),i9r=i(kl),Ny=n(kl,"P",{});var dze=s(Ny);d9r=r(dze,"This class cannot be instantiated directly using "),yTe=n(dze,"CODE",{});var RAt=s(yTe);c9r=r(RAt,"__init__()"),RAt.forEach(t),f9r=r(dze," (throws an error)."),dze.forEach(t),m9r=i(kl),Pt=n(kl,"DIV",{class:!0});var B0=s(Pt);T(qy.$$.fragment,B0),g9r=i(B0),xTe=n(B0,"P",{});var PAt=s(xTe);h9r=r(PAt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),PAt.forEach(t),p9r=i(B0),hc=n(B0,"P",{});var Ere=s(hc);_9r=r(Ere,`Note:
Loading a model from its configuration file does `),$Te=n(Ere,"STRONG",{});var BAt=s($Te);u9r=r(BAt,"not"),BAt.forEach(t),b9r=r(Ere,` load the model weights. It only affects the
model\u2019s configuration. Use `),JU=n(Ere,"A",{href:!0});var IAt=s(JU);v9r=r(IAt,"from_pretrained()"),IAt.forEach(t),F9r=r(Ere," to load the model weights."),Ere.forEach(t),T9r=i(B0),T(I9.$$.fragment,B0),B0.forEach(t),M9r=i(kl),Sr=n(kl,"DIV",{class:!0});var Sl=s(Sr);T(jy.$$.fragment,Sl),E9r=i(Sl),kTe=n(Sl,"P",{});var NAt=s(kTe);C9r=r(NAt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),NAt.forEach(t),w9r=i(Sl),cn=n(Sl,"P",{});var I0=s(cn);A9r=r(I0,"The model class to instantiate is selected based on the "),STe=n(I0,"CODE",{});var qAt=s(STe);L9r=r(qAt,"model_type"),qAt.forEach(t),y9r=r(I0,` property of the config object (either
passed as an argument or loaded from `),RTe=n(I0,"CODE",{});var jAt=s(RTe);x9r=r(jAt,"pretrained_model_name_or_path"),jAt.forEach(t),$9r=r(I0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),PTe=n(I0,"CODE",{});var DAt=s(PTe);k9r=r(DAt,"pretrained_model_name_or_path"),DAt.forEach(t),S9r=r(I0,":"),I0.forEach(t),R9r=i(Sl),ie=n(Sl,"UL",{});var fe=s(ie);N9=n(fe,"LI",{});var LNe=s(N9);BTe=n(LNe,"STRONG",{});var GAt=s(BTe);P9r=r(GAt,"albert"),GAt.forEach(t),B9r=r(LNe," \u2014 "),YU=n(LNe,"A",{href:!0});var OAt=s(YU);I9r=r(OAt,"TFAlbertForMaskedLM"),OAt.forEach(t),N9r=r(LNe," (ALBERT model)"),LNe.forEach(t),q9r=i(fe),q9=n(fe,"LI",{});var yNe=s(q9);ITe=n(yNe,"STRONG",{});var VAt=s(ITe);j9r=r(VAt,"bert"),VAt.forEach(t),D9r=r(yNe," \u2014 "),KU=n(yNe,"A",{href:!0});var XAt=s(KU);G9r=r(XAt,"TFBertForMaskedLM"),XAt.forEach(t),O9r=r(yNe," (BERT model)"),yNe.forEach(t),V9r=i(fe),j9=n(fe,"LI",{});var xNe=s(j9);NTe=n(xNe,"STRONG",{});var zAt=s(NTe);X9r=r(zAt,"camembert"),zAt.forEach(t),z9r=r(xNe," \u2014 "),ZU=n(xNe,"A",{href:!0});var QAt=s(ZU);Q9r=r(QAt,"TFCamembertForMaskedLM"),QAt.forEach(t),W9r=r(xNe," (CamemBERT model)"),xNe.forEach(t),H9r=i(fe),D9=n(fe,"LI",{});var $Ne=s(D9);qTe=n($Ne,"STRONG",{});var WAt=s(qTe);U9r=r(WAt,"convbert"),WAt.forEach(t),J9r=r($Ne," \u2014 "),eJ=n($Ne,"A",{href:!0});var HAt=s(eJ);Y9r=r(HAt,"TFConvBertForMaskedLM"),HAt.forEach(t),K9r=r($Ne," (ConvBERT model)"),$Ne.forEach(t),Z9r=i(fe),G9=n(fe,"LI",{});var kNe=s(G9);jTe=n(kNe,"STRONG",{});var UAt=s(jTe);eMr=r(UAt,"deberta"),UAt.forEach(t),oMr=r(kNe," \u2014 "),oJ=n(kNe,"A",{href:!0});var JAt=s(oJ);rMr=r(JAt,"TFDebertaForMaskedLM"),JAt.forEach(t),tMr=r(kNe," (DeBERTa model)"),kNe.forEach(t),aMr=i(fe),O9=n(fe,"LI",{});var SNe=s(O9);DTe=n(SNe,"STRONG",{});var YAt=s(DTe);nMr=r(YAt,"deberta-v2"),YAt.forEach(t),sMr=r(SNe," \u2014 "),rJ=n(SNe,"A",{href:!0});var KAt=s(rJ);lMr=r(KAt,"TFDebertaV2ForMaskedLM"),KAt.forEach(t),iMr=r(SNe," (DeBERTa-v2 model)"),SNe.forEach(t),dMr=i(fe),V9=n(fe,"LI",{});var RNe=s(V9);GTe=n(RNe,"STRONG",{});var ZAt=s(GTe);cMr=r(ZAt,"distilbert"),ZAt.forEach(t),fMr=r(RNe," \u2014 "),tJ=n(RNe,"A",{href:!0});var eLt=s(tJ);mMr=r(eLt,"TFDistilBertForMaskedLM"),eLt.forEach(t),gMr=r(RNe," (DistilBERT model)"),RNe.forEach(t),hMr=i(fe),X9=n(fe,"LI",{});var PNe=s(X9);OTe=n(PNe,"STRONG",{});var oLt=s(OTe);pMr=r(oLt,"electra"),oLt.forEach(t),_Mr=r(PNe," \u2014 "),aJ=n(PNe,"A",{href:!0});var rLt=s(aJ);uMr=r(rLt,"TFElectraForMaskedLM"),rLt.forEach(t),bMr=r(PNe," (ELECTRA model)"),PNe.forEach(t),vMr=i(fe),z9=n(fe,"LI",{});var BNe=s(z9);VTe=n(BNe,"STRONG",{});var tLt=s(VTe);FMr=r(tLt,"flaubert"),tLt.forEach(t),TMr=r(BNe," \u2014 "),nJ=n(BNe,"A",{href:!0});var aLt=s(nJ);MMr=r(aLt,"TFFlaubertWithLMHeadModel"),aLt.forEach(t),EMr=r(BNe," (FlauBERT model)"),BNe.forEach(t),CMr=i(fe),Q9=n(fe,"LI",{});var INe=s(Q9);XTe=n(INe,"STRONG",{});var nLt=s(XTe);wMr=r(nLt,"funnel"),nLt.forEach(t),AMr=r(INe," \u2014 "),sJ=n(INe,"A",{href:!0});var sLt=s(sJ);LMr=r(sLt,"TFFunnelForMaskedLM"),sLt.forEach(t),yMr=r(INe," (Funnel Transformer model)"),INe.forEach(t),xMr=i(fe),W9=n(fe,"LI",{});var NNe=s(W9);zTe=n(NNe,"STRONG",{});var lLt=s(zTe);$Mr=r(lLt,"layoutlm"),lLt.forEach(t),kMr=r(NNe," \u2014 "),lJ=n(NNe,"A",{href:!0});var iLt=s(lJ);SMr=r(iLt,"TFLayoutLMForMaskedLM"),iLt.forEach(t),RMr=r(NNe," (LayoutLM model)"),NNe.forEach(t),PMr=i(fe),H9=n(fe,"LI",{});var qNe=s(H9);QTe=n(qNe,"STRONG",{});var dLt=s(QTe);BMr=r(dLt,"longformer"),dLt.forEach(t),IMr=r(qNe," \u2014 "),iJ=n(qNe,"A",{href:!0});var cLt=s(iJ);NMr=r(cLt,"TFLongformerForMaskedLM"),cLt.forEach(t),qMr=r(qNe," (Longformer model)"),qNe.forEach(t),jMr=i(fe),U9=n(fe,"LI",{});var jNe=s(U9);WTe=n(jNe,"STRONG",{});var fLt=s(WTe);DMr=r(fLt,"mobilebert"),fLt.forEach(t),GMr=r(jNe," \u2014 "),dJ=n(jNe,"A",{href:!0});var mLt=s(dJ);OMr=r(mLt,"TFMobileBertForMaskedLM"),mLt.forEach(t),VMr=r(jNe," (MobileBERT model)"),jNe.forEach(t),XMr=i(fe),J9=n(fe,"LI",{});var DNe=s(J9);HTe=n(DNe,"STRONG",{});var gLt=s(HTe);zMr=r(gLt,"mpnet"),gLt.forEach(t),QMr=r(DNe," \u2014 "),cJ=n(DNe,"A",{href:!0});var hLt=s(cJ);WMr=r(hLt,"TFMPNetForMaskedLM"),hLt.forEach(t),HMr=r(DNe," (MPNet model)"),DNe.forEach(t),UMr=i(fe),Y9=n(fe,"LI",{});var GNe=s(Y9);UTe=n(GNe,"STRONG",{});var pLt=s(UTe);JMr=r(pLt,"rembert"),pLt.forEach(t),YMr=r(GNe," \u2014 "),fJ=n(GNe,"A",{href:!0});var _Lt=s(fJ);KMr=r(_Lt,"TFRemBertForMaskedLM"),_Lt.forEach(t),ZMr=r(GNe," (RemBERT model)"),GNe.forEach(t),eEr=i(fe),K9=n(fe,"LI",{});var ONe=s(K9);JTe=n(ONe,"STRONG",{});var uLt=s(JTe);oEr=r(uLt,"roberta"),uLt.forEach(t),rEr=r(ONe," \u2014 "),mJ=n(ONe,"A",{href:!0});var bLt=s(mJ);tEr=r(bLt,"TFRobertaForMaskedLM"),bLt.forEach(t),aEr=r(ONe," (RoBERTa model)"),ONe.forEach(t),nEr=i(fe),Z9=n(fe,"LI",{});var VNe=s(Z9);YTe=n(VNe,"STRONG",{});var vLt=s(YTe);sEr=r(vLt,"roformer"),vLt.forEach(t),lEr=r(VNe," \u2014 "),gJ=n(VNe,"A",{href:!0});var FLt=s(gJ);iEr=r(FLt,"TFRoFormerForMaskedLM"),FLt.forEach(t),dEr=r(VNe," (RoFormer model)"),VNe.forEach(t),cEr=i(fe),eM=n(fe,"LI",{});var XNe=s(eM);KTe=n(XNe,"STRONG",{});var TLt=s(KTe);fEr=r(TLt,"tapas"),TLt.forEach(t),mEr=r(XNe," \u2014 "),hJ=n(XNe,"A",{href:!0});var MLt=s(hJ);gEr=r(MLt,"TFTapasForMaskedLM"),MLt.forEach(t),hEr=r(XNe," (TAPAS model)"),XNe.forEach(t),pEr=i(fe),oM=n(fe,"LI",{});var zNe=s(oM);ZTe=n(zNe,"STRONG",{});var ELt=s(ZTe);_Er=r(ELt,"xlm"),ELt.forEach(t),uEr=r(zNe," \u2014 "),pJ=n(zNe,"A",{href:!0});var CLt=s(pJ);bEr=r(CLt,"TFXLMWithLMHeadModel"),CLt.forEach(t),vEr=r(zNe," (XLM model)"),zNe.forEach(t),FEr=i(fe),rM=n(fe,"LI",{});var QNe=s(rM);e7e=n(QNe,"STRONG",{});var wLt=s(e7e);TEr=r(wLt,"xlm-roberta"),wLt.forEach(t),MEr=r(QNe," \u2014 "),_J=n(QNe,"A",{href:!0});var ALt=s(_J);EEr=r(ALt,"TFXLMRobertaForMaskedLM"),ALt.forEach(t),CEr=r(QNe," (XLM-RoBERTa model)"),QNe.forEach(t),fe.forEach(t),wEr=i(Sl),T(tM.$$.fragment,Sl),Sl.forEach(t),kl.forEach(t),rVe=i(f),pc=n(f,"H2",{class:!0});var cze=s(pc);aM=n(cze,"A",{id:!0,class:!0,href:!0});var LLt=s(aM);o7e=n(LLt,"SPAN",{});var yLt=s(o7e);T(Dy.$$.fragment,yLt),yLt.forEach(t),LLt.forEach(t),AEr=i(cze),r7e=n(cze,"SPAN",{});var xLt=s(r7e);LEr=r(xLt,"TFAutoModelForSeq2SeqLM"),xLt.forEach(t),cze.forEach(t),tVe=i(f),nr=n(f,"DIV",{class:!0});var Rl=s(nr);T(Gy.$$.fragment,Rl),yEr=i(Rl),_c=n(Rl,"P",{});var Cre=s(_c);xEr=r(Cre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),uJ=n(Cre,"A",{href:!0});var $Lt=s(uJ);$Er=r($Lt,"from_pretrained()"),$Lt.forEach(t),kEr=r(Cre," class method or the "),bJ=n(Cre,"A",{href:!0});var kLt=s(bJ);SEr=r(kLt,"from_config()"),kLt.forEach(t),REr=r(Cre,` class
method.`),Cre.forEach(t),PEr=i(Rl),Oy=n(Rl,"P",{});var fze=s(Oy);BEr=r(fze,"This class cannot be instantiated directly using "),t7e=n(fze,"CODE",{});var SLt=s(t7e);IEr=r(SLt,"__init__()"),SLt.forEach(t),NEr=r(fze," (throws an error)."),fze.forEach(t),qEr=i(Rl),Bt=n(Rl,"DIV",{class:!0});var N0=s(Bt);T(Vy.$$.fragment,N0),jEr=i(N0),a7e=n(N0,"P",{});var RLt=s(a7e);DEr=r(RLt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),RLt.forEach(t),GEr=i(N0),uc=n(N0,"P",{});var wre=s(uc);OEr=r(wre,`Note:
Loading a model from its configuration file does `),n7e=n(wre,"STRONG",{});var PLt=s(n7e);VEr=r(PLt,"not"),PLt.forEach(t),XEr=r(wre,` load the model weights. It only affects the
model\u2019s configuration. Use `),vJ=n(wre,"A",{href:!0});var BLt=s(vJ);zEr=r(BLt,"from_pretrained()"),BLt.forEach(t),QEr=r(wre," to load the model weights."),wre.forEach(t),WEr=i(N0),T(nM.$$.fragment,N0),N0.forEach(t),HEr=i(Rl),Rr=n(Rl,"DIV",{class:!0});var Pl=s(Rr);T(Xy.$$.fragment,Pl),UEr=i(Pl),s7e=n(Pl,"P",{});var ILt=s(s7e);JEr=r(ILt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),ILt.forEach(t),YEr=i(Pl),fn=n(Pl,"P",{});var q0=s(fn);KEr=r(q0,"The model class to instantiate is selected based on the "),l7e=n(q0,"CODE",{});var NLt=s(l7e);ZEr=r(NLt,"model_type"),NLt.forEach(t),e4r=r(q0,` property of the config object (either
passed as an argument or loaded from `),i7e=n(q0,"CODE",{});var qLt=s(i7e);o4r=r(qLt,"pretrained_model_name_or_path"),qLt.forEach(t),r4r=r(q0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d7e=n(q0,"CODE",{});var jLt=s(d7e);t4r=r(jLt,"pretrained_model_name_or_path"),jLt.forEach(t),a4r=r(q0,":"),q0.forEach(t),n4r=i(Pl),ye=n(Pl,"UL",{});var Ie=s(ye);sM=n(Ie,"LI",{});var WNe=s(sM);c7e=n(WNe,"STRONG",{});var DLt=s(c7e);s4r=r(DLt,"bart"),DLt.forEach(t),l4r=r(WNe," \u2014 "),FJ=n(WNe,"A",{href:!0});var GLt=s(FJ);i4r=r(GLt,"TFBartForConditionalGeneration"),GLt.forEach(t),d4r=r(WNe," (BART model)"),WNe.forEach(t),c4r=i(Ie),lM=n(Ie,"LI",{});var HNe=s(lM);f7e=n(HNe,"STRONG",{});var OLt=s(f7e);f4r=r(OLt,"blenderbot"),OLt.forEach(t),m4r=r(HNe," \u2014 "),TJ=n(HNe,"A",{href:!0});var VLt=s(TJ);g4r=r(VLt,"TFBlenderbotForConditionalGeneration"),VLt.forEach(t),h4r=r(HNe," (Blenderbot model)"),HNe.forEach(t),p4r=i(Ie),iM=n(Ie,"LI",{});var UNe=s(iM);m7e=n(UNe,"STRONG",{});var XLt=s(m7e);_4r=r(XLt,"blenderbot-small"),XLt.forEach(t),u4r=r(UNe," \u2014 "),MJ=n(UNe,"A",{href:!0});var zLt=s(MJ);b4r=r(zLt,"TFBlenderbotSmallForConditionalGeneration"),zLt.forEach(t),v4r=r(UNe," (BlenderbotSmall model)"),UNe.forEach(t),F4r=i(Ie),dM=n(Ie,"LI",{});var JNe=s(dM);g7e=n(JNe,"STRONG",{});var QLt=s(g7e);T4r=r(QLt,"encoder-decoder"),QLt.forEach(t),M4r=r(JNe," \u2014 "),EJ=n(JNe,"A",{href:!0});var WLt=s(EJ);E4r=r(WLt,"TFEncoderDecoderModel"),WLt.forEach(t),C4r=r(JNe," (Encoder decoder model)"),JNe.forEach(t),w4r=i(Ie),cM=n(Ie,"LI",{});var YNe=s(cM);h7e=n(YNe,"STRONG",{});var HLt=s(h7e);A4r=r(HLt,"led"),HLt.forEach(t),L4r=r(YNe," \u2014 "),CJ=n(YNe,"A",{href:!0});var ULt=s(CJ);y4r=r(ULt,"TFLEDForConditionalGeneration"),ULt.forEach(t),x4r=r(YNe," (LED model)"),YNe.forEach(t),$4r=i(Ie),fM=n(Ie,"LI",{});var KNe=s(fM);p7e=n(KNe,"STRONG",{});var JLt=s(p7e);k4r=r(JLt,"marian"),JLt.forEach(t),S4r=r(KNe," \u2014 "),wJ=n(KNe,"A",{href:!0});var YLt=s(wJ);R4r=r(YLt,"TFMarianMTModel"),YLt.forEach(t),P4r=r(KNe," (Marian model)"),KNe.forEach(t),B4r=i(Ie),mM=n(Ie,"LI",{});var ZNe=s(mM);_7e=n(ZNe,"STRONG",{});var KLt=s(_7e);I4r=r(KLt,"mbart"),KLt.forEach(t),N4r=r(ZNe," \u2014 "),AJ=n(ZNe,"A",{href:!0});var ZLt=s(AJ);q4r=r(ZLt,"TFMBartForConditionalGeneration"),ZLt.forEach(t),j4r=r(ZNe," (mBART model)"),ZNe.forEach(t),D4r=i(Ie),gM=n(Ie,"LI",{});var eqe=s(gM);u7e=n(eqe,"STRONG",{});var eyt=s(u7e);G4r=r(eyt,"mt5"),eyt.forEach(t),O4r=r(eqe," \u2014 "),LJ=n(eqe,"A",{href:!0});var oyt=s(LJ);V4r=r(oyt,"TFMT5ForConditionalGeneration"),oyt.forEach(t),X4r=r(eqe," (MT5 model)"),eqe.forEach(t),z4r=i(Ie),hM=n(Ie,"LI",{});var oqe=s(hM);b7e=n(oqe,"STRONG",{});var ryt=s(b7e);Q4r=r(ryt,"pegasus"),ryt.forEach(t),W4r=r(oqe," \u2014 "),yJ=n(oqe,"A",{href:!0});var tyt=s(yJ);H4r=r(tyt,"TFPegasusForConditionalGeneration"),tyt.forEach(t),U4r=r(oqe," (Pegasus model)"),oqe.forEach(t),J4r=i(Ie),pM=n(Ie,"LI",{});var rqe=s(pM);v7e=n(rqe,"STRONG",{});var ayt=s(v7e);Y4r=r(ayt,"t5"),ayt.forEach(t),K4r=r(rqe," \u2014 "),xJ=n(rqe,"A",{href:!0});var nyt=s(xJ);Z4r=r(nyt,"TFT5ForConditionalGeneration"),nyt.forEach(t),eCr=r(rqe," (T5 model)"),rqe.forEach(t),Ie.forEach(t),oCr=i(Pl),T(_M.$$.fragment,Pl),Pl.forEach(t),Rl.forEach(t),aVe=i(f),bc=n(f,"H2",{class:!0});var mze=s(bc);uM=n(mze,"A",{id:!0,class:!0,href:!0});var syt=s(uM);F7e=n(syt,"SPAN",{});var lyt=s(F7e);T(zy.$$.fragment,lyt),lyt.forEach(t),syt.forEach(t),rCr=i(mze),T7e=n(mze,"SPAN",{});var iyt=s(T7e);tCr=r(iyt,"TFAutoModelForSequenceClassification"),iyt.forEach(t),mze.forEach(t),nVe=i(f),sr=n(f,"DIV",{class:!0});var Bl=s(sr);T(Qy.$$.fragment,Bl),aCr=i(Bl),vc=n(Bl,"P",{});var Are=s(vc);nCr=r(Are,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),$J=n(Are,"A",{href:!0});var dyt=s($J);sCr=r(dyt,"from_pretrained()"),dyt.forEach(t),lCr=r(Are," class method or the "),kJ=n(Are,"A",{href:!0});var cyt=s(kJ);iCr=r(cyt,"from_config()"),cyt.forEach(t),dCr=r(Are,` class
method.`),Are.forEach(t),cCr=i(Bl),Wy=n(Bl,"P",{});var gze=s(Wy);fCr=r(gze,"This class cannot be instantiated directly using "),M7e=n(gze,"CODE",{});var fyt=s(M7e);mCr=r(fyt,"__init__()"),fyt.forEach(t),gCr=r(gze," (throws an error)."),gze.forEach(t),hCr=i(Bl),It=n(Bl,"DIV",{class:!0});var j0=s(It);T(Hy.$$.fragment,j0),pCr=i(j0),E7e=n(j0,"P",{});var myt=s(E7e);_Cr=r(myt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),myt.forEach(t),uCr=i(j0),Fc=n(j0,"P",{});var Lre=s(Fc);bCr=r(Lre,`Note:
Loading a model from its configuration file does `),C7e=n(Lre,"STRONG",{});var gyt=s(C7e);vCr=r(gyt,"not"),gyt.forEach(t),FCr=r(Lre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SJ=n(Lre,"A",{href:!0});var hyt=s(SJ);TCr=r(hyt,"from_pretrained()"),hyt.forEach(t),MCr=r(Lre," to load the model weights."),Lre.forEach(t),ECr=i(j0),T(bM.$$.fragment,j0),j0.forEach(t),CCr=i(Bl),Pr=n(Bl,"DIV",{class:!0});var Il=s(Pr);T(Uy.$$.fragment,Il),wCr=i(Il),w7e=n(Il,"P",{});var pyt=s(w7e);ACr=r(pyt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),pyt.forEach(t),LCr=i(Il),mn=n(Il,"P",{});var D0=s(mn);yCr=r(D0,"The model class to instantiate is selected based on the "),A7e=n(D0,"CODE",{});var _yt=s(A7e);xCr=r(_yt,"model_type"),_yt.forEach(t),$Cr=r(D0,` property of the config object (either
passed as an argument or loaded from `),L7e=n(D0,"CODE",{});var uyt=s(L7e);kCr=r(uyt,"pretrained_model_name_or_path"),uyt.forEach(t),SCr=r(D0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),y7e=n(D0,"CODE",{});var byt=s(y7e);RCr=r(byt,"pretrained_model_name_or_path"),byt.forEach(t),PCr=r(D0,":"),D0.forEach(t),BCr=i(Il),te=n(Il,"UL",{});var ne=s(te);vM=n(ne,"LI",{});var tqe=s(vM);x7e=n(tqe,"STRONG",{});var vyt=s(x7e);ICr=r(vyt,"albert"),vyt.forEach(t),NCr=r(tqe," \u2014 "),RJ=n(tqe,"A",{href:!0});var Fyt=s(RJ);qCr=r(Fyt,"TFAlbertForSequenceClassification"),Fyt.forEach(t),jCr=r(tqe," (ALBERT model)"),tqe.forEach(t),DCr=i(ne),FM=n(ne,"LI",{});var aqe=s(FM);$7e=n(aqe,"STRONG",{});var Tyt=s($7e);GCr=r(Tyt,"bert"),Tyt.forEach(t),OCr=r(aqe," \u2014 "),PJ=n(aqe,"A",{href:!0});var Myt=s(PJ);VCr=r(Myt,"TFBertForSequenceClassification"),Myt.forEach(t),XCr=r(aqe," (BERT model)"),aqe.forEach(t),zCr=i(ne),TM=n(ne,"LI",{});var nqe=s(TM);k7e=n(nqe,"STRONG",{});var Eyt=s(k7e);QCr=r(Eyt,"camembert"),Eyt.forEach(t),WCr=r(nqe," \u2014 "),BJ=n(nqe,"A",{href:!0});var Cyt=s(BJ);HCr=r(Cyt,"TFCamembertForSequenceClassification"),Cyt.forEach(t),UCr=r(nqe," (CamemBERT model)"),nqe.forEach(t),JCr=i(ne),MM=n(ne,"LI",{});var sqe=s(MM);S7e=n(sqe,"STRONG",{});var wyt=s(S7e);YCr=r(wyt,"convbert"),wyt.forEach(t),KCr=r(sqe," \u2014 "),IJ=n(sqe,"A",{href:!0});var Ayt=s(IJ);ZCr=r(Ayt,"TFConvBertForSequenceClassification"),Ayt.forEach(t),e5r=r(sqe," (ConvBERT model)"),sqe.forEach(t),o5r=i(ne),EM=n(ne,"LI",{});var lqe=s(EM);R7e=n(lqe,"STRONG",{});var Lyt=s(R7e);r5r=r(Lyt,"ctrl"),Lyt.forEach(t),t5r=r(lqe," \u2014 "),NJ=n(lqe,"A",{href:!0});var yyt=s(NJ);a5r=r(yyt,"TFCTRLForSequenceClassification"),yyt.forEach(t),n5r=r(lqe," (CTRL model)"),lqe.forEach(t),s5r=i(ne),CM=n(ne,"LI",{});var iqe=s(CM);P7e=n(iqe,"STRONG",{});var xyt=s(P7e);l5r=r(xyt,"deberta"),xyt.forEach(t),i5r=r(iqe," \u2014 "),qJ=n(iqe,"A",{href:!0});var $yt=s(qJ);d5r=r($yt,"TFDebertaForSequenceClassification"),$yt.forEach(t),c5r=r(iqe," (DeBERTa model)"),iqe.forEach(t),f5r=i(ne),wM=n(ne,"LI",{});var dqe=s(wM);B7e=n(dqe,"STRONG",{});var kyt=s(B7e);m5r=r(kyt,"deberta-v2"),kyt.forEach(t),g5r=r(dqe," \u2014 "),jJ=n(dqe,"A",{href:!0});var Syt=s(jJ);h5r=r(Syt,"TFDebertaV2ForSequenceClassification"),Syt.forEach(t),p5r=r(dqe," (DeBERTa-v2 model)"),dqe.forEach(t),_5r=i(ne),AM=n(ne,"LI",{});var cqe=s(AM);I7e=n(cqe,"STRONG",{});var Ryt=s(I7e);u5r=r(Ryt,"distilbert"),Ryt.forEach(t),b5r=r(cqe," \u2014 "),DJ=n(cqe,"A",{href:!0});var Pyt=s(DJ);v5r=r(Pyt,"TFDistilBertForSequenceClassification"),Pyt.forEach(t),F5r=r(cqe," (DistilBERT model)"),cqe.forEach(t),T5r=i(ne),LM=n(ne,"LI",{});var fqe=s(LM);N7e=n(fqe,"STRONG",{});var Byt=s(N7e);M5r=r(Byt,"electra"),Byt.forEach(t),E5r=r(fqe," \u2014 "),GJ=n(fqe,"A",{href:!0});var Iyt=s(GJ);C5r=r(Iyt,"TFElectraForSequenceClassification"),Iyt.forEach(t),w5r=r(fqe," (ELECTRA model)"),fqe.forEach(t),A5r=i(ne),yM=n(ne,"LI",{});var mqe=s(yM);q7e=n(mqe,"STRONG",{});var Nyt=s(q7e);L5r=r(Nyt,"flaubert"),Nyt.forEach(t),y5r=r(mqe," \u2014 "),OJ=n(mqe,"A",{href:!0});var qyt=s(OJ);x5r=r(qyt,"TFFlaubertForSequenceClassification"),qyt.forEach(t),$5r=r(mqe," (FlauBERT model)"),mqe.forEach(t),k5r=i(ne),xM=n(ne,"LI",{});var gqe=s(xM);j7e=n(gqe,"STRONG",{});var jyt=s(j7e);S5r=r(jyt,"funnel"),jyt.forEach(t),R5r=r(gqe," \u2014 "),VJ=n(gqe,"A",{href:!0});var Dyt=s(VJ);P5r=r(Dyt,"TFFunnelForSequenceClassification"),Dyt.forEach(t),B5r=r(gqe," (Funnel Transformer model)"),gqe.forEach(t),I5r=i(ne),$M=n(ne,"LI",{});var hqe=s($M);D7e=n(hqe,"STRONG",{});var Gyt=s(D7e);N5r=r(Gyt,"gpt2"),Gyt.forEach(t),q5r=r(hqe," \u2014 "),XJ=n(hqe,"A",{href:!0});var Oyt=s(XJ);j5r=r(Oyt,"TFGPT2ForSequenceClassification"),Oyt.forEach(t),D5r=r(hqe," (OpenAI GPT-2 model)"),hqe.forEach(t),G5r=i(ne),kM=n(ne,"LI",{});var pqe=s(kM);G7e=n(pqe,"STRONG",{});var Vyt=s(G7e);O5r=r(Vyt,"gptj"),Vyt.forEach(t),V5r=r(pqe," \u2014 "),zJ=n(pqe,"A",{href:!0});var Xyt=s(zJ);X5r=r(Xyt,"TFGPTJForSequenceClassification"),Xyt.forEach(t),z5r=r(pqe," (GPT-J model)"),pqe.forEach(t),Q5r=i(ne),SM=n(ne,"LI",{});var _qe=s(SM);O7e=n(_qe,"STRONG",{});var zyt=s(O7e);W5r=r(zyt,"layoutlm"),zyt.forEach(t),H5r=r(_qe," \u2014 "),QJ=n(_qe,"A",{href:!0});var Qyt=s(QJ);U5r=r(Qyt,"TFLayoutLMForSequenceClassification"),Qyt.forEach(t),J5r=r(_qe," (LayoutLM model)"),_qe.forEach(t),Y5r=i(ne),RM=n(ne,"LI",{});var uqe=s(RM);V7e=n(uqe,"STRONG",{});var Wyt=s(V7e);K5r=r(Wyt,"longformer"),Wyt.forEach(t),Z5r=r(uqe," \u2014 "),WJ=n(uqe,"A",{href:!0});var Hyt=s(WJ);e3r=r(Hyt,"TFLongformerForSequenceClassification"),Hyt.forEach(t),o3r=r(uqe," (Longformer model)"),uqe.forEach(t),r3r=i(ne),PM=n(ne,"LI",{});var bqe=s(PM);X7e=n(bqe,"STRONG",{});var Uyt=s(X7e);t3r=r(Uyt,"mobilebert"),Uyt.forEach(t),a3r=r(bqe," \u2014 "),HJ=n(bqe,"A",{href:!0});var Jyt=s(HJ);n3r=r(Jyt,"TFMobileBertForSequenceClassification"),Jyt.forEach(t),s3r=r(bqe," (MobileBERT model)"),bqe.forEach(t),l3r=i(ne),BM=n(ne,"LI",{});var vqe=s(BM);z7e=n(vqe,"STRONG",{});var Yyt=s(z7e);i3r=r(Yyt,"mpnet"),Yyt.forEach(t),d3r=r(vqe," \u2014 "),UJ=n(vqe,"A",{href:!0});var Kyt=s(UJ);c3r=r(Kyt,"TFMPNetForSequenceClassification"),Kyt.forEach(t),f3r=r(vqe," (MPNet model)"),vqe.forEach(t),m3r=i(ne),IM=n(ne,"LI",{});var Fqe=s(IM);Q7e=n(Fqe,"STRONG",{});var Zyt=s(Q7e);g3r=r(Zyt,"openai-gpt"),Zyt.forEach(t),h3r=r(Fqe," \u2014 "),JJ=n(Fqe,"A",{href:!0});var ext=s(JJ);p3r=r(ext,"TFOpenAIGPTForSequenceClassification"),ext.forEach(t),_3r=r(Fqe," (OpenAI GPT model)"),Fqe.forEach(t),u3r=i(ne),NM=n(ne,"LI",{});var Tqe=s(NM);W7e=n(Tqe,"STRONG",{});var oxt=s(W7e);b3r=r(oxt,"rembert"),oxt.forEach(t),v3r=r(Tqe," \u2014 "),YJ=n(Tqe,"A",{href:!0});var rxt=s(YJ);F3r=r(rxt,"TFRemBertForSequenceClassification"),rxt.forEach(t),T3r=r(Tqe," (RemBERT model)"),Tqe.forEach(t),M3r=i(ne),qM=n(ne,"LI",{});var Mqe=s(qM);H7e=n(Mqe,"STRONG",{});var txt=s(H7e);E3r=r(txt,"roberta"),txt.forEach(t),C3r=r(Mqe," \u2014 "),KJ=n(Mqe,"A",{href:!0});var axt=s(KJ);w3r=r(axt,"TFRobertaForSequenceClassification"),axt.forEach(t),A3r=r(Mqe," (RoBERTa model)"),Mqe.forEach(t),L3r=i(ne),jM=n(ne,"LI",{});var Eqe=s(jM);U7e=n(Eqe,"STRONG",{});var nxt=s(U7e);y3r=r(nxt,"roformer"),nxt.forEach(t),x3r=r(Eqe," \u2014 "),ZJ=n(Eqe,"A",{href:!0});var sxt=s(ZJ);$3r=r(sxt,"TFRoFormerForSequenceClassification"),sxt.forEach(t),k3r=r(Eqe," (RoFormer model)"),Eqe.forEach(t),S3r=i(ne),DM=n(ne,"LI",{});var Cqe=s(DM);J7e=n(Cqe,"STRONG",{});var lxt=s(J7e);R3r=r(lxt,"tapas"),lxt.forEach(t),P3r=r(Cqe," \u2014 "),eY=n(Cqe,"A",{href:!0});var ixt=s(eY);B3r=r(ixt,"TFTapasForSequenceClassification"),ixt.forEach(t),I3r=r(Cqe," (TAPAS model)"),Cqe.forEach(t),N3r=i(ne),GM=n(ne,"LI",{});var wqe=s(GM);Y7e=n(wqe,"STRONG",{});var dxt=s(Y7e);q3r=r(dxt,"transfo-xl"),dxt.forEach(t),j3r=r(wqe," \u2014 "),oY=n(wqe,"A",{href:!0});var cxt=s(oY);D3r=r(cxt,"TFTransfoXLForSequenceClassification"),cxt.forEach(t),G3r=r(wqe," (Transformer-XL model)"),wqe.forEach(t),O3r=i(ne),OM=n(ne,"LI",{});var Aqe=s(OM);K7e=n(Aqe,"STRONG",{});var fxt=s(K7e);V3r=r(fxt,"xlm"),fxt.forEach(t),X3r=r(Aqe," \u2014 "),rY=n(Aqe,"A",{href:!0});var mxt=s(rY);z3r=r(mxt,"TFXLMForSequenceClassification"),mxt.forEach(t),Q3r=r(Aqe," (XLM model)"),Aqe.forEach(t),W3r=i(ne),VM=n(ne,"LI",{});var Lqe=s(VM);Z7e=n(Lqe,"STRONG",{});var gxt=s(Z7e);H3r=r(gxt,"xlm-roberta"),gxt.forEach(t),U3r=r(Lqe," \u2014 "),tY=n(Lqe,"A",{href:!0});var hxt=s(tY);J3r=r(hxt,"TFXLMRobertaForSequenceClassification"),hxt.forEach(t),Y3r=r(Lqe," (XLM-RoBERTa model)"),Lqe.forEach(t),K3r=i(ne),XM=n(ne,"LI",{});var yqe=s(XM);e8e=n(yqe,"STRONG",{});var pxt=s(e8e);Z3r=r(pxt,"xlnet"),pxt.forEach(t),e0r=r(yqe," \u2014 "),aY=n(yqe,"A",{href:!0});var _xt=s(aY);o0r=r(_xt,"TFXLNetForSequenceClassification"),_xt.forEach(t),r0r=r(yqe," (XLNet model)"),yqe.forEach(t),ne.forEach(t),t0r=i(Il),T(zM.$$.fragment,Il),Il.forEach(t),Bl.forEach(t),sVe=i(f),Tc=n(f,"H2",{class:!0});var hze=s(Tc);QM=n(hze,"A",{id:!0,class:!0,href:!0});var uxt=s(QM);o8e=n(uxt,"SPAN",{});var bxt=s(o8e);T(Jy.$$.fragment,bxt),bxt.forEach(t),uxt.forEach(t),a0r=i(hze),r8e=n(hze,"SPAN",{});var vxt=s(r8e);n0r=r(vxt,"TFAutoModelForMultipleChoice"),vxt.forEach(t),hze.forEach(t),lVe=i(f),lr=n(f,"DIV",{class:!0});var Nl=s(lr);T(Yy.$$.fragment,Nl),s0r=i(Nl),Mc=n(Nl,"P",{});var yre=s(Mc);l0r=r(yre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),nY=n(yre,"A",{href:!0});var Fxt=s(nY);i0r=r(Fxt,"from_pretrained()"),Fxt.forEach(t),d0r=r(yre," class method or the "),sY=n(yre,"A",{href:!0});var Txt=s(sY);c0r=r(Txt,"from_config()"),Txt.forEach(t),f0r=r(yre,` class
method.`),yre.forEach(t),m0r=i(Nl),Ky=n(Nl,"P",{});var pze=s(Ky);g0r=r(pze,"This class cannot be instantiated directly using "),t8e=n(pze,"CODE",{});var Mxt=s(t8e);h0r=r(Mxt,"__init__()"),Mxt.forEach(t),p0r=r(pze," (throws an error)."),pze.forEach(t),_0r=i(Nl),Nt=n(Nl,"DIV",{class:!0});var G0=s(Nt);T(Zy.$$.fragment,G0),u0r=i(G0),a8e=n(G0,"P",{});var Ext=s(a8e);b0r=r(Ext,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),Ext.forEach(t),v0r=i(G0),Ec=n(G0,"P",{});var xre=s(Ec);F0r=r(xre,`Note:
Loading a model from its configuration file does `),n8e=n(xre,"STRONG",{});var Cxt=s(n8e);T0r=r(Cxt,"not"),Cxt.forEach(t),M0r=r(xre,` load the model weights. It only affects the
model\u2019s configuration. Use `),lY=n(xre,"A",{href:!0});var wxt=s(lY);E0r=r(wxt,"from_pretrained()"),wxt.forEach(t),C0r=r(xre," to load the model weights."),xre.forEach(t),w0r=i(G0),T(WM.$$.fragment,G0),G0.forEach(t),A0r=i(Nl),Br=n(Nl,"DIV",{class:!0});var ql=s(Br);T(ex.$$.fragment,ql),L0r=i(ql),s8e=n(ql,"P",{});var Axt=s(s8e);y0r=r(Axt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),Axt.forEach(t),x0r=i(ql),gn=n(ql,"P",{});var O0=s(gn);$0r=r(O0,"The model class to instantiate is selected based on the "),l8e=n(O0,"CODE",{});var Lxt=s(l8e);k0r=r(Lxt,"model_type"),Lxt.forEach(t),S0r=r(O0,` property of the config object (either
passed as an argument or loaded from `),i8e=n(O0,"CODE",{});var yxt=s(i8e);R0r=r(yxt,"pretrained_model_name_or_path"),yxt.forEach(t),P0r=r(O0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),d8e=n(O0,"CODE",{});var xxt=s(d8e);B0r=r(xxt,"pretrained_model_name_or_path"),xxt.forEach(t),I0r=r(O0,":"),O0.forEach(t),N0r=i(ql),_e=n(ql,"UL",{});var ve=s(_e);HM=n(ve,"LI",{});var xqe=s(HM);c8e=n(xqe,"STRONG",{});var $xt=s(c8e);q0r=r($xt,"albert"),$xt.forEach(t),j0r=r(xqe," \u2014 "),iY=n(xqe,"A",{href:!0});var kxt=s(iY);D0r=r(kxt,"TFAlbertForMultipleChoice"),kxt.forEach(t),G0r=r(xqe," (ALBERT model)"),xqe.forEach(t),O0r=i(ve),UM=n(ve,"LI",{});var $qe=s(UM);f8e=n($qe,"STRONG",{});var Sxt=s(f8e);V0r=r(Sxt,"bert"),Sxt.forEach(t),X0r=r($qe," \u2014 "),dY=n($qe,"A",{href:!0});var Rxt=s(dY);z0r=r(Rxt,"TFBertForMultipleChoice"),Rxt.forEach(t),Q0r=r($qe," (BERT model)"),$qe.forEach(t),W0r=i(ve),JM=n(ve,"LI",{});var kqe=s(JM);m8e=n(kqe,"STRONG",{});var Pxt=s(m8e);H0r=r(Pxt,"camembert"),Pxt.forEach(t),U0r=r(kqe," \u2014 "),cY=n(kqe,"A",{href:!0});var Bxt=s(cY);J0r=r(Bxt,"TFCamembertForMultipleChoice"),Bxt.forEach(t),Y0r=r(kqe," (CamemBERT model)"),kqe.forEach(t),K0r=i(ve),YM=n(ve,"LI",{});var Sqe=s(YM);g8e=n(Sqe,"STRONG",{});var Ixt=s(g8e);Z0r=r(Ixt,"convbert"),Ixt.forEach(t),ewr=r(Sqe," \u2014 "),fY=n(Sqe,"A",{href:!0});var Nxt=s(fY);owr=r(Nxt,"TFConvBertForMultipleChoice"),Nxt.forEach(t),rwr=r(Sqe," (ConvBERT model)"),Sqe.forEach(t),twr=i(ve),KM=n(ve,"LI",{});var Rqe=s(KM);h8e=n(Rqe,"STRONG",{});var qxt=s(h8e);awr=r(qxt,"distilbert"),qxt.forEach(t),nwr=r(Rqe," \u2014 "),mY=n(Rqe,"A",{href:!0});var jxt=s(mY);swr=r(jxt,"TFDistilBertForMultipleChoice"),jxt.forEach(t),lwr=r(Rqe," (DistilBERT model)"),Rqe.forEach(t),iwr=i(ve),ZM=n(ve,"LI",{});var Pqe=s(ZM);p8e=n(Pqe,"STRONG",{});var Dxt=s(p8e);dwr=r(Dxt,"electra"),Dxt.forEach(t),cwr=r(Pqe," \u2014 "),gY=n(Pqe,"A",{href:!0});var Gxt=s(gY);fwr=r(Gxt,"TFElectraForMultipleChoice"),Gxt.forEach(t),mwr=r(Pqe," (ELECTRA model)"),Pqe.forEach(t),gwr=i(ve),eE=n(ve,"LI",{});var Bqe=s(eE);_8e=n(Bqe,"STRONG",{});var Oxt=s(_8e);hwr=r(Oxt,"flaubert"),Oxt.forEach(t),pwr=r(Bqe," \u2014 "),hY=n(Bqe,"A",{href:!0});var Vxt=s(hY);_wr=r(Vxt,"TFFlaubertForMultipleChoice"),Vxt.forEach(t),uwr=r(Bqe," (FlauBERT model)"),Bqe.forEach(t),bwr=i(ve),oE=n(ve,"LI",{});var Iqe=s(oE);u8e=n(Iqe,"STRONG",{});var Xxt=s(u8e);vwr=r(Xxt,"funnel"),Xxt.forEach(t),Fwr=r(Iqe," \u2014 "),pY=n(Iqe,"A",{href:!0});var zxt=s(pY);Twr=r(zxt,"TFFunnelForMultipleChoice"),zxt.forEach(t),Mwr=r(Iqe," (Funnel Transformer model)"),Iqe.forEach(t),Ewr=i(ve),rE=n(ve,"LI",{});var Nqe=s(rE);b8e=n(Nqe,"STRONG",{});var Qxt=s(b8e);Cwr=r(Qxt,"longformer"),Qxt.forEach(t),wwr=r(Nqe," \u2014 "),_Y=n(Nqe,"A",{href:!0});var Wxt=s(_Y);Awr=r(Wxt,"TFLongformerForMultipleChoice"),Wxt.forEach(t),Lwr=r(Nqe," (Longformer model)"),Nqe.forEach(t),ywr=i(ve),tE=n(ve,"LI",{});var qqe=s(tE);v8e=n(qqe,"STRONG",{});var Hxt=s(v8e);xwr=r(Hxt,"mobilebert"),Hxt.forEach(t),$wr=r(qqe," \u2014 "),uY=n(qqe,"A",{href:!0});var Uxt=s(uY);kwr=r(Uxt,"TFMobileBertForMultipleChoice"),Uxt.forEach(t),Swr=r(qqe," (MobileBERT model)"),qqe.forEach(t),Rwr=i(ve),aE=n(ve,"LI",{});var jqe=s(aE);F8e=n(jqe,"STRONG",{});var Jxt=s(F8e);Pwr=r(Jxt,"mpnet"),Jxt.forEach(t),Bwr=r(jqe," \u2014 "),bY=n(jqe,"A",{href:!0});var Yxt=s(bY);Iwr=r(Yxt,"TFMPNetForMultipleChoice"),Yxt.forEach(t),Nwr=r(jqe," (MPNet model)"),jqe.forEach(t),qwr=i(ve),nE=n(ve,"LI",{});var Dqe=s(nE);T8e=n(Dqe,"STRONG",{});var Kxt=s(T8e);jwr=r(Kxt,"rembert"),Kxt.forEach(t),Dwr=r(Dqe," \u2014 "),vY=n(Dqe,"A",{href:!0});var Zxt=s(vY);Gwr=r(Zxt,"TFRemBertForMultipleChoice"),Zxt.forEach(t),Owr=r(Dqe," (RemBERT model)"),Dqe.forEach(t),Vwr=i(ve),sE=n(ve,"LI",{});var Gqe=s(sE);M8e=n(Gqe,"STRONG",{});var e$t=s(M8e);Xwr=r(e$t,"roberta"),e$t.forEach(t),zwr=r(Gqe," \u2014 "),FY=n(Gqe,"A",{href:!0});var o$t=s(FY);Qwr=r(o$t,"TFRobertaForMultipleChoice"),o$t.forEach(t),Wwr=r(Gqe," (RoBERTa model)"),Gqe.forEach(t),Hwr=i(ve),lE=n(ve,"LI",{});var Oqe=s(lE);E8e=n(Oqe,"STRONG",{});var r$t=s(E8e);Uwr=r(r$t,"roformer"),r$t.forEach(t),Jwr=r(Oqe," \u2014 "),TY=n(Oqe,"A",{href:!0});var t$t=s(TY);Ywr=r(t$t,"TFRoFormerForMultipleChoice"),t$t.forEach(t),Kwr=r(Oqe," (RoFormer model)"),Oqe.forEach(t),Zwr=i(ve),iE=n(ve,"LI",{});var Vqe=s(iE);C8e=n(Vqe,"STRONG",{});var a$t=s(C8e);eAr=r(a$t,"xlm"),a$t.forEach(t),oAr=r(Vqe," \u2014 "),MY=n(Vqe,"A",{href:!0});var n$t=s(MY);rAr=r(n$t,"TFXLMForMultipleChoice"),n$t.forEach(t),tAr=r(Vqe," (XLM model)"),Vqe.forEach(t),aAr=i(ve),dE=n(ve,"LI",{});var Xqe=s(dE);w8e=n(Xqe,"STRONG",{});var s$t=s(w8e);nAr=r(s$t,"xlm-roberta"),s$t.forEach(t),sAr=r(Xqe," \u2014 "),EY=n(Xqe,"A",{href:!0});var l$t=s(EY);lAr=r(l$t,"TFXLMRobertaForMultipleChoice"),l$t.forEach(t),iAr=r(Xqe," (XLM-RoBERTa model)"),Xqe.forEach(t),dAr=i(ve),cE=n(ve,"LI",{});var zqe=s(cE);A8e=n(zqe,"STRONG",{});var i$t=s(A8e);cAr=r(i$t,"xlnet"),i$t.forEach(t),fAr=r(zqe," \u2014 "),CY=n(zqe,"A",{href:!0});var d$t=s(CY);mAr=r(d$t,"TFXLNetForMultipleChoice"),d$t.forEach(t),gAr=r(zqe," (XLNet model)"),zqe.forEach(t),ve.forEach(t),hAr=i(ql),T(fE.$$.fragment,ql),ql.forEach(t),Nl.forEach(t),iVe=i(f),Cc=n(f,"H2",{class:!0});var _ze=s(Cc);mE=n(_ze,"A",{id:!0,class:!0,href:!0});var c$t=s(mE);L8e=n(c$t,"SPAN",{});var f$t=s(L8e);T(ox.$$.fragment,f$t),f$t.forEach(t),c$t.forEach(t),pAr=i(_ze),y8e=n(_ze,"SPAN",{});var m$t=s(y8e);_Ar=r(m$t,"TFAutoModelForNextSentencePrediction"),m$t.forEach(t),_ze.forEach(t),dVe=i(f),ir=n(f,"DIV",{class:!0});var jl=s(ir);T(rx.$$.fragment,jl),uAr=i(jl),wc=n(jl,"P",{});var $re=s(wc);bAr=r($re,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),wY=n($re,"A",{href:!0});var g$t=s(wY);vAr=r(g$t,"from_pretrained()"),g$t.forEach(t),FAr=r($re," class method or the "),AY=n($re,"A",{href:!0});var h$t=s(AY);TAr=r(h$t,"from_config()"),h$t.forEach(t),MAr=r($re,` class
method.`),$re.forEach(t),EAr=i(jl),tx=n(jl,"P",{});var uze=s(tx);CAr=r(uze,"This class cannot be instantiated directly using "),x8e=n(uze,"CODE",{});var p$t=s(x8e);wAr=r(p$t,"__init__()"),p$t.forEach(t),AAr=r(uze," (throws an error)."),uze.forEach(t),LAr=i(jl),qt=n(jl,"DIV",{class:!0});var V0=s(qt);T(ax.$$.fragment,V0),yAr=i(V0),$8e=n(V0,"P",{});var _$t=s($8e);xAr=r(_$t,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),_$t.forEach(t),$Ar=i(V0),Ac=n(V0,"P",{});var kre=s(Ac);kAr=r(kre,`Note:
Loading a model from its configuration file does `),k8e=n(kre,"STRONG",{});var u$t=s(k8e);SAr=r(u$t,"not"),u$t.forEach(t),RAr=r(kre,` load the model weights. It only affects the
model\u2019s configuration. Use `),LY=n(kre,"A",{href:!0});var b$t=s(LY);PAr=r(b$t,"from_pretrained()"),b$t.forEach(t),BAr=r(kre," to load the model weights."),kre.forEach(t),IAr=i(V0),T(gE.$$.fragment,V0),V0.forEach(t),NAr=i(jl),Ir=n(jl,"DIV",{class:!0});var Dl=s(Ir);T(nx.$$.fragment,Dl),qAr=i(Dl),S8e=n(Dl,"P",{});var v$t=s(S8e);jAr=r(v$t,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),v$t.forEach(t),DAr=i(Dl),hn=n(Dl,"P",{});var X0=s(hn);GAr=r(X0,"The model class to instantiate is selected based on the "),R8e=n(X0,"CODE",{});var F$t=s(R8e);OAr=r(F$t,"model_type"),F$t.forEach(t),VAr=r(X0,` property of the config object (either
passed as an argument or loaded from `),P8e=n(X0,"CODE",{});var T$t=s(P8e);XAr=r(T$t,"pretrained_model_name_or_path"),T$t.forEach(t),zAr=r(X0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),B8e=n(X0,"CODE",{});var M$t=s(B8e);QAr=r(M$t,"pretrained_model_name_or_path"),M$t.forEach(t),WAr=r(X0,":"),X0.forEach(t),HAr=i(Dl),sx=n(Dl,"UL",{});var bze=s(sx);hE=n(bze,"LI",{});var Qqe=s(hE);I8e=n(Qqe,"STRONG",{});var E$t=s(I8e);UAr=r(E$t,"bert"),E$t.forEach(t),JAr=r(Qqe," \u2014 "),yY=n(Qqe,"A",{href:!0});var C$t=s(yY);YAr=r(C$t,"TFBertForNextSentencePrediction"),C$t.forEach(t),KAr=r(Qqe," (BERT model)"),Qqe.forEach(t),ZAr=i(bze),pE=n(bze,"LI",{});var Wqe=s(pE);N8e=n(Wqe,"STRONG",{});var w$t=s(N8e);eLr=r(w$t,"mobilebert"),w$t.forEach(t),oLr=r(Wqe," \u2014 "),xY=n(Wqe,"A",{href:!0});var A$t=s(xY);rLr=r(A$t,"TFMobileBertForNextSentencePrediction"),A$t.forEach(t),tLr=r(Wqe," (MobileBERT model)"),Wqe.forEach(t),bze.forEach(t),aLr=i(Dl),T(_E.$$.fragment,Dl),Dl.forEach(t),jl.forEach(t),cVe=i(f),Lc=n(f,"H2",{class:!0});var vze=s(Lc);uE=n(vze,"A",{id:!0,class:!0,href:!0});var L$t=s(uE);q8e=n(L$t,"SPAN",{});var y$t=s(q8e);T(lx.$$.fragment,y$t),y$t.forEach(t),L$t.forEach(t),nLr=i(vze),j8e=n(vze,"SPAN",{});var x$t=s(j8e);sLr=r(x$t,"TFAutoModelForTableQuestionAnswering"),x$t.forEach(t),vze.forEach(t),fVe=i(f),dr=n(f,"DIV",{class:!0});var Gl=s(dr);T(ix.$$.fragment,Gl),lLr=i(Gl),yc=n(Gl,"P",{});var Sre=s(yc);iLr=r(Sre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a table question answering head) when created
with the `),$Y=n(Sre,"A",{href:!0});var $$t=s($Y);dLr=r($$t,"from_pretrained()"),$$t.forEach(t),cLr=r(Sre," class method or the "),kY=n(Sre,"A",{href:!0});var k$t=s(kY);fLr=r(k$t,"from_config()"),k$t.forEach(t),mLr=r(Sre,` class
method.`),Sre.forEach(t),gLr=i(Gl),dx=n(Gl,"P",{});var Fze=s(dx);hLr=r(Fze,"This class cannot be instantiated directly using "),D8e=n(Fze,"CODE",{});var S$t=s(D8e);pLr=r(S$t,"__init__()"),S$t.forEach(t),_Lr=r(Fze," (throws an error)."),Fze.forEach(t),uLr=i(Gl),jt=n(Gl,"DIV",{class:!0});var z0=s(jt);T(cx.$$.fragment,z0),bLr=i(z0),G8e=n(z0,"P",{});var R$t=s(G8e);vLr=r(R$t,"Instantiates one of the model classes of the library (with a table question answering head) from a configuration."),R$t.forEach(t),FLr=i(z0),xc=n(z0,"P",{});var Rre=s(xc);TLr=r(Rre,`Note:
Loading a model from its configuration file does `),O8e=n(Rre,"STRONG",{});var P$t=s(O8e);MLr=r(P$t,"not"),P$t.forEach(t),ELr=r(Rre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SY=n(Rre,"A",{href:!0});var B$t=s(SY);CLr=r(B$t,"from_pretrained()"),B$t.forEach(t),wLr=r(Rre," to load the model weights."),Rre.forEach(t),ALr=i(z0),T(bE.$$.fragment,z0),z0.forEach(t),LLr=i(Gl),Nr=n(Gl,"DIV",{class:!0});var Ol=s(Nr);T(fx.$$.fragment,Ol),yLr=i(Ol),V8e=n(Ol,"P",{});var I$t=s(V8e);xLr=r(I$t,"Instantiate one of the model classes of the library (with a table question answering head) from a pretrained model."),I$t.forEach(t),$Lr=i(Ol),pn=n(Ol,"P",{});var Q0=s(pn);kLr=r(Q0,"The model class to instantiate is selected based on the "),X8e=n(Q0,"CODE",{});var N$t=s(X8e);SLr=r(N$t,"model_type"),N$t.forEach(t),RLr=r(Q0,` property of the config object (either
passed as an argument or loaded from `),z8e=n(Q0,"CODE",{});var q$t=s(z8e);PLr=r(q$t,"pretrained_model_name_or_path"),q$t.forEach(t),BLr=r(Q0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),Q8e=n(Q0,"CODE",{});var j$t=s(Q8e);ILr=r(j$t,"pretrained_model_name_or_path"),j$t.forEach(t),NLr=r(Q0,":"),Q0.forEach(t),qLr=i(Ol),W8e=n(Ol,"UL",{});var D$t=s(W8e);vE=n(D$t,"LI",{});var Hqe=s(vE);H8e=n(Hqe,"STRONG",{});var G$t=s(H8e);jLr=r(G$t,"tapas"),G$t.forEach(t),DLr=r(Hqe," \u2014 "),RY=n(Hqe,"A",{href:!0});var O$t=s(RY);GLr=r(O$t,"TFTapasForQuestionAnswering"),O$t.forEach(t),OLr=r(Hqe," (TAPAS model)"),Hqe.forEach(t),D$t.forEach(t),VLr=i(Ol),T(FE.$$.fragment,Ol),Ol.forEach(t),Gl.forEach(t),mVe=i(f),$c=n(f,"H2",{class:!0});var Tze=s($c);TE=n(Tze,"A",{id:!0,class:!0,href:!0});var V$t=s(TE);U8e=n(V$t,"SPAN",{});var X$t=s(U8e);T(mx.$$.fragment,X$t),X$t.forEach(t),V$t.forEach(t),XLr=i(Tze),J8e=n(Tze,"SPAN",{});var z$t=s(J8e);zLr=r(z$t,"TFAutoModelForTokenClassification"),z$t.forEach(t),Tze.forEach(t),gVe=i(f),cr=n(f,"DIV",{class:!0});var Vl=s(cr);T(gx.$$.fragment,Vl),QLr=i(Vl),kc=n(Vl,"P",{});var Pre=s(kc);WLr=r(Pre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),PY=n(Pre,"A",{href:!0});var Q$t=s(PY);HLr=r(Q$t,"from_pretrained()"),Q$t.forEach(t),ULr=r(Pre," class method or the "),BY=n(Pre,"A",{href:!0});var W$t=s(BY);JLr=r(W$t,"from_config()"),W$t.forEach(t),YLr=r(Pre,` class
method.`),Pre.forEach(t),KLr=i(Vl),hx=n(Vl,"P",{});var Mze=s(hx);ZLr=r(Mze,"This class cannot be instantiated directly using "),Y8e=n(Mze,"CODE",{});var H$t=s(Y8e);eyr=r(H$t,"__init__()"),H$t.forEach(t),oyr=r(Mze," (throws an error)."),Mze.forEach(t),ryr=i(Vl),Dt=n(Vl,"DIV",{class:!0});var W0=s(Dt);T(px.$$.fragment,W0),tyr=i(W0),K8e=n(W0,"P",{});var U$t=s(K8e);ayr=r(U$t,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),U$t.forEach(t),nyr=i(W0),Sc=n(W0,"P",{});var Bre=s(Sc);syr=r(Bre,`Note:
Loading a model from its configuration file does `),Z8e=n(Bre,"STRONG",{});var J$t=s(Z8e);lyr=r(J$t,"not"),J$t.forEach(t),iyr=r(Bre,` load the model weights. It only affects the
model\u2019s configuration. Use `),IY=n(Bre,"A",{href:!0});var Y$t=s(IY);dyr=r(Y$t,"from_pretrained()"),Y$t.forEach(t),cyr=r(Bre," to load the model weights."),Bre.forEach(t),fyr=i(W0),T(ME.$$.fragment,W0),W0.forEach(t),myr=i(Vl),qr=n(Vl,"DIV",{class:!0});var Xl=s(qr);T(_x.$$.fragment,Xl),gyr=i(Xl),e9e=n(Xl,"P",{});var K$t=s(e9e);hyr=r(K$t,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),K$t.forEach(t),pyr=i(Xl),_n=n(Xl,"P",{});var H0=s(_n);_yr=r(H0,"The model class to instantiate is selected based on the "),o9e=n(H0,"CODE",{});var Z$t=s(o9e);uyr=r(Z$t,"model_type"),Z$t.forEach(t),byr=r(H0,` property of the config object (either
passed as an argument or loaded from `),r9e=n(H0,"CODE",{});var ekt=s(r9e);vyr=r(ekt,"pretrained_model_name_or_path"),ekt.forEach(t),Fyr=r(H0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),t9e=n(H0,"CODE",{});var okt=s(t9e);Tyr=r(okt,"pretrained_model_name_or_path"),okt.forEach(t),Myr=r(H0,":"),H0.forEach(t),Eyr=i(Xl),de=n(Xl,"UL",{});var me=s(de);EE=n(me,"LI",{});var Uqe=s(EE);a9e=n(Uqe,"STRONG",{});var rkt=s(a9e);Cyr=r(rkt,"albert"),rkt.forEach(t),wyr=r(Uqe," \u2014 "),NY=n(Uqe,"A",{href:!0});var tkt=s(NY);Ayr=r(tkt,"TFAlbertForTokenClassification"),tkt.forEach(t),Lyr=r(Uqe," (ALBERT model)"),Uqe.forEach(t),yyr=i(me),CE=n(me,"LI",{});var Jqe=s(CE);n9e=n(Jqe,"STRONG",{});var akt=s(n9e);xyr=r(akt,"bert"),akt.forEach(t),$yr=r(Jqe," \u2014 "),qY=n(Jqe,"A",{href:!0});var nkt=s(qY);kyr=r(nkt,"TFBertForTokenClassification"),nkt.forEach(t),Syr=r(Jqe," (BERT model)"),Jqe.forEach(t),Ryr=i(me),wE=n(me,"LI",{});var Yqe=s(wE);s9e=n(Yqe,"STRONG",{});var skt=s(s9e);Pyr=r(skt,"camembert"),skt.forEach(t),Byr=r(Yqe," \u2014 "),jY=n(Yqe,"A",{href:!0});var lkt=s(jY);Iyr=r(lkt,"TFCamembertForTokenClassification"),lkt.forEach(t),Nyr=r(Yqe," (CamemBERT model)"),Yqe.forEach(t),qyr=i(me),AE=n(me,"LI",{});var Kqe=s(AE);l9e=n(Kqe,"STRONG",{});var ikt=s(l9e);jyr=r(ikt,"convbert"),ikt.forEach(t),Dyr=r(Kqe," \u2014 "),DY=n(Kqe,"A",{href:!0});var dkt=s(DY);Gyr=r(dkt,"TFConvBertForTokenClassification"),dkt.forEach(t),Oyr=r(Kqe," (ConvBERT model)"),Kqe.forEach(t),Vyr=i(me),LE=n(me,"LI",{});var Zqe=s(LE);i9e=n(Zqe,"STRONG",{});var ckt=s(i9e);Xyr=r(ckt,"deberta"),ckt.forEach(t),zyr=r(Zqe," \u2014 "),GY=n(Zqe,"A",{href:!0});var fkt=s(GY);Qyr=r(fkt,"TFDebertaForTokenClassification"),fkt.forEach(t),Wyr=r(Zqe," (DeBERTa model)"),Zqe.forEach(t),Hyr=i(me),yE=n(me,"LI",{});var eje=s(yE);d9e=n(eje,"STRONG",{});var mkt=s(d9e);Uyr=r(mkt,"deberta-v2"),mkt.forEach(t),Jyr=r(eje," \u2014 "),OY=n(eje,"A",{href:!0});var gkt=s(OY);Yyr=r(gkt,"TFDebertaV2ForTokenClassification"),gkt.forEach(t),Kyr=r(eje," (DeBERTa-v2 model)"),eje.forEach(t),Zyr=i(me),xE=n(me,"LI",{});var oje=s(xE);c9e=n(oje,"STRONG",{});var hkt=s(c9e);exr=r(hkt,"distilbert"),hkt.forEach(t),oxr=r(oje," \u2014 "),VY=n(oje,"A",{href:!0});var pkt=s(VY);rxr=r(pkt,"TFDistilBertForTokenClassification"),pkt.forEach(t),txr=r(oje," (DistilBERT model)"),oje.forEach(t),axr=i(me),$E=n(me,"LI",{});var rje=s($E);f9e=n(rje,"STRONG",{});var _kt=s(f9e);nxr=r(_kt,"electra"),_kt.forEach(t),sxr=r(rje," \u2014 "),XY=n(rje,"A",{href:!0});var ukt=s(XY);lxr=r(ukt,"TFElectraForTokenClassification"),ukt.forEach(t),ixr=r(rje," (ELECTRA model)"),rje.forEach(t),dxr=i(me),kE=n(me,"LI",{});var tje=s(kE);m9e=n(tje,"STRONG",{});var bkt=s(m9e);cxr=r(bkt,"flaubert"),bkt.forEach(t),fxr=r(tje," \u2014 "),zY=n(tje,"A",{href:!0});var vkt=s(zY);mxr=r(vkt,"TFFlaubertForTokenClassification"),vkt.forEach(t),gxr=r(tje," (FlauBERT model)"),tje.forEach(t),hxr=i(me),SE=n(me,"LI",{});var aje=s(SE);g9e=n(aje,"STRONG",{});var Fkt=s(g9e);pxr=r(Fkt,"funnel"),Fkt.forEach(t),_xr=r(aje," \u2014 "),QY=n(aje,"A",{href:!0});var Tkt=s(QY);uxr=r(Tkt,"TFFunnelForTokenClassification"),Tkt.forEach(t),bxr=r(aje," (Funnel Transformer model)"),aje.forEach(t),vxr=i(me),RE=n(me,"LI",{});var nje=s(RE);h9e=n(nje,"STRONG",{});var Mkt=s(h9e);Fxr=r(Mkt,"layoutlm"),Mkt.forEach(t),Txr=r(nje," \u2014 "),WY=n(nje,"A",{href:!0});var Ekt=s(WY);Mxr=r(Ekt,"TFLayoutLMForTokenClassification"),Ekt.forEach(t),Exr=r(nje," (LayoutLM model)"),nje.forEach(t),Cxr=i(me),PE=n(me,"LI",{});var sje=s(PE);p9e=n(sje,"STRONG",{});var Ckt=s(p9e);wxr=r(Ckt,"longformer"),Ckt.forEach(t),Axr=r(sje," \u2014 "),HY=n(sje,"A",{href:!0});var wkt=s(HY);Lxr=r(wkt,"TFLongformerForTokenClassification"),wkt.forEach(t),yxr=r(sje," (Longformer model)"),sje.forEach(t),xxr=i(me),BE=n(me,"LI",{});var lje=s(BE);_9e=n(lje,"STRONG",{});var Akt=s(_9e);$xr=r(Akt,"mobilebert"),Akt.forEach(t),kxr=r(lje," \u2014 "),UY=n(lje,"A",{href:!0});var Lkt=s(UY);Sxr=r(Lkt,"TFMobileBertForTokenClassification"),Lkt.forEach(t),Rxr=r(lje," (MobileBERT model)"),lje.forEach(t),Pxr=i(me),IE=n(me,"LI",{});var ije=s(IE);u9e=n(ije,"STRONG",{});var ykt=s(u9e);Bxr=r(ykt,"mpnet"),ykt.forEach(t),Ixr=r(ije," \u2014 "),JY=n(ije,"A",{href:!0});var xkt=s(JY);Nxr=r(xkt,"TFMPNetForTokenClassification"),xkt.forEach(t),qxr=r(ije," (MPNet model)"),ije.forEach(t),jxr=i(me),NE=n(me,"LI",{});var dje=s(NE);b9e=n(dje,"STRONG",{});var $kt=s(b9e);Dxr=r($kt,"rembert"),$kt.forEach(t),Gxr=r(dje," \u2014 "),YY=n(dje,"A",{href:!0});var kkt=s(YY);Oxr=r(kkt,"TFRemBertForTokenClassification"),kkt.forEach(t),Vxr=r(dje," (RemBERT model)"),dje.forEach(t),Xxr=i(me),qE=n(me,"LI",{});var cje=s(qE);v9e=n(cje,"STRONG",{});var Skt=s(v9e);zxr=r(Skt,"roberta"),Skt.forEach(t),Qxr=r(cje," \u2014 "),KY=n(cje,"A",{href:!0});var Rkt=s(KY);Wxr=r(Rkt,"TFRobertaForTokenClassification"),Rkt.forEach(t),Hxr=r(cje," (RoBERTa model)"),cje.forEach(t),Uxr=i(me),jE=n(me,"LI",{});var fje=s(jE);F9e=n(fje,"STRONG",{});var Pkt=s(F9e);Jxr=r(Pkt,"roformer"),Pkt.forEach(t),Yxr=r(fje," \u2014 "),ZY=n(fje,"A",{href:!0});var Bkt=s(ZY);Kxr=r(Bkt,"TFRoFormerForTokenClassification"),Bkt.forEach(t),Zxr=r(fje," (RoFormer model)"),fje.forEach(t),e$r=i(me),DE=n(me,"LI",{});var mje=s(DE);T9e=n(mje,"STRONG",{});var Ikt=s(T9e);o$r=r(Ikt,"xlm"),Ikt.forEach(t),r$r=r(mje," \u2014 "),eK=n(mje,"A",{href:!0});var Nkt=s(eK);t$r=r(Nkt,"TFXLMForTokenClassification"),Nkt.forEach(t),a$r=r(mje," (XLM model)"),mje.forEach(t),n$r=i(me),GE=n(me,"LI",{});var gje=s(GE);M9e=n(gje,"STRONG",{});var qkt=s(M9e);s$r=r(qkt,"xlm-roberta"),qkt.forEach(t),l$r=r(gje," \u2014 "),oK=n(gje,"A",{href:!0});var jkt=s(oK);i$r=r(jkt,"TFXLMRobertaForTokenClassification"),jkt.forEach(t),d$r=r(gje," (XLM-RoBERTa model)"),gje.forEach(t),c$r=i(me),OE=n(me,"LI",{});var hje=s(OE);E9e=n(hje,"STRONG",{});var Dkt=s(E9e);f$r=r(Dkt,"xlnet"),Dkt.forEach(t),m$r=r(hje," \u2014 "),rK=n(hje,"A",{href:!0});var Gkt=s(rK);g$r=r(Gkt,"TFXLNetForTokenClassification"),Gkt.forEach(t),h$r=r(hje," (XLNet model)"),hje.forEach(t),me.forEach(t),p$r=i(Xl),T(VE.$$.fragment,Xl),Xl.forEach(t),Vl.forEach(t),hVe=i(f),Rc=n(f,"H2",{class:!0});var Eze=s(Rc);XE=n(Eze,"A",{id:!0,class:!0,href:!0});var Okt=s(XE);C9e=n(Okt,"SPAN",{});var Vkt=s(C9e);T(ux.$$.fragment,Vkt),Vkt.forEach(t),Okt.forEach(t),_$r=i(Eze),w9e=n(Eze,"SPAN",{});var Xkt=s(w9e);u$r=r(Xkt,"TFAutoModelForQuestionAnswering"),Xkt.forEach(t),Eze.forEach(t),pVe=i(f),fr=n(f,"DIV",{class:!0});var zl=s(fr);T(bx.$$.fragment,zl),b$r=i(zl),Pc=n(zl,"P",{});var Ire=s(Pc);v$r=r(Ire,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),tK=n(Ire,"A",{href:!0});var zkt=s(tK);F$r=r(zkt,"from_pretrained()"),zkt.forEach(t),T$r=r(Ire," class method or the "),aK=n(Ire,"A",{href:!0});var Qkt=s(aK);M$r=r(Qkt,"from_config()"),Qkt.forEach(t),E$r=r(Ire,` class
method.`),Ire.forEach(t),C$r=i(zl),vx=n(zl,"P",{});var Cze=s(vx);w$r=r(Cze,"This class cannot be instantiated directly using "),A9e=n(Cze,"CODE",{});var Wkt=s(A9e);A$r=r(Wkt,"__init__()"),Wkt.forEach(t),L$r=r(Cze," (throws an error)."),Cze.forEach(t),y$r=i(zl),Gt=n(zl,"DIV",{class:!0});var U0=s(Gt);T(Fx.$$.fragment,U0),x$r=i(U0),L9e=n(U0,"P",{});var Hkt=s(L9e);$$r=r(Hkt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),Hkt.forEach(t),k$r=i(U0),Bc=n(U0,"P",{});var Nre=s(Bc);S$r=r(Nre,`Note:
Loading a model from its configuration file does `),y9e=n(Nre,"STRONG",{});var Ukt=s(y9e);R$r=r(Ukt,"not"),Ukt.forEach(t),P$r=r(Nre,` load the model weights. It only affects the
model\u2019s configuration. Use `),nK=n(Nre,"A",{href:!0});var Jkt=s(nK);B$r=r(Jkt,"from_pretrained()"),Jkt.forEach(t),I$r=r(Nre," to load the model weights."),Nre.forEach(t),N$r=i(U0),T(zE.$$.fragment,U0),U0.forEach(t),q$r=i(zl),jr=n(zl,"DIV",{class:!0});var Ql=s(jr);T(Tx.$$.fragment,Ql),j$r=i(Ql),x9e=n(Ql,"P",{});var Ykt=s(x9e);D$r=r(Ykt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),Ykt.forEach(t),G$r=i(Ql),un=n(Ql,"P",{});var J0=s(un);O$r=r(J0,"The model class to instantiate is selected based on the "),$9e=n(J0,"CODE",{});var Kkt=s($9e);V$r=r(Kkt,"model_type"),Kkt.forEach(t),X$r=r(J0,` property of the config object (either
passed as an argument or loaded from `),k9e=n(J0,"CODE",{});var Zkt=s(k9e);z$r=r(Zkt,"pretrained_model_name_or_path"),Zkt.forEach(t),Q$r=r(J0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),S9e=n(J0,"CODE",{});var eSt=s(S9e);W$r=r(eSt,"pretrained_model_name_or_path"),eSt.forEach(t),H$r=r(J0,":"),J0.forEach(t),U$r=i(Ql),ce=n(Ql,"UL",{});var ge=s(ce);QE=n(ge,"LI",{});var pje=s(QE);R9e=n(pje,"STRONG",{});var oSt=s(R9e);J$r=r(oSt,"albert"),oSt.forEach(t),Y$r=r(pje," \u2014 "),sK=n(pje,"A",{href:!0});var rSt=s(sK);K$r=r(rSt,"TFAlbertForQuestionAnswering"),rSt.forEach(t),Z$r=r(pje," (ALBERT model)"),pje.forEach(t),ekr=i(ge),WE=n(ge,"LI",{});var _je=s(WE);P9e=n(_je,"STRONG",{});var tSt=s(P9e);okr=r(tSt,"bert"),tSt.forEach(t),rkr=r(_je," \u2014 "),lK=n(_je,"A",{href:!0});var aSt=s(lK);tkr=r(aSt,"TFBertForQuestionAnswering"),aSt.forEach(t),akr=r(_je," (BERT model)"),_je.forEach(t),nkr=i(ge),HE=n(ge,"LI",{});var uje=s(HE);B9e=n(uje,"STRONG",{});var nSt=s(B9e);skr=r(nSt,"camembert"),nSt.forEach(t),lkr=r(uje," \u2014 "),iK=n(uje,"A",{href:!0});var sSt=s(iK);ikr=r(sSt,"TFCamembertForQuestionAnswering"),sSt.forEach(t),dkr=r(uje," (CamemBERT model)"),uje.forEach(t),ckr=i(ge),UE=n(ge,"LI",{});var bje=s(UE);I9e=n(bje,"STRONG",{});var lSt=s(I9e);fkr=r(lSt,"convbert"),lSt.forEach(t),mkr=r(bje," \u2014 "),dK=n(bje,"A",{href:!0});var iSt=s(dK);gkr=r(iSt,"TFConvBertForQuestionAnswering"),iSt.forEach(t),hkr=r(bje," (ConvBERT model)"),bje.forEach(t),pkr=i(ge),JE=n(ge,"LI",{});var vje=s(JE);N9e=n(vje,"STRONG",{});var dSt=s(N9e);_kr=r(dSt,"deberta"),dSt.forEach(t),ukr=r(vje," \u2014 "),cK=n(vje,"A",{href:!0});var cSt=s(cK);bkr=r(cSt,"TFDebertaForQuestionAnswering"),cSt.forEach(t),vkr=r(vje," (DeBERTa model)"),vje.forEach(t),Fkr=i(ge),YE=n(ge,"LI",{});var Fje=s(YE);q9e=n(Fje,"STRONG",{});var fSt=s(q9e);Tkr=r(fSt,"deberta-v2"),fSt.forEach(t),Mkr=r(Fje," \u2014 "),fK=n(Fje,"A",{href:!0});var mSt=s(fK);Ekr=r(mSt,"TFDebertaV2ForQuestionAnswering"),mSt.forEach(t),Ckr=r(Fje," (DeBERTa-v2 model)"),Fje.forEach(t),wkr=i(ge),KE=n(ge,"LI",{});var Tje=s(KE);j9e=n(Tje,"STRONG",{});var gSt=s(j9e);Akr=r(gSt,"distilbert"),gSt.forEach(t),Lkr=r(Tje," \u2014 "),mK=n(Tje,"A",{href:!0});var hSt=s(mK);ykr=r(hSt,"TFDistilBertForQuestionAnswering"),hSt.forEach(t),xkr=r(Tje," (DistilBERT model)"),Tje.forEach(t),$kr=i(ge),ZE=n(ge,"LI",{});var Mje=s(ZE);D9e=n(Mje,"STRONG",{});var pSt=s(D9e);kkr=r(pSt,"electra"),pSt.forEach(t),Skr=r(Mje," \u2014 "),gK=n(Mje,"A",{href:!0});var _St=s(gK);Rkr=r(_St,"TFElectraForQuestionAnswering"),_St.forEach(t),Pkr=r(Mje," (ELECTRA model)"),Mje.forEach(t),Bkr=i(ge),e4=n(ge,"LI",{});var Eje=s(e4);G9e=n(Eje,"STRONG",{});var uSt=s(G9e);Ikr=r(uSt,"flaubert"),uSt.forEach(t),Nkr=r(Eje," \u2014 "),hK=n(Eje,"A",{href:!0});var bSt=s(hK);qkr=r(bSt,"TFFlaubertForQuestionAnsweringSimple"),bSt.forEach(t),jkr=r(Eje," (FlauBERT model)"),Eje.forEach(t),Dkr=i(ge),o4=n(ge,"LI",{});var Cje=s(o4);O9e=n(Cje,"STRONG",{});var vSt=s(O9e);Gkr=r(vSt,"funnel"),vSt.forEach(t),Okr=r(Cje," \u2014 "),pK=n(Cje,"A",{href:!0});var FSt=s(pK);Vkr=r(FSt,"TFFunnelForQuestionAnswering"),FSt.forEach(t),Xkr=r(Cje," (Funnel Transformer model)"),Cje.forEach(t),zkr=i(ge),r4=n(ge,"LI",{});var wje=s(r4);V9e=n(wje,"STRONG",{});var TSt=s(V9e);Qkr=r(TSt,"gptj"),TSt.forEach(t),Wkr=r(wje," \u2014 "),_K=n(wje,"A",{href:!0});var MSt=s(_K);Hkr=r(MSt,"TFGPTJForQuestionAnswering"),MSt.forEach(t),Ukr=r(wje," (GPT-J model)"),wje.forEach(t),Jkr=i(ge),t4=n(ge,"LI",{});var Aje=s(t4);X9e=n(Aje,"STRONG",{});var ESt=s(X9e);Ykr=r(ESt,"longformer"),ESt.forEach(t),Kkr=r(Aje," \u2014 "),uK=n(Aje,"A",{href:!0});var CSt=s(uK);Zkr=r(CSt,"TFLongformerForQuestionAnswering"),CSt.forEach(t),eSr=r(Aje," (Longformer model)"),Aje.forEach(t),oSr=i(ge),a4=n(ge,"LI",{});var Lje=s(a4);z9e=n(Lje,"STRONG",{});var wSt=s(z9e);rSr=r(wSt,"mobilebert"),wSt.forEach(t),tSr=r(Lje," \u2014 "),bK=n(Lje,"A",{href:!0});var ASt=s(bK);aSr=r(ASt,"TFMobileBertForQuestionAnswering"),ASt.forEach(t),nSr=r(Lje," (MobileBERT model)"),Lje.forEach(t),sSr=i(ge),n4=n(ge,"LI",{});var yje=s(n4);Q9e=n(yje,"STRONG",{});var LSt=s(Q9e);lSr=r(LSt,"mpnet"),LSt.forEach(t),iSr=r(yje," \u2014 "),vK=n(yje,"A",{href:!0});var ySt=s(vK);dSr=r(ySt,"TFMPNetForQuestionAnswering"),ySt.forEach(t),cSr=r(yje," (MPNet model)"),yje.forEach(t),fSr=i(ge),s4=n(ge,"LI",{});var xje=s(s4);W9e=n(xje,"STRONG",{});var xSt=s(W9e);mSr=r(xSt,"rembert"),xSt.forEach(t),gSr=r(xje," \u2014 "),FK=n(xje,"A",{href:!0});var $St=s(FK);hSr=r($St,"TFRemBertForQuestionAnswering"),$St.forEach(t),pSr=r(xje," (RemBERT model)"),xje.forEach(t),_Sr=i(ge),l4=n(ge,"LI",{});var $je=s(l4);H9e=n($je,"STRONG",{});var kSt=s(H9e);uSr=r(kSt,"roberta"),kSt.forEach(t),bSr=r($je," \u2014 "),TK=n($je,"A",{href:!0});var SSt=s(TK);vSr=r(SSt,"TFRobertaForQuestionAnswering"),SSt.forEach(t),FSr=r($je," (RoBERTa model)"),$je.forEach(t),TSr=i(ge),i4=n(ge,"LI",{});var kje=s(i4);U9e=n(kje,"STRONG",{});var RSt=s(U9e);MSr=r(RSt,"roformer"),RSt.forEach(t),ESr=r(kje," \u2014 "),MK=n(kje,"A",{href:!0});var PSt=s(MK);CSr=r(PSt,"TFRoFormerForQuestionAnswering"),PSt.forEach(t),wSr=r(kje," (RoFormer model)"),kje.forEach(t),ASr=i(ge),d4=n(ge,"LI",{});var Sje=s(d4);J9e=n(Sje,"STRONG",{});var BSt=s(J9e);LSr=r(BSt,"xlm"),BSt.forEach(t),ySr=r(Sje," \u2014 "),EK=n(Sje,"A",{href:!0});var ISt=s(EK);xSr=r(ISt,"TFXLMForQuestionAnsweringSimple"),ISt.forEach(t),$Sr=r(Sje," (XLM model)"),Sje.forEach(t),kSr=i(ge),c4=n(ge,"LI",{});var Rje=s(c4);Y9e=n(Rje,"STRONG",{});var NSt=s(Y9e);SSr=r(NSt,"xlm-roberta"),NSt.forEach(t),RSr=r(Rje," \u2014 "),CK=n(Rje,"A",{href:!0});var qSt=s(CK);PSr=r(qSt,"TFXLMRobertaForQuestionAnswering"),qSt.forEach(t),BSr=r(Rje," (XLM-RoBERTa model)"),Rje.forEach(t),ISr=i(ge),f4=n(ge,"LI",{});var Pje=s(f4);K9e=n(Pje,"STRONG",{});var jSt=s(K9e);NSr=r(jSt,"xlnet"),jSt.forEach(t),qSr=r(Pje," \u2014 "),wK=n(Pje,"A",{href:!0});var DSt=s(wK);jSr=r(DSt,"TFXLNetForQuestionAnsweringSimple"),DSt.forEach(t),DSr=r(Pje," (XLNet model)"),Pje.forEach(t),ge.forEach(t),GSr=i(Ql),T(m4.$$.fragment,Ql),Ql.forEach(t),zl.forEach(t),_Ve=i(f),Ic=n(f,"H2",{class:!0});var wze=s(Ic);g4=n(wze,"A",{id:!0,class:!0,href:!0});var GSt=s(g4);Z9e=n(GSt,"SPAN",{});var OSt=s(Z9e);T(Mx.$$.fragment,OSt),OSt.forEach(t),GSt.forEach(t),OSr=i(wze),eMe=n(wze,"SPAN",{});var VSt=s(eMe);VSr=r(VSt,"TFAutoModelForVision2Seq"),VSt.forEach(t),wze.forEach(t),uVe=i(f),mr=n(f,"DIV",{class:!0});var Wl=s(mr);T(Ex.$$.fragment,Wl),XSr=i(Wl),Nc=n(Wl,"P",{});var qre=s(Nc);zSr=r(qre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),AK=n(qre,"A",{href:!0});var XSt=s(AK);QSr=r(XSt,"from_pretrained()"),XSt.forEach(t),WSr=r(qre," class method or the "),LK=n(qre,"A",{href:!0});var zSt=s(LK);HSr=r(zSt,"from_config()"),zSt.forEach(t),USr=r(qre,` class
method.`),qre.forEach(t),JSr=i(Wl),Cx=n(Wl,"P",{});var Aze=s(Cx);YSr=r(Aze,"This class cannot be instantiated directly using "),oMe=n(Aze,"CODE",{});var QSt=s(oMe);KSr=r(QSt,"__init__()"),QSt.forEach(t),ZSr=r(Aze," (throws an error)."),Aze.forEach(t),eRr=i(Wl),Ot=n(Wl,"DIV",{class:!0});var Y0=s(Ot);T(wx.$$.fragment,Y0),oRr=i(Y0),rMe=n(Y0,"P",{});var WSt=s(rMe);rRr=r(WSt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),WSt.forEach(t),tRr=i(Y0),qc=n(Y0,"P",{});var jre=s(qc);aRr=r(jre,`Note:
Loading a model from its configuration file does `),tMe=n(jre,"STRONG",{});var HSt=s(tMe);nRr=r(HSt,"not"),HSt.forEach(t),sRr=r(jre,` load the model weights. It only affects the
model\u2019s configuration. Use `),yK=n(jre,"A",{href:!0});var USt=s(yK);lRr=r(USt,"from_pretrained()"),USt.forEach(t),iRr=r(jre," to load the model weights."),jre.forEach(t),dRr=i(Y0),T(h4.$$.fragment,Y0),Y0.forEach(t),cRr=i(Wl),Dr=n(Wl,"DIV",{class:!0});var Hl=s(Dr);T(Ax.$$.fragment,Hl),fRr=i(Hl),aMe=n(Hl,"P",{});var JSt=s(aMe);mRr=r(JSt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),JSt.forEach(t),gRr=i(Hl),bn=n(Hl,"P",{});var K0=s(bn);hRr=r(K0,"The model class to instantiate is selected based on the "),nMe=n(K0,"CODE",{});var YSt=s(nMe);pRr=r(YSt,"model_type"),YSt.forEach(t),_Rr=r(K0,` property of the config object (either
passed as an argument or loaded from `),sMe=n(K0,"CODE",{});var KSt=s(sMe);uRr=r(KSt,"pretrained_model_name_or_path"),KSt.forEach(t),bRr=r(K0,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),lMe=n(K0,"CODE",{});var ZSt=s(lMe);vRr=r(ZSt,"pretrained_model_name_or_path"),ZSt.forEach(t),FRr=r(K0,":"),K0.forEach(t),TRr=i(Hl),iMe=n(Hl,"UL",{});var eRt=s(iMe);p4=n(eRt,"LI",{});var Bje=s(p4);dMe=n(Bje,"STRONG",{});var oRt=s(dMe);MRr=r(oRt,"vision-encoder-decoder"),oRt.forEach(t),ERr=r(Bje," \u2014 "),xK=n(Bje,"A",{href:!0});var rRt=s(xK);CRr=r(rRt,"TFVisionEncoderDecoderModel"),rRt.forEach(t),wRr=r(Bje," (Vision Encoder decoder model)"),Bje.forEach(t),eRt.forEach(t),ARr=i(Hl),T(_4.$$.fragment,Hl),Hl.forEach(t),Wl.forEach(t),bVe=i(f),jc=n(f,"H2",{class:!0});var Lze=s(jc);u4=n(Lze,"A",{id:!0,class:!0,href:!0});var tRt=s(u4);cMe=n(tRt,"SPAN",{});var aRt=s(cMe);T(Lx.$$.fragment,aRt),aRt.forEach(t),tRt.forEach(t),LRr=i(Lze),fMe=n(Lze,"SPAN",{});var nRt=s(fMe);yRr=r(nRt,"TFAutoModelForSpeechSeq2Seq"),nRt.forEach(t),Lze.forEach(t),vVe=i(f),gr=n(f,"DIV",{class:!0});var Ul=s(gr);T(yx.$$.fragment,Ul),xRr=i(Ul),Dc=n(Ul,"P",{});var Dre=s(Dc);$Rr=r(Dre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) when created
with the `),$K=n(Dre,"A",{href:!0});var sRt=s($K);kRr=r(sRt,"from_pretrained()"),sRt.forEach(t),SRr=r(Dre," class method or the "),kK=n(Dre,"A",{href:!0});var lRt=s(kK);RRr=r(lRt,"from_config()"),lRt.forEach(t),PRr=r(Dre,` class
method.`),Dre.forEach(t),BRr=i(Ul),xx=n(Ul,"P",{});var yze=s(xx);IRr=r(yze,"This class cannot be instantiated directly using "),mMe=n(yze,"CODE",{});var iRt=s(mMe);NRr=r(iRt,"__init__()"),iRt.forEach(t),qRr=r(yze," (throws an error)."),yze.forEach(t),jRr=i(Ul),Vt=n(Ul,"DIV",{class:!0});var Z0=s(Vt);T($x.$$.fragment,Z0),DRr=i(Z0),gMe=n(Z0,"P",{});var dRt=s(gMe);GRr=r(dRt,"Instantiates one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a configuration."),dRt.forEach(t),ORr=i(Z0),Gc=n(Z0,"P",{});var Gre=s(Gc);VRr=r(Gre,`Note:
Loading a model from its configuration file does `),hMe=n(Gre,"STRONG",{});var cRt=s(hMe);XRr=r(cRt,"not"),cRt.forEach(t),zRr=r(Gre,` load the model weights. It only affects the
model\u2019s configuration. Use `),SK=n(Gre,"A",{href:!0});var fRt=s(SK);QRr=r(fRt,"from_pretrained()"),fRt.forEach(t),WRr=r(Gre," to load the model weights."),Gre.forEach(t),HRr=i(Z0),T(b4.$$.fragment,Z0),Z0.forEach(t),URr=i(Ul),Gr=n(Ul,"DIV",{class:!0});var Jl=s(Gr);T(kx.$$.fragment,Jl),JRr=i(Jl),pMe=n(Jl,"P",{});var mRt=s(pMe);YRr=r(mRt,"Instantiate one of the model classes of the library (with a sequence-to-sequence speech-to-text modeling head) from a pretrained model."),mRt.forEach(t),KRr=i(Jl),vn=n(Jl,"P",{});var ew=s(vn);ZRr=r(ew,"The model class to instantiate is selected based on the "),_Me=n(ew,"CODE",{});var gRt=s(_Me);ePr=r(gRt,"model_type"),gRt.forEach(t),oPr=r(ew,` property of the config object (either
passed as an argument or loaded from `),uMe=n(ew,"CODE",{});var hRt=s(uMe);rPr=r(hRt,"pretrained_model_name_or_path"),hRt.forEach(t),tPr=r(ew,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),bMe=n(ew,"CODE",{});var pRt=s(bMe);aPr=r(pRt,"pretrained_model_name_or_path"),pRt.forEach(t),nPr=r(ew,":"),ew.forEach(t),sPr=i(Jl),vMe=n(Jl,"UL",{});var _Rt=s(vMe);v4=n(_Rt,"LI",{});var Ije=s(v4);FMe=n(Ije,"STRONG",{});var uRt=s(FMe);lPr=r(uRt,"speech_to_text"),uRt.forEach(t),iPr=r(Ije," \u2014 "),RK=n(Ije,"A",{href:!0});var bRt=s(RK);dPr=r(bRt,"TFSpeech2TextForConditionalGeneration"),bRt.forEach(t),cPr=r(Ije," (Speech2Text model)"),Ije.forEach(t),_Rt.forEach(t),fPr=i(Jl),T(F4.$$.fragment,Jl),Jl.forEach(t),Ul.forEach(t),FVe=i(f),Oc=n(f,"H2",{class:!0});var xze=s(Oc);T4=n(xze,"A",{id:!0,class:!0,href:!0});var vRt=s(T4);TMe=n(vRt,"SPAN",{});var FRt=s(TMe);T(Sx.$$.fragment,FRt),FRt.forEach(t),vRt.forEach(t),mPr=i(xze),MMe=n(xze,"SPAN",{});var TRt=s(MMe);gPr=r(TRt,"FlaxAutoModel"),TRt.forEach(t),xze.forEach(t),TVe=i(f),hr=n(f,"DIV",{class:!0});var Yl=s(hr);T(Rx.$$.fragment,Yl),hPr=i(Yl),Vc=n(Yl,"P",{});var Ore=s(Vc);pPr=r(Ore,`This is a generic model class that will be instantiated as one of the base model classes of the library when created
with the `),PK=n(Ore,"A",{href:!0});var MRt=s(PK);_Pr=r(MRt,"from_pretrained()"),MRt.forEach(t),uPr=r(Ore," class method or the "),BK=n(Ore,"A",{href:!0});var ERt=s(BK);bPr=r(ERt,"from_config()"),ERt.forEach(t),vPr=r(Ore,` class
method.`),Ore.forEach(t),FPr=i(Yl),Px=n(Yl,"P",{});var $ze=s(Px);TPr=r($ze,"This class cannot be instantiated directly using "),EMe=n($ze,"CODE",{});var CRt=s(EMe);MPr=r(CRt,"__init__()"),CRt.forEach(t),EPr=r($ze," (throws an error)."),$ze.forEach(t),CPr=i(Yl),Xt=n(Yl,"DIV",{class:!0});var ow=s(Xt);T(Bx.$$.fragment,ow),wPr=i(ow),CMe=n(ow,"P",{});var wRt=s(CMe);APr=r(wRt,"Instantiates one of the base model classes of the library from a configuration."),wRt.forEach(t),LPr=i(ow),Xc=n(ow,"P",{});var Vre=s(Xc);yPr=r(Vre,`Note:
Loading a model from its configuration file does `),wMe=n(Vre,"STRONG",{});var ARt=s(wMe);xPr=r(ARt,"not"),ARt.forEach(t),$Pr=r(Vre,` load the model weights. It only affects the
model\u2019s configuration. Use `),IK=n(Vre,"A",{href:!0});var LRt=s(IK);kPr=r(LRt,"from_pretrained()"),LRt.forEach(t),SPr=r(Vre," to load the model weights."),Vre.forEach(t),RPr=i(ow),T(M4.$$.fragment,ow),ow.forEach(t),PPr=i(Yl),Or=n(Yl,"DIV",{class:!0});var Kl=s(Or);T(Ix.$$.fragment,Kl),BPr=i(Kl),AMe=n(Kl,"P",{});var yRt=s(AMe);IPr=r(yRt,"Instantiate one of the base model classes of the library from a pretrained model."),yRt.forEach(t),NPr=i(Kl),Fn=n(Kl,"P",{});var rw=s(Fn);qPr=r(rw,"The model class to instantiate is selected based on the "),LMe=n(rw,"CODE",{});var xRt=s(LMe);jPr=r(xRt,"model_type"),xRt.forEach(t),DPr=r(rw,` property of the config object (either
passed as an argument or loaded from `),yMe=n(rw,"CODE",{});var $Rt=s(yMe);GPr=r($Rt,"pretrained_model_name_or_path"),$Rt.forEach(t),OPr=r(rw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),xMe=n(rw,"CODE",{});var kRt=s(xMe);VPr=r(kRt,"pretrained_model_name_or_path"),kRt.forEach(t),XPr=r(rw,":"),rw.forEach(t),zPr=i(Kl),oe=n(Kl,"UL",{});var ae=s(oe);E4=n(ae,"LI",{});var Nje=s(E4);$Me=n(Nje,"STRONG",{});var SRt=s($Me);QPr=r(SRt,"albert"),SRt.forEach(t),WPr=r(Nje," \u2014 "),NK=n(Nje,"A",{href:!0});var RRt=s(NK);HPr=r(RRt,"FlaxAlbertModel"),RRt.forEach(t),UPr=r(Nje," (ALBERT model)"),Nje.forEach(t),JPr=i(ae),C4=n(ae,"LI",{});var qje=s(C4);kMe=n(qje,"STRONG",{});var PRt=s(kMe);YPr=r(PRt,"bart"),PRt.forEach(t),KPr=r(qje," \u2014 "),qK=n(qje,"A",{href:!0});var BRt=s(qK);ZPr=r(BRt,"FlaxBartModel"),BRt.forEach(t),eBr=r(qje," (BART model)"),qje.forEach(t),oBr=i(ae),w4=n(ae,"LI",{});var jje=s(w4);SMe=n(jje,"STRONG",{});var IRt=s(SMe);rBr=r(IRt,"beit"),IRt.forEach(t),tBr=r(jje," \u2014 "),jK=n(jje,"A",{href:!0});var NRt=s(jK);aBr=r(NRt,"FlaxBeitModel"),NRt.forEach(t),nBr=r(jje," (BEiT model)"),jje.forEach(t),sBr=i(ae),A4=n(ae,"LI",{});var Dje=s(A4);RMe=n(Dje,"STRONG",{});var qRt=s(RMe);lBr=r(qRt,"bert"),qRt.forEach(t),iBr=r(Dje," \u2014 "),DK=n(Dje,"A",{href:!0});var jRt=s(DK);dBr=r(jRt,"FlaxBertModel"),jRt.forEach(t),cBr=r(Dje," (BERT model)"),Dje.forEach(t),fBr=i(ae),L4=n(ae,"LI",{});var Gje=s(L4);PMe=n(Gje,"STRONG",{});var DRt=s(PMe);mBr=r(DRt,"big_bird"),DRt.forEach(t),gBr=r(Gje," \u2014 "),GK=n(Gje,"A",{href:!0});var GRt=s(GK);hBr=r(GRt,"FlaxBigBirdModel"),GRt.forEach(t),pBr=r(Gje," (BigBird model)"),Gje.forEach(t),_Br=i(ae),y4=n(ae,"LI",{});var Oje=s(y4);BMe=n(Oje,"STRONG",{});var ORt=s(BMe);uBr=r(ORt,"blenderbot"),ORt.forEach(t),bBr=r(Oje," \u2014 "),OK=n(Oje,"A",{href:!0});var VRt=s(OK);vBr=r(VRt,"FlaxBlenderbotModel"),VRt.forEach(t),FBr=r(Oje," (Blenderbot model)"),Oje.forEach(t),TBr=i(ae),x4=n(ae,"LI",{});var Vje=s(x4);IMe=n(Vje,"STRONG",{});var XRt=s(IMe);MBr=r(XRt,"blenderbot-small"),XRt.forEach(t),EBr=r(Vje," \u2014 "),VK=n(Vje,"A",{href:!0});var zRt=s(VK);CBr=r(zRt,"FlaxBlenderbotSmallModel"),zRt.forEach(t),wBr=r(Vje," (BlenderbotSmall model)"),Vje.forEach(t),ABr=i(ae),$4=n(ae,"LI",{});var Xje=s($4);NMe=n(Xje,"STRONG",{});var QRt=s(NMe);LBr=r(QRt,"clip"),QRt.forEach(t),yBr=r(Xje," \u2014 "),XK=n(Xje,"A",{href:!0});var WRt=s(XK);xBr=r(WRt,"FlaxCLIPModel"),WRt.forEach(t),$Br=r(Xje," (CLIP model)"),Xje.forEach(t),kBr=i(ae),k4=n(ae,"LI",{});var zje=s(k4);qMe=n(zje,"STRONG",{});var HRt=s(qMe);SBr=r(HRt,"distilbert"),HRt.forEach(t),RBr=r(zje," \u2014 "),zK=n(zje,"A",{href:!0});var URt=s(zK);PBr=r(URt,"FlaxDistilBertModel"),URt.forEach(t),BBr=r(zje," (DistilBERT model)"),zje.forEach(t),IBr=i(ae),S4=n(ae,"LI",{});var Qje=s(S4);jMe=n(Qje,"STRONG",{});var JRt=s(jMe);NBr=r(JRt,"electra"),JRt.forEach(t),qBr=r(Qje," \u2014 "),QK=n(Qje,"A",{href:!0});var YRt=s(QK);jBr=r(YRt,"FlaxElectraModel"),YRt.forEach(t),DBr=r(Qje," (ELECTRA model)"),Qje.forEach(t),GBr=i(ae),R4=n(ae,"LI",{});var Wje=s(R4);DMe=n(Wje,"STRONG",{});var KRt=s(DMe);OBr=r(KRt,"gpt2"),KRt.forEach(t),VBr=r(Wje," \u2014 "),WK=n(Wje,"A",{href:!0});var ZRt=s(WK);XBr=r(ZRt,"FlaxGPT2Model"),ZRt.forEach(t),zBr=r(Wje," (OpenAI GPT-2 model)"),Wje.forEach(t),QBr=i(ae),P4=n(ae,"LI",{});var Hje=s(P4);GMe=n(Hje,"STRONG",{});var ePt=s(GMe);WBr=r(ePt,"gpt_neo"),ePt.forEach(t),HBr=r(Hje," \u2014 "),HK=n(Hje,"A",{href:!0});var oPt=s(HK);UBr=r(oPt,"FlaxGPTNeoModel"),oPt.forEach(t),JBr=r(Hje," (GPT Neo model)"),Hje.forEach(t),YBr=i(ae),B4=n(ae,"LI",{});var Uje=s(B4);OMe=n(Uje,"STRONG",{});var rPt=s(OMe);KBr=r(rPt,"gptj"),rPt.forEach(t),ZBr=r(Uje," \u2014 "),UK=n(Uje,"A",{href:!0});var tPt=s(UK);eIr=r(tPt,"FlaxGPTJModel"),tPt.forEach(t),oIr=r(Uje," (GPT-J model)"),Uje.forEach(t),rIr=i(ae),I4=n(ae,"LI",{});var Jje=s(I4);VMe=n(Jje,"STRONG",{});var aPt=s(VMe);tIr=r(aPt,"longt5"),aPt.forEach(t),aIr=r(Jje," \u2014 "),JK=n(Jje,"A",{href:!0});var nPt=s(JK);nIr=r(nPt,"FlaxLongT5Model"),nPt.forEach(t),sIr=r(Jje," (LongT5 model)"),Jje.forEach(t),lIr=i(ae),N4=n(ae,"LI",{});var Yje=s(N4);XMe=n(Yje,"STRONG",{});var sPt=s(XMe);iIr=r(sPt,"marian"),sPt.forEach(t),dIr=r(Yje," \u2014 "),YK=n(Yje,"A",{href:!0});var lPt=s(YK);cIr=r(lPt,"FlaxMarianModel"),lPt.forEach(t),fIr=r(Yje," (Marian model)"),Yje.forEach(t),mIr=i(ae),q4=n(ae,"LI",{});var Kje=s(q4);zMe=n(Kje,"STRONG",{});var iPt=s(zMe);gIr=r(iPt,"mbart"),iPt.forEach(t),hIr=r(Kje," \u2014 "),KK=n(Kje,"A",{href:!0});var dPt=s(KK);pIr=r(dPt,"FlaxMBartModel"),dPt.forEach(t),_Ir=r(Kje," (mBART model)"),Kje.forEach(t),uIr=i(ae),j4=n(ae,"LI",{});var Zje=s(j4);QMe=n(Zje,"STRONG",{});var cPt=s(QMe);bIr=r(cPt,"mt5"),cPt.forEach(t),vIr=r(Zje," \u2014 "),ZK=n(Zje,"A",{href:!0});var fPt=s(ZK);FIr=r(fPt,"FlaxMT5Model"),fPt.forEach(t),TIr=r(Zje," (MT5 model)"),Zje.forEach(t),MIr=i(ae),D4=n(ae,"LI",{});var eDe=s(D4);WMe=n(eDe,"STRONG",{});var mPt=s(WMe);EIr=r(mPt,"opt"),mPt.forEach(t),CIr=r(eDe," \u2014 "),eZ=n(eDe,"A",{href:!0});var gPt=s(eZ);wIr=r(gPt,"FlaxOPTModel"),gPt.forEach(t),AIr=r(eDe," (OPT model)"),eDe.forEach(t),LIr=i(ae),G4=n(ae,"LI",{});var oDe=s(G4);HMe=n(oDe,"STRONG",{});var hPt=s(HMe);yIr=r(hPt,"pegasus"),hPt.forEach(t),xIr=r(oDe," \u2014 "),oZ=n(oDe,"A",{href:!0});var pPt=s(oZ);$Ir=r(pPt,"FlaxPegasusModel"),pPt.forEach(t),kIr=r(oDe," (Pegasus model)"),oDe.forEach(t),SIr=i(ae),O4=n(ae,"LI",{});var rDe=s(O4);UMe=n(rDe,"STRONG",{});var _Pt=s(UMe);RIr=r(_Pt,"roberta"),_Pt.forEach(t),PIr=r(rDe," \u2014 "),rZ=n(rDe,"A",{href:!0});var uPt=s(rZ);BIr=r(uPt,"FlaxRobertaModel"),uPt.forEach(t),IIr=r(rDe," (RoBERTa model)"),rDe.forEach(t),NIr=i(ae),V4=n(ae,"LI",{});var tDe=s(V4);JMe=n(tDe,"STRONG",{});var bPt=s(JMe);qIr=r(bPt,"roformer"),bPt.forEach(t),jIr=r(tDe," \u2014 "),tZ=n(tDe,"A",{href:!0});var vPt=s(tZ);DIr=r(vPt,"FlaxRoFormerModel"),vPt.forEach(t),GIr=r(tDe," (RoFormer model)"),tDe.forEach(t),OIr=i(ae),X4=n(ae,"LI",{});var aDe=s(X4);YMe=n(aDe,"STRONG",{});var FPt=s(YMe);VIr=r(FPt,"t5"),FPt.forEach(t),XIr=r(aDe," \u2014 "),aZ=n(aDe,"A",{href:!0});var TPt=s(aZ);zIr=r(TPt,"FlaxT5Model"),TPt.forEach(t),QIr=r(aDe," (T5 model)"),aDe.forEach(t),WIr=i(ae),z4=n(ae,"LI",{});var nDe=s(z4);KMe=n(nDe,"STRONG",{});var MPt=s(KMe);HIr=r(MPt,"vision-text-dual-encoder"),MPt.forEach(t),UIr=r(nDe," \u2014 "),nZ=n(nDe,"A",{href:!0});var EPt=s(nZ);JIr=r(EPt,"FlaxVisionTextDualEncoderModel"),EPt.forEach(t),YIr=r(nDe," (VisionTextDualEncoder model)"),nDe.forEach(t),KIr=i(ae),Q4=n(ae,"LI",{});var sDe=s(Q4);ZMe=n(sDe,"STRONG",{});var CPt=s(ZMe);ZIr=r(CPt,"vit"),CPt.forEach(t),eNr=r(sDe," \u2014 "),sZ=n(sDe,"A",{href:!0});var wPt=s(sZ);oNr=r(wPt,"FlaxViTModel"),wPt.forEach(t),rNr=r(sDe," (ViT model)"),sDe.forEach(t),tNr=i(ae),W4=n(ae,"LI",{});var lDe=s(W4);eEe=n(lDe,"STRONG",{});var APt=s(eEe);aNr=r(APt,"wav2vec2"),APt.forEach(t),nNr=r(lDe," \u2014 "),lZ=n(lDe,"A",{href:!0});var LPt=s(lZ);sNr=r(LPt,"FlaxWav2Vec2Model"),LPt.forEach(t),lNr=r(lDe," (Wav2Vec2 model)"),lDe.forEach(t),iNr=i(ae),H4=n(ae,"LI",{});var iDe=s(H4);oEe=n(iDe,"STRONG",{});var yPt=s(oEe);dNr=r(yPt,"xglm"),yPt.forEach(t),cNr=r(iDe," \u2014 "),iZ=n(iDe,"A",{href:!0});var xPt=s(iZ);fNr=r(xPt,"FlaxXGLMModel"),xPt.forEach(t),mNr=r(iDe," (XGLM model)"),iDe.forEach(t),gNr=i(ae),U4=n(ae,"LI",{});var dDe=s(U4);rEe=n(dDe,"STRONG",{});var $Pt=s(rEe);hNr=r($Pt,"xlm-roberta"),$Pt.forEach(t),pNr=r(dDe," \u2014 "),dZ=n(dDe,"A",{href:!0});var kPt=s(dZ);_Nr=r(kPt,"FlaxXLMRobertaModel"),kPt.forEach(t),uNr=r(dDe," (XLM-RoBERTa model)"),dDe.forEach(t),ae.forEach(t),bNr=i(Kl),T(J4.$$.fragment,Kl),Kl.forEach(t),Yl.forEach(t),MVe=i(f),zc=n(f,"H2",{class:!0});var kze=s(zc);Y4=n(kze,"A",{id:!0,class:!0,href:!0});var SPt=s(Y4);tEe=n(SPt,"SPAN",{});var RPt=s(tEe);T(Nx.$$.fragment,RPt),RPt.forEach(t),SPt.forEach(t),vNr=i(kze),aEe=n(kze,"SPAN",{});var PPt=s(aEe);FNr=r(PPt,"FlaxAutoModelForCausalLM"),PPt.forEach(t),kze.forEach(t),EVe=i(f),pr=n(f,"DIV",{class:!0});var Zl=s(pr);T(qx.$$.fragment,Zl),TNr=i(Zl),Qc=n(Zl,"P",{});var Xre=s(Qc);MNr=r(Xre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a causal language modeling head) when created
with the `),cZ=n(Xre,"A",{href:!0});var BPt=s(cZ);ENr=r(BPt,"from_pretrained()"),BPt.forEach(t),CNr=r(Xre," class method or the "),fZ=n(Xre,"A",{href:!0});var IPt=s(fZ);wNr=r(IPt,"from_config()"),IPt.forEach(t),ANr=r(Xre,` class
method.`),Xre.forEach(t),LNr=i(Zl),jx=n(Zl,"P",{});var Sze=s(jx);yNr=r(Sze,"This class cannot be instantiated directly using "),nEe=n(Sze,"CODE",{});var NPt=s(nEe);xNr=r(NPt,"__init__()"),NPt.forEach(t),$Nr=r(Sze," (throws an error)."),Sze.forEach(t),kNr=i(Zl),zt=n(Zl,"DIV",{class:!0});var tw=s(zt);T(Dx.$$.fragment,tw),SNr=i(tw),sEe=n(tw,"P",{});var qPt=s(sEe);RNr=r(qPt,"Instantiates one of the model classes of the library (with a causal language modeling head) from a configuration."),qPt.forEach(t),PNr=i(tw),Wc=n(tw,"P",{});var zre=s(Wc);BNr=r(zre,`Note:
Loading a model from its configuration file does `),lEe=n(zre,"STRONG",{});var jPt=s(lEe);INr=r(jPt,"not"),jPt.forEach(t),NNr=r(zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),mZ=n(zre,"A",{href:!0});var DPt=s(mZ);qNr=r(DPt,"from_pretrained()"),DPt.forEach(t),jNr=r(zre," to load the model weights."),zre.forEach(t),DNr=i(tw),T(K4.$$.fragment,tw),tw.forEach(t),GNr=i(Zl),Vr=n(Zl,"DIV",{class:!0});var ei=s(Vr);T(Gx.$$.fragment,ei),ONr=i(ei),iEe=n(ei,"P",{});var GPt=s(iEe);VNr=r(GPt,"Instantiate one of the model classes of the library (with a causal language modeling head) from a pretrained model."),GPt.forEach(t),XNr=i(ei),Tn=n(ei,"P",{});var aw=s(Tn);zNr=r(aw,"The model class to instantiate is selected based on the "),dEe=n(aw,"CODE",{});var OPt=s(dEe);QNr=r(OPt,"model_type"),OPt.forEach(t),WNr=r(aw,` property of the config object (either
passed as an argument or loaded from `),cEe=n(aw,"CODE",{});var VPt=s(cEe);HNr=r(VPt,"pretrained_model_name_or_path"),VPt.forEach(t),UNr=r(aw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),fEe=n(aw,"CODE",{});var XPt=s(fEe);JNr=r(XPt,"pretrained_model_name_or_path"),XPt.forEach(t),YNr=r(aw,":"),aw.forEach(t),KNr=i(ei),xe=n(ei,"UL",{});var Ne=s(xe);Z4=n(Ne,"LI",{});var cDe=s(Z4);mEe=n(cDe,"STRONG",{});var zPt=s(mEe);ZNr=r(zPt,"bart"),zPt.forEach(t),eqr=r(cDe," \u2014 "),gZ=n(cDe,"A",{href:!0});var QPt=s(gZ);oqr=r(QPt,"FlaxBartForCausalLM"),QPt.forEach(t),rqr=r(cDe," (BART model)"),cDe.forEach(t),tqr=i(Ne),eC=n(Ne,"LI",{});var fDe=s(eC);gEe=n(fDe,"STRONG",{});var WPt=s(gEe);aqr=r(WPt,"bert"),WPt.forEach(t),nqr=r(fDe," \u2014 "),hZ=n(fDe,"A",{href:!0});var HPt=s(hZ);sqr=r(HPt,"FlaxBertForCausalLM"),HPt.forEach(t),lqr=r(fDe," (BERT model)"),fDe.forEach(t),iqr=i(Ne),oC=n(Ne,"LI",{});var mDe=s(oC);hEe=n(mDe,"STRONG",{});var UPt=s(hEe);dqr=r(UPt,"big_bird"),UPt.forEach(t),cqr=r(mDe," \u2014 "),pZ=n(mDe,"A",{href:!0});var JPt=s(pZ);fqr=r(JPt,"FlaxBigBirdForCausalLM"),JPt.forEach(t),mqr=r(mDe," (BigBird model)"),mDe.forEach(t),gqr=i(Ne),rC=n(Ne,"LI",{});var gDe=s(rC);pEe=n(gDe,"STRONG",{});var YPt=s(pEe);hqr=r(YPt,"electra"),YPt.forEach(t),pqr=r(gDe," \u2014 "),_Z=n(gDe,"A",{href:!0});var KPt=s(_Z);_qr=r(KPt,"FlaxElectraForCausalLM"),KPt.forEach(t),uqr=r(gDe," (ELECTRA model)"),gDe.forEach(t),bqr=i(Ne),tC=n(Ne,"LI",{});var hDe=s(tC);_Ee=n(hDe,"STRONG",{});var ZPt=s(_Ee);vqr=r(ZPt,"gpt2"),ZPt.forEach(t),Fqr=r(hDe," \u2014 "),uZ=n(hDe,"A",{href:!0});var eBt=s(uZ);Tqr=r(eBt,"FlaxGPT2LMHeadModel"),eBt.forEach(t),Mqr=r(hDe," (OpenAI GPT-2 model)"),hDe.forEach(t),Eqr=i(Ne),aC=n(Ne,"LI",{});var pDe=s(aC);uEe=n(pDe,"STRONG",{});var oBt=s(uEe);Cqr=r(oBt,"gpt_neo"),oBt.forEach(t),wqr=r(pDe," \u2014 "),bZ=n(pDe,"A",{href:!0});var rBt=s(bZ);Aqr=r(rBt,"FlaxGPTNeoForCausalLM"),rBt.forEach(t),Lqr=r(pDe," (GPT Neo model)"),pDe.forEach(t),yqr=i(Ne),nC=n(Ne,"LI",{});var _De=s(nC);bEe=n(_De,"STRONG",{});var tBt=s(bEe);xqr=r(tBt,"gptj"),tBt.forEach(t),$qr=r(_De," \u2014 "),vZ=n(_De,"A",{href:!0});var aBt=s(vZ);kqr=r(aBt,"FlaxGPTJForCausalLM"),aBt.forEach(t),Sqr=r(_De," (GPT-J model)"),_De.forEach(t),Rqr=i(Ne),sC=n(Ne,"LI",{});var uDe=s(sC);vEe=n(uDe,"STRONG",{});var nBt=s(vEe);Pqr=r(nBt,"opt"),nBt.forEach(t),Bqr=r(uDe," \u2014 "),FZ=n(uDe,"A",{href:!0});var sBt=s(FZ);Iqr=r(sBt,"FlaxOPTForCausalLM"),sBt.forEach(t),Nqr=r(uDe," (OPT model)"),uDe.forEach(t),qqr=i(Ne),lC=n(Ne,"LI",{});var bDe=s(lC);FEe=n(bDe,"STRONG",{});var lBt=s(FEe);jqr=r(lBt,"roberta"),lBt.forEach(t),Dqr=r(bDe," \u2014 "),TZ=n(bDe,"A",{href:!0});var iBt=s(TZ);Gqr=r(iBt,"FlaxRobertaForCausalLM"),iBt.forEach(t),Oqr=r(bDe," (RoBERTa model)"),bDe.forEach(t),Vqr=i(Ne),iC=n(Ne,"LI",{});var vDe=s(iC);TEe=n(vDe,"STRONG",{});var dBt=s(TEe);Xqr=r(dBt,"xglm"),dBt.forEach(t),zqr=r(vDe," \u2014 "),MZ=n(vDe,"A",{href:!0});var cBt=s(MZ);Qqr=r(cBt,"FlaxXGLMForCausalLM"),cBt.forEach(t),Wqr=r(vDe," (XGLM model)"),vDe.forEach(t),Ne.forEach(t),Hqr=i(ei),T(dC.$$.fragment,ei),ei.forEach(t),Zl.forEach(t),CVe=i(f),Hc=n(f,"H2",{class:!0});var Rze=s(Hc);cC=n(Rze,"A",{id:!0,class:!0,href:!0});var fBt=s(cC);MEe=n(fBt,"SPAN",{});var mBt=s(MEe);T(Ox.$$.fragment,mBt),mBt.forEach(t),fBt.forEach(t),Uqr=i(Rze),EEe=n(Rze,"SPAN",{});var gBt=s(EEe);Jqr=r(gBt,"FlaxAutoModelForPreTraining"),gBt.forEach(t),Rze.forEach(t),wVe=i(f),_r=n(f,"DIV",{class:!0});var oi=s(_r);T(Vx.$$.fragment,oi),Yqr=i(oi),Uc=n(oi,"P",{});var Qre=s(Uc);Kqr=r(Qre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a pretraining head) when created
with the `),EZ=n(Qre,"A",{href:!0});var hBt=s(EZ);Zqr=r(hBt,"from_pretrained()"),hBt.forEach(t),ejr=r(Qre," class method or the "),CZ=n(Qre,"A",{href:!0});var pBt=s(CZ);ojr=r(pBt,"from_config()"),pBt.forEach(t),rjr=r(Qre,` class
method.`),Qre.forEach(t),tjr=i(oi),Xx=n(oi,"P",{});var Pze=s(Xx);ajr=r(Pze,"This class cannot be instantiated directly using "),CEe=n(Pze,"CODE",{});var _Bt=s(CEe);njr=r(_Bt,"__init__()"),_Bt.forEach(t),sjr=r(Pze," (throws an error)."),Pze.forEach(t),ljr=i(oi),Qt=n(oi,"DIV",{class:!0});var nw=s(Qt);T(zx.$$.fragment,nw),ijr=i(nw),wEe=n(nw,"P",{});var uBt=s(wEe);djr=r(uBt,"Instantiates one of the model classes of the library (with a pretraining head) from a configuration."),uBt.forEach(t),cjr=i(nw),Jc=n(nw,"P",{});var Wre=s(Jc);fjr=r(Wre,`Note:
Loading a model from its configuration file does `),AEe=n(Wre,"STRONG",{});var bBt=s(AEe);mjr=r(bBt,"not"),bBt.forEach(t),gjr=r(Wre,` load the model weights. It only affects the
model\u2019s configuration. Use `),wZ=n(Wre,"A",{href:!0});var vBt=s(wZ);hjr=r(vBt,"from_pretrained()"),vBt.forEach(t),pjr=r(Wre," to load the model weights."),Wre.forEach(t),_jr=i(nw),T(fC.$$.fragment,nw),nw.forEach(t),ujr=i(oi),Xr=n(oi,"DIV",{class:!0});var ri=s(Xr);T(Qx.$$.fragment,ri),bjr=i(ri),LEe=n(ri,"P",{});var FBt=s(LEe);vjr=r(FBt,"Instantiate one of the model classes of the library (with a pretraining head) from a pretrained model."),FBt.forEach(t),Fjr=i(ri),Mn=n(ri,"P",{});var sw=s(Mn);Tjr=r(sw,"The model class to instantiate is selected based on the "),yEe=n(sw,"CODE",{});var TBt=s(yEe);Mjr=r(TBt,"model_type"),TBt.forEach(t),Ejr=r(sw,` property of the config object (either
passed as an argument or loaded from `),xEe=n(sw,"CODE",{});var MBt=s(xEe);Cjr=r(MBt,"pretrained_model_name_or_path"),MBt.forEach(t),wjr=r(sw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),$Ee=n(sw,"CODE",{});var EBt=s($Ee);Ajr=r(EBt,"pretrained_model_name_or_path"),EBt.forEach(t),Ljr=r(sw,":"),sw.forEach(t),yjr=i(ri),Ee=n(ri,"UL",{});var we=s(Ee);mC=n(we,"LI",{});var FDe=s(mC);kEe=n(FDe,"STRONG",{});var CBt=s(kEe);xjr=r(CBt,"albert"),CBt.forEach(t),$jr=r(FDe," \u2014 "),AZ=n(FDe,"A",{href:!0});var wBt=s(AZ);kjr=r(wBt,"FlaxAlbertForPreTraining"),wBt.forEach(t),Sjr=r(FDe," (ALBERT model)"),FDe.forEach(t),Rjr=i(we),gC=n(we,"LI",{});var TDe=s(gC);SEe=n(TDe,"STRONG",{});var ABt=s(SEe);Pjr=r(ABt,"bart"),ABt.forEach(t),Bjr=r(TDe," \u2014 "),LZ=n(TDe,"A",{href:!0});var LBt=s(LZ);Ijr=r(LBt,"FlaxBartForConditionalGeneration"),LBt.forEach(t),Njr=r(TDe," (BART model)"),TDe.forEach(t),qjr=i(we),hC=n(we,"LI",{});var MDe=s(hC);REe=n(MDe,"STRONG",{});var yBt=s(REe);jjr=r(yBt,"bert"),yBt.forEach(t),Djr=r(MDe," \u2014 "),yZ=n(MDe,"A",{href:!0});var xBt=s(yZ);Gjr=r(xBt,"FlaxBertForPreTraining"),xBt.forEach(t),Ojr=r(MDe," (BERT model)"),MDe.forEach(t),Vjr=i(we),pC=n(we,"LI",{});var EDe=s(pC);PEe=n(EDe,"STRONG",{});var $Bt=s(PEe);Xjr=r($Bt,"big_bird"),$Bt.forEach(t),zjr=r(EDe," \u2014 "),xZ=n(EDe,"A",{href:!0});var kBt=s(xZ);Qjr=r(kBt,"FlaxBigBirdForPreTraining"),kBt.forEach(t),Wjr=r(EDe," (BigBird model)"),EDe.forEach(t),Hjr=i(we),_C=n(we,"LI",{});var CDe=s(_C);BEe=n(CDe,"STRONG",{});var SBt=s(BEe);Ujr=r(SBt,"electra"),SBt.forEach(t),Jjr=r(CDe," \u2014 "),$Z=n(CDe,"A",{href:!0});var RBt=s($Z);Yjr=r(RBt,"FlaxElectraForPreTraining"),RBt.forEach(t),Kjr=r(CDe," (ELECTRA model)"),CDe.forEach(t),Zjr=i(we),uC=n(we,"LI",{});var wDe=s(uC);IEe=n(wDe,"STRONG",{});var PBt=s(IEe);eDr=r(PBt,"longt5"),PBt.forEach(t),oDr=r(wDe," \u2014 "),kZ=n(wDe,"A",{href:!0});var BBt=s(kZ);rDr=r(BBt,"FlaxLongT5ForConditionalGeneration"),BBt.forEach(t),tDr=r(wDe," (LongT5 model)"),wDe.forEach(t),aDr=i(we),bC=n(we,"LI",{});var ADe=s(bC);NEe=n(ADe,"STRONG",{});var IBt=s(NEe);nDr=r(IBt,"mbart"),IBt.forEach(t),sDr=r(ADe," \u2014 "),SZ=n(ADe,"A",{href:!0});var NBt=s(SZ);lDr=r(NBt,"FlaxMBartForConditionalGeneration"),NBt.forEach(t),iDr=r(ADe," (mBART model)"),ADe.forEach(t),dDr=i(we),vC=n(we,"LI",{});var LDe=s(vC);qEe=n(LDe,"STRONG",{});var qBt=s(qEe);cDr=r(qBt,"mt5"),qBt.forEach(t),fDr=r(LDe," \u2014 "),RZ=n(LDe,"A",{href:!0});var jBt=s(RZ);mDr=r(jBt,"FlaxMT5ForConditionalGeneration"),jBt.forEach(t),gDr=r(LDe," (MT5 model)"),LDe.forEach(t),hDr=i(we),FC=n(we,"LI",{});var yDe=s(FC);jEe=n(yDe,"STRONG",{});var DBt=s(jEe);pDr=r(DBt,"roberta"),DBt.forEach(t),_Dr=r(yDe," \u2014 "),PZ=n(yDe,"A",{href:!0});var GBt=s(PZ);uDr=r(GBt,"FlaxRobertaForMaskedLM"),GBt.forEach(t),bDr=r(yDe," (RoBERTa model)"),yDe.forEach(t),vDr=i(we),TC=n(we,"LI",{});var xDe=s(TC);DEe=n(xDe,"STRONG",{});var OBt=s(DEe);FDr=r(OBt,"roformer"),OBt.forEach(t),TDr=r(xDe," \u2014 "),BZ=n(xDe,"A",{href:!0});var VBt=s(BZ);MDr=r(VBt,"FlaxRoFormerForMaskedLM"),VBt.forEach(t),EDr=r(xDe," (RoFormer model)"),xDe.forEach(t),CDr=i(we),MC=n(we,"LI",{});var $De=s(MC);GEe=n($De,"STRONG",{});var XBt=s(GEe);wDr=r(XBt,"t5"),XBt.forEach(t),ADr=r($De," \u2014 "),IZ=n($De,"A",{href:!0});var zBt=s(IZ);LDr=r(zBt,"FlaxT5ForConditionalGeneration"),zBt.forEach(t),yDr=r($De," (T5 model)"),$De.forEach(t),xDr=i(we),EC=n(we,"LI",{});var kDe=s(EC);OEe=n(kDe,"STRONG",{});var QBt=s(OEe);$Dr=r(QBt,"wav2vec2"),QBt.forEach(t),kDr=r(kDe," \u2014 "),NZ=n(kDe,"A",{href:!0});var WBt=s(NZ);SDr=r(WBt,"FlaxWav2Vec2ForPreTraining"),WBt.forEach(t),RDr=r(kDe," (Wav2Vec2 model)"),kDe.forEach(t),PDr=i(we),CC=n(we,"LI",{});var SDe=s(CC);VEe=n(SDe,"STRONG",{});var HBt=s(VEe);BDr=r(HBt,"xlm-roberta"),HBt.forEach(t),IDr=r(SDe," \u2014 "),qZ=n(SDe,"A",{href:!0});var UBt=s(qZ);NDr=r(UBt,"FlaxXLMRobertaForMaskedLM"),UBt.forEach(t),qDr=r(SDe," (XLM-RoBERTa model)"),SDe.forEach(t),we.forEach(t),jDr=i(ri),T(wC.$$.fragment,ri),ri.forEach(t),oi.forEach(t),AVe=i(f),Yc=n(f,"H2",{class:!0});var Bze=s(Yc);AC=n(Bze,"A",{id:!0,class:!0,href:!0});var JBt=s(AC);XEe=n(JBt,"SPAN",{});var YBt=s(XEe);T(Wx.$$.fragment,YBt),YBt.forEach(t),JBt.forEach(t),DDr=i(Bze),zEe=n(Bze,"SPAN",{});var KBt=s(zEe);GDr=r(KBt,"FlaxAutoModelForMaskedLM"),KBt.forEach(t),Bze.forEach(t),LVe=i(f),ur=n(f,"DIV",{class:!0});var ti=s(ur);T(Hx.$$.fragment,ti),ODr=i(ti),Kc=n(ti,"P",{});var Hre=s(Kc);VDr=r(Hre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a masked language modeling head) when created
with the `),jZ=n(Hre,"A",{href:!0});var ZBt=s(jZ);XDr=r(ZBt,"from_pretrained()"),ZBt.forEach(t),zDr=r(Hre," class method or the "),DZ=n(Hre,"A",{href:!0});var eIt=s(DZ);QDr=r(eIt,"from_config()"),eIt.forEach(t),WDr=r(Hre,` class
method.`),Hre.forEach(t),HDr=i(ti),Ux=n(ti,"P",{});var Ize=s(Ux);UDr=r(Ize,"This class cannot be instantiated directly using "),QEe=n(Ize,"CODE",{});var oIt=s(QEe);JDr=r(oIt,"__init__()"),oIt.forEach(t),YDr=r(Ize," (throws an error)."),Ize.forEach(t),KDr=i(ti),Wt=n(ti,"DIV",{class:!0});var lw=s(Wt);T(Jx.$$.fragment,lw),ZDr=i(lw),WEe=n(lw,"P",{});var rIt=s(WEe);eGr=r(rIt,"Instantiates one of the model classes of the library (with a masked language modeling head) from a configuration."),rIt.forEach(t),oGr=i(lw),Zc=n(lw,"P",{});var Ure=s(Zc);rGr=r(Ure,`Note:
Loading a model from its configuration file does `),HEe=n(Ure,"STRONG",{});var tIt=s(HEe);tGr=r(tIt,"not"),tIt.forEach(t),aGr=r(Ure,` load the model weights. It only affects the
model\u2019s configuration. Use `),GZ=n(Ure,"A",{href:!0});var aIt=s(GZ);nGr=r(aIt,"from_pretrained()"),aIt.forEach(t),sGr=r(Ure," to load the model weights."),Ure.forEach(t),lGr=i(lw),T(LC.$$.fragment,lw),lw.forEach(t),iGr=i(ti),zr=n(ti,"DIV",{class:!0});var ai=s(zr);T(Yx.$$.fragment,ai),dGr=i(ai),UEe=n(ai,"P",{});var nIt=s(UEe);cGr=r(nIt,"Instantiate one of the model classes of the library (with a masked language modeling head) from a pretrained model."),nIt.forEach(t),fGr=i(ai),En=n(ai,"P",{});var iw=s(En);mGr=r(iw,"The model class to instantiate is selected based on the "),JEe=n(iw,"CODE",{});var sIt=s(JEe);gGr=r(sIt,"model_type"),sIt.forEach(t),hGr=r(iw,` property of the config object (either
passed as an argument or loaded from `),YEe=n(iw,"CODE",{});var lIt=s(YEe);pGr=r(lIt,"pretrained_model_name_or_path"),lIt.forEach(t),_Gr=r(iw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),KEe=n(iw,"CODE",{});var iIt=s(KEe);uGr=r(iIt,"pretrained_model_name_or_path"),iIt.forEach(t),bGr=r(iw,":"),iw.forEach(t),vGr=i(ai),$e=n(ai,"UL",{});var qe=s($e);yC=n(qe,"LI",{});var RDe=s(yC);ZEe=n(RDe,"STRONG",{});var dIt=s(ZEe);FGr=r(dIt,"albert"),dIt.forEach(t),TGr=r(RDe," \u2014 "),OZ=n(RDe,"A",{href:!0});var cIt=s(OZ);MGr=r(cIt,"FlaxAlbertForMaskedLM"),cIt.forEach(t),EGr=r(RDe," (ALBERT model)"),RDe.forEach(t),CGr=i(qe),xC=n(qe,"LI",{});var PDe=s(xC);e4e=n(PDe,"STRONG",{});var fIt=s(e4e);wGr=r(fIt,"bart"),fIt.forEach(t),AGr=r(PDe," \u2014 "),VZ=n(PDe,"A",{href:!0});var mIt=s(VZ);LGr=r(mIt,"FlaxBartForConditionalGeneration"),mIt.forEach(t),yGr=r(PDe," (BART model)"),PDe.forEach(t),xGr=i(qe),$C=n(qe,"LI",{});var BDe=s($C);o4e=n(BDe,"STRONG",{});var gIt=s(o4e);$Gr=r(gIt,"bert"),gIt.forEach(t),kGr=r(BDe," \u2014 "),XZ=n(BDe,"A",{href:!0});var hIt=s(XZ);SGr=r(hIt,"FlaxBertForMaskedLM"),hIt.forEach(t),RGr=r(BDe," (BERT model)"),BDe.forEach(t),PGr=i(qe),kC=n(qe,"LI",{});var IDe=s(kC);r4e=n(IDe,"STRONG",{});var pIt=s(r4e);BGr=r(pIt,"big_bird"),pIt.forEach(t),IGr=r(IDe," \u2014 "),zZ=n(IDe,"A",{href:!0});var _It=s(zZ);NGr=r(_It,"FlaxBigBirdForMaskedLM"),_It.forEach(t),qGr=r(IDe," (BigBird model)"),IDe.forEach(t),jGr=i(qe),SC=n(qe,"LI",{});var NDe=s(SC);t4e=n(NDe,"STRONG",{});var uIt=s(t4e);DGr=r(uIt,"distilbert"),uIt.forEach(t),GGr=r(NDe," \u2014 "),QZ=n(NDe,"A",{href:!0});var bIt=s(QZ);OGr=r(bIt,"FlaxDistilBertForMaskedLM"),bIt.forEach(t),VGr=r(NDe," (DistilBERT model)"),NDe.forEach(t),XGr=i(qe),RC=n(qe,"LI",{});var qDe=s(RC);a4e=n(qDe,"STRONG",{});var vIt=s(a4e);zGr=r(vIt,"electra"),vIt.forEach(t),QGr=r(qDe," \u2014 "),WZ=n(qDe,"A",{href:!0});var FIt=s(WZ);WGr=r(FIt,"FlaxElectraForMaskedLM"),FIt.forEach(t),HGr=r(qDe," (ELECTRA model)"),qDe.forEach(t),UGr=i(qe),PC=n(qe,"LI",{});var jDe=s(PC);n4e=n(jDe,"STRONG",{});var TIt=s(n4e);JGr=r(TIt,"mbart"),TIt.forEach(t),YGr=r(jDe," \u2014 "),HZ=n(jDe,"A",{href:!0});var MIt=s(HZ);KGr=r(MIt,"FlaxMBartForConditionalGeneration"),MIt.forEach(t),ZGr=r(jDe," (mBART model)"),jDe.forEach(t),eOr=i(qe),BC=n(qe,"LI",{});var DDe=s(BC);s4e=n(DDe,"STRONG",{});var EIt=s(s4e);oOr=r(EIt,"roberta"),EIt.forEach(t),rOr=r(DDe," \u2014 "),UZ=n(DDe,"A",{href:!0});var CIt=s(UZ);tOr=r(CIt,"FlaxRobertaForMaskedLM"),CIt.forEach(t),aOr=r(DDe," (RoBERTa model)"),DDe.forEach(t),nOr=i(qe),IC=n(qe,"LI",{});var GDe=s(IC);l4e=n(GDe,"STRONG",{});var wIt=s(l4e);sOr=r(wIt,"roformer"),wIt.forEach(t),lOr=r(GDe," \u2014 "),JZ=n(GDe,"A",{href:!0});var AIt=s(JZ);iOr=r(AIt,"FlaxRoFormerForMaskedLM"),AIt.forEach(t),dOr=r(GDe," (RoFormer model)"),GDe.forEach(t),cOr=i(qe),NC=n(qe,"LI",{});var ODe=s(NC);i4e=n(ODe,"STRONG",{});var LIt=s(i4e);fOr=r(LIt,"xlm-roberta"),LIt.forEach(t),mOr=r(ODe," \u2014 "),YZ=n(ODe,"A",{href:!0});var yIt=s(YZ);gOr=r(yIt,"FlaxXLMRobertaForMaskedLM"),yIt.forEach(t),hOr=r(ODe," (XLM-RoBERTa model)"),ODe.forEach(t),qe.forEach(t),pOr=i(ai),T(qC.$$.fragment,ai),ai.forEach(t),ti.forEach(t),yVe=i(f),ef=n(f,"H2",{class:!0});var Nze=s(ef);jC=n(Nze,"A",{id:!0,class:!0,href:!0});var xIt=s(jC);d4e=n(xIt,"SPAN",{});var $It=s(d4e);T(Kx.$$.fragment,$It),$It.forEach(t),xIt.forEach(t),_Or=i(Nze),c4e=n(Nze,"SPAN",{});var kIt=s(c4e);uOr=r(kIt,"FlaxAutoModelForSeq2SeqLM"),kIt.forEach(t),Nze.forEach(t),xVe=i(f),br=n(f,"DIV",{class:!0});var ni=s(br);T(Zx.$$.fragment,ni),bOr=i(ni),of=n(ni,"P",{});var Jre=s(of);vOr=r(Jre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence-to-sequence language modeling head) when created
with the `),KZ=n(Jre,"A",{href:!0});var SIt=s(KZ);FOr=r(SIt,"from_pretrained()"),SIt.forEach(t),TOr=r(Jre," class method or the "),ZZ=n(Jre,"A",{href:!0});var RIt=s(ZZ);MOr=r(RIt,"from_config()"),RIt.forEach(t),EOr=r(Jre,` class
method.`),Jre.forEach(t),COr=i(ni),e$=n(ni,"P",{});var qze=s(e$);wOr=r(qze,"This class cannot be instantiated directly using "),f4e=n(qze,"CODE",{});var PIt=s(f4e);AOr=r(PIt,"__init__()"),PIt.forEach(t),LOr=r(qze," (throws an error)."),qze.forEach(t),yOr=i(ni),Ht=n(ni,"DIV",{class:!0});var dw=s(Ht);T(o$.$$.fragment,dw),xOr=i(dw),m4e=n(dw,"P",{});var BIt=s(m4e);$Or=r(BIt,"Instantiates one of the model classes of the library (with a sequence-to-sequence language modeling head) from a configuration."),BIt.forEach(t),kOr=i(dw),rf=n(dw,"P",{});var Yre=s(rf);SOr=r(Yre,`Note:
Loading a model from its configuration file does `),g4e=n(Yre,"STRONG",{});var IIt=s(g4e);ROr=r(IIt,"not"),IIt.forEach(t),POr=r(Yre,` load the model weights. It only affects the
model\u2019s configuration. Use `),eee=n(Yre,"A",{href:!0});var NIt=s(eee);BOr=r(NIt,"from_pretrained()"),NIt.forEach(t),IOr=r(Yre," to load the model weights."),Yre.forEach(t),NOr=i(dw),T(DC.$$.fragment,dw),dw.forEach(t),qOr=i(ni),Qr=n(ni,"DIV",{class:!0});var si=s(Qr);T(r$.$$.fragment,si),jOr=i(si),h4e=n(si,"P",{});var qIt=s(h4e);DOr=r(qIt,"Instantiate one of the model classes of the library (with a sequence-to-sequence language modeling head) from a pretrained model."),qIt.forEach(t),GOr=i(si),Cn=n(si,"P",{});var cw=s(Cn);OOr=r(cw,"The model class to instantiate is selected based on the "),p4e=n(cw,"CODE",{});var jIt=s(p4e);VOr=r(jIt,"model_type"),jIt.forEach(t),XOr=r(cw,` property of the config object (either
passed as an argument or loaded from `),_4e=n(cw,"CODE",{});var DIt=s(_4e);zOr=r(DIt,"pretrained_model_name_or_path"),DIt.forEach(t),QOr=r(cw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),u4e=n(cw,"CODE",{});var GIt=s(u4e);WOr=r(GIt,"pretrained_model_name_or_path"),GIt.forEach(t),HOr=r(cw,":"),cw.forEach(t),UOr=i(si),ke=n(si,"UL",{});var je=s(ke);GC=n(je,"LI",{});var VDe=s(GC);b4e=n(VDe,"STRONG",{});var OIt=s(b4e);JOr=r(OIt,"bart"),OIt.forEach(t),YOr=r(VDe," \u2014 "),oee=n(VDe,"A",{href:!0});var VIt=s(oee);KOr=r(VIt,"FlaxBartForConditionalGeneration"),VIt.forEach(t),ZOr=r(VDe," (BART model)"),VDe.forEach(t),eVr=i(je),OC=n(je,"LI",{});var XDe=s(OC);v4e=n(XDe,"STRONG",{});var XIt=s(v4e);oVr=r(XIt,"blenderbot"),XIt.forEach(t),rVr=r(XDe," \u2014 "),ree=n(XDe,"A",{href:!0});var zIt=s(ree);tVr=r(zIt,"FlaxBlenderbotForConditionalGeneration"),zIt.forEach(t),aVr=r(XDe," (Blenderbot model)"),XDe.forEach(t),nVr=i(je),VC=n(je,"LI",{});var zDe=s(VC);F4e=n(zDe,"STRONG",{});var QIt=s(F4e);sVr=r(QIt,"blenderbot-small"),QIt.forEach(t),lVr=r(zDe," \u2014 "),tee=n(zDe,"A",{href:!0});var WIt=s(tee);iVr=r(WIt,"FlaxBlenderbotSmallForConditionalGeneration"),WIt.forEach(t),dVr=r(zDe," (BlenderbotSmall model)"),zDe.forEach(t),cVr=i(je),XC=n(je,"LI",{});var QDe=s(XC);T4e=n(QDe,"STRONG",{});var HIt=s(T4e);fVr=r(HIt,"encoder-decoder"),HIt.forEach(t),mVr=r(QDe," \u2014 "),aee=n(QDe,"A",{href:!0});var UIt=s(aee);gVr=r(UIt,"FlaxEncoderDecoderModel"),UIt.forEach(t),hVr=r(QDe," (Encoder decoder model)"),QDe.forEach(t),pVr=i(je),zC=n(je,"LI",{});var WDe=s(zC);M4e=n(WDe,"STRONG",{});var JIt=s(M4e);_Vr=r(JIt,"longt5"),JIt.forEach(t),uVr=r(WDe," \u2014 "),nee=n(WDe,"A",{href:!0});var YIt=s(nee);bVr=r(YIt,"FlaxLongT5ForConditionalGeneration"),YIt.forEach(t),vVr=r(WDe," (LongT5 model)"),WDe.forEach(t),FVr=i(je),QC=n(je,"LI",{});var HDe=s(QC);E4e=n(HDe,"STRONG",{});var KIt=s(E4e);TVr=r(KIt,"marian"),KIt.forEach(t),MVr=r(HDe," \u2014 "),see=n(HDe,"A",{href:!0});var ZIt=s(see);EVr=r(ZIt,"FlaxMarianMTModel"),ZIt.forEach(t),CVr=r(HDe," (Marian model)"),HDe.forEach(t),wVr=i(je),WC=n(je,"LI",{});var UDe=s(WC);C4e=n(UDe,"STRONG",{});var eNt=s(C4e);AVr=r(eNt,"mbart"),eNt.forEach(t),LVr=r(UDe," \u2014 "),lee=n(UDe,"A",{href:!0});var oNt=s(lee);yVr=r(oNt,"FlaxMBartForConditionalGeneration"),oNt.forEach(t),xVr=r(UDe," (mBART model)"),UDe.forEach(t),$Vr=i(je),HC=n(je,"LI",{});var JDe=s(HC);w4e=n(JDe,"STRONG",{});var rNt=s(w4e);kVr=r(rNt,"mt5"),rNt.forEach(t),SVr=r(JDe," \u2014 "),iee=n(JDe,"A",{href:!0});var tNt=s(iee);RVr=r(tNt,"FlaxMT5ForConditionalGeneration"),tNt.forEach(t),PVr=r(JDe," (MT5 model)"),JDe.forEach(t),BVr=i(je),UC=n(je,"LI",{});var YDe=s(UC);A4e=n(YDe,"STRONG",{});var aNt=s(A4e);IVr=r(aNt,"pegasus"),aNt.forEach(t),NVr=r(YDe," \u2014 "),dee=n(YDe,"A",{href:!0});var nNt=s(dee);qVr=r(nNt,"FlaxPegasusForConditionalGeneration"),nNt.forEach(t),jVr=r(YDe," (Pegasus model)"),YDe.forEach(t),DVr=i(je),JC=n(je,"LI",{});var KDe=s(JC);L4e=n(KDe,"STRONG",{});var sNt=s(L4e);GVr=r(sNt,"t5"),sNt.forEach(t),OVr=r(KDe," \u2014 "),cee=n(KDe,"A",{href:!0});var lNt=s(cee);VVr=r(lNt,"FlaxT5ForConditionalGeneration"),lNt.forEach(t),XVr=r(KDe," (T5 model)"),KDe.forEach(t),je.forEach(t),zVr=i(si),T(YC.$$.fragment,si),si.forEach(t),ni.forEach(t),$Ve=i(f),tf=n(f,"H2",{class:!0});var jze=s(tf);KC=n(jze,"A",{id:!0,class:!0,href:!0});var iNt=s(KC);y4e=n(iNt,"SPAN",{});var dNt=s(y4e);T(t$.$$.fragment,dNt),dNt.forEach(t),iNt.forEach(t),QVr=i(jze),x4e=n(jze,"SPAN",{});var cNt=s(x4e);WVr=r(cNt,"FlaxAutoModelForSequenceClassification"),cNt.forEach(t),jze.forEach(t),kVe=i(f),vr=n(f,"DIV",{class:!0});var li=s(vr);T(a$.$$.fragment,li),HVr=i(li),af=n(li,"P",{});var Kre=s(af);UVr=r(Kre,`This is a generic model class that will be instantiated as one of the model classes of the library (with a sequence classification head) when created
with the `),fee=n(Kre,"A",{href:!0});var fNt=s(fee);JVr=r(fNt,"from_pretrained()"),fNt.forEach(t),YVr=r(Kre," class method or the "),mee=n(Kre,"A",{href:!0});var mNt=s(mee);KVr=r(mNt,"from_config()"),mNt.forEach(t),ZVr=r(Kre,` class
method.`),Kre.forEach(t),eXr=i(li),n$=n(li,"P",{});var Dze=s(n$);oXr=r(Dze,"This class cannot be instantiated directly using "),$4e=n(Dze,"CODE",{});var gNt=s($4e);rXr=r(gNt,"__init__()"),gNt.forEach(t),tXr=r(Dze," (throws an error)."),Dze.forEach(t),aXr=i(li),Ut=n(li,"DIV",{class:!0});var fw=s(Ut);T(s$.$$.fragment,fw),nXr=i(fw),k4e=n(fw,"P",{});var hNt=s(k4e);sXr=r(hNt,"Instantiates one of the model classes of the library (with a sequence classification head) from a configuration."),hNt.forEach(t),lXr=i(fw),nf=n(fw,"P",{});var Zre=s(nf);iXr=r(Zre,`Note:
Loading a model from its configuration file does `),S4e=n(Zre,"STRONG",{});var pNt=s(S4e);dXr=r(pNt,"not"),pNt.forEach(t),cXr=r(Zre,` load the model weights. It only affects the
model\u2019s configuration. Use `),gee=n(Zre,"A",{href:!0});var _Nt=s(gee);fXr=r(_Nt,"from_pretrained()"),_Nt.forEach(t),mXr=r(Zre," to load the model weights."),Zre.forEach(t),gXr=i(fw),T(ZC.$$.fragment,fw),fw.forEach(t),hXr=i(li),Wr=n(li,"DIV",{class:!0});var ii=s(Wr);T(l$.$$.fragment,ii),pXr=i(ii),R4e=n(ii,"P",{});var uNt=s(R4e);_Xr=r(uNt,"Instantiate one of the model classes of the library (with a sequence classification head) from a pretrained model."),uNt.forEach(t),uXr=i(ii),wn=n(ii,"P",{});var mw=s(wn);bXr=r(mw,"The model class to instantiate is selected based on the "),P4e=n(mw,"CODE",{});var bNt=s(P4e);vXr=r(bNt,"model_type"),bNt.forEach(t),FXr=r(mw,` property of the config object (either
passed as an argument or loaded from `),B4e=n(mw,"CODE",{});var vNt=s(B4e);TXr=r(vNt,"pretrained_model_name_or_path"),vNt.forEach(t),MXr=r(mw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),I4e=n(mw,"CODE",{});var FNt=s(I4e);EXr=r(FNt,"pretrained_model_name_or_path"),FNt.forEach(t),CXr=r(mw,":"),mw.forEach(t),wXr=i(ii),Se=n(ii,"UL",{});var De=s(Se);e5=n(De,"LI",{});var ZDe=s(e5);N4e=n(ZDe,"STRONG",{});var TNt=s(N4e);AXr=r(TNt,"albert"),TNt.forEach(t),LXr=r(ZDe," \u2014 "),hee=n(ZDe,"A",{href:!0});var MNt=s(hee);yXr=r(MNt,"FlaxAlbertForSequenceClassification"),MNt.forEach(t),xXr=r(ZDe," (ALBERT model)"),ZDe.forEach(t),$Xr=i(De),o5=n(De,"LI",{});var eGe=s(o5);q4e=n(eGe,"STRONG",{});var ENt=s(q4e);kXr=r(ENt,"bart"),ENt.forEach(t),SXr=r(eGe," \u2014 "),pee=n(eGe,"A",{href:!0});var CNt=s(pee);RXr=r(CNt,"FlaxBartForSequenceClassification"),CNt.forEach(t),PXr=r(eGe," (BART model)"),eGe.forEach(t),BXr=i(De),r5=n(De,"LI",{});var oGe=s(r5);j4e=n(oGe,"STRONG",{});var wNt=s(j4e);IXr=r(wNt,"bert"),wNt.forEach(t),NXr=r(oGe," \u2014 "),_ee=n(oGe,"A",{href:!0});var ANt=s(_ee);qXr=r(ANt,"FlaxBertForSequenceClassification"),ANt.forEach(t),jXr=r(oGe," (BERT model)"),oGe.forEach(t),DXr=i(De),t5=n(De,"LI",{});var rGe=s(t5);D4e=n(rGe,"STRONG",{});var LNt=s(D4e);GXr=r(LNt,"big_bird"),LNt.forEach(t),OXr=r(rGe," \u2014 "),uee=n(rGe,"A",{href:!0});var yNt=s(uee);VXr=r(yNt,"FlaxBigBirdForSequenceClassification"),yNt.forEach(t),XXr=r(rGe," (BigBird model)"),rGe.forEach(t),zXr=i(De),a5=n(De,"LI",{});var tGe=s(a5);G4e=n(tGe,"STRONG",{});var xNt=s(G4e);QXr=r(xNt,"distilbert"),xNt.forEach(t),WXr=r(tGe," \u2014 "),bee=n(tGe,"A",{href:!0});var $Nt=s(bee);HXr=r($Nt,"FlaxDistilBertForSequenceClassification"),$Nt.forEach(t),UXr=r(tGe," (DistilBERT model)"),tGe.forEach(t),JXr=i(De),n5=n(De,"LI",{});var aGe=s(n5);O4e=n(aGe,"STRONG",{});var kNt=s(O4e);YXr=r(kNt,"electra"),kNt.forEach(t),KXr=r(aGe," \u2014 "),vee=n(aGe,"A",{href:!0});var SNt=s(vee);ZXr=r(SNt,"FlaxElectraForSequenceClassification"),SNt.forEach(t),ezr=r(aGe," (ELECTRA model)"),aGe.forEach(t),ozr=i(De),s5=n(De,"LI",{});var nGe=s(s5);V4e=n(nGe,"STRONG",{});var RNt=s(V4e);rzr=r(RNt,"mbart"),RNt.forEach(t),tzr=r(nGe," \u2014 "),Fee=n(nGe,"A",{href:!0});var PNt=s(Fee);azr=r(PNt,"FlaxMBartForSequenceClassification"),PNt.forEach(t),nzr=r(nGe," (mBART model)"),nGe.forEach(t),szr=i(De),l5=n(De,"LI",{});var sGe=s(l5);X4e=n(sGe,"STRONG",{});var BNt=s(X4e);lzr=r(BNt,"roberta"),BNt.forEach(t),izr=r(sGe," \u2014 "),Tee=n(sGe,"A",{href:!0});var INt=s(Tee);dzr=r(INt,"FlaxRobertaForSequenceClassification"),INt.forEach(t),czr=r(sGe," (RoBERTa model)"),sGe.forEach(t),fzr=i(De),i5=n(De,"LI",{});var lGe=s(i5);z4e=n(lGe,"STRONG",{});var NNt=s(z4e);mzr=r(NNt,"roformer"),NNt.forEach(t),gzr=r(lGe," \u2014 "),Mee=n(lGe,"A",{href:!0});var qNt=s(Mee);hzr=r(qNt,"FlaxRoFormerForSequenceClassification"),qNt.forEach(t),pzr=r(lGe," (RoFormer model)"),lGe.forEach(t),_zr=i(De),d5=n(De,"LI",{});var iGe=s(d5);Q4e=n(iGe,"STRONG",{});var jNt=s(Q4e);uzr=r(jNt,"xlm-roberta"),jNt.forEach(t),bzr=r(iGe," \u2014 "),Eee=n(iGe,"A",{href:!0});var DNt=s(Eee);vzr=r(DNt,"FlaxXLMRobertaForSequenceClassification"),DNt.forEach(t),Fzr=r(iGe," (XLM-RoBERTa model)"),iGe.forEach(t),De.forEach(t),Tzr=i(ii),T(c5.$$.fragment,ii),ii.forEach(t),li.forEach(t),SVe=i(f),sf=n(f,"H2",{class:!0});var Gze=s(sf);f5=n(Gze,"A",{id:!0,class:!0,href:!0});var GNt=s(f5);W4e=n(GNt,"SPAN",{});var ONt=s(W4e);T(i$.$$.fragment,ONt),ONt.forEach(t),GNt.forEach(t),Mzr=i(Gze),H4e=n(Gze,"SPAN",{});var VNt=s(H4e);Ezr=r(VNt,"FlaxAutoModelForQuestionAnswering"),VNt.forEach(t),Gze.forEach(t),RVe=i(f),Fr=n(f,"DIV",{class:!0});var di=s(Fr);T(d$.$$.fragment,di),Czr=i(di),lf=n(di,"P",{});var ete=s(lf);wzr=r(ete,`This is a generic model class that will be instantiated as one of the model classes of the library (with a question answering head) when created
with the `),Cee=n(ete,"A",{href:!0});var XNt=s(Cee);Azr=r(XNt,"from_pretrained()"),XNt.forEach(t),Lzr=r(ete," class method or the "),wee=n(ete,"A",{href:!0});var zNt=s(wee);yzr=r(zNt,"from_config()"),zNt.forEach(t),xzr=r(ete,` class
method.`),ete.forEach(t),$zr=i(di),c$=n(di,"P",{});var Oze=s(c$);kzr=r(Oze,"This class cannot be instantiated directly using "),U4e=n(Oze,"CODE",{});var QNt=s(U4e);Szr=r(QNt,"__init__()"),QNt.forEach(t),Rzr=r(Oze," (throws an error)."),Oze.forEach(t),Pzr=i(di),Jt=n(di,"DIV",{class:!0});var gw=s(Jt);T(f$.$$.fragment,gw),Bzr=i(gw),J4e=n(gw,"P",{});var WNt=s(J4e);Izr=r(WNt,"Instantiates one of the model classes of the library (with a question answering head) from a configuration."),WNt.forEach(t),Nzr=i(gw),df=n(gw,"P",{});var ote=s(df);qzr=r(ote,`Note:
Loading a model from its configuration file does `),Y4e=n(ote,"STRONG",{});var HNt=s(Y4e);jzr=r(HNt,"not"),HNt.forEach(t),Dzr=r(ote,` load the model weights. It only affects the
model\u2019s configuration. Use `),Aee=n(ote,"A",{href:!0});var UNt=s(Aee);Gzr=r(UNt,"from_pretrained()"),UNt.forEach(t),Ozr=r(ote," to load the model weights."),ote.forEach(t),Vzr=i(gw),T(m5.$$.fragment,gw),gw.forEach(t),Xzr=i(di),Hr=n(di,"DIV",{class:!0});var ci=s(Hr);T(m$.$$.fragment,ci),zzr=i(ci),K4e=n(ci,"P",{});var JNt=s(K4e);Qzr=r(JNt,"Instantiate one of the model classes of the library (with a question answering head) from a pretrained model."),JNt.forEach(t),Wzr=i(ci),An=n(ci,"P",{});var hw=s(An);Hzr=r(hw,"The model class to instantiate is selected based on the "),Z4e=n(hw,"CODE",{});var YNt=s(Z4e);Uzr=r(YNt,"model_type"),YNt.forEach(t),Jzr=r(hw,` property of the config object (either
passed as an argument or loaded from `),eCe=n(hw,"CODE",{});var KNt=s(eCe);Yzr=r(KNt,"pretrained_model_name_or_path"),KNt.forEach(t),Kzr=r(hw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),oCe=n(hw,"CODE",{});var ZNt=s(oCe);Zzr=r(ZNt,"pretrained_model_name_or_path"),ZNt.forEach(t),eQr=r(hw,":"),hw.forEach(t),oQr=i(ci),Re=n(ci,"UL",{});var Ge=s(Re);g5=n(Ge,"LI",{});var dGe=s(g5);rCe=n(dGe,"STRONG",{});var eqt=s(rCe);rQr=r(eqt,"albert"),eqt.forEach(t),tQr=r(dGe," \u2014 "),Lee=n(dGe,"A",{href:!0});var oqt=s(Lee);aQr=r(oqt,"FlaxAlbertForQuestionAnswering"),oqt.forEach(t),nQr=r(dGe," (ALBERT model)"),dGe.forEach(t),sQr=i(Ge),h5=n(Ge,"LI",{});var cGe=s(h5);tCe=n(cGe,"STRONG",{});var rqt=s(tCe);lQr=r(rqt,"bart"),rqt.forEach(t),iQr=r(cGe," \u2014 "),yee=n(cGe,"A",{href:!0});var tqt=s(yee);dQr=r(tqt,"FlaxBartForQuestionAnswering"),tqt.forEach(t),cQr=r(cGe," (BART model)"),cGe.forEach(t),fQr=i(Ge),p5=n(Ge,"LI",{});var fGe=s(p5);aCe=n(fGe,"STRONG",{});var aqt=s(aCe);mQr=r(aqt,"bert"),aqt.forEach(t),gQr=r(fGe," \u2014 "),xee=n(fGe,"A",{href:!0});var nqt=s(xee);hQr=r(nqt,"FlaxBertForQuestionAnswering"),nqt.forEach(t),pQr=r(fGe," (BERT model)"),fGe.forEach(t),_Qr=i(Ge),_5=n(Ge,"LI",{});var mGe=s(_5);nCe=n(mGe,"STRONG",{});var sqt=s(nCe);uQr=r(sqt,"big_bird"),sqt.forEach(t),bQr=r(mGe," \u2014 "),$ee=n(mGe,"A",{href:!0});var lqt=s($ee);vQr=r(lqt,"FlaxBigBirdForQuestionAnswering"),lqt.forEach(t),FQr=r(mGe," (BigBird model)"),mGe.forEach(t),TQr=i(Ge),u5=n(Ge,"LI",{});var gGe=s(u5);sCe=n(gGe,"STRONG",{});var iqt=s(sCe);MQr=r(iqt,"distilbert"),iqt.forEach(t),EQr=r(gGe," \u2014 "),kee=n(gGe,"A",{href:!0});var dqt=s(kee);CQr=r(dqt,"FlaxDistilBertForQuestionAnswering"),dqt.forEach(t),wQr=r(gGe," (DistilBERT model)"),gGe.forEach(t),AQr=i(Ge),b5=n(Ge,"LI",{});var hGe=s(b5);lCe=n(hGe,"STRONG",{});var cqt=s(lCe);LQr=r(cqt,"electra"),cqt.forEach(t),yQr=r(hGe," \u2014 "),See=n(hGe,"A",{href:!0});var fqt=s(See);xQr=r(fqt,"FlaxElectraForQuestionAnswering"),fqt.forEach(t),$Qr=r(hGe," (ELECTRA model)"),hGe.forEach(t),kQr=i(Ge),v5=n(Ge,"LI",{});var pGe=s(v5);iCe=n(pGe,"STRONG",{});var mqt=s(iCe);SQr=r(mqt,"mbart"),mqt.forEach(t),RQr=r(pGe," \u2014 "),Ree=n(pGe,"A",{href:!0});var gqt=s(Ree);PQr=r(gqt,"FlaxMBartForQuestionAnswering"),gqt.forEach(t),BQr=r(pGe," (mBART model)"),pGe.forEach(t),IQr=i(Ge),F5=n(Ge,"LI",{});var _Ge=s(F5);dCe=n(_Ge,"STRONG",{});var hqt=s(dCe);NQr=r(hqt,"roberta"),hqt.forEach(t),qQr=r(_Ge," \u2014 "),Pee=n(_Ge,"A",{href:!0});var pqt=s(Pee);jQr=r(pqt,"FlaxRobertaForQuestionAnswering"),pqt.forEach(t),DQr=r(_Ge," (RoBERTa model)"),_Ge.forEach(t),GQr=i(Ge),T5=n(Ge,"LI",{});var uGe=s(T5);cCe=n(uGe,"STRONG",{});var _qt=s(cCe);OQr=r(_qt,"roformer"),_qt.forEach(t),VQr=r(uGe," \u2014 "),Bee=n(uGe,"A",{href:!0});var uqt=s(Bee);XQr=r(uqt,"FlaxRoFormerForQuestionAnswering"),uqt.forEach(t),zQr=r(uGe," (RoFormer model)"),uGe.forEach(t),QQr=i(Ge),M5=n(Ge,"LI",{});var bGe=s(M5);fCe=n(bGe,"STRONG",{});var bqt=s(fCe);WQr=r(bqt,"xlm-roberta"),bqt.forEach(t),HQr=r(bGe," \u2014 "),Iee=n(bGe,"A",{href:!0});var vqt=s(Iee);UQr=r(vqt,"FlaxXLMRobertaForQuestionAnswering"),vqt.forEach(t),JQr=r(bGe," (XLM-RoBERTa model)"),bGe.forEach(t),Ge.forEach(t),YQr=i(ci),T(E5.$$.fragment,ci),ci.forEach(t),di.forEach(t),PVe=i(f),cf=n(f,"H2",{class:!0});var Vze=s(cf);C5=n(Vze,"A",{id:!0,class:!0,href:!0});var Fqt=s(C5);mCe=n(Fqt,"SPAN",{});var Tqt=s(mCe);T(g$.$$.fragment,Tqt),Tqt.forEach(t),Fqt.forEach(t),KQr=i(Vze),gCe=n(Vze,"SPAN",{});var Mqt=s(gCe);ZQr=r(Mqt,"FlaxAutoModelForTokenClassification"),Mqt.forEach(t),Vze.forEach(t),BVe=i(f),Tr=n(f,"DIV",{class:!0});var fi=s(Tr);T(h$.$$.fragment,fi),eWr=i(fi),ff=n(fi,"P",{});var rte=s(ff);oWr=r(rte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a token classification head) when created
with the `),Nee=n(rte,"A",{href:!0});var Eqt=s(Nee);rWr=r(Eqt,"from_pretrained()"),Eqt.forEach(t),tWr=r(rte," class method or the "),qee=n(rte,"A",{href:!0});var Cqt=s(qee);aWr=r(Cqt,"from_config()"),Cqt.forEach(t),nWr=r(rte,` class
method.`),rte.forEach(t),sWr=i(fi),p$=n(fi,"P",{});var Xze=s(p$);lWr=r(Xze,"This class cannot be instantiated directly using "),hCe=n(Xze,"CODE",{});var wqt=s(hCe);iWr=r(wqt,"__init__()"),wqt.forEach(t),dWr=r(Xze," (throws an error)."),Xze.forEach(t),cWr=i(fi),Yt=n(fi,"DIV",{class:!0});var pw=s(Yt);T(_$.$$.fragment,pw),fWr=i(pw),pCe=n(pw,"P",{});var Aqt=s(pCe);mWr=r(Aqt,"Instantiates one of the model classes of the library (with a token classification head) from a configuration."),Aqt.forEach(t),gWr=i(pw),mf=n(pw,"P",{});var tte=s(mf);hWr=r(tte,`Note:
Loading a model from its configuration file does `),_Ce=n(tte,"STRONG",{});var Lqt=s(_Ce);pWr=r(Lqt,"not"),Lqt.forEach(t),_Wr=r(tte,` load the model weights. It only affects the
model\u2019s configuration. Use `),jee=n(tte,"A",{href:!0});var yqt=s(jee);uWr=r(yqt,"from_pretrained()"),yqt.forEach(t),bWr=r(tte," to load the model weights."),tte.forEach(t),vWr=i(pw),T(w5.$$.fragment,pw),pw.forEach(t),FWr=i(fi),Ur=n(fi,"DIV",{class:!0});var mi=s(Ur);T(u$.$$.fragment,mi),TWr=i(mi),uCe=n(mi,"P",{});var xqt=s(uCe);MWr=r(xqt,"Instantiate one of the model classes of the library (with a token classification head) from a pretrained model."),xqt.forEach(t),EWr=i(mi),Ln=n(mi,"P",{});var _w=s(Ln);CWr=r(_w,"The model class to instantiate is selected based on the "),bCe=n(_w,"CODE",{});var $qt=s(bCe);wWr=r($qt,"model_type"),$qt.forEach(t),AWr=r(_w,` property of the config object (either
passed as an argument or loaded from `),vCe=n(_w,"CODE",{});var kqt=s(vCe);LWr=r(kqt,"pretrained_model_name_or_path"),kqt.forEach(t),yWr=r(_w,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),FCe=n(_w,"CODE",{});var Sqt=s(FCe);xWr=r(Sqt,"pretrained_model_name_or_path"),Sqt.forEach(t),$Wr=r(_w,":"),_w.forEach(t),kWr=i(mi),Ve=n(mi,"UL",{});var To=s(Ve);A5=n(To,"LI",{});var vGe=s(A5);TCe=n(vGe,"STRONG",{});var Rqt=s(TCe);SWr=r(Rqt,"albert"),Rqt.forEach(t),RWr=r(vGe," \u2014 "),Dee=n(vGe,"A",{href:!0});var Pqt=s(Dee);PWr=r(Pqt,"FlaxAlbertForTokenClassification"),Pqt.forEach(t),BWr=r(vGe," (ALBERT model)"),vGe.forEach(t),IWr=i(To),L5=n(To,"LI",{});var FGe=s(L5);MCe=n(FGe,"STRONG",{});var Bqt=s(MCe);NWr=r(Bqt,"bert"),Bqt.forEach(t),qWr=r(FGe," \u2014 "),Gee=n(FGe,"A",{href:!0});var Iqt=s(Gee);jWr=r(Iqt,"FlaxBertForTokenClassification"),Iqt.forEach(t),DWr=r(FGe," (BERT model)"),FGe.forEach(t),GWr=i(To),y5=n(To,"LI",{});var TGe=s(y5);ECe=n(TGe,"STRONG",{});var Nqt=s(ECe);OWr=r(Nqt,"big_bird"),Nqt.forEach(t),VWr=r(TGe," \u2014 "),Oee=n(TGe,"A",{href:!0});var qqt=s(Oee);XWr=r(qqt,"FlaxBigBirdForTokenClassification"),qqt.forEach(t),zWr=r(TGe," (BigBird model)"),TGe.forEach(t),QWr=i(To),x5=n(To,"LI",{});var MGe=s(x5);CCe=n(MGe,"STRONG",{});var jqt=s(CCe);WWr=r(jqt,"distilbert"),jqt.forEach(t),HWr=r(MGe," \u2014 "),Vee=n(MGe,"A",{href:!0});var Dqt=s(Vee);UWr=r(Dqt,"FlaxDistilBertForTokenClassification"),Dqt.forEach(t),JWr=r(MGe," (DistilBERT model)"),MGe.forEach(t),YWr=i(To),$5=n(To,"LI",{});var EGe=s($5);wCe=n(EGe,"STRONG",{});var Gqt=s(wCe);KWr=r(Gqt,"electra"),Gqt.forEach(t),ZWr=r(EGe," \u2014 "),Xee=n(EGe,"A",{href:!0});var Oqt=s(Xee);eHr=r(Oqt,"FlaxElectraForTokenClassification"),Oqt.forEach(t),oHr=r(EGe," (ELECTRA model)"),EGe.forEach(t),rHr=i(To),k5=n(To,"LI",{});var CGe=s(k5);ACe=n(CGe,"STRONG",{});var Vqt=s(ACe);tHr=r(Vqt,"roberta"),Vqt.forEach(t),aHr=r(CGe," \u2014 "),zee=n(CGe,"A",{href:!0});var Xqt=s(zee);nHr=r(Xqt,"FlaxRobertaForTokenClassification"),Xqt.forEach(t),sHr=r(CGe," (RoBERTa model)"),CGe.forEach(t),lHr=i(To),S5=n(To,"LI",{});var wGe=s(S5);LCe=n(wGe,"STRONG",{});var zqt=s(LCe);iHr=r(zqt,"roformer"),zqt.forEach(t),dHr=r(wGe," \u2014 "),Qee=n(wGe,"A",{href:!0});var Qqt=s(Qee);cHr=r(Qqt,"FlaxRoFormerForTokenClassification"),Qqt.forEach(t),fHr=r(wGe," (RoFormer model)"),wGe.forEach(t),mHr=i(To),R5=n(To,"LI",{});var AGe=s(R5);yCe=n(AGe,"STRONG",{});var Wqt=s(yCe);gHr=r(Wqt,"xlm-roberta"),Wqt.forEach(t),hHr=r(AGe," \u2014 "),Wee=n(AGe,"A",{href:!0});var Hqt=s(Wee);pHr=r(Hqt,"FlaxXLMRobertaForTokenClassification"),Hqt.forEach(t),_Hr=r(AGe," (XLM-RoBERTa model)"),AGe.forEach(t),To.forEach(t),uHr=i(mi),T(P5.$$.fragment,mi),mi.forEach(t),fi.forEach(t),IVe=i(f),gf=n(f,"H2",{class:!0});var zze=s(gf);B5=n(zze,"A",{id:!0,class:!0,href:!0});var Uqt=s(B5);xCe=n(Uqt,"SPAN",{});var Jqt=s(xCe);T(b$.$$.fragment,Jqt),Jqt.forEach(t),Uqt.forEach(t),bHr=i(zze),$Ce=n(zze,"SPAN",{});var Yqt=s($Ce);vHr=r(Yqt,"FlaxAutoModelForMultipleChoice"),Yqt.forEach(t),zze.forEach(t),NVe=i(f),Mr=n(f,"DIV",{class:!0});var gi=s(Mr);T(v$.$$.fragment,gi),FHr=i(gi),hf=n(gi,"P",{});var ate=s(hf);THr=r(ate,`This is a generic model class that will be instantiated as one of the model classes of the library (with a multiple choice head) when created
with the `),Hee=n(ate,"A",{href:!0});var Kqt=s(Hee);MHr=r(Kqt,"from_pretrained()"),Kqt.forEach(t),EHr=r(ate," class method or the "),Uee=n(ate,"A",{href:!0});var Zqt=s(Uee);CHr=r(Zqt,"from_config()"),Zqt.forEach(t),wHr=r(ate,` class
method.`),ate.forEach(t),AHr=i(gi),F$=n(gi,"P",{});var Qze=s(F$);LHr=r(Qze,"This class cannot be instantiated directly using "),kCe=n(Qze,"CODE",{});var ejt=s(kCe);yHr=r(ejt,"__init__()"),ejt.forEach(t),xHr=r(Qze," (throws an error)."),Qze.forEach(t),$Hr=i(gi),Kt=n(gi,"DIV",{class:!0});var uw=s(Kt);T(T$.$$.fragment,uw),kHr=i(uw),SCe=n(uw,"P",{});var ojt=s(SCe);SHr=r(ojt,"Instantiates one of the model classes of the library (with a multiple choice head) from a configuration."),ojt.forEach(t),RHr=i(uw),pf=n(uw,"P",{});var nte=s(pf);PHr=r(nte,`Note:
Loading a model from its configuration file does `),RCe=n(nte,"STRONG",{});var rjt=s(RCe);BHr=r(rjt,"not"),rjt.forEach(t),IHr=r(nte,` load the model weights. It only affects the
model\u2019s configuration. Use `),Jee=n(nte,"A",{href:!0});var tjt=s(Jee);NHr=r(tjt,"from_pretrained()"),tjt.forEach(t),qHr=r(nte," to load the model weights."),nte.forEach(t),jHr=i(uw),T(I5.$$.fragment,uw),uw.forEach(t),DHr=i(gi),Jr=n(gi,"DIV",{class:!0});var hi=s(Jr);T(M$.$$.fragment,hi),GHr=i(hi),PCe=n(hi,"P",{});var ajt=s(PCe);OHr=r(ajt,"Instantiate one of the model classes of the library (with a multiple choice head) from a pretrained model."),ajt.forEach(t),VHr=i(hi),yn=n(hi,"P",{});var bw=s(yn);XHr=r(bw,"The model class to instantiate is selected based on the "),BCe=n(bw,"CODE",{});var njt=s(BCe);zHr=r(njt,"model_type"),njt.forEach(t),QHr=r(bw,` property of the config object (either
passed as an argument or loaded from `),ICe=n(bw,"CODE",{});var sjt=s(ICe);WHr=r(sjt,"pretrained_model_name_or_path"),sjt.forEach(t),HHr=r(bw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),NCe=n(bw,"CODE",{});var ljt=s(NCe);UHr=r(ljt,"pretrained_model_name_or_path"),ljt.forEach(t),JHr=r(bw,":"),bw.forEach(t),YHr=i(hi),Xe=n(hi,"UL",{});var Mo=s(Xe);N5=n(Mo,"LI",{});var LGe=s(N5);qCe=n(LGe,"STRONG",{});var ijt=s(qCe);KHr=r(ijt,"albert"),ijt.forEach(t),ZHr=r(LGe," \u2014 "),Yee=n(LGe,"A",{href:!0});var djt=s(Yee);eUr=r(djt,"FlaxAlbertForMultipleChoice"),djt.forEach(t),oUr=r(LGe," (ALBERT model)"),LGe.forEach(t),rUr=i(Mo),q5=n(Mo,"LI",{});var yGe=s(q5);jCe=n(yGe,"STRONG",{});var cjt=s(jCe);tUr=r(cjt,"bert"),cjt.forEach(t),aUr=r(yGe," \u2014 "),Kee=n(yGe,"A",{href:!0});var fjt=s(Kee);nUr=r(fjt,"FlaxBertForMultipleChoice"),fjt.forEach(t),sUr=r(yGe," (BERT model)"),yGe.forEach(t),lUr=i(Mo),j5=n(Mo,"LI",{});var xGe=s(j5);DCe=n(xGe,"STRONG",{});var mjt=s(DCe);iUr=r(mjt,"big_bird"),mjt.forEach(t),dUr=r(xGe," \u2014 "),Zee=n(xGe,"A",{href:!0});var gjt=s(Zee);cUr=r(gjt,"FlaxBigBirdForMultipleChoice"),gjt.forEach(t),fUr=r(xGe," (BigBird model)"),xGe.forEach(t),mUr=i(Mo),D5=n(Mo,"LI",{});var $Ge=s(D5);GCe=n($Ge,"STRONG",{});var hjt=s(GCe);gUr=r(hjt,"distilbert"),hjt.forEach(t),hUr=r($Ge," \u2014 "),eoe=n($Ge,"A",{href:!0});var pjt=s(eoe);pUr=r(pjt,"FlaxDistilBertForMultipleChoice"),pjt.forEach(t),_Ur=r($Ge," (DistilBERT model)"),$Ge.forEach(t),uUr=i(Mo),G5=n(Mo,"LI",{});var kGe=s(G5);OCe=n(kGe,"STRONG",{});var _jt=s(OCe);bUr=r(_jt,"electra"),_jt.forEach(t),vUr=r(kGe," \u2014 "),ooe=n(kGe,"A",{href:!0});var ujt=s(ooe);FUr=r(ujt,"FlaxElectraForMultipleChoice"),ujt.forEach(t),TUr=r(kGe," (ELECTRA model)"),kGe.forEach(t),MUr=i(Mo),O5=n(Mo,"LI",{});var SGe=s(O5);VCe=n(SGe,"STRONG",{});var bjt=s(VCe);EUr=r(bjt,"roberta"),bjt.forEach(t),CUr=r(SGe," \u2014 "),roe=n(SGe,"A",{href:!0});var vjt=s(roe);wUr=r(vjt,"FlaxRobertaForMultipleChoice"),vjt.forEach(t),AUr=r(SGe," (RoBERTa model)"),SGe.forEach(t),LUr=i(Mo),V5=n(Mo,"LI",{});var RGe=s(V5);XCe=n(RGe,"STRONG",{});var Fjt=s(XCe);yUr=r(Fjt,"roformer"),Fjt.forEach(t),xUr=r(RGe," \u2014 "),toe=n(RGe,"A",{href:!0});var Tjt=s(toe);$Ur=r(Tjt,"FlaxRoFormerForMultipleChoice"),Tjt.forEach(t),kUr=r(RGe," (RoFormer model)"),RGe.forEach(t),SUr=i(Mo),X5=n(Mo,"LI",{});var PGe=s(X5);zCe=n(PGe,"STRONG",{});var Mjt=s(zCe);RUr=r(Mjt,"xlm-roberta"),Mjt.forEach(t),PUr=r(PGe," \u2014 "),aoe=n(PGe,"A",{href:!0});var Ejt=s(aoe);BUr=r(Ejt,"FlaxXLMRobertaForMultipleChoice"),Ejt.forEach(t),IUr=r(PGe," (XLM-RoBERTa model)"),PGe.forEach(t),Mo.forEach(t),NUr=i(hi),T(z5.$$.fragment,hi),hi.forEach(t),gi.forEach(t),qVe=i(f),_f=n(f,"H2",{class:!0});var Wze=s(_f);Q5=n(Wze,"A",{id:!0,class:!0,href:!0});var Cjt=s(Q5);QCe=n(Cjt,"SPAN",{});var wjt=s(QCe);T(E$.$$.fragment,wjt),wjt.forEach(t),Cjt.forEach(t),qUr=i(Wze),WCe=n(Wze,"SPAN",{});var Ajt=s(WCe);jUr=r(Ajt,"FlaxAutoModelForNextSentencePrediction"),Ajt.forEach(t),Wze.forEach(t),jVe=i(f),Er=n(f,"DIV",{class:!0});var pi=s(Er);T(C$.$$.fragment,pi),DUr=i(pi),uf=n(pi,"P",{});var ste=s(uf);GUr=r(ste,`This is a generic model class that will be instantiated as one of the model classes of the library (with a next sentence prediction head) when created
with the `),noe=n(ste,"A",{href:!0});var Ljt=s(noe);OUr=r(Ljt,"from_pretrained()"),Ljt.forEach(t),VUr=r(ste," class method or the "),soe=n(ste,"A",{href:!0});var yjt=s(soe);XUr=r(yjt,"from_config()"),yjt.forEach(t),zUr=r(ste,` class
method.`),ste.forEach(t),QUr=i(pi),w$=n(pi,"P",{});var Hze=s(w$);WUr=r(Hze,"This class cannot be instantiated directly using "),HCe=n(Hze,"CODE",{});var xjt=s(HCe);HUr=r(xjt,"__init__()"),xjt.forEach(t),UUr=r(Hze," (throws an error)."),Hze.forEach(t),JUr=i(pi),Zt=n(pi,"DIV",{class:!0});var vw=s(Zt);T(A$.$$.fragment,vw),YUr=i(vw),UCe=n(vw,"P",{});var $jt=s(UCe);KUr=r($jt,"Instantiates one of the model classes of the library (with a next sentence prediction head) from a configuration."),$jt.forEach(t),ZUr=i(vw),bf=n(vw,"P",{});var lte=s(bf);eJr=r(lte,`Note:
Loading a model from its configuration file does `),JCe=n(lte,"STRONG",{});var kjt=s(JCe);oJr=r(kjt,"not"),kjt.forEach(t),rJr=r(lte,` load the model weights. It only affects the
model\u2019s configuration. Use `),loe=n(lte,"A",{href:!0});var Sjt=s(loe);tJr=r(Sjt,"from_pretrained()"),Sjt.forEach(t),aJr=r(lte," to load the model weights."),lte.forEach(t),nJr=i(vw),T(W5.$$.fragment,vw),vw.forEach(t),sJr=i(pi),Yr=n(pi,"DIV",{class:!0});var _i=s(Yr);T(L$.$$.fragment,_i),lJr=i(_i),YCe=n(_i,"P",{});var Rjt=s(YCe);iJr=r(Rjt,"Instantiate one of the model classes of the library (with a next sentence prediction head) from a pretrained model."),Rjt.forEach(t),dJr=i(_i),xn=n(_i,"P",{});var Fw=s(xn);cJr=r(Fw,"The model class to instantiate is selected based on the "),KCe=n(Fw,"CODE",{});var Pjt=s(KCe);fJr=r(Pjt,"model_type"),Pjt.forEach(t),mJr=r(Fw,` property of the config object (either
passed as an argument or loaded from `),ZCe=n(Fw,"CODE",{});var Bjt=s(ZCe);gJr=r(Bjt,"pretrained_model_name_or_path"),Bjt.forEach(t),hJr=r(Fw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),e5e=n(Fw,"CODE",{});var Ijt=s(e5e);pJr=r(Ijt,"pretrained_model_name_or_path"),Ijt.forEach(t),_Jr=r(Fw,":"),Fw.forEach(t),uJr=i(_i),o5e=n(_i,"UL",{});var Njt=s(o5e);H5=n(Njt,"LI",{});var BGe=s(H5);r5e=n(BGe,"STRONG",{});var qjt=s(r5e);bJr=r(qjt,"bert"),qjt.forEach(t),vJr=r(BGe," \u2014 "),ioe=n(BGe,"A",{href:!0});var jjt=s(ioe);FJr=r(jjt,"FlaxBertForNextSentencePrediction"),jjt.forEach(t),TJr=r(BGe," (BERT model)"),BGe.forEach(t),Njt.forEach(t),MJr=i(_i),T(U5.$$.fragment,_i),_i.forEach(t),pi.forEach(t),DVe=i(f),vf=n(f,"H2",{class:!0});var Uze=s(vf);J5=n(Uze,"A",{id:!0,class:!0,href:!0});var Djt=s(J5);t5e=n(Djt,"SPAN",{});var Gjt=s(t5e);T(y$.$$.fragment,Gjt),Gjt.forEach(t),Djt.forEach(t),EJr=i(Uze),a5e=n(Uze,"SPAN",{});var Ojt=s(a5e);CJr=r(Ojt,"FlaxAutoModelForImageClassification"),Ojt.forEach(t),Uze.forEach(t),GVe=i(f),Cr=n(f,"DIV",{class:!0});var ui=s(Cr);T(x$.$$.fragment,ui),wJr=i(ui),Ff=n(ui,"P",{});var ite=s(Ff);AJr=r(ite,`This is a generic model class that will be instantiated as one of the model classes of the library (with a image classification head) when created
with the `),doe=n(ite,"A",{href:!0});var Vjt=s(doe);LJr=r(Vjt,"from_pretrained()"),Vjt.forEach(t),yJr=r(ite," class method or the "),coe=n(ite,"A",{href:!0});var Xjt=s(coe);xJr=r(Xjt,"from_config()"),Xjt.forEach(t),$Jr=r(ite,` class
method.`),ite.forEach(t),kJr=i(ui),$$=n(ui,"P",{});var Jze=s($$);SJr=r(Jze,"This class cannot be instantiated directly using "),n5e=n(Jze,"CODE",{});var zjt=s(n5e);RJr=r(zjt,"__init__()"),zjt.forEach(t),PJr=r(Jze," (throws an error)."),Jze.forEach(t),BJr=i(ui),ea=n(ui,"DIV",{class:!0});var Tw=s(ea);T(k$.$$.fragment,Tw),IJr=i(Tw),s5e=n(Tw,"P",{});var Qjt=s(s5e);NJr=r(Qjt,"Instantiates one of the model classes of the library (with a image classification head) from a configuration."),Qjt.forEach(t),qJr=i(Tw),Tf=n(Tw,"P",{});var dte=s(Tf);jJr=r(dte,`Note:
Loading a model from its configuration file does `),l5e=n(dte,"STRONG",{});var Wjt=s(l5e);DJr=r(Wjt,"not"),Wjt.forEach(t),GJr=r(dte,` load the model weights. It only affects the
model\u2019s configuration. Use `),foe=n(dte,"A",{href:!0});var Hjt=s(foe);OJr=r(Hjt,"from_pretrained()"),Hjt.forEach(t),VJr=r(dte," to load the model weights."),dte.forEach(t),XJr=i(Tw),T(Y5.$$.fragment,Tw),Tw.forEach(t),zJr=i(ui),Kr=n(ui,"DIV",{class:!0});var bi=s(Kr);T(S$.$$.fragment,bi),QJr=i(bi),i5e=n(bi,"P",{});var Ujt=s(i5e);WJr=r(Ujt,"Instantiate one of the model classes of the library (with a image classification head) from a pretrained model."),Ujt.forEach(t),HJr=i(bi),$n=n(bi,"P",{});var Mw=s($n);UJr=r(Mw,"The model class to instantiate is selected based on the "),d5e=n(Mw,"CODE",{});var Jjt=s(d5e);JJr=r(Jjt,"model_type"),Jjt.forEach(t),YJr=r(Mw,` property of the config object (either
passed as an argument or loaded from `),c5e=n(Mw,"CODE",{});var Yjt=s(c5e);KJr=r(Yjt,"pretrained_model_name_or_path"),Yjt.forEach(t),ZJr=r(Mw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),f5e=n(Mw,"CODE",{});var Kjt=s(f5e);eYr=r(Kjt,"pretrained_model_name_or_path"),Kjt.forEach(t),oYr=r(Mw,":"),Mw.forEach(t),rYr=i(bi),R$=n(bi,"UL",{});var Yze=s(R$);K5=n(Yze,"LI",{});var IGe=s(K5);m5e=n(IGe,"STRONG",{});var Zjt=s(m5e);tYr=r(Zjt,"beit"),Zjt.forEach(t),aYr=r(IGe," \u2014 "),moe=n(IGe,"A",{href:!0});var eDt=s(moe);nYr=r(eDt,"FlaxBeitForImageClassification"),eDt.forEach(t),sYr=r(IGe," (BEiT model)"),IGe.forEach(t),lYr=i(Yze),Z5=n(Yze,"LI",{});var NGe=s(Z5);g5e=n(NGe,"STRONG",{});var oDt=s(g5e);iYr=r(oDt,"vit"),oDt.forEach(t),dYr=r(NGe," \u2014 "),goe=n(NGe,"A",{href:!0});var rDt=s(goe);cYr=r(rDt,"FlaxViTForImageClassification"),rDt.forEach(t),fYr=r(NGe," (ViT model)"),NGe.forEach(t),Yze.forEach(t),mYr=i(bi),T(e3.$$.fragment,bi),bi.forEach(t),ui.forEach(t),OVe=i(f),Mf=n(f,"H2",{class:!0});var Kze=s(Mf);o3=n(Kze,"A",{id:!0,class:!0,href:!0});var tDt=s(o3);h5e=n(tDt,"SPAN",{});var aDt=s(h5e);T(P$.$$.fragment,aDt),aDt.forEach(t),tDt.forEach(t),gYr=i(Kze),p5e=n(Kze,"SPAN",{});var nDt=s(p5e);hYr=r(nDt,"FlaxAutoModelForVision2Seq"),nDt.forEach(t),Kze.forEach(t),VVe=i(f),wr=n(f,"DIV",{class:!0});var vi=s(wr);T(B$.$$.fragment,vi),pYr=i(vi),Ef=n(vi,"P",{});var cte=s(Ef);_Yr=r(cte,`This is a generic model class that will be instantiated as one of the model classes of the library (with a vision-to-text modeling head) when created
with the `),hoe=n(cte,"A",{href:!0});var sDt=s(hoe);uYr=r(sDt,"from_pretrained()"),sDt.forEach(t),bYr=r(cte," class method or the "),poe=n(cte,"A",{href:!0});var lDt=s(poe);vYr=r(lDt,"from_config()"),lDt.forEach(t),FYr=r(cte,` class
method.`),cte.forEach(t),TYr=i(vi),I$=n(vi,"P",{});var Zze=s(I$);MYr=r(Zze,"This class cannot be instantiated directly using "),_5e=n(Zze,"CODE",{});var iDt=s(_5e);EYr=r(iDt,"__init__()"),iDt.forEach(t),CYr=r(Zze," (throws an error)."),Zze.forEach(t),wYr=i(vi),oa=n(vi,"DIV",{class:!0});var Ew=s(oa);T(N$.$$.fragment,Ew),AYr=i(Ew),u5e=n(Ew,"P",{});var dDt=s(u5e);LYr=r(dDt,"Instantiates one of the model classes of the library (with a vision-to-text modeling head) from a configuration."),dDt.forEach(t),yYr=i(Ew),Cf=n(Ew,"P",{});var fte=s(Cf);xYr=r(fte,`Note:
Loading a model from its configuration file does `),b5e=n(fte,"STRONG",{});var cDt=s(b5e);$Yr=r(cDt,"not"),cDt.forEach(t),kYr=r(fte,` load the model weights. It only affects the
model\u2019s configuration. Use `),_oe=n(fte,"A",{href:!0});var fDt=s(_oe);SYr=r(fDt,"from_pretrained()"),fDt.forEach(t),RYr=r(fte," to load the model weights."),fte.forEach(t),PYr=i(Ew),T(r3.$$.fragment,Ew),Ew.forEach(t),BYr=i(vi),Zr=n(vi,"DIV",{class:!0});var Fi=s(Zr);T(q$.$$.fragment,Fi),IYr=i(Fi),v5e=n(Fi,"P",{});var mDt=s(v5e);NYr=r(mDt,"Instantiate one of the model classes of the library (with a vision-to-text modeling head) from a pretrained model."),mDt.forEach(t),qYr=i(Fi),kn=n(Fi,"P",{});var Cw=s(kn);jYr=r(Cw,"The model class to instantiate is selected based on the "),F5e=n(Cw,"CODE",{});var gDt=s(F5e);DYr=r(gDt,"model_type"),gDt.forEach(t),GYr=r(Cw,` property of the config object (either
passed as an argument or loaded from `),T5e=n(Cw,"CODE",{});var hDt=s(T5e);OYr=r(hDt,"pretrained_model_name_or_path"),hDt.forEach(t),VYr=r(Cw,` if possible), or when it\u2019s missing, by
falling back to using pattern matching on `),M5e=n(Cw,"CODE",{});var pDt=s(M5e);XYr=r(pDt,"pretrained_model_name_or_path"),pDt.forEach(t),zYr=r(Cw,":"),Cw.forEach(t),QYr=i(Fi),E5e=n(Fi,"UL",{});var _Dt=s(E5e);t3=n(_Dt,"LI",{});var qGe=s(t3);C5e=n(qGe,"STRONG",{});var uDt=s(C5e);WYr=r(uDt,"vision-encoder-decoder"),uDt.forEach(t),HYr=r(qGe," \u2014 "),uoe=n(qGe,"A",{href:!0});var bDt=s(uoe);UYr=r(bDt,"FlaxVisionEncoderDecoderModel"),bDt.forEach(t),JYr=r(qGe," (Vision Encoder decoder model)"),qGe.forEach(t),_Dt.forEach(t),YYr=i(Fi),T(a3.$$.fragment,Fi),Fi.forEach(t),vi.forEach(t),this.h()},h(){c(g,"name","hf:doc:metadata"),c(g,"content",JSON.stringify(COt)),c(m,"id","auto-classes"),c(m,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m,"href","#auto-classes"),c(p,"class","relative group"),c(Rn,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.AutoConfig"),c(Bn,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.AutoModel"),c(In,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.AutoTokenizer"),c(Li,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertModel"),c(Sf,"id","extending-the-auto-classes"),c(Sf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Sf,"href","#extending-the-auto-classes"),c(yi,"class","relative group"),c(Pf,"id","transformers.AutoConfig"),c(Pf,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Pf,"href","#transformers.AutoConfig"),c(xi,"class","relative group"),c(iS,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.AutoConfig.from_pretrained"),c(dS,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertConfig"),c(cS,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartConfig"),c(fS,"href","/docs/transformers/pr_17869/en/model_doc/beit#transformers.BeitConfig"),c(mS,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertConfig"),c(gS,"href","/docs/transformers/pr_17869/en/model_doc/bert-generation#transformers.BertGenerationConfig"),c(hS,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdConfig"),c(pS,"href","/docs/transformers/pr_17869/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusConfig"),c(_S,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.BlenderbotConfig"),c(uS,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.BlenderbotSmallConfig"),c(bS,"href","/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomConfig"),c(vS,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertConfig"),c(FS,"href","/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineConfig"),c(TS,"href","/docs/transformers/pr_17869/en/model_doc/clip#transformers.CLIPConfig"),c(MS,"href","/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertConfig"),c(ES,"href","/docs/transformers/pr_17869/en/model_doc/convnext#transformers.ConvNextConfig"),c(CS,"href","/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLConfig"),c(wS,"href","/docs/transformers/pr_17869/en/model_doc/cvt#transformers.CvtConfig"),c(AS,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecAudioConfig"),c(LS,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextConfig"),c(yS,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecVisionConfig"),c(xS,"href","/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaConfig"),c($S,"href","/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2Config"),c(kS,"href","/docs/transformers/pr_17869/en/model_doc/decision_transformer#transformers.DecisionTransformerConfig"),c(SS,"href","/docs/transformers/pr_17869/en/model_doc/deit#transformers.DeiTConfig"),c(RS,"href","/docs/transformers/pr_17869/en/model_doc/detr#transformers.DetrConfig"),c(PS,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertConfig"),c(BS,"href","/docs/transformers/pr_17869/en/model_doc/dpr#transformers.DPRConfig"),c(IS,"href","/docs/transformers/pr_17869/en/model_doc/dpt#transformers.DPTConfig"),c(NS,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraConfig"),c(qS,"href","/docs/transformers/pr_17869/en/model_doc/encoder-decoder#transformers.EncoderDecoderConfig"),c(jS,"href","/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertConfig"),c(DS,"href","/docs/transformers/pr_17869/en/model_doc/flava#transformers.FlavaConfig"),c(GS,"href","/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetConfig"),c(OS,"href","/docs/transformers/pr_17869/en/model_doc/fsmt#transformers.FSMTConfig"),c(VS,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelConfig"),c(XS,"href","/docs/transformers/pr_17869/en/model_doc/glpn#transformers.GLPNConfig"),c(zS,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Config"),c(QS,"href","/docs/transformers/pr_17869/en/model_doc/gpt_neo#transformers.GPTNeoConfig"),c(WS,"href","/docs/transformers/pr_17869/en/model_doc/gpt_neox#transformers.GPTNeoXConfig"),c(HS,"href","/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJConfig"),c(US,"href","/docs/transformers/pr_17869/en/model_doc/hubert#transformers.HubertConfig"),c(JS,"href","/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertConfig"),c(YS,"href","/docs/transformers/pr_17869/en/model_doc/imagegpt#transformers.ImageGPTConfig"),c(KS,"href","/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMConfig"),c(ZS,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2Config"),c(eR,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3Config"),c(oR,"href","/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDConfig"),c(rR,"href","/docs/transformers/pr_17869/en/model_doc/levit#transformers.LevitConfig"),c(tR,"href","/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerConfig"),c(aR,"href","/docs/transformers/pr_17869/en/model_doc/longt5#transformers.LongT5Config"),c(nR,"href","/docs/transformers/pr_17869/en/model_doc/luke#transformers.LukeConfig"),c(sR,"href","/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.LxmertConfig"),c(lR,"href","/docs/transformers/pr_17869/en/model_doc/m2m_100#transformers.M2M100Config"),c(iR,"href","/docs/transformers/pr_17869/en/model_doc/marian#transformers.MarianConfig"),c(dR,"href","/docs/transformers/pr_17869/en/model_doc/maskformer#transformers.MaskFormerConfig"),c(cR,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartConfig"),c(fR,"href","/docs/transformers/pr_17869/en/model_doc/mctct#transformers.MCTCTConfig"),c(mR,"href","/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertConfig"),c(gR,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertConfig"),c(hR,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetConfig"),c(pR,"href","/docs/transformers/pr_17869/en/model_doc/mt5#transformers.MT5Config"),c(_R,"href","/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaConfig"),c(uR,"href","/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerConfig"),c(bR,"href","/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTConfig"),c(vR,"href","/docs/transformers/pr_17869/en/model_doc/opt#transformers.OPTConfig"),c(FR,"href","/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusConfig"),c(TR,"href","/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverConfig"),c(MR,"href","/docs/transformers/pr_17869/en/model_doc/plbart#transformers.PLBartConfig"),c(ER,"href","/docs/transformers/pr_17869/en/model_doc/poolformer#transformers.PoolFormerConfig"),c(CR,"href","/docs/transformers/pr_17869/en/model_doc/prophetnet#transformers.ProphetNetConfig"),c(wR,"href","/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertConfig"),c(AR,"href","/docs/transformers/pr_17869/en/model_doc/rag#transformers.RagConfig"),c(LR,"href","/docs/transformers/pr_17869/en/model_doc/realm#transformers.RealmConfig"),c(yR,"href","/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerConfig"),c(xR,"href","/docs/transformers/pr_17869/en/model_doc/regnet#transformers.RegNetConfig"),c($R,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertConfig"),c(kR,"href","/docs/transformers/pr_17869/en/model_doc/resnet#transformers.ResNetConfig"),c(SR,"href","/docs/transformers/pr_17869/en/model_doc/retribert#transformers.RetriBertConfig"),c(RR,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaConfig"),c(PR,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerConfig"),c(BR,"href","/docs/transformers/pr_17869/en/model_doc/segformer#transformers.SegformerConfig"),c(IR,"href","/docs/transformers/pr_17869/en/model_doc/sew#transformers.SEWConfig"),c(NR,"href","/docs/transformers/pr_17869/en/model_doc/sew-d#transformers.SEWDConfig"),c(qR,"href","/docs/transformers/pr_17869/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderConfig"),c(jR,"href","/docs/transformers/pr_17869/en/model_doc/speech_to_text#transformers.Speech2TextConfig"),c(DR,"href","/docs/transformers/pr_17869/en/model_doc/speech_to_text_2#transformers.Speech2Text2Config"),c(GR,"href","/docs/transformers/pr_17869/en/model_doc/splinter#transformers.SplinterConfig"),c(OR,"href","/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertConfig"),c(VR,"href","/docs/transformers/pr_17869/en/model_doc/swin#transformers.SwinConfig"),c(XR,"href","/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5Config"),c(zR,"href","/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasConfig"),c(QR,"href","/docs/transformers/pr_17869/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerConfig"),c(WR,"href","/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLConfig"),c(HR,"href","/docs/transformers/pr_17869/en/model_doc/trocr#transformers.TrOCRConfig"),c(UR,"href","/docs/transformers/pr_17869/en/model_doc/unispeech#transformers.UniSpeechConfig"),c(JR,"href","/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatConfig"),c(YR,"href","/docs/transformers/pr_17869/en/model_doc/van#transformers.VanConfig"),c(KR,"href","/docs/transformers/pr_17869/en/model_doc/vilt#transformers.ViltConfig"),c(ZR,"href","/docs/transformers/pr_17869/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderConfig"),c(eP,"href","/docs/transformers/pr_17869/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderConfig"),c(oP,"href","/docs/transformers/pr_17869/en/model_doc/visual_bert#transformers.VisualBertConfig"),c(rP,"href","/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTConfig"),c(tP,"href","/docs/transformers/pr_17869/en/model_doc/vit_mae#transformers.ViTMAEConfig"),c(aP,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Config"),c(nP,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerConfig"),c(sP,"href","/docs/transformers/pr_17869/en/model_doc/wavlm#transformers.WavLMConfig"),c(lP,"href","/docs/transformers/pr_17869/en/model_doc/xglm#transformers.XGLMConfig"),c(iP,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMConfig"),c(dP,"href","/docs/transformers/pr_17869/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetConfig"),c(cP,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaConfig"),c(fP,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLConfig"),c(mP,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetConfig"),c(gP,"href","/docs/transformers/pr_17869/en/model_doc/yolos#transformers.YolosConfig"),c(hP,"href","/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoConfig"),c(Ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Og,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vg,"id","transformers.AutoTokenizer"),c(Vg,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Vg,"href","#transformers.AutoTokenizer"),c(ki,"class","relative group"),c(pP,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained"),c(_P,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertTokenizer"),c(uP,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(bP,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartTokenizer"),c(vP,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartTokenizerFast"),c(FP,"href","/docs/transformers/pr_17869/en/model_doc/barthez#transformers.BarthezTokenizer"),c(TP,"href","/docs/transformers/pr_17869/en/model_doc/barthez#transformers.BarthezTokenizerFast"),c(MP,"href","/docs/transformers/pr_17869/en/model_doc/bartpho#transformers.BartphoTokenizer"),c(EP,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertTokenizer"),c(CP,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertTokenizerFast"),c(wP,"href","/docs/transformers/pr_17869/en/model_doc/bert-generation#transformers.BertGenerationTokenizer"),c(AP,"href","/docs/transformers/pr_17869/en/model_doc/bert-japanese#transformers.BertJapaneseTokenizer"),c(LP,"href","/docs/transformers/pr_17869/en/model_doc/bertweet#transformers.BertweetTokenizer"),c(yP,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdTokenizer"),c(xP,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdTokenizerFast"),c($P,"href","/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(kP,"href","/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(SP,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.BlenderbotTokenizer"),c(RP,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.BlenderbotTokenizerFast"),c(PP,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.BlenderbotSmallTokenizer"),c(BP,"href","/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomTokenizerFast"),c(IP,"href","/docs/transformers/pr_17869/en/model_doc/byt5#transformers.ByT5Tokenizer"),c(NP,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertTokenizer"),c(qP,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertTokenizerFast"),c(jP,"href","/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineTokenizer"),c(DP,"href","/docs/transformers/pr_17869/en/model_doc/clip#transformers.CLIPTokenizer"),c(GP,"href","/docs/transformers/pr_17869/en/model_doc/clip#transformers.CLIPTokenizerFast"),c(OP,"href","/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertTokenizer"),c(VP,"href","/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertTokenizerFast"),c(XP,"href","/docs/transformers/pr_17869/en/model_doc/cpm#transformers.CpmTokenizer"),c(zP,"href","/docs/transformers/pr_17869/en/model_doc/cpm#transformers.CpmTokenizerFast"),c(QP,"href","/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLTokenizer"),c(WP,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaTokenizer"),c(HP,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(UP,"href","/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaTokenizer"),c(JP,"href","/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaTokenizerFast"),c(YP,"href","/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2Tokenizer"),c(KP,"href","/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2TokenizerFast"),c(ZP,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertTokenizer"),c(eB,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertTokenizerFast"),c(oB,"href","/docs/transformers/pr_17869/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizer"),c(rB,"href","/docs/transformers/pr_17869/en/model_doc/dpr#transformers.DPRQuestionEncoderTokenizerFast"),c(tB,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraTokenizer"),c(aB,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraTokenizerFast"),c(nB,"href","/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertTokenizer"),c(sB,"href","/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetTokenizer"),c(lB,"href","/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetTokenizerFast"),c(iB,"href","/docs/transformers/pr_17869/en/model_doc/fsmt#transformers.FSMTTokenizer"),c(dB,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelTokenizer"),c(cB,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelTokenizerFast"),c(fB,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(mB,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(gB,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(hB,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(pB,"href","/docs/transformers/pr_17869/en/model_doc/gpt_neox#transformers.GPTNeoXTokenizerFast"),c(_B,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(uB,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2TokenizerFast"),c(bB,"href","/docs/transformers/pr_17869/en/model_doc/herbert#transformers.HerbertTokenizer"),c(vB,"href","/docs/transformers/pr_17869/en/model_doc/herbert#transformers.HerbertTokenizerFast"),c(FB,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(TB,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaTokenizer"),c(MB,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(EB,"href","/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMTokenizer"),c(CB,"href","/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMTokenizerFast"),c(wB,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2Tokenizer"),c(AB,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2TokenizerFast"),c(LB,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3Tokenizer"),c(yB,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3TokenizerFast"),c(xB,"href","/docs/transformers/pr_17869/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizer"),c($B,"href","/docs/transformers/pr_17869/en/model_doc/layoutxlm#transformers.LayoutXLMTokenizerFast"),c(kB,"href","/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDTokenizer"),c(SB,"href","/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDTokenizerFast"),c(RB,"href","/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerTokenizer"),c(PB,"href","/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerTokenizerFast"),c(BB,"href","/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5Tokenizer"),c(IB,"href","/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5TokenizerFast"),c(NB,"href","/docs/transformers/pr_17869/en/model_doc/luke#transformers.LukeTokenizer"),c(qB,"href","/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.LxmertTokenizer"),c(jB,"href","/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.LxmertTokenizerFast"),c(DB,"href","/docs/transformers/pr_17869/en/model_doc/m2m_100#transformers.M2M100Tokenizer"),c(GB,"href","/docs/transformers/pr_17869/en/model_doc/marian#transformers.MarianTokenizer"),c(OB,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartTokenizer"),c(VB,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartTokenizerFast"),c(XB,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBart50Tokenizer"),c(zB,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBart50TokenizerFast"),c(QB,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertTokenizer"),c(WB,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertTokenizerFast"),c(HB,"href","/docs/transformers/pr_17869/en/model_doc/mluke#transformers.MLukeTokenizer"),c(UB,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertTokenizer"),c(JB,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertTokenizerFast"),c(YB,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetTokenizer"),c(KB,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetTokenizerFast"),c(ZB,"href","/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5Tokenizer"),c(eI,"href","/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5TokenizerFast"),c(oI,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertTokenizer"),c(rI,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertTokenizerFast"),c(tI,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertTokenizer"),c(aI,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(nI,"href","/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizer"),c(sI,"href","/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTTokenizerFast"),c(lI,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Tokenizer"),c(iI,"href","/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusTokenizer"),c(dI,"href","/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusTokenizerFast"),c(cI,"href","/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverTokenizer"),c(fI,"href","/docs/transformers/pr_17869/en/model_doc/phobert#transformers.PhobertTokenizer"),c(mI,"href","/docs/transformers/pr_17869/en/model_doc/plbart#transformers.PLBartTokenizer"),c(gI,"href","/docs/transformers/pr_17869/en/model_doc/prophetnet#transformers.ProphetNetTokenizer"),c(hI,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertTokenizer"),c(pI,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertTokenizerFast"),c(_I,"href","/docs/transformers/pr_17869/en/model_doc/rag#transformers.RagTokenizer"),c(uI,"href","/docs/transformers/pr_17869/en/model_doc/realm#transformers.RealmTokenizer"),c(bI,"href","/docs/transformers/pr_17869/en/model_doc/realm#transformers.RealmTokenizerFast"),c(vI,"href","/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerTokenizer"),c(FI,"href","/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerTokenizerFast"),c(TI,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertTokenizer"),c(MI,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertTokenizerFast"),c(EI,"href","/docs/transformers/pr_17869/en/model_doc/retribert#transformers.RetriBertTokenizer"),c(CI,"href","/docs/transformers/pr_17869/en/model_doc/retribert#transformers.RetriBertTokenizerFast"),c(wI,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaTokenizer"),c(AI,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(LI,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerTokenizer"),c(yI,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerTokenizerFast"),c(xI,"href","/docs/transformers/pr_17869/en/model_doc/speech_to_text#transformers.Speech2TextTokenizer"),c($I,"href","/docs/transformers/pr_17869/en/model_doc/speech_to_text_2#transformers.Speech2Text2Tokenizer"),c(kI,"href","/docs/transformers/pr_17869/en/model_doc/splinter#transformers.SplinterTokenizer"),c(SI,"href","/docs/transformers/pr_17869/en/model_doc/splinter#transformers.SplinterTokenizerFast"),c(RI,"href","/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertTokenizer"),c(PI,"href","/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertTokenizerFast"),c(BI,"href","/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5Tokenizer"),c(II,"href","/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5TokenizerFast"),c(NI,"href","/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasTokenizer"),c(qI,"href","/docs/transformers/pr_17869/en/model_doc/tapex#transformers.TapexTokenizer"),c(jI,"href","/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLTokenizer"),c(DI,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertTokenizer"),c(GI,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertTokenizerFast"),c(OI,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertTokenizer"),c(VI,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertTokenizerFast"),c(XI,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(zI,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer"),c(QI,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2_phoneme#transformers.Wav2Vec2PhonemeCTCTokenizer"),c(WI,"href","/docs/transformers/pr_17869/en/model_doc/xglm#transformers.XGLMTokenizer"),c(HI,"href","/docs/transformers/pr_17869/en/model_doc/xglm#transformers.XGLMTokenizerFast"),c(UI,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMTokenizer"),c(JI,"href","/docs/transformers/pr_17869/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetTokenizer"),c(YI,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizer"),c(KI,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaTokenizerFast"),c(ZI,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaTokenizer"),c(eN,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaTokenizerFast"),c(oN,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetTokenizer"),c(rN,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetTokenizerFast"),c(tN,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertTokenizer"),c(aN,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertTokenizerFast"),c(Lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ch,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wh,"id","transformers.AutoFeatureExtractor"),c(wh,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(wh,"href","#transformers.AutoFeatureExtractor"),c(Si,"class","relative group"),c(nN,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained"),c(sN,"href","/docs/transformers/pr_17869/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(lN,"href","/docs/transformers/pr_17869/en/model_doc/clip#transformers.CLIPFeatureExtractor"),c(iN,"href","/docs/transformers/pr_17869/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(dN,"href","/docs/transformers/pr_17869/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(cN,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(fN,"href","/docs/transformers/pr_17869/en/model_doc/beit#transformers.BeitFeatureExtractor"),c(mN,"href","/docs/transformers/pr_17869/en/model_doc/deit#transformers.DeiTFeatureExtractor"),c(gN,"href","/docs/transformers/pr_17869/en/model_doc/detr#transformers.DetrFeatureExtractor"),c(hN,"href","/docs/transformers/pr_17869/en/model_doc/dpt#transformers.DPTFeatureExtractor"),c(pN,"href","/docs/transformers/pr_17869/en/model_doc/flava#transformers.FlavaFeatureExtractor"),c(_N,"href","/docs/transformers/pr_17869/en/model_doc/glpn#transformers.GLPNFeatureExtractor"),c(uN,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(bN,"href","/docs/transformers/pr_17869/en/model_doc/imagegpt#transformers.ImageGPTFeatureExtractor"),c(vN,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2FeatureExtractor"),c(FN,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3FeatureExtractor"),c(TN,"href","/docs/transformers/pr_17869/en/model_doc/levit#transformers.LevitFeatureExtractor"),c(MN,"href","/docs/transformers/pr_17869/en/model_doc/maskformer#transformers.MaskFormerFeatureExtractor"),c(EN,"href","/docs/transformers/pr_17869/en/model_doc/mctct#transformers.MCTCTFeatureExtractor"),c(CN,"href","/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverFeatureExtractor"),c(wN,"href","/docs/transformers/pr_17869/en/model_doc/poolformer#transformers.PoolFormerFeatureExtractor"),c(AN,"href","/docs/transformers/pr_17869/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(LN,"href","/docs/transformers/pr_17869/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(yN,"href","/docs/transformers/pr_17869/en/model_doc/segformer#transformers.SegformerFeatureExtractor"),c(xN,"href","/docs/transformers/pr_17869/en/model_doc/speech_to_text#transformers.Speech2TextFeatureExtractor"),c($N,"href","/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(kN,"href","/docs/transformers/pr_17869/en/model_doc/convnext#transformers.ConvNextFeatureExtractor"),c(SN,"href","/docs/transformers/pr_17869/en/model_doc/vilt#transformers.ViltFeatureExtractor"),c(RN,"href","/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(PN,"href","/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTFeatureExtractor"),c(BN,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(IN,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2FeatureExtractor"),c(NN,"href","/docs/transformers/pr_17869/en/model_doc/yolos#transformers.YolosFeatureExtractor"),c(He,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lp,"id","transformers.AutoProcessor"),c(lp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lp,"href","#transformers.AutoProcessor"),c(Ri,"class","relative group"),c(qN,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.AutoProcessor.from_pretrained"),c(jN,"href","/docs/transformers/pr_17869/en/model_doc/clip#transformers.CLIPProcessor"),c(DN,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2Processor"),c(GN,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3Processor"),c(ON,"href","/docs/transformers/pr_17869/en/model_doc/layoutxlm#transformers.LayoutXLMProcessor"),c(VN,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(XN,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(zN,"href","/docs/transformers/pr_17869/en/model_doc/speech_to_text#transformers.Speech2TextProcessor"),c(QN,"href","/docs/transformers/pr_17869/en/model_doc/speech_to_text_2#transformers.Speech2Text2Processor"),c(WN,"href","/docs/transformers/pr_17869/en/model_doc/trocr#transformers.TrOCRProcessor"),c(HN,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(UN,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(JN,"href","/docs/transformers/pr_17869/en/model_doc/vilt#transformers.ViltProcessor"),c(YN,"href","/docs/transformers/pr_17869/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderProcessor"),c(KN,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(ZN,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(eq,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Processor"),c(Ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lp,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yp,"id","transformers.AutoModel"),c(yp,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(yp,"href","#transformers.AutoModel"),c(Bi,"class","relative group"),c(oq,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(rq,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(tq,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aq,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertModel"),c(nq,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartModel"),c(sq,"href","/docs/transformers/pr_17869/en/model_doc/beit#transformers.BeitModel"),c(lq,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertModel"),c(iq,"href","/docs/transformers/pr_17869/en/model_doc/bert-generation#transformers.BertGenerationEncoder"),c(dq,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdModel"),c(cq,"href","/docs/transformers/pr_17869/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusModel"),c(fq,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.BlenderbotModel"),c(mq,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.BlenderbotSmallModel"),c(gq,"href","/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomModel"),c(hq,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertModel"),c(pq,"href","/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineModel"),c(_q,"href","/docs/transformers/pr_17869/en/model_doc/clip#transformers.CLIPModel"),c(uq,"href","/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertModel"),c(bq,"href","/docs/transformers/pr_17869/en/model_doc/convnext#transformers.ConvNextModel"),c(vq,"href","/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLModel"),c(Fq,"href","/docs/transformers/pr_17869/en/model_doc/cvt#transformers.CvtModel"),c(Tq,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecAudioModel"),c(Mq,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextModel"),c(Eq,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecVisionModel"),c(Cq,"href","/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaModel"),c(wq,"href","/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2Model"),c(Aq,"href","/docs/transformers/pr_17869/en/model_doc/decision_transformer#transformers.DecisionTransformerModel"),c(Lq,"href","/docs/transformers/pr_17869/en/model_doc/deit#transformers.DeiTModel"),c(yq,"href","/docs/transformers/pr_17869/en/model_doc/detr#transformers.DetrModel"),c(xq,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertModel"),c($q,"href","/docs/transformers/pr_17869/en/model_doc/dpr#transformers.DPRQuestionEncoder"),c(kq,"href","/docs/transformers/pr_17869/en/model_doc/dpt#transformers.DPTModel"),c(Sq,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraModel"),c(Rq,"href","/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertModel"),c(Pq,"href","/docs/transformers/pr_17869/en/model_doc/flava#transformers.FlavaModel"),c(Bq,"href","/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetModel"),c(Iq,"href","/docs/transformers/pr_17869/en/model_doc/fsmt#transformers.FSMTModel"),c(Nq,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelModel"),c(qq,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelBaseModel"),c(jq,"href","/docs/transformers/pr_17869/en/model_doc/glpn#transformers.GLPNModel"),c(Dq,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2Model"),c(Gq,"href","/docs/transformers/pr_17869/en/model_doc/gpt_neo#transformers.GPTNeoModel"),c(Oq,"href","/docs/transformers/pr_17869/en/model_doc/gpt_neox#transformers.GPTNeoXModel"),c(Vq,"href","/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJModel"),c(Xq,"href","/docs/transformers/pr_17869/en/model_doc/hubert#transformers.HubertModel"),c(zq,"href","/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertModel"),c(Qq,"href","/docs/transformers/pr_17869/en/model_doc/imagegpt#transformers.ImageGPTModel"),c(Wq,"href","/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMModel"),c(Hq,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2Model"),c(Uq,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3Model"),c(Jq,"href","/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDModel"),c(Yq,"href","/docs/transformers/pr_17869/en/model_doc/levit#transformers.LevitModel"),c(Kq,"href","/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerModel"),c(Zq,"href","/docs/transformers/pr_17869/en/model_doc/longt5#transformers.LongT5Model"),c(ej,"href","/docs/transformers/pr_17869/en/model_doc/luke#transformers.LukeModel"),c(oj,"href","/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.LxmertModel"),c(rj,"href","/docs/transformers/pr_17869/en/model_doc/m2m_100#transformers.M2M100Model"),c(tj,"href","/docs/transformers/pr_17869/en/model_doc/marian#transformers.MarianModel"),c(aj,"href","/docs/transformers/pr_17869/en/model_doc/maskformer#transformers.MaskFormerModel"),c(nj,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartModel"),c(sj,"href","/docs/transformers/pr_17869/en/model_doc/mctct#transformers.MCTCTModel"),c(lj,"href","/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertModel"),c(ij,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertModel"),c(dj,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetModel"),c(cj,"href","/docs/transformers/pr_17869/en/model_doc/mt5#transformers.MT5Model"),c(fj,"href","/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaModel"),c(mj,"href","/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerModel"),c(gj,"href","/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTModel"),c(hj,"href","/docs/transformers/pr_17869/en/model_doc/opt#transformers.OPTModel"),c(pj,"href","/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusModel"),c(_j,"href","/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverModel"),c(uj,"href","/docs/transformers/pr_17869/en/model_doc/plbart#transformers.PLBartModel"),c(bj,"href","/docs/transformers/pr_17869/en/model_doc/poolformer#transformers.PoolFormerModel"),c(vj,"href","/docs/transformers/pr_17869/en/model_doc/prophetnet#transformers.ProphetNetModel"),c(Fj,"href","/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertModel"),c(Tj,"href","/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerModel"),c(Mj,"href","/docs/transformers/pr_17869/en/model_doc/regnet#transformers.RegNetModel"),c(Ej,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertModel"),c(Cj,"href","/docs/transformers/pr_17869/en/model_doc/resnet#transformers.ResNetModel"),c(wj,"href","/docs/transformers/pr_17869/en/model_doc/retribert#transformers.RetriBertModel"),c(Aj,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaModel"),c(Lj,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerModel"),c(yj,"href","/docs/transformers/pr_17869/en/model_doc/segformer#transformers.SegformerModel"),c(xj,"href","/docs/transformers/pr_17869/en/model_doc/sew#transformers.SEWModel"),c($j,"href","/docs/transformers/pr_17869/en/model_doc/sew-d#transformers.SEWDModel"),c(kj,"href","/docs/transformers/pr_17869/en/model_doc/speech_to_text#transformers.Speech2TextModel"),c(Sj,"href","/docs/transformers/pr_17869/en/model_doc/splinter#transformers.SplinterModel"),c(Rj,"href","/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertModel"),c(Pj,"href","/docs/transformers/pr_17869/en/model_doc/swin#transformers.SwinModel"),c(Bj,"href","/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5Model"),c(Ij,"href","/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasModel"),c(Nj,"href","/docs/transformers/pr_17869/en/model_doc/trajectory_transformer#transformers.TrajectoryTransformerModel"),c(qj,"href","/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLModel"),c(jj,"href","/docs/transformers/pr_17869/en/model_doc/unispeech#transformers.UniSpeechModel"),c(Dj,"href","/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatModel"),c(Gj,"href","/docs/transformers/pr_17869/en/model_doc/van#transformers.VanModel"),c(Oj,"href","/docs/transformers/pr_17869/en/model_doc/vilt#transformers.ViltModel"),c(Vj,"href","/docs/transformers/pr_17869/en/model_doc/vision-text-dual-encoder#transformers.VisionTextDualEncoderModel"),c(Xj,"href","/docs/transformers/pr_17869/en/model_doc/visual_bert#transformers.VisualBertModel"),c(zj,"href","/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTModel"),c(Qj,"href","/docs/transformers/pr_17869/en/model_doc/vit_mae#transformers.ViTMAEModel"),c(Wj,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2Model"),c(Hj,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerModel"),c(Uj,"href","/docs/transformers/pr_17869/en/model_doc/wavlm#transformers.WavLMModel"),c(Jj,"href","/docs/transformers/pr_17869/en/model_doc/xglm#transformers.XGLMModel"),c(Yj,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMModel"),c(Kj,"href","/docs/transformers/pr_17869/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetModel"),c(Zj,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaModel"),c(eD,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLModel"),c(oD,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetModel"),c(rD,"href","/docs/transformers/pr_17869/en/model_doc/yolos#transformers.YolosModel"),c(tD,"href","/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoModel"),c(Je,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($u,"id","transformers.AutoModelForPreTraining"),c($u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($u,"href","#transformers.AutoModelForPreTraining"),c(qi,"class","relative group"),c(aD,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nD,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sD,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(st,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lD,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertForPreTraining"),c(iD,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(dD,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertForPreTraining"),c(cD,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdForPreTraining"),c(fD,"href","/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomForCausalLM"),c(mD,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(gD,"href","/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(hD,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(pD,"href","/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(_D,"href","/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(uD,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(bD,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraForPreTraining"),c(vD,"href","/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(FD,"href","/docs/transformers/pr_17869/en/model_doc/flava#transformers.FlavaForPreTraining"),c(TD,"href","/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetForPreTraining"),c(MD,"href","/docs/transformers/pr_17869/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(ED,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelForPreTraining"),c(CD,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(wD,"href","/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(AD,"href","/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(LD,"href","/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(yD,"href","/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.LxmertForPreTraining"),c(xD,"href","/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertForPreTraining"),c($D,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertForPreTraining"),c(kD,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(SD,"href","/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaForPreTraining"),c(RD,"href","/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(PD,"href","/docs/transformers/pr_17869/en/model_doc/retribert#transformers.RetriBertModel"),c(BD,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(ID,"href","/docs/transformers/pr_17869/en/model_doc/splinter#transformers.SplinterForPreTraining"),c(ND,"href","/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(qD,"href","/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(jD,"href","/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(DD,"href","/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(GD,"href","/docs/transformers/pr_17869/en/model_doc/unispeech#transformers.UniSpeechForPreTraining"),c(OD,"href","/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatForPreTraining"),c(VD,"href","/docs/transformers/pr_17869/en/model_doc/visual_bert#transformers.VisualBertForPreTraining"),c(XD,"href","/docs/transformers/pr_17869/en/model_doc/vit_mae#transformers.ViTMAEForPreTraining"),c(zD,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2ForPreTraining"),c(QD,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForPreTraining"),c(WD,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(HD,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(UD,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(JD,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C1,"id","transformers.AutoModelForCausalLM"),c(C1,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C1,"href","#transformers.AutoModelForCausalLM"),c(Gi,"class","relative group"),c(YD,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(KD,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(ZD,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(eG,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartForCausalLM"),c(oG,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertLMHeadModel"),c(rG,"href","/docs/transformers/pr_17869/en/model_doc/bert-generation#transformers.BertGenerationDecoder"),c(tG,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdForCausalLM"),c(aG,"href","/docs/transformers/pr_17869/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForCausalLM"),c(nG,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.BlenderbotForCausalLM"),c(sG,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForCausalLM"),c(lG,"href","/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomForCausalLM"),c(iG,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertForCausalLM"),c(dG,"href","/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLLMHeadModel"),c(cG,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextForCausalLM"),c(fG,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraForCausalLM"),c(mG,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2LMHeadModel"),c(gG,"href","/docs/transformers/pr_17869/en/model_doc/gpt_neo#transformers.GPTNeoForCausalLM"),c(hG,"href","/docs/transformers/pr_17869/en/model_doc/gpt_neox#transformers.GPTNeoXForCausalLM"),c(pG,"href","/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJForCausalLM"),c(_G,"href","/docs/transformers/pr_17869/en/model_doc/marian#transformers.MarianForCausalLM"),c(uG,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartForCausalLM"),c(bG,"href","/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertForCausalLM"),c(vG,"href","/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTLMHeadModel"),c(FG,"href","/docs/transformers/pr_17869/en/model_doc/opt#transformers.OPTForCausalLM"),c(TG,"href","/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusForCausalLM"),c(MG,"href","/docs/transformers/pr_17869/en/model_doc/plbart#transformers.PLBartForCausalLM"),c(EG,"href","/docs/transformers/pr_17869/en/model_doc/prophetnet#transformers.ProphetNetForCausalLM"),c(CG,"href","/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertLMHeadModel"),c(wG,"href","/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerModelWithLMHead"),c(AG,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertForCausalLM"),c(LG,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaForCausalLM"),c(yG,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerForCausalLM"),c(xG,"href","/docs/transformers/pr_17869/en/model_doc/speech_to_text_2#transformers.Speech2Text2ForCausalLM"),c($G,"href","/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLLMHeadModel"),c(kG,"href","/docs/transformers/pr_17869/en/model_doc/trocr#transformers.TrOCRForCausalLM"),c(SG,"href","/docs/transformers/pr_17869/en/model_doc/xglm#transformers.XGLMForCausalLM"),c(RG,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(PG,"href","/docs/transformers/pr_17869/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForCausalLM"),c(BG,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaForCausalLM"),c(IG,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForCausalLM"),c(NG,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetLMHeadModel"),c(Ke,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m2,"id","transformers.AutoModelForMaskedLM"),c(m2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m2,"href","#transformers.AutoModelForMaskedLM"),c(Xi,"class","relative group"),c(qG,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jG,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DG,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(it,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GG,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertForMaskedLM"),c(OG,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(VG,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertForMaskedLM"),c(XG,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdForMaskedLM"),c(zG,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertForMaskedLM"),c(QG,"href","/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertForMaskedLM"),c(WG,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextForMaskedLM"),c(HG,"href","/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaForMaskedLM"),c(UG,"href","/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2ForMaskedLM"),c(JG,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertForMaskedLM"),c(YG,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraForMaskedLM"),c(KG,"href","/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertWithLMHeadModel"),c(ZG,"href","/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetForMaskedLM"),c(eO,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelForMaskedLM"),c(oO,"href","/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertForMaskedLM"),c(rO,"href","/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMForMaskedLM"),c(tO,"href","/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerForMaskedLM"),c(aO,"href","/docs/transformers/pr_17869/en/model_doc/luke#transformers.LukeForMaskedLM"),c(nO,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(sO,"href","/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertForMaskedLM"),c(lO,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertForMaskedLM"),c(iO,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetForMaskedLM"),c(dO,"href","/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaForMaskedLM"),c(cO,"href","/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerForMaskedLM"),c(fO,"href","/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverForMaskedLM"),c(mO,"href","/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertForMaskedLM"),c(gO,"href","/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerForMaskedLM"),c(hO,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertForMaskedLM"),c(pO,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaForMaskedLM"),c(_O,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerForMaskedLM"),c(uO,"href","/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertForMaskedLM"),c(bO,"href","/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasForMaskedLM"),c(vO,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMWithLMHeadModel"),c(FO,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaForMaskedLM"),c(TO,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMaskedLM"),c(MO,"href","/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoForMaskedLM"),c(Ze,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(So,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Z2,"id","transformers.AutoModelForSeq2SeqLM"),c(Z2,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z2,"href","#transformers.AutoModelForSeq2SeqLM"),c(Wi,"class","relative group"),c(EO,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CO,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wO,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AO,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartForConditionalGeneration"),c(LO,"href","/docs/transformers/pr_17869/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForConditionalGeneration"),c(yO,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.BlenderbotForConditionalGeneration"),c(xO,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.BlenderbotSmallForConditionalGeneration"),c($O,"href","/docs/transformers/pr_17869/en/model_doc/encoder-decoder#transformers.EncoderDecoderModel"),c(kO,"href","/docs/transformers/pr_17869/en/model_doc/fsmt#transformers.FSMTForConditionalGeneration"),c(SO,"href","/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDForConditionalGeneration"),c(RO,"href","/docs/transformers/pr_17869/en/model_doc/longt5#transformers.LongT5ForConditionalGeneration"),c(PO,"href","/docs/transformers/pr_17869/en/model_doc/m2m_100#transformers.M2M100ForConditionalGeneration"),c(BO,"href","/docs/transformers/pr_17869/en/model_doc/marian#transformers.MarianMTModel"),c(IO,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartForConditionalGeneration"),c(NO,"href","/docs/transformers/pr_17869/en/model_doc/mt5#transformers.MT5ForConditionalGeneration"),c(qO,"href","/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.PegasusForConditionalGeneration"),c(jO,"href","/docs/transformers/pr_17869/en/model_doc/plbart#transformers.PLBartForConditionalGeneration"),c(DO,"href","/docs/transformers/pr_17869/en/model_doc/prophetnet#transformers.ProphetNetForConditionalGeneration"),c(GO,"href","/docs/transformers/pr_17869/en/model_doc/t5#transformers.T5ForConditionalGeneration"),c(OO,"href","/docs/transformers/pr_17869/en/model_doc/xlm-prophetnet#transformers.XLMProphetNetForConditionalGeneration"),c(eo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fb,"id","transformers.AutoModelForSequenceClassification"),c(Fb,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Fb,"href","#transformers.AutoModelForSequenceClassification"),c(Ji,"class","relative group"),c(VO,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(XO,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(zO,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QO,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertForSequenceClassification"),c(WO,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartForSequenceClassification"),c(HO,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertForSequenceClassification"),c(UO,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdForSequenceClassification"),c(JO,"href","/docs/transformers/pr_17869/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForSequenceClassification"),c(YO,"href","/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomForSequenceClassification"),c(KO,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertForSequenceClassification"),c(ZO,"href","/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineForSequenceClassification"),c(eV,"href","/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertForSequenceClassification"),c(oV,"href","/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.CTRLForSequenceClassification"),c(rV,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextForSequenceClassification"),c(tV,"href","/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaForSequenceClassification"),c(aV,"href","/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2ForSequenceClassification"),c(nV,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertForSequenceClassification"),c(sV,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraForSequenceClassification"),c(lV,"href","/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertForSequenceClassification"),c(iV,"href","/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetForSequenceClassification"),c(dV,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelForSequenceClassification"),c(cV,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2ForSequenceClassification"),c(fV,"href","/docs/transformers/pr_17869/en/model_doc/gpt_neo#transformers.GPTNeoForSequenceClassification"),c(mV,"href","/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJForSequenceClassification"),c(gV,"href","/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertForSequenceClassification"),c(hV,"href","/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMForSequenceClassification"),c(pV,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForSequenceClassification"),c(_V,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForSequenceClassification"),c(uV,"href","/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDForSequenceClassification"),c(bV,"href","/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerForSequenceClassification"),c(vV,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartForSequenceClassification"),c(FV,"href","/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertForSequenceClassification"),c(TV,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertForSequenceClassification"),c(MV,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetForSequenceClassification"),c(EV,"href","/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaForSequenceClassification"),c(CV,"href","/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerForSequenceClassification"),c(wV,"href","/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.OpenAIGPTForSequenceClassification"),c(AV,"href","/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverForSequenceClassification"),c(LV,"href","/docs/transformers/pr_17869/en/model_doc/plbart#transformers.PLBartForSequenceClassification"),c(yV,"href","/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertForSequenceClassification"),c(xV,"href","/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerForSequenceClassification"),c($V,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertForSequenceClassification"),c(kV,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaForSequenceClassification"),c(SV,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerForSequenceClassification"),c(RV,"href","/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertForSequenceClassification"),c(PV,"href","/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasForSequenceClassification"),c(BV,"href","/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TransfoXLForSequenceClassification"),c(IV,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMForSequenceClassification"),c(NV,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaForSequenceClassification"),c(qV,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForSequenceClassification"),c(jV,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetForSequenceClassification"),c(DV,"href","/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoForSequenceClassification"),c(oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vv,"id","transformers.AutoModelForMultipleChoice"),c(vv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(vv,"href","#transformers.AutoModelForMultipleChoice"),c(Zi,"class","relative group"),c(GV,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OV,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VV,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XV,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertForMultipleChoice"),c(zV,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertForMultipleChoice"),c(QV,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdForMultipleChoice"),c(WV,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertForMultipleChoice"),c(HV,"href","/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineForMultipleChoice"),c(UV,"href","/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertForMultipleChoice"),c(JV,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextForMultipleChoice"),c(YV,"href","/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2ForMultipleChoice"),c(KV,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertForMultipleChoice"),c(ZV,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraForMultipleChoice"),c(eX,"href","/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertForMultipleChoice"),c(oX,"href","/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetForMultipleChoice"),c(rX,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelForMultipleChoice"),c(tX,"href","/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertForMultipleChoice"),c(aX,"href","/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerForMultipleChoice"),c(nX,"href","/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertForMultipleChoice"),c(sX,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertForMultipleChoice"),c(lX,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetForMultipleChoice"),c(iX,"href","/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaForMultipleChoice"),c(dX,"href","/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerForMultipleChoice"),c(cX,"href","/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertForMultipleChoice"),c(fX,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertForMultipleChoice"),c(mX,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaForMultipleChoice"),c(gX,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerForMultipleChoice"),c(hX,"href","/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertForMultipleChoice"),c(pX,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMForMultipleChoice"),c(_X,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaForMultipleChoice"),c(uX,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForMultipleChoice"),c(bX,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetForMultipleChoice"),c(vX,"href","/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoForMultipleChoice"),c(ro,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zv,"id","transformers.AutoModelForNextSentencePrediction"),c(Zv,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Zv,"href","#transformers.AutoModelForNextSentencePrediction"),c(rd,"class","relative group"),c(FX,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(TX,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(MX,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(EX,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertForNextSentencePrediction"),c(CX,"href","/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetForNextSentencePrediction"),c(wX,"href","/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertForNextSentencePrediction"),c(AX,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertForNextSentencePrediction"),c(LX,"href","/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaForNextSentencePrediction"),c(yX,"href","/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertForNextSentencePrediction"),c(to,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dF,"id","transformers.AutoModelForTokenClassification"),c(dF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(dF,"href","#transformers.AutoModelForTokenClassification"),c(nd,"class","relative group"),c(xX,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($X,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(kX,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(SX,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertForTokenClassification"),c(RX,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertForTokenClassification"),c(PX,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdForTokenClassification"),c(BX,"href","/docs/transformers/pr_17869/en/model_doc/bloom#transformers.BloomForTokenClassification"),c(IX,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertForTokenClassification"),c(NX,"href","/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineForTokenClassification"),c(qX,"href","/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertForTokenClassification"),c(jX,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextForTokenClassification"),c(DX,"href","/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaForTokenClassification"),c(GX,"href","/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2ForTokenClassification"),c(OX,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertForTokenClassification"),c(VX,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraForTokenClassification"),c(XX,"href","/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertForTokenClassification"),c(zX,"href","/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetForTokenClassification"),c(QX,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelForTokenClassification"),c(WX,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.GPT2ForTokenClassification"),c(HX,"href","/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertForTokenClassification"),c(UX,"href","/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.LayoutLMForTokenClassification"),c(JX,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForTokenClassification"),c(YX,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForTokenClassification"),c(KX,"href","/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerForTokenClassification"),c(ZX,"href","/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertForTokenClassification"),c(ez,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertForTokenClassification"),c(oz,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetForTokenClassification"),c(rz,"href","/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaForTokenClassification"),c(tz,"href","/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerForTokenClassification"),c(az,"href","/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertForTokenClassification"),c(nz,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertForTokenClassification"),c(sz,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaForTokenClassification"),c(lz,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerForTokenClassification"),c(iz,"href","/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertForTokenClassification"),c(dz,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMForTokenClassification"),c(cz,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaForTokenClassification"),c(fz,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForTokenClassification"),c(mz,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetForTokenClassification"),c(gz,"href","/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoForTokenClassification"),c(ao,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(UF,"id","transformers.AutoModelForQuestionAnswering"),c(UF,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(UF,"href","#transformers.AutoModelForQuestionAnswering"),c(id,"class","relative group"),c(hz,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pz,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_z,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uz,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.AlbertForQuestionAnswering"),c(bz,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.BartForQuestionAnswering"),c(vz,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.BertForQuestionAnswering"),c(Fz,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.BigBirdForQuestionAnswering"),c(Tz,"href","/docs/transformers/pr_17869/en/model_doc/bigbird_pegasus#transformers.BigBirdPegasusForQuestionAnswering"),c(Mz,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.CamembertForQuestionAnswering"),c(Ez,"href","/docs/transformers/pr_17869/en/model_doc/canine#transformers.CanineForQuestionAnswering"),c(Cz,"href","/docs/transformers/pr_17869/en/model_doc/convbert#transformers.ConvBertForQuestionAnswering"),c(wz,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecTextForQuestionAnswering"),c(Az,"href","/docs/transformers/pr_17869/en/model_doc/deberta#transformers.DebertaForQuestionAnswering"),c(Lz,"href","/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.DebertaV2ForQuestionAnswering"),c(yz,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.DistilBertForQuestionAnswering"),c(xz,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.ElectraForQuestionAnswering"),c($z,"href","/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.FlaubertForQuestionAnsweringSimple"),c(kz,"href","/docs/transformers/pr_17869/en/model_doc/fnet#transformers.FNetForQuestionAnswering"),c(Sz,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.FunnelForQuestionAnswering"),c(Rz,"href","/docs/transformers/pr_17869/en/model_doc/gptj#transformers.GPTJForQuestionAnswering"),c(Pz,"href","/docs/transformers/pr_17869/en/model_doc/ibert#transformers.IBertForQuestionAnswering"),c(Bz,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv2#transformers.LayoutLMv2ForQuestionAnswering"),c(Iz,"href","/docs/transformers/pr_17869/en/model_doc/layoutlmv3#transformers.LayoutLMv3ForQuestionAnswering"),c(Nz,"href","/docs/transformers/pr_17869/en/model_doc/led#transformers.LEDForQuestionAnswering"),c(qz,"href","/docs/transformers/pr_17869/en/model_doc/longformer#transformers.LongformerForQuestionAnswering"),c(jz,"href","/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.LxmertForQuestionAnswering"),c(Dz,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.MBartForQuestionAnswering"),c(Gz,"href","/docs/transformers/pr_17869/en/model_doc/megatron-bert#transformers.MegatronBertForQuestionAnswering"),c(Oz,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.MobileBertForQuestionAnswering"),c(Vz,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.MPNetForQuestionAnswering"),c(Xz,"href","/docs/transformers/pr_17869/en/model_doc/nezha#transformers.NezhaForQuestionAnswering"),c(zz,"href","/docs/transformers/pr_17869/en/model_doc/nystromformer#transformers.NystromformerForQuestionAnswering"),c(Qz,"href","/docs/transformers/pr_17869/en/model_doc/qdqbert#transformers.QDQBertForQuestionAnswering"),c(Wz,"href","/docs/transformers/pr_17869/en/model_doc/reformer#transformers.ReformerForQuestionAnswering"),c(Hz,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.RemBertForQuestionAnswering"),c(Uz,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.RobertaForQuestionAnswering"),c(Jz,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.RoFormerForQuestionAnswering"),c(Yz,"href","/docs/transformers/pr_17869/en/model_doc/splinter#transformers.SplinterForQuestionAnswering"),c(Kz,"href","/docs/transformers/pr_17869/en/model_doc/squeezebert#transformers.SqueezeBertForQuestionAnswering"),c(Zz,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.XLMForQuestionAnsweringSimple"),c(eQ,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.XLMRobertaForQuestionAnswering"),c(oQ,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta-xl#transformers.XLMRobertaXLForQuestionAnswering"),c(rQ,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.XLNetForQuestionAnsweringSimple"),c(tQ,"href","/docs/transformers/pr_17869/en/model_doc/yoso#transformers.YosoForQuestionAnswering"),c(no,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(D6,"id","transformers.AutoModelForTableQuestionAnswering"),c(D6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D6,"href","#transformers.AutoModelForTableQuestionAnswering"),c(fd,"class","relative group"),c(aQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lQ,"href","/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TapasForQuestionAnswering"),c(so,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Do,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z6,"id","transformers.AutoModelForImageClassification"),c(z6,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z6,"href","#transformers.AutoModelForImageClassification"),c(hd,"class","relative group"),c(iQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(dQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(cQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(_t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fQ,"href","/docs/transformers/pr_17869/en/model_doc/beit#transformers.BeitForImageClassification"),c(mQ,"href","/docs/transformers/pr_17869/en/model_doc/convnext#transformers.ConvNextForImageClassification"),c(gQ,"href","/docs/transformers/pr_17869/en/model_doc/cvt#transformers.CvtForImageClassification"),c(hQ,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecVisionForImageClassification"),c(pQ,"href","/docs/transformers/pr_17869/en/model_doc/deit#transformers.DeiTForImageClassification"),c(_Q,"href","/docs/transformers/pr_17869/en/model_doc/deit#transformers.DeiTForImageClassificationWithTeacher"),c(uQ,"href","/docs/transformers/pr_17869/en/model_doc/imagegpt#transformers.ImageGPTForImageClassification"),c(bQ,"href","/docs/transformers/pr_17869/en/model_doc/levit#transformers.LevitForImageClassification"),c(vQ,"href","/docs/transformers/pr_17869/en/model_doc/levit#transformers.LevitForImageClassificationWithTeacher"),c(FQ,"href","/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverForImageClassificationLearned"),c(TQ,"href","/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverForImageClassificationFourier"),c(MQ,"href","/docs/transformers/pr_17869/en/model_doc/perceiver#transformers.PerceiverForImageClassificationConvProcessing"),c(EQ,"href","/docs/transformers/pr_17869/en/model_doc/poolformer#transformers.PoolFormerForImageClassification"),c(CQ,"href","/docs/transformers/pr_17869/en/model_doc/regnet#transformers.RegNetForImageClassification"),c(wQ,"href","/docs/transformers/pr_17869/en/model_doc/resnet#transformers.ResNetForImageClassification"),c(AQ,"href","/docs/transformers/pr_17869/en/model_doc/segformer#transformers.SegformerForImageClassification"),c(LQ,"href","/docs/transformers/pr_17869/en/model_doc/swin#transformers.SwinForImageClassification"),c(yQ,"href","/docs/transformers/pr_17869/en/model_doc/van#transformers.VanForImageClassification"),c(xQ,"href","/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTForImageClassification"),c(lo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lT,"id","transformers.AutoModelForVision2Seq"),c(lT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(lT,"href","#transformers.AutoModelForVision2Seq"),c(ud,"class","relative group"),c($Q,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RQ,"href","/docs/transformers/pr_17869/en/model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel"),c(io,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Oo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mT,"id","transformers.AutoModelForVisualQuestionAnswering"),c(mT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mT,"href","#transformers.AutoModelForVisualQuestionAnswering"),c(Fd,"class","relative group"),c(PQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NQ,"href","/docs/transformers/pr_17869/en/model_doc/vilt#transformers.ViltForQuestionAnswering"),c(co,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uT,"id","transformers.AutoModelForAudioClassification"),c(uT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uT,"href","#transformers.AutoModelForAudioClassification"),c(Ed,"class","relative group"),c(qQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(DQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ft,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(GQ,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecAudioForSequenceClassification"),c(OQ,"href","/docs/transformers/pr_17869/en/model_doc/hubert#transformers.HubertForSequenceClassification"),c(VQ,"href","/docs/transformers/pr_17869/en/model_doc/sew#transformers.SEWForSequenceClassification"),c(XQ,"href","/docs/transformers/pr_17869/en/model_doc/sew-d#transformers.SEWDForSequenceClassification"),c(zQ,"href","/docs/transformers/pr_17869/en/model_doc/unispeech#transformers.UniSpeechForSequenceClassification"),c(QQ,"href","/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatForSequenceClassification"),c(WQ,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2ForSequenceClassification"),c(HQ,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForSequenceClassification"),c(UQ,"href","/docs/transformers/pr_17869/en/model_doc/wavlm#transformers.WavLMForSequenceClassification"),c(fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Xo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c($T,"id","transformers.AutoModelForAudioFrameClassification"),c($T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($T,"href","#transformers.AutoModelForAudioFrameClassification"),c(Ad,"class","relative group"),c(JQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(YQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(KQ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Tt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZQ,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecAudioForAudioFrameClassification"),c(eW,"href","/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatForAudioFrameClassification"),c(oW,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2ForAudioFrameClassification"),c(rW,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForAudioFrameClassification"),c(tW,"href","/docs/transformers/pr_17869/en/model_doc/wavlm#transformers.WavLMForAudioFrameClassification"),c(mo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jT,"id","transformers.AutoModelForCTC"),c(jT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jT,"href","#transformers.AutoModelForCTC"),c(xd,"class","relative group"),c(aW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(nW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(sW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Mt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lW,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecAudioForCTC"),c(iW,"href","/docs/transformers/pr_17869/en/model_doc/hubert#transformers.HubertForCTC"),c(dW,"href","/docs/transformers/pr_17869/en/model_doc/mctct#transformers.MCTCTForCTC"),c(cW,"href","/docs/transformers/pr_17869/en/model_doc/sew#transformers.SEWForCTC"),c(fW,"href","/docs/transformers/pr_17869/en/model_doc/sew-d#transformers.SEWDForCTC"),c(mW,"href","/docs/transformers/pr_17869/en/model_doc/unispeech#transformers.UniSpeechForCTC"),c(gW,"href","/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatForCTC"),c(hW,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC"),c(pW,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForCTC"),c(_W,"href","/docs/transformers/pr_17869/en/model_doc/wavlm#transformers.WavLMForCTC"),c(go,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Qo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ZT,"id","transformers.AutoModelForSpeechSeq2Seq"),c(ZT,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ZT,"href","#transformers.AutoModelForSpeechSeq2Seq"),c(Sd,"class","relative group"),c(uW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FW,"href","/docs/transformers/pr_17869/en/model_doc/speech-encoder-decoder#transformers.SpeechEncoderDecoderModel"),c(TW,"href","/docs/transformers/pr_17869/en/model_doc/speech_to_text#transformers.Speech2TextForConditionalGeneration"),c(ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Wo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(n7,"id","transformers.AutoModelForAudioXVector"),c(n7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(n7,"href","#transformers.AutoModelForAudioXVector"),c(Bd,"class","relative group"),c(MW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(EW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(CW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ct,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wW,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecAudioForXVector"),c(AW,"href","/docs/transformers/pr_17869/en/model_doc/unispeech-sat#transformers.UniSpeechSatForXVector"),c(LW,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.Wav2Vec2ForXVector"),c(yW,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2-conformer#transformers.Wav2Vec2ConformerForXVector"),c(xW,"href","/docs/transformers/pr_17869/en/model_doc/wavlm#transformers.WavLMForXVector"),c(po,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ho,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(h7,"id","transformers.AutoModelForMaskedImageModeling"),c(h7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(h7,"href","#transformers.AutoModelForMaskedImageModeling"),c(qd,"class","relative group"),c($W,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RW,"href","/docs/transformers/pr_17869/en/model_doc/deit#transformers.DeiTForMaskedImageModeling"),c(PW,"href","/docs/transformers/pr_17869/en/model_doc/swin#transformers.SwinForMaskedImageModeling"),c(BW,"href","/docs/transformers/pr_17869/en/model_doc/vit#transformers.ViTForMaskedImageModeling"),c(_o,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(T7,"id","transformers.AutoModelForObjectDetection"),c(T7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T7,"href","#transformers.AutoModelForObjectDetection"),c(Od,"class","relative group"),c(IW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(NW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(qW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(At,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jW,"href","/docs/transformers/pr_17869/en/model_doc/detr#transformers.DetrForObjectDetection"),c(DW,"href","/docs/transformers/pr_17869/en/model_doc/yolos#transformers.YolosForObjectDetection"),c(uo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Jo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(L7,"id","transformers.AutoModelForImageSegmentation"),c(L7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(L7,"href","#transformers.AutoModelForImageSegmentation"),c(zd,"class","relative group"),c(GW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Lt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XW,"href","/docs/transformers/pr_17869/en/model_doc/detr#transformers.DetrForSegmentation"),c(bo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(S7,"id","transformers.AutoModelForSemanticSegmentation"),c(S7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(S7,"href","#transformers.AutoModelForSemanticSegmentation"),c(Hd,"class","relative group"),c(zW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(QW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(WW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(HW,"href","/docs/transformers/pr_17869/en/model_doc/beit#transformers.BeitForSemanticSegmentation"),c(UW,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.Data2VecVisionForSemanticSegmentation"),c(JW,"href","/docs/transformers/pr_17869/en/model_doc/dpt#transformers.DPTForSemanticSegmentation"),c(YW,"href","/docs/transformers/pr_17869/en/model_doc/segformer#transformers.SegformerForSemanticSegmentation"),c(vo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Ko,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(D7,"id","transformers.AutoModelForInstanceSegmentation"),c(D7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D7,"href","#transformers.AutoModelForInstanceSegmentation"),c(Yd,"class","relative group"),c(KW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZW,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eH,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oH,"href","/docs/transformers/pr_17869/en/model_doc/maskformer#transformers.MaskFormerForInstanceSegmentation"),c(Fo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Zo,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(z7,"id","transformers.TFAutoModel"),c(z7,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(z7,"href","#transformers.TFAutoModel"),c(ec,"class","relative group"),c(rH,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(tH,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(aH,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c($t,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nH,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.TFAlbertModel"),c(sH,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.TFBartModel"),c(lH,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertModel"),c(iH,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.TFBlenderbotModel"),c(dH,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallModel"),c(cH,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.TFCamembertModel"),c(fH,"href","/docs/transformers/pr_17869/en/model_doc/clip#transformers.TFCLIPModel"),c(mH,"href","/docs/transformers/pr_17869/en/model_doc/convbert#transformers.TFConvBertModel"),c(gH,"href","/docs/transformers/pr_17869/en/model_doc/convnext#transformers.TFConvNextModel"),c(hH,"href","/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.TFCTRLModel"),c(pH,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.TFData2VecVisionModel"),c(_H,"href","/docs/transformers/pr_17869/en/model_doc/deberta#transformers.TFDebertaModel"),c(uH,"href","/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.TFDebertaV2Model"),c(bH,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.TFDistilBertModel"),c(vH,"href","/docs/transformers/pr_17869/en/model_doc/dpr#transformers.TFDPRQuestionEncoder"),c(FH,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.TFElectraModel"),c(TH,"href","/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.TFFlaubertModel"),c(MH,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.TFFunnelModel"),c(EH,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.TFFunnelBaseModel"),c(CH,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.TFGPT2Model"),c(wH,"href","/docs/transformers/pr_17869/en/model_doc/gptj#transformers.TFGPTJModel"),c(AH,"href","/docs/transformers/pr_17869/en/model_doc/hubert#transformers.TFHubertModel"),c(LH,"href","/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.TFLayoutLMModel"),c(yH,"href","/docs/transformers/pr_17869/en/model_doc/led#transformers.TFLEDModel"),c(xH,"href","/docs/transformers/pr_17869/en/model_doc/longformer#transformers.TFLongformerModel"),c($H,"href","/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.TFLxmertModel"),c(kH,"href","/docs/transformers/pr_17869/en/model_doc/marian#transformers.TFMarianModel"),c(SH,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.TFMBartModel"),c(RH,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.TFMobileBertModel"),c(PH,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.TFMPNetModel"),c(BH,"href","/docs/transformers/pr_17869/en/model_doc/mt5#transformers.TFMT5Model"),c(IH,"href","/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.TFOpenAIGPTModel"),c(NH,"href","/docs/transformers/pr_17869/en/model_doc/opt#transformers.TFOPTModel"),c(qH,"href","/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.TFPegasusModel"),c(jH,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.TFRemBertModel"),c(DH,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.TFRobertaModel"),c(GH,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.TFRoFormerModel"),c(OH,"href","/docs/transformers/pr_17869/en/model_doc/speech_to_text#transformers.TFSpeech2TextModel"),c(VH,"href","/docs/transformers/pr_17869/en/model_doc/swin#transformers.TFSwinModel"),c(XH,"href","/docs/transformers/pr_17869/en/model_doc/t5#transformers.TFT5Model"),c(zH,"href","/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TFTapasModel"),c(QH,"href","/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TFTransfoXLModel"),c(WH,"href","/docs/transformers/pr_17869/en/model_doc/vit#transformers.TFViTModel"),c(HH,"href","/docs/transformers/pr_17869/en/model_doc/vit_mae#transformers.TFViTMAEModel"),c(UH,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.TFWav2Vec2Model"),c(JH,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.TFXLMModel"),c(YH,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.TFXLMRobertaModel"),c(KH,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.TFXLNetModel"),c(yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(D8,"id","transformers.TFAutoModelForPreTraining"),c(D8,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(D8,"href","#transformers.TFAutoModelForPreTraining"),c(tc,"class","relative group"),c(ZH,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(eU,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(oU,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rU,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.TFAlbertForPreTraining"),c(tU,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(aU,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertForPreTraining"),c(nU,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(sU,"href","/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(lU,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(iU,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.TFElectraForPreTraining"),c(dU,"href","/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(cU,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.TFFunnelForPreTraining"),c(fU,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(mU,"href","/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(gU,"href","/docs/transformers/pr_17869/en/model_doc/lxmert#transformers.TFLxmertForPreTraining"),c(hU,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.TFMobileBertForPreTraining"),c(pU,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(_U,"href","/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(uU,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(bU,"href","/docs/transformers/pr_17869/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(vU,"href","/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(FU,"href","/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(TU,"href","/docs/transformers/pr_17869/en/model_doc/vit_mae#transformers.TFViTMAEForPreTraining"),c(MU,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(EU,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(CU,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c(xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(m9,"id","transformers.TFAutoModelForCausalLM"),c(m9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(m9,"href","#transformers.TFAutoModelForCausalLM"),c(sc,"class","relative group"),c(wU,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AU,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LU,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(St,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yU,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertLMHeadModel"),c(xU,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.TFCamembertForCausalLM"),c($U,"href","/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.TFCTRLLMHeadModel"),c(kU,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.TFGPT2LMHeadModel"),c(SU,"href","/docs/transformers/pr_17869/en/model_doc/gptj#transformers.TFGPTJForCausalLM"),c(RU,"href","/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.TFOpenAIGPTLMHeadModel"),c(PU,"href","/docs/transformers/pr_17869/en/model_doc/opt#transformers.TFOPTForCausalLM"),c(BU,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.TFRemBertForCausalLM"),c(IU,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.TFRobertaForCausalLM"),c(NU,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.TFRoFormerForCausalLM"),c(qU,"href","/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TFTransfoXLLMHeadModel"),c(jU,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(DU,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.TFXLNetLMHeadModel"),c($r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(y9,"id","transformers.TFAutoModelForImageClassification"),c(y9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(y9,"href","#transformers.TFAutoModelForImageClassification"),c(dc,"class","relative group"),c(GU,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(OU,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(VU,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Rt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XU,"href","/docs/transformers/pr_17869/en/model_doc/convnext#transformers.TFConvNextForImageClassification"),c(zU,"href","/docs/transformers/pr_17869/en/model_doc/data2vec#transformers.TFData2VecVisionForImageClassification"),c(QU,"href","/docs/transformers/pr_17869/en/model_doc/swin#transformers.TFSwinForImageClassification"),c(WU,"href","/docs/transformers/pr_17869/en/model_doc/vit#transformers.TFViTForImageClassification"),c(kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(B9,"id","transformers.TFAutoModelForMaskedLM"),c(B9,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B9,"href","#transformers.TFAutoModelForMaskedLM"),c(mc,"class","relative group"),c(HU,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(UU,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(JU,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Pt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(YU,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.TFAlbertForMaskedLM"),c(KU,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertForMaskedLM"),c(ZU,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.TFCamembertForMaskedLM"),c(eJ,"href","/docs/transformers/pr_17869/en/model_doc/convbert#transformers.TFConvBertForMaskedLM"),c(oJ,"href","/docs/transformers/pr_17869/en/model_doc/deberta#transformers.TFDebertaForMaskedLM"),c(rJ,"href","/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.TFDebertaV2ForMaskedLM"),c(tJ,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.TFDistilBertForMaskedLM"),c(aJ,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.TFElectraForMaskedLM"),c(nJ,"href","/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.TFFlaubertWithLMHeadModel"),c(sJ,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.TFFunnelForMaskedLM"),c(lJ,"href","/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.TFLayoutLMForMaskedLM"),c(iJ,"href","/docs/transformers/pr_17869/en/model_doc/longformer#transformers.TFLongformerForMaskedLM"),c(dJ,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.TFMobileBertForMaskedLM"),c(cJ,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.TFMPNetForMaskedLM"),c(fJ,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.TFRemBertForMaskedLM"),c(mJ,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.TFRobertaForMaskedLM"),c(gJ,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.TFRoFormerForMaskedLM"),c(hJ,"href","/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TFTapasForMaskedLM"),c(pJ,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.TFXLMWithLMHeadModel"),c(_J,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMaskedLM"),c(Sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ar,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(aM,"id","transformers.TFAutoModelForSeq2SeqLM"),c(aM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(aM,"href","#transformers.TFAutoModelForSeq2SeqLM"),c(pc,"class","relative group"),c(uJ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(bJ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(vJ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Bt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(FJ,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.TFBartForConditionalGeneration"),c(TJ,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.TFBlenderbotForConditionalGeneration"),c(MJ,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.TFBlenderbotSmallForConditionalGeneration"),c(EJ,"href","/docs/transformers/pr_17869/en/model_doc/encoder-decoder#transformers.TFEncoderDecoderModel"),c(CJ,"href","/docs/transformers/pr_17869/en/model_doc/led#transformers.TFLEDForConditionalGeneration"),c(wJ,"href","/docs/transformers/pr_17869/en/model_doc/marian#transformers.TFMarianMTModel"),c(AJ,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.TFMBartForConditionalGeneration"),c(LJ,"href","/docs/transformers/pr_17869/en/model_doc/mt5#transformers.TFMT5ForConditionalGeneration"),c(yJ,"href","/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.TFPegasusForConditionalGeneration"),c(xJ,"href","/docs/transformers/pr_17869/en/model_doc/t5#transformers.TFT5ForConditionalGeneration"),c(Rr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uM,"id","transformers.TFAutoModelForSequenceClassification"),c(uM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uM,"href","#transformers.TFAutoModelForSequenceClassification"),c(bc,"class","relative group"),c($J,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kJ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SJ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(It,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RJ,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.TFAlbertForSequenceClassification"),c(PJ,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertForSequenceClassification"),c(BJ,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.TFCamembertForSequenceClassification"),c(IJ,"href","/docs/transformers/pr_17869/en/model_doc/convbert#transformers.TFConvBertForSequenceClassification"),c(NJ,"href","/docs/transformers/pr_17869/en/model_doc/ctrl#transformers.TFCTRLForSequenceClassification"),c(qJ,"href","/docs/transformers/pr_17869/en/model_doc/deberta#transformers.TFDebertaForSequenceClassification"),c(jJ,"href","/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.TFDebertaV2ForSequenceClassification"),c(DJ,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.TFDistilBertForSequenceClassification"),c(GJ,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.TFElectraForSequenceClassification"),c(OJ,"href","/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.TFFlaubertForSequenceClassification"),c(VJ,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.TFFunnelForSequenceClassification"),c(XJ,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.TFGPT2ForSequenceClassification"),c(zJ,"href","/docs/transformers/pr_17869/en/model_doc/gptj#transformers.TFGPTJForSequenceClassification"),c(QJ,"href","/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.TFLayoutLMForSequenceClassification"),c(WJ,"href","/docs/transformers/pr_17869/en/model_doc/longformer#transformers.TFLongformerForSequenceClassification"),c(HJ,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.TFMobileBertForSequenceClassification"),c(UJ,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.TFMPNetForSequenceClassification"),c(JJ,"href","/docs/transformers/pr_17869/en/model_doc/openai-gpt#transformers.TFOpenAIGPTForSequenceClassification"),c(YJ,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.TFRemBertForSequenceClassification"),c(KJ,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.TFRobertaForSequenceClassification"),c(ZJ,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.TFRoFormerForSequenceClassification"),c(eY,"href","/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TFTapasForSequenceClassification"),c(oY,"href","/docs/transformers/pr_17869/en/model_doc/transfo-xl#transformers.TFTransfoXLForSequenceClassification"),c(rY,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.TFXLMForSequenceClassification"),c(tY,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForSequenceClassification"),c(aY,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.TFXLNetForSequenceClassification"),c(Pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(QM,"id","transformers.TFAutoModelForMultipleChoice"),c(QM,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(QM,"href","#transformers.TFAutoModelForMultipleChoice"),c(Tc,"class","relative group"),c(nY,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(sY,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(lY,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Nt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(iY,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.TFAlbertForMultipleChoice"),c(dY,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertForMultipleChoice"),c(cY,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.TFCamembertForMultipleChoice"),c(fY,"href","/docs/transformers/pr_17869/en/model_doc/convbert#transformers.TFConvBertForMultipleChoice"),c(mY,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.TFDistilBertForMultipleChoice"),c(gY,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.TFElectraForMultipleChoice"),c(hY,"href","/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.TFFlaubertForMultipleChoice"),c(pY,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.TFFunnelForMultipleChoice"),c(_Y,"href","/docs/transformers/pr_17869/en/model_doc/longformer#transformers.TFLongformerForMultipleChoice"),c(uY,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.TFMobileBertForMultipleChoice"),c(bY,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.TFMPNetForMultipleChoice"),c(vY,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.TFRemBertForMultipleChoice"),c(FY,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.TFRobertaForMultipleChoice"),c(TY,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.TFRoFormerForMultipleChoice"),c(MY,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.TFXLMForMultipleChoice"),c(EY,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForMultipleChoice"),c(CY,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.TFXLNetForMultipleChoice"),c(Br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(lr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mE,"id","transformers.TFAutoModelForNextSentencePrediction"),c(mE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(mE,"href","#transformers.TFAutoModelForNextSentencePrediction"),c(Cc,"class","relative group"),c(wY,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(AY,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(LY,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(yY,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertForNextSentencePrediction"),c(xY,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.TFMobileBertForNextSentencePrediction"),c(Ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ir,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uE,"id","transformers.TFAutoModelForTableQuestionAnswering"),c(uE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(uE,"href","#transformers.TFAutoModelForTableQuestionAnswering"),c(Lc,"class","relative group"),c($Y,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kY,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SY,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RY,"href","/docs/transformers/pr_17869/en/model_doc/tapas#transformers.TFTapasForQuestionAnswering"),c(Nr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(TE,"id","transformers.TFAutoModelForTokenClassification"),c(TE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(TE,"href","#transformers.TFAutoModelForTokenClassification"),c($c,"class","relative group"),c(PY,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BY,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IY,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Dt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NY,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.TFAlbertForTokenClassification"),c(qY,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertForTokenClassification"),c(jY,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.TFCamembertForTokenClassification"),c(DY,"href","/docs/transformers/pr_17869/en/model_doc/convbert#transformers.TFConvBertForTokenClassification"),c(GY,"href","/docs/transformers/pr_17869/en/model_doc/deberta#transformers.TFDebertaForTokenClassification"),c(OY,"href","/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.TFDebertaV2ForTokenClassification"),c(VY,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.TFDistilBertForTokenClassification"),c(XY,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.TFElectraForTokenClassification"),c(zY,"href","/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.TFFlaubertForTokenClassification"),c(QY,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.TFFunnelForTokenClassification"),c(WY,"href","/docs/transformers/pr_17869/en/model_doc/layoutlm#transformers.TFLayoutLMForTokenClassification"),c(HY,"href","/docs/transformers/pr_17869/en/model_doc/longformer#transformers.TFLongformerForTokenClassification"),c(UY,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.TFMobileBertForTokenClassification"),c(JY,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.TFMPNetForTokenClassification"),c(YY,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.TFRemBertForTokenClassification"),c(KY,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.TFRobertaForTokenClassification"),c(ZY,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.TFRoFormerForTokenClassification"),c(eK,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.TFXLMForTokenClassification"),c(oK,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForTokenClassification"),c(rK,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.TFXLNetForTokenClassification"),c(qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(XE,"id","transformers.TFAutoModelForQuestionAnswering"),c(XE,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(XE,"href","#transformers.TFAutoModelForQuestionAnswering"),c(Rc,"class","relative group"),c(tK,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(aK,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(nK,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Gt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(sK,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.TFAlbertForQuestionAnswering"),c(lK,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.TFBertForQuestionAnswering"),c(iK,"href","/docs/transformers/pr_17869/en/model_doc/camembert#transformers.TFCamembertForQuestionAnswering"),c(dK,"href","/docs/transformers/pr_17869/en/model_doc/convbert#transformers.TFConvBertForQuestionAnswering"),c(cK,"href","/docs/transformers/pr_17869/en/model_doc/deberta#transformers.TFDebertaForQuestionAnswering"),c(fK,"href","/docs/transformers/pr_17869/en/model_doc/deberta-v2#transformers.TFDebertaV2ForQuestionAnswering"),c(mK,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.TFDistilBertForQuestionAnswering"),c(gK,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.TFElectraForQuestionAnswering"),c(hK,"href","/docs/transformers/pr_17869/en/model_doc/flaubert#transformers.TFFlaubertForQuestionAnsweringSimple"),c(pK,"href","/docs/transformers/pr_17869/en/model_doc/funnel#transformers.TFFunnelForQuestionAnswering"),c(_K,"href","/docs/transformers/pr_17869/en/model_doc/gptj#transformers.TFGPTJForQuestionAnswering"),c(uK,"href","/docs/transformers/pr_17869/en/model_doc/longformer#transformers.TFLongformerForQuestionAnswering"),c(bK,"href","/docs/transformers/pr_17869/en/model_doc/mobilebert#transformers.TFMobileBertForQuestionAnswering"),c(vK,"href","/docs/transformers/pr_17869/en/model_doc/mpnet#transformers.TFMPNetForQuestionAnswering"),c(FK,"href","/docs/transformers/pr_17869/en/model_doc/rembert#transformers.TFRemBertForQuestionAnswering"),c(TK,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.TFRobertaForQuestionAnswering"),c(MK,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.TFRoFormerForQuestionAnswering"),c(EK,"href","/docs/transformers/pr_17869/en/model_doc/xlm#transformers.TFXLMForQuestionAnsweringSimple"),c(CK,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.TFXLMRobertaForQuestionAnswering"),c(wK,"href","/docs/transformers/pr_17869/en/model_doc/xlnet#transformers.TFXLNetForQuestionAnsweringSimple"),c(jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(g4,"id","transformers.TFAutoModelForVision2Seq"),c(g4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(g4,"href","#transformers.TFAutoModelForVision2Seq"),c(Ic,"class","relative group"),c(AK,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(LK,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(yK,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ot,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(xK,"href","/docs/transformers/pr_17869/en/model_doc/vision-encoder-decoder#transformers.TFVisionEncoderDecoderModel"),c(Dr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(u4,"id","transformers.TFAutoModelForSpeechSeq2Seq"),c(u4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(u4,"href","#transformers.TFAutoModelForSpeechSeq2Seq"),c(jc,"class","relative group"),c($K,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(kK,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(SK,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Vt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(RK,"href","/docs/transformers/pr_17869/en/model_doc/speech_to_text#transformers.TFSpeech2TextForConditionalGeneration"),c(Gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(T4,"id","transformers.FlaxAutoModel"),c(T4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(T4,"href","#transformers.FlaxAutoModel"),c(Oc,"class","relative group"),c(PK,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(BK,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(IK,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Xt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(NK,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.FlaxAlbertModel"),c(qK,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.FlaxBartModel"),c(jK,"href","/docs/transformers/pr_17869/en/model_doc/beit#transformers.FlaxBeitModel"),c(DK,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertModel"),c(GK,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.FlaxBigBirdModel"),c(OK,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.FlaxBlenderbotModel"),c(VK,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallModel"),c(XK,"href","/docs/transformers/pr_17869/en/model_doc/clip#transformers.FlaxCLIPModel"),c(zK,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.FlaxDistilBertModel"),c(QK,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.FlaxElectraModel"),c(WK,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.FlaxGPT2Model"),c(HK,"href","/docs/transformers/pr_17869/en/model_doc/gpt_neo#transformers.FlaxGPTNeoModel"),c(UK,"href","/docs/transformers/pr_17869/en/model_doc/gptj#transformers.FlaxGPTJModel"),c(JK,"href","/docs/transformers/pr_17869/en/model_doc/longt5#transformers.FlaxLongT5Model"),c(YK,"href","/docs/transformers/pr_17869/en/model_doc/marian#transformers.FlaxMarianModel"),c(KK,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.FlaxMBartModel"),c(ZK,"href","/docs/transformers/pr_17869/en/model_doc/mt5#transformers.FlaxMT5Model"),c(eZ,"href","/docs/transformers/pr_17869/en/model_doc/opt#transformers.FlaxOPTModel"),c(oZ,"href","/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.FlaxPegasusModel"),c(rZ,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.FlaxRobertaModel"),c(tZ,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.FlaxRoFormerModel"),c(aZ,"href","/docs/transformers/pr_17869/en/model_doc/t5#transformers.FlaxT5Model"),c(nZ,"href","/docs/transformers/pr_17869/en/model_doc/vision-text-dual-encoder#transformers.FlaxVisionTextDualEncoderModel"),c(sZ,"href","/docs/transformers/pr_17869/en/model_doc/vit#transformers.FlaxViTModel"),c(lZ,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2Model"),c(iZ,"href","/docs/transformers/pr_17869/en/model_doc/xglm#transformers.FlaxXGLMModel"),c(dZ,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaModel"),c(Or,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Y4,"id","transformers.FlaxAutoModelForCausalLM"),c(Y4,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Y4,"href","#transformers.FlaxAutoModelForCausalLM"),c(zc,"class","relative group"),c(cZ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(fZ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(mZ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(gZ,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.FlaxBartForCausalLM"),c(hZ,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertForCausalLM"),c(pZ,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.FlaxBigBirdForCausalLM"),c(_Z,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.FlaxElectraForCausalLM"),c(uZ,"href","/docs/transformers/pr_17869/en/model_doc/gpt2#transformers.FlaxGPT2LMHeadModel"),c(bZ,"href","/docs/transformers/pr_17869/en/model_doc/gpt_neo#transformers.FlaxGPTNeoForCausalLM"),c(vZ,"href","/docs/transformers/pr_17869/en/model_doc/gptj#transformers.FlaxGPTJForCausalLM"),c(FZ,"href","/docs/transformers/pr_17869/en/model_doc/opt#transformers.FlaxOPTForCausalLM"),c(TZ,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.FlaxRobertaForCausalLM"),c(MZ,"href","/docs/transformers/pr_17869/en/model_doc/xglm#transformers.FlaxXGLMForCausalLM"),c(Vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(pr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(cC,"id","transformers.FlaxAutoModelForPreTraining"),c(cC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(cC,"href","#transformers.FlaxAutoModelForPreTraining"),c(Hc,"class","relative group"),c(EZ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(CZ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(wZ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Qt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AZ,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.FlaxAlbertForPreTraining"),c(LZ,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(yZ,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertForPreTraining"),c(xZ,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.FlaxBigBirdForPreTraining"),c($Z,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.FlaxElectraForPreTraining"),c(kZ,"href","/docs/transformers/pr_17869/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(SZ,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(RZ,"href","/docs/transformers/pr_17869/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(PZ,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(BZ,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(IZ,"href","/docs/transformers/pr_17869/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(NZ,"href","/docs/transformers/pr_17869/en/model_doc/wav2vec2#transformers.FlaxWav2Vec2ForPreTraining"),c(qZ,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(Xr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(_r,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(AC,"id","transformers.FlaxAutoModelForMaskedLM"),c(AC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(AC,"href","#transformers.FlaxAutoModelForMaskedLM"),c(Yc,"class","relative group"),c(jZ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(DZ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(GZ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Wt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(OZ,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.FlaxAlbertForMaskedLM"),c(VZ,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(XZ,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertForMaskedLM"),c(zZ,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.FlaxBigBirdForMaskedLM"),c(QZ,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.FlaxDistilBertForMaskedLM"),c(WZ,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.FlaxElectraForMaskedLM"),c(HZ,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(UZ,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.FlaxRobertaForMaskedLM"),c(JZ,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.FlaxRoFormerForMaskedLM"),c(YZ,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMaskedLM"),c(zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(jC,"id","transformers.FlaxAutoModelForSeq2SeqLM"),c(jC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(jC,"href","#transformers.FlaxAutoModelForSeq2SeqLM"),c(ef,"class","relative group"),c(KZ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ZZ,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(eee,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ht,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(oee,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.FlaxBartForConditionalGeneration"),c(ree,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot#transformers.FlaxBlenderbotForConditionalGeneration"),c(tee,"href","/docs/transformers/pr_17869/en/model_doc/blenderbot-small#transformers.FlaxBlenderbotSmallForConditionalGeneration"),c(aee,"href","/docs/transformers/pr_17869/en/model_doc/encoder-decoder#transformers.FlaxEncoderDecoderModel"),c(nee,"href","/docs/transformers/pr_17869/en/model_doc/longt5#transformers.FlaxLongT5ForConditionalGeneration"),c(see,"href","/docs/transformers/pr_17869/en/model_doc/marian#transformers.FlaxMarianMTModel"),c(lee,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.FlaxMBartForConditionalGeneration"),c(iee,"href","/docs/transformers/pr_17869/en/model_doc/mt5#transformers.FlaxMT5ForConditionalGeneration"),c(dee,"href","/docs/transformers/pr_17869/en/model_doc/pegasus#transformers.FlaxPegasusForConditionalGeneration"),c(cee,"href","/docs/transformers/pr_17869/en/model_doc/t5#transformers.FlaxT5ForConditionalGeneration"),c(Qr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(br,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(KC,"id","transformers.FlaxAutoModelForSequenceClassification"),c(KC,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(KC,"href","#transformers.FlaxAutoModelForSequenceClassification"),c(tf,"class","relative group"),c(fee,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(mee,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(gee,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Ut,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(hee,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.FlaxAlbertForSequenceClassification"),c(pee,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.FlaxBartForSequenceClassification"),c(_ee,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertForSequenceClassification"),c(uee,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.FlaxBigBirdForSequenceClassification"),c(bee,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.FlaxDistilBertForSequenceClassification"),c(vee,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.FlaxElectraForSequenceClassification"),c(Fee,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.FlaxMBartForSequenceClassification"),c(Tee,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.FlaxRobertaForSequenceClassification"),c(Mee,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.FlaxRoFormerForSequenceClassification"),c(Eee,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForSequenceClassification"),c(Wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(vr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(f5,"id","transformers.FlaxAutoModelForQuestionAnswering"),c(f5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(f5,"href","#transformers.FlaxAutoModelForQuestionAnswering"),c(sf,"class","relative group"),c(Cee,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(wee,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Aee,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Jt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Lee,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.FlaxAlbertForQuestionAnswering"),c(yee,"href","/docs/transformers/pr_17869/en/model_doc/bart#transformers.FlaxBartForQuestionAnswering"),c(xee,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertForQuestionAnswering"),c($ee,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.FlaxBigBirdForQuestionAnswering"),c(kee,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.FlaxDistilBertForQuestionAnswering"),c(See,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.FlaxElectraForQuestionAnswering"),c(Ree,"href","/docs/transformers/pr_17869/en/model_doc/mbart#transformers.FlaxMBartForQuestionAnswering"),c(Pee,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.FlaxRobertaForQuestionAnswering"),c(Bee,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.FlaxRoFormerForQuestionAnswering"),c(Iee,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForQuestionAnswering"),c(Hr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Fr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(C5,"id","transformers.FlaxAutoModelForTokenClassification"),c(C5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(C5,"href","#transformers.FlaxAutoModelForTokenClassification"),c(cf,"class","relative group"),c(Nee,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(qee,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(jee,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Yt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Dee,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.FlaxAlbertForTokenClassification"),c(Gee,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertForTokenClassification"),c(Oee,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.FlaxBigBirdForTokenClassification"),c(Vee,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.FlaxDistilBertForTokenClassification"),c(Xee,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.FlaxElectraForTokenClassification"),c(zee,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.FlaxRobertaForTokenClassification"),c(Qee,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.FlaxRoFormerForTokenClassification"),c(Wee,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForTokenClassification"),c(Ur,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Tr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(B5,"id","transformers.FlaxAutoModelForMultipleChoice"),c(B5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(B5,"href","#transformers.FlaxAutoModelForMultipleChoice"),c(gf,"class","relative group"),c(Hee,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Uee,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(Jee,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Kt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Yee,"href","/docs/transformers/pr_17869/en/model_doc/albert#transformers.FlaxAlbertForMultipleChoice"),c(Kee,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertForMultipleChoice"),c(Zee,"href","/docs/transformers/pr_17869/en/model_doc/big_bird#transformers.FlaxBigBirdForMultipleChoice"),c(eoe,"href","/docs/transformers/pr_17869/en/model_doc/distilbert#transformers.FlaxDistilBertForMultipleChoice"),c(ooe,"href","/docs/transformers/pr_17869/en/model_doc/electra#transformers.FlaxElectraForMultipleChoice"),c(roe,"href","/docs/transformers/pr_17869/en/model_doc/roberta#transformers.FlaxRobertaForMultipleChoice"),c(toe,"href","/docs/transformers/pr_17869/en/model_doc/roformer#transformers.FlaxRoFormerForMultipleChoice"),c(aoe,"href","/docs/transformers/pr_17869/en/model_doc/xlm-roberta#transformers.FlaxXLMRobertaForMultipleChoice"),c(Jr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Mr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Q5,"id","transformers.FlaxAutoModelForNextSentencePrediction"),c(Q5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Q5,"href","#transformers.FlaxAutoModelForNextSentencePrediction"),c(_f,"class","relative group"),c(noe,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(soe,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(loe,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(Zt,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(ioe,"href","/docs/transformers/pr_17869/en/model_doc/bert#transformers.FlaxBertForNextSentencePrediction"),c(Yr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Er,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(J5,"id","transformers.FlaxAutoModelForImageClassification"),c(J5,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(J5,"href","#transformers.FlaxAutoModelForImageClassification"),c(vf,"class","relative group"),c(doe,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(coe,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(foe,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(ea,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(moe,"href","/docs/transformers/pr_17869/en/model_doc/beit#transformers.FlaxBeitForImageClassification"),c(goe,"href","/docs/transformers/pr_17869/en/model_doc/vit#transformers.FlaxViTForImageClassification"),c(Kr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(Cr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(o3,"id","transformers.FlaxAutoModelForVision2Seq"),c(o3,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(o3,"href","#transformers.FlaxAutoModelForVision2Seq"),c(Mf,"class","relative group"),c(hoe,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(poe,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_config"),c(_oe,"href","/docs/transformers/pr_17869/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained"),c(oa,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(uoe,"href","/docs/transformers/pr_17869/en/model_doc/vision-encoder-decoder#transformers.FlaxVisionEncoderDecoderModel"),c(Zr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),c(wr,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(f,u){e(document.head,g),b(f,v,u),b(f,p,u),e(p,m),e(m,_),M(d,_,null),e(p,h),e(p,Eo),e(Eo,Ti),b(f,yf,u),b(f,at,u),e(at,Mi),e(at,Ei),e(Ei,ww),e(at,xf),b(f,Oe,u),b(f,Qe,u),e(Qe,Ci),e(Qe,Rn),e(Rn,Aw),e(Qe,Pn),e(Qe,Bn),e(Bn,Lw),e(Qe,wi),e(Qe,In),e(In,yw),e(Qe,Ai),b(f,$f,u),M(xa,f,u),b(f,We,u),b(f,Ae,u),e(Ae,rS),e(Ae,Li),e(Li,tS),e(Ae,aS),b(f,Co,u),b(f,$a,u),e($a,nS),e($a,kf),e(kf,sS),e($a,eQe),b(f,jGe,u),b(f,yi,u),e(yi,Sf),e(Sf,mte),M(xw,mte,null),e(yi,oQe),e(yi,gte),e(gte,rQe),b(f,DGe,u),b(f,Nn,u),e(Nn,tQe),e(Nn,hte),e(hte,aQe),e(Nn,nQe),e(Nn,pte),e(pte,sQe),e(Nn,lQe),b(f,GGe,u),M($w,f,u),b(f,OGe,u),b(f,lS,u),e(lS,iQe),b(f,VGe,u),M(Rf,f,u),b(f,XGe,u),b(f,xi,u),e(xi,Pf),e(Pf,_te),M(kw,_te,null),e(xi,dQe),e(xi,ute),e(ute,cQe),b(f,zGe,u),b(f,wo,u),M(Sw,wo,null),e(wo,fQe),e(wo,Rw),e(Rw,mQe),e(Rw,iS),e(iS,gQe),e(Rw,hQe),e(wo,pQe),e(wo,Pw),e(Pw,_Qe),e(Pw,bte),e(bte,uQe),e(Pw,bQe),e(wo,vQe),e(wo,Ar),M(Bw,Ar,null),e(Ar,FQe),e(Ar,vte),e(vte,TQe),e(Ar,MQe),e(Ar,$i),e($i,EQe),e($i,Fte),e(Fte,CQe),e($i,wQe),e($i,Tte),e(Tte,AQe),e($i,LQe),e(Ar,yQe),e(Ar,A),e(A,Bf),e(Bf,Mte),e(Mte,xQe),e(Bf,$Qe),e(Bf,dS),e(dS,kQe),e(Bf,SQe),e(A,RQe),e(A,If),e(If,Ete),e(Ete,PQe),e(If,BQe),e(If,cS),e(cS,IQe),e(If,NQe),e(A,qQe),e(A,Nf),e(Nf,Cte),e(Cte,jQe),e(Nf,DQe),e(Nf,fS),e(fS,GQe),e(Nf,OQe),e(A,VQe),e(A,qf),e(qf,wte),e(wte,XQe),e(qf,zQe),e(qf,mS),e(mS,QQe),e(qf,WQe),e(A,HQe),e(A,jf),e(jf,Ate),e(Ate,UQe),e(jf,JQe),e(jf,gS),e(gS,YQe),e(jf,KQe),e(A,ZQe),e(A,Df),e(Df,Lte),e(Lte,eWe),e(Df,oWe),e(Df,hS),e(hS,rWe),e(Df,tWe),e(A,aWe),e(A,Gf),e(Gf,yte),e(yte,nWe),e(Gf,sWe),e(Gf,pS),e(pS,lWe),e(Gf,iWe),e(A,dWe),e(A,Of),e(Of,xte),e(xte,cWe),e(Of,fWe),e(Of,_S),e(_S,mWe),e(Of,gWe),e(A,hWe),e(A,Vf),e(Vf,$te),e($te,pWe),e(Vf,_We),e(Vf,uS),e(uS,uWe),e(Vf,bWe),e(A,vWe),e(A,Xf),e(Xf,kte),e(kte,FWe),e(Xf,TWe),e(Xf,bS),e(bS,MWe),e(Xf,EWe),e(A,CWe),e(A,zf),e(zf,Ste),e(Ste,wWe),e(zf,AWe),e(zf,vS),e(vS,LWe),e(zf,yWe),e(A,xWe),e(A,Qf),e(Qf,Rte),e(Rte,$We),e(Qf,kWe),e(Qf,FS),e(FS,SWe),e(Qf,RWe),e(A,PWe),e(A,Wf),e(Wf,Pte),e(Pte,BWe),e(Wf,IWe),e(Wf,TS),e(TS,NWe),e(Wf,qWe),e(A,jWe),e(A,Hf),e(Hf,Bte),e(Bte,DWe),e(Hf,GWe),e(Hf,MS),e(MS,OWe),e(Hf,VWe),e(A,XWe),e(A,Uf),e(Uf,Ite),e(Ite,zWe),e(Uf,QWe),e(Uf,ES),e(ES,WWe),e(Uf,HWe),e(A,UWe),e(A,Jf),e(Jf,Nte),e(Nte,JWe),e(Jf,YWe),e(Jf,CS),e(CS,KWe),e(Jf,ZWe),e(A,eHe),e(A,Yf),e(Yf,qte),e(qte,oHe),e(Yf,rHe),e(Yf,wS),e(wS,tHe),e(Yf,aHe),e(A,nHe),e(A,Kf),e(Kf,jte),e(jte,sHe),e(Kf,lHe),e(Kf,AS),e(AS,iHe),e(Kf,dHe),e(A,cHe),e(A,Zf),e(Zf,Dte),e(Dte,fHe),e(Zf,mHe),e(Zf,LS),e(LS,gHe),e(Zf,hHe),e(A,pHe),e(A,em),e(em,Gte),e(Gte,_He),e(em,uHe),e(em,yS),e(yS,bHe),e(em,vHe),e(A,FHe),e(A,om),e(om,Ote),e(Ote,THe),e(om,MHe),e(om,xS),e(xS,EHe),e(om,CHe),e(A,wHe),e(A,rm),e(rm,Vte),e(Vte,AHe),e(rm,LHe),e(rm,$S),e($S,yHe),e(rm,xHe),e(A,$He),e(A,tm),e(tm,Xte),e(Xte,kHe),e(tm,SHe),e(tm,kS),e(kS,RHe),e(tm,PHe),e(A,BHe),e(A,am),e(am,zte),e(zte,IHe),e(am,NHe),e(am,SS),e(SS,qHe),e(am,jHe),e(A,DHe),e(A,nm),e(nm,Qte),e(Qte,GHe),e(nm,OHe),e(nm,RS),e(RS,VHe),e(nm,XHe),e(A,zHe),e(A,sm),e(sm,Wte),e(Wte,QHe),e(sm,WHe),e(sm,PS),e(PS,HHe),e(sm,UHe),e(A,JHe),e(A,lm),e(lm,Hte),e(Hte,YHe),e(lm,KHe),e(lm,BS),e(BS,ZHe),e(lm,eUe),e(A,oUe),e(A,im),e(im,Ute),e(Ute,rUe),e(im,tUe),e(im,IS),e(IS,aUe),e(im,nUe),e(A,sUe),e(A,dm),e(dm,Jte),e(Jte,lUe),e(dm,iUe),e(dm,NS),e(NS,dUe),e(dm,cUe),e(A,fUe),e(A,cm),e(cm,Yte),e(Yte,mUe),e(cm,gUe),e(cm,qS),e(qS,hUe),e(cm,pUe),e(A,_Ue),e(A,fm),e(fm,Kte),e(Kte,uUe),e(fm,bUe),e(fm,jS),e(jS,vUe),e(fm,FUe),e(A,TUe),e(A,mm),e(mm,Zte),e(Zte,MUe),e(mm,EUe),e(mm,DS),e(DS,CUe),e(mm,wUe),e(A,AUe),e(A,gm),e(gm,eae),e(eae,LUe),e(gm,yUe),e(gm,GS),e(GS,xUe),e(gm,$Ue),e(A,kUe),e(A,hm),e(hm,oae),e(oae,SUe),e(hm,RUe),e(hm,OS),e(OS,PUe),e(hm,BUe),e(A,IUe),e(A,pm),e(pm,rae),e(rae,NUe),e(pm,qUe),e(pm,VS),e(VS,jUe),e(pm,DUe),e(A,GUe),e(A,_m),e(_m,tae),e(tae,OUe),e(_m,VUe),e(_m,XS),e(XS,XUe),e(_m,zUe),e(A,QUe),e(A,um),e(um,aae),e(aae,WUe),e(um,HUe),e(um,zS),e(zS,UUe),e(um,JUe),e(A,YUe),e(A,bm),e(bm,nae),e(nae,KUe),e(bm,ZUe),e(bm,QS),e(QS,eJe),e(bm,oJe),e(A,rJe),e(A,vm),e(vm,sae),e(sae,tJe),e(vm,aJe),e(vm,WS),e(WS,nJe),e(vm,sJe),e(A,lJe),e(A,Fm),e(Fm,lae),e(lae,iJe),e(Fm,dJe),e(Fm,HS),e(HS,cJe),e(Fm,fJe),e(A,mJe),e(A,Tm),e(Tm,iae),e(iae,gJe),e(Tm,hJe),e(Tm,US),e(US,pJe),e(Tm,_Je),e(A,uJe),e(A,Mm),e(Mm,dae),e(dae,bJe),e(Mm,vJe),e(Mm,JS),e(JS,FJe),e(Mm,TJe),e(A,MJe),e(A,Em),e(Em,cae),e(cae,EJe),e(Em,CJe),e(Em,YS),e(YS,wJe),e(Em,AJe),e(A,LJe),e(A,Cm),e(Cm,fae),e(fae,yJe),e(Cm,xJe),e(Cm,KS),e(KS,$Je),e(Cm,kJe),e(A,SJe),e(A,wm),e(wm,mae),e(mae,RJe),e(wm,PJe),e(wm,ZS),e(ZS,BJe),e(wm,IJe),e(A,NJe),e(A,Am),e(Am,gae),e(gae,qJe),e(Am,jJe),e(Am,eR),e(eR,DJe),e(Am,GJe),e(A,OJe),e(A,Lm),e(Lm,hae),e(hae,VJe),e(Lm,XJe),e(Lm,oR),e(oR,zJe),e(Lm,QJe),e(A,WJe),e(A,ym),e(ym,pae),e(pae,HJe),e(ym,UJe),e(ym,rR),e(rR,JJe),e(ym,YJe),e(A,KJe),e(A,xm),e(xm,_ae),e(_ae,ZJe),e(xm,eYe),e(xm,tR),e(tR,oYe),e(xm,rYe),e(A,tYe),e(A,$m),e($m,uae),e(uae,aYe),e($m,nYe),e($m,aR),e(aR,sYe),e($m,lYe),e(A,iYe),e(A,km),e(km,bae),e(bae,dYe),e(km,cYe),e(km,nR),e(nR,fYe),e(km,mYe),e(A,gYe),e(A,Sm),e(Sm,vae),e(vae,hYe),e(Sm,pYe),e(Sm,sR),e(sR,_Ye),e(Sm,uYe),e(A,bYe),e(A,Rm),e(Rm,Fae),e(Fae,vYe),e(Rm,FYe),e(Rm,lR),e(lR,TYe),e(Rm,MYe),e(A,EYe),e(A,Pm),e(Pm,Tae),e(Tae,CYe),e(Pm,wYe),e(Pm,iR),e(iR,AYe),e(Pm,LYe),e(A,yYe),e(A,Bm),e(Bm,Mae),e(Mae,xYe),e(Bm,$Ye),e(Bm,dR),e(dR,kYe),e(Bm,SYe),e(A,RYe),e(A,Im),e(Im,Eae),e(Eae,PYe),e(Im,BYe),e(Im,cR),e(cR,IYe),e(Im,NYe),e(A,qYe),e(A,Nm),e(Nm,Cae),e(Cae,jYe),e(Nm,DYe),e(Nm,fR),e(fR,GYe),e(Nm,OYe),e(A,VYe),e(A,qm),e(qm,wae),e(wae,XYe),e(qm,zYe),e(qm,mR),e(mR,QYe),e(qm,WYe),e(A,HYe),e(A,jm),e(jm,Aae),e(Aae,UYe),e(jm,JYe),e(jm,gR),e(gR,YYe),e(jm,KYe),e(A,ZYe),e(A,Dm),e(Dm,Lae),e(Lae,eKe),e(Dm,oKe),e(Dm,hR),e(hR,rKe),e(Dm,tKe),e(A,aKe),e(A,Gm),e(Gm,yae),e(yae,nKe),e(Gm,sKe),e(Gm,pR),e(pR,lKe),e(Gm,iKe),e(A,dKe),e(A,Om),e(Om,xae),e(xae,cKe),e(Om,fKe),e(Om,_R),e(_R,mKe),e(Om,gKe),e(A,hKe),e(A,Vm),e(Vm,$ae),e($ae,pKe),e(Vm,_Ke),e(Vm,uR),e(uR,uKe),e(Vm,bKe),e(A,vKe),e(A,Xm),e(Xm,kae),e(kae,FKe),e(Xm,TKe),e(Xm,bR),e(bR,MKe),e(Xm,EKe),e(A,CKe),e(A,zm),e(zm,Sae),e(Sae,wKe),e(zm,AKe),e(zm,vR),e(vR,LKe),e(zm,yKe),e(A,xKe),e(A,Qm),e(Qm,Rae),e(Rae,$Ke),e(Qm,kKe),e(Qm,FR),e(FR,SKe),e(Qm,RKe),e(A,PKe),e(A,Wm),e(Wm,Pae),e(Pae,BKe),e(Wm,IKe),e(Wm,TR),e(TR,NKe),e(Wm,qKe),e(A,jKe),e(A,Hm),e(Hm,Bae),e(Bae,DKe),e(Hm,GKe),e(Hm,MR),e(MR,OKe),e(Hm,VKe),e(A,XKe),e(A,Um),e(Um,Iae),e(Iae,zKe),e(Um,QKe),e(Um,ER),e(ER,WKe),e(Um,HKe),e(A,UKe),e(A,Jm),e(Jm,Nae),e(Nae,JKe),e(Jm,YKe),e(Jm,CR),e(CR,KKe),e(Jm,ZKe),e(A,eZe),e(A,Ym),e(Ym,qae),e(qae,oZe),e(Ym,rZe),e(Ym,wR),e(wR,tZe),e(Ym,aZe),e(A,nZe),e(A,Km),e(Km,jae),e(jae,sZe),e(Km,lZe),e(Km,AR),e(AR,iZe),e(Km,dZe),e(A,cZe),e(A,Zm),e(Zm,Dae),e(Dae,fZe),e(Zm,mZe),e(Zm,LR),e(LR,gZe),e(Zm,hZe),e(A,pZe),e(A,eg),e(eg,Gae),e(Gae,_Ze),e(eg,uZe),e(eg,yR),e(yR,bZe),e(eg,vZe),e(A,FZe),e(A,og),e(og,Oae),e(Oae,TZe),e(og,MZe),e(og,xR),e(xR,EZe),e(og,CZe),e(A,wZe),e(A,rg),e(rg,Vae),e(Vae,AZe),e(rg,LZe),e(rg,$R),e($R,yZe),e(rg,xZe),e(A,$Ze),e(A,tg),e(tg,Xae),e(Xae,kZe),e(tg,SZe),e(tg,kR),e(kR,RZe),e(tg,PZe),e(A,BZe),e(A,ag),e(ag,zae),e(zae,IZe),e(ag,NZe),e(ag,SR),e(SR,qZe),e(ag,jZe),e(A,DZe),e(A,ng),e(ng,Qae),e(Qae,GZe),e(ng,OZe),e(ng,RR),e(RR,VZe),e(ng,XZe),e(A,zZe),e(A,sg),e(sg,Wae),e(Wae,QZe),e(sg,WZe),e(sg,PR),e(PR,HZe),e(sg,UZe),e(A,JZe),e(A,lg),e(lg,Hae),e(Hae,YZe),e(lg,KZe),e(lg,BR),e(BR,ZZe),e(lg,eeo),e(A,oeo),e(A,ig),e(ig,Uae),e(Uae,reo),e(ig,teo),e(ig,IR),e(IR,aeo),e(ig,neo),e(A,seo),e(A,dg),e(dg,Jae),e(Jae,leo),e(dg,ieo),e(dg,NR),e(NR,deo),e(dg,ceo),e(A,feo),e(A,cg),e(cg,Yae),e(Yae,meo),e(cg,geo),e(cg,qR),e(qR,heo),e(cg,peo),e(A,_eo),e(A,fg),e(fg,Kae),e(Kae,ueo),e(fg,beo),e(fg,jR),e(jR,veo),e(fg,Feo),e(A,Teo),e(A,mg),e(mg,Zae),e(Zae,Meo),e(mg,Eeo),e(mg,DR),e(DR,Ceo),e(mg,weo),e(A,Aeo),e(A,gg),e(gg,ene),e(ene,Leo),e(gg,yeo),e(gg,GR),e(GR,xeo),e(gg,$eo),e(A,keo),e(A,hg),e(hg,one),e(one,Seo),e(hg,Reo),e(hg,OR),e(OR,Peo),e(hg,Beo),e(A,Ieo),e(A,pg),e(pg,rne),e(rne,Neo),e(pg,qeo),e(pg,VR),e(VR,jeo),e(pg,Deo),e(A,Geo),e(A,_g),e(_g,tne),e(tne,Oeo),e(_g,Veo),e(_g,XR),e(XR,Xeo),e(_g,zeo),e(A,Qeo),e(A,ug),e(ug,ane),e(ane,Weo),e(ug,Heo),e(ug,zR),e(zR,Ueo),e(ug,Jeo),e(A,Yeo),e(A,bg),e(bg,nne),e(nne,Keo),e(bg,Zeo),e(bg,QR),e(QR,eoo),e(bg,ooo),e(A,roo),e(A,vg),e(vg,sne),e(sne,too),e(vg,aoo),e(vg,WR),e(WR,noo),e(vg,soo),e(A,loo),e(A,Fg),e(Fg,lne),e(lne,ioo),e(Fg,doo),e(Fg,HR),e(HR,coo),e(Fg,foo),e(A,moo),e(A,Tg),e(Tg,ine),e(ine,goo),e(Tg,hoo),e(Tg,UR),e(UR,poo),e(Tg,_oo),e(A,uoo),e(A,Mg),e(Mg,dne),e(dne,boo),e(Mg,voo),e(Mg,JR),e(JR,Foo),e(Mg,Too),e(A,Moo),e(A,Eg),e(Eg,cne),e(cne,Eoo),e(Eg,Coo),e(Eg,YR),e(YR,woo),e(Eg,Aoo),e(A,Loo),e(A,Cg),e(Cg,fne),e(fne,yoo),e(Cg,xoo),e(Cg,KR),e(KR,$oo),e(Cg,koo),e(A,Soo),e(A,wg),e(wg,mne),e(mne,Roo),e(wg,Poo),e(wg,ZR),e(ZR,Boo),e(wg,Ioo),e(A,Noo),e(A,Ag),e(Ag,gne),e(gne,qoo),e(Ag,joo),e(Ag,eP),e(eP,Doo),e(Ag,Goo),e(A,Ooo),e(A,Lg),e(Lg,hne),e(hne,Voo),e(Lg,Xoo),e(Lg,oP),e(oP,zoo),e(Lg,Qoo),e(A,Woo),e(A,yg),e(yg,pne),e(pne,Hoo),e(yg,Uoo),e(yg,rP),e(rP,Joo),e(yg,Yoo),e(A,Koo),e(A,xg),e(xg,_ne),e(_ne,Zoo),e(xg,ero),e(xg,tP),e(tP,oro),e(xg,rro),e(A,tro),e(A,$g),e($g,une),e(une,aro),e($g,nro),e($g,aP),e(aP,sro),e($g,lro),e(A,iro),e(A,kg),e(kg,bne),e(bne,dro),e(kg,cro),e(kg,nP),e(nP,fro),e(kg,mro),e(A,gro),e(A,Sg),e(Sg,vne),e(vne,hro),e(Sg,pro),e(Sg,sP),e(sP,_ro),e(Sg,uro),e(A,bro),e(A,Rg),e(Rg,Fne),e(Fne,vro),e(Rg,Fro),e(Rg,lP),e(lP,Tro),e(Rg,Mro),e(A,Ero),e(A,Pg),e(Pg,Tne),e(Tne,Cro),e(Pg,wro),e(Pg,iP),e(iP,Aro),e(Pg,Lro),e(A,yro),e(A,Bg),e(Bg,Mne),e(Mne,xro),e(Bg,$ro),e(Bg,dP),e(dP,kro),e(Bg,Sro),e(A,Rro),e(A,Ig),e(Ig,Ene),e(Ene,Pro),e(Ig,Bro),e(Ig,cP),e(cP,Iro),e(Ig,Nro),e(A,qro),e(A,Ng),e(Ng,Cne),e(Cne,jro),e(Ng,Dro),e(Ng,fP),e(fP,Gro),e(Ng,Oro),e(A,Vro),e(A,qg),e(qg,wne),e(wne,Xro),e(qg,zro),e(qg,mP),e(mP,Qro),e(qg,Wro),e(A,Hro),e(A,jg),e(jg,Ane),e(Ane,Uro),e(jg,Jro),e(jg,gP),e(gP,Yro),e(jg,Kro),e(A,Zro),e(A,Dg),e(Dg,Lne),e(Lne,eto),e(Dg,oto),e(Dg,hP),e(hP,rto),e(Dg,tto),e(Ar,ato),M(Gg,Ar,null),e(wo,nto),e(wo,Og),M(Iw,Og,null),e(Og,sto),e(Og,yne),e(yne,lto),b(f,QGe,u),b(f,ki,u),e(ki,Vg),e(Vg,xne),M(Nw,xne,null),e(ki,ito),e(ki,$ne),e($ne,dto),b(f,WGe,u),b(f,Ao,u),M(qw,Ao,null),e(Ao,cto),e(Ao,jw),e(jw,fto),e(jw,pP),e(pP,mto),e(jw,gto),e(Ao,hto),e(Ao,Dw),e(Dw,pto),e(Dw,kne),e(kne,_to),e(Dw,uto),e(Ao,bto),e(Ao,Lr),M(Gw,Lr,null),e(Lr,vto),e(Lr,Sne),e(Sne,Fto),e(Lr,Tto),e(Lr,ka),e(ka,Mto),e(ka,Rne),e(Rne,Eto),e(ka,Cto),e(ka,Pne),e(Pne,wto),e(ka,Ato),e(ka,Bne),e(Bne,Lto),e(ka,yto),e(Lr,xto),e(Lr,k),e(k,qn),e(qn,Ine),e(Ine,$to),e(qn,kto),e(qn,_P),e(_P,Sto),e(qn,Rto),e(qn,uP),e(uP,Pto),e(qn,Bto),e(k,Ito),e(k,jn),e(jn,Nne),e(Nne,Nto),e(jn,qto),e(jn,bP),e(bP,jto),e(jn,Dto),e(jn,vP),e(vP,Gto),e(jn,Oto),e(k,Vto),e(k,Dn),e(Dn,qne),e(qne,Xto),e(Dn,zto),e(Dn,FP),e(FP,Qto),e(Dn,Wto),e(Dn,TP),e(TP,Hto),e(Dn,Uto),e(k,Jto),e(k,Xg),e(Xg,jne),e(jne,Yto),e(Xg,Kto),e(Xg,MP),e(MP,Zto),e(Xg,eao),e(k,oao),e(k,Gn),e(Gn,Dne),e(Dne,rao),e(Gn,tao),e(Gn,EP),e(EP,aao),e(Gn,nao),e(Gn,CP),e(CP,sao),e(Gn,lao),e(k,iao),e(k,zg),e(zg,Gne),e(Gne,dao),e(zg,cao),e(zg,wP),e(wP,fao),e(zg,mao),e(k,gao),e(k,Qg),e(Qg,One),e(One,hao),e(Qg,pao),e(Qg,AP),e(AP,_ao),e(Qg,uao),e(k,bao),e(k,Wg),e(Wg,Vne),e(Vne,vao),e(Wg,Fao),e(Wg,LP),e(LP,Tao),e(Wg,Mao),e(k,Eao),e(k,On),e(On,Xne),e(Xne,Cao),e(On,wao),e(On,yP),e(yP,Aao),e(On,Lao),e(On,xP),e(xP,yao),e(On,xao),e(k,$ao),e(k,Vn),e(Vn,zne),e(zne,kao),e(Vn,Sao),e(Vn,$P),e($P,Rao),e(Vn,Pao),e(Vn,kP),e(kP,Bao),e(Vn,Iao),e(k,Nao),e(k,Xn),e(Xn,Qne),e(Qne,qao),e(Xn,jao),e(Xn,SP),e(SP,Dao),e(Xn,Gao),e(Xn,RP),e(RP,Oao),e(Xn,Vao),e(k,Xao),e(k,Hg),e(Hg,Wne),e(Wne,zao),e(Hg,Qao),e(Hg,PP),e(PP,Wao),e(Hg,Hao),e(k,Uao),e(k,Ug),e(Ug,Hne),e(Hne,Jao),e(Ug,Yao),e(Ug,BP),e(BP,Kao),e(Ug,Zao),e(k,eno),e(k,Jg),e(Jg,Une),e(Une,ono),e(Jg,rno),e(Jg,IP),e(IP,tno),e(Jg,ano),e(k,nno),e(k,zn),e(zn,Jne),e(Jne,sno),e(zn,lno),e(zn,NP),e(NP,ino),e(zn,dno),e(zn,qP),e(qP,cno),e(zn,fno),e(k,mno),e(k,Yg),e(Yg,Yne),e(Yne,gno),e(Yg,hno),e(Yg,jP),e(jP,pno),e(Yg,_no),e(k,uno),e(k,Qn),e(Qn,Kne),e(Kne,bno),e(Qn,vno),e(Qn,DP),e(DP,Fno),e(Qn,Tno),e(Qn,GP),e(GP,Mno),e(Qn,Eno),e(k,Cno),e(k,Wn),e(Wn,Zne),e(Zne,wno),e(Wn,Ano),e(Wn,OP),e(OP,Lno),e(Wn,yno),e(Wn,VP),e(VP,xno),e(Wn,$no),e(k,kno),e(k,Hn),e(Hn,ese),e(ese,Sno),e(Hn,Rno),e(Hn,XP),e(XP,Pno),e(Hn,Bno),e(Hn,zP),e(zP,Ino),e(Hn,Nno),e(k,qno),e(k,Kg),e(Kg,ose),e(ose,jno),e(Kg,Dno),e(Kg,QP),e(QP,Gno),e(Kg,Ono),e(k,Vno),e(k,Un),e(Un,rse),e(rse,Xno),e(Un,zno),e(Un,WP),e(WP,Qno),e(Un,Wno),e(Un,HP),e(HP,Hno),e(Un,Uno),e(k,Jno),e(k,Jn),e(Jn,tse),e(tse,Yno),e(Jn,Kno),e(Jn,UP),e(UP,Zno),e(Jn,eso),e(Jn,JP),e(JP,oso),e(Jn,rso),e(k,tso),e(k,Yn),e(Yn,ase),e(ase,aso),e(Yn,nso),e(Yn,YP),e(YP,sso),e(Yn,lso),e(Yn,KP),e(KP,iso),e(Yn,dso),e(k,cso),e(k,Kn),e(Kn,nse),e(nse,fso),e(Kn,mso),e(Kn,ZP),e(ZP,gso),e(Kn,hso),e(Kn,eB),e(eB,pso),e(Kn,_so),e(k,uso),e(k,Zn),e(Zn,sse),e(sse,bso),e(Zn,vso),e(Zn,oB),e(oB,Fso),e(Zn,Tso),e(Zn,rB),e(rB,Mso),e(Zn,Eso),e(k,Cso),e(k,es),e(es,lse),e(lse,wso),e(es,Aso),e(es,tB),e(tB,Lso),e(es,yso),e(es,aB),e(aB,xso),e(es,$so),e(k,kso),e(k,Zg),e(Zg,ise),e(ise,Sso),e(Zg,Rso),e(Zg,nB),e(nB,Pso),e(Zg,Bso),e(k,Iso),e(k,os),e(os,dse),e(dse,Nso),e(os,qso),e(os,sB),e(sB,jso),e(os,Dso),e(os,lB),e(lB,Gso),e(os,Oso),e(k,Vso),e(k,eh),e(eh,cse),e(cse,Xso),e(eh,zso),e(eh,iB),e(iB,Qso),e(eh,Wso),e(k,Hso),e(k,rs),e(rs,fse),e(fse,Uso),e(rs,Jso),e(rs,dB),e(dB,Yso),e(rs,Kso),e(rs,cB),e(cB,Zso),e(rs,elo),e(k,olo),e(k,ts),e(ts,mse),e(mse,rlo),e(ts,tlo),e(ts,fB),e(fB,alo),e(ts,nlo),e(ts,mB),e(mB,slo),e(ts,llo),e(k,ilo),e(k,as),e(as,gse),e(gse,dlo),e(as,clo),e(as,gB),e(gB,flo),e(as,mlo),e(as,hB),e(hB,glo),e(as,hlo),e(k,plo),e(k,oh),e(oh,hse),e(hse,_lo),e(oh,ulo),e(oh,pB),e(pB,blo),e(oh,vlo),e(k,Flo),e(k,ns),e(ns,pse),e(pse,Tlo),e(ns,Mlo),e(ns,_B),e(_B,Elo),e(ns,Clo),e(ns,uB),e(uB,wlo),e(ns,Alo),e(k,Llo),e(k,ss),e(ss,_se),e(_se,ylo),e(ss,xlo),e(ss,bB),e(bB,$lo),e(ss,klo),e(ss,vB),e(vB,Slo),e(ss,Rlo),e(k,Plo),e(k,rh),e(rh,use),e(use,Blo),e(rh,Ilo),e(rh,FB),e(FB,Nlo),e(rh,qlo),e(k,jlo),e(k,ls),e(ls,bse),e(bse,Dlo),e(ls,Glo),e(ls,TB),e(TB,Olo),e(ls,Vlo),e(ls,MB),e(MB,Xlo),e(ls,zlo),e(k,Qlo),e(k,is),e(is,vse),e(vse,Wlo),e(is,Hlo),e(is,EB),e(EB,Ulo),e(is,Jlo),e(is,CB),e(CB,Ylo),e(is,Klo),e(k,Zlo),e(k,ds),e(ds,Fse),e(Fse,eio),e(ds,oio),e(ds,wB),e(wB,rio),e(ds,tio),e(ds,AB),e(AB,aio),e(ds,nio),e(k,sio),e(k,cs),e(cs,Tse),e(Tse,lio),e(cs,iio),e(cs,LB),e(LB,dio),e(cs,cio),e(cs,yB),e(yB,fio),e(cs,mio),e(k,gio),e(k,fs),e(fs,Mse),e(Mse,hio),e(fs,pio),e(fs,xB),e(xB,_io),e(fs,uio),e(fs,$B),e($B,bio),e(fs,vio),e(k,Fio),e(k,ms),e(ms,Ese),e(Ese,Tio),e(ms,Mio),e(ms,kB),e(kB,Eio),e(ms,Cio),e(ms,SB),e(SB,wio),e(ms,Aio),e(k,Lio),e(k,gs),e(gs,Cse),e(Cse,yio),e(gs,xio),e(gs,RB),e(RB,$io),e(gs,kio),e(gs,PB),e(PB,Sio),e(gs,Rio),e(k,Pio),e(k,hs),e(hs,wse),e(wse,Bio),e(hs,Iio),e(hs,BB),e(BB,Nio),e(hs,qio),e(hs,IB),e(IB,jio),e(hs,Dio),e(k,Gio),e(k,th),e(th,Ase),e(Ase,Oio),e(th,Vio),e(th,NB),e(NB,Xio),e(th,zio),e(k,Qio),e(k,ps),e(ps,Lse),e(Lse,Wio),e(ps,Hio),e(ps,qB),e(qB,Uio),e(ps,Jio),e(ps,jB),e(jB,Yio),e(ps,Kio),e(k,Zio),e(k,ah),e(ah,yse),e(yse,edo),e(ah,odo),e(ah,DB),e(DB,rdo),e(ah,tdo),e(k,ado),e(k,nh),e(nh,xse),e(xse,ndo),e(nh,sdo),e(nh,GB),e(GB,ldo),e(nh,ido),e(k,ddo),e(k,_s),e(_s,$se),e($se,cdo),e(_s,fdo),e(_s,OB),e(OB,mdo),e(_s,gdo),e(_s,VB),e(VB,hdo),e(_s,pdo),e(k,_do),e(k,us),e(us,kse),e(kse,udo),e(us,bdo),e(us,XB),e(XB,vdo),e(us,Fdo),e(us,zB),e(zB,Tdo),e(us,Mdo),e(k,Edo),e(k,bs),e(bs,Sse),e(Sse,Cdo),e(bs,wdo),e(bs,QB),e(QB,Ado),e(bs,Ldo),e(bs,WB),e(WB,ydo),e(bs,xdo),e(k,$do),e(k,sh),e(sh,Rse),e(Rse,kdo),e(sh,Sdo),e(sh,HB),e(HB,Rdo),e(sh,Pdo),e(k,Bdo),e(k,vs),e(vs,Pse),e(Pse,Ido),e(vs,Ndo),e(vs,UB),e(UB,qdo),e(vs,jdo),e(vs,JB),e(JB,Ddo),e(vs,Gdo),e(k,Odo),e(k,Fs),e(Fs,Bse),e(Bse,Vdo),e(Fs,Xdo),e(Fs,YB),e(YB,zdo),e(Fs,Qdo),e(Fs,KB),e(KB,Wdo),e(Fs,Hdo),e(k,Udo),e(k,Ts),e(Ts,Ise),e(Ise,Jdo),e(Ts,Ydo),e(Ts,ZB),e(ZB,Kdo),e(Ts,Zdo),e(Ts,eI),e(eI,eco),e(Ts,oco),e(k,rco),e(k,Ms),e(Ms,Nse),e(Nse,tco),e(Ms,aco),e(Ms,oI),e(oI,nco),e(Ms,sco),e(Ms,rI),e(rI,lco),e(Ms,ico),e(k,dco),e(k,Es),e(Es,qse),e(qse,cco),e(Es,fco),e(Es,tI),e(tI,mco),e(Es,gco),e(Es,aI),e(aI,hco),e(Es,pco),e(k,_co),e(k,Cs),e(Cs,jse),e(jse,uco),e(Cs,bco),e(Cs,nI),e(nI,vco),e(Cs,Fco),e(Cs,sI),e(sI,Tco),e(Cs,Mco),e(k,Eco),e(k,lh),e(lh,Dse),e(Dse,Cco),e(lh,wco),e(lh,lI),e(lI,Aco),e(lh,Lco),e(k,yco),e(k,ws),e(ws,Gse),e(Gse,xco),e(ws,$co),e(ws,iI),e(iI,kco),e(ws,Sco),e(ws,dI),e(dI,Rco),e(ws,Pco),e(k,Bco),e(k,ih),e(ih,Ose),e(Ose,Ico),e(ih,Nco),e(ih,cI),e(cI,qco),e(ih,jco),e(k,Dco),e(k,dh),e(dh,Vse),e(Vse,Gco),e(dh,Oco),e(dh,fI),e(fI,Vco),e(dh,Xco),e(k,zco),e(k,ch),e(ch,Xse),e(Xse,Qco),e(ch,Wco),e(ch,mI),e(mI,Hco),e(ch,Uco),e(k,Jco),e(k,fh),e(fh,zse),e(zse,Yco),e(fh,Kco),e(fh,gI),e(gI,Zco),e(fh,efo),e(k,ofo),e(k,As),e(As,Qse),e(Qse,rfo),e(As,tfo),e(As,hI),e(hI,afo),e(As,nfo),e(As,pI),e(pI,sfo),e(As,lfo),e(k,ifo),e(k,mh),e(mh,Wse),e(Wse,dfo),e(mh,cfo),e(mh,_I),e(_I,ffo),e(mh,mfo),e(k,gfo),e(k,Ls),e(Ls,Hse),e(Hse,hfo),e(Ls,pfo),e(Ls,uI),e(uI,_fo),e(Ls,ufo),e(Ls,bI),e(bI,bfo),e(Ls,vfo),e(k,Ffo),e(k,ys),e(ys,Use),e(Use,Tfo),e(ys,Mfo),e(ys,vI),e(vI,Efo),e(ys,Cfo),e(ys,FI),e(FI,wfo),e(ys,Afo),e(k,Lfo),e(k,xs),e(xs,Jse),e(Jse,yfo),e(xs,xfo),e(xs,TI),e(TI,$fo),e(xs,kfo),e(xs,MI),e(MI,Sfo),e(xs,Rfo),e(k,Pfo),e(k,$s),e($s,Yse),e(Yse,Bfo),e($s,Ifo),e($s,EI),e(EI,Nfo),e($s,qfo),e($s,CI),e(CI,jfo),e($s,Dfo),e(k,Gfo),e(k,ks),e(ks,Kse),e(Kse,Ofo),e(ks,Vfo),e(ks,wI),e(wI,Xfo),e(ks,zfo),e(ks,AI),e(AI,Qfo),e(ks,Wfo),e(k,Hfo),e(k,Ss),e(Ss,Zse),e(Zse,Ufo),e(Ss,Jfo),e(Ss,LI),e(LI,Yfo),e(Ss,Kfo),e(Ss,yI),e(yI,Zfo),e(Ss,emo),e(k,omo),e(k,gh),e(gh,ele),e(ele,rmo),e(gh,tmo),e(gh,xI),e(xI,amo),e(gh,nmo),e(k,smo),e(k,hh),e(hh,ole),e(ole,lmo),e(hh,imo),e(hh,$I),e($I,dmo),e(hh,cmo),e(k,fmo),e(k,Rs),e(Rs,rle),e(rle,mmo),e(Rs,gmo),e(Rs,kI),e(kI,hmo),e(Rs,pmo),e(Rs,SI),e(SI,_mo),e(Rs,umo),e(k,bmo),e(k,Ps),e(Ps,tle),e(tle,vmo),e(Ps,Fmo),e(Ps,RI),e(RI,Tmo),e(Ps,Mmo),e(Ps,PI),e(PI,Emo),e(Ps,Cmo),e(k,wmo),e(k,Bs),e(Bs,ale),e(ale,Amo),e(Bs,Lmo),e(Bs,BI),e(BI,ymo),e(Bs,xmo),e(Bs,II),e(II,$mo),e(Bs,kmo),e(k,Smo),e(k,ph),e(ph,nle),e(nle,Rmo),e(ph,Pmo),e(ph,NI),e(NI,Bmo),e(ph,Imo),e(k,Nmo),e(k,_h),e(_h,sle),e(sle,qmo),e(_h,jmo),e(_h,qI),e(qI,Dmo),e(_h,Gmo),e(k,Omo),e(k,uh),e(uh,lle),e(lle,Vmo),e(uh,Xmo),e(uh,jI),e(jI,zmo),e(uh,Qmo),e(k,Wmo),e(k,Is),e(Is,ile),e(ile,Hmo),e(Is,Umo),e(Is,DI),e(DI,Jmo),e(Is,Ymo),e(Is,GI),e(GI,Kmo),e(Is,Zmo),e(k,ego),e(k,Ns),e(Ns,dle),e(dle,ogo),e(Ns,rgo),e(Ns,OI),e(OI,tgo),e(Ns,ago),e(Ns,VI),e(VI,ngo),e(Ns,sgo),e(k,lgo),e(k,bh),e(bh,cle),e(cle,igo),e(bh,dgo),e(bh,XI),e(XI,cgo),e(bh,fgo),e(k,mgo),e(k,vh),e(vh,fle),e(fle,ggo),e(vh,hgo),e(vh,zI),e(zI,pgo),e(vh,_go),e(k,ugo),e(k,Fh),e(Fh,mle),e(mle,bgo),e(Fh,vgo),e(Fh,QI),e(QI,Fgo),e(Fh,Tgo),e(k,Mgo),e(k,qs),e(qs,gle),e(gle,Ego),e(qs,Cgo),e(qs,WI),e(WI,wgo),e(qs,Ago),e(qs,HI),e(HI,Lgo),e(qs,ygo),e(k,xgo),e(k,Th),e(Th,hle),e(hle,$go),e(Th,kgo),e(Th,UI),e(UI,Sgo),e(Th,Rgo),e(k,Pgo),e(k,Mh),e(Mh,ple),e(ple,Bgo),e(Mh,Igo),e(Mh,JI),e(JI,Ngo),e(Mh,qgo),e(k,jgo),e(k,js),e(js,_le),e(_le,Dgo),e(js,Ggo),e(js,YI),e(YI,Ogo),e(js,Vgo),e(js,KI),e(KI,Xgo),e(js,zgo),e(k,Qgo),e(k,Ds),e(Ds,ule),e(ule,Wgo),e(Ds,Hgo),e(Ds,ZI),e(ZI,Ugo),e(Ds,Jgo),e(Ds,eN),e(eN,Ygo),e(Ds,Kgo),e(k,Zgo),e(k,Gs),e(Gs,ble),e(ble,eho),e(Gs,oho),e(Gs,oN),e(oN,rho),e(Gs,tho),e(Gs,rN),e(rN,aho),e(Gs,nho),e(k,sho),e(k,Os),e(Os,vle),e(vle,lho),e(Os,iho),e(Os,tN),e(tN,dho),e(Os,cho),e(Os,aN),e(aN,fho),e(Os,mho),e(Lr,gho),M(Eh,Lr,null),e(Ao,hho),e(Ao,Ch),M(Ow,Ch,null),e(Ch,pho),e(Ch,Fle),e(Fle,_ho),b(f,HGe,u),b(f,Si,u),e(Si,wh),e(wh,Tle),M(Vw,Tle,null),e(Si,uho),e(Si,Mle),e(Mle,bho),b(f,UGe,u),b(f,Lo,u),M(Xw,Lo,null),e(Lo,vho),e(Lo,zw),e(zw,Fho),e(zw,nN),e(nN,Tho),e(zw,Mho),e(Lo,Eho),e(Lo,Qw),e(Qw,Cho),e(Qw,Ele),e(Ele,who),e(Qw,Aho),e(Lo,Lho),e(Lo,He),M(Ww,He,null),e(He,yho),e(He,Cle),e(Cle,xho),e(He,$ho),e(He,Sa),e(Sa,kho),e(Sa,wle),e(wle,Sho),e(Sa,Rho),e(Sa,Ale),e(Ale,Pho),e(Sa,Bho),e(Sa,Lle),e(Lle,Iho),e(Sa,Nho),e(He,qho),e(He,Y),e(Y,Ah),e(Ah,yle),e(yle,jho),e(Ah,Dho),e(Ah,sN),e(sN,Gho),e(Ah,Oho),e(Y,Vho),e(Y,Lh),e(Lh,xle),e(xle,Xho),e(Lh,zho),e(Lh,lN),e(lN,Qho),e(Lh,Who),e(Y,Hho),e(Y,yh),e(yh,$le),e($le,Uho),e(yh,Jho),e(yh,iN),e(iN,Yho),e(yh,Kho),e(Y,Zho),e(Y,xh),e(xh,kle),e(kle,epo),e(xh,opo),e(xh,dN),e(dN,rpo),e(xh,tpo),e(Y,apo),e(Y,$h),e($h,Sle),e(Sle,npo),e($h,spo),e($h,cN),e(cN,lpo),e($h,ipo),e(Y,dpo),e(Y,kh),e(kh,Rle),e(Rle,cpo),e(kh,fpo),e(kh,fN),e(fN,mpo),e(kh,gpo),e(Y,hpo),e(Y,Sh),e(Sh,Ple),e(Ple,ppo),e(Sh,_po),e(Sh,mN),e(mN,upo),e(Sh,bpo),e(Y,vpo),e(Y,Rh),e(Rh,Ble),e(Ble,Fpo),e(Rh,Tpo),e(Rh,gN),e(gN,Mpo),e(Rh,Epo),e(Y,Cpo),e(Y,Ph),e(Ph,Ile),e(Ile,wpo),e(Ph,Apo),e(Ph,hN),e(hN,Lpo),e(Ph,ypo),e(Y,xpo),e(Y,Bh),e(Bh,Nle),e(Nle,$po),e(Bh,kpo),e(Bh,pN),e(pN,Spo),e(Bh,Rpo),e(Y,Ppo),e(Y,Ih),e(Ih,qle),e(qle,Bpo),e(Ih,Ipo),e(Ih,_N),e(_N,Npo),e(Ih,qpo),e(Y,jpo),e(Y,Nh),e(Nh,jle),e(jle,Dpo),e(Nh,Gpo),e(Nh,uN),e(uN,Opo),e(Nh,Vpo),e(Y,Xpo),e(Y,qh),e(qh,Dle),e(Dle,zpo),e(qh,Qpo),e(qh,bN),e(bN,Wpo),e(qh,Hpo),e(Y,Upo),e(Y,jh),e(jh,Gle),e(Gle,Jpo),e(jh,Ypo),e(jh,vN),e(vN,Kpo),e(jh,Zpo),e(Y,e_o),e(Y,Dh),e(Dh,Ole),e(Ole,o_o),e(Dh,r_o),e(Dh,FN),e(FN,t_o),e(Dh,a_o),e(Y,n_o),e(Y,Gh),e(Gh,Vle),e(Vle,s_o),e(Gh,l_o),e(Gh,TN),e(TN,i_o),e(Gh,d_o),e(Y,c_o),e(Y,Oh),e(Oh,Xle),e(Xle,f_o),e(Oh,m_o),e(Oh,MN),e(MN,g_o),e(Oh,h_o),e(Y,p_o),e(Y,Vh),e(Vh,zle),e(zle,__o),e(Vh,u_o),e(Vh,EN),e(EN,b_o),e(Vh,v_o),e(Y,F_o),e(Y,Xh),e(Xh,Qle),e(Qle,T_o),e(Xh,M_o),e(Xh,CN),e(CN,E_o),e(Xh,C_o),e(Y,w_o),e(Y,zh),e(zh,Wle),e(Wle,A_o),e(zh,L_o),e(zh,wN),e(wN,y_o),e(zh,x_o),e(Y,$_o),e(Y,Qh),e(Qh,Hle),e(Hle,k_o),e(Qh,S_o),e(Qh,AN),e(AN,R_o),e(Qh,P_o),e(Y,B_o),e(Y,Wh),e(Wh,Ule),e(Ule,I_o),e(Wh,N_o),e(Wh,LN),e(LN,q_o),e(Wh,j_o),e(Y,D_o),e(Y,Hh),e(Hh,Jle),e(Jle,G_o),e(Hh,O_o),e(Hh,yN),e(yN,V_o),e(Hh,X_o),e(Y,z_o),e(Y,Uh),e(Uh,Yle),e(Yle,Q_o),e(Uh,W_o),e(Uh,xN),e(xN,H_o),e(Uh,U_o),e(Y,J_o),e(Y,Jh),e(Jh,Kle),e(Kle,Y_o),e(Jh,K_o),e(Jh,$N),e($N,Z_o),e(Jh,euo),e(Y,ouo),e(Y,Yh),e(Yh,Zle),e(Zle,ruo),e(Yh,tuo),e(Yh,kN),e(kN,auo),e(Yh,nuo),e(Y,suo),e(Y,Kh),e(Kh,eie),e(eie,luo),e(Kh,iuo),e(Kh,SN),e(SN,duo),e(Kh,cuo),e(Y,fuo),e(Y,Zh),e(Zh,oie),e(oie,muo),e(Zh,guo),e(Zh,RN),e(RN,huo),e(Zh,puo),e(Y,_uo),e(Y,ep),e(ep,rie),e(rie,uuo),e(ep,buo),e(ep,PN),e(PN,vuo),e(ep,Fuo),e(Y,Tuo),e(Y,op),e(op,tie),e(tie,Muo),e(op,Euo),e(op,BN),e(BN,Cuo),e(op,wuo),e(Y,Auo),e(Y,rp),e(rp,aie),e(aie,Luo),e(rp,yuo),e(rp,IN),e(IN,xuo),e(rp,$uo),e(Y,kuo),e(Y,tp),e(tp,nie),e(nie,Suo),e(tp,Ruo),e(tp,NN),e(NN,Puo),e(tp,Buo),e(He,Iuo),M(ap,He,null),e(He,Nuo),M(np,He,null),e(Lo,quo),e(Lo,sp),M(Hw,sp,null),e(sp,juo),e(sp,sie),e(sie,Duo),b(f,JGe,u),b(f,Ri,u),e(Ri,lp),e(lp,lie),M(Uw,lie,null),e(Ri,Guo),e(Ri,iie),e(iie,Ouo),b(f,YGe,u),b(f,yo,u),M(Jw,yo,null),e(yo,Vuo),e(yo,Yw),e(Yw,Xuo),e(Yw,qN),e(qN,zuo),e(Yw,Quo),e(yo,Wuo),e(yo,Kw),e(Kw,Huo),e(Kw,die),e(die,Uuo),e(Kw,Juo),e(yo,Yuo),e(yo,Ue),M(Zw,Ue,null),e(Ue,Kuo),e(Ue,cie),e(cie,Zuo),e(Ue,e1o),e(Ue,Pi),e(Pi,o1o),e(Pi,fie),e(fie,r1o),e(Pi,t1o),e(Pi,mie),e(mie,a1o),e(Pi,n1o),e(Ue,s1o),e(Ue,he),e(he,ip),e(ip,gie),e(gie,l1o),e(ip,i1o),e(ip,jN),e(jN,d1o),e(ip,c1o),e(he,f1o),e(he,dp),e(dp,hie),e(hie,m1o),e(dp,g1o),e(dp,pie),e(pie,h1o),e(dp,p1o),e(he,_1o),e(he,cp),e(cp,_ie),e(_ie,u1o),e(cp,b1o),e(cp,DN),e(DN,v1o),e(cp,F1o),e(he,T1o),e(he,fp),e(fp,uie),e(uie,M1o),e(fp,E1o),e(fp,GN),e(GN,C1o),e(fp,w1o),e(he,A1o),e(he,mp),e(mp,bie),e(bie,L1o),e(mp,y1o),e(mp,ON),e(ON,x1o),e(mp,$1o),e(he,k1o),e(he,gp),e(gp,vie),e(vie,S1o),e(gp,R1o),e(gp,VN),e(VN,P1o),e(gp,B1o),e(he,I1o),e(he,hp),e(hp,Fie),e(Fie,N1o),e(hp,q1o),e(hp,XN),e(XN,j1o),e(hp,D1o),e(he,G1o),e(he,pp),e(pp,Tie),e(Tie,O1o),e(pp,V1o),e(pp,zN),e(zN,X1o),e(pp,z1o),e(he,Q1o),e(he,_p),e(_p,Mie),e(Mie,W1o),e(_p,H1o),e(_p,QN),e(QN,U1o),e(_p,J1o),e(he,Y1o),e(he,up),e(up,Eie),e(Eie,K1o),e(up,Z1o),e(up,WN),e(WN,e2o),e(up,o2o),e(he,r2o),e(he,bp),e(bp,Cie),e(Cie,t2o),e(bp,a2o),e(bp,HN),e(HN,n2o),e(bp,s2o),e(he,l2o),e(he,vp),e(vp,wie),e(wie,i2o),e(vp,d2o),e(vp,UN),e(UN,c2o),e(vp,f2o),e(he,m2o),e(he,Fp),e(Fp,Aie),e(Aie,g2o),e(Fp,h2o),e(Fp,JN),e(JN,p2o),e(Fp,_2o),e(he,u2o),e(he,Tp),e(Tp,Lie),e(Lie,b2o),e(Tp,v2o),e(Tp,YN),e(YN,F2o),e(Tp,T2o),e(he,M2o),e(he,Mp),e(Mp,yie),e(yie,E2o),e(Mp,C2o),e(Mp,KN),e(KN,w2o),e(Mp,A2o),e(he,L2o),e(he,Ep),e(Ep,xie),e(xie,y2o),e(Ep,x2o),e(Ep,ZN),e(ZN,$2o),e(Ep,k2o),e(he,S2o),e(he,Cp),e(Cp,$ie),e($ie,R2o),e(Cp,P2o),e(Cp,eq),e(eq,B2o),e(Cp,I2o),e(Ue,N2o),M(wp,Ue,null),e(Ue,q2o),M(Ap,Ue,null),e(yo,j2o),e(yo,Lp),M(eA,Lp,null),e(Lp,D2o),e(Lp,kie),e(kie,G2o),b(f,KGe,u),b(f,Bi,u),e(Bi,yp),e(yp,Sie),M(oA,Sie,null),e(Bi,O2o),e(Bi,Rie),e(Rie,V2o),b(f,ZGe,u),b(f,xo,u),M(rA,xo,null),e(xo,X2o),e(xo,Ii),e(Ii,z2o),e(Ii,oq),e(oq,Q2o),e(Ii,W2o),e(Ii,rq),e(rq,H2o),e(Ii,U2o),e(xo,J2o),e(xo,tA),e(tA,Y2o),e(tA,Pie),e(Pie,K2o),e(tA,Z2o),e(xo,ebo),e(xo,nt),M(aA,nt,null),e(nt,obo),e(nt,Bie),e(Bie,rbo),e(nt,tbo),e(nt,Ni),e(Ni,abo),e(Ni,Iie),e(Iie,nbo),e(Ni,sbo),e(Ni,tq),e(tq,lbo),e(Ni,ibo),e(nt,dbo),M(xp,nt,null),e(xo,cbo),e(xo,Je),M(nA,Je,null),e(Je,fbo),e(Je,Nie),e(Nie,mbo),e(Je,gbo),e(Je,Ra),e(Ra,hbo),e(Ra,qie),e(qie,pbo),e(Ra,_bo),e(Ra,jie),e(jie,ubo),e(Ra,bbo),e(Ra,Die),e(Die,vbo),e(Ra,Fbo),e(Je,Tbo),e(Je,y),e(y,$p),e($p,Gie),e(Gie,Mbo),e($p,Ebo),e($p,aq),e(aq,Cbo),e($p,wbo),e(y,Abo),e(y,kp),e(kp,Oie),e(Oie,Lbo),e(kp,ybo),e(kp,nq),e(nq,xbo),e(kp,$bo),e(y,kbo),e(y,Sp),e(Sp,Vie),e(Vie,Sbo),e(Sp,Rbo),e(Sp,sq),e(sq,Pbo),e(Sp,Bbo),e(y,Ibo),e(y,Rp),e(Rp,Xie),e(Xie,Nbo),e(Rp,qbo),e(Rp,lq),e(lq,jbo),e(Rp,Dbo),e(y,Gbo),e(y,Pp),e(Pp,zie),e(zie,Obo),e(Pp,Vbo),e(Pp,iq),e(iq,Xbo),e(Pp,zbo),e(y,Qbo),e(y,Bp),e(Bp,Qie),e(Qie,Wbo),e(Bp,Hbo),e(Bp,dq),e(dq,Ubo),e(Bp,Jbo),e(y,Ybo),e(y,Ip),e(Ip,Wie),e(Wie,Kbo),e(Ip,Zbo),e(Ip,cq),e(cq,evo),e(Ip,ovo),e(y,rvo),e(y,Np),e(Np,Hie),e(Hie,tvo),e(Np,avo),e(Np,fq),e(fq,nvo),e(Np,svo),e(y,lvo),e(y,qp),e(qp,Uie),e(Uie,ivo),e(qp,dvo),e(qp,mq),e(mq,cvo),e(qp,fvo),e(y,mvo),e(y,jp),e(jp,Jie),e(Jie,gvo),e(jp,hvo),e(jp,gq),e(gq,pvo),e(jp,_vo),e(y,uvo),e(y,Dp),e(Dp,Yie),e(Yie,bvo),e(Dp,vvo),e(Dp,hq),e(hq,Fvo),e(Dp,Tvo),e(y,Mvo),e(y,Gp),e(Gp,Kie),e(Kie,Evo),e(Gp,Cvo),e(Gp,pq),e(pq,wvo),e(Gp,Avo),e(y,Lvo),e(y,Op),e(Op,Zie),e(Zie,yvo),e(Op,xvo),e(Op,_q),e(_q,$vo),e(Op,kvo),e(y,Svo),e(y,Vp),e(Vp,ede),e(ede,Rvo),e(Vp,Pvo),e(Vp,uq),e(uq,Bvo),e(Vp,Ivo),e(y,Nvo),e(y,Xp),e(Xp,ode),e(ode,qvo),e(Xp,jvo),e(Xp,bq),e(bq,Dvo),e(Xp,Gvo),e(y,Ovo),e(y,zp),e(zp,rde),e(rde,Vvo),e(zp,Xvo),e(zp,vq),e(vq,zvo),e(zp,Qvo),e(y,Wvo),e(y,Qp),e(Qp,tde),e(tde,Hvo),e(Qp,Uvo),e(Qp,Fq),e(Fq,Jvo),e(Qp,Yvo),e(y,Kvo),e(y,Wp),e(Wp,ade),e(ade,Zvo),e(Wp,eFo),e(Wp,Tq),e(Tq,oFo),e(Wp,rFo),e(y,tFo),e(y,Hp),e(Hp,nde),e(nde,aFo),e(Hp,nFo),e(Hp,Mq),e(Mq,sFo),e(Hp,lFo),e(y,iFo),e(y,Up),e(Up,sde),e(sde,dFo),e(Up,cFo),e(Up,Eq),e(Eq,fFo),e(Up,mFo),e(y,gFo),e(y,Jp),e(Jp,lde),e(lde,hFo),e(Jp,pFo),e(Jp,Cq),e(Cq,_Fo),e(Jp,uFo),e(y,bFo),e(y,Yp),e(Yp,ide),e(ide,vFo),e(Yp,FFo),e(Yp,wq),e(wq,TFo),e(Yp,MFo),e(y,EFo),e(y,Kp),e(Kp,dde),e(dde,CFo),e(Kp,wFo),e(Kp,Aq),e(Aq,AFo),e(Kp,LFo),e(y,yFo),e(y,Zp),e(Zp,cde),e(cde,xFo),e(Zp,$Fo),e(Zp,Lq),e(Lq,kFo),e(Zp,SFo),e(y,RFo),e(y,e_),e(e_,fde),e(fde,PFo),e(e_,BFo),e(e_,yq),e(yq,IFo),e(e_,NFo),e(y,qFo),e(y,o_),e(o_,mde),e(mde,jFo),e(o_,DFo),e(o_,xq),e(xq,GFo),e(o_,OFo),e(y,VFo),e(y,r_),e(r_,gde),e(gde,XFo),e(r_,zFo),e(r_,$q),e($q,QFo),e(r_,WFo),e(y,HFo),e(y,t_),e(t_,hde),e(hde,UFo),e(t_,JFo),e(t_,kq),e(kq,YFo),e(t_,KFo),e(y,ZFo),e(y,a_),e(a_,pde),e(pde,e6o),e(a_,o6o),e(a_,Sq),e(Sq,r6o),e(a_,t6o),e(y,a6o),e(y,n_),e(n_,_de),e(_de,n6o),e(n_,s6o),e(n_,Rq),e(Rq,l6o),e(n_,i6o),e(y,d6o),e(y,s_),e(s_,ude),e(ude,c6o),e(s_,f6o),e(s_,Pq),e(Pq,m6o),e(s_,g6o),e(y,h6o),e(y,l_),e(l_,bde),e(bde,p6o),e(l_,_6o),e(l_,Bq),e(Bq,u6o),e(l_,b6o),e(y,v6o),e(y,i_),e(i_,vde),e(vde,F6o),e(i_,T6o),e(i_,Iq),e(Iq,M6o),e(i_,E6o),e(y,C6o),e(y,Vs),e(Vs,Fde),e(Fde,w6o),e(Vs,A6o),e(Vs,Nq),e(Nq,L6o),e(Vs,y6o),e(Vs,qq),e(qq,x6o),e(Vs,$6o),e(y,k6o),e(y,d_),e(d_,Tde),e(Tde,S6o),e(d_,R6o),e(d_,jq),e(jq,P6o),e(d_,B6o),e(y,I6o),e(y,c_),e(c_,Mde),e(Mde,N6o),e(c_,q6o),e(c_,Dq),e(Dq,j6o),e(c_,D6o),e(y,G6o),e(y,f_),e(f_,Ede),e(Ede,O6o),e(f_,V6o),e(f_,Gq),e(Gq,X6o),e(f_,z6o),e(y,Q6o),e(y,m_),e(m_,Cde),e(Cde,W6o),e(m_,H6o),e(m_,Oq),e(Oq,U6o),e(m_,J6o),e(y,Y6o),e(y,g_),e(g_,wde),e(wde,K6o),e(g_,Z6o),e(g_,Vq),e(Vq,eTo),e(g_,oTo),e(y,rTo),e(y,h_),e(h_,Ade),e(Ade,tTo),e(h_,aTo),e(h_,Xq),e(Xq,nTo),e(h_,sTo),e(y,lTo),e(y,p_),e(p_,Lde),e(Lde,iTo),e(p_,dTo),e(p_,zq),e(zq,cTo),e(p_,fTo),e(y,mTo),e(y,__),e(__,yde),e(yde,gTo),e(__,hTo),e(__,Qq),e(Qq,pTo),e(__,_To),e(y,uTo),e(y,u_),e(u_,xde),e(xde,bTo),e(u_,vTo),e(u_,Wq),e(Wq,FTo),e(u_,TTo),e(y,MTo),e(y,b_),e(b_,$de),e($de,ETo),e(b_,CTo),e(b_,Hq),e(Hq,wTo),e(b_,ATo),e(y,LTo),e(y,v_),e(v_,kde),e(kde,yTo),e(v_,xTo),e(v_,Uq),e(Uq,$To),e(v_,kTo),e(y,STo),e(y,F_),e(F_,Sde),e(Sde,RTo),e(F_,PTo),e(F_,Jq),e(Jq,BTo),e(F_,ITo),e(y,NTo),e(y,T_),e(T_,Rde),e(Rde,qTo),e(T_,jTo),e(T_,Yq),e(Yq,DTo),e(T_,GTo),e(y,OTo),e(y,M_),e(M_,Pde),e(Pde,VTo),e(M_,XTo),e(M_,Kq),e(Kq,zTo),e(M_,QTo),e(y,WTo),e(y,E_),e(E_,Bde),e(Bde,HTo),e(E_,UTo),e(E_,Zq),e(Zq,JTo),e(E_,YTo),e(y,KTo),e(y,C_),e(C_,Ide),e(Ide,ZTo),e(C_,e7o),e(C_,ej),e(ej,o7o),e(C_,r7o),e(y,t7o),e(y,w_),e(w_,Nde),e(Nde,a7o),e(w_,n7o),e(w_,oj),e(oj,s7o),e(w_,l7o),e(y,i7o),e(y,A_),e(A_,qde),e(qde,d7o),e(A_,c7o),e(A_,rj),e(rj,f7o),e(A_,m7o),e(y,g7o),e(y,L_),e(L_,jde),e(jde,h7o),e(L_,p7o),e(L_,tj),e(tj,_7o),e(L_,u7o),e(y,b7o),e(y,y_),e(y_,Dde),e(Dde,v7o),e(y_,F7o),e(y_,aj),e(aj,T7o),e(y_,M7o),e(y,E7o),e(y,x_),e(x_,Gde),e(Gde,C7o),e(x_,w7o),e(x_,nj),e(nj,A7o),e(x_,L7o),e(y,y7o),e(y,$_),e($_,Ode),e(Ode,x7o),e($_,$7o),e($_,sj),e(sj,k7o),e($_,S7o),e(y,R7o),e(y,k_),e(k_,Vde),e(Vde,P7o),e(k_,B7o),e(k_,lj),e(lj,I7o),e(k_,N7o),e(y,q7o),e(y,S_),e(S_,Xde),e(Xde,j7o),e(S_,D7o),e(S_,ij),e(ij,G7o),e(S_,O7o),e(y,V7o),e(y,R_),e(R_,zde),e(zde,X7o),e(R_,z7o),e(R_,dj),e(dj,Q7o),e(R_,W7o),e(y,H7o),e(y,P_),e(P_,Qde),e(Qde,U7o),e(P_,J7o),e(P_,cj),e(cj,Y7o),e(P_,K7o),e(y,Z7o),e(y,B_),e(B_,Wde),e(Wde,e8o),e(B_,o8o),e(B_,fj),e(fj,r8o),e(B_,t8o),e(y,a8o),e(y,I_),e(I_,Hde),e(Hde,n8o),e(I_,s8o),e(I_,mj),e(mj,l8o),e(I_,i8o),e(y,d8o),e(y,N_),e(N_,Ude),e(Ude,c8o),e(N_,f8o),e(N_,gj),e(gj,m8o),e(N_,g8o),e(y,h8o),e(y,q_),e(q_,Jde),e(Jde,p8o),e(q_,_8o),e(q_,hj),e(hj,u8o),e(q_,b8o),e(y,v8o),e(y,j_),e(j_,Yde),e(Yde,F8o),e(j_,T8o),e(j_,pj),e(pj,M8o),e(j_,E8o),e(y,C8o),e(y,D_),e(D_,Kde),e(Kde,w8o),e(D_,A8o),e(D_,_j),e(_j,L8o),e(D_,y8o),e(y,x8o),e(y,G_),e(G_,Zde),e(Zde,$8o),e(G_,k8o),e(G_,uj),e(uj,S8o),e(G_,R8o),e(y,P8o),e(y,O_),e(O_,ece),e(ece,B8o),e(O_,I8o),e(O_,bj),e(bj,N8o),e(O_,q8o),e(y,j8o),e(y,V_),e(V_,oce),e(oce,D8o),e(V_,G8o),e(V_,vj),e(vj,O8o),e(V_,V8o),e(y,X8o),e(y,X_),e(X_,rce),e(rce,z8o),e(X_,Q8o),e(X_,Fj),e(Fj,W8o),e(X_,H8o),e(y,U8o),e(y,z_),e(z_,tce),e(tce,J8o),e(z_,Y8o),e(z_,Tj),e(Tj,K8o),e(z_,Z8o),e(y,e9o),e(y,Q_),e(Q_,ace),e(ace,o9o),e(Q_,r9o),e(Q_,Mj),e(Mj,t9o),e(Q_,a9o),e(y,n9o),e(y,W_),e(W_,nce),e(nce,s9o),e(W_,l9o),e(W_,Ej),e(Ej,i9o),e(W_,d9o),e(y,c9o),e(y,H_),e(H_,sce),e(sce,f9o),e(H_,m9o),e(H_,Cj),e(Cj,g9o),e(H_,h9o),e(y,p9o),e(y,U_),e(U_,lce),e(lce,_9o),e(U_,u9o),e(U_,wj),e(wj,b9o),e(U_,v9o),e(y,F9o),e(y,J_),e(J_,ice),e(ice,T9o),e(J_,M9o),e(J_,Aj),e(Aj,E9o),e(J_,C9o),e(y,w9o),e(y,Y_),e(Y_,dce),e(dce,A9o),e(Y_,L9o),e(Y_,Lj),e(Lj,y9o),e(Y_,x9o),e(y,$9o),e(y,K_),e(K_,cce),e(cce,k9o),e(K_,S9o),e(K_,yj),e(yj,R9o),e(K_,P9o),e(y,B9o),e(y,Z_),e(Z_,fce),e(fce,I9o),e(Z_,N9o),e(Z_,xj),e(xj,q9o),e(Z_,j9o),e(y,D9o),e(y,eu),e(eu,mce),e(mce,G9o),e(eu,O9o),e(eu,$j),e($j,V9o),e(eu,X9o),e(y,z9o),e(y,ou),e(ou,gce),e(gce,Q9o),e(ou,W9o),e(ou,kj),e(kj,H9o),e(ou,U9o),e(y,J9o),e(y,ru),e(ru,hce),e(hce,Y9o),e(ru,K9o),e(ru,Sj),e(Sj,Z9o),e(ru,eMo),e(y,oMo),e(y,tu),e(tu,pce),e(pce,rMo),e(tu,tMo),e(tu,Rj),e(Rj,aMo),e(tu,nMo),e(y,sMo),e(y,au),e(au,_ce),e(_ce,lMo),e(au,iMo),e(au,Pj),e(Pj,dMo),e(au,cMo),e(y,fMo),e(y,nu),e(nu,uce),e(uce,mMo),e(nu,gMo),e(nu,Bj),e(Bj,hMo),e(nu,pMo),e(y,_Mo),e(y,su),e(su,bce),e(bce,uMo),e(su,bMo),e(su,Ij),e(Ij,vMo),e(su,FMo),e(y,TMo),e(y,lu),e(lu,vce),e(vce,MMo),e(lu,EMo),e(lu,Nj),e(Nj,CMo),e(lu,wMo),e(y,AMo),e(y,iu),e(iu,Fce),e(Fce,LMo),e(iu,yMo),e(iu,qj),e(qj,xMo),e(iu,$Mo),e(y,kMo),e(y,du),e(du,Tce),e(Tce,SMo),e(du,RMo),e(du,jj),e(jj,PMo),e(du,BMo),e(y,IMo),e(y,cu),e(cu,Mce),e(Mce,NMo),e(cu,qMo),e(cu,Dj),e(Dj,jMo),e(cu,DMo),e(y,GMo),e(y,fu),e(fu,Ece),e(Ece,OMo),e(fu,VMo),e(fu,Gj),e(Gj,XMo),e(fu,zMo),e(y,QMo),e(y,mu),e(mu,Cce),e(Cce,WMo),e(mu,HMo),e(mu,Oj),e(Oj,UMo),e(mu,JMo),e(y,YMo),e(y,gu),e(gu,wce),e(wce,KMo),e(gu,ZMo),e(gu,Vj),e(Vj,eEo),e(gu,oEo),e(y,rEo),e(y,hu),e(hu,Ace),e(Ace,tEo),e(hu,aEo),e(hu,Xj),e(Xj,nEo),e(hu,sEo),e(y,lEo),e(y,pu),e(pu,Lce),e(Lce,iEo),e(pu,dEo),e(pu,zj),e(zj,cEo),e(pu,fEo),e(y,mEo),e(y,_u),e(_u,yce),e(yce,gEo),e(_u,hEo),e(_u,Qj),e(Qj,pEo),e(_u,_Eo),e(y,uEo),e(y,uu),e(uu,xce),e(xce,bEo),e(uu,vEo),e(uu,Wj),e(Wj,FEo),e(uu,TEo),e(y,MEo),e(y,bu),e(bu,$ce),e($ce,EEo),e(bu,CEo),e(bu,Hj),e(Hj,wEo),e(bu,AEo),e(y,LEo),e(y,vu),e(vu,kce),e(kce,yEo),e(vu,xEo),e(vu,Uj),e(Uj,$Eo),e(vu,kEo),e(y,SEo),e(y,Fu),e(Fu,Sce),e(Sce,REo),e(Fu,PEo),e(Fu,Jj),e(Jj,BEo),e(Fu,IEo),e(y,NEo),e(y,Tu),e(Tu,Rce),e(Rce,qEo),e(Tu,jEo),e(Tu,Yj),e(Yj,DEo),e(Tu,GEo),e(y,OEo),e(y,Mu),e(Mu,Pce),e(Pce,VEo),e(Mu,XEo),e(Mu,Kj),e(Kj,zEo),e(Mu,QEo),e(y,WEo),e(y,Eu),e(Eu,Bce),e(Bce,HEo),e(Eu,UEo),e(Eu,Zj),e(Zj,JEo),e(Eu,YEo),e(y,KEo),e(y,Cu),e(Cu,Ice),e(Ice,ZEo),e(Cu,e4o),e(Cu,eD),e(eD,o4o),e(Cu,r4o),e(y,t4o),e(y,wu),e(wu,Nce),e(Nce,a4o),e(wu,n4o),e(wu,oD),e(oD,s4o),e(wu,l4o),e(y,i4o),e(y,Au),e(Au,qce),e(qce,d4o),e(Au,c4o),e(Au,rD),e(rD,f4o),e(Au,m4o),e(y,g4o),e(y,Lu),e(Lu,jce),e(jce,h4o),e(Lu,p4o),e(Lu,tD),e(tD,_4o),e(Lu,u4o),e(Je,b4o),e(Je,yu),e(yu,v4o),e(yu,Dce),e(Dce,F4o),e(yu,T4o),e(yu,Gce),e(Gce,M4o),e(Je,E4o),M(xu,Je,null),b(f,eOe,u),b(f,qi,u),e(qi,$u),e($u,Oce),M(sA,Oce,null),e(qi,C4o),e(qi,Vce),e(Vce,w4o),b(f,oOe,u),b(f,$o,u),M(lA,$o,null),e($o,A4o),e($o,ji),e(ji,L4o),e(ji,aD),e(aD,y4o),e(ji,x4o),e(ji,nD),e(nD,$4o),e(ji,k4o),e($o,S4o),e($o,iA),e(iA,R4o),e(iA,Xce),e(Xce,P4o),e(iA,B4o),e($o,I4o),e($o,st),M(dA,st,null),e(st,N4o),e(st,zce),e(zce,q4o),e(st,j4o),e(st,Di),e(Di,D4o),e(Di,Qce),e(Qce,G4o),e(Di,O4o),e(Di,sD),e(sD,V4o),e(Di,X4o),e(st,z4o),M(ku,st,null),e($o,Q4o),e($o,Ye),M(cA,Ye,null),e(Ye,W4o),e(Ye,Wce),e(Wce,H4o),e(Ye,U4o),e(Ye,Pa),e(Pa,J4o),e(Pa,Hce),e(Hce,Y4o),e(Pa,K4o),e(Pa,Uce),e(Uce,Z4o),e(Pa,eCo),e(Pa,Jce),e(Jce,oCo),e(Pa,rCo),e(Ye,tCo),e(Ye,G),e(G,Su),e(Su,Yce),e(Yce,aCo),e(Su,nCo),e(Su,lD),e(lD,sCo),e(Su,lCo),e(G,iCo),e(G,Ru),e(Ru,Kce),e(Kce,dCo),e(Ru,cCo),e(Ru,iD),e(iD,fCo),e(Ru,mCo),e(G,gCo),e(G,Pu),e(Pu,Zce),e(Zce,hCo),e(Pu,pCo),e(Pu,dD),e(dD,_Co),e(Pu,uCo),e(G,bCo),e(G,Bu),e(Bu,efe),e(efe,vCo),e(Bu,FCo),e(Bu,cD),e(cD,TCo),e(Bu,MCo),e(G,ECo),e(G,Iu),e(Iu,ofe),e(ofe,CCo),e(Iu,wCo),e(Iu,fD),e(fD,ACo),e(Iu,LCo),e(G,yCo),e(G,Nu),e(Nu,rfe),e(rfe,xCo),e(Nu,$Co),e(Nu,mD),e(mD,kCo),e(Nu,SCo),e(G,RCo),e(G,qu),e(qu,tfe),e(tfe,PCo),e(qu,BCo),e(qu,gD),e(gD,ICo),e(qu,NCo),e(G,qCo),e(G,ju),e(ju,afe),e(afe,jCo),e(ju,DCo),e(ju,hD),e(hD,GCo),e(ju,OCo),e(G,VCo),e(G,Du),e(Du,nfe),e(nfe,XCo),e(Du,zCo),e(Du,pD),e(pD,QCo),e(Du,WCo),e(G,HCo),e(G,Gu),e(Gu,sfe),e(sfe,UCo),e(Gu,JCo),e(Gu,_D),e(_D,YCo),e(Gu,KCo),e(G,ZCo),e(G,Ou),e(Ou,lfe),e(lfe,e5o),e(Ou,o5o),e(Ou,uD),e(uD,r5o),e(Ou,t5o),e(G,a5o),e(G,Vu),e(Vu,ife),e(ife,n5o),e(Vu,s5o),e(Vu,bD),e(bD,l5o),e(Vu,i5o),e(G,d5o),e(G,Xu),e(Xu,dfe),e(dfe,c5o),e(Xu,f5o),e(Xu,vD),e(vD,m5o),e(Xu,g5o),e(G,h5o),e(G,zu),e(zu,cfe),e(cfe,p5o),e(zu,_5o),e(zu,FD),e(FD,u5o),e(zu,b5o),e(G,v5o),e(G,Qu),e(Qu,ffe),e(ffe,F5o),e(Qu,T5o),e(Qu,TD),e(TD,M5o),e(Qu,E5o),e(G,C5o),e(G,Wu),e(Wu,mfe),e(mfe,w5o),e(Wu,A5o),e(Wu,MD),e(MD,L5o),e(Wu,y5o),e(G,x5o),e(G,Hu),e(Hu,gfe),e(gfe,$5o),e(Hu,k5o),e(Hu,ED),e(ED,S5o),e(Hu,R5o),e(G,P5o),e(G,Uu),e(Uu,hfe),e(hfe,B5o),e(Uu,I5o),e(Uu,CD),e(CD,N5o),e(Uu,q5o),e(G,j5o),e(G,Ju),e(Ju,pfe),e(pfe,D5o),e(Ju,G5o),e(Ju,wD),e(wD,O5o),e(Ju,V5o),e(G,X5o),e(G,Yu),e(Yu,_fe),e(_fe,z5o),e(Yu,Q5o),e(Yu,AD),e(AD,W5o),e(Yu,H5o),e(G,U5o),e(G,Ku),e(Ku,ufe),e(ufe,J5o),e(Ku,Y5o),e(Ku,LD),e(LD,K5o),e(Ku,Z5o),e(G,e3o),e(G,Zu),e(Zu,bfe),e(bfe,o3o),e(Zu,r3o),e(Zu,yD),e(yD,t3o),e(Zu,a3o),e(G,n3o),e(G,e1),e(e1,vfe),e(vfe,s3o),e(e1,l3o),e(e1,xD),e(xD,i3o),e(e1,d3o),e(G,c3o),e(G,o1),e(o1,Ffe),e(Ffe,f3o),e(o1,m3o),e(o1,$D),e($D,g3o),e(o1,h3o),e(G,p3o),e(G,r1),e(r1,Tfe),e(Tfe,_3o),e(r1,u3o),e(r1,kD),e(kD,b3o),e(r1,v3o),e(G,F3o),e(G,t1),e(t1,Mfe),e(Mfe,T3o),e(t1,M3o),e(t1,SD),e(SD,E3o),e(t1,C3o),e(G,w3o),e(G,a1),e(a1,Efe),e(Efe,A3o),e(a1,L3o),e(a1,RD),e(RD,y3o),e(a1,x3o),e(G,$3o),e(G,n1),e(n1,Cfe),e(Cfe,k3o),e(n1,S3o),e(n1,PD),e(PD,R3o),e(n1,P3o),e(G,B3o),e(G,s1),e(s1,wfe),e(wfe,I3o),e(s1,N3o),e(s1,BD),e(BD,q3o),e(s1,j3o),e(G,D3o),e(G,l1),e(l1,Afe),e(Afe,G3o),e(l1,O3o),e(l1,ID),e(ID,V3o),e(l1,X3o),e(G,z3o),e(G,i1),e(i1,Lfe),e(Lfe,Q3o),e(i1,W3o),e(i1,ND),e(ND,H3o),e(i1,U3o),e(G,J3o),e(G,d1),e(d1,yfe),e(yfe,Y3o),e(d1,K3o),e(d1,qD),e(qD,Z3o),e(d1,e0o),e(G,o0o),e(G,c1),e(c1,xfe),e(xfe,r0o),e(c1,t0o),e(c1,jD),e(jD,a0o),e(c1,n0o),e(G,s0o),e(G,f1),e(f1,$fe),e($fe,l0o),e(f1,i0o),e(f1,DD),e(DD,d0o),e(f1,c0o),e(G,f0o),e(G,m1),e(m1,kfe),e(kfe,m0o),e(m1,g0o),e(m1,GD),e(GD,h0o),e(m1,p0o),e(G,_0o),e(G,g1),e(g1,Sfe),e(Sfe,u0o),e(g1,b0o),e(g1,OD),e(OD,v0o),e(g1,F0o),e(G,T0o),e(G,h1),e(h1,Rfe),e(Rfe,M0o),e(h1,E0o),e(h1,VD),e(VD,C0o),e(h1,w0o),e(G,A0o),e(G,p1),e(p1,Pfe),e(Pfe,L0o),e(p1,y0o),e(p1,XD),e(XD,x0o),e(p1,$0o),e(G,k0o),e(G,_1),e(_1,Bfe),e(Bfe,S0o),e(_1,R0o),e(_1,zD),e(zD,P0o),e(_1,B0o),e(G,I0o),e(G,u1),e(u1,Ife),e(Ife,N0o),e(u1,q0o),e(u1,QD),e(QD,j0o),e(u1,D0o),e(G,G0o),e(G,b1),e(b1,Nfe),e(Nfe,O0o),e(b1,V0o),e(b1,WD),e(WD,X0o),e(b1,z0o),e(G,Q0o),e(G,v1),e(v1,qfe),e(qfe,W0o),e(v1,H0o),e(v1,HD),e(HD,U0o),e(v1,J0o),e(G,Y0o),e(G,F1),e(F1,jfe),e(jfe,K0o),e(F1,Z0o),e(F1,UD),e(UD,ewo),e(F1,owo),e(G,rwo),e(G,T1),e(T1,Dfe),e(Dfe,two),e(T1,awo),e(T1,JD),e(JD,nwo),e(T1,swo),e(Ye,lwo),e(Ye,M1),e(M1,iwo),e(M1,Gfe),e(Gfe,dwo),e(M1,cwo),e(M1,Ofe),e(Ofe,fwo),e(Ye,mwo),M(E1,Ye,null),b(f,rOe,u),b(f,Gi,u),e(Gi,C1),e(C1,Vfe),M(fA,Vfe,null),e(Gi,gwo),e(Gi,Xfe),e(Xfe,hwo),b(f,tOe,u),b(f,ko,u),M(mA,ko,null),e(ko,pwo),e(ko,Oi),e(Oi,_wo),e(Oi,YD),e(YD,uwo),e(Oi,bwo),e(Oi,KD),e(KD,vwo),e(Oi,Fwo),e(ko,Two),e(ko,gA),e(gA,Mwo),e(gA,zfe),e(zfe,Ewo),e(gA,Cwo),e(ko,wwo),e(ko,lt),M(hA,lt,null),e(lt,Awo),e(lt,Qfe),e(Qfe,Lwo),e(lt,ywo),e(lt,Vi),e(Vi,xwo),e(Vi,Wfe),e(Wfe,$wo),e(Vi,kwo),e(Vi,ZD),e(ZD,Swo),e(Vi,Rwo),e(lt,Pwo),M(w1,lt,null),e(ko,Bwo),e(ko,Ke),M(pA,Ke,null),e(Ke,Iwo),e(Ke,Hfe),e(Hfe,Nwo),e(Ke,qwo),e(Ke,Ba),e(Ba,jwo),e(Ba,Ufe),e(Ufe,Dwo),e(Ba,Gwo),e(Ba,Jfe),e(Jfe,Owo),e(Ba,Vwo),e(Ba,Yfe),e(Yfe,Xwo),e(Ba,zwo),e(Ke,Qwo),e(Ke,z),e(z,A1),e(A1,Kfe),e(Kfe,Wwo),e(A1,Hwo),e(A1,eG),e(eG,Uwo),e(A1,Jwo),e(z,Ywo),e(z,L1),e(L1,Zfe),e(Zfe,Kwo),e(L1,Zwo),e(L1,oG),e(oG,eAo),e(L1,oAo),e(z,rAo),e(z,y1),e(y1,eme),e(eme,tAo),e(y1,aAo),e(y1,rG),e(rG,nAo),e(y1,sAo),e(z,lAo),e(z,x1),e(x1,ome),e(ome,iAo),e(x1,dAo),e(x1,tG),e(tG,cAo),e(x1,fAo),e(z,mAo),e(z,$1),e($1,rme),e(rme,gAo),e($1,hAo),e($1,aG),e(aG,pAo),e($1,_Ao),e(z,uAo),e(z,k1),e(k1,tme),e(tme,bAo),e(k1,vAo),e(k1,nG),e(nG,FAo),e(k1,TAo),e(z,MAo),e(z,S1),e(S1,ame),e(ame,EAo),e(S1,CAo),e(S1,sG),e(sG,wAo),e(S1,AAo),e(z,LAo),e(z,R1),e(R1,nme),e(nme,yAo),e(R1,xAo),e(R1,lG),e(lG,$Ao),e(R1,kAo),e(z,SAo),e(z,P1),e(P1,sme),e(sme,RAo),e(P1,PAo),e(P1,iG),e(iG,BAo),e(P1,IAo),e(z,NAo),e(z,B1),e(B1,lme),e(lme,qAo),e(B1,jAo),e(B1,dG),e(dG,DAo),e(B1,GAo),e(z,OAo),e(z,I1),e(I1,ime),e(ime,VAo),e(I1,XAo),e(I1,cG),e(cG,zAo),e(I1,QAo),e(z,WAo),e(z,N1),e(N1,dme),e(dme,HAo),e(N1,UAo),e(N1,fG),e(fG,JAo),e(N1,YAo),e(z,KAo),e(z,q1),e(q1,cme),e(cme,ZAo),e(q1,eLo),e(q1,mG),e(mG,oLo),e(q1,rLo),e(z,tLo),e(z,j1),e(j1,fme),e(fme,aLo),e(j1,nLo),e(j1,gG),e(gG,sLo),e(j1,lLo),e(z,iLo),e(z,D1),e(D1,mme),e(mme,dLo),e(D1,cLo),e(D1,hG),e(hG,fLo),e(D1,mLo),e(z,gLo),e(z,G1),e(G1,gme),e(gme,hLo),e(G1,pLo),e(G1,pG),e(pG,_Lo),e(G1,uLo),e(z,bLo),e(z,O1),e(O1,hme),e(hme,vLo),e(O1,FLo),e(O1,_G),e(_G,TLo),e(O1,MLo),e(z,ELo),e(z,V1),e(V1,pme),e(pme,CLo),e(V1,wLo),e(V1,uG),e(uG,ALo),e(V1,LLo),e(z,yLo),e(z,X1),e(X1,_me),e(_me,xLo),e(X1,$Lo),e(X1,bG),e(bG,kLo),e(X1,SLo),e(z,RLo),e(z,z1),e(z1,ume),e(ume,PLo),e(z1,BLo),e(z1,vG),e(vG,ILo),e(z1,NLo),e(z,qLo),e(z,Q1),e(Q1,bme),e(bme,jLo),e(Q1,DLo),e(Q1,FG),e(FG,GLo),e(Q1,OLo),e(z,VLo),e(z,W1),e(W1,vme),e(vme,XLo),e(W1,zLo),e(W1,TG),e(TG,QLo),e(W1,WLo),e(z,HLo),e(z,H1),e(H1,Fme),e(Fme,ULo),e(H1,JLo),e(H1,MG),e(MG,YLo),e(H1,KLo),e(z,ZLo),e(z,U1),e(U1,Tme),e(Tme,eyo),e(U1,oyo),e(U1,EG),e(EG,ryo),e(U1,tyo),e(z,ayo),e(z,J1),e(J1,Mme),e(Mme,nyo),e(J1,syo),e(J1,CG),e(CG,lyo),e(J1,iyo),e(z,dyo),e(z,Y1),e(Y1,Eme),e(Eme,cyo),e(Y1,fyo),e(Y1,wG),e(wG,myo),e(Y1,gyo),e(z,hyo),e(z,K1),e(K1,Cme),e(Cme,pyo),e(K1,_yo),e(K1,AG),e(AG,uyo),e(K1,byo),e(z,vyo),e(z,Z1),e(Z1,wme),e(wme,Fyo),e(Z1,Tyo),e(Z1,LG),e(LG,Myo),e(Z1,Eyo),e(z,Cyo),e(z,e2),e(e2,Ame),e(Ame,wyo),e(e2,Ayo),e(e2,yG),e(yG,Lyo),e(e2,yyo),e(z,xyo),e(z,o2),e(o2,Lme),e(Lme,$yo),e(o2,kyo),e(o2,xG),e(xG,Syo),e(o2,Ryo),e(z,Pyo),e(z,r2),e(r2,yme),e(yme,Byo),e(r2,Iyo),e(r2,$G),e($G,Nyo),e(r2,qyo),e(z,jyo),e(z,t2),e(t2,xme),e(xme,Dyo),e(t2,Gyo),e(t2,kG),e(kG,Oyo),e(t2,Vyo),e(z,Xyo),e(z,a2),e(a2,$me),e($me,zyo),e(a2,Qyo),e(a2,SG),e(SG,Wyo),e(a2,Hyo),e(z,Uyo),e(z,n2),e(n2,kme),e(kme,Jyo),e(n2,Yyo),e(n2,RG),e(RG,Kyo),e(n2,Zyo),e(z,exo),e(z,s2),e(s2,Sme),e(Sme,oxo),e(s2,rxo),e(s2,PG),e(PG,txo),e(s2,axo),e(z,nxo),e(z,l2),e(l2,Rme),e(Rme,sxo),e(l2,lxo),e(l2,BG),e(BG,ixo),e(l2,dxo),e(z,cxo),e(z,i2),e(i2,Pme),e(Pme,fxo),e(i2,mxo),e(i2,IG),e(IG,gxo),e(i2,hxo),e(z,pxo),e(z,d2),e(d2,Bme),e(Bme,_xo),e(d2,uxo),e(d2,NG),e(NG,bxo),e(d2,vxo),e(Ke,Fxo),e(Ke,c2),e(c2,Txo),e(c2,Ime),e(Ime,Mxo),e(c2,Exo),e(c2,Nme),e(Nme,Cxo),e(Ke,wxo),M(f2,Ke,null),b(f,aOe,u),b(f,Xi,u),e(Xi,m2),e(m2,qme),M(_A,qme,null),e(Xi,Axo),e(Xi,jme),e(jme,Lxo),b(f,nOe,u),b(f,So,u),M(uA,So,null),e(So,yxo),e(So,zi),e(zi,xxo),e(zi,qG),e(qG,$xo),e(zi,kxo),e(zi,jG),e(jG,Sxo),e(zi,Rxo),e(So,Pxo),e(So,bA),e(bA,Bxo),e(bA,Dme),e(Dme,Ixo),e(bA,Nxo),e(So,qxo),e(So,it),M(vA,it,null),e(it,jxo),e(it,Gme),e(Gme,Dxo),e(it,Gxo),e(it,Qi),e(Qi,Oxo),e(Qi,Ome),e(Ome,Vxo),e(Qi,Xxo),e(Qi,DG),e(DG,zxo),e(Qi,Qxo),e(it,Wxo),M(g2,it,null),e(So,Hxo),e(So,Ze),M(FA,Ze,null),e(Ze,Uxo),e(Ze,Vme),e(Vme,Jxo),e(Ze,Yxo),e(Ze,Ia),e(Ia,Kxo),e(Ia,Xme),e(Xme,Zxo),e(Ia,e$o),e(Ia,zme),e(zme,o$o),e(Ia,r$o),e(Ia,Qme),e(Qme,t$o),e(Ia,a$o),e(Ze,n$o),e(Ze,Q),e(Q,h2),e(h2,Wme),e(Wme,s$o),e(h2,l$o),e(h2,GG),e(GG,i$o),e(h2,d$o),e(Q,c$o),e(Q,p2),e(p2,Hme),e(Hme,f$o),e(p2,m$o),e(p2,OG),e(OG,g$o),e(p2,h$o),e(Q,p$o),e(Q,_2),e(_2,Ume),e(Ume,_$o),e(_2,u$o),e(_2,VG),e(VG,b$o),e(_2,v$o),e(Q,F$o),e(Q,u2),e(u2,Jme),e(Jme,T$o),e(u2,M$o),e(u2,XG),e(XG,E$o),e(u2,C$o),e(Q,w$o),e(Q,b2),e(b2,Yme),e(Yme,A$o),e(b2,L$o),e(b2,zG),e(zG,y$o),e(b2,x$o),e(Q,$$o),e(Q,v2),e(v2,Kme),e(Kme,k$o),e(v2,S$o),e(v2,QG),e(QG,R$o),e(v2,P$o),e(Q,B$o),e(Q,F2),e(F2,Zme),e(Zme,I$o),e(F2,N$o),e(F2,WG),e(WG,q$o),e(F2,j$o),e(Q,D$o),e(Q,T2),e(T2,ege),e(ege,G$o),e(T2,O$o),e(T2,HG),e(HG,V$o),e(T2,X$o),e(Q,z$o),e(Q,M2),e(M2,oge),e(oge,Q$o),e(M2,W$o),e(M2,UG),e(UG,H$o),e(M2,U$o),e(Q,J$o),e(Q,E2),e(E2,rge),e(rge,Y$o),e(E2,K$o),e(E2,JG),e(JG,Z$o),e(E2,eko),e(Q,oko),e(Q,C2),e(C2,tge),e(tge,rko),e(C2,tko),e(C2,YG),e(YG,ako),e(C2,nko),e(Q,sko),e(Q,w2),e(w2,age),e(age,lko),e(w2,iko),e(w2,KG),e(KG,dko),e(w2,cko),e(Q,fko),e(Q,A2),e(A2,nge),e(nge,mko),e(A2,gko),e(A2,ZG),e(ZG,hko),e(A2,pko),e(Q,_ko),e(Q,L2),e(L2,sge),e(sge,uko),e(L2,bko),e(L2,eO),e(eO,vko),e(L2,Fko),e(Q,Tko),e(Q,y2),e(y2,lge),e(lge,Mko),e(y2,Eko),e(y2,oO),e(oO,Cko),e(y2,wko),e(Q,Ako),e(Q,x2),e(x2,ige),e(ige,Lko),e(x2,yko),e(x2,rO),e(rO,xko),e(x2,$ko),e(Q,kko),e(Q,$2),e($2,dge),e(dge,Sko),e($2,Rko),e($2,tO),e(tO,Pko),e($2,Bko),e(Q,Iko),e(Q,k2),e(k2,cge),e(cge,Nko),e(k2,qko),e(k2,aO),e(aO,jko),e(k2,Dko),e(Q,Gko),e(Q,S2),e(S2,fge),e(fge,Oko),e(S2,Vko),e(S2,nO),e(nO,Xko),e(S2,zko),e(Q,Qko),e(Q,R2),e(R2,mge),e(mge,Wko),e(R2,Hko),e(R2,sO),e(sO,Uko),e(R2,Jko),e(Q,Yko),e(Q,P2),e(P2,gge),e(gge,Kko),e(P2,Zko),e(P2,lO),e(lO,eSo),e(P2,oSo),e(Q,rSo),e(Q,B2),e(B2,hge),e(hge,tSo),e(B2,aSo),e(B2,iO),e(iO,nSo),e(B2,sSo),e(Q,lSo),e(Q,I2),e(I2,pge),e(pge,iSo),e(I2,dSo),e(I2,dO),e(dO,cSo),e(I2,fSo),e(Q,mSo),e(Q,N2),e(N2,_ge),e(_ge,gSo),e(N2,hSo),e(N2,cO),e(cO,pSo),e(N2,_So),e(Q,uSo),e(Q,q2),e(q2,uge),e(uge,bSo),e(q2,vSo),e(q2,fO),e(fO,FSo),e(q2,TSo),e(Q,MSo),e(Q,j2),e(j2,bge),e(bge,ESo),e(j2,CSo),e(j2,mO),e(mO,wSo),e(j2,ASo),e(Q,LSo),e(Q,D2),e(D2,vge),e(vge,ySo),e(D2,xSo),e(D2,gO),e(gO,$So),e(D2,kSo),e(Q,SSo),e(Q,G2),e(G2,Fge),e(Fge,RSo),e(G2,PSo),e(G2,hO),e(hO,BSo),e(G2,ISo),e(Q,NSo),e(Q,O2),e(O2,Tge),e(Tge,qSo),e(O2,jSo),e(O2,pO),e(pO,DSo),e(O2,GSo),e(Q,OSo),e(Q,V2),e(V2,Mge),e(Mge,VSo),e(V2,XSo),e(V2,_O),e(_O,zSo),e(V2,QSo),e(Q,WSo),e(Q,X2),e(X2,Ege),e(Ege,HSo),e(X2,USo),e(X2,uO),e(uO,JSo),e(X2,YSo),e(Q,KSo),e(Q,z2),e(z2,Cge),e(Cge,ZSo),e(z2,eRo),e(z2,bO),e(bO,oRo),e(z2,rRo),e(Q,tRo),e(Q,Q2),e(Q2,wge),e(wge,aRo),e(Q2,nRo),e(Q2,Age),e(Age,sRo),e(Q2,lRo),e(Q,iRo),e(Q,W2),e(W2,Lge),e(Lge,dRo),e(W2,cRo),e(W2,vO),e(vO,fRo),e(W2,mRo),e(Q,gRo),e(Q,H2),e(H2,yge),e(yge,hRo),e(H2,pRo),e(H2,FO),e(FO,_Ro),e(H2,uRo),e(Q,bRo),e(Q,U2),e(U2,xge),e(xge,vRo),e(U2,FRo),e(U2,TO),e(TO,TRo),e(U2,MRo),e(Q,ERo),e(Q,J2),e(J2,$ge),e($ge,CRo),e(J2,wRo),e(J2,MO),e(MO,ARo),e(J2,LRo),e(Ze,yRo),e(Ze,Y2),e(Y2,xRo),e(Y2,kge),e(kge,$Ro),e(Y2,kRo),e(Y2,Sge),e(Sge,SRo),e(Ze,RRo),M(K2,Ze,null),b(f,sOe,u),b(f,Wi,u),e(Wi,Z2),e(Z2,Rge),M(TA,Rge,null),e(Wi,PRo),e(Wi,Pge),e(Pge,BRo),b(f,lOe,u),b(f,Ro,u),M(MA,Ro,null),e(Ro,IRo),e(Ro,Hi),e(Hi,NRo),e(Hi,EO),e(EO,qRo),e(Hi,jRo),e(Hi,CO),e(CO,DRo),e(Hi,GRo),e(Ro,ORo),e(Ro,EA),e(EA,VRo),e(EA,Bge),e(Bge,XRo),e(EA,zRo),e(Ro,QRo),e(Ro,dt),M(CA,dt,null),e(dt,WRo),e(dt,Ige),e(Ige,HRo),e(dt,URo),e(dt,Ui),e(Ui,JRo),e(Ui,Nge),e(Nge,YRo),e(Ui,KRo),e(Ui,wO),e(wO,ZRo),e(Ui,ePo),e(dt,oPo),M(eb,dt,null),e(Ro,rPo),e(Ro,eo),M(wA,eo,null),e(eo,tPo),e(eo,qge),e(qge,aPo),e(eo,nPo),e(eo,Na),e(Na,sPo),e(Na,jge),e(jge,lPo),e(Na,iPo),e(Na,Dge),e(Dge,dPo),e(Na,cPo),e(Na,Gge),e(Gge,fPo),e(Na,mPo),e(eo,gPo),e(eo,pe),e(pe,ob),e(ob,Oge),e(Oge,hPo),e(ob,pPo),e(ob,AO),e(AO,_Po),e(ob,uPo),e(pe,bPo),e(pe,rb),e(rb,Vge),e(Vge,vPo),e(rb,FPo),e(rb,LO),e(LO,TPo),e(rb,MPo),e(pe,EPo),e(pe,tb),e(tb,Xge),e(Xge,CPo),e(tb,wPo),e(tb,yO),e(yO,APo),e(tb,LPo),e(pe,yPo),e(pe,ab),e(ab,zge),e(zge,xPo),e(ab,$Po),e(ab,xO),e(xO,kPo),e(ab,SPo),e(pe,RPo),e(pe,nb),e(nb,Qge),e(Qge,PPo),e(nb,BPo),e(nb,$O),e($O,IPo),e(nb,NPo),e(pe,qPo),e(pe,sb),e(sb,Wge),e(Wge,jPo),e(sb,DPo),e(sb,kO),e(kO,GPo),e(sb,OPo),e(pe,VPo),e(pe,lb),e(lb,Hge),e(Hge,XPo),e(lb,zPo),e(lb,SO),e(SO,QPo),e(lb,WPo),e(pe,HPo),e(pe,ib),e(ib,Uge),e(Uge,UPo),e(ib,JPo),e(ib,RO),e(RO,YPo),e(ib,KPo),e(pe,ZPo),e(pe,db),e(db,Jge),e(Jge,eBo),e(db,oBo),e(db,PO),e(PO,rBo),e(db,tBo),e(pe,aBo),e(pe,cb),e(cb,Yge),e(Yge,nBo),e(cb,sBo),e(cb,BO),e(BO,lBo),e(cb,iBo),e(pe,dBo),e(pe,fb),e(fb,Kge),e(Kge,cBo),e(fb,fBo),e(fb,IO),e(IO,mBo),e(fb,gBo),e(pe,hBo),e(pe,mb),e(mb,Zge),e(Zge,pBo),e(mb,_Bo),e(mb,NO),e(NO,uBo),e(mb,bBo),e(pe,vBo),e(pe,gb),e(gb,ehe),e(ehe,FBo),e(gb,TBo),e(gb,qO),e(qO,MBo),e(gb,EBo),e(pe,CBo),e(pe,hb),e(hb,ohe),e(ohe,wBo),e(hb,ABo),e(hb,jO),e(jO,LBo),e(hb,yBo),e(pe,xBo),e(pe,pb),e(pb,rhe),e(rhe,$Bo),e(pb,kBo),e(pb,DO),e(DO,SBo),e(pb,RBo),e(pe,PBo),e(pe,_b),e(_b,the),e(the,BBo),e(_b,IBo),e(_b,GO),e(GO,NBo),e(_b,qBo),e(pe,jBo),e(pe,ub),e(ub,ahe),e(ahe,DBo),e(ub,GBo),e(ub,OO),e(OO,OBo),e(ub,VBo),e(eo,XBo),e(eo,bb),e(bb,zBo),e(bb,nhe),e(nhe,QBo),e(bb,WBo),e(bb,she),e(she,HBo),e(eo,UBo),M(vb,eo,null),b(f,iOe,u),b(f,Ji,u),e(Ji,Fb),e(Fb,lhe),M(AA,lhe,null),e(Ji,JBo),e(Ji,ihe),e(ihe,YBo),b(f,dOe,u),b(f,Po,u),M(LA,Po,null),e(Po,KBo),e(Po,Yi),e(Yi,ZBo),e(Yi,VO),e(VO,eIo),e(Yi,oIo),e(Yi,XO),e(XO,rIo),e(Yi,tIo),e(Po,aIo),e(Po,yA),e(yA,nIo),e(yA,dhe),e(dhe,sIo),e(yA,lIo),e(Po,iIo),e(Po,ct),M(xA,ct,null),e(ct,dIo),e(ct,che),e(che,cIo),e(ct,fIo),e(ct,Ki),e(Ki,mIo),e(Ki,fhe),e(fhe,gIo),e(Ki,hIo),e(Ki,zO),e(zO,pIo),e(Ki,_Io),e(ct,uIo),M(Tb,ct,null),e(Po,bIo),e(Po,oo),M($A,oo,null),e(oo,vIo),e(oo,mhe),e(mhe,FIo),e(oo,TIo),e(oo,qa),e(qa,MIo),e(qa,ghe),e(ghe,EIo),e(qa,CIo),e(qa,hhe),e(hhe,wIo),e(qa,AIo),e(qa,phe),e(phe,LIo),e(qa,yIo),e(oo,xIo),e(oo,N),e(N,Mb),e(Mb,_he),e(_he,$Io),e(Mb,kIo),e(Mb,QO),e(QO,SIo),e(Mb,RIo),e(N,PIo),e(N,Eb),e(Eb,uhe),e(uhe,BIo),e(Eb,IIo),e(Eb,WO),e(WO,NIo),e(Eb,qIo),e(N,jIo),e(N,Cb),e(Cb,bhe),e(bhe,DIo),e(Cb,GIo),e(Cb,HO),e(HO,OIo),e(Cb,VIo),e(N,XIo),e(N,wb),e(wb,vhe),e(vhe,zIo),e(wb,QIo),e(wb,UO),e(UO,WIo),e(wb,HIo),e(N,UIo),e(N,Ab),e(Ab,Fhe),e(Fhe,JIo),e(Ab,YIo),e(Ab,JO),e(JO,KIo),e(Ab,ZIo),e(N,eNo),e(N,Lb),e(Lb,The),e(The,oNo),e(Lb,rNo),e(Lb,YO),e(YO,tNo),e(Lb,aNo),e(N,nNo),e(N,yb),e(yb,Mhe),e(Mhe,sNo),e(yb,lNo),e(yb,KO),e(KO,iNo),e(yb,dNo),e(N,cNo),e(N,xb),e(xb,Ehe),e(Ehe,fNo),e(xb,mNo),e(xb,ZO),e(ZO,gNo),e(xb,hNo),e(N,pNo),e(N,$b),e($b,Che),e(Che,_No),e($b,uNo),e($b,eV),e(eV,bNo),e($b,vNo),e(N,FNo),e(N,kb),e(kb,whe),e(whe,TNo),e(kb,MNo),e(kb,oV),e(oV,ENo),e(kb,CNo),e(N,wNo),e(N,Sb),e(Sb,Ahe),e(Ahe,ANo),e(Sb,LNo),e(Sb,rV),e(rV,yNo),e(Sb,xNo),e(N,$No),e(N,Rb),e(Rb,Lhe),e(Lhe,kNo),e(Rb,SNo),e(Rb,tV),e(tV,RNo),e(Rb,PNo),e(N,BNo),e(N,Pb),e(Pb,yhe),e(yhe,INo),e(Pb,NNo),e(Pb,aV),e(aV,qNo),e(Pb,jNo),e(N,DNo),e(N,Bb),e(Bb,xhe),e(xhe,GNo),e(Bb,ONo),e(Bb,nV),e(nV,VNo),e(Bb,XNo),e(N,zNo),e(N,Ib),e(Ib,$he),e($he,QNo),e(Ib,WNo),e(Ib,sV),e(sV,HNo),e(Ib,UNo),e(N,JNo),e(N,Nb),e(Nb,khe),e(khe,YNo),e(Nb,KNo),e(Nb,lV),e(lV,ZNo),e(Nb,eqo),e(N,oqo),e(N,qb),e(qb,She),e(She,rqo),e(qb,tqo),e(qb,iV),e(iV,aqo),e(qb,nqo),e(N,sqo),e(N,jb),e(jb,Rhe),e(Rhe,lqo),e(jb,iqo),e(jb,dV),e(dV,dqo),e(jb,cqo),e(N,fqo),e(N,Db),e(Db,Phe),e(Phe,mqo),e(Db,gqo),e(Db,cV),e(cV,hqo),e(Db,pqo),e(N,_qo),e(N,Gb),e(Gb,Bhe),e(Bhe,uqo),e(Gb,bqo),e(Gb,fV),e(fV,vqo),e(Gb,Fqo),e(N,Tqo),e(N,Ob),e(Ob,Ihe),e(Ihe,Mqo),e(Ob,Eqo),e(Ob,mV),e(mV,Cqo),e(Ob,wqo),e(N,Aqo),e(N,Vb),e(Vb,Nhe),e(Nhe,Lqo),e(Vb,yqo),e(Vb,gV),e(gV,xqo),e(Vb,$qo),e(N,kqo),e(N,Xb),e(Xb,qhe),e(qhe,Sqo),e(Xb,Rqo),e(Xb,hV),e(hV,Pqo),e(Xb,Bqo),e(N,Iqo),e(N,zb),e(zb,jhe),e(jhe,Nqo),e(zb,qqo),e(zb,pV),e(pV,jqo),e(zb,Dqo),e(N,Gqo),e(N,Qb),e(Qb,Dhe),e(Dhe,Oqo),e(Qb,Vqo),e(Qb,_V),e(_V,Xqo),e(Qb,zqo),e(N,Qqo),e(N,Wb),e(Wb,Ghe),e(Ghe,Wqo),e(Wb,Hqo),e(Wb,uV),e(uV,Uqo),e(Wb,Jqo),e(N,Yqo),e(N,Hb),e(Hb,Ohe),e(Ohe,Kqo),e(Hb,Zqo),e(Hb,bV),e(bV,ejo),e(Hb,ojo),e(N,rjo),e(N,Ub),e(Ub,Vhe),e(Vhe,tjo),e(Ub,ajo),e(Ub,vV),e(vV,njo),e(Ub,sjo),e(N,ljo),e(N,Jb),e(Jb,Xhe),e(Xhe,ijo),e(Jb,djo),e(Jb,FV),e(FV,cjo),e(Jb,fjo),e(N,mjo),e(N,Yb),e(Yb,zhe),e(zhe,gjo),e(Yb,hjo),e(Yb,TV),e(TV,pjo),e(Yb,_jo),e(N,ujo),e(N,Kb),e(Kb,Qhe),e(Qhe,bjo),e(Kb,vjo),e(Kb,MV),e(MV,Fjo),e(Kb,Tjo),e(N,Mjo),e(N,Zb),e(Zb,Whe),e(Whe,Ejo),e(Zb,Cjo),e(Zb,EV),e(EV,wjo),e(Zb,Ajo),e(N,Ljo),e(N,ev),e(ev,Hhe),e(Hhe,yjo),e(ev,xjo),e(ev,CV),e(CV,$jo),e(ev,kjo),e(N,Sjo),e(N,ov),e(ov,Uhe),e(Uhe,Rjo),e(ov,Pjo),e(ov,wV),e(wV,Bjo),e(ov,Ijo),e(N,Njo),e(N,rv),e(rv,Jhe),e(Jhe,qjo),e(rv,jjo),e(rv,AV),e(AV,Djo),e(rv,Gjo),e(N,Ojo),e(N,tv),e(tv,Yhe),e(Yhe,Vjo),e(tv,Xjo),e(tv,LV),e(LV,zjo),e(tv,Qjo),e(N,Wjo),e(N,av),e(av,Khe),e(Khe,Hjo),e(av,Ujo),e(av,yV),e(yV,Jjo),e(av,Yjo),e(N,Kjo),e(N,nv),e(nv,Zhe),e(Zhe,Zjo),e(nv,eDo),e(nv,xV),e(xV,oDo),e(nv,rDo),e(N,tDo),e(N,sv),e(sv,epe),e(epe,aDo),e(sv,nDo),e(sv,$V),e($V,sDo),e(sv,lDo),e(N,iDo),e(N,lv),e(lv,ope),e(ope,dDo),e(lv,cDo),e(lv,kV),e(kV,fDo),e(lv,mDo),e(N,gDo),e(N,iv),e(iv,rpe),e(rpe,hDo),e(iv,pDo),e(iv,SV),e(SV,_Do),e(iv,uDo),e(N,bDo),e(N,dv),e(dv,tpe),e(tpe,vDo),e(dv,FDo),e(dv,RV),e(RV,TDo),e(dv,MDo),e(N,EDo),e(N,cv),e(cv,ape),e(ape,CDo),e(cv,wDo),e(cv,PV),e(PV,ADo),e(cv,LDo),e(N,yDo),e(N,fv),e(fv,npe),e(npe,xDo),e(fv,$Do),e(fv,BV),e(BV,kDo),e(fv,SDo),e(N,RDo),e(N,mv),e(mv,spe),e(spe,PDo),e(mv,BDo),e(mv,IV),e(IV,IDo),e(mv,NDo),e(N,qDo),e(N,gv),e(gv,lpe),e(lpe,jDo),e(gv,DDo),e(gv,NV),e(NV,GDo),e(gv,ODo),e(N,VDo),e(N,hv),e(hv,ipe),e(ipe,XDo),e(hv,zDo),e(hv,qV),e(qV,QDo),e(hv,WDo),e(N,HDo),e(N,pv),e(pv,dpe),e(dpe,UDo),e(pv,JDo),e(pv,jV),e(jV,YDo),e(pv,KDo),e(N,ZDo),e(N,_v),e(_v,cpe),e(cpe,eGo),e(_v,oGo),e(_v,DV),e(DV,rGo),e(_v,tGo),e(oo,aGo),e(oo,uv),e(uv,nGo),e(uv,fpe),e(fpe,sGo),e(uv,lGo),e(uv,mpe),e(mpe,iGo),e(oo,dGo),M(bv,oo,null),b(f,cOe,u),b(f,Zi,u),e(Zi,vv),e(vv,gpe),M(kA,gpe,null),e(Zi,cGo),e(Zi,hpe),e(hpe,fGo),b(f,fOe,u),b(f,Bo,u),M(SA,Bo,null),e(Bo,mGo),e(Bo,ed),e(ed,gGo),e(ed,GV),e(GV,hGo),e(ed,pGo),e(ed,OV),e(OV,_Go),e(ed,uGo),e(Bo,bGo),e(Bo,RA),e(RA,vGo),e(RA,ppe),e(ppe,FGo),e(RA,TGo),e(Bo,MGo),e(Bo,ft),M(PA,ft,null),e(ft,EGo),e(ft,_pe),e(_pe,CGo),e(ft,wGo),e(ft,od),e(od,AGo),e(od,upe),e(upe,LGo),e(od,yGo),e(od,VV),e(VV,xGo),e(od,$Go),e(ft,kGo),M(Fv,ft,null),e(Bo,SGo),e(Bo,ro),M(BA,ro,null),e(ro,RGo),e(ro,bpe),e(bpe,PGo),e(ro,BGo),e(ro,ja),e(ja,IGo),e(ja,vpe),e(vpe,NGo),e(ja,qGo),e(ja,Fpe),e(Fpe,jGo),e(ja,DGo),e(ja,Tpe),e(Tpe,GGo),e(ja,OGo),e(ro,VGo),e(ro,Z),e(Z,Tv),e(Tv,Mpe),e(Mpe,XGo),e(Tv,zGo),e(Tv,XV),e(XV,QGo),e(Tv,WGo),e(Z,HGo),e(Z,Mv),e(Mv,Epe),e(Epe,UGo),e(Mv,JGo),e(Mv,zV),e(zV,YGo),e(Mv,KGo),e(Z,ZGo),e(Z,Ev),e(Ev,Cpe),e(Cpe,eOo),e(Ev,oOo),e(Ev,QV),e(QV,rOo),e(Ev,tOo),e(Z,aOo),e(Z,Cv),e(Cv,wpe),e(wpe,nOo),e(Cv,sOo),e(Cv,WV),e(WV,lOo),e(Cv,iOo),e(Z,dOo),e(Z,wv),e(wv,Ape),e(Ape,cOo),e(wv,fOo),e(wv,HV),e(HV,mOo),e(wv,gOo),e(Z,hOo),e(Z,Av),e(Av,Lpe),e(Lpe,pOo),e(Av,_Oo),e(Av,UV),e(UV,uOo),e(Av,bOo),e(Z,vOo),e(Z,Lv),e(Lv,ype),e(ype,FOo),e(Lv,TOo),e(Lv,JV),e(JV,MOo),e(Lv,EOo),e(Z,COo),e(Z,yv),e(yv,xpe),e(xpe,wOo),e(yv,AOo),e(yv,YV),e(YV,LOo),e(yv,yOo),e(Z,xOo),e(Z,xv),e(xv,$pe),e($pe,$Oo),e(xv,kOo),e(xv,KV),e(KV,SOo),e(xv,ROo),e(Z,POo),e(Z,$v),e($v,kpe),e(kpe,BOo),e($v,IOo),e($v,ZV),e(ZV,NOo),e($v,qOo),e(Z,jOo),e(Z,kv),e(kv,Spe),e(Spe,DOo),e(kv,GOo),e(kv,eX),e(eX,OOo),e(kv,VOo),e(Z,XOo),e(Z,Sv),e(Sv,Rpe),e(Rpe,zOo),e(Sv,QOo),e(Sv,oX),e(oX,WOo),e(Sv,HOo),e(Z,UOo),e(Z,Rv),e(Rv,Ppe),e(Ppe,JOo),e(Rv,YOo),e(Rv,rX),e(rX,KOo),e(Rv,ZOo),e(Z,eVo),e(Z,Pv),e(Pv,Bpe),e(Bpe,oVo),e(Pv,rVo),e(Pv,tX),e(tX,tVo),e(Pv,aVo),e(Z,nVo),e(Z,Bv),e(Bv,Ipe),e(Ipe,sVo),e(Bv,lVo),e(Bv,aX),e(aX,iVo),e(Bv,dVo),e(Z,cVo),e(Z,Iv),e(Iv,Npe),e(Npe,fVo),e(Iv,mVo),e(Iv,nX),e(nX,gVo),e(Iv,hVo),e(Z,pVo),e(Z,Nv),e(Nv,qpe),e(qpe,_Vo),e(Nv,uVo),e(Nv,sX),e(sX,bVo),e(Nv,vVo),e(Z,FVo),e(Z,qv),e(qv,jpe),e(jpe,TVo),e(qv,MVo),e(qv,lX),e(lX,EVo),e(qv,CVo),e(Z,wVo),e(Z,jv),e(jv,Dpe),e(Dpe,AVo),e(jv,LVo),e(jv,iX),e(iX,yVo),e(jv,xVo),e(Z,$Vo),e(Z,Dv),e(Dv,Gpe),e(Gpe,kVo),e(Dv,SVo),e(Dv,dX),e(dX,RVo),e(Dv,PVo),e(Z,BVo),e(Z,Gv),e(Gv,Ope),e(Ope,IVo),e(Gv,NVo),e(Gv,cX),e(cX,qVo),e(Gv,jVo),e(Z,DVo),e(Z,Ov),e(Ov,Vpe),e(Vpe,GVo),e(Ov,OVo),e(Ov,fX),e(fX,VVo),e(Ov,XVo),e(Z,zVo),e(Z,Vv),e(Vv,Xpe),e(Xpe,QVo),e(Vv,WVo),e(Vv,mX),e(mX,HVo),e(Vv,UVo),e(Z,JVo),e(Z,Xv),e(Xv,zpe),e(zpe,YVo),e(Xv,KVo),e(Xv,gX),e(gX,ZVo),e(Xv,eXo),e(Z,oXo),e(Z,zv),e(zv,Qpe),e(Qpe,rXo),e(zv,tXo),e(zv,hX),e(hX,aXo),e(zv,nXo),e(Z,sXo),e(Z,Qv),e(Qv,Wpe),e(Wpe,lXo),e(Qv,iXo),e(Qv,pX),e(pX,dXo),e(Qv,cXo),e(Z,fXo),e(Z,Wv),e(Wv,Hpe),e(Hpe,mXo),e(Wv,gXo),e(Wv,_X),e(_X,hXo),e(Wv,pXo),e(Z,_Xo),e(Z,Hv),e(Hv,Upe),e(Upe,uXo),e(Hv,bXo),e(Hv,uX),e(uX,vXo),e(Hv,FXo),e(Z,TXo),e(Z,Uv),e(Uv,Jpe),e(Jpe,MXo),e(Uv,EXo),e(Uv,bX),e(bX,CXo),e(Uv,wXo),e(Z,AXo),e(Z,Jv),e(Jv,Ype),e(Ype,LXo),e(Jv,yXo),e(Jv,vX),e(vX,xXo),e(Jv,$Xo),e(ro,kXo),e(ro,Yv),e(Yv,SXo),e(Yv,Kpe),e(Kpe,RXo),e(Yv,PXo),e(Yv,Zpe),e(Zpe,BXo),e(ro,IXo),M(Kv,ro,null),b(f,mOe,u),b(f,rd,u),e(rd,Zv),e(Zv,e_e),M(IA,e_e,null),e(rd,NXo),e(rd,o_e),e(o_e,qXo),b(f,gOe,u),b(f,Io,u),M(NA,Io,null),e(Io,jXo),e(Io,td),e(td,DXo),e(td,FX),e(FX,GXo),e(td,OXo),e(td,TX),e(TX,VXo),e(td,XXo),e(Io,zXo),e(Io,qA),e(qA,QXo),e(qA,r_e),e(r_e,WXo),e(qA,HXo),e(Io,UXo),e(Io,mt),M(jA,mt,null),e(mt,JXo),e(mt,t_e),e(t_e,YXo),e(mt,KXo),e(mt,ad),e(ad,ZXo),e(ad,a_e),e(a_e,ezo),e(ad,ozo),e(ad,MX),e(MX,rzo),e(ad,tzo),e(mt,azo),M(eF,mt,null),e(Io,nzo),e(Io,to),M(DA,to,null),e(to,szo),e(to,n_e),e(n_e,lzo),e(to,izo),e(to,Da),e(Da,dzo),e(Da,s_e),e(s_e,czo),e(Da,fzo),e(Da,l_e),e(l_e,mzo),e(Da,gzo),e(Da,i_e),e(i_e,hzo),e(Da,pzo),e(to,_zo),e(to,No),e(No,oF),e(oF,d_e),e(d_e,uzo),e(oF,bzo),e(oF,EX),e(EX,vzo),e(oF,Fzo),e(No,Tzo),e(No,rF),e(rF,c_e),e(c_e,Mzo),e(rF,Ezo),e(rF,CX),e(CX,Czo),e(rF,wzo),e(No,Azo),e(No,tF),e(tF,f_e),e(f_e,Lzo),e(tF,yzo),e(tF,wX),e(wX,xzo),e(tF,$zo),e(No,kzo),e(No,aF),e(aF,m_e),e(m_e,Szo),e(aF,Rzo),e(aF,AX),e(AX,Pzo),e(aF,Bzo),e(No,Izo),e(No,nF),e(nF,g_e),e(g_e,Nzo),e(nF,qzo),e(nF,LX),e(LX,jzo),e(nF,Dzo),e(No,Gzo),e(No,sF),e(sF,h_e),e(h_e,Ozo),e(sF,Vzo),e(sF,yX),e(yX,Xzo),e(sF,zzo),e(to,Qzo),e(to,lF),e(lF,Wzo),e(lF,p_e),e(p_e,Hzo),e(lF,Uzo),e(lF,__e),e(__e,Jzo),e(to,Yzo),M(iF,to,null),b(f,hOe,u),b(f,nd,u),e(nd,dF),e(dF,u_e),M(GA,u_e,null),e(nd,Kzo),e(nd,b_e),e(b_e,Zzo),b(f,pOe,u),b(f,qo,u),M(OA,qo,null),e(qo,eQo),e(qo,sd),e(sd,oQo),e(sd,xX),e(xX,rQo),e(sd,tQo),e(sd,$X),e($X,aQo),e(sd,nQo),e(qo,sQo),e(qo,VA),e(VA,lQo),e(VA,v_e),e(v_e,iQo),e(VA,dQo),e(qo,cQo),e(qo,gt),M(XA,gt,null),e(gt,fQo),e(gt,F_e),e(F_e,mQo),e(gt,gQo),e(gt,ld),e(ld,hQo),e(ld,T_e),e(T_e,pQo),e(ld,_Qo),e(ld,kX),e(kX,uQo),e(ld,bQo),e(gt,vQo),M(cF,gt,null),e(qo,FQo),e(qo,ao),M(zA,ao,null),e(ao,TQo),e(ao,M_e),e(M_e,MQo),e(ao,EQo),e(ao,Ga),e(Ga,CQo),e(Ga,E_e),e(E_e,wQo),e(Ga,AQo),e(Ga,C_e),e(C_e,LQo),e(Ga,yQo),e(Ga,w_e),e(w_e,xQo),e(Ga,$Qo),e(ao,kQo),e(ao,H),e(H,fF),e(fF,A_e),e(A_e,SQo),e(fF,RQo),e(fF,SX),e(SX,PQo),e(fF,BQo),e(H,IQo),e(H,mF),e(mF,L_e),e(L_e,NQo),e(mF,qQo),e(mF,RX),e(RX,jQo),e(mF,DQo),e(H,GQo),e(H,gF),e(gF,y_e),e(y_e,OQo),e(gF,VQo),e(gF,PX),e(PX,XQo),e(gF,zQo),e(H,QQo),e(H,hF),e(hF,x_e),e(x_e,WQo),e(hF,HQo),e(hF,BX),e(BX,UQo),e(hF,JQo),e(H,YQo),e(H,pF),e(pF,$_e),e($_e,KQo),e(pF,ZQo),e(pF,IX),e(IX,eWo),e(pF,oWo),e(H,rWo),e(H,_F),e(_F,k_e),e(k_e,tWo),e(_F,aWo),e(_F,NX),e(NX,nWo),e(_F,sWo),e(H,lWo),e(H,uF),e(uF,S_e),e(S_e,iWo),e(uF,dWo),e(uF,qX),e(qX,cWo),e(uF,fWo),e(H,mWo),e(H,bF),e(bF,R_e),e(R_e,gWo),e(bF,hWo),e(bF,jX),e(jX,pWo),e(bF,_Wo),e(H,uWo),e(H,vF),e(vF,P_e),e(P_e,bWo),e(vF,vWo),e(vF,DX),e(DX,FWo),e(vF,TWo),e(H,MWo),e(H,FF),e(FF,B_e),e(B_e,EWo),e(FF,CWo),e(FF,GX),e(GX,wWo),e(FF,AWo),e(H,LWo),e(H,TF),e(TF,I_e),e(I_e,yWo),e(TF,xWo),e(TF,OX),e(OX,$Wo),e(TF,kWo),e(H,SWo),e(H,MF),e(MF,N_e),e(N_e,RWo),e(MF,PWo),e(MF,VX),e(VX,BWo),e(MF,IWo),e(H,NWo),e(H,EF),e(EF,q_e),e(q_e,qWo),e(EF,jWo),e(EF,XX),e(XX,DWo),e(EF,GWo),e(H,OWo),e(H,CF),e(CF,j_e),e(j_e,VWo),e(CF,XWo),e(CF,zX),e(zX,zWo),e(CF,QWo),e(H,WWo),e(H,wF),e(wF,D_e),e(D_e,HWo),e(wF,UWo),e(wF,QX),e(QX,JWo),e(wF,YWo),e(H,KWo),e(H,AF),e(AF,G_e),e(G_e,ZWo),e(AF,eHo),e(AF,WX),e(WX,oHo),e(AF,rHo),e(H,tHo),e(H,LF),e(LF,O_e),e(O_e,aHo),e(LF,nHo),e(LF,HX),e(HX,sHo),e(LF,lHo),e(H,iHo),e(H,yF),e(yF,V_e),e(V_e,dHo),e(yF,cHo),e(yF,UX),e(UX,fHo),e(yF,mHo),e(H,gHo),e(H,xF),e(xF,X_e),e(X_e,hHo),e(xF,pHo),e(xF,JX),e(JX,_Ho),e(xF,uHo),e(H,bHo),e(H,$F),e($F,z_e),e(z_e,vHo),e($F,FHo),e($F,YX),e(YX,THo),e($F,MHo),e(H,EHo),e(H,kF),e(kF,Q_e),e(Q_e,CHo),e(kF,wHo),e(kF,KX),e(KX,AHo),e(kF,LHo),e(H,yHo),e(H,SF),e(SF,W_e),e(W_e,xHo),e(SF,$Ho),e(SF,ZX),e(ZX,kHo),e(SF,SHo),e(H,RHo),e(H,RF),e(RF,H_e),e(H_e,PHo),e(RF,BHo),e(RF,ez),e(ez,IHo),e(RF,NHo),e(H,qHo),e(H,PF),e(PF,U_e),e(U_e,jHo),e(PF,DHo),e(PF,oz),e(oz,GHo),e(PF,OHo),e(H,VHo),e(H,BF),e(BF,J_e),e(J_e,XHo),e(BF,zHo),e(BF,rz),e(rz,QHo),e(BF,WHo),e(H,HHo),e(H,IF),e(IF,Y_e),e(Y_e,UHo),e(IF,JHo),e(IF,tz),e(tz,YHo),e(IF,KHo),e(H,ZHo),e(H,NF),e(NF,K_e),e(K_e,eUo),e(NF,oUo),e(NF,az),e(az,rUo),e(NF,tUo),e(H,aUo),e(H,qF),e(qF,Z_e),e(Z_e,nUo),e(qF,sUo),e(qF,nz),e(nz,lUo),e(qF,iUo),e(H,dUo),e(H,jF),e(jF,eue),e(eue,cUo),e(jF,fUo),e(jF,sz),e(sz,mUo),e(jF,gUo),e(H,hUo),e(H,DF),e(DF,oue),e(oue,pUo),e(DF,_Uo),e(DF,lz),e(lz,uUo),e(DF,bUo),e(H,vUo),e(H,GF),e(GF,rue),e(rue,FUo),e(GF,TUo),e(GF,iz),e(iz,MUo),e(GF,EUo),e(H,CUo),e(H,OF),e(OF,tue),e(tue,wUo),e(OF,AUo),e(OF,dz),e(dz,LUo),e(OF,yUo),e(H,xUo),e(H,VF),e(VF,aue),e(aue,$Uo),e(VF,kUo),e(VF,cz),e(cz,SUo),e(VF,RUo),e(H,PUo),e(H,XF),e(XF,nue),e(nue,BUo),e(XF,IUo),e(XF,fz),e(fz,NUo),e(XF,qUo),e(H,jUo),e(H,zF),e(zF,sue),e(sue,DUo),e(zF,GUo),e(zF,mz),e(mz,OUo),e(zF,VUo),e(H,XUo),e(H,QF),e(QF,lue),e(lue,zUo),e(QF,QUo),e(QF,gz),e(gz,WUo),e(QF,HUo),e(ao,UUo),e(ao,WF),e(WF,JUo),e(WF,iue),e(iue,YUo),e(WF,KUo),e(WF,due),e(due,ZUo),e(ao,eJo),M(HF,ao,null),b(f,_Oe,u),b(f,id,u),e(id,UF),e(UF,cue),M(QA,cue,null),e(id,oJo),e(id,fue),e(fue,rJo),b(f,uOe,u),b(f,jo,u),M(WA,jo,null),e(jo,tJo),e(jo,dd),e(dd,aJo),e(dd,hz),e(hz,nJo),e(dd,sJo),e(dd,pz),e(pz,lJo),e(dd,iJo),e(jo,dJo),e(jo,HA),e(HA,cJo),e(HA,mue),e(mue,fJo),e(HA,mJo),e(jo,gJo),e(jo,ht),M(UA,ht,null),e(ht,hJo),e(ht,gue),e(gue,pJo),e(ht,_Jo),e(ht,cd),e(cd,uJo),e(cd,hue),e(hue,bJo),e(cd,vJo),e(cd,_z),e(_z,FJo),e(cd,TJo),e(ht,MJo),M(JF,ht,null),e(jo,EJo),e(jo,no),M(JA,no,null),e(no,CJo),e(no,pue),e(pue,wJo),e(no,AJo),e(no,Oa),e(Oa,LJo),e(Oa,_ue),e(_ue,yJo),e(Oa,xJo),e(Oa,uue),e(uue,$Jo),e(Oa,kJo),e(Oa,bue),e(bue,SJo),e(Oa,RJo),e(no,PJo),e(no,V),e(V,YF),e(YF,vue),e(vue,BJo),e(YF,IJo),e(YF,uz),e(uz,NJo),e(YF,qJo),e(V,jJo),e(V,KF),e(KF,Fue),e(Fue,DJo),e(KF,GJo),e(KF,bz),e(bz,OJo),e(KF,VJo),e(V,XJo),e(V,ZF),e(ZF,Tue),e(Tue,zJo),e(ZF,QJo),e(ZF,vz),e(vz,WJo),e(ZF,HJo),e(V,UJo),e(V,e6),e(e6,Mue),e(Mue,JJo),e(e6,YJo),e(e6,Fz),e(Fz,KJo),e(e6,ZJo),e(V,eYo),e(V,o6),e(o6,Eue),e(Eue,oYo),e(o6,rYo),e(o6,Tz),e(Tz,tYo),e(o6,aYo),e(V,nYo),e(V,r6),e(r6,Cue),e(Cue,sYo),e(r6,lYo),e(r6,Mz),e(Mz,iYo),e(r6,dYo),e(V,cYo),e(V,t6),e(t6,wue),e(wue,fYo),e(t6,mYo),e(t6,Ez),e(Ez,gYo),e(t6,hYo),e(V,pYo),e(V,a6),e(a6,Aue),e(Aue,_Yo),e(a6,uYo),e(a6,Cz),e(Cz,bYo),e(a6,vYo),e(V,FYo),e(V,n6),e(n6,Lue),e(Lue,TYo),e(n6,MYo),e(n6,wz),e(wz,EYo),e(n6,CYo),e(V,wYo),e(V,s6),e(s6,yue),e(yue,AYo),e(s6,LYo),e(s6,Az),e(Az,yYo),e(s6,xYo),e(V,$Yo),e(V,l6),e(l6,xue),e(xue,kYo),e(l6,SYo),e(l6,Lz),e(Lz,RYo),e(l6,PYo),e(V,BYo),e(V,i6),e(i6,$ue),e($ue,IYo),e(i6,NYo),e(i6,yz),e(yz,qYo),e(i6,jYo),e(V,DYo),e(V,d6),e(d6,kue),e(kue,GYo),e(d6,OYo),e(d6,xz),e(xz,VYo),e(d6,XYo),e(V,zYo),e(V,c6),e(c6,Sue),e(Sue,QYo),e(c6,WYo),e(c6,$z),e($z,HYo),e(c6,UYo),e(V,JYo),e(V,f6),e(f6,Rue),e(Rue,YYo),e(f6,KYo),e(f6,kz),e(kz,ZYo),e(f6,eKo),e(V,oKo),e(V,m6),e(m6,Pue),e(Pue,rKo),e(m6,tKo),e(m6,Sz),e(Sz,aKo),e(m6,nKo),e(V,sKo),e(V,g6),e(g6,Bue),e(Bue,lKo),e(g6,iKo),e(g6,Rz),e(Rz,dKo),e(g6,cKo),e(V,fKo),e(V,h6),e(h6,Iue),e(Iue,mKo),e(h6,gKo),e(h6,Pz),e(Pz,hKo),e(h6,pKo),e(V,_Ko),e(V,p6),e(p6,Nue),e(Nue,uKo),e(p6,bKo),e(p6,Bz),e(Bz,vKo),e(p6,FKo),e(V,TKo),e(V,_6),e(_6,que),e(que,MKo),e(_6,EKo),e(_6,Iz),e(Iz,CKo),e(_6,wKo),e(V,AKo),e(V,u6),e(u6,jue),e(jue,LKo),e(u6,yKo),e(u6,Nz),e(Nz,xKo),e(u6,$Ko),e(V,kKo),e(V,b6),e(b6,Due),e(Due,SKo),e(b6,RKo),e(b6,qz),e(qz,PKo),e(b6,BKo),e(V,IKo),e(V,v6),e(v6,Gue),e(Gue,NKo),e(v6,qKo),e(v6,jz),e(jz,jKo),e(v6,DKo),e(V,GKo),e(V,F6),e(F6,Oue),e(Oue,OKo),e(F6,VKo),e(F6,Dz),e(Dz,XKo),e(F6,zKo),e(V,QKo),e(V,T6),e(T6,Vue),e(Vue,WKo),e(T6,HKo),e(T6,Gz),e(Gz,UKo),e(T6,JKo),e(V,YKo),e(V,M6),e(M6,Xue),e(Xue,KKo),e(M6,ZKo),e(M6,Oz),e(Oz,eZo),e(M6,oZo),e(V,rZo),e(V,E6),e(E6,zue),e(zue,tZo),e(E6,aZo),e(E6,Vz),e(Vz,nZo),e(E6,sZo),e(V,lZo),e(V,C6),e(C6,Que),e(Que,iZo),e(C6,dZo),e(C6,Xz),e(Xz,cZo),e(C6,fZo),e(V,mZo),e(V,w6),e(w6,Wue),e(Wue,gZo),e(w6,hZo),e(w6,zz),e(zz,pZo),e(w6,_Zo),e(V,uZo),e(V,A6),e(A6,Hue),e(Hue,bZo),e(A6,vZo),e(A6,Qz),e(Qz,FZo),e(A6,TZo),e(V,MZo),e(V,L6),e(L6,Uue),e(Uue,EZo),e(L6,CZo),e(L6,Wz),e(Wz,wZo),e(L6,AZo),e(V,LZo),e(V,y6),e(y6,Jue),e(Jue,yZo),e(y6,xZo),e(y6,Hz),e(Hz,$Zo),e(y6,kZo),e(V,SZo),e(V,x6),e(x6,Yue),e(Yue,RZo),e(x6,PZo),e(x6,Uz),e(Uz,BZo),e(x6,IZo),e(V,NZo),e(V,$6),e($6,Kue),e(Kue,qZo),e($6,jZo),e($6,Jz),e(Jz,DZo),e($6,GZo),e(V,OZo),e(V,k6),e(k6,Zue),e(Zue,VZo),e(k6,XZo),e(k6,Yz),e(Yz,zZo),e(k6,QZo),e(V,WZo),e(V,S6),e(S6,e1e),e(e1e,HZo),e(S6,UZo),e(S6,Kz),e(Kz,JZo),e(S6,YZo),e(V,KZo),e(V,R6),e(R6,o1e),e(o1e,ZZo),e(R6,eer),e(R6,Zz),e(Zz,oer),e(R6,rer),e(V,ter),e(V,P6),e(P6,r1e),e(r1e,aer),e(P6,ner),e(P6,eQ),e(eQ,ser),e(P6,ler),e(V,ier),e(V,B6),e(B6,t1e),e(t1e,der),e(B6,cer),e(B6,oQ),e(oQ,fer),e(B6,mer),e(V,ger),e(V,I6),e(I6,a1e),e(a1e,her),e(I6,per),e(I6,rQ),e(rQ,_er),e(I6,uer),e(V,ber),e(V,N6),e(N6,n1e),e(n1e,ver),e(N6,Fer),e(N6,tQ),e(tQ,Ter),e(N6,Mer),e(no,Eer),e(no,q6),e(q6,Cer),e(q6,s1e),e(s1e,wer),e(q6,Aer),e(q6,l1e),e(l1e,Ler),e(no,yer),M(j6,no,null),b(f,bOe,u),b(f,fd,u),e(fd,D6),e(D6,i1e),M(YA,i1e,null),e(fd,xer),e(fd,d1e),e(d1e,$er),b(f,vOe,u),b(f,Do,u),M(KA,Do,null),e(Do,ker),e(Do,md),e(md,Ser),e(md,aQ),e(aQ,Rer),e(md,Per),e(md,nQ),e(nQ,Ber),e(md,Ier),e(Do,Ner),e(Do,ZA),e(ZA,qer),e(ZA,c1e),e(c1e,jer),e(ZA,Der),e(Do,Ger),e(Do,pt),M(eL,pt,null),e(pt,Oer),e(pt,f1e),e(f1e,Ver),e(pt,Xer),e(pt,gd),e(gd,zer),e(gd,m1e),e(m1e,Qer),e(gd,Wer),e(gd,sQ),e(sQ,Her),e(gd,Uer),e(pt,Jer),M(G6,pt,null),e(Do,Yer),e(Do,so),M(oL,so,null),e(so,Ker),e(so,g1e),e(g1e,Zer),e(so,eor),e(so,Va),e(Va,oor),e(Va,h1e),e(h1e,ror),e(Va,tor),e(Va,p1e),e(p1e,aor),e(Va,nor),e(Va,_1e),e(_1e,sor),e(Va,lor),e(so,ior),e(so,u1e),e(u1e,O6),e(O6,b1e),e(b1e,dor),e(O6,cor),e(O6,lQ),e(lQ,mor),e(O6,gor),e(so,hor),e(so,V6),e(V6,por),e(V6,v1e),e(v1e,_or),e(V6,uor),e(V6,F1e),e(F1e,bor),e(so,vor),M(X6,so,null),b(f,FOe,u),b(f,hd,u),e(hd,z6),e(z6,T1e),M(rL,T1e,null),e(hd,For),e(hd,M1e),e(M1e,Tor),b(f,TOe,u),b(f,Go,u),M(tL,Go,null),e(Go,Mor),e(Go,pd),e(pd,Eor),e(pd,iQ),e(iQ,Cor),e(pd,wor),e(pd,dQ),e(dQ,Aor),e(pd,Lor),e(Go,yor),e(Go,aL),e(aL,xor),e(aL,E1e),e(E1e,$or),e(aL,kor),e(Go,Sor),e(Go,_t),M(nL,_t,null),e(_t,Ror),e(_t,C1e),e(C1e,Por),e(_t,Bor),e(_t,_d),e(_d,Ior),e(_d,w1e),e(w1e,Nor),e(_d,qor),e(_d,cQ),e(cQ,jor),e(_d,Dor),e(_t,Gor),M(Q6,_t,null),e(Go,Oor),e(Go,lo),M(sL,lo,null),e(lo,Vor),e(lo,A1e),e(A1e,Xor),e(lo,zor),e(lo,Xa),e(Xa,Qor),e(Xa,L1e),e(L1e,Wor),e(Xa,Hor),e(Xa,y1e),e(y1e,Uor),e(Xa,Jor),e(Xa,x1e),e(x1e,Yor),e(Xa,Kor),e(lo,Zor),e(lo,Fe),e(Fe,W6),e(W6,$1e),e($1e,err),e(W6,orr),e(W6,fQ),e(fQ,rrr),e(W6,trr),e(Fe,arr),e(Fe,H6),e(H6,k1e),e(k1e,nrr),e(H6,srr),e(H6,mQ),e(mQ,lrr),e(H6,irr),e(Fe,drr),e(Fe,U6),e(U6,S1e),e(S1e,crr),e(U6,frr),e(U6,gQ),e(gQ,mrr),e(U6,grr),e(Fe,hrr),e(Fe,J6),e(J6,R1e),e(R1e,prr),e(J6,_rr),e(J6,hQ),e(hQ,urr),e(J6,brr),e(Fe,vrr),e(Fe,Xs),e(Xs,P1e),e(P1e,Frr),e(Xs,Trr),e(Xs,pQ),e(pQ,Mrr),e(Xs,Err),e(Xs,_Q),e(_Q,Crr),e(Xs,wrr),e(Fe,Arr),e(Fe,Y6),e(Y6,B1e),e(B1e,Lrr),e(Y6,yrr),e(Y6,uQ),e(uQ,xrr),e(Y6,$rr),e(Fe,krr),e(Fe,zs),e(zs,I1e),e(I1e,Srr),e(zs,Rrr),e(zs,bQ),e(bQ,Prr),e(zs,Brr),e(zs,vQ),e(vQ,Irr),e(zs,Nrr),e(Fe,qrr),e(Fe,ut),e(ut,N1e),e(N1e,jrr),e(ut,Drr),e(ut,FQ),e(FQ,Grr),e(ut,Orr),e(ut,TQ),e(TQ,Vrr),e(ut,Xrr),e(ut,MQ),e(MQ,zrr),e(ut,Qrr),e(Fe,Wrr),e(Fe,K6),e(K6,q1e),e(q1e,Hrr),e(K6,Urr),e(K6,EQ),e(EQ,Jrr),e(K6,Yrr),e(Fe,Krr),e(Fe,Z6),e(Z6,j1e),e(j1e,Zrr),e(Z6,etr),e(Z6,CQ),e(CQ,otr),e(Z6,rtr),e(Fe,ttr),e(Fe,eT),e(eT,D1e),e(D1e,atr),e(eT,ntr),e(eT,wQ),e(wQ,str),e(eT,ltr),e(Fe,itr),e(Fe,oT),e(oT,G1e),e(G1e,dtr),e(oT,ctr),e(oT,AQ),e(AQ,ftr),e(oT,mtr),e(Fe,gtr),e(Fe,rT),e(rT,O1e),e(O1e,htr),e(rT,ptr),e(rT,LQ),e(LQ,_tr),e(rT,utr),e(Fe,btr),e(Fe,tT),e(tT,V1e),e(V1e,vtr),e(tT,Ftr),e(tT,yQ),e(yQ,Ttr),e(tT,Mtr),e(Fe,Etr),e(Fe,aT),e(aT,X1e),e(X1e,Ctr),e(aT,wtr),e(aT,xQ),e(xQ,Atr),e(aT,Ltr),e(lo,ytr),e(lo,nT),e(nT,xtr),e(nT,z1e),e(z1e,$tr),e(nT,ktr),e(nT,Q1e),e(Q1e,Str),e(lo,Rtr),M(sT,lo,null),b(f,MOe,u),b(f,ud,u),e(ud,lT),e(lT,W1e),M(lL,W1e,null),e(ud,Ptr),e(ud,H1e),e(H1e,Btr),b(f,EOe,u),b(f,Oo,u),M(iL,Oo,null),e(Oo,Itr),e(Oo,bd),e(bd,Ntr),e(bd,$Q),e($Q,qtr),e(bd,jtr),e(bd,kQ),e(kQ,Dtr),e(bd,Gtr),e(Oo,Otr),e(Oo,dL),e(dL,Vtr),e(dL,U1e),e(U1e,Xtr),e(dL,ztr),e(Oo,Qtr),e(Oo,bt),M(cL,bt,null),e(bt,Wtr),e(bt,J1e),e(J1e,Htr),e(bt,Utr),e(bt,vd),e(vd,Jtr),e(vd,Y1e),e(Y1e,Ytr),e(vd,Ktr),e(vd,SQ),e(SQ,Ztr),e(vd,ear),e(bt,oar),M(iT,bt,null),e(Oo,rar),e(Oo,io),M(fL,io,null),e(io,tar),e(io,K1e),e(K1e,aar),e(io,nar),e(io,za),e(za,sar),e(za,Z1e),e(Z1e,lar),e(za,iar),e(za,e2e),e(e2e,dar),e(za,car),e(za,o2e),e(o2e,far),e(za,mar),e(io,gar),e(io,r2e),e(r2e,dT),e(dT,t2e),e(t2e,har),e(dT,par),e(dT,RQ),e(RQ,_ar),e(dT,uar),e(io,bar),e(io,cT),e(cT,Far),e(cT,a2e),e(a2e,Tar),e(cT,Mar),e(cT,n2e),e(n2e,Ear),e(io,Car),M(fT,io,null),b(f,COe,u),b(f,Fd,u),e(Fd,mT),e(mT,s2e),M(mL,s2e,null),e(Fd,war),e(Fd,l2e),e(l2e,Aar),b(f,wOe,u),b(f,Vo,u),M(gL,Vo,null),e(Vo,Lar),e(Vo,Td),e(Td,yar),e(Td,PQ),e(PQ,xar),e(Td,$ar),e(Td,BQ),e(BQ,kar),e(Td,Sar),e(Vo,Rar),e(Vo,hL),e(hL,Par),e(hL,i2e),e(i2e,Bar),e(hL,Iar),e(Vo,Nar),e(Vo,vt),M(pL,vt,null),e(vt,qar),e(vt,d2e),e(d2e,jar),e(vt,Dar),e(vt,Md),e(Md,Gar),e(Md,c2e),e(c2e,Oar),e(Md,Var),e(Md,IQ),e(IQ,Xar),e(Md,zar),e(vt,Qar),M(gT,vt,null),e(Vo,War),e(Vo,co),M(_L,co,null),e(co,Har),e(co,f2e),e(f2e,Uar),e(co,Jar),e(co,Qa),e(Qa,Yar),e(Qa,m2e),e(m2e,Kar),e(Qa,Zar),e(Qa,g2e),e(g2e,enr),e(Qa,onr),e(Qa,h2e),e(h2e,rnr),e(Qa,tnr),e(co,anr),e(co,p2e),e(p2e,hT),e(hT,_2e),e(_2e,nnr),e(hT,snr),e(hT,NQ),e(NQ,lnr),e(hT,inr),e(co,dnr),e(co,pT),e(pT,cnr),e(pT,u2e),e(u2e,fnr),e(pT,mnr),e(pT,b2e),e(b2e,gnr),e(co,hnr),M(_T,co,null),b(f,AOe,u),b(f,Ed,u),e(Ed,uT),e(uT,v2e),M(uL,v2e,null),e(Ed,pnr),e(Ed,F2e),e(F2e,_nr),b(f,LOe,u),b(f,Xo,u),M(bL,Xo,null),e(Xo,unr),e(Xo,Cd),e(Cd,bnr),e(Cd,qQ),e(qQ,vnr),e(Cd,Fnr),e(Cd,jQ),e(jQ,Tnr),e(Cd,Mnr),e(Xo,Enr),e(Xo,vL),e(vL,Cnr),e(vL,T2e),e(T2e,wnr),e(vL,Anr),e(Xo,Lnr),e(Xo,Ft),M(FL,Ft,null),e(Ft,ynr),e(Ft,M2e),e(M2e,xnr),e(Ft,$nr),e(Ft,wd),e(wd,knr),e(wd,E2e),e(E2e,Snr),e(wd,Rnr),e(wd,DQ),e(DQ,Pnr),e(wd,Bnr),e(Ft,Inr),M(bT,Ft,null),e(Xo,Nnr),e(Xo,fo),M(TL,fo,null),e(fo,qnr),e(fo,C2e),e(C2e,jnr),e(fo,Dnr),e(fo,Wa),e(Wa,Gnr),e(Wa,w2e),e(w2e,Onr),e(Wa,Vnr),e(Wa,A2e),e(A2e,Xnr),e(Wa,znr),e(Wa,L2e),e(L2e,Qnr),e(Wa,Wnr),e(fo,Hnr),e(fo,Pe),e(Pe,vT),e(vT,y2e),e(y2e,Unr),e(vT,Jnr),e(vT,GQ),e(GQ,Ynr),e(vT,Knr),e(Pe,Znr),e(Pe,FT),e(FT,x2e),e(x2e,esr),e(FT,osr),e(FT,OQ),e(OQ,rsr),e(FT,tsr),e(Pe,asr),e(Pe,TT),e(TT,$2e),e($2e,nsr),e(TT,ssr),e(TT,VQ),e(VQ,lsr),e(TT,isr),e(Pe,dsr),e(Pe,MT),e(MT,k2e),e(k2e,csr),e(MT,fsr),e(MT,XQ),e(XQ,msr),e(MT,gsr),e(Pe,hsr),e(Pe,ET),e(ET,S2e),e(S2e,psr),e(ET,_sr),e(ET,zQ),e(zQ,usr),e(ET,bsr),e(Pe,vsr),e(Pe,CT),e(CT,R2e),e(R2e,Fsr),e(CT,Tsr),e(CT,QQ),e(QQ,Msr),e(CT,Esr),e(Pe,Csr),e(Pe,wT),e(wT,P2e),e(P2e,wsr),e(wT,Asr),e(wT,WQ),e(WQ,Lsr),e(wT,ysr),e(Pe,xsr),e(Pe,AT),e(AT,B2e),e(B2e,$sr),e(AT,ksr),e(AT,HQ),e(HQ,Ssr),e(AT,Rsr),e(Pe,Psr),e(Pe,LT),e(LT,I2e),e(I2e,Bsr),e(LT,Isr),e(LT,UQ),e(UQ,Nsr),e(LT,qsr),e(fo,jsr),e(fo,yT),e(yT,Dsr),e(yT,N2e),e(N2e,Gsr),e(yT,Osr),e(yT,q2e),e(q2e,Vsr),e(fo,Xsr),M(xT,fo,null),b(f,yOe,u),b(f,Ad,u),e(Ad,$T),e($T,j2e),M(ML,j2e,null),e(Ad,zsr),e(Ad,D2e),e(D2e,Qsr),b(f,xOe,u),b(f,zo,u),M(EL,zo,null),e(zo,Wsr),e(zo,Ld),e(Ld,Hsr),e(Ld,JQ),e(JQ,Usr),e(Ld,Jsr),e(Ld,YQ),e(YQ,Ysr),e(Ld,Ksr),e(zo,Zsr),e(zo,CL),e(CL,elr),e(CL,G2e),e(G2e,olr),e(CL,rlr),e(zo,tlr),e(zo,Tt),M(wL,Tt,null),e(Tt,alr),e(Tt,O2e),e(O2e,nlr),e(Tt,slr),e(Tt,yd),e(yd,llr),e(yd,V2e),e(V2e,ilr),e(yd,dlr),e(yd,KQ),e(KQ,clr),e(yd,flr),e(Tt,mlr),M(kT,Tt,null),e(zo,glr),e(zo,mo),M(AL,mo,null),e(mo,hlr),e(mo,X2e),e(X2e,plr),e(mo,_lr),e(mo,Ha),e(Ha,ulr),e(Ha,z2e),e(z2e,blr),e(Ha,vlr),e(Ha,Q2e),e(Q2e,Flr),e(Ha,Tlr),e(Ha,W2e),e(W2e,Mlr),e(Ha,Elr),e(mo,Clr),e(mo,et),e(et,ST),e(ST,H2e),e(H2e,wlr),e(ST,Alr),e(ST,ZQ),e(ZQ,Llr),e(ST,ylr),e(et,xlr),e(et,RT),e(RT,U2e),e(U2e,$lr),e(RT,klr),e(RT,eW),e(eW,Slr),e(RT,Rlr),e(et,Plr),e(et,PT),e(PT,J2e),e(J2e,Blr),e(PT,Ilr),e(PT,oW),e(oW,Nlr),e(PT,qlr),e(et,jlr),e(et,BT),e(BT,Y2e),e(Y2e,Dlr),e(BT,Glr),e(BT,rW),e(rW,Olr),e(BT,Vlr),e(et,Xlr),e(et,IT),e(IT,K2e),e(K2e,zlr),e(IT,Qlr),e(IT,tW),e(tW,Wlr),e(IT,Hlr),e(mo,Ulr),e(mo,NT),e(NT,Jlr),e(NT,Z2e),e(Z2e,Ylr),e(NT,Klr),e(NT,ebe),e(ebe,Zlr),e(mo,eir),M(qT,mo,null),b(f,$Oe,u),b(f,xd,u),e(xd,jT),e(jT,obe),M(LL,obe,null),e(xd,oir),e(xd,rbe),e(rbe,rir),b(f,kOe,u),b(f,Qo,u),M(yL,Qo,null),e(Qo,tir),e(Qo,$d),e($d,air),e($d,aW),e(aW,nir),e($d,sir),e($d,nW),e(nW,lir),e($d,iir),e(Qo,dir),e(Qo,xL),e(xL,cir),e(xL,tbe),e(tbe,fir),e(xL,mir),e(Qo,gir),e(Qo,Mt),M($L,Mt,null),e(Mt,hir),e(Mt,abe),e(abe,pir),e(Mt,_ir),e(Mt,kd),e(kd,uir),e(kd,nbe),e(nbe,bir),e(kd,vir),e(kd,sW),e(sW,Fir),e(kd,Tir),e(Mt,Mir),M(DT,Mt,null),e(Qo,Eir),e(Qo,go),M(kL,go,null),e(go,Cir),e(go,sbe),e(sbe,wir),e(go,Air),e(go,Ua),e(Ua,Lir),e(Ua,lbe),e(lbe,yir),e(Ua,xir),e(Ua,ibe),e(ibe,$ir),e(Ua,kir),e(Ua,dbe),e(dbe,Sir),e(Ua,Rir),e(go,Pir),e(go,Le),e(Le,GT),e(GT,cbe),e(cbe,Bir),e(GT,Iir),e(GT,lW),e(lW,Nir),e(GT,qir),e(Le,jir),e(Le,OT),e(OT,fbe),e(fbe,Dir),e(OT,Gir),e(OT,iW),e(iW,Oir),e(OT,Vir),e(Le,Xir),e(Le,VT),e(VT,mbe),e(mbe,zir),e(VT,Qir),e(VT,dW),e(dW,Wir),e(VT,Hir),e(Le,Uir),e(Le,XT),e(XT,gbe),e(gbe,Jir),e(XT,Yir),e(XT,cW),e(cW,Kir),e(XT,Zir),e(Le,edr),e(Le,zT),e(zT,hbe),e(hbe,odr),e(zT,rdr),e(zT,fW),e(fW,tdr),e(zT,adr),e(Le,ndr),e(Le,QT),e(QT,pbe),e(pbe,sdr),e(QT,ldr),e(QT,mW),e(mW,idr),e(QT,ddr),e(Le,cdr),e(Le,WT),e(WT,_be),e(_be,fdr),e(WT,mdr),e(WT,gW),e(gW,gdr),e(WT,hdr),e(Le,pdr),e(Le,HT),e(HT,ube),e(ube,_dr),e(HT,udr),e(HT,hW),e(hW,bdr),e(HT,vdr),e(Le,Fdr),e(Le,UT),e(UT,bbe),e(bbe,Tdr),e(UT,Mdr),e(UT,pW),e(pW,Edr),e(UT,Cdr),e(Le,wdr),e(Le,JT),e(JT,vbe),e(vbe,Adr),e(JT,Ldr),e(JT,_W),e(_W,ydr),e(JT,xdr),e(go,$dr),e(go,YT),e(YT,kdr),e(YT,Fbe),e(Fbe,Sdr),e(YT,Rdr),e(YT,Tbe),e(Tbe,Pdr),e(go,Bdr),M(KT,go,null),b(f,SOe,u),b(f,Sd,u),e(Sd,ZT),e(ZT,Mbe),M(SL,Mbe,null),e(Sd,Idr),e(Sd,Ebe),e(Ebe,Ndr),b(f,ROe,u),b(f,Wo,u),M(RL,Wo,null),e(Wo,qdr),e(Wo,Rd),e(Rd,jdr),e(Rd,uW),e(uW,Ddr),e(Rd,Gdr),e(Rd,bW),e(bW,Odr),e(Rd,Vdr),e(Wo,Xdr),e(Wo,PL),e(PL,zdr),e(PL,Cbe),e(Cbe,Qdr),e(PL,Wdr),e(Wo,Hdr),e(Wo,Et),M(BL,Et,null),e(Et,Udr),e(Et,wbe),e(wbe,Jdr),e(Et,Ydr),e(Et,Pd),e(Pd,Kdr),e(Pd,Abe),e(Abe,Zdr),e(Pd,ecr),e(Pd,vW),e(vW,ocr),e(Pd,rcr),e(Et,tcr),M(e7,Et,null),e(Wo,acr),e(Wo,ho),M(IL,ho,null),e(ho,ncr),e(ho,Lbe),e(Lbe,scr),e(ho,lcr),e(ho,Ja),e(Ja,icr),e(Ja,ybe),e(ybe,dcr),e(Ja,ccr),e(Ja,xbe),e(xbe,fcr),e(Ja,mcr),e(Ja,$be),e($be,gcr),e(Ja,hcr),e(ho,pcr),e(ho,NL),e(NL,o7),e(o7,kbe),e(kbe,_cr),e(o7,ucr),e(o7,FW),e(FW,bcr),e(o7,vcr),e(NL,Fcr),e(NL,r7),e(r7,Sbe),e(Sbe,Tcr),e(r7,Mcr),e(r7,TW),e(TW,Ecr),e(r7,Ccr),e(ho,wcr),e(ho,t7),e(t7,Acr),e(t7,Rbe),e(Rbe,Lcr),e(t7,ycr),e(t7,Pbe),e(Pbe,xcr),e(ho,$cr),M(a7,ho,null),b(f,POe,u),b(f,Bd,u),e(Bd,n7),e(n7,Bbe),M(qL,Bbe,null),e(Bd,kcr),e(Bd,Ibe),e(Ibe,Scr),b(f,BOe,u),b(f,Ho,u),M(jL,Ho,null),e(Ho,Rcr),e(Ho,Id),e(Id,Pcr),e(Id,MW),e(MW,Bcr),e(Id,Icr),e(Id,EW),e(EW,Ncr),e(Id,qcr),e(Ho,jcr),e(Ho,DL),e(DL,Dcr),e(DL,Nbe),e(Nbe,Gcr),e(DL,Ocr),e(Ho,Vcr),e(Ho,Ct),M(GL,Ct,null),e(Ct,Xcr),e(Ct,qbe),e(qbe,zcr),e(Ct,Qcr),e(Ct,Nd),e(Nd,Wcr),e(Nd,jbe),e(jbe,Hcr),e(Nd,Ucr),e(Nd,CW),e(CW,Jcr),e(Nd,Ycr),e(Ct,Kcr),M(s7,Ct,null),e(Ho,Zcr),e(Ho,po),M(OL,po,null),e(po,efr),e(po,Dbe),e(Dbe,ofr),e(po,rfr),e(po,Ya),e(Ya,tfr),e(Ya,Gbe),e(Gbe,afr),e(Ya,nfr),e(Ya,Obe),e(Obe,sfr),e(Ya,lfr),e(Ya,Vbe),e(Vbe,ifr),e(Ya,dfr),e(po,cfr),e(po,ot),e(ot,l7),e(l7,Xbe),e(Xbe,ffr),e(l7,mfr),e(l7,wW),e(wW,gfr),e(l7,hfr),e(ot,pfr),e(ot,i7),e(i7,zbe),e(zbe,_fr),e(i7,ufr),e(i7,AW),e(AW,bfr),e(i7,vfr),e(ot,Ffr),e(ot,d7),e(d7,Qbe),e(Qbe,Tfr),e(d7,Mfr),e(d7,LW),e(LW,Efr),e(d7,Cfr),e(ot,wfr),e(ot,c7),e(c7,Wbe),e(Wbe,Afr),e(c7,Lfr),e(c7,yW),e(yW,yfr),e(c7,xfr),e(ot,$fr),e(ot,f7),e(f7,Hbe),e(Hbe,kfr),e(f7,Sfr),e(f7,xW),e(xW,Rfr),e(f7,Pfr),e(po,Bfr),e(po,m7),e(m7,Ifr),e(m7,Ube),e(Ube,Nfr),e(m7,qfr),e(m7,Jbe),e(Jbe,jfr),e(po,Dfr),M(g7,po,null),b(f,IOe,u),b(f,qd,u),e(qd,h7),e(h7,Ybe),M(VL,Ybe,null),e(qd,Gfr),e(qd,Kbe),e(Kbe,Ofr),b(f,NOe,u),b(f,Uo,u),M(XL,Uo,null),e(Uo,Vfr),e(Uo,jd),e(jd,Xfr),e(jd,$W),e($W,zfr),e(jd,Qfr),e(jd,kW),e(kW,Wfr),e(jd,Hfr),e(Uo,Ufr),e(Uo,zL),e(zL,Jfr),e(zL,Zbe),e(Zbe,Yfr),e(zL,Kfr),e(Uo,Zfr),e(Uo,wt),M(QL,wt,null),e(wt,emr),e(wt,eve),e(eve,omr),e(wt,rmr),e(wt,Dd),e(Dd,tmr),e(Dd,ove),e(ove,amr),e(Dd,nmr),e(Dd,SW),e(SW,smr),e(Dd,lmr),e(wt,imr),M(p7,wt,null),e(Uo,dmr),e(Uo,_o),M(WL,_o,null),e(_o,cmr),e(_o,rve),e(rve,fmr),e(_o,mmr),e(_o,Ka),e(Ka,gmr),e(Ka,tve),e(tve,hmr),e(Ka,pmr),e(Ka,ave),e(ave,_mr),e(Ka,umr),e(Ka,nve),e(nve,bmr),e(Ka,vmr),e(_o,Fmr),e(_o,Gd),e(Gd,_7),e(_7,sve),e(sve,Tmr),e(_7,Mmr),e(_7,RW),e(RW,Emr),e(_7,Cmr),e(Gd,wmr),e(Gd,u7),e(u7,lve),e(lve,Amr),e(u7,Lmr),e(u7,PW),e(PW,ymr),e(u7,xmr),e(Gd,$mr),e(Gd,b7),e(b7,ive),e(ive,kmr),e(b7,Smr),e(b7,BW),e(BW,Rmr),e(b7,Pmr),e(_o,Bmr),e(_o,v7),e(v7,Imr),e(v7,dve),e(dve,Nmr),e(v7,qmr),e(v7,cve),e(cve,jmr),e(_o,Dmr),M(F7,_o,null),b(f,qOe,u),b(f,Od,u),e(Od,T7),e(T7,fve),M(HL,fve,null),e(Od,Gmr),e(Od,mve),e(mve,Omr),b(f,jOe,u),b(f,Jo,u),M(UL,Jo,null),e(Jo,Vmr),e(Jo,Vd),e(Vd,Xmr),e(Vd,IW),e(IW,zmr),e(Vd,Qmr),e(Vd,NW),e(NW,Wmr),e(Vd,Hmr),e(Jo,Umr),e(Jo,JL),e(JL,Jmr),e(JL,gve),e(gve,Ymr),e(JL,Kmr),e(Jo,Zmr),e(Jo,At),M(YL,At,null),e(At,egr),e(At,hve),e(hve,ogr),e(At,rgr),e(At,Xd),e(Xd,tgr),e(Xd,pve),e(pve,agr),e(Xd,ngr),e(Xd,qW),e(qW,sgr),e(Xd,lgr),e(At,igr),M(M7,At,null),e(Jo,dgr),e(Jo,uo),M(KL,uo,null),e(uo,cgr),e(uo,_ve),e(_ve,fgr),e(uo,mgr),e(uo,Za),e(Za,ggr),e(Za,uve),e(uve,hgr),e(Za,pgr),e(Za,bve),e(bve,_gr),e(Za,ugr),e(Za,vve),e(vve,bgr),e(Za,vgr),e(uo,Fgr),e(uo,ZL),e(ZL,E7),e(E7,Fve),e(Fve,Tgr),e(E7,Mgr),e(E7,jW),e(jW,Egr),e(E7,Cgr),e(ZL,wgr),e(ZL,C7),e(C7,Tve),e(Tve,Agr),e(C7,Lgr),e(C7,DW),e(DW,ygr),e(C7,xgr),e(uo,$gr),e(uo,w7),e(w7,kgr),e(w7,Mve),e(Mve,Sgr),e(w7,Rgr),e(w7,Eve),e(Eve,Pgr),e(uo,Bgr),M(A7,uo,null),b(f,DOe,u),b(f,zd,u),e(zd,L7),e(L7,Cve),M(ey,Cve,null),e(zd,Igr),e(zd,wve),e(wve,Ngr),b(f,GOe,u),b(f,Yo,u),M(oy,Yo,null),e(Yo,qgr),e(Yo,Qd),e(Qd,jgr),e(Qd,GW),e(GW,Dgr),e(Qd,Ggr),e(Qd,OW),e(OW,Ogr),e(Qd,Vgr),e(Yo,Xgr),e(Yo,ry),e(ry,zgr),e(ry,Ave),e(Ave,Qgr),e(ry,Wgr),e(Yo,Hgr),e(Yo,Lt),M(ty,Lt,null),e(Lt,Ugr),e(Lt,Lve),e(Lve,Jgr),e(Lt,Ygr),e(Lt,Wd),e(Wd,Kgr),e(Wd,yve),e(yve,Zgr),e(Wd,ehr),e(Wd,VW),e(VW,ohr),e(Wd,rhr),e(Lt,thr),M(y7,Lt,null),e(Yo,ahr),e(Yo,bo),M(ay,bo,null),e(bo,nhr),e(bo,xve),e(xve,shr),e(bo,lhr),e(bo,en),e(en,ihr),e(en,$ve),e($ve,dhr),e(en,chr),e(en,kve),e(kve,fhr),e(en,mhr),e(en,Sve),e(Sve,ghr),e(en,hhr),e(bo,phr),e(bo,Rve),e(Rve,x7),e(x7,Pve),e(Pve,_hr),e(x7,uhr),e(x7,XW),e(XW,bhr),e(x7,vhr),e(bo,Fhr),e(bo,$7),e($7,Thr),e($7,Bve),e(Bve,Mhr),e($7,Ehr),e($7,Ive),e(Ive,Chr),e(bo,whr),M(k7,bo,null),b(f,OOe,u),b(f,Hd,u),e(Hd,S7),e(S7,Nve),M(ny,Nve,null),e(Hd,Ahr),e(Hd,qve),e(qve,Lhr),b(f,VOe,u),b(f,Ko,u),M(sy,Ko,null),e(Ko,yhr),e(Ko,Ud),e(Ud,xhr),e(Ud,zW),e(zW,$hr),e(Ud,khr),e(Ud,QW),e(QW,Shr),e(Ud,Rhr),e(Ko,Phr),e(Ko,ly),e(ly,Bhr),e(ly,jve),e(jve,Ihr),e(ly,Nhr),e(Ko,qhr),e(Ko,yt),M(iy,yt,null),e(yt,jhr),e(yt,Dve),e(Dve,Dhr),e(yt,Ghr),e(yt,Jd),e(Jd,Ohr),e(Jd,Gve),e(Gve,Vhr),e(Jd,Xhr),e(Jd,WW),e(WW,zhr),e(Jd,Qhr),e(yt,Whr),M(R7,yt,null),e(Ko,Hhr),e(Ko,vo),M(dy,vo,null),e(vo,Uhr),e(vo,Ove),e(Ove,Jhr),e(vo,Yhr),e(vo,on),e(on,Khr),e(on,Vve),e(Vve,Zhr),e(on,epr),e(on,Xve),e(Xve,opr),e(on,rpr),e(on,zve),e(zve,tpr),e(on,apr),e(vo,npr),e(vo,rn),e(rn,P7),e(P7,Qve),e(Qve,spr),e(P7,lpr),e(P7,HW),e(HW,ipr),e(P7,dpr),e(rn,cpr),e(rn,B7),e(B7,Wve),e(Wve,fpr),e(B7,mpr),e(B7,UW),e(UW,gpr),e(B7,hpr),e(rn,ppr),e(rn,I7),e(I7,Hve),e(Hve,_pr),e(I7,upr),e(I7,JW),e(JW,bpr),e(I7,vpr),e(rn,Fpr),e(rn,N7),e(N7,Uve),e(Uve,Tpr),e(N7,Mpr),e(N7,YW),e(YW,Epr),e(N7,Cpr),e(vo,wpr),e(vo,q7),e(q7,Apr),e(q7,Jve),e(Jve,Lpr),e(q7,ypr),e(q7,Yve),e(Yve,xpr),e(vo,$pr),M(j7,vo,null),b(f,XOe,u),b(f,Yd,u),e(Yd,D7),e(D7,Kve),M(cy,Kve,null),e(Yd,kpr),e(Yd,Zve),e(Zve,Spr),b(f,zOe,u),b(f,Zo,u),M(fy,Zo,null),e(Zo,Rpr),e(Zo,Kd),e(Kd,Ppr),e(Kd,KW),e(KW,Bpr),e(Kd,Ipr),e(Kd,ZW),e(ZW,Npr),e(Kd,qpr),e(Zo,jpr),e(Zo,my),e(my,Dpr),e(my,eFe),e(eFe,Gpr),e(my,Opr),e(Zo,Vpr),e(Zo,xt),M(gy,xt,null),e(xt,Xpr),e(xt,oFe),e(oFe,zpr),e(xt,Qpr),e(xt,Zd),e(Zd,Wpr),e(Zd,rFe),e(rFe,Hpr),e(Zd,Upr),e(Zd,eH),e(eH,Jpr),e(Zd,Ypr),e(xt,Kpr),M(G7,xt,null),e(Zo,Zpr),e(Zo,Fo),M(hy,Fo,null),e(Fo,e_r),e(Fo,tFe),e(tFe,o_r),e(Fo,r_r),e(Fo,tn),e(tn,t_r),e(tn,aFe),e(aFe,a_r),e(tn,n_r),e(tn,nFe),e(nFe,s_r),e(tn,l_r),e(tn,sFe),e(sFe,i_r),e(tn,d_r),e(Fo,c_r),e(Fo,lFe),e(lFe,O7),e(O7,iFe),e(iFe,f_r),e(O7,m_r),e(O7,oH),e(oH,g_r),e(O7,h_r),e(Fo,p_r),e(Fo,V7),e(V7,__r),e(V7,dFe),e(dFe,u_r),e(V7,b_r),e(V7,cFe),e(cFe,v_r),e(Fo,F_r),M(X7,Fo,null),b(f,QOe,u),b(f,ec,u),e(ec,z7),e(z7,fFe),M(py,fFe,null),e(ec,T_r),e(ec,mFe),e(mFe,M_r),b(f,WOe,u),b(f,er,u),M(_y,er,null),e(er,E_r),e(er,oc),e(oc,C_r),e(oc,rH),e(rH,w_r),e(oc,A_r),e(oc,tH),e(tH,L_r),e(oc,y_r),e(er,x_r),e(er,uy),e(uy,$_r),e(uy,gFe),e(gFe,k_r),e(uy,S_r),e(er,R_r),e(er,$t),M(by,$t,null),e($t,P_r),e($t,hFe),e(hFe,B_r),e($t,I_r),e($t,rc),e(rc,N_r),e(rc,pFe),e(pFe,q_r),e(rc,j_r),e(rc,aH),e(aH,D_r),e(rc,G_r),e($t,O_r),M(Q7,$t,null),e(er,V_r),e(er,yr),M(vy,yr,null),e(yr,X_r),e(yr,_Fe),e(_Fe,z_r),e(yr,Q_r),e(yr,an),e(an,W_r),e(an,uFe),e(uFe,H_r),e(an,U_r),e(an,bFe),e(bFe,J_r),e(an,Y_r),e(an,vFe),e(vFe,K_r),e(an,Z_r),e(yr,eur),e(yr,j),e(j,W7),e(W7,FFe),e(FFe,our),e(W7,rur),e(W7,nH),e(nH,tur),e(W7,aur),e(j,nur),e(j,H7),e(H7,TFe),e(TFe,sur),e(H7,lur),e(H7,sH),e(sH,iur),e(H7,dur),e(j,cur),e(j,U7),e(U7,MFe),e(MFe,fur),e(U7,mur),e(U7,lH),e(lH,gur),e(U7,hur),e(j,pur),e(j,J7),e(J7,EFe),e(EFe,_ur),e(J7,uur),e(J7,iH),e(iH,bur),e(J7,vur),e(j,Fur),e(j,Y7),e(Y7,CFe),e(CFe,Tur),e(Y7,Mur),e(Y7,dH),e(dH,Eur),e(Y7,Cur),e(j,wur),e(j,K7),e(K7,wFe),e(wFe,Aur),e(K7,Lur),e(K7,cH),e(cH,yur),e(K7,xur),e(j,$ur),e(j,Z7),e(Z7,AFe),e(AFe,kur),e(Z7,Sur),e(Z7,fH),e(fH,Rur),e(Z7,Pur),e(j,Bur),e(j,e8),e(e8,LFe),e(LFe,Iur),e(e8,Nur),e(e8,mH),e(mH,qur),e(e8,jur),e(j,Dur),e(j,o8),e(o8,yFe),e(yFe,Gur),e(o8,Our),e(o8,gH),e(gH,Vur),e(o8,Xur),e(j,zur),e(j,r8),e(r8,xFe),e(xFe,Qur),e(r8,Wur),e(r8,hH),e(hH,Hur),e(r8,Uur),e(j,Jur),e(j,t8),e(t8,$Fe),e($Fe,Yur),e(t8,Kur),e(t8,pH),e(pH,Zur),e(t8,e1r),e(j,o1r),e(j,a8),e(a8,kFe),e(kFe,r1r),e(a8,t1r),e(a8,_H),e(_H,a1r),e(a8,n1r),e(j,s1r),e(j,n8),e(n8,SFe),e(SFe,l1r),e(n8,i1r),e(n8,uH),e(uH,d1r),e(n8,c1r),e(j,f1r),e(j,s8),e(s8,RFe),e(RFe,m1r),e(s8,g1r),e(s8,bH),e(bH,h1r),e(s8,p1r),e(j,_1r),e(j,l8),e(l8,PFe),e(PFe,u1r),e(l8,b1r),e(l8,vH),e(vH,v1r),e(l8,F1r),e(j,T1r),e(j,i8),e(i8,BFe),e(BFe,M1r),e(i8,E1r),e(i8,FH),e(FH,C1r),e(i8,w1r),e(j,A1r),e(j,d8),e(d8,IFe),e(IFe,L1r),e(d8,y1r),e(d8,TH),e(TH,x1r),e(d8,$1r),e(j,k1r),e(j,Qs),e(Qs,NFe),e(NFe,S1r),e(Qs,R1r),e(Qs,MH),e(MH,P1r),e(Qs,B1r),e(Qs,EH),e(EH,I1r),e(Qs,N1r),e(j,q1r),e(j,c8),e(c8,qFe),e(qFe,j1r),e(c8,D1r),e(c8,CH),e(CH,G1r),e(c8,O1r),e(j,V1r),e(j,f8),e(f8,jFe),e(jFe,X1r),e(f8,z1r),e(f8,wH),e(wH,Q1r),e(f8,W1r),e(j,H1r),e(j,m8),e(m8,DFe),e(DFe,U1r),e(m8,J1r),e(m8,AH),e(AH,Y1r),e(m8,K1r),e(j,Z1r),e(j,g8),e(g8,GFe),e(GFe,e2r),e(g8,o2r),e(g8,LH),e(LH,r2r),e(g8,t2r),e(j,a2r),e(j,h8),e(h8,OFe),e(OFe,n2r),e(h8,s2r),e(h8,yH),e(yH,l2r),e(h8,i2r),e(j,d2r),e(j,p8),e(p8,VFe),e(VFe,c2r),e(p8,f2r),e(p8,xH),e(xH,m2r),e(p8,g2r),e(j,h2r),e(j,_8),e(_8,XFe),e(XFe,p2r),e(_8,_2r),e(_8,$H),e($H,u2r),e(_8,b2r),e(j,v2r),e(j,u8),e(u8,zFe),e(zFe,F2r),e(u8,T2r),e(u8,kH),e(kH,M2r),e(u8,E2r),e(j,C2r),e(j,b8),e(b8,QFe),e(QFe,w2r),e(b8,A2r),e(b8,SH),e(SH,L2r),e(b8,y2r),e(j,x2r),e(j,v8),e(v8,WFe),e(WFe,$2r),e(v8,k2r),e(v8,RH),e(RH,S2r),e(v8,R2r),e(j,P2r),e(j,F8),e(F8,HFe),e(HFe,B2r),e(F8,I2r),e(F8,PH),e(PH,N2r),e(F8,q2r),e(j,j2r),e(j,T8),e(T8,UFe),e(UFe,D2r),e(T8,G2r),e(T8,BH),e(BH,O2r),e(T8,V2r),e(j,X2r),e(j,M8),e(M8,JFe),e(JFe,z2r),e(M8,Q2r),e(M8,IH),e(IH,W2r),e(M8,H2r),e(j,U2r),e(j,E8),e(E8,YFe),e(YFe,J2r),e(E8,Y2r),e(E8,NH),e(NH,K2r),e(E8,Z2r),e(j,ebr),e(j,C8),e(C8,KFe),e(KFe,obr),e(C8,rbr),e(C8,qH),e(qH,tbr),e(C8,abr),e(j,nbr),e(j,w8),e(w8,ZFe),e(ZFe,sbr),e(w8,lbr),e(w8,jH),e(jH,ibr),e(w8,dbr),e(j,cbr),e(j,A8),e(A8,e6e),e(e6e,fbr),e(A8,mbr),e(A8,DH),e(DH,gbr),e(A8,hbr),e(j,pbr),e(j,L8),e(L8,o6e),e(o6e,_br),e(L8,ubr),e(L8,GH),e(GH,bbr),e(L8,vbr),e(j,Fbr),e(j,y8),e(y8,r6e),e(r6e,Tbr),e(y8,Mbr),e(y8,OH),e(OH,Ebr),e(y8,Cbr),e(j,wbr),e(j,x8),e(x8,t6e),e(t6e,Abr),e(x8,Lbr),e(x8,VH),e(VH,ybr),e(x8,xbr),e(j,$br),e(j,$8),e($8,a6e),e(a6e,kbr),e($8,Sbr),e($8,XH),e(XH,Rbr),e($8,Pbr),e(j,Bbr),e(j,k8),e(k8,n6e),e(n6e,Ibr),e(k8,Nbr),e(k8,zH),e(zH,qbr),e(k8,jbr),e(j,Dbr),e(j,S8),e(S8,s6e),e(s6e,Gbr),e(S8,Obr),e(S8,QH),e(QH,Vbr),e(S8,Xbr),e(j,zbr),e(j,R8),e(R8,l6e),e(l6e,Qbr),e(R8,Wbr),e(R8,WH),e(WH,Hbr),e(R8,Ubr),e(j,Jbr),e(j,P8),e(P8,i6e),e(i6e,Ybr),e(P8,Kbr),e(P8,HH),e(HH,Zbr),e(P8,evr),e(j,ovr),e(j,B8),e(B8,d6e),e(d6e,rvr),e(B8,tvr),e(B8,UH),e(UH,avr),e(B8,nvr),e(j,svr),e(j,I8),e(I8,c6e),e(c6e,lvr),e(I8,ivr),e(I8,JH),e(JH,dvr),e(I8,cvr),e(j,fvr),e(j,N8),e(N8,f6e),e(f6e,mvr),e(N8,gvr),e(N8,YH),e(YH,hvr),e(N8,pvr),e(j,_vr),e(j,q8),e(q8,m6e),e(m6e,uvr),e(q8,bvr),e(q8,KH),e(KH,vvr),e(q8,Fvr),e(yr,Tvr),M(j8,yr,null),b(f,HOe,u),b(f,tc,u),e(tc,D8),e(D8,g6e),M(Fy,g6e,null),e(tc,Mvr),e(tc,h6e),e(h6e,Evr),b(f,UOe,u),b(f,or,u),M(Ty,or,null),e(or,Cvr),e(or,ac),e(ac,wvr),e(ac,ZH),e(ZH,Avr),e(ac,Lvr),e(ac,eU),e(eU,yvr),e(ac,xvr),e(or,$vr),e(or,My),e(My,kvr),e(My,p6e),e(p6e,Svr),e(My,Rvr),e(or,Pvr),e(or,kt),M(Ey,kt,null),e(kt,Bvr),e(kt,_6e),e(_6e,Ivr),e(kt,Nvr),e(kt,nc),e(nc,qvr),e(nc,u6e),e(u6e,jvr),e(nc,Dvr),e(nc,oU),e(oU,Gvr),e(nc,Ovr),e(kt,Vvr),M(G8,kt,null),e(or,Xvr),e(or,xr),M(Cy,xr,null),e(xr,zvr),e(xr,b6e),e(b6e,Qvr),e(xr,Wvr),e(xr,nn),e(nn,Hvr),e(nn,v6e),e(v6e,Uvr),e(nn,Jvr),e(nn,F6e),e(F6e,Yvr),e(nn,Kvr),e(nn,T6e),e(T6e,Zvr),e(nn,eFr),e(xr,oFr),e(xr,se),e(se,O8),e(O8,M6e),e(M6e,rFr),e(O8,tFr),e(O8,rU),e(rU,aFr),e(O8,nFr),e(se,sFr),e(se,V8),e(V8,E6e),e(E6e,lFr),e(V8,iFr),e(V8,tU),e(tU,dFr),e(V8,cFr),e(se,fFr),e(se,X8),e(X8,C6e),e(C6e,mFr),e(X8,gFr),e(X8,aU),e(aU,hFr),e(X8,pFr),e(se,_Fr),e(se,z8),e(z8,w6e),e(w6e,uFr),e(z8,bFr),e(z8,nU),e(nU,vFr),e(z8,FFr),e(se,TFr),e(se,Q8),e(Q8,A6e),e(A6e,MFr),e(Q8,EFr),e(Q8,sU),e(sU,CFr),e(Q8,wFr),e(se,AFr),e(se,W8),e(W8,L6e),e(L6e,LFr),e(W8,yFr),e(W8,lU),e(lU,xFr),e(W8,$Fr),e(se,kFr),e(se,H8),e(H8,y6e),e(y6e,SFr),e(H8,RFr),e(H8,iU),e(iU,PFr),e(H8,BFr),e(se,IFr),e(se,U8),e(U8,x6e),e(x6e,NFr),e(U8,qFr),e(U8,dU),e(dU,jFr),e(U8,DFr),e(se,GFr),e(se,J8),e(J8,$6e),e($6e,OFr),e(J8,VFr),e(J8,cU),e(cU,XFr),e(J8,zFr),e(se,QFr),e(se,Y8),e(Y8,k6e),e(k6e,WFr),e(Y8,HFr),e(Y8,fU),e(fU,UFr),e(Y8,JFr),e(se,YFr),e(se,K8),e(K8,S6e),e(S6e,KFr),e(K8,ZFr),e(K8,mU),e(mU,e6r),e(K8,o6r),e(se,r6r),e(se,Z8),e(Z8,R6e),e(R6e,t6r),e(Z8,a6r),e(Z8,gU),e(gU,n6r),e(Z8,s6r),e(se,l6r),e(se,e9),e(e9,P6e),e(P6e,i6r),e(e9,d6r),e(e9,hU),e(hU,c6r),e(e9,f6r),e(se,m6r),e(se,o9),e(o9,B6e),e(B6e,g6r),e(o9,h6r),e(o9,pU),e(pU,p6r),e(o9,_6r),e(se,u6r),e(se,r9),e(r9,I6e),e(I6e,b6r),e(r9,v6r),e(r9,_U),e(_U,F6r),e(r9,T6r),e(se,M6r),e(se,t9),e(t9,N6e),e(N6e,E6r),e(t9,C6r),e(t9,uU),e(uU,w6r),e(t9,A6r),e(se,L6r),e(se,a9),e(a9,q6e),e(q6e,y6r),e(a9,x6r),e(a9,bU),e(bU,$6r),e(a9,k6r),e(se,S6r),e(se,n9),e(n9,j6e),e(j6e,R6r),e(n9,P6r),e(n9,vU),e(vU,B6r),e(n9,I6r),e(se,N6r),e(se,s9),e(s9,D6e),e(D6e,q6r),e(s9,j6r),e(s9,FU),e(FU,D6r),e(s9,G6r),e(se,O6r),e(se,l9),e(l9,G6e),e(G6e,V6r),e(l9,X6r),e(l9,TU),e(TU,z6r),e(l9,Q6r),e(se,W6r),e(se,i9),e(i9,O6e),e(O6e,H6r),e(i9,U6r),e(i9,MU),e(MU,J6r),e(i9,Y6r),e(se,K6r),e(se,d9),e(d9,V6e),e(V6e,Z6r),e(d9,eTr),e(d9,EU),e(EU,oTr),e(d9,rTr),e(se,tTr),e(se,c9),e(c9,X6e),e(X6e,aTr),e(c9,nTr),e(c9,CU),e(CU,sTr),e(c9,lTr),e(xr,iTr),M(f9,xr,null),b(f,JOe,u),b(f,sc,u),e(sc,m9),e(m9,z6e),M(wy,z6e,null),e(sc,dTr),e(sc,Q6e),e(Q6e,cTr),b(f,YOe,u),b(f,rr,u),M(Ay,rr,null),e(rr,fTr),e(rr,lc),e(lc,mTr),e(lc,wU),e(wU,gTr),e(lc,hTr),e(lc,AU),e(AU,pTr),e(lc,_Tr),e(rr,uTr),e(rr,Ly),e(Ly,bTr),e(Ly,W6e),e(W6e,vTr),e(Ly,FTr),e(rr,TTr),e(rr,St),M(yy,St,null),e(St,MTr),e(St,H6e),e(H6e,ETr),e(St,CTr),e(St,ic),e(ic,wTr),e(ic,U6e),e(U6e,ATr),e(ic,LTr),e(ic,LU),e(LU,yTr),e(ic,xTr),e(St,$Tr),M(g9,St,null),e(rr,kTr),e(rr,$r),M(xy,$r,null),e($r,STr),e($r,J6e),e(J6e,RTr),e($r,PTr),e($r,sn),e(sn,BTr),e(sn,Y6e),e(Y6e,ITr),e(sn,NTr),e(sn,K6e),e(K6e,qTr),e(sn,jTr),e(sn,Z6e),e(Z6e,DTr),e(sn,GTr),e($r,OTr),e($r,Me),e(Me,h9),e(h9,eTe),e(eTe,VTr),e(h9,XTr),e(h9,yU),e(yU,zTr),e(h9,QTr),e(Me,WTr),e(Me,p9),e(p9,oTe),e(oTe,HTr),e(p9,UTr),e(p9,xU),e(xU,JTr),e(p9,YTr),e(Me,KTr),e(Me,_9),e(_9,rTe),e(rTe,ZTr),e(_9,e7r),e(_9,$U),e($U,o7r),e(_9,r7r),e(Me,t7r),e(Me,u9),e(u9,tTe),e(tTe,a7r),e(u9,n7r),e(u9,kU),e(kU,s7r),e(u9,l7r),e(Me,i7r),e(Me,b9),e(b9,aTe),e(aTe,d7r),e(b9,c7r),e(b9,SU),e(SU,f7r),e(b9,m7r),e(Me,g7r),e(Me,v9),e(v9,nTe),e(nTe,h7r),e(v9,p7r),e(v9,RU),e(RU,_7r),e(v9,u7r),e(Me,b7r),e(Me,F9),e(F9,sTe),e(sTe,v7r),e(F9,F7r),e(F9,PU),e(PU,T7r),e(F9,M7r),e(Me,E7r),e(Me,T9),e(T9,lTe),e(lTe,C7r),e(T9,w7r),e(T9,BU),e(BU,A7r),e(T9,L7r),e(Me,y7r),e(Me,M9),e(M9,iTe),e(iTe,x7r),e(M9,$7r),e(M9,IU),e(IU,k7r),e(M9,S7r),e(Me,R7r),e(Me,E9),e(E9,dTe),e(dTe,P7r),e(E9,B7r),e(E9,NU),e(NU,I7r),e(E9,N7r),e(Me,q7r),e(Me,C9),e(C9,cTe),e(cTe,j7r),e(C9,D7r),e(C9,qU),e(qU,G7r),e(C9,O7r),e(Me,V7r),e(Me,w9),e(w9,fTe),e(fTe,X7r),e(w9,z7r),e(w9,jU),e(jU,Q7r),e(w9,W7r),e(Me,H7r),e(Me,A9),e(A9,mTe),e(mTe,U7r),e(A9,J7r),e(A9,DU),e(DU,Y7r),e(A9,K7r),e($r,Z7r),M(L9,$r,null),b(f,KOe,u),b(f,dc,u),e(dc,y9),e(y9,gTe),M($y,gTe,null),e(dc,e8r),e(dc,hTe),e(hTe,o8r),b(f,ZOe,u),b(f,tr,u),M(ky,tr,null),e(tr,r8r),e(tr,cc),e(cc,t8r),e(cc,GU),e(GU,a8r),e(cc,n8r),e(cc,OU),e(OU,s8r),e(cc,l8r),e(tr,i8r),e(tr,Sy),e(Sy,d8r),e(Sy,pTe),e(pTe,c8r),e(Sy,f8r),e(tr,m8r),e(tr,Rt),M(Ry,Rt,null),e(Rt,g8r),e(Rt,_Te),e(_Te,h8r),e(Rt,p8r),e(Rt,fc),e(fc,_8r),e(fc,uTe),e(uTe,u8r),e(fc,b8r),e(fc,VU),e(VU,v8r),e(fc,F8r),e(Rt,T8r),M(x9,Rt,null),e(tr,M8r),e(tr,kr),M(Py,kr,null),e(kr,E8r),e(kr,bTe),e(bTe,C8r),e(kr,w8r),e(kr,ln),e(ln,A8r),e(ln,vTe),e(vTe,L8r),e(ln,y8r),e(ln,FTe),e(FTe,x8r),e(ln,$8r),e(ln,TTe),e(TTe,k8r),e(ln,S8r),e(kr,R8r),e(kr,dn),e(dn,$9),e($9,MTe),e(MTe,P8r),e($9,B8r),e($9,XU),e(XU,I8r),e($9,N8r),e(dn,q8r),e(dn,k9),e(k9,ETe),e(ETe,j8r),e(k9,D8r),e(k9,zU),e(zU,G8r),e(k9,O8r),e(dn,V8r),e(dn,S9),e(S9,CTe),e(CTe,X8r),e(S9,z8r),e(S9,QU),e(QU,Q8r),e(S9,W8r),e(dn,H8r),e(dn,R9),e(R9,wTe),e(wTe,U8r),e(R9,J8r),e(R9,WU),e(WU,Y8r),e(R9,K8r),e(kr,Z8r),M(P9,kr,null),b(f,eVe,u),b(f,mc,u),e(mc,B9),e(B9,ATe),M(By,ATe,null),e(mc,e9r),e(mc,LTe),e(LTe,o9r),b(f,oVe,u),b(f,ar,u),M(Iy,ar,null),e(ar,r9r),e(ar,gc),e(gc,t9r),e(gc,HU),e(HU,a9r),e(gc,n9r),e(gc,UU),e(UU,s9r),e(gc,l9r),e(ar,i9r),e(ar,Ny),e(Ny,d9r),e(Ny,yTe),e(yTe,c9r),e(Ny,f9r),e(ar,m9r),e(ar,Pt),M(qy,Pt,null),e(Pt,g9r),e(Pt,xTe),e(xTe,h9r),e(Pt,p9r),e(Pt,hc),e(hc,_9r),e(hc,$Te),e($Te,u9r),e(hc,b9r),e(hc,JU),e(JU,v9r),e(hc,F9r),e(Pt,T9r),M(I9,Pt,null),e(ar,M9r),e(ar,Sr),M(jy,Sr,null),e(Sr,E9r),e(Sr,kTe),e(kTe,C9r),e(Sr,w9r),e(Sr,cn),e(cn,A9r),e(cn,STe),e(STe,L9r),e(cn,y9r),e(cn,RTe),e(RTe,x9r),e(cn,$9r),e(cn,PTe),e(PTe,k9r),e(cn,S9r),e(Sr,R9r),e(Sr,ie),e(ie,N9),e(N9,BTe),e(BTe,P9r),e(N9,B9r),e(N9,YU),e(YU,I9r),e(N9,N9r),e(ie,q9r),e(ie,q9),e(q9,ITe),e(ITe,j9r),e(q9,D9r),e(q9,KU),e(KU,G9r),e(q9,O9r),e(ie,V9r),e(ie,j9),e(j9,NTe),e(NTe,X9r),e(j9,z9r),e(j9,ZU),e(ZU,Q9r),e(j9,W9r),e(ie,H9r),e(ie,D9),e(D9,qTe),e(qTe,U9r),e(D9,J9r),e(D9,eJ),e(eJ,Y9r),e(D9,K9r),e(ie,Z9r),e(ie,G9),e(G9,jTe),e(jTe,eMr),e(G9,oMr),e(G9,oJ),e(oJ,rMr),e(G9,tMr),e(ie,aMr),e(ie,O9),e(O9,DTe),e(DTe,nMr),e(O9,sMr),e(O9,rJ),e(rJ,lMr),e(O9,iMr),e(ie,dMr),e(ie,V9),e(V9,GTe),e(GTe,cMr),e(V9,fMr),e(V9,tJ),e(tJ,mMr),e(V9,gMr),e(ie,hMr),e(ie,X9),e(X9,OTe),e(OTe,pMr),e(X9,_Mr),e(X9,aJ),e(aJ,uMr),e(X9,bMr),e(ie,vMr),e(ie,z9),e(z9,VTe),e(VTe,FMr),e(z9,TMr),e(z9,nJ),e(nJ,MMr),e(z9,EMr),e(ie,CMr),e(ie,Q9),e(Q9,XTe),e(XTe,wMr),e(Q9,AMr),e(Q9,sJ),e(sJ,LMr),e(Q9,yMr),e(ie,xMr),e(ie,W9),e(W9,zTe),e(zTe,$Mr),e(W9,kMr),e(W9,lJ),e(lJ,SMr),e(W9,RMr),e(ie,PMr),e(ie,H9),e(H9,QTe),e(QTe,BMr),e(H9,IMr),e(H9,iJ),e(iJ,NMr),e(H9,qMr),e(ie,jMr),e(ie,U9),e(U9,WTe),e(WTe,DMr),e(U9,GMr),e(U9,dJ),e(dJ,OMr),e(U9,VMr),e(ie,XMr),e(ie,J9),e(J9,HTe),e(HTe,zMr),e(J9,QMr),e(J9,cJ),e(cJ,WMr),e(J9,HMr),e(ie,UMr),e(ie,Y9),e(Y9,UTe),e(UTe,JMr),e(Y9,YMr),e(Y9,fJ),e(fJ,KMr),e(Y9,ZMr),e(ie,eEr),e(ie,K9),e(K9,JTe),e(JTe,oEr),e(K9,rEr),e(K9,mJ),e(mJ,tEr),e(K9,aEr),e(ie,nEr),e(ie,Z9),e(Z9,YTe),e(YTe,sEr),e(Z9,lEr),e(Z9,gJ),e(gJ,iEr),e(Z9,dEr),e(ie,cEr),e(ie,eM),e(eM,KTe),e(KTe,fEr),e(eM,mEr),e(eM,hJ),e(hJ,gEr),e(eM,hEr),e(ie,pEr),e(ie,oM),e(oM,ZTe),e(ZTe,_Er),e(oM,uEr),e(oM,pJ),e(pJ,bEr),e(oM,vEr),e(ie,FEr),e(ie,rM),e(rM,e7e),e(e7e,TEr),e(rM,MEr),e(rM,_J),e(_J,EEr),e(rM,CEr),e(Sr,wEr),M(tM,Sr,null),b(f,rVe,u),b(f,pc,u),e(pc,aM),e(aM,o7e),M(Dy,o7e,null),e(pc,AEr),e(pc,r7e),e(r7e,LEr),b(f,tVe,u),b(f,nr,u),M(Gy,nr,null),e(nr,yEr),e(nr,_c),e(_c,xEr),e(_c,uJ),e(uJ,$Er),e(_c,kEr),e(_c,bJ),e(bJ,SEr),e(_c,REr),e(nr,PEr),e(nr,Oy),e(Oy,BEr),e(Oy,t7e),e(t7e,IEr),e(Oy,NEr),e(nr,qEr),e(nr,Bt),M(Vy,Bt,null),e(Bt,jEr),e(Bt,a7e),e(a7e,DEr),e(Bt,GEr),e(Bt,uc),e(uc,OEr),e(uc,n7e),e(n7e,VEr),e(uc,XEr),e(uc,vJ),e(vJ,zEr),e(uc,QEr),e(Bt,WEr),M(nM,Bt,null),e(nr,HEr),e(nr,Rr),M(Xy,Rr,null),e(Rr,UEr),e(Rr,s7e),e(s7e,JEr),e(Rr,YEr),e(Rr,fn),e(fn,KEr),e(fn,l7e),e(l7e,ZEr),e(fn,e4r),e(fn,i7e),e(i7e,o4r),e(fn,r4r),e(fn,d7e),e(d7e,t4r),e(fn,a4r),e(Rr,n4r),e(Rr,ye),e(ye,sM),e(sM,c7e),e(c7e,s4r),e(sM,l4r),e(sM,FJ),e(FJ,i4r),e(sM,d4r),e(ye,c4r),e(ye,lM),e(lM,f7e),e(f7e,f4r),e(lM,m4r),e(lM,TJ),e(TJ,g4r),e(lM,h4r),e(ye,p4r),e(ye,iM),e(iM,m7e),e(m7e,_4r),e(iM,u4r),e(iM,MJ),e(MJ,b4r),e(iM,v4r),e(ye,F4r),e(ye,dM),e(dM,g7e),e(g7e,T4r),e(dM,M4r),e(dM,EJ),e(EJ,E4r),e(dM,C4r),e(ye,w4r),e(ye,cM),e(cM,h7e),e(h7e,A4r),e(cM,L4r),e(cM,CJ),e(CJ,y4r),e(cM,x4r),e(ye,$4r),e(ye,fM),e(fM,p7e),e(p7e,k4r),e(fM,S4r),e(fM,wJ),e(wJ,R4r),e(fM,P4r),e(ye,B4r),e(ye,mM),e(mM,_7e),e(_7e,I4r),e(mM,N4r),e(mM,AJ),e(AJ,q4r),e(mM,j4r),e(ye,D4r),e(ye,gM),e(gM,u7e),e(u7e,G4r),e(gM,O4r),e(gM,LJ),e(LJ,V4r),e(gM,X4r),e(ye,z4r),e(ye,hM),e(hM,b7e),e(b7e,Q4r),e(hM,W4r),e(hM,yJ),e(yJ,H4r),e(hM,U4r),e(ye,J4r),e(ye,pM),e(pM,v7e),e(v7e,Y4r),e(pM,K4r),e(pM,xJ),e(xJ,Z4r),e(pM,eCr),e(Rr,oCr),M(_M,Rr,null),b(f,aVe,u),b(f,bc,u),e(bc,uM),e(uM,F7e),M(zy,F7e,null),e(bc,rCr),e(bc,T7e),e(T7e,tCr),b(f,nVe,u),b(f,sr,u),M(Qy,sr,null),e(sr,aCr),e(sr,vc),e(vc,nCr),e(vc,$J),e($J,sCr),e(vc,lCr),e(vc,kJ),e(kJ,iCr),e(vc,dCr),e(sr,cCr),e(sr,Wy),e(Wy,fCr),e(Wy,M7e),e(M7e,mCr),e(Wy,gCr),e(sr,hCr),e(sr,It),M(Hy,It,null),e(It,pCr),e(It,E7e),e(E7e,_Cr),e(It,uCr),e(It,Fc),e(Fc,bCr),e(Fc,C7e),e(C7e,vCr),e(Fc,FCr),e(Fc,SJ),e(SJ,TCr),e(Fc,MCr),e(It,ECr),M(bM,It,null),e(sr,CCr),e(sr,Pr),M(Uy,Pr,null),e(Pr,wCr),e(Pr,w7e),e(w7e,ACr),e(Pr,LCr),e(Pr,mn),e(mn,yCr),e(mn,A7e),e(A7e,xCr),e(mn,$Cr),e(mn,L7e),e(L7e,kCr),e(mn,SCr),e(mn,y7e),e(y7e,RCr),e(mn,PCr),e(Pr,BCr),e(Pr,te),e(te,vM),e(vM,x7e),e(x7e,ICr),e(vM,NCr),e(vM,RJ),e(RJ,qCr),e(vM,jCr),e(te,DCr),e(te,FM),e(FM,$7e),e($7e,GCr),e(FM,OCr),e(FM,PJ),e(PJ,VCr),e(FM,XCr),e(te,zCr),e(te,TM),e(TM,k7e),e(k7e,QCr),e(TM,WCr),e(TM,BJ),e(BJ,HCr),e(TM,UCr),e(te,JCr),e(te,MM),e(MM,S7e),e(S7e,YCr),e(MM,KCr),e(MM,IJ),e(IJ,ZCr),e(MM,e5r),e(te,o5r),e(te,EM),e(EM,R7e),e(R7e,r5r),e(EM,t5r),e(EM,NJ),e(NJ,a5r),e(EM,n5r),e(te,s5r),e(te,CM),e(CM,P7e),e(P7e,l5r),e(CM,i5r),e(CM,qJ),e(qJ,d5r),e(CM,c5r),e(te,f5r),e(te,wM),e(wM,B7e),e(B7e,m5r),e(wM,g5r),e(wM,jJ),e(jJ,h5r),e(wM,p5r),e(te,_5r),e(te,AM),e(AM,I7e),e(I7e,u5r),e(AM,b5r),e(AM,DJ),e(DJ,v5r),e(AM,F5r),e(te,T5r),e(te,LM),e(LM,N7e),e(N7e,M5r),e(LM,E5r),e(LM,GJ),e(GJ,C5r),e(LM,w5r),e(te,A5r),e(te,yM),e(yM,q7e),e(q7e,L5r),e(yM,y5r),e(yM,OJ),e(OJ,x5r),e(yM,$5r),e(te,k5r),e(te,xM),e(xM,j7e),e(j7e,S5r),e(xM,R5r),e(xM,VJ),e(VJ,P5r),e(xM,B5r),e(te,I5r),e(te,$M),e($M,D7e),e(D7e,N5r),e($M,q5r),e($M,XJ),e(XJ,j5r),e($M,D5r),e(te,G5r),e(te,kM),e(kM,G7e),e(G7e,O5r),e(kM,V5r),e(kM,zJ),e(zJ,X5r),e(kM,z5r),e(te,Q5r),e(te,SM),e(SM,O7e),e(O7e,W5r),e(SM,H5r),e(SM,QJ),e(QJ,U5r),e(SM,J5r),e(te,Y5r),e(te,RM),e(RM,V7e),e(V7e,K5r),e(RM,Z5r),e(RM,WJ),e(WJ,e3r),e(RM,o3r),e(te,r3r),e(te,PM),e(PM,X7e),e(X7e,t3r),e(PM,a3r),e(PM,HJ),e(HJ,n3r),e(PM,s3r),e(te,l3r),e(te,BM),e(BM,z7e),e(z7e,i3r),e(BM,d3r),e(BM,UJ),e(UJ,c3r),e(BM,f3r),e(te,m3r),e(te,IM),e(IM,Q7e),e(Q7e,g3r),e(IM,h3r),e(IM,JJ),e(JJ,p3r),e(IM,_3r),e(te,u3r),e(te,NM),e(NM,W7e),e(W7e,b3r),e(NM,v3r),e(NM,YJ),e(YJ,F3r),e(NM,T3r),e(te,M3r),e(te,qM),e(qM,H7e),e(H7e,E3r),e(qM,C3r),e(qM,KJ),e(KJ,w3r),e(qM,A3r),e(te,L3r),e(te,jM),e(jM,U7e),e(U7e,y3r),e(jM,x3r),e(jM,ZJ),e(ZJ,$3r),e(jM,k3r),e(te,S3r),e(te,DM),e(DM,J7e),e(J7e,R3r),e(DM,P3r),e(DM,eY),e(eY,B3r),e(DM,I3r),e(te,N3r),e(te,GM),e(GM,Y7e),e(Y7e,q3r),e(GM,j3r),e(GM,oY),e(oY,D3r),e(GM,G3r),e(te,O3r),e(te,OM),e(OM,K7e),e(K7e,V3r),e(OM,X3r),e(OM,rY),e(rY,z3r),e(OM,Q3r),e(te,W3r),e(te,VM),e(VM,Z7e),e(Z7e,H3r),e(VM,U3r),e(VM,tY),e(tY,J3r),e(VM,Y3r),e(te,K3r),e(te,XM),e(XM,e8e),e(e8e,Z3r),e(XM,e0r),e(XM,aY),e(aY,o0r),e(XM,r0r),e(Pr,t0r),M(zM,Pr,null),b(f,sVe,u),b(f,Tc,u),e(Tc,QM),e(QM,o8e),M(Jy,o8e,null),e(Tc,a0r),e(Tc,r8e),e(r8e,n0r),b(f,lVe,u),b(f,lr,u),M(Yy,lr,null),e(lr,s0r),e(lr,Mc),e(Mc,l0r),e(Mc,nY),e(nY,i0r),e(Mc,d0r),e(Mc,sY),e(sY,c0r),e(Mc,f0r),e(lr,m0r),e(lr,Ky),e(Ky,g0r),e(Ky,t8e),e(t8e,h0r),e(Ky,p0r),e(lr,_0r),e(lr,Nt),M(Zy,Nt,null),e(Nt,u0r),e(Nt,a8e),e(a8e,b0r),e(Nt,v0r),e(Nt,Ec),e(Ec,F0r),e(Ec,n8e),e(n8e,T0r),e(Ec,M0r),e(Ec,lY),e(lY,E0r),e(Ec,C0r),e(Nt,w0r),M(WM,Nt,null),e(lr,A0r),e(lr,Br),M(ex,Br,null),e(Br,L0r),e(Br,s8e),e(s8e,y0r),e(Br,x0r),e(Br,gn),e(gn,$0r),e(gn,l8e),e(l8e,k0r),e(gn,S0r),e(gn,i8e),e(i8e,R0r),e(gn,P0r),e(gn,d8e),e(d8e,B0r),e(gn,I0r),e(Br,N0r),e(Br,_e),e(_e,HM),e(HM,c8e),e(c8e,q0r),e(HM,j0r),e(HM,iY),e(iY,D0r),e(HM,G0r),e(_e,O0r),e(_e,UM),e(UM,f8e),e(f8e,V0r),e(UM,X0r),e(UM,dY),e(dY,z0r),e(UM,Q0r),e(_e,W0r),e(_e,JM),e(JM,m8e),e(m8e,H0r),e(JM,U0r),e(JM,cY),e(cY,J0r),e(JM,Y0r),e(_e,K0r),e(_e,YM),e(YM,g8e),e(g8e,Z0r),e(YM,ewr),e(YM,fY),e(fY,owr),e(YM,rwr),e(_e,twr),e(_e,KM),e(KM,h8e),e(h8e,awr),e(KM,nwr),e(KM,mY),e(mY,swr),e(KM,lwr),e(_e,iwr),e(_e,ZM),e(ZM,p8e),e(p8e,dwr),e(ZM,cwr),e(ZM,gY),e(gY,fwr),e(ZM,mwr),e(_e,gwr),e(_e,eE),e(eE,_8e),e(_8e,hwr),e(eE,pwr),e(eE,hY),e(hY,_wr),e(eE,uwr),e(_e,bwr),e(_e,oE),e(oE,u8e),e(u8e,vwr),e(oE,Fwr),e(oE,pY),e(pY,Twr),e(oE,Mwr),e(_e,Ewr),e(_e,rE),e(rE,b8e),e(b8e,Cwr),e(rE,wwr),e(rE,_Y),e(_Y,Awr),e(rE,Lwr),e(_e,ywr),e(_e,tE),e(tE,v8e),e(v8e,xwr),e(tE,$wr),e(tE,uY),e(uY,kwr),e(tE,Swr),e(_e,Rwr),e(_e,aE),e(aE,F8e),e(F8e,Pwr),e(aE,Bwr),e(aE,bY),e(bY,Iwr),e(aE,Nwr),e(_e,qwr),e(_e,nE),e(nE,T8e),e(T8e,jwr),e(nE,Dwr),e(nE,vY),e(vY,Gwr),e(nE,Owr),e(_e,Vwr),e(_e,sE),e(sE,M8e),e(M8e,Xwr),e(sE,zwr),e(sE,FY),e(FY,Qwr),e(sE,Wwr),e(_e,Hwr),e(_e,lE),e(lE,E8e),e(E8e,Uwr),e(lE,Jwr),e(lE,TY),e(TY,Ywr),e(lE,Kwr),e(_e,Zwr),e(_e,iE),e(iE,C8e),e(C8e,eAr),e(iE,oAr),e(iE,MY),e(MY,rAr),e(iE,tAr),e(_e,aAr),e(_e,dE),e(dE,w8e),e(w8e,nAr),e(dE,sAr),e(dE,EY),e(EY,lAr),e(dE,iAr),e(_e,dAr),e(_e,cE),e(cE,A8e),e(A8e,cAr),e(cE,fAr),e(cE,CY),e(CY,mAr),e(cE,gAr),e(Br,hAr),M(fE,Br,null),b(f,iVe,u),b(f,Cc,u),e(Cc,mE),e(mE,L8e),M(ox,L8e,null),e(Cc,pAr),e(Cc,y8e),e(y8e,_Ar),b(f,dVe,u),b(f,ir,u),M(rx,ir,null),e(ir,uAr),e(ir,wc),e(wc,bAr),e(wc,wY),e(wY,vAr),e(wc,FAr),e(wc,AY),e(AY,TAr),e(wc,MAr),e(ir,EAr),e(ir,tx),e(tx,CAr),e(tx,x8e),e(x8e,wAr),e(tx,AAr),e(ir,LAr),e(ir,qt),M(ax,qt,null),e(qt,yAr),e(qt,$8e),e($8e,xAr),e(qt,$Ar),e(qt,Ac),e(Ac,kAr),e(Ac,k8e),e(k8e,SAr),e(Ac,RAr),e(Ac,LY),e(LY,PAr),e(Ac,BAr),e(qt,IAr),M(gE,qt,null),e(ir,NAr),e(ir,Ir),M(nx,Ir,null),e(Ir,qAr),e(Ir,S8e),e(S8e,jAr),e(Ir,DAr),e(Ir,hn),e(hn,GAr),e(hn,R8e),e(R8e,OAr),e(hn,VAr),e(hn,P8e),e(P8e,XAr),e(hn,zAr),e(hn,B8e),e(B8e,QAr),e(hn,WAr),e(Ir,HAr),e(Ir,sx),e(sx,hE),e(hE,I8e),e(I8e,UAr),e(hE,JAr),e(hE,yY),e(yY,YAr),e(hE,KAr),e(sx,ZAr),e(sx,pE),e(pE,N8e),e(N8e,eLr),e(pE,oLr),e(pE,xY),e(xY,rLr),e(pE,tLr),e(Ir,aLr),M(_E,Ir,null),b(f,cVe,u),b(f,Lc,u),e(Lc,uE),e(uE,q8e),M(lx,q8e,null),e(Lc,nLr),e(Lc,j8e),e(j8e,sLr),b(f,fVe,u),b(f,dr,u),M(ix,dr,null),e(dr,lLr),e(dr,yc),e(yc,iLr),e(yc,$Y),e($Y,dLr),e(yc,cLr),e(yc,kY),e(kY,fLr),e(yc,mLr),e(dr,gLr),e(dr,dx),e(dx,hLr),e(dx,D8e),e(D8e,pLr),e(dx,_Lr),e(dr,uLr),e(dr,jt),M(cx,jt,null),e(jt,bLr),e(jt,G8e),e(G8e,vLr),e(jt,FLr),e(jt,xc),e(xc,TLr),e(xc,O8e),e(O8e,MLr),e(xc,ELr),e(xc,SY),e(SY,CLr),e(xc,wLr),e(jt,ALr),M(bE,jt,null),e(dr,LLr),e(dr,Nr),M(fx,Nr,null),e(Nr,yLr),e(Nr,V8e),e(V8e,xLr),e(Nr,$Lr),e(Nr,pn),e(pn,kLr),e(pn,X8e),e(X8e,SLr),e(pn,RLr),e(pn,z8e),e(z8e,PLr),e(pn,BLr),e(pn,Q8e),e(Q8e,ILr),e(pn,NLr),e(Nr,qLr),e(Nr,W8e),e(W8e,vE),e(vE,H8e),e(H8e,jLr),e(vE,DLr),e(vE,RY),e(RY,GLr),e(vE,OLr),e(Nr,VLr),M(FE,Nr,null),b(f,mVe,u),b(f,$c,u),e($c,TE),e(TE,U8e),M(mx,U8e,null),e($c,XLr),e($c,J8e),e(J8e,zLr),b(f,gVe,u),b(f,cr,u),M(gx,cr,null),e(cr,QLr),e(cr,kc),e(kc,WLr),e(kc,PY),e(PY,HLr),e(kc,ULr),e(kc,BY),e(BY,JLr),e(kc,YLr),e(cr,KLr),e(cr,hx),e(hx,ZLr),e(hx,Y8e),e(Y8e,eyr),e(hx,oyr),e(cr,ryr),e(cr,Dt),M(px,Dt,null),e(Dt,tyr),e(Dt,K8e),e(K8e,ayr),e(Dt,nyr),e(Dt,Sc),e(Sc,syr),e(Sc,Z8e),e(Z8e,lyr),e(Sc,iyr),e(Sc,IY),e(IY,dyr),e(Sc,cyr),e(Dt,fyr),M(ME,Dt,null),e(cr,myr),e(cr,qr),M(_x,qr,null),e(qr,gyr),e(qr,e9e),e(e9e,hyr),e(qr,pyr),e(qr,_n),e(_n,_yr),e(_n,o9e),e(o9e,uyr),e(_n,byr),e(_n,r9e),e(r9e,vyr),e(_n,Fyr),e(_n,t9e),e(t9e,Tyr),e(_n,Myr),e(qr,Eyr),e(qr,de),e(de,EE),e(EE,a9e),e(a9e,Cyr),e(EE,wyr),e(EE,NY),e(NY,Ayr),e(EE,Lyr),e(de,yyr),e(de,CE),e(CE,n9e),e(n9e,xyr),e(CE,$yr),e(CE,qY),e(qY,kyr),e(CE,Syr),e(de,Ryr),e(de,wE),e(wE,s9e),e(s9e,Pyr),e(wE,Byr),e(wE,jY),e(jY,Iyr),e(wE,Nyr),e(de,qyr),e(de,AE),e(AE,l9e),e(l9e,jyr),e(AE,Dyr),e(AE,DY),e(DY,Gyr),e(AE,Oyr),e(de,Vyr),e(de,LE),e(LE,i9e),e(i9e,Xyr),e(LE,zyr),e(LE,GY),e(GY,Qyr),e(LE,Wyr),e(de,Hyr),e(de,yE),e(yE,d9e),e(d9e,Uyr),e(yE,Jyr),e(yE,OY),e(OY,Yyr),e(yE,Kyr),e(de,Zyr),e(de,xE),e(xE,c9e),e(c9e,exr),e(xE,oxr),e(xE,VY),e(VY,rxr),e(xE,txr),e(de,axr),e(de,$E),e($E,f9e),e(f9e,nxr),e($E,sxr),e($E,XY),e(XY,lxr),e($E,ixr),e(de,dxr),e(de,kE),e(kE,m9e),e(m9e,cxr),e(kE,fxr),e(kE,zY),e(zY,mxr),e(kE,gxr),e(de,hxr),e(de,SE),e(SE,g9e),e(g9e,pxr),e(SE,_xr),e(SE,QY),e(QY,uxr),e(SE,bxr),e(de,vxr),e(de,RE),e(RE,h9e),e(h9e,Fxr),e(RE,Txr),e(RE,WY),e(WY,Mxr),e(RE,Exr),e(de,Cxr),e(de,PE),e(PE,p9e),e(p9e,wxr),e(PE,Axr),e(PE,HY),e(HY,Lxr),e(PE,yxr),e(de,xxr),e(de,BE),e(BE,_9e),e(_9e,$xr),e(BE,kxr),e(BE,UY),e(UY,Sxr),e(BE,Rxr),e(de,Pxr),e(de,IE),e(IE,u9e),e(u9e,Bxr),e(IE,Ixr),e(IE,JY),e(JY,Nxr),e(IE,qxr),e(de,jxr),e(de,NE),e(NE,b9e),e(b9e,Dxr),e(NE,Gxr),e(NE,YY),e(YY,Oxr),e(NE,Vxr),e(de,Xxr),e(de,qE),e(qE,v9e),e(v9e,zxr),e(qE,Qxr),e(qE,KY),e(KY,Wxr),e(qE,Hxr),e(de,Uxr),e(de,jE),e(jE,F9e),e(F9e,Jxr),e(jE,Yxr),e(jE,ZY),e(ZY,Kxr),e(jE,Zxr),e(de,e$r),e(de,DE),e(DE,T9e),e(T9e,o$r),e(DE,r$r),e(DE,eK),e(eK,t$r),e(DE,a$r),e(de,n$r),e(de,GE),e(GE,M9e),e(M9e,s$r),e(GE,l$r),e(GE,oK),e(oK,i$r),e(GE,d$r),e(de,c$r),e(de,OE),e(OE,E9e),e(E9e,f$r),e(OE,m$r),e(OE,rK),e(rK,g$r),e(OE,h$r),e(qr,p$r),M(VE,qr,null),b(f,hVe,u),b(f,Rc,u),e(Rc,XE),e(XE,C9e),M(ux,C9e,null),e(Rc,_$r),e(Rc,w9e),e(w9e,u$r),b(f,pVe,u),b(f,fr,u),M(bx,fr,null),e(fr,b$r),e(fr,Pc),e(Pc,v$r),e(Pc,tK),e(tK,F$r),e(Pc,T$r),e(Pc,aK),e(aK,M$r),e(Pc,E$r),e(fr,C$r),e(fr,vx),e(vx,w$r),e(vx,A9e),e(A9e,A$r),e(vx,L$r),e(fr,y$r),e(fr,Gt),M(Fx,Gt,null),e(Gt,x$r),e(Gt,L9e),e(L9e,$$r),e(Gt,k$r),e(Gt,Bc),e(Bc,S$r),e(Bc,y9e),e(y9e,R$r),e(Bc,P$r),e(Bc,nK),e(nK,B$r),e(Bc,I$r),e(Gt,N$r),M(zE,Gt,null),e(fr,q$r),e(fr,jr),M(Tx,jr,null),e(jr,j$r),e(jr,x9e),e(x9e,D$r),e(jr,G$r),e(jr,un),e(un,O$r),e(un,$9e),e($9e,V$r),e(un,X$r),e(un,k9e),e(k9e,z$r),e(un,Q$r),e(un,S9e),e(S9e,W$r),e(un,H$r),e(jr,U$r),e(jr,ce),e(ce,QE),e(QE,R9e),e(R9e,J$r),e(QE,Y$r),e(QE,sK),e(sK,K$r),e(QE,Z$r),e(ce,ekr),e(ce,WE),e(WE,P9e),e(P9e,okr),e(WE,rkr),e(WE,lK),e(lK,tkr),e(WE,akr),e(ce,nkr),e(ce,HE),e(HE,B9e),e(B9e,skr),e(HE,lkr),e(HE,iK),e(iK,ikr),e(HE,dkr),e(ce,ckr),e(ce,UE),e(UE,I9e),e(I9e,fkr),e(UE,mkr),e(UE,dK),e(dK,gkr),e(UE,hkr),e(ce,pkr),e(ce,JE),e(JE,N9e),e(N9e,_kr),e(JE,ukr),e(JE,cK),e(cK,bkr),e(JE,vkr),e(ce,Fkr),e(ce,YE),e(YE,q9e),e(q9e,Tkr),e(YE,Mkr),e(YE,fK),e(fK,Ekr),e(YE,Ckr),e(ce,wkr),e(ce,KE),e(KE,j9e),e(j9e,Akr),e(KE,Lkr),e(KE,mK),e(mK,ykr),e(KE,xkr),e(ce,$kr),e(ce,ZE),e(ZE,D9e),e(D9e,kkr),e(ZE,Skr),e(ZE,gK),e(gK,Rkr),e(ZE,Pkr),e(ce,Bkr),e(ce,e4),e(e4,G9e),e(G9e,Ikr),e(e4,Nkr),e(e4,hK),e(hK,qkr),e(e4,jkr),e(ce,Dkr),e(ce,o4),e(o4,O9e),e(O9e,Gkr),e(o4,Okr),e(o4,pK),e(pK,Vkr),e(o4,Xkr),e(ce,zkr),e(ce,r4),e(r4,V9e),e(V9e,Qkr),e(r4,Wkr),e(r4,_K),e(_K,Hkr),e(r4,Ukr),e(ce,Jkr),e(ce,t4),e(t4,X9e),e(X9e,Ykr),e(t4,Kkr),e(t4,uK),e(uK,Zkr),e(t4,eSr),e(ce,oSr),e(ce,a4),e(a4,z9e),e(z9e,rSr),e(a4,tSr),e(a4,bK),e(bK,aSr),e(a4,nSr),e(ce,sSr),e(ce,n4),e(n4,Q9e),e(Q9e,lSr),e(n4,iSr),e(n4,vK),e(vK,dSr),e(n4,cSr),e(ce,fSr),e(ce,s4),e(s4,W9e),e(W9e,mSr),e(s4,gSr),e(s4,FK),e(FK,hSr),e(s4,pSr),e(ce,_Sr),e(ce,l4),e(l4,H9e),e(H9e,uSr),e(l4,bSr),e(l4,TK),e(TK,vSr),e(l4,FSr),e(ce,TSr),e(ce,i4),e(i4,U9e),e(U9e,MSr),e(i4,ESr),e(i4,MK),e(MK,CSr),e(i4,wSr),e(ce,ASr),e(ce,d4),e(d4,J9e),e(J9e,LSr),e(d4,ySr),e(d4,EK),e(EK,xSr),e(d4,$Sr),e(ce,kSr),e(ce,c4),e(c4,Y9e),e(Y9e,SSr),e(c4,RSr),e(c4,CK),e(CK,PSr),e(c4,BSr),e(ce,ISr),e(ce,f4),e(f4,K9e),e(K9e,NSr),e(f4,qSr),e(f4,wK),e(wK,jSr),e(f4,DSr),e(jr,GSr),M(m4,jr,null),b(f,_Ve,u),b(f,Ic,u),e(Ic,g4),e(g4,Z9e),M(Mx,Z9e,null),e(Ic,OSr),e(Ic,eMe),e(eMe,VSr),b(f,uVe,u),b(f,mr,u),M(Ex,mr,null),e(mr,XSr),e(mr,Nc),e(Nc,zSr),e(Nc,AK),e(AK,QSr),e(Nc,WSr),e(Nc,LK),e(LK,HSr),e(Nc,USr),e(mr,JSr),e(mr,Cx),e(Cx,YSr),e(Cx,oMe),e(oMe,KSr),e(Cx,ZSr),e(mr,eRr),e(mr,Ot),M(wx,Ot,null),e(Ot,oRr),e(Ot,rMe),e(rMe,rRr),e(Ot,tRr),e(Ot,qc),e(qc,aRr),e(qc,tMe),e(tMe,nRr),e(qc,sRr),e(qc,yK),e(yK,lRr),e(qc,iRr),e(Ot,dRr),M(h4,Ot,null),e(mr,cRr),e(mr,Dr),M(Ax,Dr,null),e(Dr,fRr),e(Dr,aMe),e(aMe,mRr),e(Dr,gRr),e(Dr,bn),e(bn,hRr),e(bn,nMe),e(nMe,pRr),e(bn,_Rr),e(bn,sMe),e(sMe,uRr),e(bn,bRr),e(bn,lMe),e(lMe,vRr),e(bn,FRr),e(Dr,TRr),e(Dr,iMe),e(iMe,p4),e(p4,dMe),e(dMe,MRr),e(p4,ERr),e(p4,xK),e(xK,CRr),e(p4,wRr),e(Dr,ARr),M(_4,Dr,null),b(f,bVe,u),b(f,jc,u),e(jc,u4),e(u4,cMe),M(Lx,cMe,null),e(jc,LRr),e(jc,fMe),e(fMe,yRr),b(f,vVe,u),b(f,gr,u),M(yx,gr,null),e(gr,xRr),e(gr,Dc),e(Dc,$Rr),e(Dc,$K),e($K,kRr),e(Dc,SRr),e(Dc,kK),e(kK,RRr),e(Dc,PRr),e(gr,BRr),e(gr,xx),e(xx,IRr),e(xx,mMe),e(mMe,NRr),e(xx,qRr),e(gr,jRr),e(gr,Vt),M($x,Vt,null),e(Vt,DRr),e(Vt,gMe),e(gMe,GRr),e(Vt,ORr),e(Vt,Gc),e(Gc,VRr),e(Gc,hMe),e(hMe,XRr),e(Gc,zRr),e(Gc,SK),e(SK,QRr),e(Gc,WRr),e(Vt,HRr),M(b4,Vt,null),e(gr,URr),e(gr,Gr),M(kx,Gr,null),e(Gr,JRr),e(Gr,pMe),e(pMe,YRr),e(Gr,KRr),e(Gr,vn),e(vn,ZRr),e(vn,_Me),e(_Me,ePr),e(vn,oPr),e(vn,uMe),e(uMe,rPr),e(vn,tPr),e(vn,bMe),e(bMe,aPr),e(vn,nPr),e(Gr,sPr),e(Gr,vMe),e(vMe,v4),e(v4,FMe),e(FMe,lPr),e(v4,iPr),e(v4,RK),e(RK,dPr),e(v4,cPr),e(Gr,fPr),M(F4,Gr,null),b(f,FVe,u),b(f,Oc,u),e(Oc,T4),e(T4,TMe),M(Sx,TMe,null),e(Oc,mPr),e(Oc,MMe),e(MMe,gPr),b(f,TVe,u),b(f,hr,u),M(Rx,hr,null),e(hr,hPr),e(hr,Vc),e(Vc,pPr),e(Vc,PK),e(PK,_Pr),e(Vc,uPr),e(Vc,BK),e(BK,bPr),e(Vc,vPr),e(hr,FPr),e(hr,Px),e(Px,TPr),e(Px,EMe),e(EMe,MPr),e(Px,EPr),e(hr,CPr),e(hr,Xt),M(Bx,Xt,null),e(Xt,wPr),e(Xt,CMe),e(CMe,APr),e(Xt,LPr),e(Xt,Xc),e(Xc,yPr),e(Xc,wMe),e(wMe,xPr),e(Xc,$Pr),e(Xc,IK),e(IK,kPr),e(Xc,SPr),e(Xt,RPr),M(M4,Xt,null),e(hr,PPr),e(hr,Or),M(Ix,Or,null),e(Or,BPr),e(Or,AMe),e(AMe,IPr),e(Or,NPr),e(Or,Fn),e(Fn,qPr),e(Fn,LMe),e(LMe,jPr),e(Fn,DPr),e(Fn,yMe),e(yMe,GPr),e(Fn,OPr),e(Fn,xMe),e(xMe,VPr),e(Fn,XPr),e(Or,zPr),e(Or,oe),e(oe,E4),e(E4,$Me),e($Me,QPr),e(E4,WPr),e(E4,NK),e(NK,HPr),e(E4,UPr),e(oe,JPr),e(oe,C4),e(C4,kMe),e(kMe,YPr),e(C4,KPr),e(C4,qK),e(qK,ZPr),e(C4,eBr),e(oe,oBr),e(oe,w4),e(w4,SMe),e(SMe,rBr),e(w4,tBr),e(w4,jK),e(jK,aBr),e(w4,nBr),e(oe,sBr),e(oe,A4),e(A4,RMe),e(RMe,lBr),e(A4,iBr),e(A4,DK),e(DK,dBr),e(A4,cBr),e(oe,fBr),e(oe,L4),e(L4,PMe),e(PMe,mBr),e(L4,gBr),e(L4,GK),e(GK,hBr),e(L4,pBr),e(oe,_Br),e(oe,y4),e(y4,BMe),e(BMe,uBr),e(y4,bBr),e(y4,OK),e(OK,vBr),e(y4,FBr),e(oe,TBr),e(oe,x4),e(x4,IMe),e(IMe,MBr),e(x4,EBr),e(x4,VK),e(VK,CBr),e(x4,wBr),e(oe,ABr),e(oe,$4),e($4,NMe),e(NMe,LBr),e($4,yBr),e($4,XK),e(XK,xBr),e($4,$Br),e(oe,kBr),e(oe,k4),e(k4,qMe),e(qMe,SBr),e(k4,RBr),e(k4,zK),e(zK,PBr),e(k4,BBr),e(oe,IBr),e(oe,S4),e(S4,jMe),e(jMe,NBr),e(S4,qBr),e(S4,QK),e(QK,jBr),e(S4,DBr),e(oe,GBr),e(oe,R4),e(R4,DMe),e(DMe,OBr),e(R4,VBr),e(R4,WK),e(WK,XBr),e(R4,zBr),e(oe,QBr),e(oe,P4),e(P4,GMe),e(GMe,WBr),e(P4,HBr),e(P4,HK),e(HK,UBr),e(P4,JBr),e(oe,YBr),e(oe,B4),e(B4,OMe),e(OMe,KBr),e(B4,ZBr),e(B4,UK),e(UK,eIr),e(B4,oIr),e(oe,rIr),e(oe,I4),e(I4,VMe),e(VMe,tIr),e(I4,aIr),e(I4,JK),e(JK,nIr),e(I4,sIr),e(oe,lIr),e(oe,N4),e(N4,XMe),e(XMe,iIr),e(N4,dIr),e(N4,YK),e(YK,cIr),e(N4,fIr),e(oe,mIr),e(oe,q4),e(q4,zMe),e(zMe,gIr),e(q4,hIr),e(q4,KK),e(KK,pIr),e(q4,_Ir),e(oe,uIr),e(oe,j4),e(j4,QMe),e(QMe,bIr),e(j4,vIr),e(j4,ZK),e(ZK,FIr),e(j4,TIr),e(oe,MIr),e(oe,D4),e(D4,WMe),e(WMe,EIr),e(D4,CIr),e(D4,eZ),e(eZ,wIr),e(D4,AIr),e(oe,LIr),e(oe,G4),e(G4,HMe),e(HMe,yIr),e(G4,xIr),e(G4,oZ),e(oZ,$Ir),e(G4,kIr),e(oe,SIr),e(oe,O4),e(O4,UMe),e(UMe,RIr),e(O4,PIr),e(O4,rZ),e(rZ,BIr),e(O4,IIr),e(oe,NIr),e(oe,V4),e(V4,JMe),e(JMe,qIr),e(V4,jIr),e(V4,tZ),e(tZ,DIr),e(V4,GIr),e(oe,OIr),e(oe,X4),e(X4,YMe),e(YMe,VIr),e(X4,XIr),e(X4,aZ),e(aZ,zIr),e(X4,QIr),e(oe,WIr),e(oe,z4),e(z4,KMe),e(KMe,HIr),e(z4,UIr),e(z4,nZ),e(nZ,JIr),e(z4,YIr),e(oe,KIr),e(oe,Q4),e(Q4,ZMe),e(ZMe,ZIr),e(Q4,eNr),e(Q4,sZ),e(sZ,oNr),e(Q4,rNr),e(oe,tNr),e(oe,W4),e(W4,eEe),e(eEe,aNr),e(W4,nNr),e(W4,lZ),e(lZ,sNr),e(W4,lNr),e(oe,iNr),e(oe,H4),e(H4,oEe),e(oEe,dNr),e(H4,cNr),e(H4,iZ),e(iZ,fNr),e(H4,mNr),e(oe,gNr),e(oe,U4),e(U4,rEe),e(rEe,hNr),e(U4,pNr),e(U4,dZ),e(dZ,_Nr),e(U4,uNr),e(Or,bNr),M(J4,Or,null),b(f,MVe,u),b(f,zc,u),e(zc,Y4),e(Y4,tEe),M(Nx,tEe,null),e(zc,vNr),e(zc,aEe),e(aEe,FNr),b(f,EVe,u),b(f,pr,u),M(qx,pr,null),e(pr,TNr),e(pr,Qc),e(Qc,MNr),e(Qc,cZ),e(cZ,ENr),e(Qc,CNr),e(Qc,fZ),e(fZ,wNr),e(Qc,ANr),e(pr,LNr),e(pr,jx),e(jx,yNr),e(jx,nEe),e(nEe,xNr),e(jx,$Nr),e(pr,kNr),e(pr,zt),M(Dx,zt,null),e(zt,SNr),e(zt,sEe),e(sEe,RNr),e(zt,PNr),e(zt,Wc),e(Wc,BNr),e(Wc,lEe),e(lEe,INr),e(Wc,NNr),e(Wc,mZ),e(mZ,qNr),e(Wc,jNr),e(zt,DNr),M(K4,zt,null),e(pr,GNr),e(pr,Vr),M(Gx,Vr,null),e(Vr,ONr),e(Vr,iEe),e(iEe,VNr),e(Vr,XNr),e(Vr,Tn),e(Tn,zNr),e(Tn,dEe),e(dEe,QNr),e(Tn,WNr),e(Tn,cEe),e(cEe,HNr),e(Tn,UNr),e(Tn,fEe),e(fEe,JNr),e(Tn,YNr),e(Vr,KNr),e(Vr,xe),e(xe,Z4),e(Z4,mEe),e(mEe,ZNr),e(Z4,eqr),e(Z4,gZ),e(gZ,oqr),e(Z4,rqr),e(xe,tqr),e(xe,eC),e(eC,gEe),e(gEe,aqr),e(eC,nqr),e(eC,hZ),e(hZ,sqr),e(eC,lqr),e(xe,iqr),e(xe,oC),e(oC,hEe),e(hEe,dqr),e(oC,cqr),e(oC,pZ),e(pZ,fqr),e(oC,mqr),e(xe,gqr),e(xe,rC),e(rC,pEe),e(pEe,hqr),e(rC,pqr),e(rC,_Z),e(_Z,_qr),e(rC,uqr),e(xe,bqr),e(xe,tC),e(tC,_Ee),e(_Ee,vqr),e(tC,Fqr),e(tC,uZ),e(uZ,Tqr),e(tC,Mqr),e(xe,Eqr),e(xe,aC),e(aC,uEe),e(uEe,Cqr),e(aC,wqr),e(aC,bZ),e(bZ,Aqr),e(aC,Lqr),e(xe,yqr),e(xe,nC),e(nC,bEe),e(bEe,xqr),e(nC,$qr),e(nC,vZ),e(vZ,kqr),e(nC,Sqr),e(xe,Rqr),e(xe,sC),e(sC,vEe),e(vEe,Pqr),e(sC,Bqr),e(sC,FZ),e(FZ,Iqr),e(sC,Nqr),e(xe,qqr),e(xe,lC),e(lC,FEe),e(FEe,jqr),e(lC,Dqr),e(lC,TZ),e(TZ,Gqr),e(lC,Oqr),e(xe,Vqr),e(xe,iC),e(iC,TEe),e(TEe,Xqr),e(iC,zqr),e(iC,MZ),e(MZ,Qqr),e(iC,Wqr),e(Vr,Hqr),M(dC,Vr,null),b(f,CVe,u),b(f,Hc,u),e(Hc,cC),e(cC,MEe),M(Ox,MEe,null),e(Hc,Uqr),e(Hc,EEe),e(EEe,Jqr),b(f,wVe,u),b(f,_r,u),M(Vx,_r,null),e(_r,Yqr),e(_r,Uc),e(Uc,Kqr),e(Uc,EZ),e(EZ,Zqr),e(Uc,ejr),e(Uc,CZ),e(CZ,ojr),e(Uc,rjr),e(_r,tjr),e(_r,Xx),e(Xx,ajr),e(Xx,CEe),e(CEe,njr),e(Xx,sjr),e(_r,ljr),e(_r,Qt),M(zx,Qt,null),e(Qt,ijr),e(Qt,wEe),e(wEe,djr),e(Qt,cjr),e(Qt,Jc),e(Jc,fjr),e(Jc,AEe),e(AEe,mjr),e(Jc,gjr),e(Jc,wZ),e(wZ,hjr),e(Jc,pjr),e(Qt,_jr),M(fC,Qt,null),e(_r,ujr),e(_r,Xr),M(Qx,Xr,null),e(Xr,bjr),e(Xr,LEe),e(LEe,vjr),e(Xr,Fjr),e(Xr,Mn),e(Mn,Tjr),e(Mn,yEe),e(yEe,Mjr),e(Mn,Ejr),e(Mn,xEe),e(xEe,Cjr),e(Mn,wjr),e(Mn,$Ee),e($Ee,Ajr),e(Mn,Ljr),e(Xr,yjr),e(Xr,Ee),e(Ee,mC),e(mC,kEe),e(kEe,xjr),e(mC,$jr),e(mC,AZ),e(AZ,kjr),e(mC,Sjr),e(Ee,Rjr),e(Ee,gC),e(gC,SEe),e(SEe,Pjr),e(gC,Bjr),e(gC,LZ),e(LZ,Ijr),e(gC,Njr),e(Ee,qjr),e(Ee,hC),e(hC,REe),e(REe,jjr),e(hC,Djr),e(hC,yZ),e(yZ,Gjr),e(hC,Ojr),e(Ee,Vjr),e(Ee,pC),e(pC,PEe),e(PEe,Xjr),e(pC,zjr),e(pC,xZ),e(xZ,Qjr),e(pC,Wjr),e(Ee,Hjr),e(Ee,_C),e(_C,BEe),e(BEe,Ujr),e(_C,Jjr),e(_C,$Z),e($Z,Yjr),e(_C,Kjr),e(Ee,Zjr),e(Ee,uC),e(uC,IEe),e(IEe,eDr),e(uC,oDr),e(uC,kZ),e(kZ,rDr),e(uC,tDr),e(Ee,aDr),e(Ee,bC),e(bC,NEe),e(NEe,nDr),e(bC,sDr),e(bC,SZ),e(SZ,lDr),e(bC,iDr),e(Ee,dDr),e(Ee,vC),e(vC,qEe),e(qEe,cDr),e(vC,fDr),e(vC,RZ),e(RZ,mDr),e(vC,gDr),e(Ee,hDr),e(Ee,FC),e(FC,jEe),e(jEe,pDr),e(FC,_Dr),e(FC,PZ),e(PZ,uDr),e(FC,bDr),e(Ee,vDr),e(Ee,TC),e(TC,DEe),e(DEe,FDr),e(TC,TDr),e(TC,BZ),e(BZ,MDr),e(TC,EDr),e(Ee,CDr),e(Ee,MC),e(MC,GEe),e(GEe,wDr),e(MC,ADr),e(MC,IZ),e(IZ,LDr),e(MC,yDr),e(Ee,xDr),e(Ee,EC),e(EC,OEe),e(OEe,$Dr),e(EC,kDr),e(EC,NZ),e(NZ,SDr),e(EC,RDr),e(Ee,PDr),e(Ee,CC),e(CC,VEe),e(VEe,BDr),e(CC,IDr),e(CC,qZ),e(qZ,NDr),e(CC,qDr),e(Xr,jDr),M(wC,Xr,null),b(f,AVe,u),b(f,Yc,u),e(Yc,AC),e(AC,XEe),M(Wx,XEe,null),e(Yc,DDr),e(Yc,zEe),e(zEe,GDr),b(f,LVe,u),b(f,ur,u),M(Hx,ur,null),e(ur,ODr),e(ur,Kc),e(Kc,VDr),e(Kc,jZ),e(jZ,XDr),e(Kc,zDr),e(Kc,DZ),e(DZ,QDr),e(Kc,WDr),e(ur,HDr),e(ur,Ux),e(Ux,UDr),e(Ux,QEe),e(QEe,JDr),e(Ux,YDr),e(ur,KDr),e(ur,Wt),M(Jx,Wt,null),e(Wt,ZDr),e(Wt,WEe),e(WEe,eGr),e(Wt,oGr),e(Wt,Zc),e(Zc,rGr),e(Zc,HEe),e(HEe,tGr),e(Zc,aGr),e(Zc,GZ),e(GZ,nGr),e(Zc,sGr),e(Wt,lGr),M(LC,Wt,null),e(ur,iGr),e(ur,zr),M(Yx,zr,null),e(zr,dGr),e(zr,UEe),e(UEe,cGr),e(zr,fGr),e(zr,En),e(En,mGr),e(En,JEe),e(JEe,gGr),e(En,hGr),e(En,YEe),e(YEe,pGr),e(En,_Gr),e(En,KEe),e(KEe,uGr),e(En,bGr),e(zr,vGr),e(zr,$e),e($e,yC),e(yC,ZEe),e(ZEe,FGr),e(yC,TGr),e(yC,OZ),e(OZ,MGr),e(yC,EGr),e($e,CGr),e($e,xC),e(xC,e4e),e(e4e,wGr),e(xC,AGr),e(xC,VZ),e(VZ,LGr),e(xC,yGr),e($e,xGr),e($e,$C),e($C,o4e),e(o4e,$Gr),e($C,kGr),e($C,XZ),e(XZ,SGr),e($C,RGr),e($e,PGr),e($e,kC),e(kC,r4e),e(r4e,BGr),e(kC,IGr),e(kC,zZ),e(zZ,NGr),e(kC,qGr),e($e,jGr),e($e,SC),e(SC,t4e),e(t4e,DGr),e(SC,GGr),e(SC,QZ),e(QZ,OGr),e(SC,VGr),e($e,XGr),e($e,RC),e(RC,a4e),e(a4e,zGr),e(RC,QGr),e(RC,WZ),e(WZ,WGr),e(RC,HGr),e($e,UGr),e($e,PC),e(PC,n4e),e(n4e,JGr),e(PC,YGr),e(PC,HZ),e(HZ,KGr),e(PC,ZGr),e($e,eOr),e($e,BC),e(BC,s4e),e(s4e,oOr),e(BC,rOr),e(BC,UZ),e(UZ,tOr),e(BC,aOr),e($e,nOr),e($e,IC),e(IC,l4e),e(l4e,sOr),e(IC,lOr),e(IC,JZ),e(JZ,iOr),e(IC,dOr),e($e,cOr),e($e,NC),e(NC,i4e),e(i4e,fOr),e(NC,mOr),e(NC,YZ),e(YZ,gOr),e(NC,hOr),e(zr,pOr),M(qC,zr,null),b(f,yVe,u),b(f,ef,u),e(ef,jC),e(jC,d4e),M(Kx,d4e,null),e(ef,_Or),e(ef,c4e),e(c4e,uOr),b(f,xVe,u),b(f,br,u),M(Zx,br,null),e(br,bOr),e(br,of),e(of,vOr),e(of,KZ),e(KZ,FOr),e(of,TOr),e(of,ZZ),e(ZZ,MOr),e(of,EOr),e(br,COr),e(br,e$),e(e$,wOr),e(e$,f4e),e(f4e,AOr),e(e$,LOr),e(br,yOr),e(br,Ht),M(o$,Ht,null),e(Ht,xOr),e(Ht,m4e),e(m4e,$Or),e(Ht,kOr),e(Ht,rf),e(rf,SOr),e(rf,g4e),e(g4e,ROr),e(rf,POr),e(rf,eee),e(eee,BOr),e(rf,IOr),e(Ht,NOr),M(DC,Ht,null),e(br,qOr),e(br,Qr),M(r$,Qr,null),e(Qr,jOr),e(Qr,h4e),e(h4e,DOr),e(Qr,GOr),e(Qr,Cn),e(Cn,OOr),e(Cn,p4e),e(p4e,VOr),e(Cn,XOr),e(Cn,_4e),e(_4e,zOr),e(Cn,QOr),e(Cn,u4e),e(u4e,WOr),e(Cn,HOr),e(Qr,UOr),e(Qr,ke),e(ke,GC),e(GC,b4e),e(b4e,JOr),e(GC,YOr),e(GC,oee),e(oee,KOr),e(GC,ZOr),e(ke,eVr),e(ke,OC),e(OC,v4e),e(v4e,oVr),e(OC,rVr),e(OC,ree),e(ree,tVr),e(OC,aVr),e(ke,nVr),e(ke,VC),e(VC,F4e),e(F4e,sVr),e(VC,lVr),e(VC,tee),e(tee,iVr),e(VC,dVr),e(ke,cVr),e(ke,XC),e(XC,T4e),e(T4e,fVr),e(XC,mVr),e(XC,aee),e(aee,gVr),e(XC,hVr),e(ke,pVr),e(ke,zC),e(zC,M4e),e(M4e,_Vr),e(zC,uVr),e(zC,nee),e(nee,bVr),e(zC,vVr),e(ke,FVr),e(ke,QC),e(QC,E4e),e(E4e,TVr),e(QC,MVr),e(QC,see),e(see,EVr),e(QC,CVr),e(ke,wVr),e(ke,WC),e(WC,C4e),e(C4e,AVr),e(WC,LVr),e(WC,lee),e(lee,yVr),e(WC,xVr),e(ke,$Vr),e(ke,HC),e(HC,w4e),e(w4e,kVr),e(HC,SVr),e(HC,iee),e(iee,RVr),e(HC,PVr),e(ke,BVr),e(ke,UC),e(UC,A4e),e(A4e,IVr),e(UC,NVr),e(UC,dee),e(dee,qVr),e(UC,jVr),e(ke,DVr),e(ke,JC),e(JC,L4e),e(L4e,GVr),e(JC,OVr),e(JC,cee),e(cee,VVr),e(JC,XVr),e(Qr,zVr),M(YC,Qr,null),b(f,$Ve,u),b(f,tf,u),e(tf,KC),e(KC,y4e),M(t$,y4e,null),e(tf,QVr),e(tf,x4e),e(x4e,WVr),b(f,kVe,u),b(f,vr,u),M(a$,vr,null),e(vr,HVr),e(vr,af),e(af,UVr),e(af,fee),e(fee,JVr),e(af,YVr),e(af,mee),e(mee,KVr),e(af,ZVr),e(vr,eXr),e(vr,n$),e(n$,oXr),e(n$,$4e),e($4e,rXr),e(n$,tXr),e(vr,aXr),e(vr,Ut),M(s$,Ut,null),e(Ut,nXr),e(Ut,k4e),e(k4e,sXr),e(Ut,lXr),e(Ut,nf),e(nf,iXr),e(nf,S4e),e(S4e,dXr),e(nf,cXr),e(nf,gee),e(gee,fXr),e(nf,mXr),e(Ut,gXr),M(ZC,Ut,null),e(vr,hXr),e(vr,Wr),M(l$,Wr,null),e(Wr,pXr),e(Wr,R4e),e(R4e,_Xr),e(Wr,uXr),e(Wr,wn),e(wn,bXr),e(wn,P4e),e(P4e,vXr),e(wn,FXr),e(wn,B4e),e(B4e,TXr),e(wn,MXr),e(wn,I4e),e(I4e,EXr),e(wn,CXr),e(Wr,wXr),e(Wr,Se),e(Se,e5),e(e5,N4e),e(N4e,AXr),e(e5,LXr),e(e5,hee),e(hee,yXr),e(e5,xXr),e(Se,$Xr),e(Se,o5),e(o5,q4e),e(q4e,kXr),e(o5,SXr),e(o5,pee),e(pee,RXr),e(o5,PXr),e(Se,BXr),e(Se,r5),e(r5,j4e),e(j4e,IXr),e(r5,NXr),e(r5,_ee),e(_ee,qXr),e(r5,jXr),e(Se,DXr),e(Se,t5),e(t5,D4e),e(D4e,GXr),e(t5,OXr),e(t5,uee),e(uee,VXr),e(t5,XXr),e(Se,zXr),e(Se,a5),e(a5,G4e),e(G4e,QXr),e(a5,WXr),e(a5,bee),e(bee,HXr),e(a5,UXr),e(Se,JXr),e(Se,n5),e(n5,O4e),e(O4e,YXr),e(n5,KXr),e(n5,vee),e(vee,ZXr),e(n5,ezr),e(Se,ozr),e(Se,s5),e(s5,V4e),e(V4e,rzr),e(s5,tzr),e(s5,Fee),e(Fee,azr),e(s5,nzr),e(Se,szr),e(Se,l5),e(l5,X4e),e(X4e,lzr),e(l5,izr),e(l5,Tee),e(Tee,dzr),e(l5,czr),e(Se,fzr),e(Se,i5),e(i5,z4e),e(z4e,mzr),e(i5,gzr),e(i5,Mee),e(Mee,hzr),e(i5,pzr),e(Se,_zr),e(Se,d5),e(d5,Q4e),e(Q4e,uzr),e(d5,bzr),e(d5,Eee),e(Eee,vzr),e(d5,Fzr),e(Wr,Tzr),M(c5,Wr,null),b(f,SVe,u),b(f,sf,u),e(sf,f5),e(f5,W4e),M(i$,W4e,null),e(sf,Mzr),e(sf,H4e),e(H4e,Ezr),b(f,RVe,u),b(f,Fr,u),M(d$,Fr,null),e(Fr,Czr),e(Fr,lf),e(lf,wzr),e(lf,Cee),e(Cee,Azr),e(lf,Lzr),e(lf,wee),e(wee,yzr),e(lf,xzr),e(Fr,$zr),e(Fr,c$),e(c$,kzr),e(c$,U4e),e(U4e,Szr),e(c$,Rzr),e(Fr,Pzr),e(Fr,Jt),M(f$,Jt,null),e(Jt,Bzr),e(Jt,J4e),e(J4e,Izr),e(Jt,Nzr),e(Jt,df),e(df,qzr),e(df,Y4e),e(Y4e,jzr),e(df,Dzr),e(df,Aee),e(Aee,Gzr),e(df,Ozr),e(Jt,Vzr),M(m5,Jt,null),e(Fr,Xzr),e(Fr,Hr),M(m$,Hr,null),e(Hr,zzr),e(Hr,K4e),e(K4e,Qzr),e(Hr,Wzr),e(Hr,An),e(An,Hzr),e(An,Z4e),e(Z4e,Uzr),e(An,Jzr),e(An,eCe),e(eCe,Yzr),e(An,Kzr),e(An,oCe),e(oCe,Zzr),e(An,eQr),e(Hr,oQr),e(Hr,Re),e(Re,g5),e(g5,rCe),e(rCe,rQr),e(g5,tQr),e(g5,Lee),e(Lee,aQr),e(g5,nQr),e(Re,sQr),e(Re,h5),e(h5,tCe),e(tCe,lQr),e(h5,iQr),e(h5,yee),e(yee,dQr),e(h5,cQr),e(Re,fQr),e(Re,p5),e(p5,aCe),e(aCe,mQr),e(p5,gQr),e(p5,xee),e(xee,hQr),e(p5,pQr),e(Re,_Qr),e(Re,_5),e(_5,nCe),e(nCe,uQr),e(_5,bQr),e(_5,$ee),e($ee,vQr),e(_5,FQr),e(Re,TQr),e(Re,u5),e(u5,sCe),e(sCe,MQr),e(u5,EQr),e(u5,kee),e(kee,CQr),e(u5,wQr),e(Re,AQr),e(Re,b5),e(b5,lCe),e(lCe,LQr),e(b5,yQr),e(b5,See),e(See,xQr),e(b5,$Qr),e(Re,kQr),e(Re,v5),e(v5,iCe),e(iCe,SQr),e(v5,RQr),e(v5,Ree),e(Ree,PQr),e(v5,BQr),e(Re,IQr),e(Re,F5),e(F5,dCe),e(dCe,NQr),e(F5,qQr),e(F5,Pee),e(Pee,jQr),e(F5,DQr),e(Re,GQr),e(Re,T5),e(T5,cCe),e(cCe,OQr),e(T5,VQr),e(T5,Bee),e(Bee,XQr),e(T5,zQr),e(Re,QQr),e(Re,M5),e(M5,fCe),e(fCe,WQr),e(M5,HQr),e(M5,Iee),e(Iee,UQr),e(M5,JQr),e(Hr,YQr),M(E5,Hr,null),b(f,PVe,u),b(f,cf,u),e(cf,C5),e(C5,mCe),M(g$,mCe,null),e(cf,KQr),e(cf,gCe),e(gCe,ZQr),b(f,BVe,u),b(f,Tr,u),M(h$,Tr,null),e(Tr,eWr),e(Tr,ff),e(ff,oWr),e(ff,Nee),e(Nee,rWr),e(ff,tWr),e(ff,qee),e(qee,aWr),e(ff,nWr),e(Tr,sWr),e(Tr,p$),e(p$,lWr),e(p$,hCe),e(hCe,iWr),e(p$,dWr),e(Tr,cWr),e(Tr,Yt),M(_$,Yt,null),e(Yt,fWr),e(Yt,pCe),e(pCe,mWr),e(Yt,gWr),e(Yt,mf),e(mf,hWr),e(mf,_Ce),e(_Ce,pWr),e(mf,_Wr),e(mf,jee),e(jee,uWr),e(mf,bWr),e(Yt,vWr),M(w5,Yt,null),e(Tr,FWr),e(Tr,Ur),M(u$,Ur,null),e(Ur,TWr),e(Ur,uCe),e(uCe,MWr),e(Ur,EWr),e(Ur,Ln),e(Ln,CWr),e(Ln,bCe),e(bCe,wWr),e(Ln,AWr),e(Ln,vCe),e(vCe,LWr),e(Ln,yWr),e(Ln,FCe),e(FCe,xWr),e(Ln,$Wr),e(Ur,kWr),e(Ur,Ve),e(Ve,A5),e(A5,TCe),e(TCe,SWr),e(A5,RWr),e(A5,Dee),e(Dee,PWr),e(A5,BWr),e(Ve,IWr),e(Ve,L5),e(L5,MCe),e(MCe,NWr),e(L5,qWr),e(L5,Gee),e(Gee,jWr),e(L5,DWr),e(Ve,GWr),e(Ve,y5),e(y5,ECe),e(ECe,OWr),e(y5,VWr),e(y5,Oee),e(Oee,XWr),e(y5,zWr),e(Ve,QWr),e(Ve,x5),e(x5,CCe),e(CCe,WWr),e(x5,HWr),e(x5,Vee),e(Vee,UWr),e(x5,JWr),e(Ve,YWr),e(Ve,$5),e($5,wCe),e(wCe,KWr),e($5,ZWr),e($5,Xee),e(Xee,eHr),e($5,oHr),e(Ve,rHr),e(Ve,k5),e(k5,ACe),e(ACe,tHr),e(k5,aHr),e(k5,zee),e(zee,nHr),e(k5,sHr),e(Ve,lHr),e(Ve,S5),e(S5,LCe),e(LCe,iHr),e(S5,dHr),e(S5,Qee),e(Qee,cHr),e(S5,fHr),e(Ve,mHr),e(Ve,R5),e(R5,yCe),e(yCe,gHr),e(R5,hHr),e(R5,Wee),e(Wee,pHr),e(R5,_Hr),e(Ur,uHr),M(P5,Ur,null),b(f,IVe,u),b(f,gf,u),e(gf,B5),e(B5,xCe),M(b$,xCe,null),e(gf,bHr),e(gf,$Ce),e($Ce,vHr),b(f,NVe,u),b(f,Mr,u),M(v$,Mr,null),e(Mr,FHr),e(Mr,hf),e(hf,THr),e(hf,Hee),e(Hee,MHr),e(hf,EHr),e(hf,Uee),e(Uee,CHr),e(hf,wHr),e(Mr,AHr),e(Mr,F$),e(F$,LHr),e(F$,kCe),e(kCe,yHr),e(F$,xHr),e(Mr,$Hr),e(Mr,Kt),M(T$,Kt,null),e(Kt,kHr),e(Kt,SCe),e(SCe,SHr),e(Kt,RHr),e(Kt,pf),e(pf,PHr),e(pf,RCe),e(RCe,BHr),e(pf,IHr),e(pf,Jee),e(Jee,NHr),e(pf,qHr),e(Kt,jHr),M(I5,Kt,null),e(Mr,DHr),e(Mr,Jr),M(M$,Jr,null),e(Jr,GHr),e(Jr,PCe),e(PCe,OHr),e(Jr,VHr),e(Jr,yn),e(yn,XHr),e(yn,BCe),e(BCe,zHr),e(yn,QHr),e(yn,ICe),e(ICe,WHr),e(yn,HHr),e(yn,NCe),e(NCe,UHr),e(yn,JHr),e(Jr,YHr),e(Jr,Xe),e(Xe,N5),e(N5,qCe),e(qCe,KHr),e(N5,ZHr),e(N5,Yee),e(Yee,eUr),e(N5,oUr),e(Xe,rUr),e(Xe,q5),e(q5,jCe),e(jCe,tUr),e(q5,aUr),e(q5,Kee),e(Kee,nUr),e(q5,sUr),e(Xe,lUr),e(Xe,j5),e(j5,DCe),e(DCe,iUr),e(j5,dUr),e(j5,Zee),e(Zee,cUr),e(j5,fUr),e(Xe,mUr),e(Xe,D5),e(D5,GCe),e(GCe,gUr),e(D5,hUr),e(D5,eoe),e(eoe,pUr),e(D5,_Ur),e(Xe,uUr),e(Xe,G5),e(G5,OCe),e(OCe,bUr),e(G5,vUr),e(G5,ooe),e(ooe,FUr),e(G5,TUr),e(Xe,MUr),e(Xe,O5),e(O5,VCe),e(VCe,EUr),e(O5,CUr),e(O5,roe),e(roe,wUr),e(O5,AUr),e(Xe,LUr),e(Xe,V5),e(V5,XCe),e(XCe,yUr),e(V5,xUr),e(V5,toe),e(toe,$Ur),e(V5,kUr),e(Xe,SUr),e(Xe,X5),e(X5,zCe),e(zCe,RUr),e(X5,PUr),e(X5,aoe),e(aoe,BUr),e(X5,IUr),e(Jr,NUr),M(z5,Jr,null),b(f,qVe,u),b(f,_f,u),e(_f,Q5),e(Q5,QCe),M(E$,QCe,null),e(_f,qUr),e(_f,WCe),e(WCe,jUr),b(f,jVe,u),b(f,Er,u),M(C$,Er,null),e(Er,DUr),e(Er,uf),e(uf,GUr),e(uf,noe),e(noe,OUr),e(uf,VUr),e(uf,soe),e(soe,XUr),e(uf,zUr),e(Er,QUr),e(Er,w$),e(w$,WUr),e(w$,HCe),e(HCe,HUr),e(w$,UUr),e(Er,JUr),e(Er,Zt),M(A$,Zt,null),e(Zt,YUr),e(Zt,UCe),e(UCe,KUr),e(Zt,ZUr),e(Zt,bf),e(bf,eJr),e(bf,JCe),e(JCe,oJr),e(bf,rJr),e(bf,loe),e(loe,tJr),e(bf,aJr),e(Zt,nJr),M(W5,Zt,null),e(Er,sJr),e(Er,Yr),M(L$,Yr,null),e(Yr,lJr),e(Yr,YCe),e(YCe,iJr),e(Yr,dJr),e(Yr,xn),e(xn,cJr),e(xn,KCe),e(KCe,fJr),e(xn,mJr),e(xn,ZCe),e(ZCe,gJr),e(xn,hJr),e(xn,e5e),e(e5e,pJr),e(xn,_Jr),e(Yr,uJr),e(Yr,o5e),e(o5e,H5),e(H5,r5e),e(r5e,bJr),e(H5,vJr),e(H5,ioe),e(ioe,FJr),e(H5,TJr),e(Yr,MJr),M(U5,Yr,null),b(f,DVe,u),b(f,vf,u),e(vf,J5),e(J5,t5e),M(y$,t5e,null),e(vf,EJr),e(vf,a5e),e(a5e,CJr),b(f,GVe,u),b(f,Cr,u),M(x$,Cr,null),e(Cr,wJr),e(Cr,Ff),e(Ff,AJr),e(Ff,doe),e(doe,LJr),e(Ff,yJr),e(Ff,coe),e(coe,xJr),e(Ff,$Jr),e(Cr,kJr),e(Cr,$$),e($$,SJr),e($$,n5e),e(n5e,RJr),e($$,PJr),e(Cr,BJr),e(Cr,ea),M(k$,ea,null),e(ea,IJr),e(ea,s5e),e(s5e,NJr),e(ea,qJr),e(ea,Tf),e(Tf,jJr),e(Tf,l5e),e(l5e,DJr),e(Tf,GJr),e(Tf,foe),e(foe,OJr),e(Tf,VJr),e(ea,XJr),M(Y5,ea,null),e(Cr,zJr),e(Cr,Kr),M(S$,Kr,null),e(Kr,QJr),e(Kr,i5e),e(i5e,WJr),e(Kr,HJr),e(Kr,$n),e($n,UJr),e($n,d5e),e(d5e,JJr),e($n,YJr),e($n,c5e),e(c5e,KJr),e($n,ZJr),e($n,f5e),e(f5e,eYr),e($n,oYr),e(Kr,rYr),e(Kr,R$),e(R$,K5),e(K5,m5e),e(m5e,tYr),e(K5,aYr),e(K5,moe),e(moe,nYr),e(K5,sYr),e(R$,lYr),e(R$,Z5),e(Z5,g5e),e(g5e,iYr),e(Z5,dYr),e(Z5,goe),e(goe,cYr),e(Z5,fYr),e(Kr,mYr),M(e3,Kr,null),b(f,OVe,u),b(f,Mf,u),e(Mf,o3),e(o3,h5e),M(P$,h5e,null),e(Mf,gYr),e(Mf,p5e),e(p5e,hYr),b(f,VVe,u),b(f,wr,u),M(B$,wr,null),e(wr,pYr),e(wr,Ef),e(Ef,_Yr),e(Ef,hoe),e(hoe,uYr),e(Ef,bYr),e(Ef,poe),e(poe,vYr),e(Ef,FYr),e(wr,TYr),e(wr,I$),e(I$,MYr),e(I$,_5e),e(_5e,EYr),e(I$,CYr),e(wr,wYr),e(wr,oa),M(N$,oa,null),e(oa,AYr),e(oa,u5e),e(u5e,LYr),e(oa,yYr),e(oa,Cf),e(Cf,xYr),e(Cf,b5e),e(b5e,$Yr),e(Cf,kYr),e(Cf,_oe),e(_oe,SYr),e(Cf,RYr),e(oa,PYr),M(r3,oa,null),e(wr,BYr),e(wr,Zr),M(q$,Zr,null),e(Zr,IYr),e(Zr,v5e),e(v5e,NYr),e(Zr,qYr),e(Zr,kn),e(kn,jYr),e(kn,F5e),e(F5e,DYr),e(kn,GYr),e(kn,T5e),e(T5e,OYr),e(kn,VYr),e(kn,M5e),e(M5e,XYr),e(kn,zYr),e(Zr,QYr),e(Zr,E5e),e(E5e,t3),e(t3,C5e),e(C5e,WYr),e(t3,HYr),e(t3,uoe),e(uoe,UYr),e(t3,JYr),e(Zr,YYr),M(a3,Zr,null),XVe=!0},p(f,[u]){const j$={};u&2&&(j$.$$scope={dirty:u,ctx:f}),Rf.$set(j$);const w5e={};u&2&&(w5e.$$scope={dirty:u,ctx:f}),Gg.$set(w5e);const A5e={};u&2&&(A5e.$$scope={dirty:u,ctx:f}),Eh.$set(A5e);const L5e={};u&2&&(L5e.$$scope={dirty:u,ctx:f}),ap.$set(L5e);const D$={};u&2&&(D$.$$scope={dirty:u,ctx:f}),np.$set(D$);const y5e={};u&2&&(y5e.$$scope={dirty:u,ctx:f}),wp.$set(y5e);const Sn={};u&2&&(Sn.$$scope={dirty:u,ctx:f}),Ap.$set(Sn);const x5e={};u&2&&(x5e.$$scope={dirty:u,ctx:f}),xp.$set(x5e);const $5e={};u&2&&($5e.$$scope={dirty:u,ctx:f}),xu.$set($5e);const k5e={};u&2&&(k5e.$$scope={dirty:u,ctx:f}),ku.$set(k5e);const G$={};u&2&&(G$.$$scope={dirty:u,ctx:f}),E1.$set(G$);const S5e={};u&2&&(S5e.$$scope={dirty:u,ctx:f}),w1.$set(S5e);const O$={};u&2&&(O$.$$scope={dirty:u,ctx:f}),f2.$set(O$);const R5e={};u&2&&(R5e.$$scope={dirty:u,ctx:f}),g2.$set(R5e);const V$={};u&2&&(V$.$$scope={dirty:u,ctx:f}),K2.$set(V$);const P5e={};u&2&&(P5e.$$scope={dirty:u,ctx:f}),eb.$set(P5e);const B5e={};u&2&&(B5e.$$scope={dirty:u,ctx:f}),vb.$set(B5e);const I5e={};u&2&&(I5e.$$scope={dirty:u,ctx:f}),Tb.$set(I5e);const wf={};u&2&&(wf.$$scope={dirty:u,ctx:f}),bv.$set(wf);const N5e={};u&2&&(N5e.$$scope={dirty:u,ctx:f}),Fv.$set(N5e);const q5e={};u&2&&(q5e.$$scope={dirty:u,ctx:f}),Kv.$set(q5e);const j5e={};u&2&&(j5e.$$scope={dirty:u,ctx:f}),eF.$set(j5e);const X$={};u&2&&(X$.$$scope={dirty:u,ctx:f}),iF.$set(X$);const D5e={};u&2&&(D5e.$$scope={dirty:u,ctx:f}),cF.$set(D5e);const G5e={};u&2&&(G5e.$$scope={dirty:u,ctx:f}),HF.$set(G5e);const O5e={};u&2&&(O5e.$$scope={dirty:u,ctx:f}),JF.$set(O5e);const rt={};u&2&&(rt.$$scope={dirty:u,ctx:f}),j6.$set(rt);const z$={};u&2&&(z$.$$scope={dirty:u,ctx:f}),G6.$set(z$);const V5e={};u&2&&(V5e.$$scope={dirty:u,ctx:f}),X6.$set(V5e);const Q$={};u&2&&(Q$.$$scope={dirty:u,ctx:f}),Q6.$set(Q$);const X5e={};u&2&&(X5e.$$scope={dirty:u,ctx:f}),sT.$set(X5e);const tt={};u&2&&(tt.$$scope={dirty:u,ctx:f}),iT.$set(tt);const z5e={};u&2&&(z5e.$$scope={dirty:u,ctx:f}),fT.$set(z5e);const Af={};u&2&&(Af.$$scope={dirty:u,ctx:f}),gT.$set(Af);const Q5e={};u&2&&(Q5e.$$scope={dirty:u,ctx:f}),_T.$set(Q5e);const W5e={};u&2&&(W5e.$$scope={dirty:u,ctx:f}),bT.$set(W5e);const L={};u&2&&(L.$$scope={dirty:u,ctx:f}),xT.$set(L);const n3={};u&2&&(n3.$$scope={dirty:u,ctx:f}),kT.$set(n3);const H5e={};u&2&&(H5e.$$scope={dirty:u,ctx:f}),qT.$set(H5e);const U5e={};u&2&&(U5e.$$scope={dirty:u,ctx:f}),DT.$set(U5e);const s3={};u&2&&(s3.$$scope={dirty:u,ctx:f}),KT.$set(s3);const J5e={};u&2&&(J5e.$$scope={dirty:u,ctx:f}),e7.$set(J5e);const Y5e={};u&2&&(Y5e.$$scope={dirty:u,ctx:f}),a7.$set(Y5e);const l3={};u&2&&(l3.$$scope={dirty:u,ctx:f}),s7.$set(l3);const K5e={};u&2&&(K5e.$$scope={dirty:u,ctx:f}),g7.$set(K5e);const Z5e={};u&2&&(Z5e.$$scope={dirty:u,ctx:f}),p7.$set(Z5e);const i3={};u&2&&(i3.$$scope={dirty:u,ctx:f}),F7.$set(i3);const e3e={};u&2&&(e3e.$$scope={dirty:u,ctx:f}),M7.$set(e3e);const o3e={};u&2&&(o3e.$$scope={dirty:u,ctx:f}),A7.$set(o3e);const d3={};u&2&&(d3.$$scope={dirty:u,ctx:f}),y7.$set(d3);const r3e={};u&2&&(r3e.$$scope={dirty:u,ctx:f}),k7.$set(r3e);const t3e={};u&2&&(t3e.$$scope={dirty:u,ctx:f}),R7.$set(t3e);const c3={};u&2&&(c3.$$scope={dirty:u,ctx:f}),j7.$set(c3);const a3e={};u&2&&(a3e.$$scope={dirty:u,ctx:f}),G7.$set(a3e);const n3e={};u&2&&(n3e.$$scope={dirty:u,ctx:f}),X7.$set(n3e);const f3={};u&2&&(f3.$$scope={dirty:u,ctx:f}),Q7.$set(f3);const s3e={};u&2&&(s3e.$$scope={dirty:u,ctx:f}),j8.$set(s3e);const l3e={};u&2&&(l3e.$$scope={dirty:u,ctx:f}),G8.$set(l3e);const m3={};u&2&&(m3.$$scope={dirty:u,ctx:f}),f9.$set(m3);const i3e={};u&2&&(i3e.$$scope={dirty:u,ctx:f}),g9.$set(i3e);const d3e={};u&2&&(d3e.$$scope={dirty:u,ctx:f}),L9.$set(d3e);const g3={};u&2&&(g3.$$scope={dirty:u,ctx:f}),x9.$set(g3);const c3e={};u&2&&(c3e.$$scope={dirty:u,ctx:f}),P9.$set(c3e);const f3e={};u&2&&(f3e.$$scope={dirty:u,ctx:f}),I9.$set(f3e);const h3={};u&2&&(h3.$$scope={dirty:u,ctx:f}),tM.$set(h3);const m3e={};u&2&&(m3e.$$scope={dirty:u,ctx:f}),nM.$set(m3e);const g3e={};u&2&&(g3e.$$scope={dirty:u,ctx:f}),_M.$set(g3e);const p3={};u&2&&(p3.$$scope={dirty:u,ctx:f}),bM.$set(p3);const h3e={};u&2&&(h3e.$$scope={dirty:u,ctx:f}),zM.$set(h3e);const p3e={};u&2&&(p3e.$$scope={dirty:u,ctx:f}),WM.$set(p3e);const _3={};u&2&&(_3.$$scope={dirty:u,ctx:f}),fE.$set(_3);const _3e={};u&2&&(_3e.$$scope={dirty:u,ctx:f}),gE.$set(_3e);const u3e={};u&2&&(u3e.$$scope={dirty:u,ctx:f}),_E.$set(u3e);const u3={};u&2&&(u3.$$scope={dirty:u,ctx:f}),bE.$set(u3);const b3e={};u&2&&(b3e.$$scope={dirty:u,ctx:f}),FE.$set(b3e);const v3e={};u&2&&(v3e.$$scope={dirty:u,ctx:f}),ME.$set(v3e);const b3={};u&2&&(b3.$$scope={dirty:u,ctx:f}),VE.$set(b3);const F3e={};u&2&&(F3e.$$scope={dirty:u,ctx:f}),zE.$set(F3e);const T3e={};u&2&&(T3e.$$scope={dirty:u,ctx:f}),m4.$set(T3e);const v3={};u&2&&(v3.$$scope={dirty:u,ctx:f}),h4.$set(v3);const M3e={};u&2&&(M3e.$$scope={dirty:u,ctx:f}),_4.$set(M3e);const E3e={};u&2&&(E3e.$$scope={dirty:u,ctx:f}),b4.$set(E3e);const F3={};u&2&&(F3.$$scope={dirty:u,ctx:f}),F4.$set(F3);const C3e={};u&2&&(C3e.$$scope={dirty:u,ctx:f}),M4.$set(C3e);const w3e={};u&2&&(w3e.$$scope={dirty:u,ctx:f}),J4.$set(w3e);const T3={};u&2&&(T3.$$scope={dirty:u,ctx:f}),K4.$set(T3);const A3e={};u&2&&(A3e.$$scope={dirty:u,ctx:f}),dC.$set(A3e);const L3e={};u&2&&(L3e.$$scope={dirty:u,ctx:f}),fC.$set(L3e);const M3={};u&2&&(M3.$$scope={dirty:u,ctx:f}),wC.$set(M3);const y3e={};u&2&&(y3e.$$scope={dirty:u,ctx:f}),LC.$set(y3e);const x3e={};u&2&&(x3e.$$scope={dirty:u,ctx:f}),qC.$set(x3e);const E3={};u&2&&(E3.$$scope={dirty:u,ctx:f}),DC.$set(E3);const $3e={};u&2&&($3e.$$scope={dirty:u,ctx:f}),YC.$set($3e);const k3e={};u&2&&(k3e.$$scope={dirty:u,ctx:f}),ZC.$set(k3e);const C3={};u&2&&(C3.$$scope={dirty:u,ctx:f}),c5.$set(C3);const S3e={};u&2&&(S3e.$$scope={dirty:u,ctx:f}),m5.$set(S3e);const R3e={};u&2&&(R3e.$$scope={dirty:u,ctx:f}),E5.$set(R3e);const w3={};u&2&&(w3.$$scope={dirty:u,ctx:f}),w5.$set(w3);const P3e={};u&2&&(P3e.$$scope={dirty:u,ctx:f}),P5.$set(P3e);const B3e={};u&2&&(B3e.$$scope={dirty:u,ctx:f}),I5.$set(B3e);const A3={};u&2&&(A3.$$scope={dirty:u,ctx:f}),z5.$set(A3);const I3e={};u&2&&(I3e.$$scope={dirty:u,ctx:f}),W5.$set(I3e);const N3e={};u&2&&(N3e.$$scope={dirty:u,ctx:f}),U5.$set(N3e);const L3={};u&2&&(L3.$$scope={dirty:u,ctx:f}),Y5.$set(L3);const q3e={};u&2&&(q3e.$$scope={dirty:u,ctx:f}),e3.$set(q3e);const j3e={};u&2&&(j3e.$$scope={dirty:u,ctx:f}),r3.$set(j3e);const y3={};u&2&&(y3.$$scope={dirty:u,ctx:f}),a3.$set(y3)},i(f){XVe||(E(d.$$.fragment,f),E(xa.$$.fragment,f),E(xw.$$.fragment,f),E($w.$$.fragment,f),E(Rf.$$.fragment,f),E(kw.$$.fragment,f),E(Sw.$$.fragment,f),E(Bw.$$.fragment,f),E(Gg.$$.fragment,f),E(Iw.$$.fragment,f),E(Nw.$$.fragment,f),E(qw.$$.fragment,f),E(Gw.$$.fragment,f),E(Eh.$$.fragment,f),E(Ow.$$.fragment,f),E(Vw.$$.fragment,f),E(Xw.$$.fragment,f),E(Ww.$$.fragment,f),E(ap.$$.fragment,f),E(np.$$.fragment,f),E(Hw.$$.fragment,f),E(Uw.$$.fragment,f),E(Jw.$$.fragment,f),E(Zw.$$.fragment,f),E(wp.$$.fragment,f),E(Ap.$$.fragment,f),E(eA.$$.fragment,f),E(oA.$$.fragment,f),E(rA.$$.fragment,f),E(aA.$$.fragment,f),E(xp.$$.fragment,f),E(nA.$$.fragment,f),E(xu.$$.fragment,f),E(sA.$$.fragment,f),E(lA.$$.fragment,f),E(dA.$$.fragment,f),E(ku.$$.fragment,f),E(cA.$$.fragment,f),E(E1.$$.fragment,f),E(fA.$$.fragment,f),E(mA.$$.fragment,f),E(hA.$$.fragment,f),E(w1.$$.fragment,f),E(pA.$$.fragment,f),E(f2.$$.fragment,f),E(_A.$$.fragment,f),E(uA.$$.fragment,f),E(vA.$$.fragment,f),E(g2.$$.fragment,f),E(FA.$$.fragment,f),E(K2.$$.fragment,f),E(TA.$$.fragment,f),E(MA.$$.fragment,f),E(CA.$$.fragment,f),E(eb.$$.fragment,f),E(wA.$$.fragment,f),E(vb.$$.fragment,f),E(AA.$$.fragment,f),E(LA.$$.fragment,f),E(xA.$$.fragment,f),E(Tb.$$.fragment,f),E($A.$$.fragment,f),E(bv.$$.fragment,f),E(kA.$$.fragment,f),E(SA.$$.fragment,f),E(PA.$$.fragment,f),E(Fv.$$.fragment,f),E(BA.$$.fragment,f),E(Kv.$$.fragment,f),E(IA.$$.fragment,f),E(NA.$$.fragment,f),E(jA.$$.fragment,f),E(eF.$$.fragment,f),E(DA.$$.fragment,f),E(iF.$$.fragment,f),E(GA.$$.fragment,f),E(OA.$$.fragment,f),E(XA.$$.fragment,f),E(cF.$$.fragment,f),E(zA.$$.fragment,f),E(HF.$$.fragment,f),E(QA.$$.fragment,f),E(WA.$$.fragment,f),E(UA.$$.fragment,f),E(JF.$$.fragment,f),E(JA.$$.fragment,f),E(j6.$$.fragment,f),E(YA.$$.fragment,f),E(KA.$$.fragment,f),E(eL.$$.fragment,f),E(G6.$$.fragment,f),E(oL.$$.fragment,f),E(X6.$$.fragment,f),E(rL.$$.fragment,f),E(tL.$$.fragment,f),E(nL.$$.fragment,f),E(Q6.$$.fragment,f),E(sL.$$.fragment,f),E(sT.$$.fragment,f),E(lL.$$.fragment,f),E(iL.$$.fragment,f),E(cL.$$.fragment,f),E(iT.$$.fragment,f),E(fL.$$.fragment,f),E(fT.$$.fragment,f),E(mL.$$.fragment,f),E(gL.$$.fragment,f),E(pL.$$.fragment,f),E(gT.$$.fragment,f),E(_L.$$.fragment,f),E(_T.$$.fragment,f),E(uL.$$.fragment,f),E(bL.$$.fragment,f),E(FL.$$.fragment,f),E(bT.$$.fragment,f),E(TL.$$.fragment,f),E(xT.$$.fragment,f),E(ML.$$.fragment,f),E(EL.$$.fragment,f),E(wL.$$.fragment,f),E(kT.$$.fragment,f),E(AL.$$.fragment,f),E(qT.$$.fragment,f),E(LL.$$.fragment,f),E(yL.$$.fragment,f),E($L.$$.fragment,f),E(DT.$$.fragment,f),E(kL.$$.fragment,f),E(KT.$$.fragment,f),E(SL.$$.fragment,f),E(RL.$$.fragment,f),E(BL.$$.fragment,f),E(e7.$$.fragment,f),E(IL.$$.fragment,f),E(a7.$$.fragment,f),E(qL.$$.fragment,f),E(jL.$$.fragment,f),E(GL.$$.fragment,f),E(s7.$$.fragment,f),E(OL.$$.fragment,f),E(g7.$$.fragment,f),E(VL.$$.fragment,f),E(XL.$$.fragment,f),E(QL.$$.fragment,f),E(p7.$$.fragment,f),E(WL.$$.fragment,f),E(F7.$$.fragment,f),E(HL.$$.fragment,f),E(UL.$$.fragment,f),E(YL.$$.fragment,f),E(M7.$$.fragment,f),E(KL.$$.fragment,f),E(A7.$$.fragment,f),E(ey.$$.fragment,f),E(oy.$$.fragment,f),E(ty.$$.fragment,f),E(y7.$$.fragment,f),E(ay.$$.fragment,f),E(k7.$$.fragment,f),E(ny.$$.fragment,f),E(sy.$$.fragment,f),E(iy.$$.fragment,f),E(R7.$$.fragment,f),E(dy.$$.fragment,f),E(j7.$$.fragment,f),E(cy.$$.fragment,f),E(fy.$$.fragment,f),E(gy.$$.fragment,f),E(G7.$$.fragment,f),E(hy.$$.fragment,f),E(X7.$$.fragment,f),E(py.$$.fragment,f),E(_y.$$.fragment,f),E(by.$$.fragment,f),E(Q7.$$.fragment,f),E(vy.$$.fragment,f),E(j8.$$.fragment,f),E(Fy.$$.fragment,f),E(Ty.$$.fragment,f),E(Ey.$$.fragment,f),E(G8.$$.fragment,f),E(Cy.$$.fragment,f),E(f9.$$.fragment,f),E(wy.$$.fragment,f),E(Ay.$$.fragment,f),E(yy.$$.fragment,f),E(g9.$$.fragment,f),E(xy.$$.fragment,f),E(L9.$$.fragment,f),E($y.$$.fragment,f),E(ky.$$.fragment,f),E(Ry.$$.fragment,f),E(x9.$$.fragment,f),E(Py.$$.fragment,f),E(P9.$$.fragment,f),E(By.$$.fragment,f),E(Iy.$$.fragment,f),E(qy.$$.fragment,f),E(I9.$$.fragment,f),E(jy.$$.fragment,f),E(tM.$$.fragment,f),E(Dy.$$.fragment,f),E(Gy.$$.fragment,f),E(Vy.$$.fragment,f),E(nM.$$.fragment,f),E(Xy.$$.fragment,f),E(_M.$$.fragment,f),E(zy.$$.fragment,f),E(Qy.$$.fragment,f),E(Hy.$$.fragment,f),E(bM.$$.fragment,f),E(Uy.$$.fragment,f),E(zM.$$.fragment,f),E(Jy.$$.fragment,f),E(Yy.$$.fragment,f),E(Zy.$$.fragment,f),E(WM.$$.fragment,f),E(ex.$$.fragment,f),E(fE.$$.fragment,f),E(ox.$$.fragment,f),E(rx.$$.fragment,f),E(ax.$$.fragment,f),E(gE.$$.fragment,f),E(nx.$$.fragment,f),E(_E.$$.fragment,f),E(lx.$$.fragment,f),E(ix.$$.fragment,f),E(cx.$$.fragment,f),E(bE.$$.fragment,f),E(fx.$$.fragment,f),E(FE.$$.fragment,f),E(mx.$$.fragment,f),E(gx.$$.fragment,f),E(px.$$.fragment,f),E(ME.$$.fragment,f),E(_x.$$.fragment,f),E(VE.$$.fragment,f),E(ux.$$.fragment,f),E(bx.$$.fragment,f),E(Fx.$$.fragment,f),E(zE.$$.fragment,f),E(Tx.$$.fragment,f),E(m4.$$.fragment,f),E(Mx.$$.fragment,f),E(Ex.$$.fragment,f),E(wx.$$.fragment,f),E(h4.$$.fragment,f),E(Ax.$$.fragment,f),E(_4.$$.fragment,f),E(Lx.$$.fragment,f),E(yx.$$.fragment,f),E($x.$$.fragment,f),E(b4.$$.fragment,f),E(kx.$$.fragment,f),E(F4.$$.fragment,f),E(Sx.$$.fragment,f),E(Rx.$$.fragment,f),E(Bx.$$.fragment,f),E(M4.$$.fragment,f),E(Ix.$$.fragment,f),E(J4.$$.fragment,f),E(Nx.$$.fragment,f),E(qx.$$.fragment,f),E(Dx.$$.fragment,f),E(K4.$$.fragment,f),E(Gx.$$.fragment,f),E(dC.$$.fragment,f),E(Ox.$$.fragment,f),E(Vx.$$.fragment,f),E(zx.$$.fragment,f),E(fC.$$.fragment,f),E(Qx.$$.fragment,f),E(wC.$$.fragment,f),E(Wx.$$.fragment,f),E(Hx.$$.fragment,f),E(Jx.$$.fragment,f),E(LC.$$.fragment,f),E(Yx.$$.fragment,f),E(qC.$$.fragment,f),E(Kx.$$.fragment,f),E(Zx.$$.fragment,f),E(o$.$$.fragment,f),E(DC.$$.fragment,f),E(r$.$$.fragment,f),E(YC.$$.fragment,f),E(t$.$$.fragment,f),E(a$.$$.fragment,f),E(s$.$$.fragment,f),E(ZC.$$.fragment,f),E(l$.$$.fragment,f),E(c5.$$.fragment,f),E(i$.$$.fragment,f),E(d$.$$.fragment,f),E(f$.$$.fragment,f),E(m5.$$.fragment,f),E(m$.$$.fragment,f),E(E5.$$.fragment,f),E(g$.$$.fragment,f),E(h$.$$.fragment,f),E(_$.$$.fragment,f),E(w5.$$.fragment,f),E(u$.$$.fragment,f),E(P5.$$.fragment,f),E(b$.$$.fragment,f),E(v$.$$.fragment,f),E(T$.$$.fragment,f),E(I5.$$.fragment,f),E(M$.$$.fragment,f),E(z5.$$.fragment,f),E(E$.$$.fragment,f),E(C$.$$.fragment,f),E(A$.$$.fragment,f),E(W5.$$.fragment,f),E(L$.$$.fragment,f),E(U5.$$.fragment,f),E(y$.$$.fragment,f),E(x$.$$.fragment,f),E(k$.$$.fragment,f),E(Y5.$$.fragment,f),E(S$.$$.fragment,f),E(e3.$$.fragment,f),E(P$.$$.fragment,f),E(B$.$$.fragment,f),E(N$.$$.fragment,f),E(r3.$$.fragment,f),E(q$.$$.fragment,f),E(a3.$$.fragment,f),XVe=!0)},o(f){C(d.$$.fragment,f),C(xa.$$.fragment,f),C(xw.$$.fragment,f),C($w.$$.fragment,f),C(Rf.$$.fragment,f),C(kw.$$.fragment,f),C(Sw.$$.fragment,f),C(Bw.$$.fragment,f),C(Gg.$$.fragment,f),C(Iw.$$.fragment,f),C(Nw.$$.fragment,f),C(qw.$$.fragment,f),C(Gw.$$.fragment,f),C(Eh.$$.fragment,f),C(Ow.$$.fragment,f),C(Vw.$$.fragment,f),C(Xw.$$.fragment,f),C(Ww.$$.fragment,f),C(ap.$$.fragment,f),C(np.$$.fragment,f),C(Hw.$$.fragment,f),C(Uw.$$.fragment,f),C(Jw.$$.fragment,f),C(Zw.$$.fragment,f),C(wp.$$.fragment,f),C(Ap.$$.fragment,f),C(eA.$$.fragment,f),C(oA.$$.fragment,f),C(rA.$$.fragment,f),C(aA.$$.fragment,f),C(xp.$$.fragment,f),C(nA.$$.fragment,f),C(xu.$$.fragment,f),C(sA.$$.fragment,f),C(lA.$$.fragment,f),C(dA.$$.fragment,f),C(ku.$$.fragment,f),C(cA.$$.fragment,f),C(E1.$$.fragment,f),C(fA.$$.fragment,f),C(mA.$$.fragment,f),C(hA.$$.fragment,f),C(w1.$$.fragment,f),C(pA.$$.fragment,f),C(f2.$$.fragment,f),C(_A.$$.fragment,f),C(uA.$$.fragment,f),C(vA.$$.fragment,f),C(g2.$$.fragment,f),C(FA.$$.fragment,f),C(K2.$$.fragment,f),C(TA.$$.fragment,f),C(MA.$$.fragment,f),C(CA.$$.fragment,f),C(eb.$$.fragment,f),C(wA.$$.fragment,f),C(vb.$$.fragment,f),C(AA.$$.fragment,f),C(LA.$$.fragment,f),C(xA.$$.fragment,f),C(Tb.$$.fragment,f),C($A.$$.fragment,f),C(bv.$$.fragment,f),C(kA.$$.fragment,f),C(SA.$$.fragment,f),C(PA.$$.fragment,f),C(Fv.$$.fragment,f),C(BA.$$.fragment,f),C(Kv.$$.fragment,f),C(IA.$$.fragment,f),C(NA.$$.fragment,f),C(jA.$$.fragment,f),C(eF.$$.fragment,f),C(DA.$$.fragment,f),C(iF.$$.fragment,f),C(GA.$$.fragment,f),C(OA.$$.fragment,f),C(XA.$$.fragment,f),C(cF.$$.fragment,f),C(zA.$$.fragment,f),C(HF.$$.fragment,f),C(QA.$$.fragment,f),C(WA.$$.fragment,f),C(UA.$$.fragment,f),C(JF.$$.fragment,f),C(JA.$$.fragment,f),C(j6.$$.fragment,f),C(YA.$$.fragment,f),C(KA.$$.fragment,f),C(eL.$$.fragment,f),C(G6.$$.fragment,f),C(oL.$$.fragment,f),C(X6.$$.fragment,f),C(rL.$$.fragment,f),C(tL.$$.fragment,f),C(nL.$$.fragment,f),C(Q6.$$.fragment,f),C(sL.$$.fragment,f),C(sT.$$.fragment,f),C(lL.$$.fragment,f),C(iL.$$.fragment,f),C(cL.$$.fragment,f),C(iT.$$.fragment,f),C(fL.$$.fragment,f),C(fT.$$.fragment,f),C(mL.$$.fragment,f),C(gL.$$.fragment,f),C(pL.$$.fragment,f),C(gT.$$.fragment,f),C(_L.$$.fragment,f),C(_T.$$.fragment,f),C(uL.$$.fragment,f),C(bL.$$.fragment,f),C(FL.$$.fragment,f),C(bT.$$.fragment,f),C(TL.$$.fragment,f),C(xT.$$.fragment,f),C(ML.$$.fragment,f),C(EL.$$.fragment,f),C(wL.$$.fragment,f),C(kT.$$.fragment,f),C(AL.$$.fragment,f),C(qT.$$.fragment,f),C(LL.$$.fragment,f),C(yL.$$.fragment,f),C($L.$$.fragment,f),C(DT.$$.fragment,f),C(kL.$$.fragment,f),C(KT.$$.fragment,f),C(SL.$$.fragment,f),C(RL.$$.fragment,f),C(BL.$$.fragment,f),C(e7.$$.fragment,f),C(IL.$$.fragment,f),C(a7.$$.fragment,f),C(qL.$$.fragment,f),C(jL.$$.fragment,f),C(GL.$$.fragment,f),C(s7.$$.fragment,f),C(OL.$$.fragment,f),C(g7.$$.fragment,f),C(VL.$$.fragment,f),C(XL.$$.fragment,f),C(QL.$$.fragment,f),C(p7.$$.fragment,f),C(WL.$$.fragment,f),C(F7.$$.fragment,f),C(HL.$$.fragment,f),C(UL.$$.fragment,f),C(YL.$$.fragment,f),C(M7.$$.fragment,f),C(KL.$$.fragment,f),C(A7.$$.fragment,f),C(ey.$$.fragment,f),C(oy.$$.fragment,f),C(ty.$$.fragment,f),C(y7.$$.fragment,f),C(ay.$$.fragment,f),C(k7.$$.fragment,f),C(ny.$$.fragment,f),C(sy.$$.fragment,f),C(iy.$$.fragment,f),C(R7.$$.fragment,f),C(dy.$$.fragment,f),C(j7.$$.fragment,f),C(cy.$$.fragment,f),C(fy.$$.fragment,f),C(gy.$$.fragment,f),C(G7.$$.fragment,f),C(hy.$$.fragment,f),C(X7.$$.fragment,f),C(py.$$.fragment,f),C(_y.$$.fragment,f),C(by.$$.fragment,f),C(Q7.$$.fragment,f),C(vy.$$.fragment,f),C(j8.$$.fragment,f),C(Fy.$$.fragment,f),C(Ty.$$.fragment,f),C(Ey.$$.fragment,f),C(G8.$$.fragment,f),C(Cy.$$.fragment,f),C(f9.$$.fragment,f),C(wy.$$.fragment,f),C(Ay.$$.fragment,f),C(yy.$$.fragment,f),C(g9.$$.fragment,f),C(xy.$$.fragment,f),C(L9.$$.fragment,f),C($y.$$.fragment,f),C(ky.$$.fragment,f),C(Ry.$$.fragment,f),C(x9.$$.fragment,f),C(Py.$$.fragment,f),C(P9.$$.fragment,f),C(By.$$.fragment,f),C(Iy.$$.fragment,f),C(qy.$$.fragment,f),C(I9.$$.fragment,f),C(jy.$$.fragment,f),C(tM.$$.fragment,f),C(Dy.$$.fragment,f),C(Gy.$$.fragment,f),C(Vy.$$.fragment,f),C(nM.$$.fragment,f),C(Xy.$$.fragment,f),C(_M.$$.fragment,f),C(zy.$$.fragment,f),C(Qy.$$.fragment,f),C(Hy.$$.fragment,f),C(bM.$$.fragment,f),C(Uy.$$.fragment,f),C(zM.$$.fragment,f),C(Jy.$$.fragment,f),C(Yy.$$.fragment,f),C(Zy.$$.fragment,f),C(WM.$$.fragment,f),C(ex.$$.fragment,f),C(fE.$$.fragment,f),C(ox.$$.fragment,f),C(rx.$$.fragment,f),C(ax.$$.fragment,f),C(gE.$$.fragment,f),C(nx.$$.fragment,f),C(_E.$$.fragment,f),C(lx.$$.fragment,f),C(ix.$$.fragment,f),C(cx.$$.fragment,f),C(bE.$$.fragment,f),C(fx.$$.fragment,f),C(FE.$$.fragment,f),C(mx.$$.fragment,f),C(gx.$$.fragment,f),C(px.$$.fragment,f),C(ME.$$.fragment,f),C(_x.$$.fragment,f),C(VE.$$.fragment,f),C(ux.$$.fragment,f),C(bx.$$.fragment,f),C(Fx.$$.fragment,f),C(zE.$$.fragment,f),C(Tx.$$.fragment,f),C(m4.$$.fragment,f),C(Mx.$$.fragment,f),C(Ex.$$.fragment,f),C(wx.$$.fragment,f),C(h4.$$.fragment,f),C(Ax.$$.fragment,f),C(_4.$$.fragment,f),C(Lx.$$.fragment,f),C(yx.$$.fragment,f),C($x.$$.fragment,f),C(b4.$$.fragment,f),C(kx.$$.fragment,f),C(F4.$$.fragment,f),C(Sx.$$.fragment,f),C(Rx.$$.fragment,f),C(Bx.$$.fragment,f),C(M4.$$.fragment,f),C(Ix.$$.fragment,f),C(J4.$$.fragment,f),C(Nx.$$.fragment,f),C(qx.$$.fragment,f),C(Dx.$$.fragment,f),C(K4.$$.fragment,f),C(Gx.$$.fragment,f),C(dC.$$.fragment,f),C(Ox.$$.fragment,f),C(Vx.$$.fragment,f),C(zx.$$.fragment,f),C(fC.$$.fragment,f),C(Qx.$$.fragment,f),C(wC.$$.fragment,f),C(Wx.$$.fragment,f),C(Hx.$$.fragment,f),C(Jx.$$.fragment,f),C(LC.$$.fragment,f),C(Yx.$$.fragment,f),C(qC.$$.fragment,f),C(Kx.$$.fragment,f),C(Zx.$$.fragment,f),C(o$.$$.fragment,f),C(DC.$$.fragment,f),C(r$.$$.fragment,f),C(YC.$$.fragment,f),C(t$.$$.fragment,f),C(a$.$$.fragment,f),C(s$.$$.fragment,f),C(ZC.$$.fragment,f),C(l$.$$.fragment,f),C(c5.$$.fragment,f),C(i$.$$.fragment,f),C(d$.$$.fragment,f),C(f$.$$.fragment,f),C(m5.$$.fragment,f),C(m$.$$.fragment,f),C(E5.$$.fragment,f),C(g$.$$.fragment,f),C(h$.$$.fragment,f),C(_$.$$.fragment,f),C(w5.$$.fragment,f),C(u$.$$.fragment,f),C(P5.$$.fragment,f),C(b$.$$.fragment,f),C(v$.$$.fragment,f),C(T$.$$.fragment,f),C(I5.$$.fragment,f),C(M$.$$.fragment,f),C(z5.$$.fragment,f),C(E$.$$.fragment,f),C(C$.$$.fragment,f),C(A$.$$.fragment,f),C(W5.$$.fragment,f),C(L$.$$.fragment,f),C(U5.$$.fragment,f),C(y$.$$.fragment,f),C(x$.$$.fragment,f),C(k$.$$.fragment,f),C(Y5.$$.fragment,f),C(S$.$$.fragment,f),C(e3.$$.fragment,f),C(P$.$$.fragment,f),C(B$.$$.fragment,f),C(N$.$$.fragment,f),C(r3.$$.fragment,f),C(q$.$$.fragment,f),C(a3.$$.fragment,f),XVe=!1},d(f){t(g),f&&t(v),f&&t(p),w(d),f&&t(yf),f&&t(at),f&&t(Oe),f&&t(Qe),f&&t($f),w(xa,f),f&&t(We),f&&t(Ae),f&&t(Co),f&&t($a),f&&t(jGe),f&&t(yi),w(xw),f&&t(DGe),f&&t(Nn),f&&t(GGe),w($w,f),f&&t(OGe),f&&t(lS),f&&t(VGe),w(Rf,f),f&&t(XGe),f&&t(xi),w(kw),f&&t(zGe),f&&t(wo),w(Sw),w(Bw),w(Gg),w(Iw),f&&t(QGe),f&&t(ki),w(Nw),f&&t(WGe),f&&t(Ao),w(qw),w(Gw),w(Eh),w(Ow),f&&t(HGe),f&&t(Si),w(Vw),f&&t(UGe),f&&t(Lo),w(Xw),w(Ww),w(ap),w(np),w(Hw),f&&t(JGe),f&&t(Ri),w(Uw),f&&t(YGe),f&&t(yo),w(Jw),w(Zw),w(wp),w(Ap),w(eA),f&&t(KGe),f&&t(Bi),w(oA),f&&t(ZGe),f&&t(xo),w(rA),w(aA),w(xp),w(nA),w(xu),f&&t(eOe),f&&t(qi),w(sA),f&&t(oOe),f&&t($o),w(lA),w(dA),w(ku),w(cA),w(E1),f&&t(rOe),f&&t(Gi),w(fA),f&&t(tOe),f&&t(ko),w(mA),w(hA),w(w1),w(pA),w(f2),f&&t(aOe),f&&t(Xi),w(_A),f&&t(nOe),f&&t(So),w(uA),w(vA),w(g2),w(FA),w(K2),f&&t(sOe),f&&t(Wi),w(TA),f&&t(lOe),f&&t(Ro),w(MA),w(CA),w(eb),w(wA),w(vb),f&&t(iOe),f&&t(Ji),w(AA),f&&t(dOe),f&&t(Po),w(LA),w(xA),w(Tb),w($A),w(bv),f&&t(cOe),f&&t(Zi),w(kA),f&&t(fOe),f&&t(Bo),w(SA),w(PA),w(Fv),w(BA),w(Kv),f&&t(mOe),f&&t(rd),w(IA),f&&t(gOe),f&&t(Io),w(NA),w(jA),w(eF),w(DA),w(iF),f&&t(hOe),f&&t(nd),w(GA),f&&t(pOe),f&&t(qo),w(OA),w(XA),w(cF),w(zA),w(HF),f&&t(_Oe),f&&t(id),w(QA),f&&t(uOe),f&&t(jo),w(WA),w(UA),w(JF),w(JA),w(j6),f&&t(bOe),f&&t(fd),w(YA),f&&t(vOe),f&&t(Do),w(KA),w(eL),w(G6),w(oL),w(X6),f&&t(FOe),f&&t(hd),w(rL),f&&t(TOe),f&&t(Go),w(tL),w(nL),w(Q6),w(sL),w(sT),f&&t(MOe),f&&t(ud),w(lL),f&&t(EOe),f&&t(Oo),w(iL),w(cL),w(iT),w(fL),w(fT),f&&t(COe),f&&t(Fd),w(mL),f&&t(wOe),f&&t(Vo),w(gL),w(pL),w(gT),w(_L),w(_T),f&&t(AOe),f&&t(Ed),w(uL),f&&t(LOe),f&&t(Xo),w(bL),w(FL),w(bT),w(TL),w(xT),f&&t(yOe),f&&t(Ad),w(ML),f&&t(xOe),f&&t(zo),w(EL),w(wL),w(kT),w(AL),w(qT),f&&t($Oe),f&&t(xd),w(LL),f&&t(kOe),f&&t(Qo),w(yL),w($L),w(DT),w(kL),w(KT),f&&t(SOe),f&&t(Sd),w(SL),f&&t(ROe),f&&t(Wo),w(RL),w(BL),w(e7),w(IL),w(a7),f&&t(POe),f&&t(Bd),w(qL),f&&t(BOe),f&&t(Ho),w(jL),w(GL),w(s7),w(OL),w(g7),f&&t(IOe),f&&t(qd),w(VL),f&&t(NOe),f&&t(Uo),w(XL),w(QL),w(p7),w(WL),w(F7),f&&t(qOe),f&&t(Od),w(HL),f&&t(jOe),f&&t(Jo),w(UL),w(YL),w(M7),w(KL),w(A7),f&&t(DOe),f&&t(zd),w(ey),f&&t(GOe),f&&t(Yo),w(oy),w(ty),w(y7),w(ay),w(k7),f&&t(OOe),f&&t(Hd),w(ny),f&&t(VOe),f&&t(Ko),w(sy),w(iy),w(R7),w(dy),w(j7),f&&t(XOe),f&&t(Yd),w(cy),f&&t(zOe),f&&t(Zo),w(fy),w(gy),w(G7),w(hy),w(X7),f&&t(QOe),f&&t(ec),w(py),f&&t(WOe),f&&t(er),w(_y),w(by),w(Q7),w(vy),w(j8),f&&t(HOe),f&&t(tc),w(Fy),f&&t(UOe),f&&t(or),w(Ty),w(Ey),w(G8),w(Cy),w(f9),f&&t(JOe),f&&t(sc),w(wy),f&&t(YOe),f&&t(rr),w(Ay),w(yy),w(g9),w(xy),w(L9),f&&t(KOe),f&&t(dc),w($y),f&&t(ZOe),f&&t(tr),w(ky),w(Ry),w(x9),w(Py),w(P9),f&&t(eVe),f&&t(mc),w(By),f&&t(oVe),f&&t(ar),w(Iy),w(qy),w(I9),w(jy),w(tM),f&&t(rVe),f&&t(pc),w(Dy),f&&t(tVe),f&&t(nr),w(Gy),w(Vy),w(nM),w(Xy),w(_M),f&&t(aVe),f&&t(bc),w(zy),f&&t(nVe),f&&t(sr),w(Qy),w(Hy),w(bM),w(Uy),w(zM),f&&t(sVe),f&&t(Tc),w(Jy),f&&t(lVe),f&&t(lr),w(Yy),w(Zy),w(WM),w(ex),w(fE),f&&t(iVe),f&&t(Cc),w(ox),f&&t(dVe),f&&t(ir),w(rx),w(ax),w(gE),w(nx),w(_E),f&&t(cVe),f&&t(Lc),w(lx),f&&t(fVe),f&&t(dr),w(ix),w(cx),w(bE),w(fx),w(FE),f&&t(mVe),f&&t($c),w(mx),f&&t(gVe),f&&t(cr),w(gx),w(px),w(ME),w(_x),w(VE),f&&t(hVe),f&&t(Rc),w(ux),f&&t(pVe),f&&t(fr),w(bx),w(Fx),w(zE),w(Tx),w(m4),f&&t(_Ve),f&&t(Ic),w(Mx),f&&t(uVe),f&&t(mr),w(Ex),w(wx),w(h4),w(Ax),w(_4),f&&t(bVe),f&&t(jc),w(Lx),f&&t(vVe),f&&t(gr),w(yx),w($x),w(b4),w(kx),w(F4),f&&t(FVe),f&&t(Oc),w(Sx),f&&t(TVe),f&&t(hr),w(Rx),w(Bx),w(M4),w(Ix),w(J4),f&&t(MVe),f&&t(zc),w(Nx),f&&t(EVe),f&&t(pr),w(qx),w(Dx),w(K4),w(Gx),w(dC),f&&t(CVe),f&&t(Hc),w(Ox),f&&t(wVe),f&&t(_r),w(Vx),w(zx),w(fC),w(Qx),w(wC),f&&t(AVe),f&&t(Yc),w(Wx),f&&t(LVe),f&&t(ur),w(Hx),w(Jx),w(LC),w(Yx),w(qC),f&&t(yVe),f&&t(ef),w(Kx),f&&t(xVe),f&&t(br),w(Zx),w(o$),w(DC),w(r$),w(YC),f&&t($Ve),f&&t(tf),w(t$),f&&t(kVe),f&&t(vr),w(a$),w(s$),w(ZC),w(l$),w(c5),f&&t(SVe),f&&t(sf),w(i$),f&&t(RVe),f&&t(Fr),w(d$),w(f$),w(m5),w(m$),w(E5),f&&t(PVe),f&&t(cf),w(g$),f&&t(BVe),f&&t(Tr),w(h$),w(_$),w(w5),w(u$),w(P5),f&&t(IVe),f&&t(gf),w(b$),f&&t(NVe),f&&t(Mr),w(v$),w(T$),w(I5),w(M$),w(z5),f&&t(qVe),f&&t(_f),w(E$),f&&t(jVe),f&&t(Er),w(C$),w(A$),w(W5),w(L$),w(U5),f&&t(DVe),f&&t(vf),w(y$),f&&t(GVe),f&&t(Cr),w(x$),w(k$),w(Y5),w(S$),w(e3),f&&t(OVe),f&&t(Mf),w(P$),f&&t(VVe),f&&t(wr),w(B$),w(N$),w(r3),w(q$),w(a3)}}}const COt={local:"auto-classes",sections:[{local:"extending-the-auto-classes",title:"Extending the Auto Classes"},{local:"transformers.AutoConfig",title:"AutoConfig"},{local:"transformers.AutoTokenizer",title:"AutoTokenizer"},{local:"transformers.AutoFeatureExtractor",title:"AutoFeatureExtractor"},{local:"transformers.AutoProcessor",title:"AutoProcessor"},{local:"transformers.AutoModel",title:"AutoModel"},{local:"transformers.AutoModelForPreTraining",title:"AutoModelForPreTraining"},{local:"transformers.AutoModelForCausalLM",title:"AutoModelForCausalLM"},{local:"transformers.AutoModelForMaskedLM",title:"AutoModelForMaskedLM"},{local:"transformers.AutoModelForSeq2SeqLM",title:"AutoModelForSeq2SeqLM"},{local:"transformers.AutoModelForSequenceClassification",title:"AutoModelForSequenceClassification"},{local:"transformers.AutoModelForMultipleChoice",title:"AutoModelForMultipleChoice"},{local:"transformers.AutoModelForNextSentencePrediction",title:"AutoModelForNextSentencePrediction"},{local:"transformers.AutoModelForTokenClassification",title:"AutoModelForTokenClassification"},{local:"transformers.AutoModelForQuestionAnswering",title:"AutoModelForQuestionAnswering"},{local:"transformers.AutoModelForTableQuestionAnswering",title:"AutoModelForTableQuestionAnswering"},{local:"transformers.AutoModelForImageClassification",title:"AutoModelForImageClassification"},{local:"transformers.AutoModelForVision2Seq",title:"AutoModelForVision2Seq"},{local:"transformers.AutoModelForVisualQuestionAnswering",title:"AutoModelForVisualQuestionAnswering"},{local:"transformers.AutoModelForAudioClassification",title:"AutoModelForAudioClassification"},{local:"transformers.AutoModelForAudioFrameClassification",title:"AutoModelForAudioFrameClassification"},{local:"transformers.AutoModelForCTC",title:"AutoModelForCTC"},{local:"transformers.AutoModelForSpeechSeq2Seq",title:"AutoModelForSpeechSeq2Seq"},{local:"transformers.AutoModelForAudioXVector",title:"AutoModelForAudioXVector"},{local:"transformers.AutoModelForMaskedImageModeling",title:"AutoModelForMaskedImageModeling"},{local:"transformers.AutoModelForObjectDetection",title:"AutoModelForObjectDetection"},{local:"transformers.AutoModelForImageSegmentation",title:"AutoModelForImageSegmentation"},{local:"transformers.AutoModelForSemanticSegmentation",title:"AutoModelForSemanticSegmentation"},{local:"transformers.AutoModelForInstanceSegmentation",title:"AutoModelForInstanceSegmentation"},{local:"transformers.TFAutoModel",title:"TFAutoModel"},{local:"transformers.TFAutoModelForPreTraining",title:"TFAutoModelForPreTraining"},{local:"transformers.TFAutoModelForCausalLM",title:"TFAutoModelForCausalLM"},{local:"transformers.TFAutoModelForImageClassification",title:"TFAutoModelForImageClassification"},{local:"transformers.TFAutoModelForMaskedLM",title:"TFAutoModelForMaskedLM"},{local:"transformers.TFAutoModelForSeq2SeqLM",title:"TFAutoModelForSeq2SeqLM"},{local:"transformers.TFAutoModelForSequenceClassification",title:"TFAutoModelForSequenceClassification"},{local:"transformers.TFAutoModelForMultipleChoice",title:"TFAutoModelForMultipleChoice"},{local:"transformers.TFAutoModelForNextSentencePrediction",title:"TFAutoModelForNextSentencePrediction"},{local:"transformers.TFAutoModelForTableQuestionAnswering",title:"TFAutoModelForTableQuestionAnswering"},{local:"transformers.TFAutoModelForTokenClassification",title:"TFAutoModelForTokenClassification"},{local:"transformers.TFAutoModelForQuestionAnswering",title:"TFAutoModelForQuestionAnswering"},{local:"transformers.TFAutoModelForVision2Seq",title:"TFAutoModelForVision2Seq"},{local:"transformers.TFAutoModelForSpeechSeq2Seq",title:"TFAutoModelForSpeechSeq2Seq"},{local:"transformers.FlaxAutoModel",title:"FlaxAutoModel"},{local:"transformers.FlaxAutoModelForCausalLM",title:"FlaxAutoModelForCausalLM"},{local:"transformers.FlaxAutoModelForPreTraining",title:"FlaxAutoModelForPreTraining"},{local:"transformers.FlaxAutoModelForMaskedLM",title:"FlaxAutoModelForMaskedLM"},{local:"transformers.FlaxAutoModelForSeq2SeqLM",title:"FlaxAutoModelForSeq2SeqLM"},{local:"transformers.FlaxAutoModelForSequenceClassification",title:"FlaxAutoModelForSequenceClassification"},{local:"transformers.FlaxAutoModelForQuestionAnswering",title:"FlaxAutoModelForQuestionAnswering"},{local:"transformers.FlaxAutoModelForTokenClassification",title:"FlaxAutoModelForTokenClassification"},{local:"transformers.FlaxAutoModelForMultipleChoice",title:"FlaxAutoModelForMultipleChoice"},{local:"transformers.FlaxAutoModelForNextSentencePrediction",title:"FlaxAutoModelForNextSentencePrediction"},{local:"transformers.FlaxAutoModelForImageClassification",title:"FlaxAutoModelForImageClassification"},{local:"transformers.FlaxAutoModelForVision2Seq",title:"FlaxAutoModelForVision2Seq"}],title:"Auto Classes"};function wOt(x){return EDt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class SOt extends vDt{constructor(g){super();FDt(this,g,wOt,EOt,TDt,{})}}export{SOt as default,COt as metadata};
