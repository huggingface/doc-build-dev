import{S as n_,i as a_,s as r_,e as r,t as n,k as d,c as l,a as o,h as a,d as t,m as c,b as h,g as i,G as s,w as E,x as j,y as k,q as b,o as $,B as x,M as l_,N as Oo,p as Nr,v as o_,n as Lr,L as Zf}from"../../chunks/vendor-hf-doc-builder.js";import{T as Ta}from"../../chunks/Tip-hf-doc-builder.js";import{Y as ju}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Kt}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as U}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as t_}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as i_}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function u_(Z){let u,q;return u=new t_({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter7/section4_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter7/section4_tf.ipynb"}]}}),{c(){E(u.$$.fragment)},l(_){j(u.$$.fragment,_)},m(_,w){k(u,_,w),q=!0},i(_){q||(b(u.$$.fragment,_),q=!0)},o(_){$(u.$$.fragment,_),q=!1},d(_){x(u,_)}}}function p_(Z){let u,q;return u=new t_({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter7/section4_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter7/section4_pt.ipynb"}]}}),{c(){E(u.$$.fragment)},l(_){j(u.$$.fragment,_)},m(_,w){k(u,_,w),q=!0},i(_){q||(b(u.$$.fragment,_),q=!0)},o(_){$(u.$$.fragment,_),q=!1},d(_){x(u,_)}}}function d_(Z){let u,q,_,w,A,v,T,S;return{c(){u=r("p"),q=n("\u270F\uFE0F "),_=r("strong"),w=n("A votre tour !"),A=n(" Un autre mot anglais souvent utilis\xE9 en fran\xE7ais est \xAB "),v=r("em"),T=n("email"),S=n(" \xBB. Trouvez le premier \xE9chantillon dans l\u2019\xE9chantillon d\u2019entra\xEEnement qui utilise ce mot. Comment est-il traduit ? Comment le mod\xE8le pr\xE9-entra\xEEn\xE9 traduit-il cette m\xEAme phrase ?")},l(z){u=l(z,"P",{});var C=o(u);q=a(C,"\u270F\uFE0F "),_=l(C,"STRONG",{});var F=o(_);w=a(F,"A votre tour !"),F.forEach(t),A=a(C," Un autre mot anglais souvent utilis\xE9 en fran\xE7ais est \xAB "),v=l(C,"EM",{});var D=o(v);T=a(D,"email"),D.forEach(t),S=a(C," \xBB. Trouvez le premier \xE9chantillon dans l\u2019\xE9chantillon d\u2019entra\xEEnement qui utilise ce mot. Comment est-il traduit ? Comment le mod\xE8le pr\xE9-entra\xEEn\xE9 traduit-il cette m\xEAme phrase ?"),C.forEach(t)},m(z,C){i(z,u,C),s(u,q),s(u,_),s(_,w),s(u,A),s(u,v),s(v,T),s(u,S)},d(z){z&&t(u)}}}function c_(Z){let u,q,_,w,A,v,T,S,z,C,F,D,y,R;return{c(){u=r("p"),q=n("\u{1F4A1} Si vous utilisez un "),_=r("em"),w=n("tokenizer"),A=n(" multilingue tel que mBART, mBART-50 ou M2M100, vous devrez d\xE9finir les codes de langue de vos entr\xE9es et cibles dans le "),v=r("em"),T=n("tokenizer"),S=n(" en d\xE9finissant "),z=r("code"),C=n("tokenizer.src_lang"),F=n(" et "),D=r("code"),y=n("tokenizer.tgt_lang"),R=n(" aux bonnes valeurs.")},l(H){u=l(H,"P",{});var L=o(u);q=a(L,"\u{1F4A1} Si vous utilisez un "),_=l(L,"EM",{});var Y=o(_);w=a(Y,"tokenizer"),Y.forEach(t),A=a(L," multilingue tel que mBART, mBART-50 ou M2M100, vous devrez d\xE9finir les codes de langue de vos entr\xE9es et cibles dans le "),v=l(L,"EM",{});var O=o(v);T=a(O,"tokenizer"),O.forEach(t),S=a(L," en d\xE9finissant "),z=l(L,"CODE",{});var V=o(z);C=a(V,"tokenizer.src_lang"),V.forEach(t),F=a(L," et "),D=l(L,"CODE",{});var W=o(D);y=a(W,"tokenizer.tgt_lang"),W.forEach(t),R=a(L," aux bonnes valeurs."),L.forEach(t)},m(H,L){i(H,u,L),s(u,q),s(u,_),s(_,w),s(u,A),s(u,v),s(v,T),s(u,S),s(u,z),s(z,C),s(u,F),s(u,D),s(D,y),s(u,R)},d(H){H&&t(u)}}}function m_(Z){let u,q,_,w,A,v,T,S,z,C,F;return{c(){u=r("p"),q=n("\u{1F4A1} Si vous utilisez un mod\xE8le T5 (plus pr\xE9cis\xE9ment, un des "),_=r("em"),w=n("checkpoints"),A=d(),v=r("code"),T=n("t5-xxx"),S=n("), le mod\xE8le s\u2019attendra \xE0 ce que les entr\xE9es aient un pr\xE9fixe indiquant la t\xE2che \xE0 accomplir, comme "),z=r("code"),C=n("translate: English to French:"),F=n(".")},l(D){u=l(D,"P",{});var y=o(u);q=a(y,"\u{1F4A1} Si vous utilisez un mod\xE8le T5 (plus pr\xE9cis\xE9ment, un des "),_=l(y,"EM",{});var R=o(_);w=a(R,"checkpoints"),R.forEach(t),A=c(y),v=l(y,"CODE",{});var H=o(v);T=a(H,"t5-xxx"),H.forEach(t),S=a(y,"), le mod\xE8le s\u2019attendra \xE0 ce que les entr\xE9es aient un pr\xE9fixe indiquant la t\xE2che \xE0 accomplir, comme "),z=l(y,"CODE",{});var L=o(z);C=a(L,"translate: English to French:"),L.forEach(t),F=a(y,"."),y.forEach(t)},m(D,y){i(D,u,y),s(u,q),s(u,_),s(_,w),s(u,A),s(u,v),s(v,T),s(u,S),s(u,z),s(z,C),s(u,F)},d(D){D&&t(u)}}}function f_(Z){let u,q,_,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se,N,I,Q;return{c(){u=r("p"),q=n("\u26A0\uFE0F Nous ne faisons pas attention au masque d\u2019attention des cibles car le mod\xE8le ne s\u2019y attend pas. Au lieu de cela, les \xE9tiquettes correspondant \xE0 un "),_=r("em"),w=n("token"),A=n(" de "),v=r("em"),T=n("padding"),S=n(" doivent \xEAtre mises \xE0 "),z=r("code"),C=n("-100"),F=n(" afin qu\u2019elles soient ignor\xE9es dans le calcul de la perte. Cela sera fait par notre collateur de donn\xE9es plus tard puisque nous appliquons le "),D=r("em"),y=n("padding"),R=n(" dynamique, mais si vous utilisez le "),H=r("em"),L=n("padding"),Y=n(" ici, vous devriez adapter la fonction de pr\xE9traitement pour mettre toutes les \xE9tiquettes qui correspondent au "),O=r("em"),V=n("token"),W=n(" de "),M=r("em"),P=n("padding"),se=n(" \xE0 "),N=r("code"),I=n("-100"),Q=n(".")},l(ee){u=l(ee,"P",{});var X=o(u);q=a(X,"\u26A0\uFE0F Nous ne faisons pas attention au masque d\u2019attention des cibles car le mod\xE8le ne s\u2019y attend pas. Au lieu de cela, les \xE9tiquettes correspondant \xE0 un "),_=l(X,"EM",{});var ie=o(_);w=a(ie,"token"),ie.forEach(t),A=a(X," de "),v=l(X,"EM",{});var re=o(v);T=a(re,"padding"),re.forEach(t),S=a(X," doivent \xEAtre mises \xE0 "),z=l(X,"CODE",{});var te=o(z);C=a(te,"-100"),te.forEach(t),F=a(X," afin qu\u2019elles soient ignor\xE9es dans le calcul de la perte. Cela sera fait par notre collateur de donn\xE9es plus tard puisque nous appliquons le "),D=l(X,"EM",{});var me=o(D);y=a(me,"padding"),me.forEach(t),R=a(X," dynamique, mais si vous utilisez le "),H=l(X,"EM",{});var le=o(H);L=a(le,"padding"),le.forEach(t),Y=a(X," ici, vous devriez adapter la fonction de pr\xE9traitement pour mettre toutes les \xE9tiquettes qui correspondent au "),O=l(X,"EM",{});var de=o(O);V=a(de,"token"),de.forEach(t),W=a(X," de "),M=l(X,"EM",{});var ue=o(M);P=a(ue,"padding"),ue.forEach(t),se=a(X," \xE0 "),N=l(X,"CODE",{});var ve=o(N);I=a(ve,"-100"),ve.forEach(t),Q=a(X,"."),X.forEach(t)},m(ee,X){i(ee,u,X),s(u,q),s(u,_),s(_,w),s(u,A),s(u,v),s(v,T),s(u,S),s(u,z),s(z,C),s(u,F),s(u,D),s(D,y),s(u,R),s(u,H),s(H,L),s(u,Y),s(u,O),s(O,V),s(u,W),s(u,M),s(M,P),s(u,se),s(u,N),s(N,I),s(u,Q)},d(ee){ee&&t(u)}}}function __(Z){let u,q,_,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se;return w=new Kt({}),W=new U({props:{code:`from transformers import TFAutoModelForSeq2SeqLM

model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, from_pt=True)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSeq2SeqLM

model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint, from_pt=<span class="hljs-literal">True</span>)`}}),P=new Ta({props:{warning:!1,$$slots:{default:[v_]},$$scope:{ctx:Z}}}),{c(){u=r("h2"),q=r("a"),_=r("span"),E(w.$$.fragment),A=d(),v=r("span"),T=r("i"),S=n("Finetuner"),z=n(" du mod\xE8le avec Keras"),C=d(),F=r("p"),D=n("Tout d\u2019abord, nous avons besoin d\u2019un mod\xE8le \xE0 "),y=r("em"),R=n("finetuner"),H=n(". Nous allons utiliser l\u2019API habituelle "),L=r("code"),Y=n("AutoModel"),O=n(" :"),V=d(),E(W.$$.fragment),M=d(),E(P.$$.fragment),this.h()},l(N){u=l(N,"H2",{class:!0});var I=o(u);q=l(I,"A",{id:!0,class:!0,href:!0});var Q=o(q);_=l(Q,"SPAN",{});var ee=o(_);j(w.$$.fragment,ee),ee.forEach(t),Q.forEach(t),A=c(I),v=l(I,"SPAN",{});var X=o(v);T=l(X,"I",{});var ie=o(T);S=a(ie,"Finetuner"),ie.forEach(t),z=a(X," du mod\xE8le avec Keras"),X.forEach(t),I.forEach(t),C=c(N),F=l(N,"P",{});var re=o(F);D=a(re,"Tout d\u2019abord, nous avons besoin d\u2019un mod\xE8le \xE0 "),y=l(re,"EM",{});var te=o(y);R=a(te,"finetuner"),te.forEach(t),H=a(re,". Nous allons utiliser l\u2019API habituelle "),L=l(re,"CODE",{});var me=o(L);Y=a(me,"AutoModel"),me.forEach(t),O=a(re," :"),re.forEach(t),V=c(N),j(W.$$.fragment,N),M=c(N),j(P.$$.fragment,N),this.h()},h(){h(q,"id","ifinetuneri-du-modle-avec-keras"),h(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(q,"href","#ifinetuneri-du-modle-avec-keras"),h(u,"class","relative group")},m(N,I){i(N,u,I),s(u,q),s(q,_),k(w,_,null),s(u,A),s(u,v),s(v,T),s(T,S),s(v,z),i(N,C,I),i(N,F,I),s(F,D),s(F,y),s(y,R),s(F,H),s(F,L),s(L,Y),s(F,O),i(N,V,I),k(W,N,I),i(N,M,I),k(P,N,I),se=!0},i(N){se||(b(w.$$.fragment,N),b(W.$$.fragment,N),b(P.$$.fragment,N),se=!0)},o(N){$(w.$$.fragment,N),$(W.$$.fragment,N),$(P.$$.fragment,N),se=!1},d(N){N&&t(u),x(w),N&&t(C),N&&t(F),N&&t(V),x(W,N),N&&t(M),x(P,N)}}}function h_(Z){let u,q,_,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se,N,I,Q,ee,X,ie,re,te,me,le,de,ue,ve,be,$e,_e;return w=new Kt({}),$e=new U({props:{code:`from transformers import AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)`}}),{c(){u=r("h2"),q=r("a"),_=r("span"),E(w.$$.fragment),A=d(),v=r("span"),T=r("i"),S=n("Finetuner"),z=n(" le mod\xE8le avec l'API "),C=r("code"),F=n("Trainer"),D=d(),y=r("p"),R=n("Le code actuel utilisant "),H=r("code"),L=n("Trainer"),Y=n(" sera le m\xEAme que pr\xE9c\xE9demment, avec juste un petit changement : nous utilisons ici "),O=r("a"),V=r("code"),W=n("Seq2SeqTrainer"),M=n(" qui est une sous-classe de "),P=r("code"),se=n("Trainer"),N=n(" qui nous permet de traiter correctement l\u2019\xE9valuation, en utilisant la m\xE9thode "),I=r("code"),Q=n("generate()"),ee=n(" pour pr\xE9dire les sorties \xE0 partir des entr\xE9es. Nous y reviendrons plus en d\xE9tail lorsque nous parlerons du calcul de la m\xE9trique."),X=d(),ie=r("p"),re=n("Tout d\u2019abord, nous avons besoin d\u2019un mod\xE8le \xE0 "),te=r("em"),me=n("finetuner"),le=n(". Nous allons utiliser l\u2019API habituelle "),de=r("code"),ue=n("AutoModel"),ve=n(" :"),be=d(),E($e.$$.fragment),this.h()},l(J){u=l(J,"H2",{class:!0});var pe=o(u);q=l(pe,"A",{id:!0,class:!0,href:!0});var ce=o(q);_=l(ce,"SPAN",{});var G=o(_);j(w.$$.fragment,G),G.forEach(t),ce.forEach(t),A=c(pe),v=l(pe,"SPAN",{});var Ae=o(v);T=l(Ae,"I",{});var ge=o(T);S=a(ge,"Finetuner"),ge.forEach(t),z=a(Ae," le mod\xE8le avec l'API "),C=l(Ae,"CODE",{});var Qe=o(C);F=a(Qe,"Trainer"),Qe.forEach(t),Ae.forEach(t),pe.forEach(t),D=c(J),y=l(J,"P",{});var qe=o(y);R=a(qe,"Le code actuel utilisant "),H=l(qe,"CODE",{});var fe=o(H);L=a(fe,"Trainer"),fe.forEach(t),Y=a(qe," sera le m\xEAme que pr\xE9c\xE9demment, avec juste un petit changement : nous utilisons ici "),O=l(qe,"A",{href:!0,rel:!0});var Me=o(O);V=l(Me,"CODE",{});var ne=o(V);W=a(ne,"Seq2SeqTrainer"),ne.forEach(t),Me.forEach(t),M=a(qe," qui est une sous-classe de "),P=l(qe,"CODE",{});var Oe=o(P);se=a(Oe,"Trainer"),Oe.forEach(t),N=a(qe," qui nous permet de traiter correctement l\u2019\xE9valuation, en utilisant la m\xE9thode "),I=l(qe,"CODE",{});var ae=o(I);Q=a(ae,"generate()"),ae.forEach(t),ee=a(qe," pour pr\xE9dire les sorties \xE0 partir des entr\xE9es. Nous y reviendrons plus en d\xE9tail lorsque nous parlerons du calcul de la m\xE9trique."),qe.forEach(t),X=c(J),ie=l(J,"P",{});var ze=o(ie);re=a(ze,"Tout d\u2019abord, nous avons besoin d\u2019un mod\xE8le \xE0 "),te=l(ze,"EM",{});var ye=o(te);me=a(ye,"finetuner"),ye.forEach(t),le=a(ze,". Nous allons utiliser l\u2019API habituelle "),de=l(ze,"CODE",{});var De=o(de);ue=a(De,"AutoModel"),De.forEach(t),ve=a(ze," :"),ze.forEach(t),be=c(J),j($e.$$.fragment,J),this.h()},h(){h(q,"id","ifinetuneri-le-modle-avec-lapi-trainer"),h(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(q,"href","#ifinetuneri-le-modle-avec-lapi-trainer"),h(u,"class","relative group"),h(O,"href","https://huggingface.co/transformers/main_classes/trainer.html#seq2seqtrainer"),h(O,"rel","nofollow")},m(J,pe){i(J,u,pe),s(u,q),s(q,_),k(w,_,null),s(u,A),s(u,v),s(v,T),s(T,S),s(v,z),s(v,C),s(C,F),i(J,D,pe),i(J,y,pe),s(y,R),s(y,H),s(H,L),s(y,Y),s(y,O),s(O,V),s(V,W),s(y,M),s(y,P),s(P,se),s(y,N),s(y,I),s(I,Q),s(y,ee),i(J,X,pe),i(J,ie,pe),s(ie,re),s(ie,te),s(te,me),s(ie,le),s(ie,de),s(de,ue),s(ie,ve),i(J,be,pe),k($e,J,pe),_e=!0},i(J){_e||(b(w.$$.fragment,J),b($e.$$.fragment,J),_e=!0)},o(J){$(w.$$.fragment,J),$($e.$$.fragment,J),_e=!1},d(J){J&&t(u),x(w),J&&t(D),J&&t(y),J&&t(X),J&&t(ie),J&&t(be),x($e,J)}}}function v_(Z){let u,q,_,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se;return{c(){u=r("p"),q=n("\u{1F4A1} Le "),_=r("em"),w=n("checkpoint"),A=d(),v=r("code"),T=n("Helsinki-NLP/opus-mt-en-fr"),S=n(" ne dispose que de poids PyTorch, vous aurez donc une erreur si vous essayez de charger le mod\xE8le sans utiliser l\u2019argument "),z=r("code"),C=n("from_pt=True"),F=n(" dans la m\xE9thode "),D=r("code"),y=n("from_pretrained()"),R=n(". Lorsque vous sp\xE9cifiez "),H=r("code"),L=n("from_pt=True"),Y=n(", la biblioth\xE8que t\xE9l\xE9chargera et convertira automatiquement les poids PyTorch pour vous. Comme vous pouvez le constater, c\u2019est tr\xE8s simple de passer d\u2019un "),O=r("em"),V=n("framework"),W=n(" \xE0 l\u2019autre dans \u{1F917} "),M=r("em"),P=n("Transformers"),se=n(" !")},l(N){u=l(N,"P",{});var I=o(u);q=a(I,"\u{1F4A1} Le "),_=l(I,"EM",{});var Q=o(_);w=a(Q,"checkpoint"),Q.forEach(t),A=c(I),v=l(I,"CODE",{});var ee=o(v);T=a(ee,"Helsinki-NLP/opus-mt-en-fr"),ee.forEach(t),S=a(I," ne dispose que de poids PyTorch, vous aurez donc une erreur si vous essayez de charger le mod\xE8le sans utiliser l\u2019argument "),z=l(I,"CODE",{});var X=o(z);C=a(X,"from_pt=True"),X.forEach(t),F=a(I," dans la m\xE9thode "),D=l(I,"CODE",{});var ie=o(D);y=a(ie,"from_pretrained()"),ie.forEach(t),R=a(I,". Lorsque vous sp\xE9cifiez "),H=l(I,"CODE",{});var re=o(H);L=a(re,"from_pt=True"),re.forEach(t),Y=a(I,", la biblioth\xE8que t\xE9l\xE9chargera et convertira automatiquement les poids PyTorch pour vous. Comme vous pouvez le constater, c\u2019est tr\xE8s simple de passer d\u2019un "),O=l(I,"EM",{});var te=o(O);V=a(te,"framework"),te.forEach(t),W=a(I," \xE0 l\u2019autre dans \u{1F917} "),M=l(I,"EM",{});var me=o(M);P=a(me,"Transformers"),me.forEach(t),se=a(I," !"),I.forEach(t)},m(N,I){i(N,u,I),s(u,q),s(u,_),s(_,w),s(u,A),s(u,v),s(v,T),s(u,S),s(u,z),s(z,C),s(u,F),s(u,D),s(D,y),s(u,R),s(u,H),s(H,L),s(u,Y),s(u,O),s(O,V),s(u,W),s(u,M),s(M,P),s(u,se)},d(N){N&&t(u)}}}function b_(Z){let u,q;return u=new U({props:{code:`from transformers import DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors="tf")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),{c(){E(u.$$.fragment)},l(_){j(u.$$.fragment,_)},m(_,w){k(u,_,w),q=!0},i(_){q||(b(u.$$.fragment,_),q=!0)},o(_){$(u.$$.fragment,_),q=!1},d(_){x(u,_)}}}function $_(Z){let u,q;return u=new U({props:{code:`from transformers import DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)`}}),{c(){E(u.$$.fragment)},l(_){j(u.$$.fragment,_)},m(_,w){k(u,_,w),q=!0},i(_){q||(b(u.$$.fragment,_),q=!0)},o(_){$(u.$$.fragment,_),q=!1},d(_){x(u,_)}}}function g_(Z){let u,q,_,w,A,v,T,S,z,C,F;return C=new U({props:{code:`tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["input_ids", "attention_mask", "labels"],
    collate_fn=data_collator,
    shuffle=True,
    batch_size=32,
)
tf_eval_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["input_ids", "attention_mask", "labels"],
    collate_fn=data_collator,
    shuffle=False,
    batch_size=16,
)`,highlighted:`tf_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>],
    collate_fn=data_collator,
    shuffle=<span class="hljs-literal">True</span>,
    batch_size=<span class="hljs-number">32</span>,
)
tf_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>],
    collate_fn=data_collator,
    shuffle=<span class="hljs-literal">False</span>,
    batch_size=<span class="hljs-number">16</span>,
)`}}),{c(){u=r("p"),q=n("Nous pouvons maintenant utiliser ce "),_=r("code"),w=n("data_collator"),A=n(" pour convertir chacun de nos jeux de donn\xE9es en un "),v=r("code"),T=n("tf.data.Dataset"),S=n(", pr\xEAt pour l\u2019entra\xEEnement :"),z=d(),E(C.$$.fragment)},l(D){u=l(D,"P",{});var y=o(u);q=a(y,"Nous pouvons maintenant utiliser ce "),_=l(y,"CODE",{});var R=o(_);w=a(R,"data_collator"),R.forEach(t),A=a(y," pour convertir chacun de nos jeux de donn\xE9es en un "),v=l(y,"CODE",{});var H=o(v);T=a(H,"tf.data.Dataset"),H.forEach(t),S=a(y,", pr\xEAt pour l\u2019entra\xEEnement :"),y.forEach(t),z=c(D),j(C.$$.fragment,D)},m(D,y){i(D,u,y),s(u,q),s(u,_),s(_,w),s(u,A),s(u,v),s(v,T),s(u,S),i(D,z,y),k(C,D,y),F=!0},i(D){F||(b(C.$$.fragment,D),F=!0)},o(D){$(C.$$.fragment,D),F=!1},d(D){D&&t(u),D&&t(z),x(C,D)}}}function q_(Z){let u,q,_,w,A,v,T,S;return{c(){u=r("p"),q=n("Nous allons transmettre ce "),_=r("code"),w=n("data_collator"),A=n(" au "),v=r("code"),T=n("Seq2SeqTrainer"),S=n(". Ensuite, jetons un coup d\u2019oeil \xE0 la m\xE9trique.")},l(z){u=l(z,"P",{});var C=o(u);q=a(C,"Nous allons transmettre ce "),_=l(C,"CODE",{});var F=o(_);w=a(F,"data_collator"),F.forEach(t),A=a(C," au "),v=l(C,"CODE",{});var D=o(v);T=a(D,"Seq2SeqTrainer"),D.forEach(t),S=a(C,". Ensuite, jetons un coup d\u2019oeil \xE0 la m\xE9trique."),C.forEach(t)},m(z,C){i(z,u,C),s(u,q),s(u,_),s(_,w),s(u,A),s(u,v),s(v,T),s(u,S)},i:Zf,o:Zf,d(z){z&&t(u)}}}function e_(Z){let u,q,_,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se,N,I,Q,ee,X,ie,re,te,me,le,de,ue,ve,be,$e,_e,J,pe;return{c(){u=r("p"),q=n("La fonctionnalit\xE9 que "),_=r("code"),w=n("Seq2SeqTrainer"),A=n(" ajoute \xE0 sa superclasse "),v=r("code"),T=n("Trainer"),S=n(" est la possibilit\xE9 d\u2019utiliser la m\xE9thode "),z=r("code"),C=n("generate()"),F=n(" pendant l\u2019\xE9valuation ou la pr\xE9diction. Pendant l\u2019entra\xEEnement, le mod\xE8le utilisera les "),D=r("code"),y=n("decoder_input_ids"),R=n(" avec un masque d\u2019attention assurant qu\u2019il n\u2019utilise pas les "),H=r("em"),L=n("tokens"),Y=n(" apr\xE8s le "),O=r("em"),V=n("token"),W=n(" qu\u2019il essaie de pr\xE9dire, pour acc\xE9l\xE9rer l\u2019entra\xEEnement. Pendant l\u2019inf\xE9rence, nous ne pourrons pas les utiliser puisque nous n\u2019aurons pas d\u2019\xE9tiquettes. Ainsi c\u2019est une bonne id\xE9e d\u2019\xE9valuer notre mod\xE8le avec la m\xEAme configuration."),M=d(),P=r("p"),se=n("Comme nous l\u2019avons vu dans le "),N=r("a"),I=n("chapitre 1"),Q=n(", le d\xE9codeur effectue l\u2019inf\xE9rence en pr\xE9disant les "),ee=r("em"),X=n("tokens"),ie=n(" un par un. C\u2019est quelque chose qui est impl\xE9ment\xE9 en coulisses dans \u{1F917} "),re=r("em"),te=n("Transformers"),me=n(" par la m\xE9thode "),le=r("code"),de=n("generate()"),ue=n(". Le "),ve=r("code"),be=n("Seq2SeqTrainer"),$e=n(" nous laissera utiliser cette m\xE9thode pour l\u2019\xE9valuation si nous indiquons "),_e=r("code"),J=n("predict_with_generate=True"),pe=n("."),this.h()},l(ce){u=l(ce,"P",{});var G=o(u);q=a(G,"La fonctionnalit\xE9 que "),_=l(G,"CODE",{});var Ae=o(_);w=a(Ae,"Seq2SeqTrainer"),Ae.forEach(t),A=a(G," ajoute \xE0 sa superclasse "),v=l(G,"CODE",{});var ge=o(v);T=a(ge,"Trainer"),ge.forEach(t),S=a(G," est la possibilit\xE9 d\u2019utiliser la m\xE9thode "),z=l(G,"CODE",{});var Qe=o(z);C=a(Qe,"generate()"),Qe.forEach(t),F=a(G," pendant l\u2019\xE9valuation ou la pr\xE9diction. Pendant l\u2019entra\xEEnement, le mod\xE8le utilisera les "),D=l(G,"CODE",{});var qe=o(D);y=a(qe,"decoder_input_ids"),qe.forEach(t),R=a(G," avec un masque d\u2019attention assurant qu\u2019il n\u2019utilise pas les "),H=l(G,"EM",{});var fe=o(H);L=a(fe,"tokens"),fe.forEach(t),Y=a(G," apr\xE8s le "),O=l(G,"EM",{});var Me=o(O);V=a(Me,"token"),Me.forEach(t),W=a(G," qu\u2019il essaie de pr\xE9dire, pour acc\xE9l\xE9rer l\u2019entra\xEEnement. Pendant l\u2019inf\xE9rence, nous ne pourrons pas les utiliser puisque nous n\u2019aurons pas d\u2019\xE9tiquettes. Ainsi c\u2019est une bonne id\xE9e d\u2019\xE9valuer notre mod\xE8le avec la m\xEAme configuration."),G.forEach(t),M=c(ce),P=l(ce,"P",{});var ne=o(P);se=a(ne,"Comme nous l\u2019avons vu dans le "),N=l(ne,"A",{href:!0});var Oe=o(N);I=a(Oe,"chapitre 1"),Oe.forEach(t),Q=a(ne,", le d\xE9codeur effectue l\u2019inf\xE9rence en pr\xE9disant les "),ee=l(ne,"EM",{});var ae=o(ee);X=a(ae,"tokens"),ae.forEach(t),ie=a(ne," un par un. C\u2019est quelque chose qui est impl\xE9ment\xE9 en coulisses dans \u{1F917} "),re=l(ne,"EM",{});var ze=o(re);te=a(ze,"Transformers"),ze.forEach(t),me=a(ne," par la m\xE9thode "),le=l(ne,"CODE",{});var ye=o(le);de=a(ye,"generate()"),ye.forEach(t),ue=a(ne,". Le "),ve=l(ne,"CODE",{});var De=o(ve);be=a(De,"Seq2SeqTrainer"),De.forEach(t),$e=a(ne," nous laissera utiliser cette m\xE9thode pour l\u2019\xE9valuation si nous indiquons "),_e=l(ne,"CODE",{});var us=o(_e);J=a(us,"predict_with_generate=True"),us.forEach(t),pe=a(ne,"."),ne.forEach(t),this.h()},h(){h(N,"href","/course/fr/chapter1/6")},m(ce,G){i(ce,u,G),s(u,q),s(u,_),s(_,w),s(u,A),s(u,v),s(v,T),s(u,S),s(u,z),s(z,C),s(u,F),s(u,D),s(D,y),s(u,R),s(u,H),s(H,L),s(u,Y),s(u,O),s(O,V),s(u,W),i(ce,M,G),i(ce,P,G),s(P,se),s(P,N),s(N,I),s(P,Q),s(P,ee),s(ee,X),s(P,ie),s(P,re),s(re,te),s(P,me),s(P,le),s(le,de),s(P,ue),s(P,ve),s(ve,be),s(P,$e),s(P,_e),s(_e,J),s(P,pe)},d(ce){ce&&t(u),ce&&t(M),ce&&t(P)}}}function E_(Z){let u,q,_,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W;return V=new U({props:{code:`import numpy as np


def compute_metrics(eval_preds):
    preds, labels = eval_preds
    # Dans le cas o\xF9 le mod\xE8le retourne plus que les logits de pr\xE9diction
    if isinstance(preds, tuple):
        preds = preds[0]

    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)

    # Remplacer les -100 dans les \xE9tiquettes car nous ne pouvons pas les d\xE9coder
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    # Quelques post-traitements simples
    decoded_preds = [pred.strip() for pred in decoded_preds]
    decoded_labels = [[label.strip()] for label in decoded_labels]

    result = metric.compute(predictions=decoded_preds, references=decoded_labels)
    return {"bleu": result["score"]}`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_preds</span>):
    preds, labels = eval_preds
    <span class="hljs-comment"># Dans le cas o\xF9 le mod\xE8le retourne plus que les logits de pr\xE9diction</span>
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(preds, <span class="hljs-built_in">tuple</span>):
        preds = preds[<span class="hljs-number">0</span>]

    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Remplacer les -100 dans les \xE9tiquettes car nous ne pouvons pas les d\xE9coder</span>
    labels = np.where(labels != -<span class="hljs-number">100</span>, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Quelques post-traitements simples</span>
    decoded_preds = [pred.strip() <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> decoded_preds]
    decoded_labels = [[label.strip()] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> decoded_labels]

    result = metric.compute(predictions=decoded_preds, references=decoded_labels)
    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;bleu&quot;</span>: result[<span class="hljs-string">&quot;score&quot;</span>]}`}}),{c(){u=r("p"),q=n("Pour passer des sorties du mod\xE8le aux textes utilisables par la m\xE9trique, nous allons utiliser la m\xE9thode "),_=r("code"),w=n("tokenizer.batch_decode()"),A=n(". Nous devons juste nettoyer tous les "),v=r("code"),T=n("-100"),S=n(" dans les \xE9tiquettes. Le "),z=r("em"),C=n("tokenizer"),F=n(" fera automatiquement la m\xEAme chose pour le "),D=r("em"),y=n("token"),R=n(" de "),H=r("em"),L=n("padding"),Y=n(" :"),O=d(),E(V.$$.fragment)},l(M){u=l(M,"P",{});var P=o(u);q=a(P,"Pour passer des sorties du mod\xE8le aux textes utilisables par la m\xE9trique, nous allons utiliser la m\xE9thode "),_=l(P,"CODE",{});var se=o(_);w=a(se,"tokenizer.batch_decode()"),se.forEach(t),A=a(P,". Nous devons juste nettoyer tous les "),v=l(P,"CODE",{});var N=o(v);T=a(N,"-100"),N.forEach(t),S=a(P," dans les \xE9tiquettes. Le "),z=l(P,"EM",{});var I=o(z);C=a(I,"tokenizer"),I.forEach(t),F=a(P," fera automatiquement la m\xEAme chose pour le "),D=l(P,"EM",{});var Q=o(D);y=a(Q,"token"),Q.forEach(t),R=a(P," de "),H=l(P,"EM",{});var ee=o(H);L=a(ee,"padding"),ee.forEach(t),Y=a(P," :"),P.forEach(t),O=c(M),j(V.$$.fragment,M)},m(M,P){i(M,u,P),s(u,q),s(u,_),s(_,w),s(u,A),s(u,v),s(v,T),s(u,S),s(u,z),s(z,C),s(u,F),s(u,D),s(D,y),s(u,R),s(u,H),s(H,L),s(u,Y),i(M,O,P),k(V,M,P),W=!0},i(M){W||(b(V.$$.fragment,M),W=!0)},o(M){$(V.$$.fragment,M),W=!1},d(M){M&&t(u),M&&t(O),x(V,M)}}}function j_(Z){let u,q,_,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W;return V=new U({props:{code:`import numpy as np


def compute_metrics():
    all_preds = []
    all_labels = []
    sampled_dataset = tokenized_datasets["validation"].shuffle().select(range(200))
    tf_generate_dataset = sampled_dataset.to_tf_dataset(
        columns=["input_ids", "attention_mask", "labels"],
        collate_fn=data_collator,
        shuffle=False,
        batch_size=4,
    )
    for batch in tf_generate_dataset:
        predictions = model.generate(
            input_ids=batch["input_ids"], attention_mask=batch["attention_mask"]
        )
        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)
        labels = batch["labels"].numpy()
        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)
        decoded_preds = [pred.strip() for pred in decoded_preds]
        decoded_labels = [[label.strip()] for label in decoded_labels]
        all_preds.extend(decoded_preds)
        all_labels.extend(decoded_labels)

    result = metric.compute(predictions=all_preds, references=all_labels)
    return {"bleu": result["score"]}`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>():
    all_preds = []
    all_labels = []
    sampled_dataset = tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>].shuffle().select(<span class="hljs-built_in">range</span>(<span class="hljs-number">200</span>))
    tf_generate_dataset = sampled_dataset.to_tf_dataset(
        columns=[<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>],
        collate_fn=data_collator,
        shuffle=<span class="hljs-literal">False</span>,
        batch_size=<span class="hljs-number">4</span>,
    )
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> tf_generate_dataset:
        predictions = model.generate(
            input_ids=batch[<span class="hljs-string">&quot;input_ids&quot;</span>], attention_mask=batch[<span class="hljs-string">&quot;attention_mask&quot;</span>]
        )
        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=<span class="hljs-literal">True</span>)
        labels = batch[<span class="hljs-string">&quot;labels&quot;</span>].numpy()
        labels = np.where(labels != -<span class="hljs-number">100</span>, labels, tokenizer.pad_token_id)
        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=<span class="hljs-literal">True</span>)
        decoded_preds = [pred.strip() <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> decoded_preds]
        decoded_labels = [[label.strip()] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> decoded_labels]
        all_preds.extend(decoded_preds)
        all_labels.extend(decoded_labels)

    result = metric.compute(predictions=all_preds, references=all_labels)
    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;bleu&quot;</span>: result[<span class="hljs-string">&quot;score&quot;</span>]}`}}),{c(){u=r("p"),q=n("Pour passer des sorties du mod\xE8le aux textes que la m\xE9trique peut utiliser, nous allons utiliser la m\xE9thode "),_=r("code"),w=n("tokenizer.batch_decode()"),A=n(". Nous devons juste nettoyer tous les "),v=r("code"),T=n("-100"),S=n(" dans les \xE9tiquettes. Le "),z=r("em"),C=n("tokenizer"),F=n(" fera automatiquement la m\xEAme chose pour le "),D=r("em"),y=n("token"),R=n(" de "),H=r("em"),L=n("padding"),Y=n(". D\xE9finissons une fonction qui prend notre mod\xE8le et un jeu de donn\xE9es et calcule des m\xE9triques sur ceux-ci. Comme la g\xE9n\xE9ration de longues s\xE9quences peut \xEAtre lente, nous sous-\xE9chantillonnons l\u2019ensemble de validation pour nous assurer que cela ne prend pas une \xE9ternit\xE9 :"),O=d(),E(V.$$.fragment)},l(M){u=l(M,"P",{});var P=o(u);q=a(P,"Pour passer des sorties du mod\xE8le aux textes que la m\xE9trique peut utiliser, nous allons utiliser la m\xE9thode "),_=l(P,"CODE",{});var se=o(_);w=a(se,"tokenizer.batch_decode()"),se.forEach(t),A=a(P,". Nous devons juste nettoyer tous les "),v=l(P,"CODE",{});var N=o(v);T=a(N,"-100"),N.forEach(t),S=a(P," dans les \xE9tiquettes. Le "),z=l(P,"EM",{});var I=o(z);C=a(I,"tokenizer"),I.forEach(t),F=a(P," fera automatiquement la m\xEAme chose pour le "),D=l(P,"EM",{});var Q=o(D);y=a(Q,"token"),Q.forEach(t),R=a(P," de "),H=l(P,"EM",{});var ee=o(H);L=a(ee,"padding"),ee.forEach(t),Y=a(P,". D\xE9finissons une fonction qui prend notre mod\xE8le et un jeu de donn\xE9es et calcule des m\xE9triques sur ceux-ci. Comme la g\xE9n\xE9ration de longues s\xE9quences peut \xEAtre lente, nous sous-\xE9chantillonnons l\u2019ensemble de validation pour nous assurer que cela ne prend pas une \xE9ternit\xE9 :"),P.forEach(t),O=c(M),j(V.$$.fragment,M)},m(M,P){i(M,u,P),s(u,q),s(u,_),s(_,w),s(u,A),s(u,v),s(v,T),s(u,S),s(u,z),s(z,C),s(u,F),s(u,D),s(D,y),s(u,R),s(u,H),s(H,L),s(u,Y),i(M,O,P),k(V,M,P),W=!0},i(M){W||(b(V.$$.fragment,M),W=!0)},o(M){$(V.$$.fragment,M),W=!1},d(M){M&&t(u),M&&t(O),x(V,M)}}}function k_(Z){let u,q,_,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se,N,I,Q,ee,X,ie,re,te,me,le,de,ue,ve,be,$e,_e,J,pe,ce,G,Ae,ge,Qe,qe,fe,Me,ne,Oe,ae,ze,ye,De,us,Ue,es,ps,ss,Pe,Fe,He,Ee,Xs,Ie,Ws,Qs,Je,Re,As,Ne,g,oe,gs,je,Be,he,Ke,Le,pt,xe,ts,dt,qs,Ye,Js,Ve,ds,Te,ct,cs,ns,Ms,Ys,Ge,Vt,Es,Ns,Ls,Ce,kt,as,Gt,ms,ke,xt,wt,mt,zt,yt,Pt,Xt,fs,xs,_s,Xe,Ct,ws,Dt,ft,js,Tt,We,Wt,Os,St,Qt,Us,zs,Se,ys,rs,Zs,_t,At,Jt,hs,Yt,Zt,et,vs,Ps,Cs,ht,st,vt,Ze;return y=new U({props:{code:`from transformers import Seq2SeqTrainingArguments

args = Seq2SeqTrainingArguments(
    f"marian-finetuned-kde4-en-to-fr",
    evaluation_strategy="no",
    save_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=32,
    per_device_eval_batch_size=64,
    weight_decay=0.01,
    save_total_limit=3,
    num_train_epochs=3,
    predict_with_generate=True,
    fp16=True,
    push_to_hub=True,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainingArguments

args = Seq2SeqTrainingArguments(
    <span class="hljs-string">f&quot;marian-finetuned-kde4-en-to-fr&quot;</span>,
    evaluation_strategy=<span class="hljs-string">&quot;no&quot;</span>,
    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    per_device_train_batch_size=<span class="hljs-number">32</span>,
    per_device_eval_batch_size=<span class="hljs-number">64</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
    save_total_limit=<span class="hljs-number">3</span>,
    num_train_epochs=<span class="hljs-number">3</span>,
    predict_with_generate=<span class="hljs-literal">True</span>,
    fp16=<span class="hljs-literal">True</span>,
    push_to_hub=<span class="hljs-literal">True</span>,
)`}}),Fe=new Ta({props:{$$slots:{default:[w_]},$$scope:{ctx:Z}}}),Re=new U({props:{code:`from transformers import Seq2SeqTrainer

trainer = Seq2SeqTrainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainer

trainer = Seq2SeqTrainer(
    model,
    args,
    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)`}}),he=new U({props:{code:"trainer.evaluate(max_length=max_target_length)",highlighted:"trainer.evaluate(max_length=max_target_length)"}}),Le=new U({props:{code:`{'eval_loss': 1.6964408159255981,
 'eval_bleu': 39.26865061007616,
 'eval_runtime': 965.8884,
 'eval_samples_per_second': 21.76,
 'eval_steps_per_second': 0.341}`,highlighted:`{<span class="hljs-string">&#x27;eval_loss&#x27;</span>: <span class="hljs-number">1.6964408159255981</span>,
 <span class="hljs-string">&#x27;eval_bleu&#x27;</span>: <span class="hljs-number">39.26865061007616</span>,
 <span class="hljs-string">&#x27;eval_runtime&#x27;</span>: <span class="hljs-number">965.8884</span>,
 <span class="hljs-string">&#x27;eval_samples_per_second&#x27;</span>: <span class="hljs-number">21.76</span>,
 <span class="hljs-string">&#x27;eval_steps_per_second&#x27;</span>: <span class="hljs-number">0.341</span>}`}}),Ve=new U({props:{code:"trainer.train()",highlighted:"trainer.train()"}}),Ns=new U({props:{code:"trainer.evaluate(max_length=max_target_length)",highlighted:"trainer.evaluate(max_length=max_target_length)"}}),Ce=new U({props:{code:`{'eval_loss': 0.8558505773544312,
 'eval_bleu': 52.94161337775576,
 'eval_runtime': 714.2576,
 'eval_samples_per_second': 29.426,
 'eval_steps_per_second': 0.461,
 'epoch': 3.0}`,highlighted:`{<span class="hljs-string">&#x27;eval_loss&#x27;</span>: <span class="hljs-number">0.8558505773544312</span>,
 <span class="hljs-string">&#x27;eval_bleu&#x27;</span>: <span class="hljs-number">52.94161337775576</span>,
 <span class="hljs-string">&#x27;eval_runtime&#x27;</span>: <span class="hljs-number">714.2576</span>,
 <span class="hljs-string">&#x27;eval_samples_per_second&#x27;</span>: <span class="hljs-number">29.426</span>,
 <span class="hljs-string">&#x27;eval_steps_per_second&#x27;</span>: <span class="hljs-number">0.461</span>,
 <span class="hljs-string">&#x27;epoch&#x27;</span>: <span class="hljs-number">3.0</span>}`}}),We=new U({props:{code:'trainer.push_to_hub(tags="translation", commit_message="Training complete")',highlighted:'trainer.push_to_hub(tags=<span class="hljs-string">&quot;translation&quot;</span>, commit_message=<span class="hljs-string">&quot;Training complete&quot;</span>)'}}),Us=new U({props:{code:"'https://huggingface.co/sgugger/marian-finetuned-kde4-en-to-fr/commit/3601d621e3baae2bc63d3311452535f8f58f6ef3'",highlighted:'<span class="hljs-string">&#x27;https://huggingface.co/sgugger/marian-finetuned-kde4-en-to-fr/commit/3601d621e3baae2bc63d3311452535f8f58f6ef3&#x27;</span>'}}),{c(){u=r("p"),q=n("Une fois ceci fait, nous pouvons d\xE9finir notre "),_=r("code"),w=n("Seq2SeqTrainingArguments"),A=n(". Comme pour le "),v=r("code"),T=n("Trainer"),S=n(", nous utilisons une sous-classe de "),z=r("code"),C=n("TrainingArguments"),F=n(" qui contient quelques champs suppl\xE9mentaires :"),D=d(),E(y.$$.fragment),R=d(),H=r("p"),L=n("En dehors des hyperparam\xE8tres habituels (comme le taux d\u2019apprentissage, le nombre d\u2019\xE9poques, la taille des batchs et une le taux de d\xE9croissance des poids), voici quelques changements par rapport \xE0 ce que nous avons vu dans les sections pr\xE9c\xE9dentes :"),Y=d(),O=r("ul"),V=r("li"),W=n("Nous ne d\xE9finissons pas d\u2019\xE9valuation car elle prend du temps. Nous allons juste \xE9valuer une fois notre mod\xE8le avant l\u2019entra\xEEnement et apr\xE8s."),M=d(),P=r("li"),se=n("Nous avons mis "),N=r("code"),I=n("fp16=True"),Q=n(", ce qui acc\xE9l\xE8re l\u2019entra\xEEnement sur les GPUs modernes."),ee=d(),X=r("li"),ie=n("Nous d\xE9finissons "),re=r("code"),te=n("predict_with_generate=True"),me=n(", comme discut\xE9 ci-dessus."),le=d(),de=r("li"),ue=n("Nous utilisons "),ve=r("code"),be=n("push_to_hub=True"),$e=n(" pour t\xE9l\xE9charger le mod\xE8le sur le "),_e=r("em"),J=n("Hub"),pe=n(" \xE0 la fin de chaque \xE9poque."),ce=d(),G=r("p"),Ae=n("Notez que vous pouvez sp\xE9cifier le nom complet du d\xE9p\xF4t vers lequel vous voulez pousser avec l\u2019argument "),ge=r("code"),Qe=n("hub_model_id"),qe=n(" (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),fe=r("a"),Me=r("code"),ne=n("huggingface-course"),Oe=n(", nous avons ajout\xE9 "),ae=r("code"),ze=n('hub_model_id="huggingface-course/marian-finetuned-kde4-en-to-fr"'),ye=n(" \xE0 "),De=r("code"),us=n("Seq2SeqTrainingArguments"),Ue=n(". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace et nomm\xE9 d\u2019apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini. Dans notre cas ce sera "),es=r("code"),ps=n('"sgugger/marian-finetuned-kde4-en-to-fr"'),ss=n(" (qui est le mod\xE8le que nous avons li\xE9 au d\xE9but de cette section)."),Pe=d(),E(Fe.$$.fragment),He=d(),Ee=r("p"),Xs=n("Enfin, nous passons tout au "),Ie=r("code"),Ws=n("Seq2SeqTrainer"),Qs=n(" :"),Je=d(),E(Re.$$.fragment),As=d(),Ne=r("p"),g=n("Avant d\u2019entra\xEEner, nous allons d\u2019abord regarder le score obtenu par notre mod\xE8le, pour v\xE9rifier que nous n\u2019aggravons pas les choses avec notre "),oe=r("em"),gs=n("finetuning"),je=n(". Cette commande va prendre un peu de temps, vous pouvez donc prendre un caf\xE9 pendant qu\u2019elle s\u2019ex\xE9cute :"),Be=d(),E(he.$$.fragment),Ke=d(),E(Le.$$.fragment),pt=d(),xe=r("p"),ts=n("Un score BLEU de 39 n\u2019est pas trop mauvais, ce qui refl\xE8te le fait que notre mod\xE8le est d\xE9j\xE0 bon pour traduire des phrases anglaises en phrases fran\xE7aises."),dt=d(),qs=r("p"),Ye=n("Vient ensuite l\u2019entra\xEEnement, qui prendra \xE9galement un peu de temps :"),Js=d(),E(Ve.$$.fragment),ds=d(),Te=r("p"),ct=n("Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),cs=r("em"),ns=n("Hub"),Ms=n(" en arri\xE8re-plan. De cette fa\xE7on, vous serez en mesure de reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),Ys=d(),Ge=r("p"),Vt=n("Une fois l\u2019entra\xEEnement termin\xE9, nous \xE9valuons \xE0 nouveau notre mod\xE8le. Avec un peu de chance, nous verrons une am\xE9lioration du score BLEU !"),Es=d(),E(Ns.$$.fragment),Ls=d(),E(Ce.$$.fragment),kt=d(),as=r("p"),Gt=n("C\u2019est une am\xE9lioration de pr\xE8s de 14 points, ce qui est formidable."),ms=d(),ke=r("p"),xt=n("Enfin, nous utilisons la m\xE9thode "),wt=r("code"),mt=n("push_to_hub()"),zt=n(" pour nous assurer que nous t\xE9l\xE9chargeons la derni\xE8re version du mod\xE8le. "),yt=r("code"),Pt=n("Trainer"),Xt=n(" r\xE9dige \xE9galement une carte de mod\xE8le avec tous les r\xE9sultats de l\u2019\xE9valuation et la t\xE9l\xE9charge. Cette carte de mod\xE8le contient des m\xE9tadonn\xE9es qui aident le "),fs=r("em"),xs=n("Hub"),_s=n(" \xE0 choisir le "),Xe=r("em"),Ct=n("widget"),ws=n(" pour l\u2019inf\xE9rence. Habituellement, il n\u2019y a pas besoin de dire quoi que ce soit car il peut inf\xE9rer le bon "),Dt=r("em"),ft=n("widget"),js=n(" \xE0 partir de la classe du mod\xE8le, mais dans ce cas, la m\xEAme classe de mod\xE8le peut \xEAtre utilis\xE9e pour toutes sortes de probl\xE8mes de s\xE9quence \xE0 s\xE9quence. Ainsi nous sp\xE9cifions que c\u2019est un mod\xE8le de traduction :"),Tt=d(),E(We.$$.fragment),Wt=d(),Os=r("p"),St=n("Cette commande renvoie l\u2019URL du commit qu\u2019elle vient de faire, si vous voulez l\u2019inspecter :"),Qt=d(),E(Us.$$.fragment),zs=d(),Se=r("p"),ys=n("\xC0 ce stade, vous pouvez utiliser le "),rs=r("em"),Zs=n("widget"),_t=n(" d\u2019inf\xE9rence sur le "),At=r("em"),Jt=n("Hub"),hs=n(" pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),Yt=r("em"),Zt=n("finetuner"),et=n(" un mod\xE8le sur une t\xE2che de traduction. F\xE9licitations !"),vs=d(),Ps=r("p"),Cs=n("Si vous souhaitez vous plonger un peu plus profond\xE9ment dans la boucle d\u2019entra\xEEnement, nous allons maintenant vous montrer comment faire la m\xEAme chose en utilisant \u{1F917} "),ht=r("em"),st=n("Accelerate"),vt=n("."),this.h()},l(f){u=l(f,"P",{});var B=o(u);q=a(B,"Une fois ceci fait, nous pouvons d\xE9finir notre "),_=l(B,"CODE",{});var bs=o(_);w=a(bs,"Seq2SeqTrainingArguments"),bs.forEach(t),A=a(B,". Comme pour le "),v=l(B,"CODE",{});var Dn=o(v);T=a(Dn,"Trainer"),Dn.forEach(t),S=a(B,", nous utilisons une sous-classe de "),z=l(B,"CODE",{});var tt=o(z);C=a(tt,"TrainingArguments"),tt.forEach(t),F=a(B," qui contient quelques champs suppl\xE9mentaires :"),B.forEach(t),D=c(f),j(y.$$.fragment,f),R=c(f),H=l(f,"P",{});var en=o(H);L=a(en,"En dehors des hyperparam\xE8tres habituels (comme le taux d\u2019apprentissage, le nombre d\u2019\xE9poques, la taille des batchs et une le taux de d\xE9croissance des poids), voici quelques changements par rapport \xE0 ce que nous avons vu dans les sections pr\xE9c\xE9dentes :"),en.forEach(t),Y=c(f),O=l(f,"UL",{});var Fs=o(O);V=l(Fs,"LI",{});var sn=o(V);W=a(sn,"Nous ne d\xE9finissons pas d\u2019\xE9valuation car elle prend du temps. Nous allons juste \xE9valuer une fois notre mod\xE8le avant l\u2019entra\xEEnement et apr\xE8s."),sn.forEach(t),M=c(Fs),P=l(Fs,"LI",{});var bt=o(P);se=a(bt,"Nous avons mis "),N=l(bt,"CODE",{});var Tn=o(N);I=a(Tn,"fp16=True"),Tn.forEach(t),Q=a(bt,", ce qui acc\xE9l\xE8re l\u2019entra\xEEnement sur les GPUs modernes."),bt.forEach(t),ee=c(Fs),X=l(Fs,"LI",{});var Mt=o(X);ie=a(Mt,"Nous d\xE9finissons "),re=l(Mt,"CODE",{});var Hs=o(re);te=a(Hs,"predict_with_generate=True"),Hs.forEach(t),me=a(Mt,", comme discut\xE9 ci-dessus."),Mt.forEach(t),le=c(Fs),de=l(Fs,"LI",{});var nt=o(de);ue=a(nt,"Nous utilisons "),ve=l(nt,"CODE",{});var $t=o(ve);be=a($t,"push_to_hub=True"),$t.forEach(t),$e=a(nt," pour t\xE9l\xE9charger le mod\xE8le sur le "),_e=l(nt,"EM",{});var tn=o(_e);J=a(tn,"Hub"),tn.forEach(t),pe=a(nt," \xE0 la fin de chaque \xE9poque."),nt.forEach(t),Fs.forEach(t),ce=c(f),G=l(f,"P",{});var we=o(G);Ae=a(we,"Notez que vous pouvez sp\xE9cifier le nom complet du d\xE9p\xF4t vers lequel vous voulez pousser avec l\u2019argument "),ge=l(we,"CODE",{});var vn=o(ge);Qe=a(vn,"hub_model_id"),vn.forEach(t),qe=a(we," (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),fe=l(we,"A",{href:!0,rel:!0});var at=o(fe);Me=l(at,"CODE",{});var rt=o(Me);ne=a(rt,"huggingface-course"),rt.forEach(t),at.forEach(t),Oe=a(we,", nous avons ajout\xE9 "),ae=l(we,"CODE",{});var ks=o(ae);ze=a(ks,'hub_model_id="huggingface-course/marian-finetuned-kde4-en-to-fr"'),ks.forEach(t),ye=a(we," \xE0 "),De=l(we,"CODE",{});var Nt=o(De);us=a(Nt,"Seq2SeqTrainingArguments"),Nt.forEach(t),Ue=a(we,". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace et nomm\xE9 d\u2019apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini. Dans notre cas ce sera "),es=l(we,"CODE",{});var nn=o(es);ps=a(nn,'"sgugger/marian-finetuned-kde4-en-to-fr"'),nn.forEach(t),ss=a(we," (qui est le mod\xE8le que nous avons li\xE9 au d\xE9but de cette section)."),we.forEach(t),Pe=c(f),j(Fe.$$.fragment,f),He=c(f),Ee=l(f,"P",{});var Lt=o(Ee);Xs=a(Lt,"Enfin, nous passons tout au "),Ie=l(Lt,"CODE",{});var gt=o(Ie);Ws=a(gt,"Seq2SeqTrainer"),gt.forEach(t),Qs=a(Lt," :"),Lt.forEach(t),Je=c(f),j(Re.$$.fragment,f),As=c(f),Ne=l(f,"P",{});var Ds=o(Ne);g=a(Ds,"Avant d\u2019entra\xEEner, nous allons d\u2019abord regarder le score obtenu par notre mod\xE8le, pour v\xE9rifier que nous n\u2019aggravons pas les choses avec notre "),oe=l(Ds,"EM",{});var Is=o(oe);gs=a(Is,"finetuning"),Is.forEach(t),je=a(Ds,". Cette commande va prendre un peu de temps, vous pouvez donc prendre un caf\xE9 pendant qu\u2019elle s\u2019ex\xE9cute :"),Ds.forEach(t),Be=c(f),j(he.$$.fragment,f),Ke=c(f),j(Le.$$.fragment,f),pt=c(f),xe=l(f,"P",{});var bn=o(xe);ts=a(bn,"Un score BLEU de 39 n\u2019est pas trop mauvais, ce qui refl\xE8te le fait que notre mod\xE8le est d\xE9j\xE0 bon pour traduire des phrases anglaises en phrases fran\xE7aises."),bn.forEach(t),dt=c(f),qs=l(f,"P",{});var lt=o(qs);Ye=a(lt,"Vient ensuite l\u2019entra\xEEnement, qui prendra \xE9galement un peu de temps :"),lt.forEach(t),Js=c(f),j(Ve.$$.fragment,f),ds=c(f),Te=l(f,"P",{});var Ot=o(Te);ct=a(Ot,"Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),cs=l(Ot,"EM",{});var m=o(cs);ns=a(m,"Hub"),m.forEach(t),Ms=a(Ot," en arri\xE8re-plan. De cette fa\xE7on, vous serez en mesure de reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),Ot.forEach(t),Ys=c(f),Ge=l(f,"P",{});var K=o(Ge);Vt=a(K,"Une fois l\u2019entra\xEEnement termin\xE9, nous \xE9valuons \xE0 nouveau notre mod\xE8le. Avec un peu de chance, nous verrons une am\xE9lioration du score BLEU !"),K.forEach(t),Es=c(f),j(Ns.$$.fragment,f),Ls=c(f),j(Ce.$$.fragment,f),kt=c(f),as=l(f,"P",{});var Jn=o(as);Gt=a(Jn,"C\u2019est une am\xE9lioration de pr\xE8s de 14 points, ce qui est formidable."),Jn.forEach(t),ms=c(f),ke=l(f,"P",{});var ls=o(ke);xt=a(ls,"Enfin, nous utilisons la m\xE9thode "),wt=l(ls,"CODE",{});var Ut=o(wt);mt=a(Ut,"push_to_hub()"),Ut.forEach(t),zt=a(ls," pour nous assurer que nous t\xE9l\xE9chargeons la derni\xE8re version du mod\xE8le. "),yt=l(ls,"CODE",{});var qt=o(yt);Pt=a(qt,"Trainer"),qt.forEach(t),Xt=a(ls," r\xE9dige \xE9galement une carte de mod\xE8le avec tous les r\xE9sultats de l\u2019\xE9valuation et la t\xE9l\xE9charge. Cette carte de mod\xE8le contient des m\xE9tadonn\xE9es qui aident le "),fs=l(ls,"EM",{});var Ft=o(fs);xs=a(Ft,"Hub"),Ft.forEach(t),_s=a(ls," \xE0 choisir le "),Xe=l(ls,"EM",{});var Sn=o(Xe);Ct=a(Sn,"widget"),Sn.forEach(t),ws=a(ls," pour l\u2019inf\xE9rence. Habituellement, il n\u2019y a pas besoin de dire quoi que ce soit car il peut inf\xE9rer le bon "),Dt=l(ls,"EM",{});var Bs=o(Dt);ft=a(Bs,"widget"),Bs.forEach(t),js=a(ls," \xE0 partir de la classe du mod\xE8le, mais dans ce cas, la m\xEAme classe de mod\xE8le peut \xEAtre utilis\xE9e pour toutes sortes de probl\xE8mes de s\xE9quence \xE0 s\xE9quence. Ainsi nous sp\xE9cifions que c\u2019est un mod\xE8le de traduction :"),ls.forEach(t),Tt=c(f),j(We.$$.fragment,f),Wt=c(f),Os=l(f,"P",{});var Yn=o(Os);St=a(Yn,"Cette commande renvoie l\u2019URL du commit qu\u2019elle vient de faire, si vous voulez l\u2019inspecter :"),Yn.forEach(t),Qt=c(f),j(Us.$$.fragment,f),zs=c(f),Se=l(f,"P",{});var Ts=o(Se);ys=a(Ts,"\xC0 ce stade, vous pouvez utiliser le "),rs=l(Ts,"EM",{});var Zn=o(rs);Zs=a(Zn,"widget"),Zn.forEach(t),_t=a(Ts," d\u2019inf\xE9rence sur le "),At=l(Ts,"EM",{});var Ht=o(At);Jt=a(Ht,"Hub"),Ht.forEach(t),hs=a(Ts," pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),Yt=l(Ts,"EM",{});var An=o(Yt);Zt=a(An,"finetuner"),An.forEach(t),et=a(Ts," un mod\xE8le sur une t\xE2che de traduction. F\xE9licitations !"),Ts.forEach(t),vs=c(f),Ps=l(f,"P",{});var ot=o(Ps);Cs=a(ot,"Si vous souhaitez vous plonger un peu plus profond\xE9ment dans la boucle d\u2019entra\xEEnement, nous allons maintenant vous montrer comment faire la m\xEAme chose en utilisant \u{1F917} "),ht=l(ot,"EM",{});var an=o(ht);st=a(an,"Accelerate"),an.forEach(t),vt=a(ot,"."),ot.forEach(t),this.h()},h(){h(fe,"href","https://huggingface.co/huggingface-course"),h(fe,"rel","nofollow")},m(f,B){i(f,u,B),s(u,q),s(u,_),s(_,w),s(u,A),s(u,v),s(v,T),s(u,S),s(u,z),s(z,C),s(u,F),i(f,D,B),k(y,f,B),i(f,R,B),i(f,H,B),s(H,L),i(f,Y,B),i(f,O,B),s(O,V),s(V,W),s(O,M),s(O,P),s(P,se),s(P,N),s(N,I),s(P,Q),s(O,ee),s(O,X),s(X,ie),s(X,re),s(re,te),s(X,me),s(O,le),s(O,de),s(de,ue),s(de,ve),s(ve,be),s(de,$e),s(de,_e),s(_e,J),s(de,pe),i(f,ce,B),i(f,G,B),s(G,Ae),s(G,ge),s(ge,Qe),s(G,qe),s(G,fe),s(fe,Me),s(Me,ne),s(G,Oe),s(G,ae),s(ae,ze),s(G,ye),s(G,De),s(De,us),s(G,Ue),s(G,es),s(es,ps),s(G,ss),i(f,Pe,B),k(Fe,f,B),i(f,He,B),i(f,Ee,B),s(Ee,Xs),s(Ee,Ie),s(Ie,Ws),s(Ee,Qs),i(f,Je,B),k(Re,f,B),i(f,As,B),i(f,Ne,B),s(Ne,g),s(Ne,oe),s(oe,gs),s(Ne,je),i(f,Be,B),k(he,f,B),i(f,Ke,B),k(Le,f,B),i(f,pt,B),i(f,xe,B),s(xe,ts),i(f,dt,B),i(f,qs,B),s(qs,Ye),i(f,Js,B),k(Ve,f,B),i(f,ds,B),i(f,Te,B),s(Te,ct),s(Te,cs),s(cs,ns),s(Te,Ms),i(f,Ys,B),i(f,Ge,B),s(Ge,Vt),i(f,Es,B),k(Ns,f,B),i(f,Ls,B),k(Ce,f,B),i(f,kt,B),i(f,as,B),s(as,Gt),i(f,ms,B),i(f,ke,B),s(ke,xt),s(ke,wt),s(wt,mt),s(ke,zt),s(ke,yt),s(yt,Pt),s(ke,Xt),s(ke,fs),s(fs,xs),s(ke,_s),s(ke,Xe),s(Xe,Ct),s(ke,ws),s(ke,Dt),s(Dt,ft),s(ke,js),i(f,Tt,B),k(We,f,B),i(f,Wt,B),i(f,Os,B),s(Os,St),i(f,Qt,B),k(Us,f,B),i(f,zs,B),i(f,Se,B),s(Se,ys),s(Se,rs),s(rs,Zs),s(Se,_t),s(Se,At),s(At,Jt),s(Se,hs),s(Se,Yt),s(Yt,Zt),s(Se,et),i(f,vs,B),i(f,Ps,B),s(Ps,Cs),s(Ps,ht),s(ht,st),s(Ps,vt),Ze=!0},i(f){Ze||(b(y.$$.fragment,f),b(Fe.$$.fragment,f),b(Re.$$.fragment,f),b(he.$$.fragment,f),b(Le.$$.fragment,f),b(Ve.$$.fragment,f),b(Ns.$$.fragment,f),b(Ce.$$.fragment,f),b(We.$$.fragment,f),b(Us.$$.fragment,f),Ze=!0)},o(f){$(y.$$.fragment,f),$(Fe.$$.fragment,f),$(Re.$$.fragment,f),$(he.$$.fragment,f),$(Le.$$.fragment,f),$(Ve.$$.fragment,f),$(Ns.$$.fragment,f),$(Ce.$$.fragment,f),$(We.$$.fragment,f),$(Us.$$.fragment,f),Ze=!1},d(f){f&&t(u),f&&t(D),x(y,f),f&&t(R),f&&t(H),f&&t(Y),f&&t(O),f&&t(ce),f&&t(G),f&&t(Pe),x(Fe,f),f&&t(He),f&&t(Ee),f&&t(Je),x(Re,f),f&&t(As),f&&t(Ne),f&&t(Be),x(he,f),f&&t(Ke),x(Le,f),f&&t(pt),f&&t(xe),f&&t(dt),f&&t(qs),f&&t(Js),x(Ve,f),f&&t(ds),f&&t(Te),f&&t(Ys),f&&t(Ge),f&&t(Es),x(Ns,f),f&&t(Ls),x(Ce,f),f&&t(kt),f&&t(as),f&&t(ms),f&&t(ke),f&&t(Tt),x(We,f),f&&t(Wt),f&&t(Os),f&&t(Qt),x(Us,f),f&&t(zs),f&&t(Se),f&&t(vs),f&&t(Ps)}}}function x_(Z){let u,q,_,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se,N,I,Q,ee,X,ie,re,te,me,le,de,ue,ve,be,$e,_e,J,pe,ce,G,Ae,ge,Qe,qe,fe,Me,ne,Oe,ae,ze,ye,De,us,Ue,es,ps,ss,Pe,Fe,He,Ee,Xs,Ie,Ws,Qs,Je,Re,As,Ne;return w=new U({props:{code:"print(compute_metrics())",highlighted:'<span class="hljs-built_in">print</span>(compute_metrics())'}}),v=new U({props:{code:"{'bleu': 33.26983701454733}",highlighted:'{&#x27;bleu&#x27;: <span class="hljs-number">33.26983701454733</span>}'}}),R=new U({props:{code:`from transformers import create_optimizer
from transformers.keras_callbacks import PushToHubCallback
import tensorflow as tf

# Le nombre d'\xE9tapes d'entra\xEEnement est le nombre d'\xE9chantillons dans le jeu de donn\xE9es, divis\xE9 par la taille du batch,
# puis multipli\xE9 par le nombre total d'\xE9poques. Notez que le jeu de donn\xE9es tf_train_dataset est ici un tf.data.Dataset,
# et non le jeu de donn\xE9es original donc son len() est d\xE9j\xE0 num_samples // batch_size.
num_epochs = 3
num_train_steps = len(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
    init_lr=5e-5,
    num_warmup_steps=0,
    num_train_steps=num_train_steps,
    weight_decay_rate=0.01,
)
model.compile(optimizer=optimizer)

# Entra\xEEner en mixed-precision float16
tf.keras.mixed_precision.set_global_policy("mixed_float16")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer
<span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-comment"># Le nombre d&#x27;\xE9tapes d&#x27;entra\xEEnement est le nombre d&#x27;\xE9chantillons dans le jeu de donn\xE9es, divis\xE9 par la taille du batch,</span>
<span class="hljs-comment"># puis multipli\xE9 par le nombre total d&#x27;\xE9poques. Notez que le jeu de donn\xE9es tf_train_dataset est ici un tf.data.Dataset,</span>
<span class="hljs-comment"># et non le jeu de donn\xE9es original donc son len() est d\xE9j\xE0 num_samples // batch_size.</span>
num_epochs = <span class="hljs-number">3</span>
num_train_steps = <span class="hljs-built_in">len</span>(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
    init_lr=<span class="hljs-number">5e-5</span>,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_train_steps=num_train_steps,
    weight_decay_rate=<span class="hljs-number">0.01</span>,
)
model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)

<span class="hljs-comment"># Entra\xEEner en mixed-precision float16</span>
tf.keras.mixed_precision.set_global_policy(<span class="hljs-string">&quot;mixed_float16&quot;</span>)`}}),te=new U({props:{code:`from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(
    output_dir="marian-finetuned-kde4-en-to-fr", tokenizer=tokenizer
)

model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=[callback],
    epochs=num_epochs,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback

callback = PushToHubCallback(
    output_dir=<span class="hljs-string">&quot;marian-finetuned-kde4-en-to-fr&quot;</span>, tokenizer=tokenizer
)

model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=[callback],
    epochs=num_epochs,
)`}}),ae=new Ta({props:{$$slots:{default:[z_]},$$scope:{ctx:Z}}}),Ue=new U({props:{code:"print(compute_metrics())",highlighted:'<span class="hljs-built_in">print</span>(compute_metrics())'}}),ps=new U({props:{code:"{'bleu': 57.334066271545865}",highlighted:'{&#x27;bleu&#x27;: <span class="hljs-number">57.334066271545865</span>}'}}),{c(){u=r("p"),q=n("Avant de commencer, voyons quel type de r\xE9sultats nous obtenons avec notre mod\xE8le sans entra\xEEnement :"),_=d(),E(w.$$.fragment),A=d(),E(v.$$.fragment),T=d(),S=r("p"),z=n("Une fois ceci fait, nous pouvons pr\xE9parer tout ce dont nous avons besoin pour compiler et entra\xEEner notre mod\xE8le. Notez l\u2019utilisation de "),C=r("code"),F=n('tf.keras.mixed_precision.set_global_policy("mixed_float16")'),D=n(". Ceci indiquera \xE0 Keras de s\u2019entra\xEEner en utilisant float16, ce qui peut donner un gain de vitesse significatif sur les GPUs qui le supportent (Nvidia 20xx/V100 ou plus r\xE9cent)."),y=d(),E(R.$$.fragment),H=d(),L=r("p"),Y=n("Ensuite, nous d\xE9finissons un "),O=r("code"),V=n("PushToHubCallback"),W=n(" pour t\xE9l\xE9charger notre mod\xE8le sur le "),M=r("em"),P=n("Hub"),se=n(" pendant l\u2019entra\xEEnement, comme nous l\u2019avons vu dans la "),N=r("a"),I=n("section 2"),Q=n(", puis nous entra\xEEnons simplement le mod\xE8le avec ce "),ee=r("em"),X=n("callback"),ie=n(" :"),re=d(),E(te.$$.fragment),me=d(),le=r("p"),de=n("Notez que vous pouvez sp\xE9cifier le nom du d\xE9p\xF4t vers lequel vous voulez pousser le mod\xE8le avec l\u2019argument "),ue=r("code"),ve=n("hub_model_id"),be=n(" (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),$e=r("a"),_e=r("code"),J=n("huggingface-course"),pe=n(", nous avons ajout\xE9 "),ce=r("code"),G=n('hub_model_id="huggingface-course/marian-finetuned-kde4-en-to-fr"'),Ae=n(" dans "),ge=r("code"),Qe=n("Seq2SeqTrainingArguments"),qe=n(". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace et nomm\xE9 apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini. Ici ce sera "),fe=r("code"),Me=n('"sgugger/marian-finetuned-kde4-en-to-fr"'),ne=n(" (qui est le mod\xE8le que nous avons li\xE9 au d\xE9but de cette section)."),Oe=d(),E(ae.$$.fragment),ze=d(),ye=r("p"),De=n("Enfin, voyons \xE0 quoi ressemblent nos m\xE9triques maintenant que l\u2019entra\xEEnement est termin\xE9 :"),us=d(),E(Ue.$$.fragment),es=d(),E(ps.$$.fragment),ss=d(),Pe=r("p"),Fe=n("\xC0 ce stade, vous pouvez utiliser le "),He=r("em"),Ee=n("widget"),Xs=n(" d\u2019inf\xE9rence sur le "),Ie=r("em"),Ws=n("Hub"),Qs=n(" pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),Je=r("em"),Re=n("finetuner"),As=n(" un mod\xE8le sur une t\xE2che de traduction. F\xE9licitations !"),this.h()},l(g){u=l(g,"P",{});var oe=o(u);q=a(oe,"Avant de commencer, voyons quel type de r\xE9sultats nous obtenons avec notre mod\xE8le sans entra\xEEnement :"),oe.forEach(t),_=c(g),j(w.$$.fragment,g),A=c(g),j(v.$$.fragment,g),T=c(g),S=l(g,"P",{});var gs=o(S);z=a(gs,"Une fois ceci fait, nous pouvons pr\xE9parer tout ce dont nous avons besoin pour compiler et entra\xEEner notre mod\xE8le. Notez l\u2019utilisation de "),C=l(gs,"CODE",{});var je=o(C);F=a(je,'tf.keras.mixed_precision.set_global_policy("mixed_float16")'),je.forEach(t),D=a(gs,". Ceci indiquera \xE0 Keras de s\u2019entra\xEEner en utilisant float16, ce qui peut donner un gain de vitesse significatif sur les GPUs qui le supportent (Nvidia 20xx/V100 ou plus r\xE9cent)."),gs.forEach(t),y=c(g),j(R.$$.fragment,g),H=c(g),L=l(g,"P",{});var Be=o(L);Y=a(Be,"Ensuite, nous d\xE9finissons un "),O=l(Be,"CODE",{});var he=o(O);V=a(he,"PushToHubCallback"),he.forEach(t),W=a(Be," pour t\xE9l\xE9charger notre mod\xE8le sur le "),M=l(Be,"EM",{});var Ke=o(M);P=a(Ke,"Hub"),Ke.forEach(t),se=a(Be," pendant l\u2019entra\xEEnement, comme nous l\u2019avons vu dans la "),N=l(Be,"A",{href:!0});var Le=o(N);I=a(Le,"section 2"),Le.forEach(t),Q=a(Be,", puis nous entra\xEEnons simplement le mod\xE8le avec ce "),ee=l(Be,"EM",{});var pt=o(ee);X=a(pt,"callback"),pt.forEach(t),ie=a(Be," :"),Be.forEach(t),re=c(g),j(te.$$.fragment,g),me=c(g),le=l(g,"P",{});var xe=o(le);de=a(xe,"Notez que vous pouvez sp\xE9cifier le nom du d\xE9p\xF4t vers lequel vous voulez pousser le mod\xE8le avec l\u2019argument "),ue=l(xe,"CODE",{});var ts=o(ue);ve=a(ts,"hub_model_id"),ts.forEach(t),be=a(xe," (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),$e=l(xe,"A",{href:!0,rel:!0});var dt=o($e);_e=l(dt,"CODE",{});var qs=o(_e);J=a(qs,"huggingface-course"),qs.forEach(t),dt.forEach(t),pe=a(xe,", nous avons ajout\xE9 "),ce=l(xe,"CODE",{});var Ye=o(ce);G=a(Ye,'hub_model_id="huggingface-course/marian-finetuned-kde4-en-to-fr"'),Ye.forEach(t),Ae=a(xe," dans "),ge=l(xe,"CODE",{});var Js=o(ge);Qe=a(Js,"Seq2SeqTrainingArguments"),Js.forEach(t),qe=a(xe,". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace et nomm\xE9 apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini. Ici ce sera "),fe=l(xe,"CODE",{});var Ve=o(fe);Me=a(Ve,'"sgugger/marian-finetuned-kde4-en-to-fr"'),Ve.forEach(t),ne=a(xe," (qui est le mod\xE8le que nous avons li\xE9 au d\xE9but de cette section)."),xe.forEach(t),Oe=c(g),j(ae.$$.fragment,g),ze=c(g),ye=l(g,"P",{});var ds=o(ye);De=a(ds,"Enfin, voyons \xE0 quoi ressemblent nos m\xE9triques maintenant que l\u2019entra\xEEnement est termin\xE9 :"),ds.forEach(t),us=c(g),j(Ue.$$.fragment,g),es=c(g),j(ps.$$.fragment,g),ss=c(g),Pe=l(g,"P",{});var Te=o(Pe);Fe=a(Te,"\xC0 ce stade, vous pouvez utiliser le "),He=l(Te,"EM",{});var ct=o(He);Ee=a(ct,"widget"),ct.forEach(t),Xs=a(Te," d\u2019inf\xE9rence sur le "),Ie=l(Te,"EM",{});var cs=o(Ie);Ws=a(cs,"Hub"),cs.forEach(t),Qs=a(Te," pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),Je=l(Te,"EM",{});var ns=o(Je);Re=a(ns,"finetuner"),ns.forEach(t),As=a(Te," un mod\xE8le sur une t\xE2che de traduction. F\xE9licitations !"),Te.forEach(t),this.h()},h(){h(N,"href","/course/fr/chapter7/2"),h($e,"href","https://huggingface.co/huggingface-course"),h($e,"rel","nofollow")},m(g,oe){i(g,u,oe),s(u,q),i(g,_,oe),k(w,g,oe),i(g,A,oe),k(v,g,oe),i(g,T,oe),i(g,S,oe),s(S,z),s(S,C),s(C,F),s(S,D),i(g,y,oe),k(R,g,oe),i(g,H,oe),i(g,L,oe),s(L,Y),s(L,O),s(O,V),s(L,W),s(L,M),s(M,P),s(L,se),s(L,N),s(N,I),s(L,Q),s(L,ee),s(ee,X),s(L,ie),i(g,re,oe),k(te,g,oe),i(g,me,oe),i(g,le,oe),s(le,de),s(le,ue),s(ue,ve),s(le,be),s(le,$e),s($e,_e),s(_e,J),s(le,pe),s(le,ce),s(ce,G),s(le,Ae),s(le,ge),s(ge,Qe),s(le,qe),s(le,fe),s(fe,Me),s(le,ne),i(g,Oe,oe),k(ae,g,oe),i(g,ze,oe),i(g,ye,oe),s(ye,De),i(g,us,oe),k(Ue,g,oe),i(g,es,oe),k(ps,g,oe),i(g,ss,oe),i(g,Pe,oe),s(Pe,Fe),s(Pe,He),s(He,Ee),s(Pe,Xs),s(Pe,Ie),s(Ie,Ws),s(Pe,Qs),s(Pe,Je),s(Je,Re),s(Pe,As),Ne=!0},i(g){Ne||(b(w.$$.fragment,g),b(v.$$.fragment,g),b(R.$$.fragment,g),b(te.$$.fragment,g),b(ae.$$.fragment,g),b(Ue.$$.fragment,g),b(ps.$$.fragment,g),Ne=!0)},o(g){$(w.$$.fragment,g),$(v.$$.fragment,g),$(R.$$.fragment,g),$(te.$$.fragment,g),$(ae.$$.fragment,g),$(Ue.$$.fragment,g),$(ps.$$.fragment,g),Ne=!1},d(g){g&&t(u),g&&t(_),x(w,g),g&&t(A),x(v,g),g&&t(T),g&&t(S),g&&t(y),x(R,g),g&&t(H),g&&t(L),g&&t(re),x(te,g),g&&t(me),g&&t(le),g&&t(Oe),x(ae,g),g&&t(ze),g&&t(ye),g&&t(us),x(Ue,g),g&&t(es),x(ps,g),g&&t(ss),g&&t(Pe)}}}function w_(Z){let u,q,_,w,A;return{c(){u=r("p"),q=n("\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de la d\xE9finition de votre "),_=r("code"),w=n("Seq2SeqTrainer"),A=n(" et devrez d\xE9finir un nouveau nom.")},l(v){u=l(v,"P",{});var T=o(u);q=a(T,"\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de la d\xE9finition de votre "),_=l(T,"CODE",{});var S=o(_);w=a(S,"Seq2SeqTrainer"),S.forEach(t),A=a(T," et devrez d\xE9finir un nouveau nom."),T.forEach(t)},m(v,T){i(v,u,T),s(u,q),s(u,_),s(_,w),s(u,A)},d(v){v&&t(u)}}}function z_(Z){let u,q,_,w,A;return{c(){u=r("p"),q=n("\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de l\u2019appel de "),_=r("code"),w=n("model.fit()"),A=n(" et devrez d\xE9finir un nouveau nom.")},l(v){u=l(v,"P",{});var T=o(u);q=a(T,"\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de l\u2019appel de "),_=l(T,"CODE",{});var S=o(_);w=a(S,"model.fit()"),S.forEach(t),A=a(T," et devrez d\xE9finir un nouveau nom."),T.forEach(t)},m(v,T){i(v,u,T),s(u,q),s(u,_),s(_,w),s(u,A)},d(v){v&&t(u)}}}function s_(Z){let u,q,_,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se,N,I,Q,ee,X,ie,re,te,me,le,de,ue,ve,be,$e,_e,J,pe,ce,G,Ae,ge,Qe,qe,fe,Me,ne,Oe,ae,ze,ye,De,us,Ue,es,ps,ss,Pe,Fe,He,Ee,Xs,Ie,Ws,Qs,Je,Re,As,Ne,g,oe,gs,je,Be,he,Ke,Le,pt,xe,ts,dt,qs,Ye,Js,Ve,ds,Te,ct,cs,ns,Ms,Ys,Ge,Vt,Es,Ns,Ls,Ce,kt,as,Gt,ms,ke,xt,wt,mt,zt,yt,Pt,Xt,fs,xs,_s,Xe,Ct,ws,Dt,ft,js,Tt,We,Wt,Os,St,Qt,Us,zs,Se,ys,rs,Zs,_t,At,Jt,hs,Yt,Zt,et,vs,Ps,Cs,ht,st,vt,Ze,f,B,bs,Dn,tt,en,Fs,sn,bt,Tn,Mt,Hs,nt,$t,tn,we,vn,at,rt,ks,Nt,nn,Lt,gt,Ds,Is,bn,lt,Ot;return w=new Kt({}),M=new Kt({}),ue=new U({props:{code:`from torch.utils.data import DataLoader

tokenized_datasets.set_format("torch")
train_dataloader = DataLoader(
    tokenized_datasets["train"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)
eval_dataloader = DataLoader(
    tokenized_datasets["validation"], collate_fn=data_collator, batch_size=8
)`,highlighted:`<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

tokenized_datasets.set_format(<span class="hljs-string">&quot;torch&quot;</span>)
train_dataloader = DataLoader(
    tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    shuffle=<span class="hljs-literal">True</span>,
    collate_fn=data_collator,
    batch_size=<span class="hljs-number">8</span>,
)
eval_dataloader = DataLoader(
    tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>], collate_fn=data_collator, batch_size=<span class="hljs-number">8</span>
)`}}),G=new U({props:{code:"model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)",highlighted:"model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"}}),fe=new U({props:{code:`from transformers import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW

optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">2e-5</span>)`}}),Fe=new U({props:{code:`from accelerate import Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)`,highlighted:`<span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)`}}),je=new U({props:{code:`from transformers import get_scheduler

num_train_epochs = 3
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler

num_train_epochs = <span class="hljs-number">3</span>
num_update_steps_per_epoch = <span class="hljs-built_in">len</span>(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    <span class="hljs-string">&quot;linear&quot;</span>,
    optimizer=optimizer,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_training_steps=num_training_steps,
)`}}),Ge=new U({props:{code:`from huggingface_hub import Repository, get_full_repo_name

model_name = "marian-finetuned-kde4-en-to-fr-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> Repository, get_full_repo_name

model_name = <span class="hljs-string">&quot;marian-finetuned-kde4-en-to-fr-accelerate&quot;</span>
repo_name = get_full_repo_name(model_name)
repo_name`}}),Es=new U({props:{code:"'sgugger/marian-finetuned-kde4-en-to-fr-accelerate'",highlighted:'<span class="hljs-string">&#x27;sgugger/marian-finetuned-kde4-en-to-fr-accelerate&#x27;</span>'}}),as=new U({props:{code:`output_dir = "marian-finetuned-kde4-en-to-fr-accelerate"
repo = Repository(output_dir, clone_from=repo_name)`,highlighted:`output_dir = <span class="hljs-string">&quot;marian-finetuned-kde4-en-to-fr-accelerate&quot;</span>
repo = Repository(output_dir, clone_from=repo_name)`}}),Xe=new Kt({}),Se=new U({props:{code:`def postprocess(predictions, labels):
    predictions = predictions.cpu().numpy()
    labels = labels.cpu().numpy()

    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)

    # Remplace -100 dans les \xE9tiquettes car nous ne pouvons pas les d\xE9coder
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    # Quelques post-traitements simples
    decoded_preds = [pred.strip() for pred in decoded_preds]
    decoded_labels = [[label.strip()] for label in decoded_labels]
    return decoded_preds, decoded_labels`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">postprocess</span>(<span class="hljs-params">predictions, labels</span>):
    predictions = predictions.cpu().numpy()
    labels = labels.cpu().numpy()

    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Remplace -100 dans les \xE9tiquettes car nous ne pouvons pas les d\xE9coder</span>
    labels = np.where(labels != -<span class="hljs-number">100</span>, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Quelques post-traitements simples</span>
    decoded_preds = [pred.strip() <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> decoded_preds]
    decoded_labels = [[label.strip()] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> decoded_labels]
    <span class="hljs-keyword">return</span> decoded_preds, decoded_labels`}}),we=new U({props:{code:`from tqdm.auto import tqdm
import torch

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
    # Entra\xEEnement
    model.train()
    for batch in train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # Evaluation
    model.eval()
    for batch in tqdm(eval_dataloader):
        with torch.no_grad():
            generated_tokens = accelerator.unwrap_model(model).generate(
                batch["input_ids"],
                attention_mask=batch["attention_mask"],
                max_length=128,
            )
        labels = batch["labels"]

        # N\xE9cessaire pour rembourrer les pr\xE9dictions et les \xE9tiquettes \xE0 rassembler
        generated_tokens = accelerator.pad_across_processes(
            generated_tokens, dim=1, pad_index=tokenizer.pad_token_id
        )
        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)

        predictions_gathered = accelerator.gather(generated_tokens)
        labels_gathered = accelerator.gather(labels)

        decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)
        metric.add_batch(predictions=decoded_preds, references=decoded_labels)

    results = metric.compute()
    print(f"epoch {epoch}, BLEU score: {results['score']:.2f}")

    # Sauvegarder et t\xE9l\xE9charger
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=f"Training in progress epoch {epoch}", blocking=False
        )`,highlighted:`<span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm
<span class="hljs-keyword">import</span> torch

progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_train_epochs):
    <span class="hljs-comment"># Entra\xEEnement</span>
    model.train()
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(<span class="hljs-number">1</span>)

    <span class="hljs-comment"># Evaluation</span>
    model.<span class="hljs-built_in">eval</span>()
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> tqdm(eval_dataloader):
        <span class="hljs-keyword">with</span> torch.no_grad():
            generated_tokens = accelerator.unwrap_model(model).generate(
                batch[<span class="hljs-string">&quot;input_ids&quot;</span>],
                attention_mask=batch[<span class="hljs-string">&quot;attention_mask&quot;</span>],
                max_length=<span class="hljs-number">128</span>,
            )
        labels = batch[<span class="hljs-string">&quot;labels&quot;</span>]

        <span class="hljs-comment"># N\xE9cessaire pour rembourrer les pr\xE9dictions et les \xE9tiquettes \xE0 rassembler</span>
        generated_tokens = accelerator.pad_across_processes(
            generated_tokens, dim=<span class="hljs-number">1</span>, pad_index=tokenizer.pad_token_id
        )
        labels = accelerator.pad_across_processes(labels, dim=<span class="hljs-number">1</span>, pad_index=-<span class="hljs-number">100</span>)

        predictions_gathered = accelerator.gather(generated_tokens)
        labels_gathered = accelerator.gather(labels)

        decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)
        metric.add_batch(predictions=decoded_preds, references=decoded_labels)

    results = metric.compute()
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;epoch <span class="hljs-subst">{epoch}</span>, BLEU score: <span class="hljs-subst">{results[<span class="hljs-string">&#x27;score&#x27;</span>]:<span class="hljs-number">.2</span>f}</span>&quot;</span>)

    <span class="hljs-comment"># Sauvegarder et t\xE9l\xE9charger</span>
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    <span class="hljs-keyword">if</span> accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=<span class="hljs-string">f&quot;Training in progress epoch <span class="hljs-subst">{epoch}</span>&quot;</span>, blocking=<span class="hljs-literal">False</span>
        )`}}),at=new U({props:{code:`epoch 0, BLEU score: 53.47
epoch 1, BLEU score: 54.24
epoch 2, BLEU score: 54.44`,highlighted:`epoch <span class="hljs-number">0</span>, BLEU score: <span class="hljs-number">53.47</span>
epoch <span class="hljs-number">1</span>, BLEU score: <span class="hljs-number">54.24</span>
epoch <span class="hljs-number">2</span>, BLEU score: <span class="hljs-number">54.44</span>`}}),{c(){u=r("h2"),q=r("a"),_=r("span"),E(w.$$.fragment),A=d(),v=r("span"),T=n("Une boucle d'entra\xEEnement personnalis\xE9e"),S=d(),z=r("p"),C=n("Jetons maintenant un coup d\u2019\u0153il \xE0 la boucle d\u2019entra\xEEnement compl\xE8te afin que vous puissiez facilement personnaliser les parties dont vous avez besoin. Elle ressemblera beaucoup \xE0 ce que nous avons fait dans la "),F=r("a"),D=n("section 2"),y=n(" et dans le "),R=r("a"),H=n("chapitre 3"),L=n("."),Y=d(),O=r("h3"),V=r("a"),W=r("span"),E(M.$$.fragment),P=d(),se=r("span"),N=n("Pr\xE9parer le tout pour l'entra\xEEnement"),I=d(),Q=r("p"),ee=n("Vous avez vu tout cela plusieurs fois maintenant, donc nous allons passer en revue le code assez rapidement. D\u2019abord, nous allons construire le "),X=r("code"),ie=n("DataLoader"),re=n(" \xE0 partir de nos jeux de donn\xE9es, apr\xE8s avoir configur\xE9 les jeux de donn\xE9es au format "),te=r("code"),me=n('"torch"'),le=n(" pour obtenir les tenseurs PyTorch :"),de=d(),E(ue.$$.fragment),ve=d(),be=r("p"),$e=n("Ensuite, nous r\xE9instantifions notre mod\xE8le pour nous assurer que nous ne poursuivons pas le "),_e=r("em"),J=n("finetuning"),pe=n(" pr\xE9c\xE9dent et que nous repartons du mod\xE8le pr\xE9-entra\xEEn\xE9 :"),ce=d(),E(G.$$.fragment),Ae=d(),ge=r("p"),Qe=n("Nous aurons alors besoin d\u2019un optimiseur :"),qe=d(),E(fe.$$.fragment),Me=d(),ne=r("p"),Oe=n("Une fois que nous avons tous ces objets, nous pouvons les envoyer \xE0 la m\xE9thode "),ae=r("code"),ze=n("accelerator.prepare()"),ye=n(". Rappelez-vous que si vous voulez entra\xEEner sur des TPUs dans un "),De=r("em"),us=n("notebook"),Ue=n(" de Colab, vous devez d\xE9placer tout ce code dans une fonction d\u2019entra\xEEnement et ne devrait pas ex\xE9cuter une cellule qui instancie un "),es=r("code"),ps=n("Accelerator"),ss=n("."),Pe=d(),E(Fe.$$.fragment),He=d(),Ee=r("p"),Xs=n("Maintenant que nous avons envoy\xE9 notre "),Ie=r("code"),Ws=n("train_dataloader"),Qs=n(" \xE0 "),Je=r("code"),Re=n("accelerator.prepare()"),As=n(", nous pouvons utiliser sa longueur pour calculer le nombre d\u2019\xE9tapes d\u2019entra\xEEnement. Rappelez-vous que nous devrions toujours faire cela apr\xE8s avoir pr\xE9par\xE9 le chargeur de donn\xE9es car cette m\xE9thode va changer la longueur du "),Ne=r("code"),g=n("DataLoader"),oe=n(". Nous utilisons un programme lin\xE9aire classique du taux d\u2019apprentissage \xE0 0 :"),gs=d(),E(je.$$.fragment),Be=d(),he=r("p"),Ke=n("Enfin, pour pousser notre mod\xE8le vers le "),Le=r("em"),pt=n("Hub"),xe=n(", nous aurons besoin de cr\xE9er un objet "),ts=r("code"),dt=n("Repository"),qs=n(" dans un dossier de travail. Tout d\u2019abord, connectez-vous au "),Ye=r("em"),Js=n("Hub"),Ve=n(" si vous n\u2019\xEAtes pas d\xE9j\xE0 connect\xE9. Nous d\xE9terminerons le nom du d\xE9p\xF4t \xE0 partir de l\u2019identifiant du mod\xE8le que nous voulons donner \xE0 notre mod\xE8le (n\u2019h\xE9sitez pas \xE0 remplacer le "),ds=r("code"),Te=n("repo_name"),ct=n(" par votre propre choix, il doit juste contenir votre nom d\u2019utilisateur, ce que fait la fonction "),cs=r("code"),ns=n("get_full_repo_name()"),Ms=n(") :"),Ys=d(),E(Ge.$$.fragment),Vt=d(),E(Es.$$.fragment),Ns=d(),Ls=r("p"),Ce=n("Ensuite, nous pouvons cloner ce d\xE9p\xF4t dans un dossier local. S\u2019il existe d\xE9j\xE0, ce dossier local doit \xEAtre un clone du d\xE9p\xF4t avec lequel nous travaillons :"),kt=d(),E(as.$$.fragment),Gt=d(),ms=r("p"),ke=n("Nous pouvons maintenant t\xE9l\xE9charger tout ce que nous sauvegardons dans "),xt=r("code"),wt=n("output_dir"),mt=n(" en appelant la m\xE9thode "),zt=r("code"),yt=n("repo.push_to_hub()"),Pt=n(". Cela nous aidera \xE0 t\xE9l\xE9charger les mod\xE8les interm\xE9diaires \xE0 la fin de chaque \xE9poque."),Xt=d(),fs=r("h3"),xs=r("a"),_s=r("span"),E(Xe.$$.fragment),Ct=d(),ws=r("span"),Dt=n("Boucle d'entra\xEEnement"),ft=d(),js=r("p"),Tt=n("Nous sommes maintenant pr\xEAts \xE0 \xE9crire la boucle d\u2019entra\xEEnement compl\xE8te. Pour simplifier sa partie \xE9valuation, nous d\xE9finissons cette fonction "),We=r("code"),Wt=n("postprocess()"),Os=n(" qui prend les pr\xE9dictions et les \xE9tiquettes et les convertit en listes de cha\xEEnes de caract\xE8res que notre objet "),St=r("code"),Qt=n("metric"),Us=n(" attend :"),zs=d(),E(Se.$$.fragment),ys=d(),rs=r("p"),Zs=n("La boucle d\u2019entra\xEEnement ressemble beaucoup \xE0 celles de la "),_t=r("a"),At=n("section 2"),Jt=n(" et du "),hs=r("a"),Yt=n("chapitre 3"),Zt=n(", avec quelques diff\xE9rences dans la partie \xE9valuation. Donc concentrons-nous sur cela !"),et=d(),vs=r("p"),Ps=n("La premi\xE8re chose \xE0 noter est que nous utilisons la m\xE9thode "),Cs=r("code"),ht=n("generate()"),st=n(" pour calculer les pr\xE9dictions. C\u2019est une m\xE9thode sur notre mod\xE8le de base et non pas le mod\xE8le envelopp\xE9 cr\xE9\xE9 dans la m\xE9thode "),vt=r("code"),Ze=n("prepare()"),f=n(". C\u2019est pourquoi nous d\xE9ballons d\u2019abord le mod\xE8le, puis nous appelons cette m\xE9thode."),B=d(),bs=r("p"),Dn=n("La deuxi\xE8me chose est que, comme avec la classification de "),tt=r("a"),en=r("em"),Fs=n("token"),sn=n(", deux processus peuvent avoir rembourr\xE9s les entr\xE9es et les \xE9tiquettes \xE0 des formes diff\xE9rentes. Ainsi nous utilisons "),bt=r("code"),Tn=n("accelerator.pad_across_processes()"),Mt=n(" pour rendre les pr\xE9dictions et les \xE9tiquettes de la m\xEAme forme avant d\u2019appeler la m\xE9thode "),Hs=r("code"),nt=n("gather()"),$t=n(". Si nous ne faisons pas cela, l\u2019\xE9valuation va soit se tromper, soit se bloquer pour toujours."),tn=d(),E(we.$$.fragment),vn=d(),E(at.$$.fragment),rt=d(),ks=r("p"),Nt=n("Une fois que c\u2019est fait, vous devriez avoir un mod\xE8le qui a des r\xE9sultats assez similaires \xE0 celui entra\xEEn\xE9 avec "),nn=r("code"),Lt=n("Seq2SeqTrainer"),gt=n(". Vous pouvez v\xE9rifier celui que nous avons entra\xEEn\xE9 en utilisant ce code sur "),Ds=r("a"),Is=r("em"),bn=n("huggingface-course/marian-finetuned-kde4-en-to-fr-accelerate"),lt=n(". Et si vous voulez tester des modifications de la boucle d\u2019entra\xEEnement, vous pouvez les mettre en \u0153uvre directement en modifiant le code ci-dessus !"),this.h()},l(m){u=l(m,"H2",{class:!0});var K=o(u);q=l(K,"A",{id:!0,class:!0,href:!0});var Jn=o(q);_=l(Jn,"SPAN",{});var ls=o(_);j(w.$$.fragment,ls),ls.forEach(t),Jn.forEach(t),A=c(K),v=l(K,"SPAN",{});var Ut=o(v);T=a(Ut,"Une boucle d'entra\xEEnement personnalis\xE9e"),Ut.forEach(t),K.forEach(t),S=c(m),z=l(m,"P",{});var qt=o(z);C=a(qt,"Jetons maintenant un coup d\u2019\u0153il \xE0 la boucle d\u2019entra\xEEnement compl\xE8te afin que vous puissiez facilement personnaliser les parties dont vous avez besoin. Elle ressemblera beaucoup \xE0 ce que nous avons fait dans la "),F=l(qt,"A",{href:!0});var Ft=o(F);D=a(Ft,"section 2"),Ft.forEach(t),y=a(qt," et dans le "),R=l(qt,"A",{href:!0});var Sn=o(R);H=a(Sn,"chapitre 3"),Sn.forEach(t),L=a(qt,"."),qt.forEach(t),Y=c(m),O=l(m,"H3",{class:!0});var Bs=o(O);V=l(Bs,"A",{id:!0,class:!0,href:!0});var Yn=o(V);W=l(Yn,"SPAN",{});var Ts=o(W);j(M.$$.fragment,Ts),Ts.forEach(t),Yn.forEach(t),P=c(Bs),se=l(Bs,"SPAN",{});var Zn=o(se);N=a(Zn,"Pr\xE9parer le tout pour l'entra\xEEnement"),Zn.forEach(t),Bs.forEach(t),I=c(m),Q=l(m,"P",{});var Ht=o(Q);ee=a(Ht,"Vous avez vu tout cela plusieurs fois maintenant, donc nous allons passer en revue le code assez rapidement. D\u2019abord, nous allons construire le "),X=l(Ht,"CODE",{});var An=o(X);ie=a(An,"DataLoader"),An.forEach(t),re=a(Ht," \xE0 partir de nos jeux de donn\xE9es, apr\xE8s avoir configur\xE9 les jeux de donn\xE9es au format "),te=l(Ht,"CODE",{});var ot=o(te);me=a(ot,'"torch"'),ot.forEach(t),le=a(Ht," pour obtenir les tenseurs PyTorch :"),Ht.forEach(t),de=c(m),j(ue.$$.fragment,m),ve=c(m),be=l(m,"P",{});var an=o(be);$e=a(an,"Ensuite, nous r\xE9instantifions notre mod\xE8le pour nous assurer que nous ne poursuivons pas le "),_e=l(an,"EM",{});var Mn=o(_e);J=a(Mn,"finetuning"),Mn.forEach(t),pe=a(an," pr\xE9c\xE9dent et que nous repartons du mod\xE8le pr\xE9-entra\xEEn\xE9 :"),an.forEach(t),ce=c(m),j(G.$$.fragment,m),Ae=c(m),ge=l(m,"P",{});var Sa=o(ge);Qe=a(Sa,"Nous aurons alors besoin d\u2019un optimiseur :"),Sa.forEach(t),qe=c(m),j(fe.$$.fragment,m),Me=c(m),ne=l(m,"P",{});var it=o(ne);Oe=a(it,"Une fois que nous avons tous ces objets, nous pouvons les envoyer \xE0 la m\xE9thode "),ae=l(it,"CODE",{});var Or=o(ae);ze=a(Or,"accelerator.prepare()"),Or.forEach(t),ye=a(it,". Rappelez-vous que si vous voulez entra\xEEner sur des TPUs dans un "),De=l(it,"EM",{});var Aa=o(De);us=a(Aa,"notebook"),Aa.forEach(t),Ue=a(it," de Colab, vous devez d\xE9placer tout ce code dans une fonction d\u2019entra\xEEnement et ne devrait pas ex\xE9cuter une cellule qui instancie un "),es=l(it,"CODE",{});var Nn=o(es);ps=a(Nn,"Accelerator"),Nn.forEach(t),ss=a(it,"."),it.forEach(t),Pe=c(m),j(Fe.$$.fragment,m),He=c(m),Ee=l(m,"P",{});var It=o(Ee);Xs=a(It,"Maintenant que nous avons envoy\xE9 notre "),Ie=l(It,"CODE",{});var Ln=o(Ie);Ws=a(Ln,"train_dataloader"),Ln.forEach(t),Qs=a(It," \xE0 "),Je=l(It,"CODE",{});var Ma=o(Je);Re=a(Ma,"accelerator.prepare()"),Ma.forEach(t),As=a(It,", nous pouvons utiliser sa longueur pour calculer le nombre d\u2019\xE9tapes d\u2019entra\xEEnement. Rappelez-vous que nous devrions toujours faire cela apr\xE8s avoir pr\xE9par\xE9 le chargeur de donn\xE9es car cette m\xE9thode va changer la longueur du "),Ne=l(It,"CODE",{});var Bt=o(Ne);g=a(Bt,"DataLoader"),Bt.forEach(t),oe=a(It,". Nous utilisons un programme lin\xE9aire classique du taux d\u2019apprentissage \xE0 0 :"),It.forEach(t),gs=c(m),j(je.$$.fragment,m),Be=c(m),he=l(m,"P",{});var Rs=o(he);Ke=a(Rs,"Enfin, pour pousser notre mod\xE8le vers le "),Le=l(Rs,"EM",{});var ra=o(Le);pt=a(ra,"Hub"),ra.forEach(t),xe=a(Rs,", nous aurons besoin de cr\xE9er un objet "),ts=l(Rs,"CODE",{});var Ur=o(ts);dt=a(Ur,"Repository"),Ur.forEach(t),qs=a(Rs," dans un dossier de travail. Tout d\u2019abord, connectez-vous au "),Ye=l(Rs,"EM",{});var Fr=o(Ye);Js=a(Fr,"Hub"),Fr.forEach(t),Ve=a(Rs," si vous n\u2019\xEAtes pas d\xE9j\xE0 connect\xE9. Nous d\xE9terminerons le nom du d\xE9p\xF4t \xE0 partir de l\u2019identifiant du mod\xE8le que nous voulons donner \xE0 notre mod\xE8le (n\u2019h\xE9sitez pas \xE0 remplacer le "),ds=l(Rs,"CODE",{});var la=o(ds);Te=a(la,"repo_name"),la.forEach(t),ct=a(Rs," par votre propre choix, il doit juste contenir votre nom d\u2019utilisateur, ce que fait la fonction "),cs=l(Rs,"CODE",{});var Hr=o(cs);ns=a(Hr,"get_full_repo_name()"),Hr.forEach(t),Ms=a(Rs,") :"),Rs.forEach(t),Ys=c(m),j(Ge.$$.fragment,m),Vt=c(m),j(Es.$$.fragment,m),Ns=c(m),Ls=l(m,"P",{});var Ir=o(Ls);Ce=a(Ir,"Ensuite, nous pouvons cloner ce d\xE9p\xF4t dans un dossier local. S\u2019il existe d\xE9j\xE0, ce dossier local doit \xEAtre un clone du d\xE9p\xF4t avec lequel nous travaillons :"),Ir.forEach(t),kt=c(m),j(as.$$.fragment,m),Gt=c(m),ms=l(m,"P",{});var $n=o(ms);ke=a($n,"Nous pouvons maintenant t\xE9l\xE9charger tout ce que nous sauvegardons dans "),xt=l($n,"CODE",{});var On=o(xt);wt=a(On,"output_dir"),On.forEach(t),mt=a($n," en appelant la m\xE9thode "),zt=l($n,"CODE",{});var Na=o(zt);yt=a(Na,"repo.push_to_hub()"),Na.forEach(t),Pt=a($n,". Cela nous aidera \xE0 t\xE9l\xE9charger les mod\xE8les interm\xE9diaires \xE0 la fin de chaque \xE9poque."),$n.forEach(t),Xt=c(m),fs=l(m,"H3",{class:!0});var Rt=o(fs);xs=l(Rt,"A",{id:!0,class:!0,href:!0});var La=o(xs);_s=l(La,"SPAN",{});var rn=o(_s);j(Xe.$$.fragment,rn),rn.forEach(t),La.forEach(t),Ct=c(Rt),ws=l(Rt,"SPAN",{});var gn=o(ws);Dt=a(gn,"Boucle d'entra\xEEnement"),gn.forEach(t),Rt.forEach(t),ft=c(m),js=l(m,"P",{});var ln=o(js);Tt=a(ln,"Nous sommes maintenant pr\xEAts \xE0 \xE9crire la boucle d\u2019entra\xEEnement compl\xE8te. Pour simplifier sa partie \xE9valuation, nous d\xE9finissons cette fonction "),We=l(ln,"CODE",{});var Un=o(We);Wt=a(Un,"postprocess()"),Un.forEach(t),Os=a(ln," qui prend les pr\xE9dictions et les \xE9tiquettes et les convertit en listes de cha\xEEnes de caract\xE8res que notre objet "),St=l(ln,"CODE",{});var Br=o(St);Qt=a(Br,"metric"),Br.forEach(t),Us=a(ln," attend :"),ln.forEach(t),zs=c(m),j(Se.$$.fragment,m),ys=c(m),rs=l(m,"P",{});var on=o(rs);Zs=a(on,"La boucle d\u2019entra\xEEnement ressemble beaucoup \xE0 celles de la "),_t=l(on,"A",{href:!0});var Rr=o(_t);At=a(Rr,"section 2"),Rr.forEach(t),Jt=a(on," et du "),hs=l(on,"A",{href:!0});var Oa=o(hs);Yt=a(Oa,"chapitre 3"),Oa.forEach(t),Zt=a(on,", avec quelques diff\xE9rences dans la partie \xE9valuation. Donc concentrons-nous sur cela !"),on.forEach(t),et=c(m),vs=l(m,"P",{});var Et=o(vs);Ps=a(Et,"La premi\xE8re chose \xE0 noter est que nous utilisons la m\xE9thode "),Cs=l(Et,"CODE",{});var Ua=o(Cs);ht=a(Ua,"generate()"),Ua.forEach(t),st=a(Et," pour calculer les pr\xE9dictions. C\u2019est une m\xE9thode sur notre mod\xE8le de base et non pas le mod\xE8le envelopp\xE9 cr\xE9\xE9 dans la m\xE9thode "),vt=l(Et,"CODE",{});var Ss=o(vt);Ze=a(Ss,"prepare()"),Ss.forEach(t),f=a(Et,". C\u2019est pourquoi nous d\xE9ballons d\u2019abord le mod\xE8le, puis nous appelons cette m\xE9thode."),Et.forEach(t),B=c(m),bs=l(m,"P",{});var un=o(bs);Dn=a(un,"La deuxi\xE8me chose est que, comme avec la classification de "),tt=l(un,"A",{href:!0});var oa=o(tt);en=l(oa,"EM",{});var Kr=o(en);Fs=a(Kr,"token"),Kr.forEach(t),oa.forEach(t),sn=a(un,", deux processus peuvent avoir rembourr\xE9s les entr\xE9es et les \xE9tiquettes \xE0 des formes diff\xE9rentes. Ainsi nous utilisons "),bt=l(un,"CODE",{});var Vr=o(bt);Tn=a(Vr,"accelerator.pad_across_processes()"),Vr.forEach(t),Mt=a(un," pour rendre les pr\xE9dictions et les \xE9tiquettes de la m\xEAme forme avant d\u2019appeler la m\xE9thode "),Hs=l(un,"CODE",{});var ia=o(Hs);nt=a(ia,"gather()"),ia.forEach(t),$t=a(un,". Si nous ne faisons pas cela, l\u2019\xE9valuation va soit se tromper, soit se bloquer pour toujours."),un.forEach(t),tn=c(m),j(we.$$.fragment,m),vn=c(m),j(at.$$.fragment,m),rt=c(m),ks=l(m,"P",{});var Fn=o(ks);Nt=a(Fn,"Une fois que c\u2019est fait, vous devriez avoir un mod\xE8le qui a des r\xE9sultats assez similaires \xE0 celui entra\xEEn\xE9 avec "),nn=l(Fn,"CODE",{});var Gr=o(nn);Lt=a(Gr,"Seq2SeqTrainer"),Gr.forEach(t),gt=a(Fn,". Vous pouvez v\xE9rifier celui que nous avons entra\xEEn\xE9 en utilisant ce code sur "),Ds=l(Fn,"A",{href:!0,rel:!0});var ua=o(Ds);Is=l(ua,"EM",{});var Xr=o(Is);bn=a(Xr,"huggingface-course/marian-finetuned-kde4-en-to-fr-accelerate"),Xr.forEach(t),ua.forEach(t),lt=a(Fn,". Et si vous voulez tester des modifications de la boucle d\u2019entra\xEEnement, vous pouvez les mettre en \u0153uvre directement en modifiant le code ci-dessus !"),Fn.forEach(t),this.h()},h(){h(q,"id","une-boucle-dentranement-personnalise"),h(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(q,"href","#une-boucle-dentranement-personnalise"),h(u,"class","relative group"),h(F,"href","/course/fr/chapter7/2"),h(R,"href","/course/fr/chapter3/4"),h(V,"id","prparer-le-tout-pour-lentranement"),h(V,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(V,"href","#prparer-le-tout-pour-lentranement"),h(O,"class","relative group"),h(xs,"id","boucle-dentranement"),h(xs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(xs,"href","#boucle-dentranement"),h(fs,"class","relative group"),h(_t,"href","/course/fr/chapter7/2"),h(hs,"href","/course/fr/chapter3"),h(tt,"href","/course/fr/chapter7/2"),h(Ds,"href","https://huggingface.co/huggingface-course/marian-finetuned-kde4-en-to-fr-accelerate"),h(Ds,"rel","nofollow")},m(m,K){i(m,u,K),s(u,q),s(q,_),k(w,_,null),s(u,A),s(u,v),s(v,T),i(m,S,K),i(m,z,K),s(z,C),s(z,F),s(F,D),s(z,y),s(z,R),s(R,H),s(z,L),i(m,Y,K),i(m,O,K),s(O,V),s(V,W),k(M,W,null),s(O,P),s(O,se),s(se,N),i(m,I,K),i(m,Q,K),s(Q,ee),s(Q,X),s(X,ie),s(Q,re),s(Q,te),s(te,me),s(Q,le),i(m,de,K),k(ue,m,K),i(m,ve,K),i(m,be,K),s(be,$e),s(be,_e),s(_e,J),s(be,pe),i(m,ce,K),k(G,m,K),i(m,Ae,K),i(m,ge,K),s(ge,Qe),i(m,qe,K),k(fe,m,K),i(m,Me,K),i(m,ne,K),s(ne,Oe),s(ne,ae),s(ae,ze),s(ne,ye),s(ne,De),s(De,us),s(ne,Ue),s(ne,es),s(es,ps),s(ne,ss),i(m,Pe,K),k(Fe,m,K),i(m,He,K),i(m,Ee,K),s(Ee,Xs),s(Ee,Ie),s(Ie,Ws),s(Ee,Qs),s(Ee,Je),s(Je,Re),s(Ee,As),s(Ee,Ne),s(Ne,g),s(Ee,oe),i(m,gs,K),k(je,m,K),i(m,Be,K),i(m,he,K),s(he,Ke),s(he,Le),s(Le,pt),s(he,xe),s(he,ts),s(ts,dt),s(he,qs),s(he,Ye),s(Ye,Js),s(he,Ve),s(he,ds),s(ds,Te),s(he,ct),s(he,cs),s(cs,ns),s(he,Ms),i(m,Ys,K),k(Ge,m,K),i(m,Vt,K),k(Es,m,K),i(m,Ns,K),i(m,Ls,K),s(Ls,Ce),i(m,kt,K),k(as,m,K),i(m,Gt,K),i(m,ms,K),s(ms,ke),s(ms,xt),s(xt,wt),s(ms,mt),s(ms,zt),s(zt,yt),s(ms,Pt),i(m,Xt,K),i(m,fs,K),s(fs,xs),s(xs,_s),k(Xe,_s,null),s(fs,Ct),s(fs,ws),s(ws,Dt),i(m,ft,K),i(m,js,K),s(js,Tt),s(js,We),s(We,Wt),s(js,Os),s(js,St),s(St,Qt),s(js,Us),i(m,zs,K),k(Se,m,K),i(m,ys,K),i(m,rs,K),s(rs,Zs),s(rs,_t),s(_t,At),s(rs,Jt),s(rs,hs),s(hs,Yt),s(rs,Zt),i(m,et,K),i(m,vs,K),s(vs,Ps),s(vs,Cs),s(Cs,ht),s(vs,st),s(vs,vt),s(vt,Ze),s(vs,f),i(m,B,K),i(m,bs,K),s(bs,Dn),s(bs,tt),s(tt,en),s(en,Fs),s(bs,sn),s(bs,bt),s(bt,Tn),s(bs,Mt),s(bs,Hs),s(Hs,nt),s(bs,$t),i(m,tn,K),k(we,m,K),i(m,vn,K),k(at,m,K),i(m,rt,K),i(m,ks,K),s(ks,Nt),s(ks,nn),s(nn,Lt),s(ks,gt),s(ks,Ds),s(Ds,Is),s(Is,bn),s(ks,lt),Ot=!0},i(m){Ot||(b(w.$$.fragment,m),b(M.$$.fragment,m),b(ue.$$.fragment,m),b(G.$$.fragment,m),b(fe.$$.fragment,m),b(Fe.$$.fragment,m),b(je.$$.fragment,m),b(Ge.$$.fragment,m),b(Es.$$.fragment,m),b(as.$$.fragment,m),b(Xe.$$.fragment,m),b(Se.$$.fragment,m),b(we.$$.fragment,m),b(at.$$.fragment,m),Ot=!0)},o(m){$(w.$$.fragment,m),$(M.$$.fragment,m),$(ue.$$.fragment,m),$(G.$$.fragment,m),$(fe.$$.fragment,m),$(Fe.$$.fragment,m),$(je.$$.fragment,m),$(Ge.$$.fragment,m),$(Es.$$.fragment,m),$(as.$$.fragment,m),$(Xe.$$.fragment,m),$(Se.$$.fragment,m),$(we.$$.fragment,m),$(at.$$.fragment,m),Ot=!1},d(m){m&&t(u),x(w),m&&t(S),m&&t(z),m&&t(Y),m&&t(O),x(M),m&&t(I),m&&t(Q),m&&t(de),x(ue,m),m&&t(ve),m&&t(be),m&&t(ce),x(G,m),m&&t(Ae),m&&t(ge),m&&t(qe),x(fe,m),m&&t(Me),m&&t(ne),m&&t(Pe),x(Fe,m),m&&t(He),m&&t(Ee),m&&t(gs),x(je,m),m&&t(Be),m&&t(he),m&&t(Ys),x(Ge,m),m&&t(Vt),x(Es,m),m&&t(Ns),m&&t(Ls),m&&t(kt),x(as,m),m&&t(Gt),m&&t(ms),m&&t(Xt),m&&t(fs),x(Xe),m&&t(ft),m&&t(js),m&&t(zs),x(Se,m),m&&t(ys),m&&t(rs),m&&t(et),m&&t(vs),m&&t(B),m&&t(bs),m&&t(tn),x(we,m),m&&t(vn),x(at,m),m&&t(rt),m&&t(ks)}}}function y_(Z){let u,q,_,w,A,v,T,S;return{c(){u=r("p"),q=n("\u270F\uFE0F "),_=r("strong"),w=n("A votre tour !"),A=n(" Que retourne le mod\xE8le sur l\u2019\xE9chantillon avec le mot \xAB "),v=r("em"),T=n("email"),S=n(" \xBB que vous avez identifi\xE9 plus t\xF4t ?")},l(z){u=l(z,"P",{});var C=o(u);q=a(C,"\u270F\uFE0F "),_=l(C,"STRONG",{});var F=o(_);w=a(F,"A votre tour !"),F.forEach(t),A=a(C," Que retourne le mod\xE8le sur l\u2019\xE9chantillon avec le mot \xAB "),v=l(C,"EM",{});var D=o(v);T=a(D,"email"),D.forEach(t),S=a(C," \xBB que vous avez identifi\xE9 plus t\xF4t ?"),C.forEach(t)},m(z,C){i(z,u,C),s(u,q),s(u,_),s(_,w),s(u,A),s(u,v),s(v,T),s(u,S)},d(z){z&&t(u)}}}function P_(Z){let u,q,_,w,A,v,T,S,z,C,F,D,y,R,H,L,Y,O,V,W,M,P,se,N,I,Q,ee,X,ie,re,te,me,le,de,ue,ve,be,$e,_e,J,pe,ce,G,Ae,ge,Qe,qe,fe,Me,ne,Oe,ae,ze,ye,De,us,Ue,es,ps,ss,Pe,Fe,He,Ee,Xs,Ie,Ws,Qs,Je,Re,As,Ne,g,oe,gs,je,Be,he,Ke,Le,pt,xe,ts,dt,qs,Ye,Js,Ve,ds,Te,ct,cs,ns,Ms,Ys,Ge,Vt,Es,Ns,Ls,Ce,kt,as,Gt,ms,ke,xt,wt,mt,zt,yt,Pt,Xt,fs,xs,_s,Xe,Ct,ws,Dt,ft,js,Tt,We,Wt,Os,St,Qt,Us,zs,Se,ys,rs,Zs,_t,At,Jt,hs,Yt,Zt,et,vs,Ps,Cs,ht,st,vt,Ze,f,B,bs,Dn,tt,en,Fs,sn,bt,Tn,Mt,Hs,nt,$t,tn,we,vn,at,rt,ks,Nt,nn,Lt,gt,Ds,Is,bn,lt,Ot,m,K,Jn,ls,Ut,qt,Ft,Sn,Bs,Yn,Ts,Zn,Ht,An,ot,an,Mn,Sa,it,Or,Aa,Nn,It,Ln,Ma,Bt,Rs,ra,Ur,Fr,la,Hr,Ir,$n,On,Na,Rt,La,rn,gn,ln,Un,Br,on,Rr,Oa,Et,Ua,Ss,un,oa,Kr,Vr,ia,Fn,Gr,ua,Xr,ku,Fa,xu,wu,Uo,Ha,Fo,pn,zu,Pl,yu,Pu,Ia,Cl,Cu,Du,Dl,Tu,Su,Ho,pa,Io,Hn,Au,Tl,Mu,Nu,Sl,Lu,Ou,Bo,da,Uu,Al,Fu,Hu,Ro,Ba,Ko,In,Iu,Ml,Bu,Ru,Nl,Ku,Vu,Vo,Bn,Gu,Ll,Xu,Wu,Ol,Qu,Ju,Go,Wr,Yu,Xo,Ra,Wo,ca,Zu,Ul,ep,sp,Qo,Ka,Jo,Va,Yo,dn,tp,Fl,np,ap,Hl,rp,lp,Il,op,ip,Zo,cn,up,Bl,pp,dp,Rl,cp,mp,Kl,fp,_p,ei,Ga,si,Qr,hp,ti,ma,ni,fa,ai,Jr,vp,ri,Xa,li,_a,bp,Vl,$p,gp,oi,qn,En,Yr,Zr,qp,ii,ea,ha,Gl,Wa,Ep,Xl,jp,ui,os,kp,Wl,xp,wp,el,zp,yp,Ql,Pp,Cp,Jl,Dp,Tp,Yl,Sp,Ap,Zl,Mp,Np,eo,Lp,Op,pi,is,Up,Qa,so,Fp,Hp,to,Ip,Bp,no,Rp,Kp,ao,Vp,Gp,ro,Xp,Wp,lo,Qp,Jp,oo,Yp,Zp,di,jn,kn,sl,tl,ed,ci,Ja,mi,Ya,fi,va,sd,io,td,nd,_i,Za,hi,er,vi,nl,ad,bi,sr,$i,tr,gi,al,rd,qi,nr,Ei,ar,ji,xn,wn,rl,sa,ba,uo,rr,ld,po,od,ki,lr,xi,ll,Rn,id,or,ud,pd,ir,dd,cd,wi,mn,md,co,fd,_d,ur,hd,vd,mo,bd,$d,zi,pr,yi,Kn,gd,fo,qd,Ed,ol,jd,kd,Pi,dr,Ci,il,xd,Di,ul,wd,Ti,cr,Si,mr,Ai,Ks,zd,_o,yd,Pd,fr,ho,Cd,Dd,vo,Td,Sd,bo,Ad,Md,_r,Nd,Ld,Mi,hr,Ni,vr,Li,br,Oi,$r,Ui,pl,Od,Fi,zn,yn,dl,$a,Ud,$o,Fd,Hd,Hi,ta,ga,go,gr,Id,cl,qo,Bd,Rd,Ii,Vn,Kd,Eo,Vd,Gd,jo,Xd,Wd,Bi,qr,Ri,qa,Qd,ko,Jd,Yd,Ki,Ea,Zd,xo,ec,sc,Vi,Er,Gi,Pn,Cn,ml,fl,na,ja,wo,jr,tc,_l,nc,zo,ac,Xi,jt,rc,yo,lc,oc,Po,ic,uc,Co,pc,dc,Do,cc,mc,Wi,kr,Qi,xr,Ji,fn,fc,To,_c,hc,So,vc,bc,Ao,$c,gc,Yi,wr,Zi,zr,eu,hl,qc,su,ka,tu;_=new i_({props:{fw:Z[0]}}),S=new Kt({});const kc=[p_,u_],yr=[];function xc(e,p){return e[0]==="pt"?0:1}y=xc(Z),R=yr[y]=kc[y](Z),pe=new ju({props:{id:"1JvfrvZgi6c"}}),Ge=new Kt({}),ws=new Kt({}),zs=new U({props:{code:`from datasets import load_dataset, load_metric

raw_datasets = load_dataset("kde4", lang1="en", lang2="fr")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, load_metric

raw_datasets = load_dataset(<span class="hljs-string">&quot;kde4&quot;</span>, lang1=<span class="hljs-string">&quot;en&quot;</span>, lang2=<span class="hljs-string">&quot;fr&quot;</span>)`}}),Cs=new U({props:{code:"raw_datasets",highlighted:"raw_datasets"}}),st=new U({props:{code:`DatasetDict({
    train: Dataset({
        features: ['id', 'translation'],
        num_rows: 210173
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;translation&#x27;</span>],
        num_rows: <span class="hljs-number">210173</span>
    })
})`}}),Hs=new U({props:{code:`split_datasets = raw_datasets["train"].train_test_split(train_size=0.9, seed=20)
split_datasets`,highlighted:`split_datasets = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].train_test_split(train_size=<span class="hljs-number">0.9</span>, seed=<span class="hljs-number">20</span>)
split_datasets`}}),$t=new U({props:{code:`DatasetDict({
    train: Dataset({
        features: ['id', 'translation'],
        num_rows: 189155
    })
    test: Dataset({
        features: ['id', 'translation'],
        num_rows: 21018
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;translation&#x27;</span>],
        num_rows: <span class="hljs-number">189155</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;translation&#x27;</span>],
        num_rows: <span class="hljs-number">21018</span>
    })
})`}}),rt=new U({props:{code:'split_datasets["validation"] = split_datasets.pop("test")',highlighted:'split_datasets[<span class="hljs-string">&quot;validation&quot;</span>] = split_datasets.pop(<span class="hljs-string">&quot;test&quot;</span>)'}}),gt=new U({props:{code:'split_datasets["train"][1]["translation"]',highlighted:'split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>]'}}),Is=new U({props:{code:`{'en': 'Default to expanded threads',
 'fr': 'Par d\xE9faut, d\xE9velopper les fils de discussion'}`,highlighted:`{<span class="hljs-string">&#x27;en&#x27;</span>: <span class="hljs-string">&#x27;Default to expanded threads&#x27;</span>,
 <span class="hljs-string">&#x27;fr&#x27;</span>: <span class="hljs-string">&#x27;Par d\xE9faut, d\xE9velopper les fils de discussion&#x27;</span>}`}}),Ut=new U({props:{code:`from transformers import pipeline

model_checkpoint = "Helsinki-NLP/opus-mt-en-fr"
translator = pipeline("translation", model=model_checkpoint)
translator("Default to expanded threads")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

model_checkpoint = <span class="hljs-string">&quot;Helsinki-NLP/opus-mt-en-fr&quot;</span>
translator = pipeline(<span class="hljs-string">&quot;translation&quot;</span>, model=model_checkpoint)
translator(<span class="hljs-string">&quot;Default to expanded threads&quot;</span>)`}}),Ft=new U({props:{code:"[{'translation_text': 'Par d\xE9faut pour les threads \xE9largis'}]",highlighted:'[{<span class="hljs-string">&#x27;translation_text&#x27;</span>: <span class="hljs-string">&#x27;Par d\xE9faut pour les threads \xE9largis&#x27;</span>}]'}}),ot=new U({props:{code:'split_datasets["train"][172]["translation"]',highlighted:'split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">172</span>][<span class="hljs-string">&quot;translation&quot;</span>]'}}),Mn=new U({props:{code:`{'en': 'Unable to import %1 using the OFX importer plugin. This file is not the correct format.',
 'fr': "Impossible d'importer %1 en utilisant le module d'extension d'importation OFX. Ce fichier n'a pas un format correct."}`,highlighted:`{<span class="hljs-string">&#x27;en&#x27;</span>: <span class="hljs-string">&#x27;Unable to import %1 using the OFX importer plugin. This file is not the correct format.&#x27;</span>,
 <span class="hljs-string">&#x27;fr&#x27;</span>: <span class="hljs-string">&quot;Impossible d&#x27;importer %1 en utilisant le module d&#x27;extension d&#x27;importation OFX. Ce fichier n&#x27;a pas un format correct.&quot;</span>}`}}),Nn=new U({props:{code:`translator(
    "Unable to import %1 using the OFX importer plugin. This file is not the correct format."
)`,highlighted:`translator(
    <span class="hljs-string">&quot;Unable to import %1 using the OFX importer plugin. This file is not the correct format.&quot;</span>
)`}}),Ln=new U({props:{code:`[{'translation_text': "Impossible d'importer %1 en utilisant le plugin d'importateur OFX. Ce fichier n'est pas le bon format."}]`,highlighted:'[{<span class="hljs-string">&#x27;translation_text&#x27;</span>: <span class="hljs-string">&quot;Impossible d&#x27;importer %1 en utilisant le plugin d&#x27;importateur OFX. Ce fichier n&#x27;est pas le bon format.&quot;</span>}]'}}),On=new ju({props:{id:"0Oxphw4Q9fo"}}),Rt=new Ta({props:{$$slots:{default:[d_]},$$scope:{ctx:Z}}}),Un=new Kt({}),Et=new ju({props:{id:"XAR8jnZZuUs"}}),Ha=new U({props:{code:`from transformers import AutoTokenizer

model_checkpoint = "Helsinki-NLP/opus-mt-en-fr"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors="tf")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

model_checkpoint = <span class="hljs-string">&quot;Helsinki-NLP/opus-mt-en-fr&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),pa=new Ta({props:{$$slots:{default:[c_]},$$scope:{ctx:Z}}}),Ba=new U({props:{code:`with open(file_path) as f:
    content = f.read()`,highlighted:`<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path) <span class="hljs-keyword">as</span> f:
    content = f.<span class="hljs-built_in">read</span>()`}}),Ra=new U({props:{code:`en_sentence = split_datasets["train"][1]["translation"]["en"]
fr_sentence = split_datasets["train"][1]["translation"]["fr"]

inputs = tokenizer(en_sentence)
with tokenizer.as_target_tokenizer():
    targets = tokenizer(fr_sentence)`,highlighted:`en_sentence = split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>][<span class="hljs-string">&quot;en&quot;</span>]
fr_sentence = split_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;translation&quot;</span>][<span class="hljs-string">&quot;fr&quot;</span>]

inputs = tokenizer(en_sentence)
<span class="hljs-keyword">with</span> tokenizer.as_target_tokenizer():
    targets = tokenizer(fr_sentence)`}}),Ka=new U({props:{code:`wrong_targets = tokenizer(fr_sentence)
print(tokenizer.convert_ids_to_tokens(wrong_targets["input_ids"]))
print(tokenizer.convert_ids_to_tokens(targets["input_ids"]))`,highlighted:`wrong_targets = tokenizer(fr_sentence)
<span class="hljs-built_in">print</span>(tokenizer.convert_ids_to_tokens(wrong_targets[<span class="hljs-string">&quot;input_ids&quot;</span>]))
<span class="hljs-built_in">print</span>(tokenizer.convert_ids_to_tokens(targets[<span class="hljs-string">&quot;input_ids&quot;</span>]))`}}),Va=new U({props:{code:`['\u2581Par', '\u2581d\xE9', 'f', 'aut', ',', '\u2581d\xE9', 've', 'lop', 'per', '\u2581les', '\u2581fil', 's', '\u2581de', '\u2581discussion', '</s>']
['\u2581Par', '\u2581d\xE9faut', ',', '\u2581d\xE9velopper', '\u2581les', '\u2581fils', '\u2581de', '\u2581discussion', '</s>']`,highlighted:`[<span class="hljs-string">&#x27;\u2581Par&#x27;</span>, <span class="hljs-string">&#x27;\u2581d\xE9&#x27;</span>, <span class="hljs-string">&#x27;f&#x27;</span>, <span class="hljs-string">&#x27;aut&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>, <span class="hljs-string">&#x27;\u2581d\xE9&#x27;</span>, <span class="hljs-string">&#x27;ve&#x27;</span>, <span class="hljs-string">&#x27;lop&#x27;</span>, <span class="hljs-string">&#x27;per&#x27;</span>, <span class="hljs-string">&#x27;\u2581les&#x27;</span>, <span class="hljs-string">&#x27;\u2581fil&#x27;</span>, <span class="hljs-string">&#x27;s&#x27;</span>, <span class="hljs-string">&#x27;\u2581de&#x27;</span>, <span class="hljs-string">&#x27;\u2581discussion&#x27;</span>, <span class="hljs-string">&#x27;&lt;/s&gt;&#x27;</span>]
[<span class="hljs-string">&#x27;\u2581Par&#x27;</span>, <span class="hljs-string">&#x27;\u2581d\xE9faut&#x27;</span>, <span class="hljs-string">&#x27;,&#x27;</span>, <span class="hljs-string">&#x27;\u2581d\xE9velopper&#x27;</span>, <span class="hljs-string">&#x27;\u2581les&#x27;</span>, <span class="hljs-string">&#x27;\u2581fils&#x27;</span>, <span class="hljs-string">&#x27;\u2581de&#x27;</span>, <span class="hljs-string">&#x27;\u2581discussion&#x27;</span>, <span class="hljs-string">&#x27;&lt;/s&gt;&#x27;</span>]`}}),Ga=new U({props:{code:`max_input_length = 128
max_target_length = 128


def preprocess_function(examples):
    inputs = [ex["en"] for ex in examples["translation"]]
    targets = [ex["fr"] for ex in examples["translation"]]
    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)

    # Configurer le tokenizer pour les cibles.
    with tokenizer.as_target_tokenizer():
        labels = tokenizer(targets, max_length=max_target_length, truncation=True)

    model_inputs["labels"] = labels["input_ids"]
    return model_inputs`,highlighted:`max_input_length = <span class="hljs-number">128</span>
max_target_length = <span class="hljs-number">128</span>


<span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
    inputs = [ex[<span class="hljs-string">&quot;en&quot;</span>] <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;translation&quot;</span>]]
    targets = [ex[<span class="hljs-string">&quot;fr&quot;</span>] <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;translation&quot;</span>]]
    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Configurer le tokenizer pour les cibles.</span>
    <span class="hljs-keyword">with</span> tokenizer.as_target_tokenizer():
        labels = tokenizer(targets, max_length=max_target_length, truncation=<span class="hljs-literal">True</span>)

    model_inputs[<span class="hljs-string">&quot;labels&quot;</span>] = labels[<span class="hljs-string">&quot;input_ids&quot;</span>]
    <span class="hljs-keyword">return</span> model_inputs`}}),ma=new Ta({props:{$$slots:{default:[m_]},$$scope:{ctx:Z}}}),fa=new Ta({props:{warning:!0,$$slots:{default:[f_]},$$scope:{ctx:Z}}}),Xa=new U({props:{code:`tokenized_datasets = split_datasets.map(
    preprocess_function,
    batched=True,
    remove_columns=split_datasets["train"].column_names,
)`,highlighted:`tokenized_datasets = split_datasets.<span class="hljs-built_in">map</span>(
    preprocess_function,
    batched=<span class="hljs-literal">True</span>,
    remove_columns=split_datasets[<span class="hljs-string">&quot;train&quot;</span>].column_names,
)`}});const wc=[h_,__],Pr=[];function zc(e,p){return e[0]==="pt"?0:1}qn=zc(Z),En=Pr[qn]=wc[qn](Z),Wa=new Kt({});const yc=[$_,b_],Cr=[];function Pc(e,p){return e[0]==="pt"?0:1}jn=Pc(Z),kn=Cr[jn]=yc[jn](Z),Ja=new U({props:{code:`batch = data_collator([tokenized_datasets["train"][i] for i in range(1, 3)])
batch.keys()`,highlighted:`batch = data_collator([tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)])
batch.keys()`}}),Ya=new U({props:{code:"dict_keys(['attention_mask', 'input_ids', 'labels', 'decoder_input_ids'])",highlighted:'dict_keys([<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;labels&#x27;</span>, <span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>])'}}),Za=new U({props:{code:'batch["labels"]',highlighted:'batch[<span class="hljs-string">&quot;labels&quot;</span>]'}}),er=new U({props:{code:`tensor([[  577,  5891,     2,  3184,    16,  2542,     5,  1710,     0,  -100,
          -100,  -100,  -100,  -100,  -100,  -100],
        [ 1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,   817,
           550,  7032,  5821,  7907, 12649,     0]])`,highlighted:`tensor([[  <span class="hljs-number">577</span>,  <span class="hljs-number">5891</span>,     <span class="hljs-number">2</span>,  <span class="hljs-number">3184</span>,    <span class="hljs-number">16</span>,  <span class="hljs-number">2542</span>,     <span class="hljs-number">5</span>,  <span class="hljs-number">1710</span>,     <span class="hljs-number">0</span>,  -<span class="hljs-number">100</span>,
          -<span class="hljs-number">100</span>,  -<span class="hljs-number">100</span>,  -<span class="hljs-number">100</span>,  -<span class="hljs-number">100</span>,  -<span class="hljs-number">100</span>,  -<span class="hljs-number">100</span>],
        [ <span class="hljs-number">1211</span>,     <span class="hljs-number">3</span>,    <span class="hljs-number">49</span>,  <span class="hljs-number">9409</span>,  <span class="hljs-number">1211</span>,     <span class="hljs-number">3</span>, <span class="hljs-number">29140</span>,   <span class="hljs-number">817</span>,  <span class="hljs-number">3124</span>,   <span class="hljs-number">817</span>,
           <span class="hljs-number">550</span>,  <span class="hljs-number">7032</span>,  <span class="hljs-number">5821</span>,  <span class="hljs-number">7907</span>, <span class="hljs-number">12649</span>,     <span class="hljs-number">0</span>]])`}}),sr=new U({props:{code:'batch["decoder_input_ids"]',highlighted:'batch[<span class="hljs-string">&quot;decoder_input_ids&quot;</span>]'}}),tr=new U({props:{code:`tensor([[59513,   577,  5891,     2,  3184,    16,  2542,     5,  1710,     0,
         59513, 59513, 59513, 59513, 59513, 59513],
        [59513,  1211,     3,    49,  9409,  1211,     3, 29140,   817,  3124,
           817,   550,  7032,  5821,  7907, 12649]])`,highlighted:`tensor([[<span class="hljs-number">59513</span>,   <span class="hljs-number">577</span>,  <span class="hljs-number">5891</span>,     <span class="hljs-number">2</span>,  <span class="hljs-number">3184</span>,    <span class="hljs-number">16</span>,  <span class="hljs-number">2542</span>,     <span class="hljs-number">5</span>,  <span class="hljs-number">1710</span>,     <span class="hljs-number">0</span>,
         <span class="hljs-number">59513</span>, <span class="hljs-number">59513</span>, <span class="hljs-number">59513</span>, <span class="hljs-number">59513</span>, <span class="hljs-number">59513</span>, <span class="hljs-number">59513</span>],
        [<span class="hljs-number">59513</span>,  <span class="hljs-number">1211</span>,     <span class="hljs-number">3</span>,    <span class="hljs-number">49</span>,  <span class="hljs-number">9409</span>,  <span class="hljs-number">1211</span>,     <span class="hljs-number">3</span>, <span class="hljs-number">29140</span>,   <span class="hljs-number">817</span>,  <span class="hljs-number">3124</span>,
           <span class="hljs-number">817</span>,   <span class="hljs-number">550</span>,  <span class="hljs-number">7032</span>,  <span class="hljs-number">5821</span>,  <span class="hljs-number">7907</span>, <span class="hljs-number">12649</span>]])`}}),nr=new U({props:{code:`for i in range(1, 3):
    print(tokenized_datasets["train"][i]["labels"])`,highlighted:`<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>):
    <span class="hljs-built_in">print</span>(tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][i][<span class="hljs-string">&quot;labels&quot;</span>])`}}),ar=new U({props:{code:`[577, 5891, 2, 3184, 16, 2542, 5, 1710, 0]
[1211, 3, 49, 9409, 1211, 3, 29140, 817, 3124, 817, 550, 7032, 5821, 7907, 12649, 0]`,highlighted:`[<span class="hljs-number">577</span>, <span class="hljs-number">5891</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3184</span>, <span class="hljs-number">16</span>, <span class="hljs-number">2542</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1710</span>, <span class="hljs-number">0</span>]
[<span class="hljs-number">1211</span>, <span class="hljs-number">3</span>, <span class="hljs-number">49</span>, <span class="hljs-number">9409</span>, <span class="hljs-number">1211</span>, <span class="hljs-number">3</span>, <span class="hljs-number">29140</span>, <span class="hljs-number">817</span>, <span class="hljs-number">3124</span>, <span class="hljs-number">817</span>, <span class="hljs-number">550</span>, <span class="hljs-number">7032</span>, <span class="hljs-number">5821</span>, <span class="hljs-number">7907</span>, <span class="hljs-number">12649</span>, <span class="hljs-number">0</span>]`}});const Cc=[q_,g_],Dr=[];function Dc(e,p){return e[0]==="pt"?0:1}xn=Dc(Z),wn=Dr[xn]=Cc[xn](Z),rr=new Kt({}),lr=new ju({props:{id:"M05L1DhFqcw"}});let ut=Z[0]==="pt"&&e_();pr=new U({props:{code:"!pip install sacrebleu",highlighted:"!pip install sacrebleu"}}),dr=new U({props:{code:`from datasets import load_metric

metric = load_metric("sacrebleu")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric

metric = load_metric(<span class="hljs-string">&quot;sacrebleu&quot;</span>)`}}),cr=new U({props:{code:`predictions = [
    "This plugin lets you translate web pages between several languages automatically."
]
references = [
    [
        "This plugin allows you to automatically translate web pages between several languages."
    ]
]
metric.compute(predictions=predictions, references=references)`,highlighted:`predictions = [
    <span class="hljs-string">&quot;This plugin lets you translate web pages between several languages automatically.&quot;</span>
]
references = [
    [
        <span class="hljs-string">&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span>
    ]
]
metric.compute(predictions=predictions, references=references)`}}),mr=new U({props:{code:`{'score': 46.750469682990165,
 'counts': [11, 6, 4, 3],
 'totals': [12, 11, 10, 9],
 'precisions': [91.67, 54.54, 40.0, 33.33],
 'bp': 0.9200444146293233,
 'sys_len': 12,
 'ref_len': 13}`,highlighted:`{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">46.750469682990165</span>,
 <span class="hljs-string">&#x27;counts&#x27;</span>: [<span class="hljs-number">11</span>, <span class="hljs-number">6</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>],
 <span class="hljs-string">&#x27;totals&#x27;</span>: [<span class="hljs-number">12</span>, <span class="hljs-number">11</span>, <span class="hljs-number">10</span>, <span class="hljs-number">9</span>],
 <span class="hljs-string">&#x27;precisions&#x27;</span>: [<span class="hljs-number">91.67</span>, <span class="hljs-number">54.54</span>, <span class="hljs-number">40.0</span>, <span class="hljs-number">33.33</span>],
 <span class="hljs-string">&#x27;bp&#x27;</span>: <span class="hljs-number">0.9200444146293233</span>,
 <span class="hljs-string">&#x27;sys_len&#x27;</span>: <span class="hljs-number">12</span>,
 <span class="hljs-string">&#x27;ref_len&#x27;</span>: <span class="hljs-number">13</span>}`}}),hr=new U({props:{code:`predictions = ["This This This This"]
references = [
    [
        "This plugin allows you to automatically translate web pages between several languages."
    ]
]
metric.compute(predictions=predictions, references=references)`,highlighted:`predictions = [<span class="hljs-string">&quot;This This This This&quot;</span>]
references = [
    [
        <span class="hljs-string">&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span>
    ]
]
metric.compute(predictions=predictions, references=references)`}}),vr=new U({props:{code:`{'score': 1.683602693167689,
 'counts': [1, 0, 0, 0],
 'totals': [4, 3, 2, 1],
 'precisions': [25.0, 16.67, 12.5, 12.5],
 'bp': 0.10539922456186433,
 'sys_len': 4,
 'ref_len': 13}`,highlighted:`{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">1.683602693167689</span>,
 <span class="hljs-string">&#x27;counts&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;totals&#x27;</span>: [<span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>],
 <span class="hljs-string">&#x27;precisions&#x27;</span>: [<span class="hljs-number">25.0</span>, <span class="hljs-number">16.67</span>, <span class="hljs-number">12.5</span>, <span class="hljs-number">12.5</span>],
 <span class="hljs-string">&#x27;bp&#x27;</span>: <span class="hljs-number">0.10539922456186433</span>,
 <span class="hljs-string">&#x27;sys_len&#x27;</span>: <span class="hljs-number">4</span>,
 <span class="hljs-string">&#x27;ref_len&#x27;</span>: <span class="hljs-number">13</span>}`}}),br=new U({props:{code:`predictions = ["This plugin"]
references = [
    [
        "This plugin allows you to automatically translate web pages between several languages."
    ]
]
metric.compute(predictions=predictions, references=references)`,highlighted:`predictions = [<span class="hljs-string">&quot;This plugin&quot;</span>]
references = [
    [
        <span class="hljs-string">&quot;This plugin allows you to automatically translate web pages between several languages.&quot;</span>
    ]
]
metric.compute(predictions=predictions, references=references)`}}),$r=new U({props:{code:`{'score': 0.0,
 'counts': [2, 1, 0, 0],
 'totals': [2, 1, 0, 0],
 'precisions': [100.0, 100.0, 0.0, 0.0],
 'bp': 0.004086771438464067,
 'sys_len': 2,
 'ref_len': 13}`,highlighted:`{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0</span>,
 <span class="hljs-string">&#x27;counts&#x27;</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;totals&#x27;</span>: [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;precisions&#x27;</span>: [<span class="hljs-number">100.0</span>, <span class="hljs-number">100.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>],
 <span class="hljs-string">&#x27;bp&#x27;</span>: <span class="hljs-number">0.004086771438464067</span>,
 <span class="hljs-string">&#x27;sys_len&#x27;</span>: <span class="hljs-number">2</span>,
 <span class="hljs-string">&#x27;ref_len&#x27;</span>: <span class="hljs-number">13</span>}`}});const Tc=[j_,E_],Tr=[];function Sc(e,p){return e[0]==="tf"?0:1}zn=Sc(Z),yn=Tr[zn]=Tc[zn](Z),gr=new Kt({}),qr=new U({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`}}),Er=new U({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}});const Ac=[x_,k_],Sr=[];function Mc(e,p){return e[0]==="tf"?0:1}Pn=Mc(Z),Cn=Sr[Pn]=Ac[Pn](Z);let $s=Z[0]==="pt"&&s_();return jr=new Kt({}),kr=new U({props:{code:`from transformers import pipeline

# Remplacez ceci par votre propre checkpoint
model_checkpoint = "huggingface-course/marian-finetuned-kde4-en-to-fr"
translator = pipeline("translation", model=model_checkpoint)
translator("Default to expanded threads")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-comment"># Remplacez ceci par votre propre checkpoint</span>
model_checkpoint = <span class="hljs-string">&quot;huggingface-course/marian-finetuned-kde4-en-to-fr&quot;</span>
translator = pipeline(<span class="hljs-string">&quot;translation&quot;</span>, model=model_checkpoint)
translator(<span class="hljs-string">&quot;Default to expanded threads&quot;</span>)`}}),xr=new U({props:{code:"[{'translation_text': 'Par d\xE9faut, d\xE9velopper les fils de discussion'}]",highlighted:'[{<span class="hljs-string">&#x27;translation_text&#x27;</span>: <span class="hljs-string">&#x27;Par d\xE9faut, d\xE9velopper les fils de discussion&#x27;</span>}]'}}),wr=new U({props:{code:`translator(
    "Unable to import %1 using the OFX importer plugin. This file is not the correct format."
)`,highlighted:`translator(
    <span class="hljs-string">&quot;Unable to import %1 using the OFX importer plugin. This file is not the correct format.&quot;</span>
)`}}),zr=new U({props:{code:`[{'translation_text': "Impossible d'importer %1 en utilisant le module externe d'importation OFX. Ce fichier n'est pas le bon format."}]`,highlighted:'[{<span class="hljs-string">&#x27;translation_text&#x27;</span>: <span class="hljs-string">&quot;Impossible d&#x27;importer %1 en utilisant le module externe d&#x27;importation OFX. Ce fichier n&#x27;est pas le bon format.&quot;</span>}]'}}),ka=new Ta({props:{$$slots:{default:[y_]},$$scope:{ctx:Z}}}),{c(){u=r("meta"),q=d(),E(_.$$.fragment),w=d(),A=r("h1"),v=r("a"),T=r("span"),E(S.$$.fragment),z=d(),C=r("span"),F=n("Traduction"),D=d(),R.c(),H=d(),L=r("p"),Y=n("Plongeons maintenant dans la traduction. Il s\u2019agit d\u2019une autre "),O=r("a"),V=n("t\xE2che de s\xE9quence \xE0 s\xE9quence"),W=n(", ce qui signifie que c\u2019est un probl\xE8me qui peut \xEAtre formul\xE9 comme le passage d\u2019une s\xE9quence \xE0 une autre. En ce sens, le probl\xE8me est assez proche de la t\xE2che de "),M=r("a"),P=n("r\xE9sum\xE9"),se=n(" et vous pouvez adapter ce que nous allons voir ici \xE0 d\u2019autres probl\xE8mes de s\xE9quence \xE0 s\xE9quence tels que :"),N=d(),I=r("ul"),Q=r("li"),ee=n("Le "),X=r("strong"),ie=n("transfert de style"),re=n(" ? c\u2019est-\xE0-dire cr\xE9er un mod\xE8le qui "),te=r("em"),me=n("traduit"),le=n(" des textes \xE9crits dans un certain style vers un autre (par exemple, du formel au d\xE9contract\xE9 ou de l\u2019anglais shakespearien \xE0 l\u2019anglais moderne)."),de=d(),ue=r("li"),ve=n("La "),be=r("strong"),$e=n("g\xE9n\xE9ration de r\xE9ponse \xE0 des questions"),_e=n(" c\u2019est-\xE0-dire cr\xE9er un mod\xE8le qui g\xE9n\xE8re des r\xE9ponses \xE0 des questions compte tenu d\u2019un contexte."),J=d(),E(pe.$$.fragment),ce=d(),G=r("p"),Ae=n("Si vous disposez d\u2019un corpus de textes suffisamment important en deux langues diff\xE9rentes (ou plus), vous pouvez entra\xEEner un nouveau mod\xE8le de traduction \xE0 partir de z\xE9ro, comme nous le ferons dans la section sur la "),ge=r("a"),Qe=n("mod\xE9lisation causale du langage"),qe=n(". Il est toutefois plus rapide de "),fe=r("em"),Me=n("finetuner"),ne=n(" un mod\xE8le de traduction existant, qu\u2019il s\u2019agisse d\u2019un mod\xE8le multilingue comme mT5 ou mBART que vous souhaitez adapter \xE0 une paire de langues sp\xE9cifique, ou m\xEAme d\u2019un mod\xE8le sp\xE9cialis\xE9 dans la traduction d\u2019une langue vers une autre que vous souhaitez adapter \xE0 votre corpus sp\xE9cifique."),Oe=d(),ae=r("p"),ze=n("Dans cette section, nous allons "),ye=r("em"),De=n("finetuner"),us=n(" un mod\xE8le Marian pr\xE9-entra\xEEn\xE9 pour traduire de l\u2019anglais au fran\xE7ais (puisque de nombreux employ\xE9s de Hugging Face parlent ces deux langues) sur le jeu de donn\xE9es "),Ue=r("a"),es=n("KDE4"),ps=n(" qui est un jeu de donn\xE9es de fichiers localis\xE9s pour les applications "),ss=r("a"),Pe=n("KDE"),Fe=n(". Le mod\xE8le que nous utiliserons a \xE9t\xE9 pr\xE9-entra\xEEn\xE9 sur un large corpus de textes fran\xE7ais et anglais provenant du jeu de donn\xE9es "),He=r("a"),Ee=n("Opus"),Xs=n(" qui contient en fait le jeu de donn\xE9es KDE4. A noter que m\xEAme si le mod\xE8le pr\xE9-entra\xEEn\xE9 que nous utilisons a vu ces donn\xE9es pendant son pr\xE9-entra\xEEnement, nous verrons que nous pouvons obtenir une meilleure version de ce mod\xE8le apr\xE8s un "),Ie=r("em"),Ws=n("finetuning"),Qs=n("."),Je=d(),Re=r("p"),As=n("Une fois que nous aurons termin\xE9, nous aurons un mod\xE8le capable de faire des pr\xE9dictions comme celle-ci :"),Ne=d(),g=r("iframe"),gs=d(),je=r("iframe"),he=d(),Ke=r("a"),Le=r("img"),xe=d(),ts=r("img"),qs=d(),Ye=r("p"),Js=n("Comme dans les sections pr\xE9c\xE9dentes, vous pouvez trouver, t\xE9l\xE9charger et v\xE9rifier les pr\xE9cisions de ce mod\xE8le sur le "),Ve=r("a"),ds=r("em"),Te=n("Hub"),ct=n("."),cs=d(),ns=r("h2"),Ms=r("a"),Ys=r("span"),E(Ge.$$.fragment),Vt=d(),Es=r("span"),Ns=n("Pr\xE9paration des donn\xE9es"),Ls=d(),Ce=r("p"),kt=n("Pour "),as=r("em"),Gt=n("finetuner"),ms=n(" ou entra\xEEner un mod\xE8le de traduction \xE0 partir de z\xE9ro, nous avons besoin d\u2019un jeu de donn\xE9es adapt\xE9 \xE0 cette t\xE2che. Comme mentionn\xE9 pr\xE9c\xE9demment, nous utiliserons le jeu de donn\xE9es "),ke=r("a"),xt=n("KDE4"),wt=n(" dans cette section. Notez que vous pouvez adapter assez facilement le code pour utiliser vos propres donn\xE9es du moment que vous disposez de paires de phrases dans les deux langues que vous voulez traduire. Reportez-vous au "),mt=r("a"),zt=n("chapitre 5"),yt=n(" si vous avez besoin d\u2019un rappel sur la fa\xE7on de charger vos donn\xE9es personnalis\xE9es dans un "),Pt=r("code"),Xt=n("Dataset"),fs=n("."),xs=d(),_s=r("h3"),Xe=r("a"),Ct=r("span"),E(ws.$$.fragment),Dt=d(),ft=r("span"),js=n("Le jeu de donn\xE9es KDE4"),Tt=d(),We=r("p"),Wt=n("Comme d\u2019habitude, nous t\xE9l\xE9chargeons notre jeu de donn\xE9es en utilisant la fonction "),Os=r("code"),St=n("load_dataset()"),Qt=n(" :"),Us=d(),E(zs.$$.fragment),Se=d(),ys=r("p"),rs=n("Si vous souhaitez travailler avec une autre paire de langues, 92 langues sont disponibles au total pour ce jeu de donn\xE9es. Vous pouvez les voir dans la "),Zs=r("a"),_t=n("carte du jeu de donn\xE9es"),At=n("."),Jt=d(),hs=r("img"),Zt=d(),et=r("p"),vs=n("Jetons un coup d\u2019\u0153il au jeu de donn\xE9es :"),Ps=d(),E(Cs.$$.fragment),ht=d(),E(st.$$.fragment),vt=d(),Ze=r("p"),f=n("Nous avons 210 173 paires de phrases. Cependant regroup\xE9es dans un seul \xE9chantillon. Nous devrons donc cr\xE9er notre propre jeu de validation. Comme nous l\u2019avons vu dans le "),B=r("a"),bs=n("chapitre 5"),Dn=n(", un "),tt=r("code"),en=n("Dataset"),Fs=n(" poss\xE8de une m\xE9thode "),sn=r("code"),bt=n("train_test_split()"),Tn=n(" qui peut nous aider. Nous allons fournir une graine pour la reproductibilit\xE9 :"),Mt=d(),E(Hs.$$.fragment),nt=d(),E($t.$$.fragment),tn=d(),we=r("p"),vn=n("Nous pouvons renommer la cl\xE9 \u201Ctest\u201D en \u201Cvalidation\u201D comme ceci :"),at=d(),E(rt.$$.fragment),ks=d(),Nt=r("p"),nn=n("Examinons maintenant un \xE9l\xE9ment de ce jeu de donn\xE9es :"),Lt=d(),E(gt.$$.fragment),Ds=d(),E(Is.$$.fragment),bn=d(),lt=r("p"),Ot=n(`Nous obtenons un dictionnaire contenant deux phrases dans la paire de langues qui nous int\xE9resse.
Une particularit\xE9 de ce jeu de donn\xE9es rempli de termes techniques informatiques est qu\u2019ils sont tous enti\xE8rement traduits en fran\xE7ais. Cependant, les ing\xE9nieurs fran\xE7ais sont souvent paresseux et laissent la plupart des mots sp\xE9cifiques \xE0 l\u2019informatique en anglais lorsqu\u2019ils parlent. Ici, par exemple, le mot \xAB `),m=r("em"),K=n("threads"),Jn=n(" \xBB pourrait tr\xE8s bien appara\xEEtre dans une phrase fran\xE7aise, surtout dans une conversation technique. Mais dans ce jeu de donn\xE9es, il a \xE9t\xE9 traduit en \xAB fils de discussion \xBB. Le mod\xE8le pr\xE9-entra\xEEn\xE9 que nous utilisons (qui a \xE9t\xE9 pr\xE9-entra\xEEn\xE9 sur un plus grand corpus de phrases fran\xE7aises et anglaises) prend l\u2019option de laisser le mot tel quel :"),ls=d(),E(Ut.$$.fragment),qt=d(),E(Ft.$$.fragment),Sn=d(),Bs=r("p"),Yn=n("Un autre exemple de ce comportement peut \xEAtre observ\xE9 avec le mot  \xAB "),Ts=r("em"),Zn=n("plugin"),Ht=n(` \xBB qui n\u2019est pas officiellement un mot fran\xE7ais mais que la plupart des francophones comprendront et ne prendront pas la peine de traduire.
Dans le jeu de donn\xE9es KDE4, ce mot a \xE9t\xE9 traduit en fran\xE7ais par le plus officiel \xAB module d\u2019extension \xBB :`),An=d(),E(ot.$$.fragment),an=d(),E(Mn.$$.fragment),Sa=d(),it=r("p"),Or=n("Notre mod\xE8le pr\xE9-entra\xEEn\xE9, lui, s\u2019en tient au mot anglais :"),Aa=d(),E(Nn.$$.fragment),It=d(),E(Ln.$$.fragment),Ma=d(),Bt=r("p"),Rs=n("Il sera int\xE9ressant de voir si notre mod\xE8le "),ra=r("em"),Ur=n("finetun\xE9"),Fr=n(" tient compte de ces particularit\xE9s (alerte "),la=r("em"),Hr=n("spoiler"),Ir=n(" : il le fera)."),$n=d(),E(On.$$.fragment),Na=d(),E(Rt.$$.fragment),La=d(),rn=r("h3"),gn=r("a"),ln=r("span"),E(Un.$$.fragment),Br=d(),on=r("span"),Rr=n("Traitement des donn\xE9es"),Oa=d(),E(Et.$$.fragment),Ua=d(),Ss=r("p"),un=n("Vous devriez maintenant conna\xEEtre le principe : les textes doivent tous \xEAtre convertis en ensembles d\u2019ID de "),oa=r("em"),Kr=n("tokens"),Vr=n(" pour que le mod\xE8le puisse leur donner un sens. Pour cette t\xE2che, nous aurons besoin de tokeniser les entr\xE9es et les cibles. Notre premi\xE8re t\xE2che est de cr\xE9er notre objet "),ia=r("code"),Fn=n("tokenizer"),Gr=n(". Comme indiqu\xE9 pr\xE9c\xE9demment, nous utiliserons un mod\xE8le pr\xE9-entra\xEEn\xE9 Marian English to French. Si vous essayez ce code avec une autre paire de langues, assurez-vous d\u2019adapter le "),ua=r("em"),Xr=n("checkpoint"),ku=n(" du mod\xE8le. L\u2019organisation "),Fa=r("a"),xu=n("Helsinki-NLP"),wu=n(" fournit plus de mille mod\xE8les dans plusieurs langues."),Uo=d(),E(Ha.$$.fragment),Fo=d(),pn=r("p"),zu=n("Vous pouvez remplacer le "),Pl=r("code"),yu=n("model_checkpoint"),Pu=n(" par un tout autre mod\xE8le disponible sur le "),Ia=r("a"),Cl=r("em"),Cu=n("Hub"),Du=n(" qui aurait votre pr\xE9f\xE9rence, ou par un dossier en local o\xF9 vous avez sauvegard\xE9 un mod\xE8le pr\xE9-entra\xEEn\xE9 et un "),Dl=r("em"),Tu=n("tokenizer"),Su=n("."),Ho=d(),E(pa.$$.fragment),Io=d(),Hn=r("p"),Au=n("La pr\xE9paration de nos donn\xE9es est assez simple. Il y a juste une chose \xE0 retenir : vous traitez les entr\xE9es comme d\u2019habitude, mais pour les cibles, vous devez envelopper le "),Tl=r("em"),Mu=n("tokenizer"),Nu=n(" dans le gestionnaire de contexte "),Sl=r("code"),Lu=n("as_target_tokenizer()"),Ou=n("."),Bo=d(),da=r("p"),Uu=n("Un gestionnaire de contexte en Python est introduit avec l\u2019instruction "),Al=r("code"),Fu=n("with"),Hu=n(" et est utile lorsque vous avez deux op\xE9rations li\xE9es \xE0 ex\xE9cuter en paire. L\u2019exemple le plus courant est lorsque vous \xE9crivez ou lisez un fichier, ce qui est souvent fait dans une instruction comme :"),Ro=d(),E(Ba.$$.fragment),Ko=d(),In=r("p"),Iu=n("Ici, les deux op\xE9rations connexes qui sont ex\xE9cut\xE9es en paire sont les actions d\u2019ouverture et de fermeture du fichier. L\u2019objet correspondant au fichier ouvert "),Ml=r("code"),Bu=n("f"),Ru=n(" n\u2019existe qu\u2019\xE0 l\u2019int\xE9rieur du bloc indent\xE9 sous le "),Nl=r("code"),Ku=n("with"),Vu=n(". L\u2019ouverture se produit avant ce bloc et la fermeture \xE0 la fin du bloc."),Vo=d(),Bn=r("p"),Gu=n("Dans le cas pr\xE9sent, le gestionnaire de contexte "),Ll=r("code"),Xu=n("as_target_tokenizer()"),Wu=n(" va d\xE9finir le "),Ol=r("em"),Qu=n("tokenizer"),Ju=n(" dans la langue de sortie (ici, le fran\xE7ais) avant l\u2019ex\xE9cution du bloc indent\xE9, puis le red\xE9finir dans la langue d\u2019entr\xE9e (ici, l\u2019anglais)."),Go=d(),Wr=r("p"),Yu=n("Ainsi, le pr\xE9traitement d\u2019un \xE9chantillon ressemble \xE0 ceci :"),Xo=d(),E(Ra.$$.fragment),Wo=d(),ca=r("p"),Zu=n("Si nous oublions de tokeniser les cibles dans le gestionnaire de contexte, elles seront tokenis\xE9es par le "),Ul=r("em"),ep=n("tokenizer"),sp=n(" d\u2019entr\xE9e, ce qui dans le cas d\u2019un mod\xE8le Marian, ne va pas du tout bien se passer :"),Qo=d(),E(Ka.$$.fragment),Jo=d(),E(Va.$$.fragment),Yo=d(),dn=r("p"),tp=n("Comme on peut le voir, utiliser le "),Fl=r("em"),np=n("tokenizer"),ap=n(" anglais pour pr\xE9traiter une phrase fran\xE7aise donne un batch de "),Hl=r("em"),rp=n("tokens"),lp=n(" plus important, puisque le "),Il=r("em"),op=n("tokenizer"),ip=n(" ne conna\xEEt aucun mot fran\xE7ais (sauf ceux qui apparaissent aussi en anglais, comme \xAB discussion \xBB)."),Zo=d(),cn=r("p"),up=n("Les "),Bl=r("code"),pp=n("inputs"),dp=n(" et les "),Rl=r("code"),cp=n("targets"),mp=n(" sont des dictionnaires avec nos cl\xE9s habituelles (identifiants d\u2019entr\xE9e, masque d\u2019attention, etc.). La derni\xE8re \xE9tape est de d\xE9finir une cl\xE9 "),Kl=r("code"),fp=n('"labels"'),_p=n(" dans les entr\xE9es. Nous faisons cela dans la fonction de pr\xE9traitement que nous allons appliquer sur les jeux de donn\xE9es :"),ei=d(),E(Ga.$$.fragment),si=d(),Qr=r("p"),hp=n("Notez que nous avons fix\xE9 des longueurs maximales similaires pour nos entr\xE9es et nos sorties. Comme les textes que nous traitons semblent assez courts, nous utilisons 128."),ti=d(),E(ma.$$.fragment),ni=d(),E(fa.$$.fragment),ai=d(),Jr=r("p"),vp=n("Nous pouvons maintenant appliquer ce pr\xE9traitement en une seule fois sur toutes les \xE9chantillons de notre jeu de donn\xE9es :"),ri=d(),E(Xa.$$.fragment),li=d(),_a=r("p"),bp=n("Maintenant que les donn\xE9es ont \xE9t\xE9 pr\xE9trait\xE9es, nous sommes pr\xEAts \xE0 "),Vl=r("em"),$p=n("finetuner"),gp=n(" notre mod\xE8le pr\xE9-entra\xEEn\xE9 !"),oi=d(),En.c(),Yr=d(),Zr=r("p"),qp=n("Notez que cette fois-ci, nous utilisons un mod\xE8le qui a \xE9t\xE9 entra\xEEn\xE9 sur une t\xE2che de traduction et qui peut d\xE9j\xE0 \xEAtre utilis\xE9, donc il n\u2019y a pas d\u2019avertissement concernant les poids manquants ou ceux nouvellement initialis\xE9s."),ii=d(),ea=r("h3"),ha=r("a"),Gl=r("span"),E(Wa.$$.fragment),Ep=d(),Xl=r("span"),jp=n("Collecte des donn\xE9es"),ui=d(),os=r("p"),kp=n("Nous aurons besoin d\u2019un assembleur de donn\xE9es pour g\xE9rer le rembourrage pour la mise en batchs dynamique. Ici, nous ne pouvons pas simplement utiliser un "),Wl=r("code"),xp=n("DataCollatorWithPadding"),wp=n(" comme dans le "),el=r("a"),zp=n("chapitre 3"),yp=n(" car cela ne rembourre que les entr\xE9es (identifiants d\u2019entr\xE9e, masque d\u2019attention, et "),Ql=r("em"),Pp=n("token"),Cp=n(" de type identifiants). Nos \xE9tiquettes doivent \xE9galement \xEAtre rembourr\xE9es \xE0 la longueur maximale rencontr\xE9e dans les \xE9tiquettes. Et, comme mentionn\xE9 pr\xE9c\xE9demment, la valeur de remplissage utilis\xE9e pour remplir les \xE9tiquettes doit \xEAtre "),Jl=r("code"),Dp=n("-100"),Tp=n(" et non le "),Yl=r("em"),Sp=n("token"),Ap=n(" de "),Zl=r("em"),Mp=n("padding"),Np=n(" du "),eo=r("em"),Lp=n("tokenizer"),Op=n(" afin de s\u2019assurer que ces valeurs soient ignor\xE9es dans le calcul de la perte."),pi=d(),is=r("p"),Up=n("Tout ceci est r\xE9alis\xE9 par un "),Qa=r("a"),so=r("code"),Fp=n("DataCollatorForSeq2Seq"),Hp=n(". Comme le "),to=r("code"),Ip=n("DataCollatorWithPadding"),Bp=n(", il prend le "),no=r("code"),Rp=n("tokenizer"),Kp=n(" utilis\xE9 pour pr\xE9traiter les entr\xE9es, mais \xE9galement le "),ao=r("code"),Vp=n("model"),Gp=n(". C\u2019est parce que ce collateur de donn\xE9es est \xE9galement responsable de la pr\xE9paration des identifiants d\u2019entr\xE9e du d\xE9codeur, qui sont des versions d\xE9cal\xE9es des \xE9tiquettes avec un "),ro=r("em"),Xp=n("token"),Wp=n(" sp\xE9cial au d\xE9but. Comme ce d\xE9calage est effectu\xE9 de mani\xE8re l\xE9g\xE8rement diff\xE9rente selon les architectures, le "),lo=r("code"),Qp=n("DataCollatorForSeq2Seq"),Jp=n(" a besoin de conna\xEEtre l\u2019objet "),oo=r("code"),Yp=n("model"),Zp=n(" :"),di=d(),kn.c(),sl=d(),tl=r("p"),ed=n("Pour le tester sur quelques \xE9chantillons, nous l\u2019appelons simplement sur une liste d\u2019exemples de notre \xE9chantillon d\u2019entrainement tok\xE9nis\xE9 :"),ci=d(),E(Ja.$$.fragment),mi=d(),E(Ya.$$.fragment),fi=d(),va=r("p"),sd=n("Nous pouvons v\xE9rifier que nos \xE9tiquettes ont \xE9t\xE9 rembourr\xE9es \xE0 la longueur maximale du batch, en utilisant "),io=r("code"),td=n("-100"),nd=n(" :"),_i=d(),E(Za.$$.fragment),hi=d(),E(er.$$.fragment),vi=d(),nl=r("p"),ad=n("Nous pouvons aussi jeter un coup d\u2019\u0153il aux identifiants d\u2019entr\xE9e du d\xE9codeur, pour voir qu\u2019il s\u2019agit de versions d\xE9cal\xE9es des \xE9tiquettes :"),bi=d(),E(sr.$$.fragment),$i=d(),E(tr.$$.fragment),gi=d(),al=r("p"),rd=n("Voici les \xE9tiquettes des premier et deuxi\xE8me \xE9l\xE9ments de notre jeu de donn\xE9es :"),qi=d(),E(nr.$$.fragment),Ei=d(),E(ar.$$.fragment),ji=d(),wn.c(),rl=d(),sa=r("h3"),ba=r("a"),uo=r("span"),E(rr.$$.fragment),ld=d(),po=r("span"),od=n("M\xE9triques"),ki=d(),E(lr.$$.fragment),xi=d(),ut&&ut.c(),ll=d(),Rn=r("p"),id=n("La m\xE9trique traditionnelle utilis\xE9e pour la traduction est le "),or=r("a"),ud=n("score BLEU"),pd=n(", introduit dans "),ir=r("a"),dd=n("un article de 2002"),cd=n(" par Kishore Papineni et al. Le score BLEU \xE9value dans quelle mesure les traductions sont proches de leurs \xE9tiquettes. Il ne mesure pas l\u2019intelligibilit\xE9 ou l\u2019exactitude grammaticale des r\xE9sultats g\xE9n\xE9r\xE9s par le mod\xE8le, mais utilise des r\xE8gles statistiques pour garantir que tous les mots des r\xE9sultats g\xE9n\xE9r\xE9s apparaissent \xE9galement dans les cibles. En outre, il existe des r\xE8gles qui p\xE9nalisent les r\xE9p\xE9titions des m\xEAmes mots s\u2019ils ne sont pas \xE9galement r\xE9p\xE9t\xE9s dans les cibles (pour \xE9viter que le mod\xE8le ne produise des phrases telles que \xAB the the the the the the the \xBB) et les phrases produites qui sont plus courtes que celles des cibles (pour \xE9viter que le mod\xE8le ne produise des phrases telles que \xAB the \xBB)."),wi=d(),mn=r("p"),md=n("L\u2019une des faiblesses de BLEU est qu\u2019il s\u2019attend \xE0 ce que le texte soit d\xE9j\xE0 tokenis\xE9, ce qui rend difficile la comparaison des scores entre les mod\xE8les qui utilisent diff\xE9rents "),co=r("em"),fd=n("tokenizers"),_d=n(". Par cons\xE9quent, la mesure la plus couramment utilis\xE9e aujourd\u2019hui pour \xE9valuer les mod\xE8les de traduction est "),ur=r("a"),hd=n("SacreBLEU"),vd=n(" qui rem\xE9die \xE0 cette faiblesse (et \xE0 d\u2019autres) en standardisant l\u2019\xE9tape de tokenisation. Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que "),mo=r("em"),bd=n("SacreBLEU"),$d=n(" :"),zi=d(),E(pr.$$.fragment),yi=d(),Kn=r("p"),gd=n("Nous pouvons ensuite charger ce score via "),fo=r("code"),qd=n("load_metric()"),Ed=n(" comme nous l\u2019avons fait dans le "),ol=r("a"),jd=n("chapitre 3"),kd=n(" :"),Pi=d(),E(dr.$$.fragment),Ci=d(),il=r("p"),xd=n("Cette m\xE9trique prend des textes comme entr\xE9es et cibles. Elle est con\xE7ue pour accepter plusieurs cibles acceptables car il y a souvent plusieurs traductions possibles d\u2019une m\xEAme phrase. Le jeu de donn\xE9es que nous utilisons n\u2019en fournit qu\u2019une seule, mais en NLP, il n\u2019est pas rare de trouver des jeux de donn\xE9es ayant plusieurs phrases comme \xE9tiquettes. Ainsi, les pr\xE9dictions doivent \xEAtre une liste de phrases mais les r\xE9f\xE9rences doivent \xEAtre une liste de listes de phrases."),Di=d(),ul=r("p"),wd=n("Essayons un exemple :"),Ti=d(),E(cr.$$.fragment),Si=d(),E(mr.$$.fragment),Ai=d(),Ks=r("p"),zd=n("Cela donne un score BLEU de 46.75, ce qui est plut\xF4t bon. A titre de comparaison, le "),_o=r("em"),yd=n("Transformer"),Pd=n(" original dans l\u2019article "),fr=r("a"),ho=r("em"),Cd=n("Attention Is All You Need"),Dd=n(" a obtenu un score BLEU de 41.8 sur une t\xE2che de traduction similaire entre l\u2019anglais et le fran\xE7ais ! (Pour plus d\u2019informations sur les m\xE9triques individuelles, comme "),vo=r("code"),Td=n("counts"),Sd=n(" et "),bo=r("code"),Ad=n("bp"),Md=n(", voir le "),_r=r("a"),Nd=n("d\xE9p\xF4t SacreBLEU"),Ld=n(". D\u2019autre part, si nous essayons avec les deux mauvais types de pr\xE9dictions (r\xE9p\xE9titions ou pr\xE9diction trop courte) qui sortent souvent des mod\xE8les de traduction, nous obtiendrons des scores BLEU plut\xF4t mauvais :"),Mi=d(),E(hr.$$.fragment),Ni=d(),E(vr.$$.fragment),Li=d(),E(br.$$.fragment),Oi=d(),E($r.$$.fragment),Ui=d(),pl=r("p"),Od=n("Le score peut aller de 0 \xE0 100. Plus il est \xE9lev\xE9, mieux c\u2019est."),Fi=d(),yn.c(),dl=d(),$a=r("p"),Ud=n("Maintenant que c\u2019est fait, nous sommes pr\xEAts \xE0 "),$o=r("em"),Fd=n("finetuner"),Hd=n(" notre mod\xE8le !"),Hi=d(),ta=r("h3"),ga=r("a"),go=r("span"),E(gr.$$.fragment),Id=d(),cl=r("span"),qo=r("i"),Bd=n("Finetuner"),Rd=n(" le mod\xE8le"),Ii=d(),Vn=r("p"),Kd=n("La premi\xE8re \xE9tape consiste \xE0 se connecter \xE0 Hugging Face, afin de pouvoir t\xE9l\xE9charger vos r\xE9sultats sur le "),Eo=r("em"),Vd=n("Hub"),Gd=n(". Il y a une fonction pratique pour vous aider \xE0 le faire dans un "),jo=r("em"),Xd=n("notebook"),Wd=n(" :"),Bi=d(),E(qr.$$.fragment),Ri=d(),qa=r("p"),Qd=n("Cela affichera un "),ko=r("em"),Jd=n("widget"),Yd=n(" o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),Ki=d(),Ea=r("p"),Zd=n("Si vous ne travaillez pas dans un "),xo=r("em"),ec=n("notebook"),sc=n(", tapez simplement la ligne suivante dans votre terminal :"),Vi=d(),E(Er.$$.fragment),Gi=d(),Cn.c(),ml=d(),$s&&$s.c(),fl=d(),na=r("h3"),ja=r("a"),wo=r("span"),E(jr.$$.fragment),tc=d(),_l=r("span"),nc=n("Utilisation du mod\xE8le "),zo=r("i"),ac=n("finetun\xE9"),Xi=d(),jt=r("p"),rc=n("Nous vous avons d\xE9j\xE0 montr\xE9 comment vous pouvez utiliser le mod\xE8le que nous avons "),yo=r("em"),lc=n("finetun\xE9"),oc=n(" sur le "),Po=r("em"),ic=n("Hub"),uc=n(" avec le "),Co=r("em"),pc=n("widget"),dc=n(" d\u2019inf\xE9rence. Pour l\u2019utiliser localement dans un "),Do=r("code"),cc=n("pipeline"),mc=n(", nous devons juste sp\xE9cifier l\u2019identifiant de mod\xE8le appropri\xE9 :"),Wi=d(),E(kr.$$.fragment),Qi=d(),E(xr.$$.fragment),Ji=d(),fn=r("p"),fc=n("Comme pr\xE9vu, notre mod\xE8le pr\xE9-entra\xEEn\xE9 a adapt\xE9 ses connaissances au corpus sur lequel nous l\u2019avons "),To=r("em"),_c=n("finetun\xE9"),hc=n(". Et au lieu de laisser le mot anglais \xAB "),So=r("em"),vc=n("threads"),bc=n(" \xBB, le mod\xE8le le traduit maintenant par la version fran\xE7aise officielle. Il en va de m\xEAme pour \xAB "),Ao=r("em"),$c=n("plugin"),gc=n(" \xBB :"),Yi=d(),E(wr.$$.fragment),Zi=d(),E(zr.$$.fragment),eu=d(),hl=r("p"),qc=n("Un autre excellent exemple d\u2019adaptation au domaine !"),su=d(),E(ka.$$.fragment),this.h()},l(e){const p=l_('[data-svelte="svelte-1phssyn"]',document.head);u=l(p,"META",{name:!0,content:!0}),p.forEach(t),q=c(e),j(_.$$.fragment,e),w=c(e),A=l(e,"H1",{class:!0});var Ar=o(A);v=l(Ar,"A",{id:!0,class:!0,href:!0});var vl=o(v);T=l(vl,"SPAN",{});var Mo=o(T);j(S.$$.fragment,Mo),Mo.forEach(t),vl.forEach(t),z=c(Ar),C=l(Ar,"SPAN",{});var No=o(C);F=a(No,"Traduction"),No.forEach(t),Ar.forEach(t),D=c(e),R.l(e),H=c(e),L=l(e,"P",{});var aa=o(L);Y=a(aa,"Plongeons maintenant dans la traduction. Il s\u2019agit d\u2019une autre "),O=l(aa,"A",{href:!0});var Lo=o(O);V=a(Lo,"t\xE2che de s\xE9quence \xE0 s\xE9quence"),Lo.forEach(t),W=a(aa,", ce qui signifie que c\u2019est un probl\xE8me qui peut \xEAtre formul\xE9 comme le passage d\u2019une s\xE9quence \xE0 une autre. En ce sens, le probl\xE8me est assez proche de la t\xE2che de "),M=l(aa,"A",{href:!0});var bl=o(M);P=a(bl,"r\xE9sum\xE9"),bl.forEach(t),se=a(aa," et vous pouvez adapter ce que nous allons voir ici \xE0 d\u2019autres probl\xE8mes de s\xE9quence \xE0 s\xE9quence tels que :"),aa.forEach(t),N=c(e),I=l(e,"UL",{});var xa=o(I);Q=l(xa,"LI",{});var Gn=o(Q);ee=a(Gn,"Le "),X=l(Gn,"STRONG",{});var $l=o(X);ie=a($l,"transfert de style"),$l.forEach(t),re=a(Gn," ? c\u2019est-\xE0-dire cr\xE9er un mod\xE8le qui "),te=l(Gn,"EM",{});var gl=o(te);me=a(gl,"traduit"),gl.forEach(t),le=a(Gn," des textes \xE9crits dans un certain style vers un autre (par exemple, du formel au d\xE9contract\xE9 ou de l\u2019anglais shakespearien \xE0 l\u2019anglais moderne)."),Gn.forEach(t),de=c(xa),ue=l(xa,"LI",{});var Mr=o(ue);ve=a(Mr,"La "),be=l(Mr,"STRONG",{});var Nc=o(be);$e=a(Nc,"g\xE9n\xE9ration de r\xE9ponse \xE0 des questions"),Nc.forEach(t),_e=a(Mr," c\u2019est-\xE0-dire cr\xE9er un mod\xE8le qui g\xE9n\xE8re des r\xE9ponses \xE0 des questions compte tenu d\u2019un contexte."),Mr.forEach(t),xa.forEach(t),J=c(e),j(pe.$$.fragment,e),ce=c(e),G=l(e,"P",{});var ql=o(G);Ae=a(ql,"Si vous disposez d\u2019un corpus de textes suffisamment important en deux langues diff\xE9rentes (ou plus), vous pouvez entra\xEEner un nouveau mod\xE8le de traduction \xE0 partir de z\xE9ro, comme nous le ferons dans la section sur la "),ge=l(ql,"A",{href:!0});var Lc=o(ge);Qe=a(Lc,"mod\xE9lisation causale du langage"),Lc.forEach(t),qe=a(ql,". Il est toutefois plus rapide de "),fe=l(ql,"EM",{});var Oc=o(fe);Me=a(Oc,"finetuner"),Oc.forEach(t),ne=a(ql," un mod\xE8le de traduction existant, qu\u2019il s\u2019agisse d\u2019un mod\xE8le multilingue comme mT5 ou mBART que vous souhaitez adapter \xE0 une paire de langues sp\xE9cifique, ou m\xEAme d\u2019un mod\xE8le sp\xE9cialis\xE9 dans la traduction d\u2019une langue vers une autre que vous souhaitez adapter \xE0 votre corpus sp\xE9cifique."),ql.forEach(t),Oe=c(e),ae=l(e,"P",{});var _n=o(ae);ze=a(_n,"Dans cette section, nous allons "),ye=l(_n,"EM",{});var Uc=o(ye);De=a(Uc,"finetuner"),Uc.forEach(t),us=a(_n," un mod\xE8le Marian pr\xE9-entra\xEEn\xE9 pour traduire de l\u2019anglais au fran\xE7ais (puisque de nombreux employ\xE9s de Hugging Face parlent ces deux langues) sur le jeu de donn\xE9es "),Ue=l(_n,"A",{href:!0,rel:!0});var Fc=o(Ue);es=a(Fc,"KDE4"),Fc.forEach(t),ps=a(_n," qui est un jeu de donn\xE9es de fichiers localis\xE9s pour les applications "),ss=l(_n,"A",{href:!0,rel:!0});var Hc=o(ss);Pe=a(Hc,"KDE"),Hc.forEach(t),Fe=a(_n,". Le mod\xE8le que nous utiliserons a \xE9t\xE9 pr\xE9-entra\xEEn\xE9 sur un large corpus de textes fran\xE7ais et anglais provenant du jeu de donn\xE9es "),He=l(_n,"A",{href:!0,rel:!0});var Ic=o(He);Ee=a(Ic,"Opus"),Ic.forEach(t),Xs=a(_n," qui contient en fait le jeu de donn\xE9es KDE4. A noter que m\xEAme si le mod\xE8le pr\xE9-entra\xEEn\xE9 que nous utilisons a vu ces donn\xE9es pendant son pr\xE9-entra\xEEnement, nous verrons que nous pouvons obtenir une meilleure version de ce mod\xE8le apr\xE8s un "),Ie=l(_n,"EM",{});var Bc=o(Ie);Ws=a(Bc,"finetuning"),Bc.forEach(t),Qs=a(_n,"."),_n.forEach(t),Je=c(e),Re=l(e,"P",{});var Rc=o(Re);As=a(Rc,"Une fois que nous aurons termin\xE9, nous aurons un mod\xE8le capable de faire des pr\xE9dictions comme celle-ci :"),Rc.forEach(t),Ne=c(e),g=l(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),o(g).forEach(t),gs=c(e),je=l(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),o(je).forEach(t),he=c(e),Ke=l(e,"A",{class:!0,href:!0});var nu=o(Ke);Le=l(nu,"IMG",{class:!0,src:!0,alt:!0}),xe=c(nu),ts=l(nu,"IMG",{class:!0,src:!0,alt:!0}),nu.forEach(t),qs=c(e),Ye=l(e,"P",{});var au=o(Ye);Js=a(au,"Comme dans les sections pr\xE9c\xE9dentes, vous pouvez trouver, t\xE9l\xE9charger et v\xE9rifier les pr\xE9cisions de ce mod\xE8le sur le "),Ve=l(au,"A",{href:!0,rel:!0});var Kc=o(Ve);ds=l(Kc,"EM",{});var Vc=o(ds);Te=a(Vc,"Hub"),Vc.forEach(t),Kc.forEach(t),ct=a(au,"."),au.forEach(t),cs=c(e),ns=l(e,"H2",{class:!0});var ru=o(ns);Ms=l(ru,"A",{id:!0,class:!0,href:!0});var Gc=o(Ms);Ys=l(Gc,"SPAN",{});var Xc=o(Ys);j(Ge.$$.fragment,Xc),Xc.forEach(t),Gc.forEach(t),Vt=c(ru),Es=l(ru,"SPAN",{});var Wc=o(Es);Ns=a(Wc,"Pr\xE9paration des donn\xE9es"),Wc.forEach(t),ru.forEach(t),Ls=c(e),Ce=l(e,"P",{});var Xn=o(Ce);kt=a(Xn,"Pour "),as=l(Xn,"EM",{});var Qc=o(as);Gt=a(Qc,"finetuner"),Qc.forEach(t),ms=a(Xn," ou entra\xEEner un mod\xE8le de traduction \xE0 partir de z\xE9ro, nous avons besoin d\u2019un jeu de donn\xE9es adapt\xE9 \xE0 cette t\xE2che. Comme mentionn\xE9 pr\xE9c\xE9demment, nous utiliserons le jeu de donn\xE9es "),ke=l(Xn,"A",{href:!0,rel:!0});var Jc=o(ke);xt=a(Jc,"KDE4"),Jc.forEach(t),wt=a(Xn," dans cette section. Notez que vous pouvez adapter assez facilement le code pour utiliser vos propres donn\xE9es du moment que vous disposez de paires de phrases dans les deux langues que vous voulez traduire. Reportez-vous au "),mt=l(Xn,"A",{href:!0});var Yc=o(mt);zt=a(Yc,"chapitre 5"),Yc.forEach(t),yt=a(Xn," si vous avez besoin d\u2019un rappel sur la fa\xE7on de charger vos donn\xE9es personnalis\xE9es dans un "),Pt=l(Xn,"CODE",{});var Zc=o(Pt);Xt=a(Zc,"Dataset"),Zc.forEach(t),fs=a(Xn,"."),Xn.forEach(t),xs=c(e),_s=l(e,"H3",{class:!0});var lu=o(_s);Xe=l(lu,"A",{id:!0,class:!0,href:!0});var em=o(Xe);Ct=l(em,"SPAN",{});var sm=o(Ct);j(ws.$$.fragment,sm),sm.forEach(t),em.forEach(t),Dt=c(lu),ft=l(lu,"SPAN",{});var tm=o(ft);js=a(tm,"Le jeu de donn\xE9es KDE4"),tm.forEach(t),lu.forEach(t),Tt=c(e),We=l(e,"P",{});var ou=o(We);Wt=a(ou,"Comme d\u2019habitude, nous t\xE9l\xE9chargeons notre jeu de donn\xE9es en utilisant la fonction "),Os=l(ou,"CODE",{});var nm=o(Os);St=a(nm,"load_dataset()"),nm.forEach(t),Qt=a(ou," :"),ou.forEach(t),Us=c(e),j(zs.$$.fragment,e),Se=c(e),ys=l(e,"P",{});var iu=o(ys);rs=a(iu,"Si vous souhaitez travailler avec une autre paire de langues, 92 langues sont disponibles au total pour ce jeu de donn\xE9es. Vous pouvez les voir dans la "),Zs=l(iu,"A",{href:!0,rel:!0});var am=o(Zs);_t=a(am,"carte du jeu de donn\xE9es"),am.forEach(t),At=a(iu,"."),iu.forEach(t),Jt=c(e),hs=l(e,"IMG",{src:!0,alt:!0,width:!0}),Zt=c(e),et=l(e,"P",{});var rm=o(et);vs=a(rm,"Jetons un coup d\u2019\u0153il au jeu de donn\xE9es :"),rm.forEach(t),Ps=c(e),j(Cs.$$.fragment,e),ht=c(e),j(st.$$.fragment,e),vt=c(e),Ze=l(e,"P",{});var wa=o(Ze);f=a(wa,"Nous avons 210 173 paires de phrases. Cependant regroup\xE9es dans un seul \xE9chantillon. Nous devrons donc cr\xE9er notre propre jeu de validation. Comme nous l\u2019avons vu dans le "),B=l(wa,"A",{href:!0});var lm=o(B);bs=a(lm,"chapitre 5"),lm.forEach(t),Dn=a(wa,", un "),tt=l(wa,"CODE",{});var om=o(tt);en=a(om,"Dataset"),om.forEach(t),Fs=a(wa," poss\xE8de une m\xE9thode "),sn=l(wa,"CODE",{});var im=o(sn);bt=a(im,"train_test_split()"),im.forEach(t),Tn=a(wa," qui peut nous aider. Nous allons fournir une graine pour la reproductibilit\xE9 :"),wa.forEach(t),Mt=c(e),j(Hs.$$.fragment,e),nt=c(e),j($t.$$.fragment,e),tn=c(e),we=l(e,"P",{});var um=o(we);vn=a(um,"Nous pouvons renommer la cl\xE9 \u201Ctest\u201D en \u201Cvalidation\u201D comme ceci :"),um.forEach(t),at=c(e),j(rt.$$.fragment,e),ks=c(e),Nt=l(e,"P",{});var pm=o(Nt);nn=a(pm,"Examinons maintenant un \xE9l\xE9ment de ce jeu de donn\xE9es :"),pm.forEach(t),Lt=c(e),j(gt.$$.fragment,e),Ds=c(e),j(Is.$$.fragment,e),bn=c(e),lt=l(e,"P",{});var uu=o(lt);Ot=a(uu,`Nous obtenons un dictionnaire contenant deux phrases dans la paire de langues qui nous int\xE9resse.
Une particularit\xE9 de ce jeu de donn\xE9es rempli de termes techniques informatiques est qu\u2019ils sont tous enti\xE8rement traduits en fran\xE7ais. Cependant, les ing\xE9nieurs fran\xE7ais sont souvent paresseux et laissent la plupart des mots sp\xE9cifiques \xE0 l\u2019informatique en anglais lorsqu\u2019ils parlent. Ici, par exemple, le mot \xAB `),m=l(uu,"EM",{});var dm=o(m);K=a(dm,"threads"),dm.forEach(t),Jn=a(uu," \xBB pourrait tr\xE8s bien appara\xEEtre dans une phrase fran\xE7aise, surtout dans une conversation technique. Mais dans ce jeu de donn\xE9es, il a \xE9t\xE9 traduit en \xAB fils de discussion \xBB. Le mod\xE8le pr\xE9-entra\xEEn\xE9 que nous utilisons (qui a \xE9t\xE9 pr\xE9-entra\xEEn\xE9 sur un plus grand corpus de phrases fran\xE7aises et anglaises) prend l\u2019option de laisser le mot tel quel :"),uu.forEach(t),ls=c(e),j(Ut.$$.fragment,e),qt=c(e),j(Ft.$$.fragment,e),Sn=c(e),Bs=l(e,"P",{});var pu=o(Bs);Yn=a(pu,"Un autre exemple de ce comportement peut \xEAtre observ\xE9 avec le mot  \xAB "),Ts=l(pu,"EM",{});var cm=o(Ts);Zn=a(cm,"plugin"),cm.forEach(t),Ht=a(pu,` \xBB qui n\u2019est pas officiellement un mot fran\xE7ais mais que la plupart des francophones comprendront et ne prendront pas la peine de traduire.
Dans le jeu de donn\xE9es KDE4, ce mot a \xE9t\xE9 traduit en fran\xE7ais par le plus officiel \xAB module d\u2019extension \xBB :`),pu.forEach(t),An=c(e),j(ot.$$.fragment,e),an=c(e),j(Mn.$$.fragment,e),Sa=c(e),it=l(e,"P",{});var mm=o(it);Or=a(mm,"Notre mod\xE8le pr\xE9-entra\xEEn\xE9, lui, s\u2019en tient au mot anglais :"),mm.forEach(t),Aa=c(e),j(Nn.$$.fragment,e),It=c(e),j(Ln.$$.fragment,e),Ma=c(e),Bt=l(e,"P",{});var El=o(Bt);Rs=a(El,"Il sera int\xE9ressant de voir si notre mod\xE8le "),ra=l(El,"EM",{});var fm=o(ra);Ur=a(fm,"finetun\xE9"),fm.forEach(t),Fr=a(El," tient compte de ces particularit\xE9s (alerte "),la=l(El,"EM",{});var _m=o(la);Hr=a(_m,"spoiler"),_m.forEach(t),Ir=a(El," : il le fera)."),El.forEach(t),$n=c(e),j(On.$$.fragment,e),Na=c(e),j(Rt.$$.fragment,e),La=c(e),rn=l(e,"H3",{class:!0});var du=o(rn);gn=l(du,"A",{id:!0,class:!0,href:!0});var hm=o(gn);ln=l(hm,"SPAN",{});var vm=o(ln);j(Un.$$.fragment,vm),vm.forEach(t),hm.forEach(t),Br=c(du),on=l(du,"SPAN",{});var bm=o(on);Rr=a(bm,"Traitement des donn\xE9es"),bm.forEach(t),du.forEach(t),Oa=c(e),j(Et.$$.fragment,e),Ua=c(e),Ss=l(e,"P",{});var Wn=o(Ss);un=a(Wn,"Vous devriez maintenant conna\xEEtre le principe : les textes doivent tous \xEAtre convertis en ensembles d\u2019ID de "),oa=l(Wn,"EM",{});var $m=o(oa);Kr=a($m,"tokens"),$m.forEach(t),Vr=a(Wn," pour que le mod\xE8le puisse leur donner un sens. Pour cette t\xE2che, nous aurons besoin de tokeniser les entr\xE9es et les cibles. Notre premi\xE8re t\xE2che est de cr\xE9er notre objet "),ia=l(Wn,"CODE",{});var gm=o(ia);Fn=a(gm,"tokenizer"),gm.forEach(t),Gr=a(Wn,". Comme indiqu\xE9 pr\xE9c\xE9demment, nous utiliserons un mod\xE8le pr\xE9-entra\xEEn\xE9 Marian English to French. Si vous essayez ce code avec une autre paire de langues, assurez-vous d\u2019adapter le "),ua=l(Wn,"EM",{});var qm=o(ua);Xr=a(qm,"checkpoint"),qm.forEach(t),ku=a(Wn," du mod\xE8le. L\u2019organisation "),Fa=l(Wn,"A",{href:!0,rel:!0});var Em=o(Fa);xu=a(Em,"Helsinki-NLP"),Em.forEach(t),wu=a(Wn," fournit plus de mille mod\xE8les dans plusieurs langues."),Wn.forEach(t),Uo=c(e),j(Ha.$$.fragment,e),Fo=c(e),pn=l(e,"P",{});var za=o(pn);zu=a(za,"Vous pouvez remplacer le "),Pl=l(za,"CODE",{});var jm=o(Pl);yu=a(jm,"model_checkpoint"),jm.forEach(t),Pu=a(za," par un tout autre mod\xE8le disponible sur le "),Ia=l(za,"A",{href:!0,rel:!0});var km=o(Ia);Cl=l(km,"EM",{});var xm=o(Cl);Cu=a(xm,"Hub"),xm.forEach(t),km.forEach(t),Du=a(za," qui aurait votre pr\xE9f\xE9rence, ou par un dossier en local o\xF9 vous avez sauvegard\xE9 un mod\xE8le pr\xE9-entra\xEEn\xE9 et un "),Dl=l(za,"EM",{});var wm=o(Dl);Tu=a(wm,"tokenizer"),wm.forEach(t),Su=a(za,"."),za.forEach(t),Ho=c(e),j(pa.$$.fragment,e),Io=c(e),Hn=l(e,"P",{});var jl=o(Hn);Au=a(jl,"La pr\xE9paration de nos donn\xE9es est assez simple. Il y a juste une chose \xE0 retenir : vous traitez les entr\xE9es comme d\u2019habitude, mais pour les cibles, vous devez envelopper le "),Tl=l(jl,"EM",{});var zm=o(Tl);Mu=a(zm,"tokenizer"),zm.forEach(t),Nu=a(jl," dans le gestionnaire de contexte "),Sl=l(jl,"CODE",{});var ym=o(Sl);Lu=a(ym,"as_target_tokenizer()"),ym.forEach(t),Ou=a(jl,"."),jl.forEach(t),Bo=c(e),da=l(e,"P",{});var cu=o(da);Uu=a(cu,"Un gestionnaire de contexte en Python est introduit avec l\u2019instruction "),Al=l(cu,"CODE",{});var Pm=o(Al);Fu=a(Pm,"with"),Pm.forEach(t),Hu=a(cu," et est utile lorsque vous avez deux op\xE9rations li\xE9es \xE0 ex\xE9cuter en paire. L\u2019exemple le plus courant est lorsque vous \xE9crivez ou lisez un fichier, ce qui est souvent fait dans une instruction comme :"),cu.forEach(t),Ro=c(e),j(Ba.$$.fragment,e),Ko=c(e),In=l(e,"P",{});var kl=o(In);Iu=a(kl,"Ici, les deux op\xE9rations connexes qui sont ex\xE9cut\xE9es en paire sont les actions d\u2019ouverture et de fermeture du fichier. L\u2019objet correspondant au fichier ouvert "),Ml=l(kl,"CODE",{});var Cm=o(Ml);Bu=a(Cm,"f"),Cm.forEach(t),Ru=a(kl," n\u2019existe qu\u2019\xE0 l\u2019int\xE9rieur du bloc indent\xE9 sous le "),Nl=l(kl,"CODE",{});var Dm=o(Nl);Ku=a(Dm,"with"),Dm.forEach(t),Vu=a(kl,". L\u2019ouverture se produit avant ce bloc et la fermeture \xE0 la fin du bloc."),kl.forEach(t),Vo=c(e),Bn=l(e,"P",{});var xl=o(Bn);Gu=a(xl,"Dans le cas pr\xE9sent, le gestionnaire de contexte "),Ll=l(xl,"CODE",{});var Tm=o(Ll);Xu=a(Tm,"as_target_tokenizer()"),Tm.forEach(t),Wu=a(xl," va d\xE9finir le "),Ol=l(xl,"EM",{});var Sm=o(Ol);Qu=a(Sm,"tokenizer"),Sm.forEach(t),Ju=a(xl," dans la langue de sortie (ici, le fran\xE7ais) avant l\u2019ex\xE9cution du bloc indent\xE9, puis le red\xE9finir dans la langue d\u2019entr\xE9e (ici, l\u2019anglais)."),xl.forEach(t),Go=c(e),Wr=l(e,"P",{});var Am=o(Wr);Yu=a(Am,"Ainsi, le pr\xE9traitement d\u2019un \xE9chantillon ressemble \xE0 ceci :"),Am.forEach(t),Xo=c(e),j(Ra.$$.fragment,e),Wo=c(e),ca=l(e,"P",{});var mu=o(ca);Zu=a(mu,"Si nous oublions de tokeniser les cibles dans le gestionnaire de contexte, elles seront tokenis\xE9es par le "),Ul=l(mu,"EM",{});var Mm=o(Ul);ep=a(Mm,"tokenizer"),Mm.forEach(t),sp=a(mu," d\u2019entr\xE9e, ce qui dans le cas d\u2019un mod\xE8le Marian, ne va pas du tout bien se passer :"),mu.forEach(t),Qo=c(e),j(Ka.$$.fragment,e),Jo=c(e),j(Va.$$.fragment,e),Yo=c(e),dn=l(e,"P",{});var ya=o(dn);tp=a(ya,"Comme on peut le voir, utiliser le "),Fl=l(ya,"EM",{});var Nm=o(Fl);np=a(Nm,"tokenizer"),Nm.forEach(t),ap=a(ya," anglais pour pr\xE9traiter une phrase fran\xE7aise donne un batch de "),Hl=l(ya,"EM",{});var Lm=o(Hl);rp=a(Lm,"tokens"),Lm.forEach(t),lp=a(ya," plus important, puisque le "),Il=l(ya,"EM",{});var Om=o(Il);op=a(Om,"tokenizer"),Om.forEach(t),ip=a(ya," ne conna\xEEt aucun mot fran\xE7ais (sauf ceux qui apparaissent aussi en anglais, comme \xAB discussion \xBB)."),ya.forEach(t),Zo=c(e),cn=l(e,"P",{});var Pa=o(cn);up=a(Pa,"Les "),Bl=l(Pa,"CODE",{});var Um=o(Bl);pp=a(Um,"inputs"),Um.forEach(t),dp=a(Pa," et les "),Rl=l(Pa,"CODE",{});var Fm=o(Rl);cp=a(Fm,"targets"),Fm.forEach(t),mp=a(Pa," sont des dictionnaires avec nos cl\xE9s habituelles (identifiants d\u2019entr\xE9e, masque d\u2019attention, etc.). La derni\xE8re \xE9tape est de d\xE9finir une cl\xE9 "),Kl=l(Pa,"CODE",{});var Hm=o(Kl);fp=a(Hm,'"labels"'),Hm.forEach(t),_p=a(Pa," dans les entr\xE9es. Nous faisons cela dans la fonction de pr\xE9traitement que nous allons appliquer sur les jeux de donn\xE9es :"),Pa.forEach(t),ei=c(e),j(Ga.$$.fragment,e),si=c(e),Qr=l(e,"P",{});var Im=o(Qr);hp=a(Im,"Notez que nous avons fix\xE9 des longueurs maximales similaires pour nos entr\xE9es et nos sorties. Comme les textes que nous traitons semblent assez courts, nous utilisons 128."),Im.forEach(t),ti=c(e),j(ma.$$.fragment,e),ni=c(e),j(fa.$$.fragment,e),ai=c(e),Jr=l(e,"P",{});var Bm=o(Jr);vp=a(Bm,"Nous pouvons maintenant appliquer ce pr\xE9traitement en une seule fois sur toutes les \xE9chantillons de notre jeu de donn\xE9es :"),Bm.forEach(t),ri=c(e),j(Xa.$$.fragment,e),li=c(e),_a=l(e,"P",{});var fu=o(_a);bp=a(fu,"Maintenant que les donn\xE9es ont \xE9t\xE9 pr\xE9trait\xE9es, nous sommes pr\xEAts \xE0 "),Vl=l(fu,"EM",{});var Rm=o(Vl);$p=a(Rm,"finetuner"),Rm.forEach(t),gp=a(fu," notre mod\xE8le pr\xE9-entra\xEEn\xE9 !"),fu.forEach(t),oi=c(e),En.l(e),Yr=c(e),Zr=l(e,"P",{});var Km=o(Zr);qp=a(Km,"Notez que cette fois-ci, nous utilisons un mod\xE8le qui a \xE9t\xE9 entra\xEEn\xE9 sur une t\xE2che de traduction et qui peut d\xE9j\xE0 \xEAtre utilis\xE9, donc il n\u2019y a pas d\u2019avertissement concernant les poids manquants ou ceux nouvellement initialis\xE9s."),Km.forEach(t),ii=c(e),ea=l(e,"H3",{class:!0});var _u=o(ea);ha=l(_u,"A",{id:!0,class:!0,href:!0});var Vm=o(ha);Gl=l(Vm,"SPAN",{});var Gm=o(Gl);j(Wa.$$.fragment,Gm),Gm.forEach(t),Vm.forEach(t),Ep=c(_u),Xl=l(_u,"SPAN",{});var Xm=o(Xl);jp=a(Xm,"Collecte des donn\xE9es"),Xm.forEach(t),_u.forEach(t),ui=c(e),os=l(e,"P",{});var Vs=o(os);kp=a(Vs,"Nous aurons besoin d\u2019un assembleur de donn\xE9es pour g\xE9rer le rembourrage pour la mise en batchs dynamique. Ici, nous ne pouvons pas simplement utiliser un "),Wl=l(Vs,"CODE",{});var Wm=o(Wl);xp=a(Wm,"DataCollatorWithPadding"),Wm.forEach(t),wp=a(Vs," comme dans le "),el=l(Vs,"A",{href:!0});var Qm=o(el);zp=a(Qm,"chapitre 3"),Qm.forEach(t),yp=a(Vs," car cela ne rembourre que les entr\xE9es (identifiants d\u2019entr\xE9e, masque d\u2019attention, et "),Ql=l(Vs,"EM",{});var Jm=o(Ql);Pp=a(Jm,"token"),Jm.forEach(t),Cp=a(Vs," de type identifiants). Nos \xE9tiquettes doivent \xE9galement \xEAtre rembourr\xE9es \xE0 la longueur maximale rencontr\xE9e dans les \xE9tiquettes. Et, comme mentionn\xE9 pr\xE9c\xE9demment, la valeur de remplissage utilis\xE9e pour remplir les \xE9tiquettes doit \xEAtre "),Jl=l(Vs,"CODE",{});var Ym=o(Jl);Dp=a(Ym,"-100"),Ym.forEach(t),Tp=a(Vs," et non le "),Yl=l(Vs,"EM",{});var Zm=o(Yl);Sp=a(Zm,"token"),Zm.forEach(t),Ap=a(Vs," de "),Zl=l(Vs,"EM",{});var ef=o(Zl);Mp=a(ef,"padding"),ef.forEach(t),Np=a(Vs," du "),eo=l(Vs,"EM",{});var sf=o(eo);Lp=a(sf,"tokenizer"),sf.forEach(t),Op=a(Vs," afin de s\u2019assurer que ces valeurs soient ignor\xE9es dans le calcul de la perte."),Vs.forEach(t),pi=c(e),is=l(e,"P",{});var Gs=o(is);Up=a(Gs,"Tout ceci est r\xE9alis\xE9 par un "),Qa=l(Gs,"A",{href:!0,rel:!0});var tf=o(Qa);so=l(tf,"CODE",{});var nf=o(so);Fp=a(nf,"DataCollatorForSeq2Seq"),nf.forEach(t),tf.forEach(t),Hp=a(Gs,". Comme le "),to=l(Gs,"CODE",{});var af=o(to);Ip=a(af,"DataCollatorWithPadding"),af.forEach(t),Bp=a(Gs,", il prend le "),no=l(Gs,"CODE",{});var rf=o(no);Rp=a(rf,"tokenizer"),rf.forEach(t),Kp=a(Gs," utilis\xE9 pour pr\xE9traiter les entr\xE9es, mais \xE9galement le "),ao=l(Gs,"CODE",{});var lf=o(ao);Vp=a(lf,"model"),lf.forEach(t),Gp=a(Gs,". C\u2019est parce que ce collateur de donn\xE9es est \xE9galement responsable de la pr\xE9paration des identifiants d\u2019entr\xE9e du d\xE9codeur, qui sont des versions d\xE9cal\xE9es des \xE9tiquettes avec un "),ro=l(Gs,"EM",{});var of=o(ro);Xp=a(of,"token"),of.forEach(t),Wp=a(Gs," sp\xE9cial au d\xE9but. Comme ce d\xE9calage est effectu\xE9 de mani\xE8re l\xE9g\xE8rement diff\xE9rente selon les architectures, le "),lo=l(Gs,"CODE",{});var uf=o(lo);Qp=a(uf,"DataCollatorForSeq2Seq"),uf.forEach(t),Jp=a(Gs," a besoin de conna\xEEtre l\u2019objet "),oo=l(Gs,"CODE",{});var pf=o(oo);Yp=a(pf,"model"),pf.forEach(t),Zp=a(Gs," :"),Gs.forEach(t),di=c(e),kn.l(e),sl=c(e),tl=l(e,"P",{});var df=o(tl);ed=a(df,"Pour le tester sur quelques \xE9chantillons, nous l\u2019appelons simplement sur une liste d\u2019exemples de notre \xE9chantillon d\u2019entrainement tok\xE9nis\xE9 :"),df.forEach(t),ci=c(e),j(Ja.$$.fragment,e),mi=c(e),j(Ya.$$.fragment,e),fi=c(e),va=l(e,"P",{});var hu=o(va);sd=a(hu,"Nous pouvons v\xE9rifier que nos \xE9tiquettes ont \xE9t\xE9 rembourr\xE9es \xE0 la longueur maximale du batch, en utilisant "),io=l(hu,"CODE",{});var cf=o(io);td=a(cf,"-100"),cf.forEach(t),nd=a(hu," :"),hu.forEach(t),_i=c(e),j(Za.$$.fragment,e),hi=c(e),j(er.$$.fragment,e),vi=c(e),nl=l(e,"P",{});var mf=o(nl);ad=a(mf,"Nous pouvons aussi jeter un coup d\u2019\u0153il aux identifiants d\u2019entr\xE9e du d\xE9codeur, pour voir qu\u2019il s\u2019agit de versions d\xE9cal\xE9es des \xE9tiquettes :"),mf.forEach(t),bi=c(e),j(sr.$$.fragment,e),$i=c(e),j(tr.$$.fragment,e),gi=c(e),al=l(e,"P",{});var ff=o(al);rd=a(ff,"Voici les \xE9tiquettes des premier et deuxi\xE8me \xE9l\xE9ments de notre jeu de donn\xE9es :"),ff.forEach(t),qi=c(e),j(nr.$$.fragment,e),Ei=c(e),j(ar.$$.fragment,e),ji=c(e),wn.l(e),rl=c(e),sa=l(e,"H3",{class:!0});var vu=o(sa);ba=l(vu,"A",{id:!0,class:!0,href:!0});var _f=o(ba);uo=l(_f,"SPAN",{});var hf=o(uo);j(rr.$$.fragment,hf),hf.forEach(t),_f.forEach(t),ld=c(vu),po=l(vu,"SPAN",{});var vf=o(po);od=a(vf,"M\xE9triques"),vf.forEach(t),vu.forEach(t),ki=c(e),j(lr.$$.fragment,e),xi=c(e),ut&&ut.l(e),ll=c(e),Rn=l(e,"P",{});var wl=o(Rn);id=a(wl,"La m\xE9trique traditionnelle utilis\xE9e pour la traduction est le "),or=l(wl,"A",{href:!0,rel:!0});var bf=o(or);ud=a(bf,"score BLEU"),bf.forEach(t),pd=a(wl,", introduit dans "),ir=l(wl,"A",{href:!0,rel:!0});var $f=o(ir);dd=a($f,"un article de 2002"),$f.forEach(t),cd=a(wl," par Kishore Papineni et al. Le score BLEU \xE9value dans quelle mesure les traductions sont proches de leurs \xE9tiquettes. Il ne mesure pas l\u2019intelligibilit\xE9 ou l\u2019exactitude grammaticale des r\xE9sultats g\xE9n\xE9r\xE9s par le mod\xE8le, mais utilise des r\xE8gles statistiques pour garantir que tous les mots des r\xE9sultats g\xE9n\xE9r\xE9s apparaissent \xE9galement dans les cibles. En outre, il existe des r\xE8gles qui p\xE9nalisent les r\xE9p\xE9titions des m\xEAmes mots s\u2019ils ne sont pas \xE9galement r\xE9p\xE9t\xE9s dans les cibles (pour \xE9viter que le mod\xE8le ne produise des phrases telles que \xAB the the the the the the the \xBB) et les phrases produites qui sont plus courtes que celles des cibles (pour \xE9viter que le mod\xE8le ne produise des phrases telles que \xAB the \xBB)."),wl.forEach(t),wi=c(e),mn=l(e,"P",{});var Ca=o(mn);md=a(Ca,"L\u2019une des faiblesses de BLEU est qu\u2019il s\u2019attend \xE0 ce que le texte soit d\xE9j\xE0 tokenis\xE9, ce qui rend difficile la comparaison des scores entre les mod\xE8les qui utilisent diff\xE9rents "),co=l(Ca,"EM",{});var gf=o(co);fd=a(gf,"tokenizers"),gf.forEach(t),_d=a(Ca,". Par cons\xE9quent, la mesure la plus couramment utilis\xE9e aujourd\u2019hui pour \xE9valuer les mod\xE8les de traduction est "),ur=l(Ca,"A",{href:!0,rel:!0});var qf=o(ur);hd=a(qf,"SacreBLEU"),qf.forEach(t),vd=a(Ca," qui rem\xE9die \xE0 cette faiblesse (et \xE0 d\u2019autres) en standardisant l\u2019\xE9tape de tokenisation. Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que "),mo=l(Ca,"EM",{});var Ef=o(mo);bd=a(Ef,"SacreBLEU"),Ef.forEach(t),$d=a(Ca," :"),Ca.forEach(t),zi=c(e),j(pr.$$.fragment,e),yi=c(e),Kn=l(e,"P",{});var zl=o(Kn);gd=a(zl,"Nous pouvons ensuite charger ce score via "),fo=l(zl,"CODE",{});var jf=o(fo);qd=a(jf,"load_metric()"),jf.forEach(t),Ed=a(zl," comme nous l\u2019avons fait dans le "),ol=l(zl,"A",{href:!0});var kf=o(ol);jd=a(kf,"chapitre 3"),kf.forEach(t),kd=a(zl," :"),zl.forEach(t),Pi=c(e),j(dr.$$.fragment,e),Ci=c(e),il=l(e,"P",{});var xf=o(il);xd=a(xf,"Cette m\xE9trique prend des textes comme entr\xE9es et cibles. Elle est con\xE7ue pour accepter plusieurs cibles acceptables car il y a souvent plusieurs traductions possibles d\u2019une m\xEAme phrase. Le jeu de donn\xE9es que nous utilisons n\u2019en fournit qu\u2019une seule, mais en NLP, il n\u2019est pas rare de trouver des jeux de donn\xE9es ayant plusieurs phrases comme \xE9tiquettes. Ainsi, les pr\xE9dictions doivent \xEAtre une liste de phrases mais les r\xE9f\xE9rences doivent \xEAtre une liste de listes de phrases."),xf.forEach(t),Di=c(e),ul=l(e,"P",{});var wf=o(ul);wd=a(wf,"Essayons un exemple :"),wf.forEach(t),Ti=c(e),j(cr.$$.fragment,e),Si=c(e),j(mr.$$.fragment,e),Ai=c(e),Ks=l(e,"P",{});var hn=o(Ks);zd=a(hn,"Cela donne un score BLEU de 46.75, ce qui est plut\xF4t bon. A titre de comparaison, le "),_o=l(hn,"EM",{});var zf=o(_o);yd=a(zf,"Transformer"),zf.forEach(t),Pd=a(hn," original dans l\u2019article "),fr=l(hn,"A",{href:!0,rel:!0});var yf=o(fr);ho=l(yf,"EM",{});var Pf=o(ho);Cd=a(Pf,"Attention Is All You Need"),Pf.forEach(t),yf.forEach(t),Dd=a(hn," a obtenu un score BLEU de 41.8 sur une t\xE2che de traduction similaire entre l\u2019anglais et le fran\xE7ais ! (Pour plus d\u2019informations sur les m\xE9triques individuelles, comme "),vo=l(hn,"CODE",{});var Cf=o(vo);Td=a(Cf,"counts"),Cf.forEach(t),Sd=a(hn," et "),bo=l(hn,"CODE",{});var Df=o(bo);Ad=a(Df,"bp"),Df.forEach(t),Md=a(hn,", voir le "),_r=l(hn,"A",{href:!0,rel:!0});var Tf=o(_r);Nd=a(Tf,"d\xE9p\xF4t SacreBLEU"),Tf.forEach(t),Ld=a(hn,". D\u2019autre part, si nous essayons avec les deux mauvais types de pr\xE9dictions (r\xE9p\xE9titions ou pr\xE9diction trop courte) qui sortent souvent des mod\xE8les de traduction, nous obtiendrons des scores BLEU plut\xF4t mauvais :"),hn.forEach(t),Mi=c(e),j(hr.$$.fragment,e),Ni=c(e),j(vr.$$.fragment,e),Li=c(e),j(br.$$.fragment,e),Oi=c(e),j($r.$$.fragment,e),Ui=c(e),pl=l(e,"P",{});var Sf=o(pl);Od=a(Sf,"Le score peut aller de 0 \xE0 100. Plus il est \xE9lev\xE9, mieux c\u2019est."),Sf.forEach(t),Fi=c(e),yn.l(e),dl=c(e),$a=l(e,"P",{});var bu=o($a);Ud=a(bu,"Maintenant que c\u2019est fait, nous sommes pr\xEAts \xE0 "),$o=l(bu,"EM",{});var Af=o($o);Fd=a(Af,"finetuner"),Af.forEach(t),Hd=a(bu," notre mod\xE8le !"),bu.forEach(t),Hi=c(e),ta=l(e,"H3",{class:!0});var $u=o(ta);ga=l($u,"A",{id:!0,class:!0,href:!0});var Mf=o(ga);go=l(Mf,"SPAN",{});var Nf=o(go);j(gr.$$.fragment,Nf),Nf.forEach(t),Mf.forEach(t),Id=c($u),cl=l($u,"SPAN",{});var Ec=o(cl);qo=l(Ec,"I",{});var Lf=o(qo);Bd=a(Lf,"Finetuner"),Lf.forEach(t),Rd=a(Ec," le mod\xE8le"),Ec.forEach(t),$u.forEach(t),Ii=c(e),Vn=l(e,"P",{});var yl=o(Vn);Kd=a(yl,"La premi\xE8re \xE9tape consiste \xE0 se connecter \xE0 Hugging Face, afin de pouvoir t\xE9l\xE9charger vos r\xE9sultats sur le "),Eo=l(yl,"EM",{});var Of=o(Eo);Vd=a(Of,"Hub"),Of.forEach(t),Gd=a(yl,". Il y a une fonction pratique pour vous aider \xE0 le faire dans un "),jo=l(yl,"EM",{});var Uf=o(jo);Xd=a(Uf,"notebook"),Uf.forEach(t),Wd=a(yl," :"),yl.forEach(t),Bi=c(e),j(qr.$$.fragment,e),Ri=c(e),qa=l(e,"P",{});var gu=o(qa);Qd=a(gu,"Cela affichera un "),ko=l(gu,"EM",{});var Ff=o(ko);Jd=a(Ff,"widget"),Ff.forEach(t),Yd=a(gu," o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),gu.forEach(t),Ki=c(e),Ea=l(e,"P",{});var qu=o(Ea);Zd=a(qu,"Si vous ne travaillez pas dans un "),xo=l(qu,"EM",{});var Hf=o(xo);ec=a(Hf,"notebook"),Hf.forEach(t),sc=a(qu,", tapez simplement la ligne suivante dans votre terminal :"),qu.forEach(t),Vi=c(e),j(Er.$$.fragment,e),Gi=c(e),Cn.l(e),ml=c(e),$s&&$s.l(e),fl=c(e),na=l(e,"H3",{class:!0});var Eu=o(na);ja=l(Eu,"A",{id:!0,class:!0,href:!0});var If=o(ja);wo=l(If,"SPAN",{});var Bf=o(wo);j(jr.$$.fragment,Bf),Bf.forEach(t),If.forEach(t),tc=c(Eu),_l=l(Eu,"SPAN",{});var jc=o(_l);nc=a(jc,"Utilisation du mod\xE8le "),zo=l(jc,"I",{});var Rf=o(zo);ac=a(Rf,"finetun\xE9"),Rf.forEach(t),jc.forEach(t),Eu.forEach(t),Xi=c(e),jt=l(e,"P",{});var Qn=o(jt);rc=a(Qn,"Nous vous avons d\xE9j\xE0 montr\xE9 comment vous pouvez utiliser le mod\xE8le que nous avons "),yo=l(Qn,"EM",{});var Kf=o(yo);lc=a(Kf,"finetun\xE9"),Kf.forEach(t),oc=a(Qn," sur le "),Po=l(Qn,"EM",{});var Vf=o(Po);ic=a(Vf,"Hub"),Vf.forEach(t),uc=a(Qn," avec le "),Co=l(Qn,"EM",{});var Gf=o(Co);pc=a(Gf,"widget"),Gf.forEach(t),dc=a(Qn," d\u2019inf\xE9rence. Pour l\u2019utiliser localement dans un "),Do=l(Qn,"CODE",{});var Xf=o(Do);cc=a(Xf,"pipeline"),Xf.forEach(t),mc=a(Qn,", nous devons juste sp\xE9cifier l\u2019identifiant de mod\xE8le appropri\xE9 :"),Qn.forEach(t),Wi=c(e),j(kr.$$.fragment,e),Qi=c(e),j(xr.$$.fragment,e),Ji=c(e),fn=l(e,"P",{});var Da=o(fn);fc=a(Da,"Comme pr\xE9vu, notre mod\xE8le pr\xE9-entra\xEEn\xE9 a adapt\xE9 ses connaissances au corpus sur lequel nous l\u2019avons "),To=l(Da,"EM",{});var Wf=o(To);_c=a(Wf,"finetun\xE9"),Wf.forEach(t),hc=a(Da,". Et au lieu de laisser le mot anglais \xAB "),So=l(Da,"EM",{});var Qf=o(So);vc=a(Qf,"threads"),Qf.forEach(t),bc=a(Da," \xBB, le mod\xE8le le traduit maintenant par la version fran\xE7aise officielle. Il en va de m\xEAme pour \xAB "),Ao=l(Da,"EM",{});var Jf=o(Ao);$c=a(Jf,"plugin"),Jf.forEach(t),gc=a(Da," \xBB :"),Da.forEach(t),Yi=c(e),j(wr.$$.fragment,e),Zi=c(e),j(zr.$$.fragment,e),eu=c(e),hl=l(e,"P",{});var Yf=o(hl);qc=a(Yf,"Un autre excellent exemple d\u2019adaptation au domaine !"),Yf.forEach(t),su=c(e),j(ka.$$.fragment,e),this.h()},h(){h(u,"name","hf:doc:metadata"),h(u,"content",JSON.stringify(C_)),h(v,"id","traduction"),h(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(v,"href","#traduction"),h(A,"class","relative group"),h(O,"href","/course/fr/chapitre1/7"),h(M,"href","/course/fr/chapitre7/6"),h(ge,"href","/course/fr/chapitre7/6"),h(Ue,"href","https://huggingface.co/datasets/kde4"),h(Ue,"rel","nofollow"),h(ss,"href","https://apps.kde.org/"),h(ss,"rel","nofollow"),h(He,"href","https://opus.nlpl.eu/"),h(He,"rel","nofollow"),Oo(g.src,oe="https://hf.space/gradioiframe/course-demos/marian-finetuned-kde4-en-to-fr/+")||h(g,"src",oe),h(g,"frameborder","0"),h(g,"height","350"),h(g,"title","Gradio app"),h(g,"class","block dark:hidden container p-0 flex-grow space-iframe"),h(g,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),h(g,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),Oo(je.src,Be="https://hf.space/gradioiframe/course-demos/marian-finetuned-kde4-en-to-fr-darkmode/+")||h(je,"src",Be),h(je,"frameborder","0"),h(je,"height","350"),h(je,"title","Gradio app"),h(je,"class","hidden dark:block container p-0 flex-grow space-iframe"),h(je,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),h(je,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),h(Le,"class","block dark:hidden lg:w-3/5"),Oo(Le.src,pt="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/modeleval-marian-finetuned-kde4-en-to-fr.png")||h(Le,"src",pt),h(Le,"alt","One-hot encoded labels for question answering."),h(ts,"class","hidden dark:block lg:w-3/5"),Oo(ts.src,dt="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/modeleval-marian-finetuned-kde4-en-to-fr-dark.png")||h(ts,"src",dt),h(ts,"alt","One-hot encoded labels for question answering."),h(Ke,"class","flex justify-center"),h(Ke,"href","/huggingface-course/marian-finetuned-kde4-en-to-fr"),h(Ve,"href","https://huggingface.co/huggingface-course/marian-finetuned-kde4-en-to-fr?text=This+plugin+allows+you+to+automatically+translate+web+pages+between+several+languages."),h(Ve,"rel","nofollow"),h(Ms,"id","prparation-des-donnes"),h(Ms,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ms,"href","#prparation-des-donnes"),h(ns,"class","relative group"),h(ke,"href","https://huggingface.co/datasets/kde4"),h(ke,"rel","nofollow"),h(mt,"href","/course/fr/chapter5"),h(Xe,"id","le-jeu-de-donnes-kde4"),h(Xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Xe,"href","#le-jeu-de-donnes-kde4"),h(_s,"class","relative group"),h(Zs,"href","https://huggingface.co/datasets/kde4"),h(Zs,"rel","nofollow"),Oo(hs.src,Yt="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/language_tags.png")||h(hs,"src",Yt),h(hs,"alt","Language available for the KDE4 dataset."),h(hs,"width","100%"),h(B,"href","/course/fr/chapter5"),h(gn,"id","traitement-des-donnes"),h(gn,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(gn,"href","#traitement-des-donnes"),h(rn,"class","relative group"),h(Fa,"href","https://huggingface.co/Helsinki-NLP"),h(Fa,"rel","nofollow"),h(Ia,"href","https://huggingface.co/models"),h(Ia,"rel","nofollow"),h(ha,"id","collecte-des-donnes"),h(ha,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ha,"href","#collecte-des-donnes"),h(ea,"class","relative group"),h(el,"href","/course/fr/chapter3"),h(Qa,"href","https://huggingface.co/transformers/main_classes/data_collator.html#datacollatorforseq2seq"),h(Qa,"rel","nofollow"),h(ba,"id","mtriques"),h(ba,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ba,"href","#mtriques"),h(sa,"class","relative group"),h(or,"href","https://en.wikipedia.org/wiki/BLEU"),h(or,"rel","nofollow"),h(ir,"href","https://aclanthology.org/P02-1040.pdf"),h(ir,"rel","nofollow"),h(ur,"href","https://github.com/mjpost/sacrebleu"),h(ur,"rel","nofollow"),h(ol,"href","/course/fr/chapter3"),h(fr,"href","https://arxiv.org/pdf/1706.03762.pdf"),h(fr,"rel","nofollow"),h(_r,"href","https://github.com/mjpost/sacrebleu/blob/078c440168c6adc89ba75fe6d63f0d922d42bcfe/sacrebleu/metrics/bleu.py#L74"),h(_r,"rel","nofollow"),h(ga,"id","ifinetuneri-le-modle"),h(ga,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ga,"href","#ifinetuneri-le-modle"),h(ta,"class","relative group"),h(ja,"id","utilisation-du-modle-ifinetuni"),h(ja,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(ja,"href","#utilisation-du-modle-ifinetuni"),h(na,"class","relative group")},m(e,p){s(document.head,u),i(e,q,p),k(_,e,p),i(e,w,p),i(e,A,p),s(A,v),s(v,T),k(S,T,null),s(A,z),s(A,C),s(C,F),i(e,D,p),yr[y].m(e,p),i(e,H,p),i(e,L,p),s(L,Y),s(L,O),s(O,V),s(L,W),s(L,M),s(M,P),s(L,se),i(e,N,p),i(e,I,p),s(I,Q),s(Q,ee),s(Q,X),s(X,ie),s(Q,re),s(Q,te),s(te,me),s(Q,le),s(I,de),s(I,ue),s(ue,ve),s(ue,be),s(be,$e),s(ue,_e),i(e,J,p),k(pe,e,p),i(e,ce,p),i(e,G,p),s(G,Ae),s(G,ge),s(ge,Qe),s(G,qe),s(G,fe),s(fe,Me),s(G,ne),i(e,Oe,p),i(e,ae,p),s(ae,ze),s(ae,ye),s(ye,De),s(ae,us),s(ae,Ue),s(Ue,es),s(ae,ps),s(ae,ss),s(ss,Pe),s(ae,Fe),s(ae,He),s(He,Ee),s(ae,Xs),s(ae,Ie),s(Ie,Ws),s(ae,Qs),i(e,Je,p),i(e,Re,p),s(Re,As),i(e,Ne,p),i(e,g,p),i(e,gs,p),i(e,je,p),i(e,he,p),i(e,Ke,p),s(Ke,Le),s(Ke,xe),s(Ke,ts),i(e,qs,p),i(e,Ye,p),s(Ye,Js),s(Ye,Ve),s(Ve,ds),s(ds,Te),s(Ye,ct),i(e,cs,p),i(e,ns,p),s(ns,Ms),s(Ms,Ys),k(Ge,Ys,null),s(ns,Vt),s(ns,Es),s(Es,Ns),i(e,Ls,p),i(e,Ce,p),s(Ce,kt),s(Ce,as),s(as,Gt),s(Ce,ms),s(Ce,ke),s(ke,xt),s(Ce,wt),s(Ce,mt),s(mt,zt),s(Ce,yt),s(Ce,Pt),s(Pt,Xt),s(Ce,fs),i(e,xs,p),i(e,_s,p),s(_s,Xe),s(Xe,Ct),k(ws,Ct,null),s(_s,Dt),s(_s,ft),s(ft,js),i(e,Tt,p),i(e,We,p),s(We,Wt),s(We,Os),s(Os,St),s(We,Qt),i(e,Us,p),k(zs,e,p),i(e,Se,p),i(e,ys,p),s(ys,rs),s(ys,Zs),s(Zs,_t),s(ys,At),i(e,Jt,p),i(e,hs,p),i(e,Zt,p),i(e,et,p),s(et,vs),i(e,Ps,p),k(Cs,e,p),i(e,ht,p),k(st,e,p),i(e,vt,p),i(e,Ze,p),s(Ze,f),s(Ze,B),s(B,bs),s(Ze,Dn),s(Ze,tt),s(tt,en),s(Ze,Fs),s(Ze,sn),s(sn,bt),s(Ze,Tn),i(e,Mt,p),k(Hs,e,p),i(e,nt,p),k($t,e,p),i(e,tn,p),i(e,we,p),s(we,vn),i(e,at,p),k(rt,e,p),i(e,ks,p),i(e,Nt,p),s(Nt,nn),i(e,Lt,p),k(gt,e,p),i(e,Ds,p),k(Is,e,p),i(e,bn,p),i(e,lt,p),s(lt,Ot),s(lt,m),s(m,K),s(lt,Jn),i(e,ls,p),k(Ut,e,p),i(e,qt,p),k(Ft,e,p),i(e,Sn,p),i(e,Bs,p),s(Bs,Yn),s(Bs,Ts),s(Ts,Zn),s(Bs,Ht),i(e,An,p),k(ot,e,p),i(e,an,p),k(Mn,e,p),i(e,Sa,p),i(e,it,p),s(it,Or),i(e,Aa,p),k(Nn,e,p),i(e,It,p),k(Ln,e,p),i(e,Ma,p),i(e,Bt,p),s(Bt,Rs),s(Bt,ra),s(ra,Ur),s(Bt,Fr),s(Bt,la),s(la,Hr),s(Bt,Ir),i(e,$n,p),k(On,e,p),i(e,Na,p),k(Rt,e,p),i(e,La,p),i(e,rn,p),s(rn,gn),s(gn,ln),k(Un,ln,null),s(rn,Br),s(rn,on),s(on,Rr),i(e,Oa,p),k(Et,e,p),i(e,Ua,p),i(e,Ss,p),s(Ss,un),s(Ss,oa),s(oa,Kr),s(Ss,Vr),s(Ss,ia),s(ia,Fn),s(Ss,Gr),s(Ss,ua),s(ua,Xr),s(Ss,ku),s(Ss,Fa),s(Fa,xu),s(Ss,wu),i(e,Uo,p),k(Ha,e,p),i(e,Fo,p),i(e,pn,p),s(pn,zu),s(pn,Pl),s(Pl,yu),s(pn,Pu),s(pn,Ia),s(Ia,Cl),s(Cl,Cu),s(pn,Du),s(pn,Dl),s(Dl,Tu),s(pn,Su),i(e,Ho,p),k(pa,e,p),i(e,Io,p),i(e,Hn,p),s(Hn,Au),s(Hn,Tl),s(Tl,Mu),s(Hn,Nu),s(Hn,Sl),s(Sl,Lu),s(Hn,Ou),i(e,Bo,p),i(e,da,p),s(da,Uu),s(da,Al),s(Al,Fu),s(da,Hu),i(e,Ro,p),k(Ba,e,p),i(e,Ko,p),i(e,In,p),s(In,Iu),s(In,Ml),s(Ml,Bu),s(In,Ru),s(In,Nl),s(Nl,Ku),s(In,Vu),i(e,Vo,p),i(e,Bn,p),s(Bn,Gu),s(Bn,Ll),s(Ll,Xu),s(Bn,Wu),s(Bn,Ol),s(Ol,Qu),s(Bn,Ju),i(e,Go,p),i(e,Wr,p),s(Wr,Yu),i(e,Xo,p),k(Ra,e,p),i(e,Wo,p),i(e,ca,p),s(ca,Zu),s(ca,Ul),s(Ul,ep),s(ca,sp),i(e,Qo,p),k(Ka,e,p),i(e,Jo,p),k(Va,e,p),i(e,Yo,p),i(e,dn,p),s(dn,tp),s(dn,Fl),s(Fl,np),s(dn,ap),s(dn,Hl),s(Hl,rp),s(dn,lp),s(dn,Il),s(Il,op),s(dn,ip),i(e,Zo,p),i(e,cn,p),s(cn,up),s(cn,Bl),s(Bl,pp),s(cn,dp),s(cn,Rl),s(Rl,cp),s(cn,mp),s(cn,Kl),s(Kl,fp),s(cn,_p),i(e,ei,p),k(Ga,e,p),i(e,si,p),i(e,Qr,p),s(Qr,hp),i(e,ti,p),k(ma,e,p),i(e,ni,p),k(fa,e,p),i(e,ai,p),i(e,Jr,p),s(Jr,vp),i(e,ri,p),k(Xa,e,p),i(e,li,p),i(e,_a,p),s(_a,bp),s(_a,Vl),s(Vl,$p),s(_a,gp),i(e,oi,p),Pr[qn].m(e,p),i(e,Yr,p),i(e,Zr,p),s(Zr,qp),i(e,ii,p),i(e,ea,p),s(ea,ha),s(ha,Gl),k(Wa,Gl,null),s(ea,Ep),s(ea,Xl),s(Xl,jp),i(e,ui,p),i(e,os,p),s(os,kp),s(os,Wl),s(Wl,xp),s(os,wp),s(os,el),s(el,zp),s(os,yp),s(os,Ql),s(Ql,Pp),s(os,Cp),s(os,Jl),s(Jl,Dp),s(os,Tp),s(os,Yl),s(Yl,Sp),s(os,Ap),s(os,Zl),s(Zl,Mp),s(os,Np),s(os,eo),s(eo,Lp),s(os,Op),i(e,pi,p),i(e,is,p),s(is,Up),s(is,Qa),s(Qa,so),s(so,Fp),s(is,Hp),s(is,to),s(to,Ip),s(is,Bp),s(is,no),s(no,Rp),s(is,Kp),s(is,ao),s(ao,Vp),s(is,Gp),s(is,ro),s(ro,Xp),s(is,Wp),s(is,lo),s(lo,Qp),s(is,Jp),s(is,oo),s(oo,Yp),s(is,Zp),i(e,di,p),Cr[jn].m(e,p),i(e,sl,p),i(e,tl,p),s(tl,ed),i(e,ci,p),k(Ja,e,p),i(e,mi,p),k(Ya,e,p),i(e,fi,p),i(e,va,p),s(va,sd),s(va,io),s(io,td),s(va,nd),i(e,_i,p),k(Za,e,p),i(e,hi,p),k(er,e,p),i(e,vi,p),i(e,nl,p),s(nl,ad),i(e,bi,p),k(sr,e,p),i(e,$i,p),k(tr,e,p),i(e,gi,p),i(e,al,p),s(al,rd),i(e,qi,p),k(nr,e,p),i(e,Ei,p),k(ar,e,p),i(e,ji,p),Dr[xn].m(e,p),i(e,rl,p),i(e,sa,p),s(sa,ba),s(ba,uo),k(rr,uo,null),s(sa,ld),s(sa,po),s(po,od),i(e,ki,p),k(lr,e,p),i(e,xi,p),ut&&ut.m(e,p),i(e,ll,p),i(e,Rn,p),s(Rn,id),s(Rn,or),s(or,ud),s(Rn,pd),s(Rn,ir),s(ir,dd),s(Rn,cd),i(e,wi,p),i(e,mn,p),s(mn,md),s(mn,co),s(co,fd),s(mn,_d),s(mn,ur),s(ur,hd),s(mn,vd),s(mn,mo),s(mo,bd),s(mn,$d),i(e,zi,p),k(pr,e,p),i(e,yi,p),i(e,Kn,p),s(Kn,gd),s(Kn,fo),s(fo,qd),s(Kn,Ed),s(Kn,ol),s(ol,jd),s(Kn,kd),i(e,Pi,p),k(dr,e,p),i(e,Ci,p),i(e,il,p),s(il,xd),i(e,Di,p),i(e,ul,p),s(ul,wd),i(e,Ti,p),k(cr,e,p),i(e,Si,p),k(mr,e,p),i(e,Ai,p),i(e,Ks,p),s(Ks,zd),s(Ks,_o),s(_o,yd),s(Ks,Pd),s(Ks,fr),s(fr,ho),s(ho,Cd),s(Ks,Dd),s(Ks,vo),s(vo,Td),s(Ks,Sd),s(Ks,bo),s(bo,Ad),s(Ks,Md),s(Ks,_r),s(_r,Nd),s(Ks,Ld),i(e,Mi,p),k(hr,e,p),i(e,Ni,p),k(vr,e,p),i(e,Li,p),k(br,e,p),i(e,Oi,p),k($r,e,p),i(e,Ui,p),i(e,pl,p),s(pl,Od),i(e,Fi,p),Tr[zn].m(e,p),i(e,dl,p),i(e,$a,p),s($a,Ud),s($a,$o),s($o,Fd),s($a,Hd),i(e,Hi,p),i(e,ta,p),s(ta,ga),s(ga,go),k(gr,go,null),s(ta,Id),s(ta,cl),s(cl,qo),s(qo,Bd),s(cl,Rd),i(e,Ii,p),i(e,Vn,p),s(Vn,Kd),s(Vn,Eo),s(Eo,Vd),s(Vn,Gd),s(Vn,jo),s(jo,Xd),s(Vn,Wd),i(e,Bi,p),k(qr,e,p),i(e,Ri,p),i(e,qa,p),s(qa,Qd),s(qa,ko),s(ko,Jd),s(qa,Yd),i(e,Ki,p),i(e,Ea,p),s(Ea,Zd),s(Ea,xo),s(xo,ec),s(Ea,sc),i(e,Vi,p),k(Er,e,p),i(e,Gi,p),Sr[Pn].m(e,p),i(e,ml,p),$s&&$s.m(e,p),i(e,fl,p),i(e,na,p),s(na,ja),s(ja,wo),k(jr,wo,null),s(na,tc),s(na,_l),s(_l,nc),s(_l,zo),s(zo,ac),i(e,Xi,p),i(e,jt,p),s(jt,rc),s(jt,yo),s(yo,lc),s(jt,oc),s(jt,Po),s(Po,ic),s(jt,uc),s(jt,Co),s(Co,pc),s(jt,dc),s(jt,Do),s(Do,cc),s(jt,mc),i(e,Wi,p),k(kr,e,p),i(e,Qi,p),k(xr,e,p),i(e,Ji,p),i(e,fn,p),s(fn,fc),s(fn,To),s(To,_c),s(fn,hc),s(fn,So),s(So,vc),s(fn,bc),s(fn,Ao),s(Ao,$c),s(fn,gc),i(e,Yi,p),k(wr,e,p),i(e,Zi,p),k(zr,e,p),i(e,eu,p),i(e,hl,p),s(hl,qc),i(e,su,p),k(ka,e,p),tu=!0},p(e,[p]){const Ar={};p&1&&(Ar.fw=e[0]),_.$set(Ar);let vl=y;y=xc(e),y!==vl&&(Lr(),$(yr[vl],1,1,()=>{yr[vl]=null}),Nr(),R=yr[y],R||(R=yr[y]=kc[y](e),R.c()),b(R,1),R.m(H.parentNode,H));const Mo={};p&2&&(Mo.$$scope={dirty:p,ctx:e}),Rt.$set(Mo);const No={};p&2&&(No.$$scope={dirty:p,ctx:e}),pa.$set(No);const aa={};p&2&&(aa.$$scope={dirty:p,ctx:e}),ma.$set(aa);const Lo={};p&2&&(Lo.$$scope={dirty:p,ctx:e}),fa.$set(Lo);let bl=qn;qn=zc(e),qn!==bl&&(Lr(),$(Pr[bl],1,1,()=>{Pr[bl]=null}),Nr(),En=Pr[qn],En||(En=Pr[qn]=wc[qn](e),En.c()),b(En,1),En.m(Yr.parentNode,Yr));let xa=jn;jn=Pc(e),jn!==xa&&(Lr(),$(Cr[xa],1,1,()=>{Cr[xa]=null}),Nr(),kn=Cr[jn],kn||(kn=Cr[jn]=yc[jn](e),kn.c()),b(kn,1),kn.m(sl.parentNode,sl));let Gn=xn;xn=Dc(e),xn!==Gn&&(Lr(),$(Dr[Gn],1,1,()=>{Dr[Gn]=null}),Nr(),wn=Dr[xn],wn||(wn=Dr[xn]=Cc[xn](e),wn.c()),b(wn,1),wn.m(rl.parentNode,rl)),e[0]==="pt"?ut||(ut=e_(),ut.c(),ut.m(ll.parentNode,ll)):ut&&(ut.d(1),ut=null);let $l=zn;zn=Sc(e),zn!==$l&&(Lr(),$(Tr[$l],1,1,()=>{Tr[$l]=null}),Nr(),yn=Tr[zn],yn||(yn=Tr[zn]=Tc[zn](e),yn.c()),b(yn,1),yn.m(dl.parentNode,dl));let gl=Pn;Pn=Mc(e),Pn!==gl&&(Lr(),$(Sr[gl],1,1,()=>{Sr[gl]=null}),Nr(),Cn=Sr[Pn],Cn||(Cn=Sr[Pn]=Ac[Pn](e),Cn.c()),b(Cn,1),Cn.m(ml.parentNode,ml)),e[0]==="pt"?$s?p&1&&b($s,1):($s=s_(),$s.c(),b($s,1),$s.m(fl.parentNode,fl)):$s&&(Lr(),$($s,1,1,()=>{$s=null}),Nr());const Mr={};p&2&&(Mr.$$scope={dirty:p,ctx:e}),ka.$set(Mr)},i(e){tu||(b(_.$$.fragment,e),b(S.$$.fragment,e),b(R),b(pe.$$.fragment,e),b(Ge.$$.fragment,e),b(ws.$$.fragment,e),b(zs.$$.fragment,e),b(Cs.$$.fragment,e),b(st.$$.fragment,e),b(Hs.$$.fragment,e),b($t.$$.fragment,e),b(rt.$$.fragment,e),b(gt.$$.fragment,e),b(Is.$$.fragment,e),b(Ut.$$.fragment,e),b(Ft.$$.fragment,e),b(ot.$$.fragment,e),b(Mn.$$.fragment,e),b(Nn.$$.fragment,e),b(Ln.$$.fragment,e),b(On.$$.fragment,e),b(Rt.$$.fragment,e),b(Un.$$.fragment,e),b(Et.$$.fragment,e),b(Ha.$$.fragment,e),b(pa.$$.fragment,e),b(Ba.$$.fragment,e),b(Ra.$$.fragment,e),b(Ka.$$.fragment,e),b(Va.$$.fragment,e),b(Ga.$$.fragment,e),b(ma.$$.fragment,e),b(fa.$$.fragment,e),b(Xa.$$.fragment,e),b(En),b(Wa.$$.fragment,e),b(kn),b(Ja.$$.fragment,e),b(Ya.$$.fragment,e),b(Za.$$.fragment,e),b(er.$$.fragment,e),b(sr.$$.fragment,e),b(tr.$$.fragment,e),b(nr.$$.fragment,e),b(ar.$$.fragment,e),b(wn),b(rr.$$.fragment,e),b(lr.$$.fragment,e),b(pr.$$.fragment,e),b(dr.$$.fragment,e),b(cr.$$.fragment,e),b(mr.$$.fragment,e),b(hr.$$.fragment,e),b(vr.$$.fragment,e),b(br.$$.fragment,e),b($r.$$.fragment,e),b(yn),b(gr.$$.fragment,e),b(qr.$$.fragment,e),b(Er.$$.fragment,e),b(Cn),b($s),b(jr.$$.fragment,e),b(kr.$$.fragment,e),b(xr.$$.fragment,e),b(wr.$$.fragment,e),b(zr.$$.fragment,e),b(ka.$$.fragment,e),tu=!0)},o(e){$(_.$$.fragment,e),$(S.$$.fragment,e),$(R),$(pe.$$.fragment,e),$(Ge.$$.fragment,e),$(ws.$$.fragment,e),$(zs.$$.fragment,e),$(Cs.$$.fragment,e),$(st.$$.fragment,e),$(Hs.$$.fragment,e),$($t.$$.fragment,e),$(rt.$$.fragment,e),$(gt.$$.fragment,e),$(Is.$$.fragment,e),$(Ut.$$.fragment,e),$(Ft.$$.fragment,e),$(ot.$$.fragment,e),$(Mn.$$.fragment,e),$(Nn.$$.fragment,e),$(Ln.$$.fragment,e),$(On.$$.fragment,e),$(Rt.$$.fragment,e),$(Un.$$.fragment,e),$(Et.$$.fragment,e),$(Ha.$$.fragment,e),$(pa.$$.fragment,e),$(Ba.$$.fragment,e),$(Ra.$$.fragment,e),$(Ka.$$.fragment,e),$(Va.$$.fragment,e),$(Ga.$$.fragment,e),$(ma.$$.fragment,e),$(fa.$$.fragment,e),$(Xa.$$.fragment,e),$(En),$(Wa.$$.fragment,e),$(kn),$(Ja.$$.fragment,e),$(Ya.$$.fragment,e),$(Za.$$.fragment,e),$(er.$$.fragment,e),$(sr.$$.fragment,e),$(tr.$$.fragment,e),$(nr.$$.fragment,e),$(ar.$$.fragment,e),$(wn),$(rr.$$.fragment,e),$(lr.$$.fragment,e),$(pr.$$.fragment,e),$(dr.$$.fragment,e),$(cr.$$.fragment,e),$(mr.$$.fragment,e),$(hr.$$.fragment,e),$(vr.$$.fragment,e),$(br.$$.fragment,e),$($r.$$.fragment,e),$(yn),$(gr.$$.fragment,e),$(qr.$$.fragment,e),$(Er.$$.fragment,e),$(Cn),$($s),$(jr.$$.fragment,e),$(kr.$$.fragment,e),$(xr.$$.fragment,e),$(wr.$$.fragment,e),$(zr.$$.fragment,e),$(ka.$$.fragment,e),tu=!1},d(e){t(u),e&&t(q),x(_,e),e&&t(w),e&&t(A),x(S),e&&t(D),yr[y].d(e),e&&t(H),e&&t(L),e&&t(N),e&&t(I),e&&t(J),x(pe,e),e&&t(ce),e&&t(G),e&&t(Oe),e&&t(ae),e&&t(Je),e&&t(Re),e&&t(Ne),e&&t(g),e&&t(gs),e&&t(je),e&&t(he),e&&t(Ke),e&&t(qs),e&&t(Ye),e&&t(cs),e&&t(ns),x(Ge),e&&t(Ls),e&&t(Ce),e&&t(xs),e&&t(_s),x(ws),e&&t(Tt),e&&t(We),e&&t(Us),x(zs,e),e&&t(Se),e&&t(ys),e&&t(Jt),e&&t(hs),e&&t(Zt),e&&t(et),e&&t(Ps),x(Cs,e),e&&t(ht),x(st,e),e&&t(vt),e&&t(Ze),e&&t(Mt),x(Hs,e),e&&t(nt),x($t,e),e&&t(tn),e&&t(we),e&&t(at),x(rt,e),e&&t(ks),e&&t(Nt),e&&t(Lt),x(gt,e),e&&t(Ds),x(Is,e),e&&t(bn),e&&t(lt),e&&t(ls),x(Ut,e),e&&t(qt),x(Ft,e),e&&t(Sn),e&&t(Bs),e&&t(An),x(ot,e),e&&t(an),x(Mn,e),e&&t(Sa),e&&t(it),e&&t(Aa),x(Nn,e),e&&t(It),x(Ln,e),e&&t(Ma),e&&t(Bt),e&&t($n),x(On,e),e&&t(Na),x(Rt,e),e&&t(La),e&&t(rn),x(Un),e&&t(Oa),x(Et,e),e&&t(Ua),e&&t(Ss),e&&t(Uo),x(Ha,e),e&&t(Fo),e&&t(pn),e&&t(Ho),x(pa,e),e&&t(Io),e&&t(Hn),e&&t(Bo),e&&t(da),e&&t(Ro),x(Ba,e),e&&t(Ko),e&&t(In),e&&t(Vo),e&&t(Bn),e&&t(Go),e&&t(Wr),e&&t(Xo),x(Ra,e),e&&t(Wo),e&&t(ca),e&&t(Qo),x(Ka,e),e&&t(Jo),x(Va,e),e&&t(Yo),e&&t(dn),e&&t(Zo),e&&t(cn),e&&t(ei),x(Ga,e),e&&t(si),e&&t(Qr),e&&t(ti),x(ma,e),e&&t(ni),x(fa,e),e&&t(ai),e&&t(Jr),e&&t(ri),x(Xa,e),e&&t(li),e&&t(_a),e&&t(oi),Pr[qn].d(e),e&&t(Yr),e&&t(Zr),e&&t(ii),e&&t(ea),x(Wa),e&&t(ui),e&&t(os),e&&t(pi),e&&t(is),e&&t(di),Cr[jn].d(e),e&&t(sl),e&&t(tl),e&&t(ci),x(Ja,e),e&&t(mi),x(Ya,e),e&&t(fi),e&&t(va),e&&t(_i),x(Za,e),e&&t(hi),x(er,e),e&&t(vi),e&&t(nl),e&&t(bi),x(sr,e),e&&t($i),x(tr,e),e&&t(gi),e&&t(al),e&&t(qi),x(nr,e),e&&t(Ei),x(ar,e),e&&t(ji),Dr[xn].d(e),e&&t(rl),e&&t(sa),x(rr),e&&t(ki),x(lr,e),e&&t(xi),ut&&ut.d(e),e&&t(ll),e&&t(Rn),e&&t(wi),e&&t(mn),e&&t(zi),x(pr,e),e&&t(yi),e&&t(Kn),e&&t(Pi),x(dr,e),e&&t(Ci),e&&t(il),e&&t(Di),e&&t(ul),e&&t(Ti),x(cr,e),e&&t(Si),x(mr,e),e&&t(Ai),e&&t(Ks),e&&t(Mi),x(hr,e),e&&t(Ni),x(vr,e),e&&t(Li),x(br,e),e&&t(Oi),x($r,e),e&&t(Ui),e&&t(pl),e&&t(Fi),Tr[zn].d(e),e&&t(dl),e&&t($a),e&&t(Hi),e&&t(ta),x(gr),e&&t(Ii),e&&t(Vn),e&&t(Bi),x(qr,e),e&&t(Ri),e&&t(qa),e&&t(Ki),e&&t(Ea),e&&t(Vi),x(Er,e),e&&t(Gi),Sr[Pn].d(e),e&&t(ml),$s&&$s.d(e),e&&t(fl),e&&t(na),x(jr),e&&t(Xi),e&&t(jt),e&&t(Wi),x(kr,e),e&&t(Qi),x(xr,e),e&&t(Ji),e&&t(fn),e&&t(Yi),x(wr,e),e&&t(Zi),x(zr,e),e&&t(eu),e&&t(hl),e&&t(su),x(ka,e)}}}const C_={local:"traduction",sections:[{local:"prparation-des-donnes",sections:[{local:"le-jeu-de-donnes-kde4",title:"Le jeu de donn\xE9es KDE4"},{local:"traitement-des-donnes",title:"Traitement des donn\xE9es"}],title:"Pr\xE9paration des donn\xE9es"},{local:"ifinetuneri-le-modle-avec-lapi-trainer",title:"<i>Finetuner</i> le mod\xE8le avec l'API `Trainer`"},{local:"ifinetuneri-du-modle-avec-keras",sections:[{local:"collecte-des-donnes",title:"Collecte des donn\xE9es"},{local:"mtriques",title:"M\xE9triques"},{local:"ifinetuneri-le-modle",title:"<i>Finetuner</i> le mod\xE8le"}],title:"<i>Finetuner</i> du mod\xE8le avec Keras"},{local:"une-boucle-dentranement-personnalise",sections:[{local:"prparer-le-tout-pour-lentranement",title:"Pr\xE9parer le tout pour l'entra\xEEnement"},{local:"boucle-dentranement",title:"Boucle d'entra\xEEnement"},{local:"utilisation-du-modle-ifinetuni",title:"Utilisation du mod\xE8le <i>finetun\xE9</i>"}],title:"Une boucle d'entra\xEEnement personnalis\xE9e"}],title:"Traduction"};function D_(Z,u,q){let _="pt";return o_(()=>{const w=new URLSearchParams(window.location.search);q(0,_=w.get("fw")||"pt")}),[_]}class U_ extends n_{constructor(u){super();a_(this,u,D_,P_,r_,{})}}export{U_ as default,C_ as metadata};
