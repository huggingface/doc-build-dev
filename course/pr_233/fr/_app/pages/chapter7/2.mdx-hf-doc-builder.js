import{S as Bv,i as Hv,s as Gv,e as l,w as j,k as p,t as n,c as o,a as r,x as w,d as s,m as c,h as a,b as _,g as u,G as e,y as x,q as b,o as $,B as C,M as Uv,N as Yc,p as Vr,v as Vv,n as Wr,L as Sv}from"../../chunks/vendor-hf-doc-builder.js";import{T as Xr}from"../../chunks/Tip-hf-doc-builder.js";import{Y as Lv}from"../../chunks/Youtube-hf-doc-builder.js";import{I as ut}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as M}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as Fv}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as Wv}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function Xv(V){let d,g;return d=new Fv({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter7/section2_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter7/section2_tf.ipynb"}]}}),{c(){j(d.$$.fragment)},l(v){w(d.$$.fragment,v)},m(v,q){x(d,v,q),g=!0},i(v){g||(b(d.$$.fragment,v),g=!0)},o(v){$(d.$$.fragment,v),g=!1},d(v){C(d,v)}}}function Zv(V){let d,g;return d=new Fv({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter7/section2_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter7/section2_pt.ipynb"}]}}),{c(){j(d.$$.fragment)},l(v){w(d.$$.fragment,v)},m(v,q){x(d,v,q),g=!0},i(v){g||(b(d.$$.fragment,v),g=!0)},o(v){$(d.$$.fragment,v),g=!1},d(v){C(d,v)}}}function Kv(V){let d,g,v,q,O,E,k,D;return{c(){d=l("p"),g=n("\u{1F4A1} Tant que votre jeu de donn\xE9es consiste en des textes divis\xE9s en mots avec leurs \xE9tiquettes correspondantes, vous pourrez adapter les proc\xE9dures de traitement des donn\xE9es d\xE9crites ici \xE0 votre propre jeu de donn\xE9es. Reportez-vous au "),v=l("a"),q=n("Chapitre 5"),O=n(" si vous avez besoin d\u2019un rafra\xEEchissement sur la fa\xE7on de charger vos propres donn\xE9es personnalis\xE9es dans un "),E=l("code"),k=n("Dataset"),D=n("."),this.h()},l(y){d=o(y,"P",{});var z=r(d);g=a(z,"\u{1F4A1} Tant que votre jeu de donn\xE9es consiste en des textes divis\xE9s en mots avec leurs \xE9tiquettes correspondantes, vous pourrez adapter les proc\xE9dures de traitement des donn\xE9es d\xE9crites ici \xE0 votre propre jeu de donn\xE9es. Reportez-vous au "),v=o(z,"A",{href:!0});var B=r(v);q=a(B,"Chapitre 5"),B.forEach(s),O=a(z," si vous avez besoin d\u2019un rafra\xEEchissement sur la fa\xE7on de charger vos propres donn\xE9es personnalis\xE9es dans un "),E=o(z,"CODE",{});var A=r(E);k=a(A,"Dataset"),A.forEach(s),D=a(z,"."),z.forEach(s),this.h()},h(){_(v,"href","/course/fr/chapter5")},m(y,z){u(y,d,z),e(d,g),e(d,v),e(v,q),e(d,O),e(d,E),e(E,k),e(d,D)},d(y){y&&s(d)}}}function Yv(V){let d,g,v,q,O,E,k,D;return{c(){d=l("p"),g=n("\u270F\uFE0F "),v=l("em"),q=n("A votre tour !"),O=n(" Affichez les deux m\xEAmes phrases avec leurs \xE9tiquettes POS ou "),E=l("em"),k=n("chunking"),D=n(".")},l(y){d=o(y,"P",{});var z=r(d);g=a(z,"\u270F\uFE0F "),v=o(z,"EM",{});var B=r(v);q=a(B,"A votre tour !"),B.forEach(s),O=a(z," Affichez les deux m\xEAmes phrases avec leurs \xE9tiquettes POS ou "),E=o(z,"EM",{});var A=r(E);k=a(A,"chunking"),A.forEach(s),D=a(z,"."),z.forEach(s)},m(y,z){u(y,d,z),e(d,g),e(d,v),e(v,q),e(d,O),e(d,E),e(E,k),e(d,D)},d(y){y&&s(d)}}}function Jv(V){let d,g,v,q,O,E,k,D,y,z,B;return{c(){d=l("p"),g=n("\u270F\uFE0F "),v=l("em"),q=n("A votre tour !"),O=n(" Certains chercheurs pr\xE9f\xE8rent n\u2019attribuer qu\u2019une seule \xE9tiquette par mot et attribuer "),E=l("code"),k=n("-100"),D=n(" aux autres sous-"),y=l("em"),z=n("tokens"),B=n(" dans un mot donn\xE9. Ceci afin d\u2019\xE9viter que les longs mots qui se divisent en plusieurs batchs ne contribuent fortement \xE0 la perte. Changez la fonction pr\xE9c\xE9dente pour aligner les \xE9tiquettes avec les identifiants d\u2019entr\xE9e en suivant cette r\xE8gle.")},l(A){d=o(A,"P",{});var F=r(d);g=a(F,"\u270F\uFE0F "),v=o(F,"EM",{});var I=r(v);q=a(I,"A votre tour !"),I.forEach(s),O=a(F," Certains chercheurs pr\xE9f\xE8rent n\u2019attribuer qu\u2019une seule \xE9tiquette par mot et attribuer "),E=o(F,"CODE",{});var P=r(E);k=a(P,"-100"),P.forEach(s),D=a(F," aux autres sous-"),y=o(F,"EM",{});var T=r(y);z=a(T,"tokens"),T.forEach(s),B=a(F," dans un mot donn\xE9. Ceci afin d\u2019\xE9viter que les longs mots qui se divisent en plusieurs batchs ne contribuent fortement \xE0 la perte. Changez la fonction pr\xE9c\xE9dente pour aligner les \xE9tiquettes avec les identifiants d\u2019entr\xE9e en suivant cette r\xE8gle."),F.forEach(s)},m(A,F){u(A,d,F),e(d,g),e(d,v),e(v,q),e(d,O),e(d,E),e(E,k),e(d,D),e(d,y),e(y,z),e(d,B)},d(A){A&&s(d)}}}function Qv(V){let d,g,v,q,O,E,k,D,y,z,B,A,F;return q=new ut({}),{c(){d=l("h2"),g=l("a"),v=l("span"),j(q.$$.fragment),O=p(),E=l("span"),k=l("i"),D=n("Finetuning"),y=n(" du mod\xE8le avec Keras"),z=p(),B=l("p"),A=n("Le code utilisant Keras sera tr\xE8s similaire au pr\xE9c\xE9dent. Les seuls changements sont la fa\xE7on dont les donn\xE9es sont rassembl\xE9es dans un batch ainsi que la fonction de calcul de la m\xE9trique."),this.h()},l(I){d=o(I,"H2",{class:!0});var P=r(d);g=o(P,"A",{id:!0,class:!0,href:!0});var T=r(g);v=o(T,"SPAN",{});var W=r(v);w(q.$$.fragment,W),W.forEach(s),T.forEach(s),O=c(P),E=o(P,"SPAN",{});var G=r(E);k=o(G,"I",{});var S=r(k);D=a(S,"Finetuning"),S.forEach(s),y=a(G," du mod\xE8le avec Keras"),G.forEach(s),P.forEach(s),z=c(I),B=o(I,"P",{});var X=r(B);A=a(X,"Le code utilisant Keras sera tr\xE8s similaire au pr\xE9c\xE9dent. Les seuls changements sont la fa\xE7on dont les donn\xE9es sont rassembl\xE9es dans un batch ainsi que la fonction de calcul de la m\xE9trique."),X.forEach(s),this.h()},h(){_(g,"id","ifinetuningi-du-modle-avec-keras"),_(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(g,"href","#ifinetuningi-du-modle-avec-keras"),_(d,"class","relative group")},m(I,P){u(I,d,P),e(d,g),e(g,v),x(q,v,null),e(d,O),e(d,E),e(E,k),e(k,D),e(E,y),u(I,z,P),u(I,B,P),e(B,A),F=!0},i(I){F||(b(q.$$.fragment,I),F=!0)},o(I){$(q.$$.fragment,I),F=!1},d(I){I&&s(d),C(q),I&&s(z),I&&s(B)}}}function eh(V){let d,g,v,q,O,E,k,D,y,z,B,A,F,I,P,T,W,G;return q=new ut({}),{c(){d=l("h2"),g=l("a"),v=l("span"),j(q.$$.fragment),O=p(),E=l("span"),k=l("i"),D=n("Finetuning"),y=n(" du mod\xE8le avec l'API "),z=l("code"),B=n("Trainer"),A=p(),F=l("p"),I=n("Le code utilisant "),P=l("code"),T=n("Trainer"),W=n(" sera le m\xEAme que pr\xE9c\xE9demment. Les seuls changements sont la fa\xE7on dont les donn\xE9es sont rassembl\xE9es dans un batch ainsi que la fonction de calcul de la m\xE9trique."),this.h()},l(S){d=o(S,"H2",{class:!0});var X=r(d);g=o(X,"A",{id:!0,class:!0,href:!0});var J=r(g);v=o(J,"SPAN",{});var le=r(v);w(q.$$.fragment,le),le.forEach(s),J.forEach(s),O=c(X),E=o(X,"SPAN",{});var N=r(E);k=o(N,"I",{});var U=r(k);D=a(U,"Finetuning"),U.forEach(s),y=a(N," du mod\xE8le avec l'API "),z=o(N,"CODE",{});var se=r(z);B=a(se,"Trainer"),se.forEach(s),N.forEach(s),X.forEach(s),A=c(S),F=o(S,"P",{});var Y=r(F);I=a(Y,"Le code utilisant "),P=o(Y,"CODE",{});var ee=r(P);T=a(ee,"Trainer"),ee.forEach(s),W=a(Y," sera le m\xEAme que pr\xE9c\xE9demment. Les seuls changements sont la fa\xE7on dont les donn\xE9es sont rassembl\xE9es dans un batch ainsi que la fonction de calcul de la m\xE9trique."),Y.forEach(s),this.h()},h(){_(g,"id","ifinetuningi-du-modle-avec-lapi-trainer"),_(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(g,"href","#ifinetuningi-du-modle-avec-lapi-trainer"),_(d,"class","relative group")},m(S,X){u(S,d,X),e(d,g),e(g,v),x(q,v,null),e(d,O),e(d,E),e(E,k),e(k,D),e(E,y),e(E,z),e(z,B),u(S,A,X),u(S,F,X),e(F,I),e(F,P),e(P,T),e(F,W),G=!0},i(S){G||(b(q.$$.fragment,S),G=!0)},o(S){$(q.$$.fragment,S),G=!1},d(S){S&&s(d),C(q),S&&s(A),S&&s(F)}}}function sh(V){let d,g;return d=new M({props:{code:`from transformers import DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(
    tokenizer=tokenizer, return_tensors="tf"
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(
    tokenizer=tokenizer, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>
)`}}),{c(){j(d.$$.fragment)},l(v){w(d.$$.fragment,v)},m(v,q){x(d,v,q),g=!0},i(v){g||(b(d.$$.fragment,v),g=!0)},o(v){$(d.$$.fragment,v),g=!1},d(v){C(d,v)}}}function th(V){let d,g;return d=new M({props:{code:`from transformers import DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)`}}),{c(){j(d.$$.fragment)},l(v){w(d.$$.fragment,v)},m(v,q){x(d,v,q),g=!0},i(v){g||(b(d.$$.fragment,v),g=!0)},o(v){$(d.$$.fragment,v),g=!1},d(v){C(d,v)}}}function nh(V){let d,g,v,q,O,E,k,D,y,z,B,A,F,I;return z=new M({props:{code:`tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels", "token_type_ids"],
    collate_fn=data_collator,
    shuffle=True,
    batch_size=16,
)

tf_eval_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels", "token_type_ids"],
    collate_fn=data_collator,
    shuffle=False,
    batch_size=16,
)`,highlighted:`tf_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
    collate_fn=data_collator,
    shuffle=<span class="hljs-literal">True</span>,
    batch_size=<span class="hljs-number">16</span>,
)

tf_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
    collate_fn=data_collator,
    shuffle=<span class="hljs-literal">False</span>,
    batch_size=<span class="hljs-number">16</span>,
)`}}),{c(){d=l("p"),g=n("Notre collateur de donn\xE9es est pr\xEAt \xE0 fonctionner ! Maintenant, utilisons-le pour cr\xE9er un "),v=l("code"),q=n("tf.data.Dataset"),O=n(" avec la m\xE9thode "),E=l("code"),k=n("to_tf_dataset()"),D=n("."),y=p(),j(z.$$.fragment),B=p(),A=l("p"),F=n("Prochain arr\xEAt : le mod\xE8le lui-m\xEAme.")},l(P){d=o(P,"P",{});var T=r(d);g=a(T,"Notre collateur de donn\xE9es est pr\xEAt \xE0 fonctionner ! Maintenant, utilisons-le pour cr\xE9er un "),v=o(T,"CODE",{});var W=r(v);q=a(W,"tf.data.Dataset"),W.forEach(s),O=a(T," avec la m\xE9thode "),E=o(T,"CODE",{});var G=r(E);k=a(G,"to_tf_dataset()"),G.forEach(s),D=a(T,"."),T.forEach(s),y=c(P),w(z.$$.fragment,P),B=c(P),A=o(P,"P",{});var S=r(A);F=a(S,"Prochain arr\xEAt : le mod\xE8le lui-m\xEAme."),S.forEach(s)},m(P,T){u(P,d,T),e(d,g),e(d,v),e(v,q),e(d,O),e(d,E),e(E,k),e(d,D),u(P,y,T),x(z,P,T),u(P,B,T),u(P,A,T),e(A,F),I=!0},i(P){I||(b(z.$$.fragment,P),I=!0)},o(P){$(z.$$.fragment,P),I=!1},d(P){P&&s(d),P&&s(y),C(z,P),P&&s(B),P&&s(A)}}}function ah(V){let d,g,v,q,O;return{c(){d=l("p"),g=n("Comme nous pouvons le voir, le deuxi\xE8me jeu d\u2019\xE9tiquettes a \xE9t\xE9 compl\xE9t\xE9 \xE0 la longueur du premier en utilisant des "),v=l("code"),q=n("-100"),O=n(".")},l(E){d=o(E,"P",{});var k=r(d);g=a(k,"Comme nous pouvons le voir, le deuxi\xE8me jeu d\u2019\xE9tiquettes a \xE9t\xE9 compl\xE9t\xE9 \xE0 la longueur du premier en utilisant des "),v=o(k,"CODE",{});var D=r(v);q=a(D,"-100"),D.forEach(s),O=a(k,"."),k.forEach(s)},m(E,k){u(E,d,k),e(d,g),e(d,v),e(v,q),e(d,O)},i:Sv,o:Sv,d(E){E&&s(d)}}}function Iv(V){let d,g,v,q,O,E,k,D,y,z,B,A,F,I,P,T,W,G,S,X,J,le,N,U,se,Y,ee,R,K,me,Me,he,H,oe,Q,ue,Z,ce,ss,_e,Ee,Os,ze,Ne,ts,ae,bs,$s,Ot,Ea,te,qa,pn,Ps,ka,ja,pt,ns,cn,Re,dn,as,ct,Oe,Fe,Ds,ls,wa,os,dt,xa,mn,fn,Pe,vn,mt,Ca,Gn,gs,Ws,rs,Ms,Ns,Pt,Xs,hn,Dt,Zs,Un,je,ft,Vn,we,Mt,_n,pe,is,bn,Ks,vt,Nt,Wn,Ys,At,us,Tt,fe,ya,St,Es,Ze,Js,Ae,za,As,Oa,Xn,xe,$n,gn,Zn,Te,ht,En,qn,Kn,qs,kn,Be,ps,ks,_t,Lt,Ts,Yn,Ce,Se,It,js,Pa,Ss,bt,Da,Jn,cs,$t,Rt,ws,Ma,gt,Qs,et,st,Ke,jn,He,wn,ie,Qn,$e,Na,xn,Et,Aa,Cn,qt,Ta,yn,Ft,Bt,zn,On,Ye,Pn;return q=new ut({}),H=new M({props:{code:`id2label = {str(i): label for i, label in enumerate(label_names)}
label2id = {v: k for k, v in id2label.items()}`,highlighted:`id2label = {<span class="hljs-built_in">str</span>(i): label <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(label_names)}
label2id = {v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> id2label.items()}`}}),Ne=new M({props:{code:`from transformers import TFAutoModelForTokenClassification

model = TFAutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForTokenClassification

model = TFAutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)`}}),ns=new M({props:{code:"model.config.num_labels",highlighted:"model.config.num_labels"}}),Re=new M({props:{code:"9",highlighted:'<span class="hljs-number">9</span>'}}),as=new Xr({props:{warning:!0,$$slots:{default:[lh]},$$scope:{ctx:V}}}),ls=new ut({}),Ws=new M({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`}}),Mt=new M({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}}),Ze=new M({props:{code:`from transformers import create_optimizer
import tensorflow as tf

# Entra\xEEner en mixed-precision float16
# Commentez cette ligne si vous utilisez un GPU qui ne b\xE9n\xE9ficiera pas de cette fonction
tf.keras.mixed_precision.set_global_policy("mixed_float16")

# Le nombre d'\xE9tapes d'entra\xEEnement est le nombre d'\xE9chantillons dans l'ensemble de donn\xE9es, divis\xE9 par la taille du batch puis multipli\xE9 par le nombre total d'\xE9poques
# par le nombre total d'\xE9poques. Notez que le jeu de donn\xE9es tf_train_dataset est ici un batchtf.data.Dataset,
# et non le jeu de donn\xE9es original Hugging Face Dataset, donc son len() est d\xE9j\xE0 num_samples // batch_size
num_epochs = 3
num_train_steps = len(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
    init_lr=2e-5,
    num_warmup_steps=0,
    num_train_steps=num_train_steps,
    weight_decay_rate=0.01,
)
model.compile(optimizer=optimizer)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-comment"># Entra\xEEner en mixed-precision float16</span>
<span class="hljs-comment"># Commentez cette ligne si vous utilisez un GPU qui ne b\xE9n\xE9ficiera pas de cette fonction</span>
tf.keras.mixed_precision.set_global_policy(<span class="hljs-string">&quot;mixed_float16&quot;</span>)

<span class="hljs-comment"># Le nombre d&#x27;\xE9tapes d&#x27;entra\xEEnement est le nombre d&#x27;\xE9chantillons dans l&#x27;ensemble de donn\xE9es, divis\xE9 par la taille du batch puis multipli\xE9 par le nombre total d&#x27;\xE9poques</span>
<span class="hljs-comment"># par le nombre total d&#x27;\xE9poques. Notez que le jeu de donn\xE9es tf_train_dataset est ici un batchtf.data.Dataset,</span>
<span class="hljs-comment"># et non le jeu de donn\xE9es original Hugging Face Dataset, donc son len() est d\xE9j\xE0 num_samples // batch_size</span>
num_epochs = <span class="hljs-number">3</span>
num_train_steps = <span class="hljs-built_in">len</span>(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
    init_lr=<span class="hljs-number">2e-5</span>,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_train_steps=num_train_steps,
    weight_decay_rate=<span class="hljs-number">0.01</span>,
)
model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)`}}),Ts=new M({props:{code:`from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(output_dir="bert-finetuned-ner", tokenizer=tokenizer)

model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=[callback],
    epochs=num_epochs,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback

callback = PushToHubCallback(output_dir=<span class="hljs-string">&quot;bert-finetuned-ner&quot;</span>, tokenizer=tokenizer)

model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=[callback],
    epochs=num_epochs,
)`}}),et=new Xr({props:{$$slots:{default:[oh]},$$scope:{ctx:V}}}),{c(){d=l("h3"),g=l("a"),v=l("span"),j(q.$$.fragment),O=p(),E=l("span"),k=n("D\xE9finir le mod\xE8le"),D=p(),y=l("p"),z=n("Puisque nous travaillons sur un probl\xE8me de classification de "),B=l("em"),A=n("tokens"),F=n(", nous allons utiliser la classe "),I=l("code"),P=n("TFAutoModelForTokenClassification"),T=n(". La principale chose \xE0 retenir lors de la d\xE9finition de ce mod\xE8le est de transmettre des informations sur le nombre d\u2019\xE9tiquettes que nous avons. La fa\xE7on la plus simple de le faire est de passer ce nombre avec l\u2019argument "),W=l("code"),G=n("num_labels"),S=n(", mais si nous voulons un joli "),X=l("em"),J=n("widget"),le=n(" d\u2019inf\xE9rence fonctionnant comme celui que nous avons vu au d\xE9but de cette section, il est pr\xE9f\xE9rable de d\xE9finir les correspondances correctes des \xE9tiquettes \xE0 la place."),N=p(),U=l("p"),se=n("Elles devraient \xEAtre d\xE9finies par deux dictionnaires, "),Y=l("code"),ee=n("id2label"),R=n(" et "),K=l("code"),me=n("label2id"),Me=n(", qui contiennent la correspondance de l\u2019identifiant \xE0 l\u2019\xE9tiquette et vice versa :"),he=p(),j(H.$$.fragment),oe=p(),Q=l("p"),ue=n("Maintenant, nous pouvons simplement les passer \xE0 la m\xE9thode "),Z=l("code"),ce=n("TFAutoModelForTokenClassification.from_pretrained()"),ss=n(", et ils seront d\xE9finis dans la configuration du mod\xE8le puis correctement enregistr\xE9s et t\xE9l\xE9charg\xE9s vers le "),_e=l("em"),Ee=n("Hub"),Os=n(" :"),ze=p(),j(Ne.$$.fragment),ts=p(),ae=l("p"),bs=n("Comme lorsque nous avons d\xE9fini notre "),$s=l("code"),Ot=n("TFAutoModelForSequenceClassification"),Ea=n(" au "),te=l("a"),qa=n("chapitre 3"),pn=n(", la cr\xE9ation du mod\xE8le \xE9met un avertissement indiquant que certains poids n\u2019ont pas \xE9t\xE9 utilis\xE9s (ceux de la t\xEAte de pr\xE9-entra\xEEnement) et que d\u2019autres poids ont \xE9t\xE9 initialis\xE9s de mani\xE8re al\xE9atoire (ceux de la t\xEAte de classification des nouveaux "),Ps=l("em"),ka=n("tokens"),ja=n("), et que ce mod\xE8le doit \xEAtre entra\xEEn\xE9. Nous ferons cela dans une minute mais v\xE9rifions d\u2019abord que notre mod\xE8le a le bon nombre d\u2019\xE9tiquettes :"),pt=p(),j(ns.$$.fragment),cn=p(),j(Re.$$.fragment),dn=p(),j(as.$$.fragment),ct=p(),Oe=l("h3"),Fe=l("a"),Ds=l("span"),j(ls.$$.fragment),wa=p(),os=l("span"),dt=l("i"),xa=n("Finetuning"),mn=n(" du mod\xE8le"),fn=p(),Pe=l("p"),vn=n("Nous sommes maintenant pr\xEAts \xE0 entra\xEEner notre mod\xE8le ! Mais nous devons d\u2019abord faire un peu de m\xE9nage : nous devons nous connecter \xE0 Hugging Face et d\xE9finir nos hyperparam\xE8tres d\u2019entra\xEEnement. Si vous travaillez dans un "),mt=l("em"),Ca=n("notebook"),Gn=n(", il y a une fonction pratique pour vous aider \xE0 le faire :"),gs=p(),j(Ws.$$.fragment),rs=p(),Ms=l("p"),Ns=n("Cela affichera un "),Pt=l("em"),Xs=n("widget"),hn=n(" o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),Dt=p(),Zs=l("p"),Un=n("Si vous ne travaillez pas dans un "),je=l("em"),ft=n("notebook"),Vn=n(", tapez simplement la ligne suivante dans votre terminal :"),we=p(),j(Mt.$$.fragment),_n=p(),pe=l("p"),is=n("Apr\xE8s s\u2019\xEAtre connect\xE9, nous pouvons pr\xE9parer tout ce dont nous avons besoin pour compiler notre mod\xE8le. \u{1F917} "),bn=l("em"),Ks=n("Transformers"),vt=n(" fournit une fonction pratique "),Nt=l("code"),Wn=n("create_optimizer()"),Ys=n(" qui vous donnera un optimiseur "),At=l("code"),us=n("AdamW"),Tt=n(" avec des param\xE8tres appropri\xE9s pour le taux de d\xE9croissance des poids et le taux de d\xE9croissance de l\u2019apprentissage, les deux am\xE9liorant les performances de votre mod\xE8le par rapport \xE0 l\u2019optimiseur "),fe=l("code"),ya=n("Adam"),St=n(" :"),Es=p(),j(Ze.$$.fragment),Js=p(),Ae=l("p"),za=n("Notez \xE9galement que nous ne fournissons pas d\u2019argument "),As=l("code"),Oa=n("loss"),Xn=n(" \xE0 "),xe=l("code"),$n=n("compile()"),gn=n(". C\u2019est parce que les mod\xE8les peuvent en fait calculer la perte en interne. Si vous compilez sans perte et fournissez vos \xE9tiquettes dans le dictionnaire d\u2019entr\xE9e (comme nous le faisons dans nos jeux de donn\xE9es), alors le mod\xE8le s\u2019entra\xEEnera en utilisant cette perte interne, qui sera appropri\xE9e pour la t\xE2che et le type de mod\xE8le que vous avez choisi."),Zn=p(),Te=l("p"),ht=n("Ensuite, nous d\xE9finissons un "),En=l("code"),qn=n("PushToHubCallback"),Kn=n(" pour t\xE9l\xE9charger notre mod\xE8le vers le "),qs=l("em"),kn=n("Hub"),Be=n(" pendant l\u2019entra\xEEnement, et nous ajustons le mod\xE8le avec ce "),ps=l("em"),ks=n("callback"),_t=n(" :"),Lt=p(),j(Ts.$$.fragment),Yn=p(),Ce=l("p"),Se=n("Vous pouvez sp\xE9cifier le nom complet du d\xE9p\xF4t vers lequel vous voulez pousser avec l\u2019argument "),It=l("code"),js=n("hub_model_id"),Pa=n(" (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),Ss=l("a"),bt=l("code"),Da=n("huggingface-course"),Jn=n(", nous avons ajout\xE9 "),cs=l("code"),$t=n('hub_model_id="huggingface-course/bert-finetuned-ner"'),Rt=n(". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace de noms et nomm\xE9 apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, par exemple "),ws=l("code"),Ma=n('"cool_huggingface_user/bert-finetuned-ner"'),gt=n("."),Qs=p(),j(et.$$.fragment),st=p(),Ke=l("p"),jn=n("Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),He=l("em"),wn=n("Hub"),ie=n(" en arri\xE8re-plan. De cette fa\xE7on, vous pourrez reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),Qn=p(),$e=l("p"),Na=n("A ce stade, vous pouvez utiliser le "),xn=l("em"),Et=n("widget"),Aa=n(" d\u2019inf\xE9rence sur le "),Cn=l("em"),qt=n("Hub"),Ta=n(" pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),yn=l("em"),Ft=n("finetuner"),Bt=n(" un mod\xE8le sur une t\xE2che de classification de "),zn=l("em"),On=n("tokens"),Ye=n(". F\xE9licitations ! Mais quelle est la qualit\xE9 r\xE9elle de notre mod\xE8le ? Nous devons \xE9valuer certaines m\xE9triques pour le d\xE9couvrir."),this.h()},l(f){d=o(f,"H3",{class:!0});var L=r(d);g=o(L,"A",{id:!0,class:!0,href:!0});var Dn=r(g);v=o(Dn,"SPAN",{});var Sa=r(v);w(q.$$.fragment,Sa),Sa.forEach(s),Dn.forEach(s),O=c(L),E=o(L,"SPAN",{});var Ls=r(E);k=a(Ls,"D\xE9finir le mod\xE8le"),Ls.forEach(s),L.forEach(s),D=c(f),y=o(f,"P",{});var be=r(y);z=a(be,"Puisque nous travaillons sur un probl\xE8me de classification de "),B=o(be,"EM",{});var Mn=r(B);A=a(Mn,"tokens"),Mn.forEach(s),F=a(be,", nous allons utiliser la classe "),I=o(be,"CODE",{});var xs=r(I);P=a(xs,"TFAutoModelForTokenClassification"),xs.forEach(s),T=a(be,". La principale chose \xE0 retenir lors de la d\xE9finition de ce mod\xE8le est de transmettre des informations sur le nombre d\u2019\xE9tiquettes que nous avons. La fa\xE7on la plus simple de le faire est de passer ce nombre avec l\u2019argument "),W=o(be,"CODE",{});var La=r(W);G=a(La,"num_labels"),La.forEach(s),S=a(be,", mais si nous voulons un joli "),X=o(be,"EM",{});var Is=r(X);J=a(Is,"widget"),Is.forEach(s),le=a(be," d\u2019inf\xE9rence fonctionnant comme celui que nous avons vu au d\xE9but de cette section, il est pr\xE9f\xE9rable de d\xE9finir les correspondances correctes des \xE9tiquettes \xE0 la place."),be.forEach(s),N=c(f),U=o(f,"P",{});var Ht=r(U);se=a(Ht,"Elles devraient \xEAtre d\xE9finies par deux dictionnaires, "),Y=o(Ht,"CODE",{});var Nn=r(Y);ee=a(Nn,"id2label"),Nn.forEach(s),R=a(Ht," et "),K=o(Ht,"CODE",{});var kt=r(K);me=a(kt,"label2id"),kt.forEach(s),Me=a(Ht,", qui contiennent la correspondance de l\u2019identifiant \xE0 l\u2019\xE9tiquette et vice versa :"),Ht.forEach(s),he=c(f),w(H.$$.fragment,f),oe=c(f),Q=o(f,"P",{});var Gt=r(Q);ue=a(Gt,"Maintenant, nous pouvons simplement les passer \xE0 la m\xE9thode "),Z=o(Gt,"CODE",{});var Ut=r(Z);ce=a(Ut,"TFAutoModelForTokenClassification.from_pretrained()"),Ut.forEach(s),ss=a(Gt,", et ils seront d\xE9finis dans la configuration du mod\xE8le puis correctement enregistr\xE9s et t\xE9l\xE9charg\xE9s vers le "),_e=o(Gt,"EM",{});var Vt=r(_e);Ee=a(Vt,"Hub"),Vt.forEach(s),Os=a(Gt," :"),Gt.forEach(s),ze=c(f),w(Ne.$$.fragment,f),ts=c(f),ae=o(f,"P",{});var Rs=r(ae);bs=a(Rs,"Comme lorsque nous avons d\xE9fini notre "),$s=o(Rs,"CODE",{});var jt=r($s);Ot=a(jt,"TFAutoModelForSequenceClassification"),jt.forEach(s),Ea=a(Rs," au "),te=o(Rs,"A",{href:!0});var Fs=r(te);qa=a(Fs,"chapitre 3"),Fs.forEach(s),pn=a(Rs,", la cr\xE9ation du mod\xE8le \xE9met un avertissement indiquant que certains poids n\u2019ont pas \xE9t\xE9 utilis\xE9s (ceux de la t\xEAte de pr\xE9-entra\xEEnement) et que d\u2019autres poids ont \xE9t\xE9 initialis\xE9s de mani\xE8re al\xE9atoire (ceux de la t\xEAte de classification des nouveaux "),Ps=o(Rs,"EM",{});var ve=r(Ps);ka=a(ve,"tokens"),ve.forEach(s),ja=a(Rs,"), et que ce mod\xE8le doit \xEAtre entra\xEEn\xE9. Nous ferons cela dans une minute mais v\xE9rifions d\u2019abord que notre mod\xE8le a le bon nombre d\u2019\xE9tiquettes :"),Rs.forEach(s),pt=c(f),w(ns.$$.fragment,f),cn=c(f),w(Re.$$.fragment,f),dn=c(f),w(as.$$.fragment,f),ct=c(f),Oe=o(f,"H3",{class:!0});var Wt=r(Oe);Fe=o(Wt,"A",{id:!0,class:!0,href:!0});var tt=r(Fe);Ds=o(tt,"SPAN",{});var ql=r(Ds);w(ls.$$.fragment,ql),ql.forEach(s),tt.forEach(s),wa=c(Wt),os=o(Wt,"SPAN",{});var An=r(os);dt=o(An,"I",{});var ea=r(dt);xa=a(ea,"Finetuning"),ea.forEach(s),mn=a(An," du mod\xE8le"),An.forEach(s),Wt.forEach(s),fn=c(f),Pe=o(f,"P",{});var Tn=r(Pe);vn=a(Tn,"Nous sommes maintenant pr\xEAts \xE0 entra\xEEner notre mod\xE8le ! Mais nous devons d\u2019abord faire un peu de m\xE9nage : nous devons nous connecter \xE0 Hugging Face et d\xE9finir nos hyperparam\xE8tres d\u2019entra\xEEnement. Si vous travaillez dans un "),mt=o(Tn,"EM",{});var ds=r(mt);Ca=a(ds,"notebook"),ds.forEach(s),Gn=a(Tn,", il y a une fonction pratique pour vous aider \xE0 le faire :"),Tn.forEach(s),gs=c(f),w(Ws.$$.fragment,f),rs=c(f),Ms=o(f,"P",{});var Xt=r(Ms);Ns=a(Xt,"Cela affichera un "),Pt=o(Xt,"EM",{});var sa=r(Pt);Xs=a(sa,"widget"),sa.forEach(s),hn=a(Xt," o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),Xt.forEach(s),Dt=c(f),Zs=o(f,"P",{});var ta=r(Zs);Un=a(ta,"Si vous ne travaillez pas dans un "),je=o(ta,"EM",{});var na=r(je);ft=a(na,"notebook"),na.forEach(s),Vn=a(ta,", tapez simplement la ligne suivante dans votre terminal :"),ta.forEach(s),we=c(f),w(Mt.$$.fragment,f),_n=c(f),pe=o(f,"P",{});var Je=r(pe);is=a(Je,"Apr\xE8s s\u2019\xEAtre connect\xE9, nous pouvons pr\xE9parer tout ce dont nous avons besoin pour compiler notre mod\xE8le. \u{1F917} "),bn=o(Je,"EM",{});var kl=r(bn);Ks=a(kl,"Transformers"),kl.forEach(s),vt=a(Je," fournit une fonction pratique "),Nt=o(Je,"CODE",{});var aa=r(Nt);Wn=a(aa,"create_optimizer()"),aa.forEach(s),Ys=a(Je," qui vous donnera un optimiseur "),At=o(Je,"CODE",{});var la=r(At);us=a(la,"AdamW"),la.forEach(s),Tt=a(Je," avec des param\xE8tres appropri\xE9s pour le taux de d\xE9croissance des poids et le taux de d\xE9croissance de l\u2019apprentissage, les deux am\xE9liorant les performances de votre mod\xE8le par rapport \xE0 l\u2019optimiseur "),fe=o(Je,"CODE",{});var jl=r(fe);ya=a(jl,"Adam"),jl.forEach(s),St=a(Je," :"),Je.forEach(s),Es=c(f),w(Ze.$$.fragment,f),Js=c(f),Ae=o(f,"P",{});var wt=r(Ae);za=a(wt,"Notez \xE9galement que nous ne fournissons pas d\u2019argument "),As=o(wt,"CODE",{});var xt=r(As);Oa=a(xt,"loss"),xt.forEach(s),Xn=a(wt," \xE0 "),xe=o(wt,"CODE",{});var Ct=r(xe);$n=a(Ct,"compile()"),Ct.forEach(s),gn=a(wt,". C\u2019est parce que les mod\xE8les peuvent en fait calculer la perte en interne. Si vous compilez sans perte et fournissez vos \xE9tiquettes dans le dictionnaire d\u2019entr\xE9e (comme nous le faisons dans nos jeux de donn\xE9es), alors le mod\xE8le s\u2019entra\xEEnera en utilisant cette perte interne, qui sera appropri\xE9e pour la t\xE2che et le type de mod\xE8le que vous avez choisi."),wt.forEach(s),Zn=c(f),Te=o(f,"P",{});var Ge=r(Te);ht=a(Ge,"Ensuite, nous d\xE9finissons un "),En=o(Ge,"CODE",{});var nt=r(En);qn=a(nt,"PushToHubCallback"),nt.forEach(s),Kn=a(Ge," pour t\xE9l\xE9charger notre mod\xE8le vers le "),qs=o(Ge,"EM",{});var Bs=r(qs);kn=a(Bs,"Hub"),Bs.forEach(s),Be=a(Ge," pendant l\u2019entra\xEEnement, et nous ajustons le mod\xE8le avec ce "),ps=o(Ge,"EM",{});var oa=r(ps);ks=a(oa,"callback"),oa.forEach(s),_t=a(Ge," :"),Ge.forEach(s),Lt=c(f),w(Ts.$$.fragment,f),Yn=c(f),Ce=o(f,"P",{});var Ue=r(Ce);Se=a(Ue,"Vous pouvez sp\xE9cifier le nom complet du d\xE9p\xF4t vers lequel vous voulez pousser avec l\u2019argument "),It=o(Ue,"CODE",{});var wl=r(It);js=a(wl,"hub_model_id"),wl.forEach(s),Pa=a(Ue," (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),Ss=o(Ue,"A",{href:!0,rel:!0});var Ia=r(Ss);bt=o(Ia,"CODE",{});var at=r(bt);Da=a(at,"huggingface-course"),at.forEach(s),Ia.forEach(s),Jn=a(Ue,", nous avons ajout\xE9 "),cs=o(Ue,"CODE",{});var Ra=r(cs);$t=a(Ra,'hub_model_id="huggingface-course/bert-finetuned-ner"'),Ra.forEach(s),Rt=a(Ue,". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace de noms et nomm\xE9 apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, par exemple "),ws=o(Ue,"CODE",{});var Hs=r(ws);Ma=a(Hs,'"cool_huggingface_user/bert-finetuned-ner"'),Hs.forEach(s),gt=a(Ue,"."),Ue.forEach(s),Qs=c(f),w(et.$$.fragment,f),st=c(f),Ke=o(f,"P",{});var Sn=r(Ke);jn=a(Sn,"Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),He=o(Sn,"EM",{});var De=r(He);wn=a(De,"Hub"),De.forEach(s),ie=a(Sn," en arri\xE8re-plan. De cette fa\xE7on, vous pourrez reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),Sn.forEach(s),Qn=c(f),$e=o(f,"P",{});var Ve=r($e);Na=a(Ve,"A ce stade, vous pouvez utiliser le "),xn=o(Ve,"EM",{});var ra=r(xn);Et=a(ra,"widget"),ra.forEach(s),Aa=a(Ve," d\u2019inf\xE9rence sur le "),Cn=o(Ve,"EM",{});var ia=r(Cn);qt=a(ia,"Hub"),ia.forEach(s),Ta=a(Ve," pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),yn=o(Ve,"EM",{});var xl=r(yn);Ft=a(xl,"finetuner"),xl.forEach(s),Bt=a(Ve," un mod\xE8le sur une t\xE2che de classification de "),zn=o(Ve,"EM",{});var Cl=r(zn);On=a(Cl,"tokens"),Cl.forEach(s),Ye=a(Ve,". F\xE9licitations ! Mais quelle est la qualit\xE9 r\xE9elle de notre mod\xE8le ? Nous devons \xE9valuer certaines m\xE9triques pour le d\xE9couvrir."),Ve.forEach(s),this.h()},h(){_(g,"id","dfinir-le-modle"),_(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(g,"href","#dfinir-le-modle"),_(d,"class","relative group"),_(te,"href","/course/fr/chapter3"),_(Fe,"id","ifinetuningi-du-modle"),_(Fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Fe,"href","#ifinetuningi-du-modle"),_(Oe,"class","relative group"),_(Ss,"href","https://huggingface.co/huggingface-course"),_(Ss,"rel","nofollow")},m(f,L){u(f,d,L),e(d,g),e(g,v),x(q,v,null),e(d,O),e(d,E),e(E,k),u(f,D,L),u(f,y,L),e(y,z),e(y,B),e(B,A),e(y,F),e(y,I),e(I,P),e(y,T),e(y,W),e(W,G),e(y,S),e(y,X),e(X,J),e(y,le),u(f,N,L),u(f,U,L),e(U,se),e(U,Y),e(Y,ee),e(U,R),e(U,K),e(K,me),e(U,Me),u(f,he,L),x(H,f,L),u(f,oe,L),u(f,Q,L),e(Q,ue),e(Q,Z),e(Z,ce),e(Q,ss),e(Q,_e),e(_e,Ee),e(Q,Os),u(f,ze,L),x(Ne,f,L),u(f,ts,L),u(f,ae,L),e(ae,bs),e(ae,$s),e($s,Ot),e(ae,Ea),e(ae,te),e(te,qa),e(ae,pn),e(ae,Ps),e(Ps,ka),e(ae,ja),u(f,pt,L),x(ns,f,L),u(f,cn,L),x(Re,f,L),u(f,dn,L),x(as,f,L),u(f,ct,L),u(f,Oe,L),e(Oe,Fe),e(Fe,Ds),x(ls,Ds,null),e(Oe,wa),e(Oe,os),e(os,dt),e(dt,xa),e(os,mn),u(f,fn,L),u(f,Pe,L),e(Pe,vn),e(Pe,mt),e(mt,Ca),e(Pe,Gn),u(f,gs,L),x(Ws,f,L),u(f,rs,L),u(f,Ms,L),e(Ms,Ns),e(Ms,Pt),e(Pt,Xs),e(Ms,hn),u(f,Dt,L),u(f,Zs,L),e(Zs,Un),e(Zs,je),e(je,ft),e(Zs,Vn),u(f,we,L),x(Mt,f,L),u(f,_n,L),u(f,pe,L),e(pe,is),e(pe,bn),e(bn,Ks),e(pe,vt),e(pe,Nt),e(Nt,Wn),e(pe,Ys),e(pe,At),e(At,us),e(pe,Tt),e(pe,fe),e(fe,ya),e(pe,St),u(f,Es,L),x(Ze,f,L),u(f,Js,L),u(f,Ae,L),e(Ae,za),e(Ae,As),e(As,Oa),e(Ae,Xn),e(Ae,xe),e(xe,$n),e(Ae,gn),u(f,Zn,L),u(f,Te,L),e(Te,ht),e(Te,En),e(En,qn),e(Te,Kn),e(Te,qs),e(qs,kn),e(Te,Be),e(Te,ps),e(ps,ks),e(Te,_t),u(f,Lt,L),x(Ts,f,L),u(f,Yn,L),u(f,Ce,L),e(Ce,Se),e(Ce,It),e(It,js),e(Ce,Pa),e(Ce,Ss),e(Ss,bt),e(bt,Da),e(Ce,Jn),e(Ce,cs),e(cs,$t),e(Ce,Rt),e(Ce,ws),e(ws,Ma),e(Ce,gt),u(f,Qs,L),x(et,f,L),u(f,st,L),u(f,Ke,L),e(Ke,jn),e(Ke,He),e(He,wn),e(Ke,ie),u(f,Qn,L),u(f,$e,L),e($e,Na),e($e,xn),e(xn,Et),e($e,Aa),e($e,Cn),e(Cn,qt),e($e,Ta),e($e,yn),e(yn,Ft),e($e,Bt),e($e,zn),e(zn,On),e($e,Ye),Pn=!0},i(f){Pn||(b(q.$$.fragment,f),b(H.$$.fragment,f),b(Ne.$$.fragment,f),b(ns.$$.fragment,f),b(Re.$$.fragment,f),b(as.$$.fragment,f),b(ls.$$.fragment,f),b(Ws.$$.fragment,f),b(Mt.$$.fragment,f),b(Ze.$$.fragment,f),b(Ts.$$.fragment,f),b(et.$$.fragment,f),Pn=!0)},o(f){$(q.$$.fragment,f),$(H.$$.fragment,f),$(Ne.$$.fragment,f),$(ns.$$.fragment,f),$(Re.$$.fragment,f),$(as.$$.fragment,f),$(ls.$$.fragment,f),$(Ws.$$.fragment,f),$(Mt.$$.fragment,f),$(Ze.$$.fragment,f),$(Ts.$$.fragment,f),$(et.$$.fragment,f),Pn=!1},d(f){f&&s(d),C(q),f&&s(D),f&&s(y),f&&s(N),f&&s(U),f&&s(he),C(H,f),f&&s(oe),f&&s(Q),f&&s(ze),C(Ne,f),f&&s(ts),f&&s(ae),f&&s(pt),C(ns,f),f&&s(cn),C(Re,f),f&&s(dn),C(as,f),f&&s(ct),f&&s(Oe),C(ls),f&&s(fn),f&&s(Pe),f&&s(gs),C(Ws,f),f&&s(rs),f&&s(Ms),f&&s(Dt),f&&s(Zs),f&&s(we),C(Mt,f),f&&s(_n),f&&s(pe),f&&s(Es),C(Ze,f),f&&s(Js),f&&s(Ae),f&&s(Zn),f&&s(Te),f&&s(Lt),C(Ts,f),f&&s(Yn),f&&s(Ce),f&&s(Qs),C(et,f),f&&s(st),f&&s(Ke),f&&s(Qn),f&&s($e)}}}function lh(V){let d,g,v,q,O;return{c(){d=l("p"),g=n("\u26A0\uFE0F Si vous avez un mod\xE8le avec le mauvais nombre d\u2019\xE9tiquettes, vous obtiendrez plus tard une erreur obscure lors de l\u2019appel de "),v=l("code"),q=n("model.fit()"),O=n(". Cela peut \xEAtre ennuyeux \xE0 d\xE9boguer donc assurez-vous de faire cette v\xE9rification pour confirmer que vous avez le nombre d\u2019\xE9tiquettes attendu.")},l(E){d=o(E,"P",{});var k=r(d);g=a(k,"\u26A0\uFE0F Si vous avez un mod\xE8le avec le mauvais nombre d\u2019\xE9tiquettes, vous obtiendrez plus tard une erreur obscure lors de l\u2019appel de "),v=o(k,"CODE",{});var D=r(v);q=a(D,"model.fit()"),D.forEach(s),O=a(k,". Cela peut \xEAtre ennuyeux \xE0 d\xE9boguer donc assurez-vous de faire cette v\xE9rification pour confirmer que vous avez le nombre d\u2019\xE9tiquettes attendu."),k.forEach(s)},m(E,k){u(E,d,k),e(d,g),e(d,v),e(v,q),e(d,O)},d(E){E&&s(d)}}}function oh(V){let d,g,v,q,O;return{c(){d=l("p"),g=n("\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de l\u2019appel de "),v=l("code"),q=n("model.fit()"),O=n(" et devrez d\xE9finir un nouveau nom.")},l(E){d=o(E,"P",{});var k=r(d);g=a(k,"\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de l\u2019appel de "),v=o(k,"CODE",{});var D=r(v);q=a(D,"model.fit()"),D.forEach(s),O=a(k," et devrez d\xE9finir un nouveau nom."),k.forEach(s)},m(E,k){u(E,d,k),e(d,g),e(d,v),e(v,q),e(d,O)},d(E){E&&s(d)}}}function rh(V){let d,g,v,q,O,E,k,D,y,z,B,A,F,I,P,T,W,G,S,X,J,le,N,U,se,Y,ee;return W=new M({props:{code:"!pip install seqeval",highlighted:"!pip install seqeval"}}),{c(){d=l("p"),g=n("Le "),v=l("em"),q=n("framework"),O=n("  traditionnel utilis\xE9 pour \xE9valuer la pr\xE9diction de la classification des "),E=l("em"),k=n("tokens"),D=n(" est "),y=l("a"),z=l("em"),B=n("seqeval"),A=n(". Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que "),F=l("em"),I=n("seqeval"),P=n(" :"),T=p(),j(W.$$.fragment),G=p(),S=l("p"),X=n("Nous pouvons ensuite le charger via la fonction "),J=l("code"),le=n("load_metric()"),N=n(" comme nous l\u2019avons fait dans le "),U=l("a"),se=n("chapitre 3"),Y=n(" :"),this.h()},l(R){d=o(R,"P",{});var K=r(d);g=a(K,"Le "),v=o(K,"EM",{});var me=r(v);q=a(me,"framework"),me.forEach(s),O=a(K,"  traditionnel utilis\xE9 pour \xE9valuer la pr\xE9diction de la classification des "),E=o(K,"EM",{});var Me=r(E);k=a(Me,"tokens"),Me.forEach(s),D=a(K," est "),y=o(K,"A",{href:!0,rel:!0});var he=r(y);z=o(he,"EM",{});var H=r(z);B=a(H,"seqeval"),H.forEach(s),he.forEach(s),A=a(K,". Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que "),F=o(K,"EM",{});var oe=r(F);I=a(oe,"seqeval"),oe.forEach(s),P=a(K," :"),K.forEach(s),T=c(R),w(W.$$.fragment,R),G=c(R),S=o(R,"P",{});var Q=r(S);X=a(Q,"Nous pouvons ensuite le charger via la fonction "),J=o(Q,"CODE",{});var ue=r(J);le=a(ue,"load_metric()"),ue.forEach(s),N=a(Q," comme nous l\u2019avons fait dans le "),U=o(Q,"A",{href:!0});var Z=r(U);se=a(Z,"chapitre 3"),Z.forEach(s),Y=a(Q," :"),Q.forEach(s),this.h()},h(){_(y,"href","https://github.com/chakki-works/seqeval"),_(y,"rel","nofollow"),_(U,"href","/course/fr/chapter3")},m(R,K){u(R,d,K),e(d,g),e(d,v),e(v,q),e(d,O),e(d,E),e(E,k),e(d,D),e(d,y),e(y,z),e(z,B),e(d,A),e(d,F),e(F,I),e(d,P),u(R,T,K),x(W,R,K),u(R,G,K),u(R,S,K),e(S,X),e(S,J),e(J,le),e(S,N),e(S,U),e(U,se),e(S,Y),ee=!0},i(R){ee||(b(W.$$.fragment,R),ee=!0)},o(R){$(W.$$.fragment,R),ee=!1},d(R){R&&s(d),R&&s(T),C(W,R),R&&s(G),R&&s(S)}}}function ih(V){let d,g,v,q,O,E,k,D,y,z,B,A,F,I,P,T,W,G,S,X,J,le,N,U,se,Y,ee,R,K,me,Me,he,H,oe,Q,ue;return Y=new M({props:{code:"!pip install seqeval",highlighted:"!pip install seqeval"}}),{c(){d=l("p"),g=n("Pour que le "),v=l("code"),q=n("Trainer"),O=n(" calcule une m\xE9trique \xE0 chaque \xE9poque, nous devrons d\xE9finir une fonction "),E=l("code"),k=n("compute_metrics()"),D=n(" qui prend les tableaux de pr\xE9dictions et d\u2019\xE9tiquettes, et retourne un dictionnaire avec les noms et les valeurs des m\xE9triques."),y=p(),z=l("p"),B=n("Le "),A=l("em"),F=n("framework"),I=n(" traditionnel utilis\xE9 pour \xE9valuer la pr\xE9diction de la classification des "),P=l("em"),T=n("tokens"),W=n(" est "),G=l("a"),S=l("em"),X=n("seqeval"),J=n(". Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que "),le=l("em"),N=n("seqeval"),U=n(" :"),se=p(),j(Y.$$.fragment),ee=p(),R=l("p"),K=n("Nous pouvons ensuite le charger via la fonction "),me=l("code"),Me=n("load_metric()"),he=n(" comme nous l\u2019avons fait dans le "),H=l("a"),oe=n("chapitre 3"),Q=n(" :"),this.h()},l(Z){d=o(Z,"P",{});var ce=r(d);g=a(ce,"Pour que le "),v=o(ce,"CODE",{});var ss=r(v);q=a(ss,"Trainer"),ss.forEach(s),O=a(ce," calcule une m\xE9trique \xE0 chaque \xE9poque, nous devrons d\xE9finir une fonction "),E=o(ce,"CODE",{});var _e=r(E);k=a(_e,"compute_metrics()"),_e.forEach(s),D=a(ce," qui prend les tableaux de pr\xE9dictions et d\u2019\xE9tiquettes, et retourne un dictionnaire avec les noms et les valeurs des m\xE9triques."),ce.forEach(s),y=c(Z),z=o(Z,"P",{});var Ee=r(z);B=a(Ee,"Le "),A=o(Ee,"EM",{});var Os=r(A);F=a(Os,"framework"),Os.forEach(s),I=a(Ee," traditionnel utilis\xE9 pour \xE9valuer la pr\xE9diction de la classification des "),P=o(Ee,"EM",{});var ze=r(P);T=a(ze,"tokens"),ze.forEach(s),W=a(Ee," est "),G=o(Ee,"A",{href:!0,rel:!0});var Ne=r(G);S=o(Ne,"EM",{});var ts=r(S);X=a(ts,"seqeval"),ts.forEach(s),Ne.forEach(s),J=a(Ee,". Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que "),le=o(Ee,"EM",{});var ae=r(le);N=a(ae,"seqeval"),ae.forEach(s),U=a(Ee," :"),Ee.forEach(s),se=c(Z),w(Y.$$.fragment,Z),ee=c(Z),R=o(Z,"P",{});var bs=r(R);K=a(bs,"Nous pouvons ensuite le charger via la fonction "),me=o(bs,"CODE",{});var $s=r(me);Me=a($s,"load_metric()"),$s.forEach(s),he=a(bs," comme nous l\u2019avons fait dans le "),H=o(bs,"A",{href:!0});var Ot=r(H);oe=a(Ot,"chapitre 3"),Ot.forEach(s),Q=a(bs," :"),bs.forEach(s),this.h()},h(){_(G,"href","https://github.com/chakki-works/seqeval"),_(G,"rel","nofollow"),_(H,"href","/course/fr/chapter3")},m(Z,ce){u(Z,d,ce),e(d,g),e(d,v),e(v,q),e(d,O),e(d,E),e(E,k),e(d,D),u(Z,y,ce),u(Z,z,ce),e(z,B),e(z,A),e(A,F),e(z,I),e(z,P),e(P,T),e(z,W),e(z,G),e(G,S),e(S,X),e(z,J),e(z,le),e(le,N),e(z,U),u(Z,se,ce),x(Y,Z,ce),u(Z,ee,ce),u(Z,R,ce),e(R,K),e(R,me),e(me,Me),e(R,he),e(R,H),e(H,oe),e(R,Q),ue=!0},i(Z){ue||(b(Y.$$.fragment,Z),ue=!0)},o(Z){$(Y.$$.fragment,Z),ue=!1},d(Z){Z&&s(d),Z&&s(y),Z&&s(z),Z&&s(se),C(Y,Z),Z&&s(ee),Z&&s(R)}}}function uh(V){let d,g,v,q,O,E,k,D,y,z,B,A,F,I,P,T,W,G,S,X,J,le;return T=new M({props:{code:`import numpy as np

all_predictions = []
all_labels = []
for batch in tf_eval_dataset:
    logits = model.predict(batch)["logits"]
    labels = batch["labels"]
    predictions = np.argmax(logits, axis=-1)
    for prediction, label in zip(predictions, labels):
        for predicted_idx, label_idx in zip(prediction, label):
            if label_idx == -100:
                continue
            all_predictions.append(label_names[predicted_idx])
            all_labels.append(label_names[label_idx])
metric.compute(predictions=[all_predictions], references=[all_labels])`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

all_predictions = []
all_labels = []
<span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> tf_eval_dataset:
    logits = model.predict(batch)[<span class="hljs-string">&quot;logits&quot;</span>]
    labels = batch[<span class="hljs-string">&quot;labels&quot;</span>]
    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)
    <span class="hljs-keyword">for</span> prediction, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions, labels):
        <span class="hljs-keyword">for</span> predicted_idx, label_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction, label):
            <span class="hljs-keyword">if</span> label_idx == -<span class="hljs-number">100</span>:
                <span class="hljs-keyword">continue</span>
            all_predictions.append(label_names[predicted_idx])
            all_labels.append(label_names[label_idx])
metric.compute(predictions=[all_predictions], references=[all_labels])`}}),G=new M({props:{code:`{'LOC': {'precision': 0.91, 'recall': 0.92, 'f1': 0.91, 'number': 1668},
 'MISC': {'precision': 0.70, 'recall': 0.79, 'f1': 0.74, 'number': 702},
 'ORG': {'precision': 0.85, 'recall': 0.90, 'f1': 0.88, 'number': 1661},
 'PER': {'precision': 0.95, 'recall': 0.95, 'f1': 0.95, 'number': 1617},
 'overall_precision': 0.87,
 'overall_recall': 0.91,
 'overall_f1': 0.89,
 'overall_accuracy': 0.97}`,highlighted:`{<span class="hljs-string">&#x27;LOC&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">0.91</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.92</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.91</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">1668</span>},
 <span class="hljs-string">&#x27;MISC&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">0.70</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.79</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.74</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">702</span>},
 <span class="hljs-string">&#x27;ORG&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">0.85</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.90</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.88</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">1661</span>},
 <span class="hljs-string">&#x27;PER&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">0.95</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.95</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.95</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">1617</span>},
 <span class="hljs-string">&#x27;overall_precision&#x27;</span>: <span class="hljs-number">0.87</span>,
 <span class="hljs-string">&#x27;overall_recall&#x27;</span>: <span class="hljs-number">0.91</span>,
 <span class="hljs-string">&#x27;overall_f1&#x27;</span>: <span class="hljs-number">0.89</span>,
 <span class="hljs-string">&#x27;overall_accuracy&#x27;</span>: <span class="hljs-number">0.97</span>}`}}),{c(){d=l("p"),g=n("Cela renvoie un batch d\u2019informations ! Nous obtenons la pr\xE9cision, le rappel et le score F1 pour chaque entit\xE9 s\xE9par\xE9e, ainsi que pour l\u2019ensemble. Voyons maintenant ce qui se passe si nous essayons d\u2019utiliser les pr\xE9dictions de notre mod\xE8le pour calculer des scores r\xE9els."),v=p(),q=l("p"),O=n("TensorFlow n\u2019aime pas concat\xE9ner nos pr\xE9dictions ensemble car elles ont des longueurs de s\xE9quence variables. Cela signifie que nous ne pouvons pas simplement utiliser "),E=l("code"),k=n("model.predict()"),D=n(". Mais cela ne va pas nous arr\xEAter. Nous obtiendrons des pr\xE9dictions un batch \xE0 la fois et les concat\xE9nerons en une grande liste longue au fur et \xE0 mesure et en laissant de c\xF4t\xE9 les "),y=l("em"),z=n("tokens"),B=p(),A=l("code"),F=n("-100"),I=n(" qui indiquent le masquage/le remplissage. Puis nous calculerons les m\xE9triques sur la liste \xE0 la fin :"),P=p(),j(T.$$.fragment),W=p(),j(G.$$.fragment),S=p(),X=l("p"),J=n("Comment s\u2019est comport\xE9 votre mod\xE8le, compar\xE9 au n\xF4tre ? Si vous avez obtenu des chiffres similaires, votre entra\xEEnement a \xE9t\xE9 un succ\xE8s !")},l(N){d=o(N,"P",{});var U=r(d);g=a(U,"Cela renvoie un batch d\u2019informations ! Nous obtenons la pr\xE9cision, le rappel et le score F1 pour chaque entit\xE9 s\xE9par\xE9e, ainsi que pour l\u2019ensemble. Voyons maintenant ce qui se passe si nous essayons d\u2019utiliser les pr\xE9dictions de notre mod\xE8le pour calculer des scores r\xE9els."),U.forEach(s),v=c(N),q=o(N,"P",{});var se=r(q);O=a(se,"TensorFlow n\u2019aime pas concat\xE9ner nos pr\xE9dictions ensemble car elles ont des longueurs de s\xE9quence variables. Cela signifie que nous ne pouvons pas simplement utiliser "),E=o(se,"CODE",{});var Y=r(E);k=a(Y,"model.predict()"),Y.forEach(s),D=a(se,". Mais cela ne va pas nous arr\xEAter. Nous obtiendrons des pr\xE9dictions un batch \xE0 la fois et les concat\xE9nerons en une grande liste longue au fur et \xE0 mesure et en laissant de c\xF4t\xE9 les "),y=o(se,"EM",{});var ee=r(y);z=a(ee,"tokens"),ee.forEach(s),B=c(se),A=o(se,"CODE",{});var R=r(A);F=a(R,"-100"),R.forEach(s),I=a(se," qui indiquent le masquage/le remplissage. Puis nous calculerons les m\xE9triques sur la liste \xE0 la fin :"),se.forEach(s),P=c(N),w(T.$$.fragment,N),W=c(N),w(G.$$.fragment,N),S=c(N),X=o(N,"P",{});var K=r(X);J=a(K,"Comment s\u2019est comport\xE9 votre mod\xE8le, compar\xE9 au n\xF4tre ? Si vous avez obtenu des chiffres similaires, votre entra\xEEnement a \xE9t\xE9 un succ\xE8s !"),K.forEach(s)},m(N,U){u(N,d,U),e(d,g),u(N,v,U),u(N,q,U),e(q,O),e(q,E),e(E,k),e(q,D),e(q,y),e(y,z),e(q,B),e(q,A),e(A,F),e(q,I),u(N,P,U),x(T,N,U),u(N,W,U),x(G,N,U),u(N,S,U),u(N,X,U),e(X,J),le=!0},i(N){le||(b(T.$$.fragment,N),b(G.$$.fragment,N),le=!0)},o(N){$(T.$$.fragment,N),$(G.$$.fragment,N),le=!1},d(N){N&&s(d),N&&s(v),N&&s(q),N&&s(P),C(T,N),N&&s(W),C(G,N),N&&s(S),N&&s(X)}}}function ph(V){let d,g,v,q,O,E,k,D,y,z,B,A,F,I,P,T,W,G,S,X,J,le,N,U,se,Y,ee,R,K,me,Me,he;return S=new M({props:{code:`import numpy as np


def compute_metrics(eval_preds):
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)

    # Suppression de l'index ignor\xE9 (tokens sp\xE9ciaux) et conversion en \xE9tiquettes
    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]
    true_predictions = [
        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)
    return {
        "precision": all_metrics["overall_precision"],
        "recall": all_metrics["overall_recall"],
        "f1": all_metrics["overall_f1"],
        "accuracy": all_metrics["overall_accuracy"],
    }`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_preds</span>):
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)

    <span class="hljs-comment"># Suppression de l&#x27;index ignor\xE9 (tokens sp\xE9ciaux) et conversion en \xE9tiquettes</span>
    true_labels = [[label_names[l] <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> label <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels]
    true_predictions = [
        [label_names[p] <span class="hljs-keyword">for</span> (p, l) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction, label) <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>]
        <span class="hljs-keyword">for</span> prediction, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions, labels)
    ]
    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)
    <span class="hljs-keyword">return</span> {
        <span class="hljs-string">&quot;precision&quot;</span>: all_metrics[<span class="hljs-string">&quot;overall_precision&quot;</span>],
        <span class="hljs-string">&quot;recall&quot;</span>: all_metrics[<span class="hljs-string">&quot;overall_recall&quot;</span>],
        <span class="hljs-string">&quot;f1&quot;</span>: all_metrics[<span class="hljs-string">&quot;overall_f1&quot;</span>],
        <span class="hljs-string">&quot;accuracy&quot;</span>: all_metrics[<span class="hljs-string">&quot;overall_accuracy&quot;</span>],
    }`}}),{c(){d=l("p"),g=n("Cela renvoie un batch d\u2019informations ! Nous obtenons la pr\xE9cision, le rappel et le score F1 pour chaque entit\xE9 s\xE9par\xE9e, ainsi que le score global. Pour notre calcul de m\xE9trique, nous ne garderons que le score global, mais n\u2019h\xE9sitez pas \xE0 modifier la fonction "),v=l("code"),q=n("compute_metrics()"),O=n(" pour retourner toutes les m\xE9triques que vous souhaitez."),E=p(),k=l("p"),D=n("Cette fonction "),y=l("code"),z=n("compute_metrics()"),B=n(" prend d\u2019abord l\u2019argmax des logits pour les convertir en pr\xE9dictions (comme d\u2019habitude, les logits et les probabilit\xE9s sont dans le m\xEAme ordre, donc nous n\u2019avons pas besoin d\u2019appliquer la fonction softmax). Ensuite, nous devons convertir les \xE9tiquettes et les pr\xE9dictions des entiers en cha\xEEnes de caract\xE8res. Nous supprimons toutes les valeurs dont l\u2019\xE9tiquette est "),A=l("code"),F=n("-100"),I=n(", puis nous passons les r\xE9sultats \xE0 la m\xE9thode "),P=l("code"),T=n("metric.compute()"),W=n(" :"),G=p(),j(S.$$.fragment),X=p(),J=l("p"),le=n("Maintenant que ceci est fait, nous sommes presque pr\xEAts \xE0 d\xE9finir notre "),N=l("code"),U=n("Trainer"),se=n(". Nous avons juste besoin d\u2019un objet "),Y=l("code"),ee=n("model"),R=n(" pour "),K=l("em"),me=n("finetuner"),Me=n(" !")},l(H){d=o(H,"P",{});var oe=r(d);g=a(oe,"Cela renvoie un batch d\u2019informations ! Nous obtenons la pr\xE9cision, le rappel et le score F1 pour chaque entit\xE9 s\xE9par\xE9e, ainsi que le score global. Pour notre calcul de m\xE9trique, nous ne garderons que le score global, mais n\u2019h\xE9sitez pas \xE0 modifier la fonction "),v=o(oe,"CODE",{});var Q=r(v);q=a(Q,"compute_metrics()"),Q.forEach(s),O=a(oe," pour retourner toutes les m\xE9triques que vous souhaitez."),oe.forEach(s),E=c(H),k=o(H,"P",{});var ue=r(k);D=a(ue,"Cette fonction "),y=o(ue,"CODE",{});var Z=r(y);z=a(Z,"compute_metrics()"),Z.forEach(s),B=a(ue," prend d\u2019abord l\u2019argmax des logits pour les convertir en pr\xE9dictions (comme d\u2019habitude, les logits et les probabilit\xE9s sont dans le m\xEAme ordre, donc nous n\u2019avons pas besoin d\u2019appliquer la fonction softmax). Ensuite, nous devons convertir les \xE9tiquettes et les pr\xE9dictions des entiers en cha\xEEnes de caract\xE8res. Nous supprimons toutes les valeurs dont l\u2019\xE9tiquette est "),A=o(ue,"CODE",{});var ce=r(A);F=a(ce,"-100"),ce.forEach(s),I=a(ue,", puis nous passons les r\xE9sultats \xE0 la m\xE9thode "),P=o(ue,"CODE",{});var ss=r(P);T=a(ss,"metric.compute()"),ss.forEach(s),W=a(ue," :"),ue.forEach(s),G=c(H),w(S.$$.fragment,H),X=c(H),J=o(H,"P",{});var _e=r(J);le=a(_e,"Maintenant que ceci est fait, nous sommes presque pr\xEAts \xE0 d\xE9finir notre "),N=o(_e,"CODE",{});var Ee=r(N);U=a(Ee,"Trainer"),Ee.forEach(s),se=a(_e,". Nous avons juste besoin d\u2019un objet "),Y=o(_e,"CODE",{});var Os=r(Y);ee=a(Os,"model"),Os.forEach(s),R=a(_e," pour "),K=o(_e,"EM",{});var ze=r(K);me=a(ze,"finetuner"),ze.forEach(s),Me=a(_e," !"),_e.forEach(s)},m(H,oe){u(H,d,oe),e(d,g),e(d,v),e(v,q),e(d,O),u(H,E,oe),u(H,k,oe),e(k,D),e(k,y),e(y,z),e(k,B),e(k,A),e(A,F),e(k,I),e(k,P),e(P,T),e(k,W),u(H,G,oe),x(S,H,oe),u(H,X,oe),u(H,J,oe),e(J,le),e(J,N),e(N,U),e(J,se),e(J,Y),e(Y,ee),e(J,R),e(J,K),e(K,me),e(J,Me),he=!0},i(H){he||(b(S.$$.fragment,H),he=!0)},o(H){$(S.$$.fragment,H),he=!1},d(H){H&&s(d),H&&s(E),H&&s(k),H&&s(G),C(S,H),H&&s(X),H&&s(J)}}}function Rv(V){let d,g,v,q,O,E,k,D,y,z,B,A,F,I,P,T,W,G,S,X,J,le,N,U,se,Y,ee,R,K,me,Me,he,H,oe,Q,ue,Z,ce,ss,_e,Ee,Os,ze,Ne,ts,ae,bs,$s,Ot,Ea,te,qa,pn,Ps,ka,ja,pt,ns,cn,Re,dn,as,ct,Oe,Fe,Ds,ls,wa,os,dt,xa,mn,fn,Pe,vn,mt,Ca,Gn,gs,Ws,rs,Ms,Ns,Pt,Xs,hn,Dt,Zs,Un,je,ft,Vn,we,Mt,_n,pe,is,bn,Ks,vt,Nt,Wn,Ys,At,us,Tt,fe,ya,St,Es,Ze,Js,Ae,za,As,Oa,Xn,xe,$n,gn,Zn,Te,ht,En,qn,Kn,qs,kn,Be,ps,ks,_t,Lt,Ts,Yn,Ce,Se,It,js,Pa,Ss,bt,Da,Jn,cs,$t,Rt,ws,Ma,gt,Qs,et,st,Ke,jn,He,wn,ie,Qn,$e,Na,xn,Et,Aa,Cn,qt,Ta,yn,Ft,Bt,zn,On,Ye,Pn,f,L,Dn,Sa,Ls,be,Mn,xs,La,Is,Ht,Nn,kt,Gt,Ut,Vt,Rs,jt,Fs,ve,Wt,tt,ql,An,ea,Tn,ds,Xt,sa,ta,na,Je,kl,aa,la,jl,wt,xt,Ct,Ge,nt,Bs,oa,Ue,wl,Ia,at,Ra,Hs,Sn,De,Ve,ra,ia,xl,Cl,yt,Ln,Uo,ua,eo,so,Zr,to,Vo,Fa,Wo,Cs,yl,lt,Kr,Ba,Yr,Jr,Ha,Qr,ei,no,Zt,ao,Xo,Ga,zl,ys,si,Ua,ti,ni,lo,Kt,oo,ro,ai,io,uo,li,po,Zo,Va,co,Yt,Ko,Wa,Xa,mo,zt,fo,We,oi,Za,ri,ii,Ka,ui,pi,vo,Gs,In,pa,Ya,Yo,Jt,Jo,Qt,ms,ho,Rn,ci,_o,bo,Qo,Ja,$o,ye,er,ca,di,sr,Us,Qa,mi,el,fi,vi,go,Vs,hi,sl,_i,bi,Ol,en,$i,tl,gi,Ei,nl,qi,ki,tr,Xe,nr,re,ji,Eo,qo,wi,ko,jo,xi,al,wo,Ci,xo,ar,Pl,Co,lr,ll,Dl,da,yi,Fn,zi,Oi,Ml,ol,or,ge,Pi,yo,zo,Di,Oo,rr,rl,Nl,il,ir,ot,Mi,Po,Do,Ni,Mo,No,Ai,ur,Bn,pr,ul,Ao,ne,Ti,pl,Si,Li,Hn,To,Ii,So,cr;return q=new ut({}),H=new M({props:{code:`id2label = {str(i): label for i, label in enumerate(label_names)}
label2id = {v: k for k, v in id2label.items()}`,highlighted:`id2label = {<span class="hljs-built_in">str</span>(i): label <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(label_names)}
label2id = {v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> id2label.items()}`}}),Ne=new M({props:{code:`from transformers import AutoModelForTokenClassification

model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification

model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)`}}),ns=new M({props:{code:"model.config.num_labels",highlighted:"model.config.num_labels"}}),Re=new M({props:{code:"9",highlighted:'<span class="hljs-number">9</span>'}}),as=new Xr({props:{warning:!0,$$slots:{default:[ch]},$$scope:{ctx:V}}}),ls=new ut({}),Ns=new M({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`}}),is=new M({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}}),us=new M({props:{code:`from transformers import TrainingArguments

args = TrainingArguments(
    "bert-finetuned-ner",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
    push_to_hub=True,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

args = TrainingArguments(
    <span class="hljs-string">&quot;bert-finetuned-ner&quot;</span>,
    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    num_train_epochs=<span class="hljs-number">3</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
    push_to_hub=<span class="hljs-literal">True</span>,
)`}}),Be=new Xr({props:{$$slots:{default:[dh]},$$scope:{ctx:V}}}),Se=new M({props:{code:`from transformers import Trainer

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer,
)
trainer.train()`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],
    data_collator=data_collator,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer,
)
trainer.train()`}}),Qs=new M({props:{code:'trainer.push_to_hub(commit_message="Training complete")',highlighted:'trainer.push_to_hub(commit_message=<span class="hljs-string">&quot;Training complete&quot;</span>)'}}),He=new M({props:{code:"'https://huggingface.co/sgugger/bert-finetuned-ner/commit/26ab21e5b1568f9afeccdaed2d8715f571d786ed'",highlighted:'<span class="hljs-string">&#x27;https://huggingface.co/sgugger/bert-finetuned-ner/commit/26ab21e5b1568f9afeccdaed2d8715f571d786ed&#x27;</span>'}}),xs=new ut({}),tt=new ut({}),Ct=new M({props:{code:`from torch.utils.data import DataLoader

train_dataloader = DataLoader(
    tokenized_datasets["train"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
)
eval_dataloader = DataLoader(
    tokenized_datasets["validation"], collate_fn=data_collator, batch_size=8
)`,highlighted:`<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

train_dataloader = DataLoader(
    tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    shuffle=<span class="hljs-literal">True</span>,
    collate_fn=data_collator,
    batch_size=<span class="hljs-number">8</span>,
)
eval_dataloader = DataLoader(
    tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>], collate_fn=data_collator, batch_size=<span class="hljs-number">8</span>
)`}}),at=new M({props:{code:`model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)`,highlighted:`model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint,
    id2label=id2label,
    label2id=label2id,
)`}}),Ln=new M({props:{code:`from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)`,highlighted:`<span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW

optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">2e-5</span>)`}}),Fa=new M({props:{code:`from accelerate import Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)`,highlighted:`<span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)`}}),Cs=new Xr({props:{$$slots:{default:[mh]},$$scope:{ctx:V}}}),Ga=new M({props:{code:`from transformers import get_scheduler

num_train_epochs = 3
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler

num_train_epochs = <span class="hljs-number">3</span>
num_update_steps_per_epoch = <span class="hljs-built_in">len</span>(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    <span class="hljs-string">&quot;linear&quot;</span>,
    optimizer=optimizer,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_training_steps=num_training_steps,
)`}}),Va=new M({props:{code:`from huggingface_hub import Repository, get_full_repo_name

model_name = "bert-finetuned-ner-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> Repository, get_full_repo_name

model_name = <span class="hljs-string">&quot;bert-finetuned-ner-accelerate&quot;</span>
repo_name = get_full_repo_name(model_name)
repo_name`}}),Yt=new M({props:{code:"'sgugger/bert-finetuned-ner-accelerate'",highlighted:'<span class="hljs-string">&#x27;sgugger/bert-finetuned-ner-accelerate&#x27;</span>'}}),zt=new M({props:{code:`output_dir = "bert-finetuned-ner-accelerate"
repo = Repository(output_dir, clone_from=repo_name)`,highlighted:`output_dir = <span class="hljs-string">&quot;bert-finetuned-ner-accelerate&quot;</span>
repo = Repository(output_dir, clone_from=repo_name)`}}),Ya=new ut({}),ye=new M({props:{code:`def postprocess(predictions, labels):
    predictions = predictions.detach().cpu().clone().numpy()
    labels = labels.detach().cpu().clone().numpy()

    # Suppression de l'index ignor\xE9 (tokens sp\xE9ciaux) et conversion en \xE9tiquettes
    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]
    true_predictions = [
        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    return true_labels, true_predictions`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">postprocess</span>(<span class="hljs-params">predictions, labels</span>):
    predictions = predictions.detach().cpu().clone().numpy()
    labels = labels.detach().cpu().clone().numpy()

    <span class="hljs-comment"># Suppression de l&#x27;index ignor\xE9 (tokens sp\xE9ciaux) et conversion en \xE9tiquettes</span>
    true_labels = [[label_names[l] <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> label <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels]
    true_predictions = [
        [label_names[p] <span class="hljs-keyword">for</span> (p, l) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction, label) <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>]
        <span class="hljs-keyword">for</span> prediction, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions, labels)
    ]
    <span class="hljs-keyword">return</span> true_labels, true_predictions`}}),ll=new M({props:{code:`from tqdm.auto import tqdm
import torch

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
    # Entra\xEEnement
    model.train()
    for batch in train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # Evaluation
    model.eval()
    for batch in eval_dataloader:
        with torch.no_grad():
            outputs = model(**batch)

        predictions = outputs.logits.argmax(dim=-1)
        labels = batch["labels"]

        # N\xE9cessaire pour rembourrer les pr\xE9dictions et les \xE9tiquettes \xE0 rassembler
        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)
        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)

        predictions_gathered = accelerator.gather(predictions)
        labels_gathered = accelerator.gather(labels)

        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)
        metric.add_batch(predictions=true_predictions, references=true_labels)

    results = metric.compute()
    print(
        f"epoch {epoch}:",
        {
            key: results[f"overall_{key}"]
            for key in ["precision", "recall", "f1", "accuracy"]
        },
    )

    # Sauvegarder et t\xE9l\xE9charger
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=f"Training in progress epoch {epoch}", blocking=False
        )`,highlighted:`<span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm
<span class="hljs-keyword">import</span> torch

progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_train_epochs):
    <span class="hljs-comment"># Entra\xEEnement</span>
    model.train()
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(<span class="hljs-number">1</span>)

    <span class="hljs-comment"># Evaluation</span>
    model.<span class="hljs-built_in">eval</span>()
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> eval_dataloader:
        <span class="hljs-keyword">with</span> torch.no_grad():
            outputs = model(**batch)

        predictions = outputs.logits.argmax(dim=-<span class="hljs-number">1</span>)
        labels = batch[<span class="hljs-string">&quot;labels&quot;</span>]

        <span class="hljs-comment"># N\xE9cessaire pour rembourrer les pr\xE9dictions et les \xE9tiquettes \xE0 rassembler</span>
        predictions = accelerator.pad_across_processes(predictions, dim=<span class="hljs-number">1</span>, pad_index=-<span class="hljs-number">100</span>)
        labels = accelerator.pad_across_processes(labels, dim=<span class="hljs-number">1</span>, pad_index=-<span class="hljs-number">100</span>)

        predictions_gathered = accelerator.gather(predictions)
        labels_gathered = accelerator.gather(labels)

        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)
        metric.add_batch(predictions=true_predictions, references=true_labels)

    results = metric.compute()
    <span class="hljs-built_in">print</span>(
        <span class="hljs-string">f&quot;epoch <span class="hljs-subst">{epoch}</span>:&quot;</span>,
        {
            key: results[<span class="hljs-string">f&quot;overall_<span class="hljs-subst">{key}</span>&quot;</span>]
            <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;precision&quot;</span>, <span class="hljs-string">&quot;recall&quot;</span>, <span class="hljs-string">&quot;f1&quot;</span>, <span class="hljs-string">&quot;accuracy&quot;</span>]
        },
    )

    <span class="hljs-comment"># Sauvegarder et t\xE9l\xE9charger</span>
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    <span class="hljs-keyword">if</span> accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=<span class="hljs-string">f&quot;Training in progress epoch <span class="hljs-subst">{epoch}</span>&quot;</span>, blocking=<span class="hljs-literal">False</span>
        )`}}),ol=new M({props:{code:`accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)`,highlighted:`accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)`}}),{c(){d=l("h3"),g=l("a"),v=l("span"),j(q.$$.fragment),O=p(),E=l("span"),k=n("D\xE9finir le mod\xE8le"),D=p(),y=l("p"),z=n("Puisque nous travaillons sur un probl\xE8me de classification de "),B=l("em"),A=n("tokens"),F=n(", nous allons utiliser la classe "),I=l("code"),P=n("AutoModelForTokenClassification"),T=n(". La principale chose \xE0 retenir lors de la d\xE9finition de ce mod\xE8le est de transmettre des informations sur le nombre d\u2019\xE9tiquettes que nous avons. La fa\xE7on la plus simple de le faire est de passer ce nombre avec l\u2019argument "),W=l("code"),G=n("num_labels"),S=n(", mais si nous voulons un joli "),X=l("em"),J=n("widget"),le=n(" d\u2019inf\xE9rence fonctionnant comme celui que nous avons vu au d\xE9but de cette section, il est pr\xE9f\xE9rable de d\xE9finir les correspondances des \xE9tiquettes \xE0 la place."),N=p(),U=l("p"),se=n("Elles devraient \xEAtre d\xE9finies par deux dictionnaires, "),Y=l("code"),ee=n("id2label"),R=n(" et "),K=l("code"),me=n("label2id"),Me=n(", qui contiennent les correspondances entre identifiants et \xE9tiquettes et vice versa :"),he=p(),j(H.$$.fragment),oe=p(),Q=l("p"),ue=n("Maintenant nous pouvons simplement les passer \xE0 la m\xE9thode "),Z=l("code"),ce=n("AutoModelForTokenClassification.from_pretrained()"),ss=n(", ils seront d\xE9finis dans la configuration du mod\xE8le puis correctement sauvegard\xE9s et t\xE9l\xE9charg\xE9s vers le "),_e=l("em"),Ee=n("Hub"),Os=n(" :"),ze=p(),j(Ne.$$.fragment),ts=p(),ae=l("p"),bs=n("Comme lorsque nous avons d\xE9fini notre "),$s=l("code"),Ot=n("AutoModelForSequenceClassification"),Ea=n(" au "),te=l("a"),qa=n("chapitre 3"),pn=n(", la cr\xE9ation du mod\xE8le \xE9met un avertissement indiquant que certains poids n\u2019ont pas \xE9t\xE9 utilis\xE9s (ceux de la t\xEAte de pr\xE9-entra\xEEnement) et que d\u2019autres poids ont \xE9t\xE9 initialis\xE9s de mani\xE8re al\xE9atoire (ceux de la t\xEAte de classification des nouveaux "),Ps=l("em"),ka=n("tokens"),ja=n("), et que ce mod\xE8le doit \xEAtre entra\xEEn\xE9. Nous ferons cela dans une minute, mais v\xE9rifions d\u2019abord que notre mod\xE8le a le bon nombre d\u2019\xE9tiquettes :"),pt=p(),j(ns.$$.fragment),cn=p(),j(Re.$$.fragment),dn=p(),j(as.$$.fragment),ct=p(),Oe=l("h3"),Fe=l("a"),Ds=l("span"),j(ls.$$.fragment),wa=p(),os=l("span"),dt=l("i"),xa=n("Finetuning"),mn=n(" du mod\xE8le"),fn=p(),Pe=l("p"),vn=n("Nous sommes maintenant pr\xEAts \xE0 entra\xEEner notre mod\xE8le ! Nous devons juste faire deux derni\xE8res choses avant de d\xE9finir notre "),mt=l("code"),Ca=n("Trainer"),Gn=n(" : se connecter \xE0 Hugging Face et d\xE9finir nos arguments d\u2019entra\xEEnement. Si vous travaillez dans un "),gs=l("em"),Ws=n("notebook"),rs=n(", il y a une fonction pratique pour vous aider \xE0 le faire :"),Ms=p(),j(Ns.$$.fragment),Pt=p(),Xs=l("p"),hn=n("Cela affichera un "),Dt=l("em"),Zs=n("widget"),Un=n(" o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),je=p(),ft=l("p"),Vn=n("Si vous ne travaillez pas dans un "),we=l("em"),Mt=n("notebook"),_n=n(", tapez simplement la ligne suivante dans votre terminal :"),pe=p(),j(is.$$.fragment),bn=p(),Ks=l("p"),vt=n("Une fois ceci fait, nous pouvons d\xE9finir nos "),Nt=l("code"),Wn=n("TrainingArguments"),Ys=n(" :"),At=p(),j(us.$$.fragment),Tt=p(),fe=l("p"),ya=n("Vous avez d\xE9j\xE0 vu la plupart d\u2019entre eux. Nous d\xE9finissons quelques hyperparam\xE8tres (comme le taux d\u2019apprentissage, le nombre d\u2019\xE9poques \xE0 entra\xEEner, et le taux de d\xE9croissance des poids), et nous sp\xE9cifions "),St=l("code"),Es=n("push_to_hub=True"),Ze=n(" pour indiquer que nous voulons sauvegarder le mod\xE8le, l\u2019\xE9valuer \xE0 la fin de chaque \xE9poque, et que nous voulons t\xE9l\xE9charger nos r\xE9sultats vers le "),Js=l("em"),Ae=n("Hub"),za=n(". Notez que vous pouvez sp\xE9cifier le nom du d\xE9p\xF4t vers lequel vous voulez pousser avec l\u2019argument "),As=l("code"),Oa=n("hub_model_id"),Xn=n(" (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),xe=l("a"),$n=l("code"),gn=n("huggingface-course"),Zn=n(", nous avons ajout\xE9 "),Te=l("code"),ht=n('hub_model_id="huggingface-course/bert-finetuned-ner"``TrainingArguments'),En=n(". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace de noms et nomm\xE9 d\u2019apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, donc dans notre cas ce sera "),qn=l("code"),Kn=n('"sgugger/bert-finetuned-ner"'),qs=n("."),kn=p(),j(Be.$$.fragment),ps=p(),ks=l("p"),_t=n("Enfin, nous passons tout au "),Lt=l("code"),Ts=n("Trainer"),Yn=n(" et lan\xE7ons l\u2019entra\xEEnement :"),Ce=p(),j(Se.$$.fragment),It=p(),js=l("p"),Pa=n("Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),Ss=l("em"),bt=n("Hub"),Da=n(" en arri\xE8re-plan. De cette fa\xE7on, vous serez en mesure de reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),Jn=p(),cs=l("p"),$t=n("Une fois l\u2019entra\xEEnement termin\xE9, nous utilisons la m\xE9thode "),Rt=l("code"),ws=n("push_to_hub()"),Ma=n(" pour nous assurer que nous t\xE9l\xE9chargeons la version la plus r\xE9cente du mod\xE8le :"),gt=p(),j(Qs.$$.fragment),et=p(),st=l("p"),Ke=n("Cette commande renvoie l\u2019URL du commit qu\u2019elle vient de faire, si vous voulez l\u2019inspecter :"),jn=p(),j(He.$$.fragment),wn=p(),ie=l("p"),Qn=n("Le "),$e=l("code"),Na=n("Trainer"),xn=n(" r\xE9dige \xE9galement une carte mod\xE8le avec tous les r\xE9sultats de l\u2019\xE9valuation et la t\xE9l\xE9charge. A ce stade, vous pouvez utiliser le "),Et=l("em"),Aa=n("widget"),Cn=n(" d\u2019inf\xE9rence sur le "),qt=l("em"),Ta=n("Hub"),yn=n(" pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 affiner un mod\xE8le sur une t\xE2che de classification de "),Ft=l("em"),Bt=n("tokens"),zn=n(". F\xE9licitations !"),On=p(),Ye=l("p"),Pn=n("Si vous voulez plonger un peu plus profond\xE9ment dans la boucle d\u2019entra\xEEnement, nous allons maintenant vous montrer comment faire la m\xEAme chose en utilisant \u{1F917} "),f=l("em"),L=n("Accelerate"),Dn=n("."),Sa=p(),Ls=l("h2"),be=l("a"),Mn=l("span"),j(xs.$$.fragment),La=p(),Is=l("span"),Ht=n("Une boucle d'entra\xEEnement personnalis\xE9e"),Nn=p(),kt=l("p"),Gt=n("Jetons maintenant un coup d\u2019\u0153il \xE0 la boucle d\u2019entra\xEEnement compl\xE8te afin que vous puissiez facilement personnaliser les parties dont vous avez besoin. Elle ressemblera beaucoup \xE0 ce que nous avons fait dans le "),Ut=l("a"),Vt=n("chapitre 3"),Rs=n(" avec quelques changements pour l\u2019\xE9valuation."),jt=p(),Fs=l("h3"),ve=l("a"),Wt=l("span"),j(tt.$$.fragment),ql=p(),An=l("span"),ea=n("Pr\xE9parer tout pour l'entra\xEEnement"),Tn=p(),ds=l("p"),Xt=n("D\u2019abord nous devons construire le "),sa=l("code"),ta=n("DataLoader"),na=n("s \xE0 partir de nos jeux de donn\xE9es. Nous r\xE9utilisons notre "),Je=l("code"),kl=n("data_collator"),aa=n(" comme un "),la=l("code"),jl=n("collate_fn"),wt=n(" et m\xE9langer l\u2019ensemble d\u2019entra\xEEnement, mais pas l\u2019ensemble de validation :"),xt=p(),j(Ct.$$.fragment),Ge=p(),nt=l("p"),Bs=n("Ensuite, nous r\xE9instantifions notre mod\xE8le pour nous assurer que nous ne continuons pas le "),oa=l("em"),Ue=n("finetuning"),wl=n(" d\u2019avant et que nous repartons bien du mod\xE8le pr\xE9-entra\xEEn\xE9 de BERT :"),Ia=p(),j(at.$$.fragment),Ra=p(),Hs=l("p"),Sn=n("Ensuite, nous avons besoin d\u2019un optimiseur. Nous utilisons le classique "),De=l("code"),Ve=n("AdamW"),ra=n(", qui est comme "),ia=l("code"),xl=n("Adam"),Cl=n(", mais avec un correctif dans la fa\xE7on dont le taux de d\xE9croissance des poids est appliqu\xE9e :"),yt=p(),j(Ln.$$.fragment),Uo=p(),ua=l("p"),eo=n("Une fois que nous avons tous ces objets, nous pouvons les envoyer \xE0 la m\xE9thode "),so=l("code"),Zr=n("accelerator.prepare()"),to=n(" :"),Vo=p(),j(Fa.$$.fragment),Wo=p(),j(Cs.$$.fragment),yl=p(),lt=l("p"),Kr=n("Maintenant que nous avons envoy\xE9 notre "),Ba=l("code"),Yr=n("train_dataloader"),Jr=n(" \xE0 "),Ha=l("code"),Qr=n("accelerator.prepare()"),ei=n(", nous pouvons utiliser sa longueur pour calculer le nombre d\u2019\xE9tapes d\u2019entra\xEEnement. Rappelez-vous que nous devrions toujours faire cela apr\xE8s avoir pr\xE9par\xE9 le "),no=l("em"),Zt=n("dataloader"),ao=n(" car cette m\xE9thode modifiera sa longueur. Nous utilisons un programme lin\xE9aire classique du taux d\u2019apprentissage \xE0 0 :"),Xo=p(),j(Ga.$$.fragment),zl=p(),ys=l("p"),si=n("Enfin, pour pousser notre mod\xE8le vers le "),Ua=l("em"),ti=n("Hub"),ni=n(", nous avons besoin de cr\xE9er un objet "),lo=l("code"),Kt=n("Repository"),oo=n(" dans un dossier de travail. Tout d\u2019abord, connectez-vous \xE0 Hugging Face si vous n\u2019\xEAtes pas d\xE9j\xE0 connect\xE9. Nous d\xE9terminons le nom du d\xE9p\xF4t \xE0 partir de l\u2019identifiant du mod\xE8le que nous voulons donner \xE0 notre mod\xE8le (n\u2019h\xE9sitez pas \xE0 remplacer le "),ro=l("code"),ai=n("repo_name"),io=n(" par votre propre choix, il doit juste contenir votre nom d\u2019utilisateur et ce que fait la fonction "),uo=l("code"),li=n("get_full_repo_name()"),po=n(") :"),Zo=p(),j(Va.$$.fragment),co=p(),j(Yt.$$.fragment),Ko=p(),Wa=l("p"),Xa=n("Ensuite, nous pouvons cloner ce d\xE9p\xF4t dans un dossier local. S\u2019il existe d\xE9j\xE0, ce dossier local doit \xEAtre un clone existant du r\xE9f\xE9rentiel avec lequel nous travaillons :"),mo=p(),j(zt.$$.fragment),fo=p(),We=l("p"),oi=n("Nous pouvons maintenant t\xE9l\xE9charger tout ce que nous sauvegardons dans "),Za=l("code"),ri=n("output_dir"),ii=n(" en appelant la m\xE9thode "),Ka=l("code"),ui=n("repo.push_to_hub()"),pi=n(". Cela nous aidera \xE0 t\xE9l\xE9charger les mod\xE8les interm\xE9diaires \xE0 la fin de chaque \xE9poque."),vo=p(),Gs=l("h3"),In=l("a"),pa=l("span"),j(Ya.$$.fragment),Yo=p(),Jt=l("span"),Jo=n("Boucle d'entra\xEEnement"),Qt=p(),ms=l("p"),ho=n("Nous sommes maintenant pr\xEAts \xE0 \xE9crire la boucle d\u2019entra\xEEnement compl\xE8te. Pour simplifier sa partie \xE9valuation, nous d\xE9finissons cette fonction "),Rn=l("code"),ci=n("postprocess()"),_o=n(" qui prend les pr\xE9dictions et les \xE9tiquettes, et les convertit en listes de cha\xEEnes de caract\xE8res comme notre objet "),bo=l("code"),Qo=n("metric"),Ja=n(" l\u2019attend :"),$o=p(),j(ye.$$.fragment),er=p(),ca=l("p"),di=n("Ensuite, nous pouvons \xE9crire la boucle d\u2019entra\xEEnement. Apr\xE8s avoir d\xE9fini une barre de progression pour suivre l\u2019\xE9volution de l\u2019entra\xEEnement, la boucle comporte trois parties :"),sr=p(),Us=l("ul"),Qa=l("li"),mi=n("L\u2019entra\xEEnement proprement dit, qui est l\u2019it\xE9ration classique sur le "),el=l("code"),fi=n("train_dataloader"),vi=n(", passage en avant, puis passage en arri\xE8re et \xE9tape d\u2019optimisation."),go=p(),Vs=l("li"),hi=n("L\u2019\xE9valuation, dans laquelle il y a une nouveaut\xE9 apr\xE8s avoir obtenu les sorties de notre mod\xE8le sur un batch : puisque deux processus peuvent avoir padd\xE9 les entr\xE9es et les \xE9tiquettes \xE0 des formes diff\xE9rentes, nous devons utiliser "),sl=l("code"),_i=n("accelerator.pad_across_processes()"),bi=n(" pour rendre les pr\xE9dictions et les \xE9tiquettes de la m\xEAme forme avant d\u2019appeler la m\xE9thode "),Ol=l("code"),en=n("gather()"),$i=n(". Si nous ne le faisons pas, l\u2019\xE9valuation va soit se tromper, soit se bloquer pour toujours. Ensuite, nous envoyons les r\xE9sultats \xE0 "),tl=l("code"),gi=n("metric.add_batch()"),Ei=n(" et appelons "),nl=l("code"),qi=n("metric.compute()"),ki=n(" une fois que la boucle d\u2019\xE9valuation est termin\xE9e."),tr=p(),Xe=l("li"),nr=n("Sauvegarde et t\xE9l\xE9chargement, o\xF9 nous sauvegardons d\u2019abord le mod\xE8le et le "),re=l("em"),ji=n("tokenizer"),Eo=n(", puis appelons "),qo=l("code"),wi=n("repo.push_to_hub()"),ko=n(". Remarquez que nous utilisons l\u2019argument "),jo=l("code"),xi=n("blocking=False"),al=n(" pour indiquer \xE0 la biblioth\xE8que \u{1F917} "),wo=l("em"),Ci=n("Hub"),xo=n(" de pousser dans un processus asynchrone. De cette fa\xE7on, l\u2019entra\xEEnement continue normalement et cette (longue) instruction est ex\xE9cut\xE9e en arri\xE8re-plan."),ar=p(),Pl=l("p"),Co=n("Voici le code complet de la boucle d\u2019entra\xEEnement :"),lr=p(),j(ll.$$.fragment),Dl=p(),da=l("p"),yi=n("Au cas o\xF9 ce serait la premi\xE8re fois que vous verriez un mod\xE8le enregistr\xE9 avec \u{1F917} "),Fn=l("em"),zi=n("Accelerate"),Oi=n(", prenons un moment pour inspecter les trois lignes de code qui l\u2019accompagnent :"),Ml=p(),j(ol.$$.fragment),or=p(),ge=l("p"),Pi=n("La premi\xE8re ligne est explicite : elle indique \xE0 tous les processus d\u2019attendre que tout le monde soit \xE0 ce stade avant de continuer. C\u2019est pour s\u2019assurer que nous avons le m\xEAme mod\xE8le dans chaque processus avant de sauvegarder. Ensuite, nous prenons le "),yo=l("code"),zo=n("unwrapped_model"),Di=n(" qui est le mod\xE8le de base que nous avons d\xE9fini. La m\xE9thode "),Oo=l("code"),rr=n("accelerator.prepare()"),rl=n(" modifie le mod\xE8le pour qu\u2019il fonctionne dans l\u2019entra\xEEnement distribu\xE9, donc il n\u2019aura plus la m\xE9thode "),Nl=l("code"),il=n("save_pretrained()"),ir=n(" ; la m\xE9thode "),ot=l("code"),Mi=n("accelerator.unwrap_model()"),Po=n(" annule cette \xE9tape. Enfin, nous appelons "),Do=l("code"),Ni=n("save_pretrained()"),Mo=n(" mais nous disons \xE0 cette m\xE9thode d\u2019utiliser "),No=l("code"),Ai=n("accelerator.save()"),ur=n(" au lieu de "),Bn=l("code"),pr=n("torch.save()"),ul=n("."),Ao=p(),ne=l("p"),Ti=n("Une fois ceci fait, vous devriez avoir un mod\xE8le qui produit des r\xE9sultats assez similaires \xE0 celui entra\xEEn\xE9 avec le "),pl=l("code"),Si=n("Trainer"),Li=n(". Vous pouvez v\xE9rifier le mod\xE8le que nous avons form\xE9 en utilisant ce code \xE0 "),Hn=l("a"),To=l("em"),Ii=n("huggingface-course/bert-finetuned-ner-accelerate"),So=n(". Et si vous voulez tester des modifications de la boucle d\u2019entra\xEEnement, vous pouvez les impl\xE9menter directement en modifiant le code ci-dessus !"),this.h()},l(i){d=o(i,"H3",{class:!0});var h=r(d);g=o(h,"A",{id:!0,class:!0,href:!0});var Cu=r(g);v=o(Cu,"SPAN",{});var yu=r(v);w(q.$$.fragment,yu),yu.forEach(s),Cu.forEach(s),O=c(h),E=o(h,"SPAN",{});var dr=r(E);k=a(dr,"D\xE9finir le mod\xE8le"),dr.forEach(s),h.forEach(s),D=c(i),y=o(i,"P",{});var sn=r(y);z=a(sn,"Puisque nous travaillons sur un probl\xE8me de classification de "),B=o(sn,"EM",{});var zu=r(B);A=a(zu,"tokens"),zu.forEach(s),F=a(sn,", nous allons utiliser la classe "),I=o(sn,"CODE",{});var mr=r(I);P=a(mr,"AutoModelForTokenClassification"),mr.forEach(s),T=a(sn,". La principale chose \xE0 retenir lors de la d\xE9finition de ce mod\xE8le est de transmettre des informations sur le nombre d\u2019\xE9tiquettes que nous avons. La fa\xE7on la plus simple de le faire est de passer ce nombre avec l\u2019argument "),W=o(sn,"CODE",{});var Ou=r(W);G=a(Ou,"num_labels"),Ou.forEach(s),S=a(sn,", mais si nous voulons un joli "),X=o(sn,"EM",{});var Pu=r(X);J=a(Pu,"widget"),Pu.forEach(s),le=a(sn," d\u2019inf\xE9rence fonctionnant comme celui que nous avons vu au d\xE9but de cette section, il est pr\xE9f\xE9rable de d\xE9finir les correspondances des \xE9tiquettes \xE0 la place."),sn.forEach(s),N=c(i),U=o(i,"P",{});var ma=r(U);se=a(ma,"Elles devraient \xEAtre d\xE9finies par deux dictionnaires, "),Y=o(ma,"CODE",{});var Du=r(Y);ee=a(Du,"id2label"),Du.forEach(s),R=a(ma," et "),K=o(ma,"CODE",{});var Mu=r(K);me=a(Mu,"label2id"),Mu.forEach(s),Me=a(ma,", qui contiennent les correspondances entre identifiants et \xE9tiquettes et vice versa :"),ma.forEach(s),he=c(i),w(H.$$.fragment,i),oe=c(i),Q=o(i,"P",{});var fa=r(Q);ue=a(fa,"Maintenant nous pouvons simplement les passer \xE0 la m\xE9thode "),Z=o(fa,"CODE",{});var Nu=r(Z);ce=a(Nu,"AutoModelForTokenClassification.from_pretrained()"),Nu.forEach(s),ss=a(fa,", ils seront d\xE9finis dans la configuration du mod\xE8le puis correctement sauvegard\xE9s et t\xE9l\xE9charg\xE9s vers le "),_e=o(fa,"EM",{});var Au=r(_e);Ee=a(Au,"Hub"),Au.forEach(s),Os=a(fa," :"),fa.forEach(s),ze=c(i),w(Ne.$$.fragment,i),ts=c(i),ae=o(i,"P",{});var tn=r(ae);bs=a(tn,"Comme lorsque nous avons d\xE9fini notre "),$s=o(tn,"CODE",{});var Tu=r($s);Ot=a(Tu,"AutoModelForSequenceClassification"),Tu.forEach(s),Ea=a(tn," au "),te=o(tn,"A",{href:!0});var Su=r(te);qa=a(Su,"chapitre 3"),Su.forEach(s),pn=a(tn,", la cr\xE9ation du mod\xE8le \xE9met un avertissement indiquant que certains poids n\u2019ont pas \xE9t\xE9 utilis\xE9s (ceux de la t\xEAte de pr\xE9-entra\xEEnement) et que d\u2019autres poids ont \xE9t\xE9 initialis\xE9s de mani\xE8re al\xE9atoire (ceux de la t\xEAte de classification des nouveaux "),Ps=o(tn,"EM",{});var Ri=r(Ps);ka=a(Ri,"tokens"),Ri.forEach(s),ja=a(tn,"), et que ce mod\xE8le doit \xEAtre entra\xEEn\xE9. Nous ferons cela dans une minute, mais v\xE9rifions d\u2019abord que notre mod\xE8le a le bon nombre d\u2019\xE9tiquettes :"),tn.forEach(s),pt=c(i),w(ns.$$.fragment,i),cn=c(i),w(Re.$$.fragment,i),dn=c(i),w(as.$$.fragment,i),ct=c(i),Oe=o(i,"H3",{class:!0});var fs=r(Oe);Fe=o(fs,"A",{id:!0,class:!0,href:!0});var Lu=r(Fe);Ds=o(Lu,"SPAN",{});var fr=r(Ds);w(ls.$$.fragment,fr),fr.forEach(s),Lu.forEach(s),wa=c(fs),os=o(fs,"SPAN",{});var Fi=r(os);dt=o(Fi,"I",{});var Iu=r(dt);xa=a(Iu,"Finetuning"),Iu.forEach(s),mn=a(Fi," du mod\xE8le"),Fi.forEach(s),fs.forEach(s),fn=c(i),Pe=o(i,"P",{});var va=r(Pe);vn=a(va,"Nous sommes maintenant pr\xEAts \xE0 entra\xEEner notre mod\xE8le ! Nous devons juste faire deux derni\xE8res choses avant de d\xE9finir notre "),mt=o(va,"CODE",{});var Ru=r(mt);Ca=a(Ru,"Trainer"),Ru.forEach(s),Gn=a(va," : se connecter \xE0 Hugging Face et d\xE9finir nos arguments d\u2019entra\xEEnement. Si vous travaillez dans un "),gs=o(va,"EM",{});var Fu=r(gs);Ws=a(Fu,"notebook"),Fu.forEach(s),rs=a(va,", il y a une fonction pratique pour vous aider \xE0 le faire :"),va.forEach(s),Ms=c(i),w(Ns.$$.fragment,i),Pt=c(i),Xs=o(i,"P",{});var Al=r(Xs);hn=a(Al,"Cela affichera un "),Dt=o(Al,"EM",{});var Bu=r(Dt);Zs=a(Bu,"widget"),Bu.forEach(s),Un=a(Al," o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),Al.forEach(s),je=c(i),ft=o(i,"P",{});var vr=r(ft);Vn=a(vr,"Si vous ne travaillez pas dans un "),we=o(vr,"EM",{});var Lo=r(we);Mt=a(Lo,"notebook"),Lo.forEach(s),_n=a(vr,", tapez simplement la ligne suivante dans votre terminal :"),vr.forEach(s),pe=c(i),w(is.$$.fragment,i),bn=c(i),Ks=o(i,"P",{});var hr=r(Ks);vt=a(hr,"Une fois ceci fait, nous pouvons d\xE9finir nos "),Nt=o(hr,"CODE",{});var Hu=r(Nt);Wn=a(Hu,"TrainingArguments"),Hu.forEach(s),Ys=a(hr," :"),hr.forEach(s),At=c(i),w(us.$$.fragment,i),Tt=c(i),fe=o(i,"P",{});var vs=r(fe);ya=a(vs,"Vous avez d\xE9j\xE0 vu la plupart d\u2019entre eux. Nous d\xE9finissons quelques hyperparam\xE8tres (comme le taux d\u2019apprentissage, le nombre d\u2019\xE9poques \xE0 entra\xEEner, et le taux de d\xE9croissance des poids), et nous sp\xE9cifions "),St=o(vs,"CODE",{});var Tl=r(St);Es=a(Tl,"push_to_hub=True"),Tl.forEach(s),Ze=a(vs," pour indiquer que nous voulons sauvegarder le mod\xE8le, l\u2019\xE9valuer \xE0 la fin de chaque \xE9poque, et que nous voulons t\xE9l\xE9charger nos r\xE9sultats vers le "),Js=o(vs,"EM",{});var Bi=r(Js);Ae=a(Bi,"Hub"),Bi.forEach(s),za=a(vs,". Notez que vous pouvez sp\xE9cifier le nom du d\xE9p\xF4t vers lequel vous voulez pousser avec l\u2019argument "),As=o(vs,"CODE",{});var Sl=r(As);Oa=a(Sl,"hub_model_id"),Sl.forEach(s),Xn=a(vs," (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),xe=o(vs,"A",{href:!0,rel:!0});var Hi=r(xe);$n=o(Hi,"CODE",{});var de=r($n);gn=a(de,"huggingface-course"),de.forEach(s),Hi.forEach(s),Zn=a(vs,", nous avons ajout\xE9 "),Te=o(vs,"CODE",{});var Gu=r(Te);ht=a(Gu,'hub_model_id="huggingface-course/bert-finetuned-ner"``TrainingArguments'),Gu.forEach(s),En=a(vs,". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace de noms et nomm\xE9 d\u2019apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, donc dans notre cas ce sera "),qn=o(vs,"CODE",{});var _r=r(qn);Kn=a(_r,'"sgugger/bert-finetuned-ner"'),_r.forEach(s),qs=a(vs,"."),vs.forEach(s),kn=c(i),w(Be.$$.fragment,i),ps=c(i),ks=o(i,"P",{});var br=r(ks);_t=a(br,"Enfin, nous passons tout au "),Lt=o(br,"CODE",{});var Uu=r(Lt);Ts=a(Uu,"Trainer"),Uu.forEach(s),Yn=a(br," et lan\xE7ons l\u2019entra\xEEnement :"),br.forEach(s),Ce=c(i),w(Se.$$.fragment,i),It=c(i),js=o(i,"P",{});var Ll=r(js);Pa=a(Ll,"Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),Ss=o(Ll,"EM",{});var Vu=r(Ss);bt=a(Vu,"Hub"),Vu.forEach(s),Da=a(Ll," en arri\xE8re-plan. De cette fa\xE7on, vous serez en mesure de reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),Ll.forEach(s),Jn=c(i),cs=o(i,"P",{});var $r=r(cs);$t=a($r,"Une fois l\u2019entra\xEEnement termin\xE9, nous utilisons la m\xE9thode "),Rt=o($r,"CODE",{});var gr=r(Rt);ws=a(gr,"push_to_hub()"),gr.forEach(s),Ma=a($r," pour nous assurer que nous t\xE9l\xE9chargeons la version la plus r\xE9cente du mod\xE8le :"),$r.forEach(s),gt=c(i),w(Qs.$$.fragment,i),et=c(i),st=o(i,"P",{});var Wu=r(st);Ke=a(Wu,"Cette commande renvoie l\u2019URL du commit qu\u2019elle vient de faire, si vous voulez l\u2019inspecter :"),Wu.forEach(s),jn=c(i),w(He.$$.fragment,i),wn=c(i),ie=o(i,"P",{});var nn=r(ie);Qn=a(nn,"Le "),$e=o(nn,"CODE",{});var Er=r($e);Na=a(Er,"Trainer"),Er.forEach(s),xn=a(nn," r\xE9dige \xE9galement une carte mod\xE8le avec tous les r\xE9sultats de l\u2019\xE9valuation et la t\xE9l\xE9charge. A ce stade, vous pouvez utiliser le "),Et=o(nn,"EM",{});var Xu=r(Et);Aa=a(Xu,"widget"),Xu.forEach(s),Cn=a(nn," d\u2019inf\xE9rence sur le "),qt=o(nn,"EM",{});var Zu=r(qt);Ta=a(Zu,"Hub"),Zu.forEach(s),yn=a(nn," pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 affiner un mod\xE8le sur une t\xE2che de classification de "),Ft=o(nn,"EM",{});var qr=r(Ft);Bt=a(qr,"tokens"),qr.forEach(s),zn=a(nn,". F\xE9licitations !"),nn.forEach(s),On=c(i),Ye=o(i,"P",{});var kr=r(Ye);Pn=a(kr,"Si vous voulez plonger un peu plus profond\xE9ment dans la boucle d\u2019entra\xEEnement, nous allons maintenant vous montrer comment faire la m\xEAme chose en utilisant \u{1F917} "),f=o(kr,"EM",{});var Ku=r(f);L=a(Ku,"Accelerate"),Ku.forEach(s),Dn=a(kr,"."),kr.forEach(s),Sa=c(i),Ls=o(i,"H2",{class:!0});var Il=r(Ls);be=o(Il,"A",{id:!0,class:!0,href:!0});var Yu=r(be);Mn=o(Yu,"SPAN",{});var Ju=r(Mn);w(xs.$$.fragment,Ju),Ju.forEach(s),Yu.forEach(s),La=c(Il),Is=o(Il,"SPAN",{});var jr=r(Is);Ht=a(jr,"Une boucle d'entra\xEEnement personnalis\xE9e"),jr.forEach(s),Il.forEach(s),Nn=c(i),kt=o(i,"P",{});var wr=r(kt);Gt=a(wr,"Jetons maintenant un coup d\u2019\u0153il \xE0 la boucle d\u2019entra\xEEnement compl\xE8te afin que vous puissiez facilement personnaliser les parties dont vous avez besoin. Elle ressemblera beaucoup \xE0 ce que nous avons fait dans le "),Ut=o(wr,"A",{href:!0});var Qu=r(Ut);Vt=a(Qu,"chapitre 3"),Qu.forEach(s),Rs=a(wr," avec quelques changements pour l\u2019\xE9valuation."),wr.forEach(s),jt=c(i),Fs=o(i,"H3",{class:!0});var Rl=r(Fs);ve=o(Rl,"A",{id:!0,class:!0,href:!0});var ep=r(ve);Wt=o(ep,"SPAN",{});var sp=r(Wt);w(tt.$$.fragment,sp),sp.forEach(s),ep.forEach(s),ql=c(Rl),An=o(Rl,"SPAN",{});var xr=r(An);ea=a(xr,"Pr\xE9parer tout pour l'entra\xEEnement"),xr.forEach(s),Rl.forEach(s),Tn=c(i),ds=o(i,"P",{});var ha=r(ds);Xt=a(ha,"D\u2019abord nous devons construire le "),sa=o(ha,"CODE",{});var tp=r(sa);ta=a(tp,"DataLoader"),tp.forEach(s),na=a(ha,"s \xE0 partir de nos jeux de donn\xE9es. Nous r\xE9utilisons notre "),Je=o(ha,"CODE",{});var Cr=r(Je);kl=a(Cr,"data_collator"),Cr.forEach(s),aa=a(ha," comme un "),la=o(ha,"CODE",{});var np=r(la);jl=a(np,"collate_fn"),np.forEach(s),wt=a(ha," et m\xE9langer l\u2019ensemble d\u2019entra\xEEnement, mais pas l\u2019ensemble de validation :"),ha.forEach(s),xt=c(i),w(Ct.$$.fragment,i),Ge=c(i),nt=o(i,"P",{});var yr=r(nt);Bs=a(yr,"Ensuite, nous r\xE9instantifions notre mod\xE8le pour nous assurer que nous ne continuons pas le "),oa=o(yr,"EM",{});var Gi=r(oa);Ue=a(Gi,"finetuning"),Gi.forEach(s),wl=a(yr," d\u2019avant et que nous repartons bien du mod\xE8le pr\xE9-entra\xEEn\xE9 de BERT :"),yr.forEach(s),Ia=c(i),w(at.$$.fragment,i),Ra=c(i),Hs=o(i,"P",{});var an=r(Hs);Sn=a(an,"Ensuite, nous avons besoin d\u2019un optimiseur. Nous utilisons le classique "),De=o(an,"CODE",{});var Ui=r(De);Ve=a(Ui,"AdamW"),Ui.forEach(s),ra=a(an,", qui est comme "),ia=o(an,"CODE",{});var Io=r(ia);xl=a(Io,"Adam"),Io.forEach(s),Cl=a(an,", mais avec un correctif dans la fa\xE7on dont le taux de d\xE9croissance des poids est appliqu\xE9e :"),an.forEach(s),yt=c(i),w(Ln.$$.fragment,i),Uo=c(i),ua=o(i,"P",{});var zr=r(ua);eo=a(zr,"Une fois que nous avons tous ces objets, nous pouvons les envoyer \xE0 la m\xE9thode "),so=o(zr,"CODE",{});var Vi=r(so);Zr=a(Vi,"accelerator.prepare()"),Vi.forEach(s),to=a(zr," :"),zr.forEach(s),Vo=c(i),w(Fa.$$.fragment,i),Wo=c(i),w(Cs.$$.fragment,i),yl=c(i),lt=o(i,"P",{});var rt=r(lt);Kr=a(rt,"Maintenant que nous avons envoy\xE9 notre "),Ba=o(rt,"CODE",{});var Wi=r(Ba);Yr=a(Wi,"train_dataloader"),Wi.forEach(s),Jr=a(rt," \xE0 "),Ha=o(rt,"CODE",{});var Fl=r(Ha);Qr=a(Fl,"accelerator.prepare()"),Fl.forEach(s),ei=a(rt,", nous pouvons utiliser sa longueur pour calculer le nombre d\u2019\xE9tapes d\u2019entra\xEEnement. Rappelez-vous que nous devrions toujours faire cela apr\xE8s avoir pr\xE9par\xE9 le "),no=o(rt,"EM",{});var Xi=r(no);Zt=a(Xi,"dataloader"),Xi.forEach(s),ao=a(rt," car cette m\xE9thode modifiera sa longueur. Nous utilisons un programme lin\xE9aire classique du taux d\u2019apprentissage \xE0 0 :"),rt.forEach(s),Xo=c(i),w(Ga.$$.fragment,i),zl=c(i),ys=o(i,"P",{});var qe=r(ys);si=a(qe,"Enfin, pour pousser notre mod\xE8le vers le "),Ua=o(qe,"EM",{});var ap=r(Ua);ti=a(ap,"Hub"),ap.forEach(s),ni=a(qe,", nous avons besoin de cr\xE9er un objet "),lo=o(qe,"CODE",{});var Or=r(lo);Kt=a(Or,"Repository"),Or.forEach(s),oo=a(qe," dans un dossier de travail. Tout d\u2019abord, connectez-vous \xE0 Hugging Face si vous n\u2019\xEAtes pas d\xE9j\xE0 connect\xE9. Nous d\xE9terminons le nom du d\xE9p\xF4t \xE0 partir de l\u2019identifiant du mod\xE8le que nous voulons donner \xE0 notre mod\xE8le (n\u2019h\xE9sitez pas \xE0 remplacer le "),ro=o(qe,"CODE",{});var lp=r(ro);ai=a(lp,"repo_name"),lp.forEach(s),io=a(qe," par votre propre choix, il doit juste contenir votre nom d\u2019utilisateur et ce que fait la fonction "),uo=o(qe,"CODE",{});var op=r(uo);li=a(op,"get_full_repo_name()"),op.forEach(s),po=a(qe,") :"),qe.forEach(s),Zo=c(i),w(Va.$$.fragment,i),co=c(i),w(Yt.$$.fragment,i),Ko=c(i),Wa=o(i,"P",{});var Pr=r(Wa);Xa=a(Pr,"Ensuite, nous pouvons cloner ce d\xE9p\xF4t dans un dossier local. S\u2019il existe d\xE9j\xE0, ce dossier local doit \xEAtre un clone existant du r\xE9f\xE9rentiel avec lequel nous travaillons :"),Pr.forEach(s),mo=c(i),w(zt.$$.fragment,i),fo=c(i),We=o(i,"P",{});var Bl=r(We);oi=a(Bl,"Nous pouvons maintenant t\xE9l\xE9charger tout ce que nous sauvegardons dans "),Za=o(Bl,"CODE",{});var rp=r(Za);ri=a(rp,"output_dir"),rp.forEach(s),ii=a(Bl," en appelant la m\xE9thode "),Ka=o(Bl,"CODE",{});var Dr=r(Ka);ui=a(Dr,"repo.push_to_hub()"),Dr.forEach(s),pi=a(Bl,". Cela nous aidera \xE0 t\xE9l\xE9charger les mod\xE8les interm\xE9diaires \xE0 la fin de chaque \xE9poque."),Bl.forEach(s),vo=c(i),Gs=o(i,"H3",{class:!0});var Mr=r(Gs);In=o(Mr,"A",{id:!0,class:!0,href:!0});var ip=r(In);pa=o(ip,"SPAN",{});var Nr=r(pa);w(Ya.$$.fragment,Nr),Nr.forEach(s),ip.forEach(s),Yo=c(Mr),Jt=o(Mr,"SPAN",{});var up=r(Jt);Jo=a(up,"Boucle d'entra\xEEnement"),up.forEach(s),Mr.forEach(s),Qt=c(i),ms=o(i,"P",{});var Hl=r(ms);ho=a(Hl,"Nous sommes maintenant pr\xEAts \xE0 \xE9crire la boucle d\u2019entra\xEEnement compl\xE8te. Pour simplifier sa partie \xE9valuation, nous d\xE9finissons cette fonction "),Rn=o(Hl,"CODE",{});var Zi=r(Rn);ci=a(Zi,"postprocess()"),Zi.forEach(s),_o=a(Hl," qui prend les pr\xE9dictions et les \xE9tiquettes, et les convertit en listes de cha\xEEnes de caract\xE8res comme notre objet "),bo=o(Hl,"CODE",{});var cl=r(bo);Qo=a(cl,"metric"),cl.forEach(s),Ja=a(Hl," l\u2019attend :"),Hl.forEach(s),$o=c(i),w(ye.$$.fragment,i),er=c(i),ca=o(i,"P",{});var Ki=r(ca);di=a(Ki,"Ensuite, nous pouvons \xE9crire la boucle d\u2019entra\xEEnement. Apr\xE8s avoir d\xE9fini une barre de progression pour suivre l\u2019\xE9volution de l\u2019entra\xEEnement, la boucle comporte trois parties :"),Ki.forEach(s),sr=c(i),Us=o(i,"UL",{});var ke=r(Us);Qa=o(ke,"LI",{});var Ar=r(Qa);mi=a(Ar,"L\u2019entra\xEEnement proprement dit, qui est l\u2019it\xE9ration classique sur le "),el=o(Ar,"CODE",{});var Tr=r(el);fi=a(Tr,"train_dataloader"),Tr.forEach(s),vi=a(Ar,", passage en avant, puis passage en arri\xE8re et \xE9tape d\u2019optimisation."),Ar.forEach(s),go=c(ke),Vs=o(ke,"LI",{});var ln=r(Vs);hi=a(ln,"L\u2019\xE9valuation, dans laquelle il y a une nouveaut\xE9 apr\xE8s avoir obtenu les sorties de notre mod\xE8le sur un batch : puisque deux processus peuvent avoir padd\xE9 les entr\xE9es et les \xE9tiquettes \xE0 des formes diff\xE9rentes, nous devons utiliser "),sl=o(ln,"CODE",{});var pp=r(sl);_i=a(pp,"accelerator.pad_across_processes()"),pp.forEach(s),bi=a(ln," pour rendre les pr\xE9dictions et les \xE9tiquettes de la m\xEAme forme avant d\u2019appeler la m\xE9thode "),Ol=o(ln,"CODE",{});var Sr=r(Ol);en=a(Sr,"gather()"),Sr.forEach(s),$i=a(ln,". Si nous ne le faisons pas, l\u2019\xE9valuation va soit se tromper, soit se bloquer pour toujours. Ensuite, nous envoyons les r\xE9sultats \xE0 "),tl=o(ln,"CODE",{});var cp=r(tl);gi=a(cp,"metric.add_batch()"),cp.forEach(s),Ei=a(ln," et appelons "),nl=o(ln,"CODE",{});var dp=r(nl);qi=a(dp,"metric.compute()"),dp.forEach(s),ki=a(ln," une fois que la boucle d\u2019\xE9valuation est termin\xE9e."),ln.forEach(s),tr=c(ke),Xe=o(ke,"LI",{});var it=r(Xe);nr=a(it,"Sauvegarde et t\xE9l\xE9chargement, o\xF9 nous sauvegardons d\u2019abord le mod\xE8le et le "),re=o(it,"EM",{});var mp=r(re);ji=a(mp,"tokenizer"),mp.forEach(s),Eo=a(it,", puis appelons "),qo=o(it,"CODE",{});var fp=r(qo);wi=a(fp,"repo.push_to_hub()"),fp.forEach(s),ko=a(it,". Remarquez que nous utilisons l\u2019argument "),jo=o(it,"CODE",{});var Lr=r(jo);xi=a(Lr,"blocking=False"),Lr.forEach(s),al=a(it," pour indiquer \xE0 la biblioth\xE8que \u{1F917} "),wo=o(it,"EM",{});var vp=r(wo);Ci=a(vp,"Hub"),vp.forEach(s),xo=a(it," de pousser dans un processus asynchrone. De cette fa\xE7on, l\u2019entra\xEEnement continue normalement et cette (longue) instruction est ex\xE9cut\xE9e en arri\xE8re-plan."),it.forEach(s),ke.forEach(s),ar=c(i),Pl=o(i,"P",{});var hp=r(Pl);Co=a(hp,"Voici le code complet de la boucle d\u2019entra\xEEnement :"),hp.forEach(s),lr=c(i),w(ll.$$.fragment,i),Dl=c(i),da=o(i,"P",{});var Gl=r(da);yi=a(Gl,"Au cas o\xF9 ce serait la premi\xE8re fois que vous verriez un mod\xE8le enregistr\xE9 avec \u{1F917} "),Fn=o(Gl,"EM",{});var _p=r(Fn);zi=a(_p,"Accelerate"),_p.forEach(s),Oi=a(Gl,", prenons un moment pour inspecter les trois lignes de code qui l\u2019accompagnent :"),Gl.forEach(s),Ml=c(i),w(ol.$$.fragment,i),or=c(i),ge=o(i,"P",{});var Qe=r(ge);Pi=a(Qe,"La premi\xE8re ligne est explicite : elle indique \xE0 tous les processus d\u2019attendre que tout le monde soit \xE0 ce stade avant de continuer. C\u2019est pour s\u2019assurer que nous avons le m\xEAme mod\xE8le dans chaque processus avant de sauvegarder. Ensuite, nous prenons le "),yo=o(Qe,"CODE",{});var Ir=r(yo);zo=a(Ir,"unwrapped_model"),Ir.forEach(s),Di=a(Qe," qui est le mod\xE8le de base que nous avons d\xE9fini. La m\xE9thode "),Oo=o(Qe,"CODE",{});var bp=r(Oo);rr=a(bp,"accelerator.prepare()"),bp.forEach(s),rl=a(Qe," modifie le mod\xE8le pour qu\u2019il fonctionne dans l\u2019entra\xEEnement distribu\xE9, donc il n\u2019aura plus la m\xE9thode "),Nl=o(Qe,"CODE",{});var $p=r(Nl);il=a($p,"save_pretrained()"),$p.forEach(s),ir=a(Qe," ; la m\xE9thode "),ot=o(Qe,"CODE",{});var Yi=r(ot);Mi=a(Yi,"accelerator.unwrap_model()"),Yi.forEach(s),Po=a(Qe," annule cette \xE9tape. Enfin, nous appelons "),Do=o(Qe,"CODE",{});var Ul=r(Do);Ni=a(Ul,"save_pretrained()"),Ul.forEach(s),Mo=a(Qe," mais nous disons \xE0 cette m\xE9thode d\u2019utiliser "),No=o(Qe,"CODE",{});var Ji=r(No);Ai=a(Ji,"accelerator.save()"),Ji.forEach(s),ur=a(Qe," au lieu de "),Bn=o(Qe,"CODE",{});var Ro=r(Bn);pr=a(Ro,"torch.save()"),Ro.forEach(s),ul=a(Qe,"."),Qe.forEach(s),Ao=c(i),ne=o(i,"P",{});var Vl=r(ne);Ti=a(Vl,"Une fois ceci fait, vous devriez avoir un mod\xE8le qui produit des r\xE9sultats assez similaires \xE0 celui entra\xEEn\xE9 avec le "),pl=o(Vl,"CODE",{});var Qi=r(pl);Si=a(Qi,"Trainer"),Qi.forEach(s),Li=a(Vl,". Vous pouvez v\xE9rifier le mod\xE8le que nous avons form\xE9 en utilisant ce code \xE0 "),Hn=o(Vl,"A",{href:!0,rel:!0});var Fo=r(Hn);To=o(Fo,"EM",{});var gp=r(To);Ii=a(gp,"huggingface-course/bert-finetuned-ner-accelerate"),gp.forEach(s),Fo.forEach(s),So=a(Vl,". Et si vous voulez tester des modifications de la boucle d\u2019entra\xEEnement, vous pouvez les impl\xE9menter directement en modifiant le code ci-dessus !"),Vl.forEach(s),this.h()},h(){_(g,"id","dfinir-le-modle"),_(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(g,"href","#dfinir-le-modle"),_(d,"class","relative group"),_(te,"href","/course/fr/chapter3"),_(Fe,"id","ifinetuningi-du-modle"),_(Fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Fe,"href","#ifinetuningi-du-modle"),_(Oe,"class","relative group"),_(xe,"href","https://huggingface.co/huggingface-course"),_(xe,"rel","nofollow"),_(be,"id","une-boucle-dentranement-personnalise"),_(be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(be,"href","#une-boucle-dentranement-personnalise"),_(Ls,"class","relative group"),_(Ut,"href","/course/fr/chapter3/4"),_(ve,"id","prparer-tout-pour-lentranement"),_(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(ve,"href","#prparer-tout-pour-lentranement"),_(Fs,"class","relative group"),_(In,"id","boucle-dentranement"),_(In,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(In,"href","#boucle-dentranement"),_(Gs,"class","relative group"),_(Hn,"href","https://huggingface.co/huggingface-course/bert-finetuned-ner-accelerate"),_(Hn,"rel","nofollow")},m(i,h){u(i,d,h),e(d,g),e(g,v),x(q,v,null),e(d,O),e(d,E),e(E,k),u(i,D,h),u(i,y,h),e(y,z),e(y,B),e(B,A),e(y,F),e(y,I),e(I,P),e(y,T),e(y,W),e(W,G),e(y,S),e(y,X),e(X,J),e(y,le),u(i,N,h),u(i,U,h),e(U,se),e(U,Y),e(Y,ee),e(U,R),e(U,K),e(K,me),e(U,Me),u(i,he,h),x(H,i,h),u(i,oe,h),u(i,Q,h),e(Q,ue),e(Q,Z),e(Z,ce),e(Q,ss),e(Q,_e),e(_e,Ee),e(Q,Os),u(i,ze,h),x(Ne,i,h),u(i,ts,h),u(i,ae,h),e(ae,bs),e(ae,$s),e($s,Ot),e(ae,Ea),e(ae,te),e(te,qa),e(ae,pn),e(ae,Ps),e(Ps,ka),e(ae,ja),u(i,pt,h),x(ns,i,h),u(i,cn,h),x(Re,i,h),u(i,dn,h),x(as,i,h),u(i,ct,h),u(i,Oe,h),e(Oe,Fe),e(Fe,Ds),x(ls,Ds,null),e(Oe,wa),e(Oe,os),e(os,dt),e(dt,xa),e(os,mn),u(i,fn,h),u(i,Pe,h),e(Pe,vn),e(Pe,mt),e(mt,Ca),e(Pe,Gn),e(Pe,gs),e(gs,Ws),e(Pe,rs),u(i,Ms,h),x(Ns,i,h),u(i,Pt,h),u(i,Xs,h),e(Xs,hn),e(Xs,Dt),e(Dt,Zs),e(Xs,Un),u(i,je,h),u(i,ft,h),e(ft,Vn),e(ft,we),e(we,Mt),e(ft,_n),u(i,pe,h),x(is,i,h),u(i,bn,h),u(i,Ks,h),e(Ks,vt),e(Ks,Nt),e(Nt,Wn),e(Ks,Ys),u(i,At,h),x(us,i,h),u(i,Tt,h),u(i,fe,h),e(fe,ya),e(fe,St),e(St,Es),e(fe,Ze),e(fe,Js),e(Js,Ae),e(fe,za),e(fe,As),e(As,Oa),e(fe,Xn),e(fe,xe),e(xe,$n),e($n,gn),e(fe,Zn),e(fe,Te),e(Te,ht),e(fe,En),e(fe,qn),e(qn,Kn),e(fe,qs),u(i,kn,h),x(Be,i,h),u(i,ps,h),u(i,ks,h),e(ks,_t),e(ks,Lt),e(Lt,Ts),e(ks,Yn),u(i,Ce,h),x(Se,i,h),u(i,It,h),u(i,js,h),e(js,Pa),e(js,Ss),e(Ss,bt),e(js,Da),u(i,Jn,h),u(i,cs,h),e(cs,$t),e(cs,Rt),e(Rt,ws),e(cs,Ma),u(i,gt,h),x(Qs,i,h),u(i,et,h),u(i,st,h),e(st,Ke),u(i,jn,h),x(He,i,h),u(i,wn,h),u(i,ie,h),e(ie,Qn),e(ie,$e),e($e,Na),e(ie,xn),e(ie,Et),e(Et,Aa),e(ie,Cn),e(ie,qt),e(qt,Ta),e(ie,yn),e(ie,Ft),e(Ft,Bt),e(ie,zn),u(i,On,h),u(i,Ye,h),e(Ye,Pn),e(Ye,f),e(f,L),e(Ye,Dn),u(i,Sa,h),u(i,Ls,h),e(Ls,be),e(be,Mn),x(xs,Mn,null),e(Ls,La),e(Ls,Is),e(Is,Ht),u(i,Nn,h),u(i,kt,h),e(kt,Gt),e(kt,Ut),e(Ut,Vt),e(kt,Rs),u(i,jt,h),u(i,Fs,h),e(Fs,ve),e(ve,Wt),x(tt,Wt,null),e(Fs,ql),e(Fs,An),e(An,ea),u(i,Tn,h),u(i,ds,h),e(ds,Xt),e(ds,sa),e(sa,ta),e(ds,na),e(ds,Je),e(Je,kl),e(ds,aa),e(ds,la),e(la,jl),e(ds,wt),u(i,xt,h),x(Ct,i,h),u(i,Ge,h),u(i,nt,h),e(nt,Bs),e(nt,oa),e(oa,Ue),e(nt,wl),u(i,Ia,h),x(at,i,h),u(i,Ra,h),u(i,Hs,h),e(Hs,Sn),e(Hs,De),e(De,Ve),e(Hs,ra),e(Hs,ia),e(ia,xl),e(Hs,Cl),u(i,yt,h),x(Ln,i,h),u(i,Uo,h),u(i,ua,h),e(ua,eo),e(ua,so),e(so,Zr),e(ua,to),u(i,Vo,h),x(Fa,i,h),u(i,Wo,h),x(Cs,i,h),u(i,yl,h),u(i,lt,h),e(lt,Kr),e(lt,Ba),e(Ba,Yr),e(lt,Jr),e(lt,Ha),e(Ha,Qr),e(lt,ei),e(lt,no),e(no,Zt),e(lt,ao),u(i,Xo,h),x(Ga,i,h),u(i,zl,h),u(i,ys,h),e(ys,si),e(ys,Ua),e(Ua,ti),e(ys,ni),e(ys,lo),e(lo,Kt),e(ys,oo),e(ys,ro),e(ro,ai),e(ys,io),e(ys,uo),e(uo,li),e(ys,po),u(i,Zo,h),x(Va,i,h),u(i,co,h),x(Yt,i,h),u(i,Ko,h),u(i,Wa,h),e(Wa,Xa),u(i,mo,h),x(zt,i,h),u(i,fo,h),u(i,We,h),e(We,oi),e(We,Za),e(Za,ri),e(We,ii),e(We,Ka),e(Ka,ui),e(We,pi),u(i,vo,h),u(i,Gs,h),e(Gs,In),e(In,pa),x(Ya,pa,null),e(Gs,Yo),e(Gs,Jt),e(Jt,Jo),u(i,Qt,h),u(i,ms,h),e(ms,ho),e(ms,Rn),e(Rn,ci),e(ms,_o),e(ms,bo),e(bo,Qo),e(ms,Ja),u(i,$o,h),x(ye,i,h),u(i,er,h),u(i,ca,h),e(ca,di),u(i,sr,h),u(i,Us,h),e(Us,Qa),e(Qa,mi),e(Qa,el),e(el,fi),e(Qa,vi),e(Us,go),e(Us,Vs),e(Vs,hi),e(Vs,sl),e(sl,_i),e(Vs,bi),e(Vs,Ol),e(Ol,en),e(Vs,$i),e(Vs,tl),e(tl,gi),e(Vs,Ei),e(Vs,nl),e(nl,qi),e(Vs,ki),e(Us,tr),e(Us,Xe),e(Xe,nr),e(Xe,re),e(re,ji),e(Xe,Eo),e(Xe,qo),e(qo,wi),e(Xe,ko),e(Xe,jo),e(jo,xi),e(Xe,al),e(Xe,wo),e(wo,Ci),e(Xe,xo),u(i,ar,h),u(i,Pl,h),e(Pl,Co),u(i,lr,h),x(ll,i,h),u(i,Dl,h),u(i,da,h),e(da,yi),e(da,Fn),e(Fn,zi),e(da,Oi),u(i,Ml,h),x(ol,i,h),u(i,or,h),u(i,ge,h),e(ge,Pi),e(ge,yo),e(yo,zo),e(ge,Di),e(ge,Oo),e(Oo,rr),e(ge,rl),e(ge,Nl),e(Nl,il),e(ge,ir),e(ge,ot),e(ot,Mi),e(ge,Po),e(ge,Do),e(Do,Ni),e(ge,Mo),e(ge,No),e(No,Ai),e(ge,ur),e(ge,Bn),e(Bn,pr),e(ge,ul),u(i,Ao,h),u(i,ne,h),e(ne,Ti),e(ne,pl),e(pl,Si),e(ne,Li),e(ne,Hn),e(Hn,To),e(To,Ii),e(ne,So),cr=!0},i(i){cr||(b(q.$$.fragment,i),b(H.$$.fragment,i),b(Ne.$$.fragment,i),b(ns.$$.fragment,i),b(Re.$$.fragment,i),b(as.$$.fragment,i),b(ls.$$.fragment,i),b(Ns.$$.fragment,i),b(is.$$.fragment,i),b(us.$$.fragment,i),b(Be.$$.fragment,i),b(Se.$$.fragment,i),b(Qs.$$.fragment,i),b(He.$$.fragment,i),b(xs.$$.fragment,i),b(tt.$$.fragment,i),b(Ct.$$.fragment,i),b(at.$$.fragment,i),b(Ln.$$.fragment,i),b(Fa.$$.fragment,i),b(Cs.$$.fragment,i),b(Ga.$$.fragment,i),b(Va.$$.fragment,i),b(Yt.$$.fragment,i),b(zt.$$.fragment,i),b(Ya.$$.fragment,i),b(ye.$$.fragment,i),b(ll.$$.fragment,i),b(ol.$$.fragment,i),cr=!0)},o(i){$(q.$$.fragment,i),$(H.$$.fragment,i),$(Ne.$$.fragment,i),$(ns.$$.fragment,i),$(Re.$$.fragment,i),$(as.$$.fragment,i),$(ls.$$.fragment,i),$(Ns.$$.fragment,i),$(is.$$.fragment,i),$(us.$$.fragment,i),$(Be.$$.fragment,i),$(Se.$$.fragment,i),$(Qs.$$.fragment,i),$(He.$$.fragment,i),$(xs.$$.fragment,i),$(tt.$$.fragment,i),$(Ct.$$.fragment,i),$(at.$$.fragment,i),$(Ln.$$.fragment,i),$(Fa.$$.fragment,i),$(Cs.$$.fragment,i),$(Ga.$$.fragment,i),$(Va.$$.fragment,i),$(Yt.$$.fragment,i),$(zt.$$.fragment,i),$(Ya.$$.fragment,i),$(ye.$$.fragment,i),$(ll.$$.fragment,i),$(ol.$$.fragment,i),cr=!1},d(i){i&&s(d),C(q),i&&s(D),i&&s(y),i&&s(N),i&&s(U),i&&s(he),C(H,i),i&&s(oe),i&&s(Q),i&&s(ze),C(Ne,i),i&&s(ts),i&&s(ae),i&&s(pt),C(ns,i),i&&s(cn),C(Re,i),i&&s(dn),C(as,i),i&&s(ct),i&&s(Oe),C(ls),i&&s(fn),i&&s(Pe),i&&s(Ms),C(Ns,i),i&&s(Pt),i&&s(Xs),i&&s(je),i&&s(ft),i&&s(pe),C(is,i),i&&s(bn),i&&s(Ks),i&&s(At),C(us,i),i&&s(Tt),i&&s(fe),i&&s(kn),C(Be,i),i&&s(ps),i&&s(ks),i&&s(Ce),C(Se,i),i&&s(It),i&&s(js),i&&s(Jn),i&&s(cs),i&&s(gt),C(Qs,i),i&&s(et),i&&s(st),i&&s(jn),C(He,i),i&&s(wn),i&&s(ie),i&&s(On),i&&s(Ye),i&&s(Sa),i&&s(Ls),C(xs),i&&s(Nn),i&&s(kt),i&&s(jt),i&&s(Fs),C(tt),i&&s(Tn),i&&s(ds),i&&s(xt),C(Ct,i),i&&s(Ge),i&&s(nt),i&&s(Ia),C(at,i),i&&s(Ra),i&&s(Hs),i&&s(yt),C(Ln,i),i&&s(Uo),i&&s(ua),i&&s(Vo),C(Fa,i),i&&s(Wo),C(Cs,i),i&&s(yl),i&&s(lt),i&&s(Xo),C(Ga,i),i&&s(zl),i&&s(ys),i&&s(Zo),C(Va,i),i&&s(co),C(Yt,i),i&&s(Ko),i&&s(Wa),i&&s(mo),C(zt,i),i&&s(fo),i&&s(We),i&&s(vo),i&&s(Gs),C(Ya),i&&s(Qt),i&&s(ms),i&&s($o),C(ye,i),i&&s(er),i&&s(ca),i&&s(sr),i&&s(Us),i&&s(ar),i&&s(Pl),i&&s(lr),C(ll,i),i&&s(Dl),i&&s(da),i&&s(Ml),C(ol,i),i&&s(or),i&&s(ge),i&&s(Ao),i&&s(ne)}}}function ch(V){let d,g,v,q,O;return{c(){d=l("p"),g=n("\u26A0\uFE0F Si vous avez un mod\xE8le avec le mauvais nombre d\u2019\xE9tiquettes, vous obtiendrez une erreur obscure lors de l\u2019appel de la m\xE9thode "),v=l("code"),q=n("Trainer.train()"),O=n(" (quelque chose comme \u201CCUDA error : device-side assert triggered\u201D). C\u2019est la premi\xE8re cause de bogues signal\xE9s par les utilisateurs pour de telles erreurs, donc assurez-vous de faire cette v\xE9rification pour confirmer que vous avez le nombre d\u2019\xE9tiquettes attendu.")},l(E){d=o(E,"P",{});var k=r(d);g=a(k,"\u26A0\uFE0F Si vous avez un mod\xE8le avec le mauvais nombre d\u2019\xE9tiquettes, vous obtiendrez une erreur obscure lors de l\u2019appel de la m\xE9thode "),v=o(k,"CODE",{});var D=r(v);q=a(D,"Trainer.train()"),D.forEach(s),O=a(k," (quelque chose comme \u201CCUDA error : device-side assert triggered\u201D). C\u2019est la premi\xE8re cause de bogues signal\xE9s par les utilisateurs pour de telles erreurs, donc assurez-vous de faire cette v\xE9rification pour confirmer que vous avez le nombre d\u2019\xE9tiquettes attendu."),k.forEach(s)},m(E,k){u(E,d,k),e(d,g),e(d,v),e(v,q),e(d,O)},d(E){E&&s(d)}}}function dh(V){let d,g,v,q,O;return{c(){d=l("p"),g=n("\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de la d\xE9finition de votre "),v=l("code"),q=n("Trainer"),O=n(" et devrez d\xE9finir un nouveau nom.")},l(E){d=o(E,"P",{});var k=r(d);g=a(k,"\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de la d\xE9finition de votre "),v=o(k,"CODE",{});var D=r(v);q=a(D,"Trainer"),D.forEach(s),O=a(k," et devrez d\xE9finir un nouveau nom."),k.forEach(s)},m(E,k){u(E,d,k),e(d,g),e(d,v),e(v,q),e(d,O)},d(E){E&&s(d)}}}function mh(V){let d,g,v,q,O;return{c(){d=l("p"),g=n("\u{1F6A8} Si vous entra\xEEnez sur un TPU, vous devrez d\xE9placer tout le code \xE0 partir de la cellule ci-dessus dans une fonction d\u2019entra\xEEnement d\xE9di\xE9e. Voir le "),v=l("a"),q=n("chapitre 3"),O=n(" pour plus de d\xE9tails."),this.h()},l(E){d=o(E,"P",{});var k=r(d);g=a(k,"\u{1F6A8} Si vous entra\xEEnez sur un TPU, vous devrez d\xE9placer tout le code \xE0 partir de la cellule ci-dessus dans une fonction d\u2019entra\xEEnement d\xE9di\xE9e. Voir le "),v=o(k,"A",{href:!0});var D=r(v);q=a(D,"chapitre 3"),D.forEach(s),O=a(k," pour plus de d\xE9tails."),k.forEach(s),this.h()},h(){_(v,"href","/course/fr/chapter3")},m(E,k){u(E,d,k),e(d,g),e(d,v),e(v,q),e(d,O)},d(E){E&&s(d)}}}function fh(V){let d,g,v,q,O,E,k,D,y,z,B,A,F,I,P,T,W,G,S,X,J,le,N,U,se,Y,ee,R,K,me,Me,he,H,oe,Q,ue,Z,ce,ss,_e,Ee,Os,ze,Ne,ts,ae,bs,$s,Ot,Ea,te,qa,pn,Ps,ka,ja,pt,ns,cn,Re,dn,as,ct,Oe,Fe,Ds,ls,wa,os,dt,xa,mn,fn,Pe,vn,mt,Ca,Gn,gs,Ws,rs,Ms,Ns,Pt,Xs,hn,Dt,Zs,Un,je,ft,Vn,we,Mt,_n,pe,is,bn,Ks,vt,Nt,Wn,Ys,At,us,Tt,fe,ya,St,Es,Ze,Js,Ae,za,As,Oa,Xn,xe,$n,gn,Zn,Te,ht,En,qn,Kn,qs,kn,Be,ps,ks,_t,Lt,Ts,Yn,Ce,Se,It,js,Pa,Ss,bt,Da,Jn,cs,$t,Rt,ws,Ma,gt,Qs,et,st,Ke,jn,He,wn,ie,Qn,$e,Na,xn,Et,Aa,Cn,qt,Ta,yn,Ft,Bt,zn,On,Ye,Pn,f,L,Dn,Sa,Ls,be,Mn,xs,La,Is,Ht,Nn,kt,Gt,Ut,Vt,Rs,jt,Fs,ve,Wt,tt,ql,An,ea,Tn,ds,Xt,sa,ta,na,Je,kl,aa,la,jl,wt,xt,Ct,Ge,nt,Bs,oa,Ue,wl,Ia,at,Ra,Hs,Sn,De,Ve,ra,ia,xl,Cl,yt,Ln,Uo,ua,eo,so,Zr,to,Vo,Fa,Wo,Cs,yl,lt,Kr,Ba,Yr,Jr,Ha,Qr,ei,no,Zt,ao,Xo,Ga,zl,ys,si,Ua,ti,ni,lo,Kt,oo,ro,ai,io,uo,li,po,Zo,Va,co,Yt,Ko,Wa,Xa,mo,zt,fo,We,oi,Za,ri,ii,Ka,ui,pi,vo,Gs,In,pa,Ya,Yo,Jt,Jo,Qt,ms,ho,Rn,ci,_o,bo,Qo,Ja,$o,ye,er,ca,di,sr,Us,Qa,mi,el,fi,vi,go,Vs,hi,sl,_i,bi,Ol,en,$i,tl,gi,Ei,nl,qi,ki,tr,Xe,nr,re,ji,Eo,qo,wi,ko,jo,xi,al,wo,Ci,xo,ar,Pl,Co,lr,ll,Dl,da,yi,Fn,zi,Oi,Ml,ol,or,ge,Pi,yo,zo,Di,Oo,rr,rl,Nl,il,ir,ot,Mi,Po,Do,Ni,Mo,No,Ai,ur,Bn,pr,ul,Ao,ne,Ti,pl,Si,Li,Hn,To,Ii,So,cr,i,h,Cu,yu,dr,sn,zu,mr,Ou,Pu,ma,Du,Mu,fa,Nu,Au,tn,Tu,Su,Ri,fs,Lu,fr,Fi,Iu,va,Ru,Fu,Al,Bu,vr,Lo,hr,Hu,vs,Tl,Bi,Sl,Hi,de,Gu,_r,br,Uu,Ll,Vu,$r,gr,Wu,nn,Er,Xu,Zu,qr,kr,Ku,Il,Yu,Ju,jr,wr,Qu,Rl,ep,sp,xr,ha,tp,Cr,np,yr,Gi,an,Ui,Io,zr,Vi,rt,Wi,Fl,Xi,qe,ap,Or,lp,op,Pr,Bl,rp,Dr,Mr,ip,Nr,up,Hl,Zi,cl,Ki,ke,Ar,Tr,ln,pp,Sr,cp,dp,it,mp,fp,Lr,vp,hp,Gl,_p,Qe,Ir,bp,$p,Yi,Ul,Ji,Ro,Vl,Qi,Fo,gp,dc,eu,mc,Rr,Jc,Ep,Qc,ed,fc,dl,ml,qp,Bo,Fr,Xp,su,sd,Zp,td,vc,on,nd,Kp,ad,ld,kp,od,rd,Yp,id,ud,Jp,pd,cd,hc,_a,dd,tu,Qp,md,fd,ec,vd,hd,sc,_d,bd,_c,fl,vl,jp,wp,$d,bc,nu,$c,au,gc,xp,gd,Ec,lu,qc,ou,kc,hl,_l,Cp,yp,Ho,Br,tc,ru,Ed,nc,qd,jc,bl,$l,zp,iu,wc,Op,kd,xc,uu,Cc,pu,yc,Pp,jd,zc,cu,Oc,Dp,wd,Pc,du,Dc,gl,El,Mp,Np,Go,Hr,ac,mu,xd,Ap,Cd,lc,yd,Mc,rn,zd,oc,Od,Pd,rc,Dd,Md,ic,Nd,Ad,uc,Td,Sd,Nc,fu,Ac,vu,Tc,Tp,Ld,Sc;v=new Wv({props:{fw:V[0]}}),D=new ut({});const Bd=[Zv,Xv],hu=[];function Hd(t,m){return t[0]==="pt"?0:1}P=Hd(V),T=hu[P]=Bd[P](V),gs=new Lv({props:{id:"wVHdVlPScxA"}}),Ae=new ut({}),qs=new Xr({props:{$$slots:{default:[Kv]},$$scope:{ctx:V}}}),_t=new ut({}),$t=new M({props:{code:`from datasets import load_dataset

raw_datasets = load_dataset("conll2003")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

raw_datasets = load_dataset(<span class="hljs-string">&quot;conll2003&quot;</span>)`}}),Ke=new M({props:{code:"raw_datasets",highlighted:"raw_datasets"}}),He=new M({props:{code:`DatasetDict({
    train: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 14041
    })
    validation: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 3250
    })
    test: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 3453
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],
        num_rows: <span class="hljs-number">14041</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],
        num_rows: <span class="hljs-number">3250</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],
        num_rows: <span class="hljs-number">3453</span>
    })
})`}}),Ye=new M({props:{code:'raw_datasets["train"][0]["tokens"]',highlighted:'raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;tokens&quot;</span>]'}}),f=new M({props:{code:"['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']",highlighted:'[<span class="hljs-string">&#x27;EU&#x27;</span>, <span class="hljs-string">&#x27;rejects&#x27;</span>, <span class="hljs-string">&#x27;German&#x27;</span>, <span class="hljs-string">&#x27;call&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;boycott&#x27;</span>, <span class="hljs-string">&#x27;British&#x27;</span>, <span class="hljs-string">&#x27;lamb&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>]'}}),be=new M({props:{code:'raw_datasets["train"][0]["ner_tags"]',highlighted:'raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]'}}),xs=new M({props:{code:"[3, 0, 7, 0, 0, 0, 7, 0, 0]",highlighted:'[<span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]'}}),Vt=new M({props:{code:`ner_feature = raw_datasets["train"].features["ner_tags"]
ner_feature`,highlighted:`ner_feature = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].features[<span class="hljs-string">&quot;ner_tags&quot;</span>]
ner_feature`}}),jt=new M({props:{code:"Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], names_file=None, id=None), length=-1, id=None)",highlighted:'<span class="hljs-type">Sequence</span>(feature=ClassLabel(num_classes=<span class="hljs-number">9</span>, names=[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;I-PER&#x27;</span>, <span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;I-ORG&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;I-LOC&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>], names_file=<span class="hljs-literal">None</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>), length=-<span class="hljs-number">1</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)'}}),xt=new M({props:{code:`label_names = ner_feature.feature.names
label_names`,highlighted:`label_names = ner_feature.feature.names
label_names`}}),Ge=new M({props:{code:"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']",highlighted:'[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;I-PER&#x27;</span>, <span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;I-ORG&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;I-LOC&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>]'}}),Xa=new M({props:{code:`words = raw_datasets["train"][0]["tokens"]
labels = raw_datasets["train"][0]["ner_tags"]
line1 = ""
line2 = ""
for word, label in zip(words, labels):
    full_label = label_names[label]
    max_length = max(len(word), len(full_label))
    line1 += word + " " * (max_length - len(word) + 1)
    line2 += full_label + " " * (max_length - len(full_label) + 1)

print(line1)
print(line2)`,highlighted:`words = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;tokens&quot;</span>]
labels = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]
line1 = <span class="hljs-string">&quot;&quot;</span>
line2 = <span class="hljs-string">&quot;&quot;</span>
<span class="hljs-keyword">for</span> word, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(words, labels):
    full_label = label_names[label]
    max_length = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">len</span>(word), <span class="hljs-built_in">len</span>(full_label))
    line1 += word + <span class="hljs-string">&quot; &quot;</span> * (max_length - <span class="hljs-built_in">len</span>(word) + <span class="hljs-number">1</span>)
    line2 += full_label + <span class="hljs-string">&quot; &quot;</span> * (max_length - <span class="hljs-built_in">len</span>(full_label) + <span class="hljs-number">1</span>)

<span class="hljs-built_in">print</span>(line1)
<span class="hljs-built_in">print</span>(line2)`}}),zt=new M({props:{code:`'EU    rejects German call to boycott British lamb .'
'B-ORG O       B-MISC O    O  O       B-MISC  O    O'`,highlighted:`<span class="hljs-string">&#x27;EU    rejects German call to boycott British lamb .&#x27;</span>
<span class="hljs-string">&#x27;B-ORG O       B-MISC O    O  O       B-MISC  O    O&#x27;</span>`}}),Gs=new M({props:{code:`'Germany \\'s representative to the European Union \\'s veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .'
'B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O'`,highlighted:`<span class="hljs-string">&#x27;Germany \\&#x27;s representative to the European Union \\&#x27;s veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .&#x27;</span>
<span class="hljs-string">&#x27;B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O&#x27;</span>`}}),Jt=new Xr({props:{$$slots:{default:[Yv]},$$scope:{ctx:V}}}),Rn=new ut({}),Ja=new Lv({props:{id:"iY2AZYdZAr0"}}),Xe=new M({props:{code:`from transformers import AutoTokenizer

model_checkpoint = "bert-base-cased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

model_checkpoint = <span class="hljs-string">&quot;bert-base-cased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)`}}),rl=new M({props:{code:"tokenizer.is_fast",highlighted:"tokenizer.is_fast"}}),il=new M({props:{code:"True",highlighted:'<span class="hljs-literal">True</span>'}}),Bn=new M({props:{code:`inputs = tokenizer(raw_datasets["train"][0]["tokens"], is_split_into_words=True)
inputs.tokens()`,highlighted:`inputs = tokenizer(raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;tokens&quot;</span>], is_split_into_words=<span class="hljs-literal">True</span>)
inputs.tokens()`}}),ul=new M({props:{code:"['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]']",highlighted:'[<span class="hljs-string">&#x27;[CLS]&#x27;</span>, <span class="hljs-string">&#x27;EU&#x27;</span>, <span class="hljs-string">&#x27;rejects&#x27;</span>, <span class="hljs-string">&#x27;German&#x27;</span>, <span class="hljs-string">&#x27;call&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;boycott&#x27;</span>, <span class="hljs-string">&#x27;British&#x27;</span>, <span class="hljs-string">&#x27;la&#x27;</span>, <span class="hljs-string">&#x27;##mb&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>]'}}),Tl=new M({props:{code:"inputs.word_ids()",highlighted:"inputs.word_ids()"}}),Sl=new M({props:{code:"[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]",highlighted:'[<span class="hljs-literal">None</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-literal">None</span>]'}}),an=new M({props:{code:`def align_labels_with_tokens(labels, word_ids):
    new_labels = []
    current_word = None
    for word_id in word_ids:
        if word_id != current_word:
            # D\xE9but d'un nouveau mot !
            current_word = word_id
            label = -100 if word_id is None else labels[word_id]
            new_labels.append(label)
        elif word_id is None:
            # Token sp\xE9cial
            new_labels.append(-100)
        else:
            # M\xEAme mot que le token pr\xE9c\xE9dent
            label = labels[word_id]
            # Si l'\xE9tiquette est B-XXX, nous la changeons en I-XXX
            if label % 2 == 1:
                label += 1
            new_labels.append(label)

    return new_labels`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">align_labels_with_tokens</span>(<span class="hljs-params">labels, word_ids</span>):
    new_labels = []
    current_word = <span class="hljs-literal">None</span>
    <span class="hljs-keyword">for</span> word_id <span class="hljs-keyword">in</span> word_ids:
        <span class="hljs-keyword">if</span> word_id != current_word:
            <span class="hljs-comment"># D\xE9but d&#x27;un nouveau mot !</span>
            current_word = word_id
            label = -<span class="hljs-number">100</span> <span class="hljs-keyword">if</span> word_id <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> labels[word_id]
            new_labels.append(label)
        <span class="hljs-keyword">elif</span> word_id <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
            <span class="hljs-comment"># Token sp\xE9cial</span>
            new_labels.append(-<span class="hljs-number">100</span>)
        <span class="hljs-keyword">else</span>:
            <span class="hljs-comment"># M\xEAme mot que le token pr\xE9c\xE9dent</span>
            label = labels[word_id]
            <span class="hljs-comment"># Si l&#x27;\xE9tiquette est B-XXX, nous la changeons en I-XXX</span>
            <span class="hljs-keyword">if</span> label % <span class="hljs-number">2</span> == <span class="hljs-number">1</span>:
                label += <span class="hljs-number">1</span>
            new_labels.append(label)

    <span class="hljs-keyword">return</span> new_labels`}}),rt=new M({props:{code:`labels = raw_datasets["train"][0]["ner_tags"]
word_ids = inputs.word_ids()
print(labels)
print(align_labels_with_tokens(labels, word_ids))`,highlighted:`labels = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]
word_ids = inputs.word_ids()
<span class="hljs-built_in">print</span>(labels)
<span class="hljs-built_in">print</span>(align_labels_with_tokens(labels, word_ids))`}}),Fl=new M({props:{code:`[3, 0, 7, 0, 0, 0, 7, 0, 0]
[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]`,highlighted:`[<span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]
[-<span class="hljs-number">100</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">100</span>]`}}),cl=new Xr({props:{$$slots:{default:[Jv]},$$scope:{ctx:V}}}),Ul=new M({props:{code:`def tokenize_and_align_labels(examples):
    tokenized_inputs = tokenizer(
        examples["tokens"], truncation=True, is_split_into_words=True
    )
    all_labels = examples["ner_tags"]
    new_labels = []
    for i, labels in enumerate(all_labels):
        word_ids = tokenized_inputs.word_ids(i)
        new_labels.append(align_labels_with_tokens(labels, word_ids))

    tokenized_inputs["labels"] = new_labels
    return tokenized_inputs`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_and_align_labels</span>(<span class="hljs-params">examples</span>):
    tokenized_inputs = tokenizer(
        examples[<span class="hljs-string">&quot;tokens&quot;</span>], truncation=<span class="hljs-literal">True</span>, is_split_into_words=<span class="hljs-literal">True</span>
    )
    all_labels = examples[<span class="hljs-string">&quot;ner_tags&quot;</span>]
    new_labels = []
    <span class="hljs-keyword">for</span> i, labels <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(all_labels):
        word_ids = tokenized_inputs.word_ids(i)
        new_labels.append(align_labels_with_tokens(labels, word_ids))

    tokenized_inputs[<span class="hljs-string">&quot;labels&quot;</span>] = new_labels
    <span class="hljs-keyword">return</span> tokenized_inputs`}}),eu=new M({props:{code:`tokenized_datasets = raw_datasets.map(
    tokenize_and_align_labels,
    batched=True,
    remove_columns=raw_datasets["train"].column_names,
)`,highlighted:`tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(
    tokenize_and_align_labels,
    batched=<span class="hljs-literal">True</span>,
    remove_columns=raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].column_names,
)`}});const Gd=[eh,Qv],_u=[];function Ud(t,m){return t[0]==="pt"?0:1}dl=Ud(V),ml=_u[dl]=Gd[dl](V),su=new ut({});const Vd=[th,sh],bu=[];function Wd(t,m){return t[0]==="pt"?0:1}fl=Wd(V),vl=bu[fl]=Vd[fl](V),nu=new M({props:{code:`batch = data_collator([tokenized_datasets["train"][i] for i in range(2)])
batch["labels"]`,highlighted:`batch = data_collator([tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>)])
batch[<span class="hljs-string">&quot;labels&quot;</span>]`}}),au=new M({props:{code:`tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],
        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])`,highlighted:`tensor([[-<span class="hljs-number">100</span>,    <span class="hljs-number">3</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">7</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">7</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">0</span>, -<span class="hljs-number">100</span>],
        [-<span class="hljs-number">100</span>,    <span class="hljs-number">1</span>,    <span class="hljs-number">2</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>]])`}}),lu=new M({props:{code:`for i in range(2):
    print(tokenized_datasets["train"][i]["labels"])`,highlighted:`<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):
    <span class="hljs-built_in">print</span>(tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][i][<span class="hljs-string">&quot;labels&quot;</span>])`}}),ou=new M({props:{code:`[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]
[-100, 1, 2, -100]`,highlighted:`[-<span class="hljs-number">100</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">100</span>]
[-<span class="hljs-number">100</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, -<span class="hljs-number">100</span>]`}});const Xd=[ah,nh],$u=[];function Zd(t,m){return t[0]==="pt"?0:1}hl=Zd(V),_l=$u[hl]=Xd[hl](V);let hs=V[0]==="tf"&&Iv(V);ru=new ut({});const Kd=[ih,rh],gu=[];function Yd(t,m){return t[0]==="pt"?0:1}bl=Yd(V),$l=gu[bl]=Kd[bl](V),iu=new M({props:{code:`from datasets import load_metric

metric = load_metric("seqeval")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric

metric = load_metric(<span class="hljs-string">&quot;seqeval&quot;</span>)`}}),uu=new M({props:{code:`labels = raw_datasets["train"][0]["ner_tags"]
labels = [label_names[i] for i in labels]
labels`,highlighted:`labels = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]
labels = [label_names[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> labels]
labels`}}),pu=new M({props:{code:"['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']",highlighted:'[<span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>]'}}),cu=new M({props:{code:`predictions = labels.copy()
predictions[2] = "O"
metric.compute(predictions=[predictions], references=[labels])`,highlighted:`predictions = labels.copy()
predictions[<span class="hljs-number">2</span>] = <span class="hljs-string">&quot;O&quot;</span>
metric.compute(predictions=[predictions], references=[labels])`}}),du=new M({props:{code:`{'MISC': {'precision': 1.0, 'recall': 0.5, 'f1': 0.67, 'number': 2},
 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},
 'overall_precision': 1.0,
 'overall_recall': 0.67,
 'overall_f1': 0.8,
 'overall_accuracy': 0.89}`,highlighted:`{<span class="hljs-string">&#x27;MISC&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">1.0</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.5</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.67</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">2</span>},
 <span class="hljs-string">&#x27;ORG&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">1.0</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">1.0</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">1.0</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">1</span>},
 <span class="hljs-string">&#x27;overall_precision&#x27;</span>: <span class="hljs-number">1.0</span>,
 <span class="hljs-string">&#x27;overall_recall&#x27;</span>: <span class="hljs-number">0.67</span>,
 <span class="hljs-string">&#x27;overall_f1&#x27;</span>: <span class="hljs-number">0.8</span>,
 <span class="hljs-string">&#x27;overall_accuracy&#x27;</span>: <span class="hljs-number">0.89</span>}`}});const Jd=[ph,uh],Eu=[];function Qd(t,m){return t[0]==="pt"?0:1}gl=Qd(V),El=Eu[gl]=Jd[gl](V);let _s=V[0]==="pt"&&Rv(V);return mu=new ut({}),fu=new M({props:{code:`from transformers import pipeline

# Remplacez ceci par votre propre checkpoint
model_checkpoint = "huggingface-course/bert-finetuned-ner"
token_classifier = pipeline(
    "token-classification", model=model_checkpoint, aggregation_strategy="simple"
)
token_classifier("My name is Sylvain and I work at Hugging Face in Brooklyn.")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-comment"># Remplacez ceci par votre propre checkpoint</span>
model_checkpoint = <span class="hljs-string">&quot;huggingface-course/bert-finetuned-ner&quot;</span>
token_classifier = pipeline(
    <span class="hljs-string">&quot;token-classification&quot;</span>, model=model_checkpoint, aggregation_strategy=<span class="hljs-string">&quot;simple&quot;</span>
)
token_classifier(<span class="hljs-string">&quot;My name is Sylvain and I work at Hugging Face in Brooklyn.&quot;</span>)`}}),vu=new M({props:{code:`[{'entity_group': 'PER', 'score': 0.9988506, 'word': 'Sylvain', 'start': 11, 'end': 18},
 {'entity_group': 'ORG', 'score': 0.9647625, 'word': 'Hugging Face', 'start': 33, 'end': 45},
 {'entity_group': 'LOC', 'score': 0.9986118, 'word': 'Brooklyn', 'start': 49, 'end': 57}]`,highlighted:`[{<span class="hljs-string">&#x27;entity_group&#x27;</span>: <span class="hljs-string">&#x27;PER&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9988506</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;Sylvain&#x27;</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">11</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">18</span>},
 {<span class="hljs-string">&#x27;entity_group&#x27;</span>: <span class="hljs-string">&#x27;ORG&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9647625</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;Hugging Face&#x27;</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">33</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">45</span>},
 {<span class="hljs-string">&#x27;entity_group&#x27;</span>: <span class="hljs-string">&#x27;LOC&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9986118</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;Brooklyn&#x27;</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">49</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">57</span>}]`}}),{c(){d=l("meta"),g=p(),j(v.$$.fragment),q=p(),O=l("h1"),E=l("a"),k=l("span"),j(D.$$.fragment),y=p(),z=l("span"),B=n("Classification de "),A=l("i"),F=n("tokens"),I=p(),T.c(),W=p(),G=l("p"),S=n("La premi\xE8re application que nous allons explorer est la classification de "),X=l("em"),J=n("tokens"),le=n(". Cette t\xE2che g\xE9n\xE9rique englobe tous les probl\xE8mes qui peuvent \xEAtre formul\xE9s comme l\u2019attribution d\u2019une \xE9tiquette \xE0 chaque "),N=l("em"),U=n("token"),se=n(" d\u2019une phrase, tels que :"),Y=p(),ee=l("ul"),R=l("li"),K=n("la "),me=l("strong"),Me=n("reconnaissance d\u2019entit\xE9s nomm\xE9es (NER de l\u2019anglais "),he=l("em"),H=n("Named Entity Recognition"),oe=n(")"),Q=n(", c\u2019est-\xE0-dire trouver les entit\xE9s (telles que des personnes, des lieux ou des organisations) dans une phrase. Ce t\xE2che peut \xEAtre formul\xE9e comme l\u2019attribution d\u2019une \xE9tiquette \xE0 chaque "),ue=l("em"),Z=n("token"),ce=n(" faisant parti d\u2019une entit\xE9 en ayant une classe sp\xE9cifique par entit\xE9, et une classe pour les "),ss=l("em"),_e=n("tokens"),Ee=n(" ne faisant pas parti d\u2019entit\xE9."),Os=p(),ze=l("li"),Ne=n("le "),ts=l("strong"),ae=l("em"),bs=n("part-of-speech tagging"),$s=n(" (POS)"),Ot=n(", c\u2019est-\xE0-dire marquer chaque mot dans une phrase comme correspondant \xE0 une partie particuli\xE8re (comme un nom, un verbe, un adjectif, etc.)."),Ea=p(),te=l("li"),qa=n("le "),pn=l("strong"),Ps=l("em"),ka=n("chunking"),ja=n(", c\u2019est-\xE0-dire trouver les "),pt=l("em"),ns=n("tokens"),cn=n(" qui appartiennent \xE0 la m\xEAme entit\xE9. Cette t\xE2che (qui peut \xEAtre combin\xE9e avec le POS ou la NER) peut \xEAtre formul\xE9e comme l\u2019attribution d\u2019une \xE9tiquette (habituellement "),Re=l("code"),dn=n("B-"),as=n(") \xE0 tous les "),ct=l("em"),Oe=n("tokens"),Fe=n(" qui sont au d\xE9but d\u2019un morceau, une autre \xE9tiquette (habituellement "),Ds=l("code"),ls=n("I-"),wa=n(") aux "),os=l("em"),dt=n("tokens"),xa=n(" qui sont \xE0 l\u2019int\xE9rieur d\u2019un morceau, et une troisi\xE8me \xE9tiquette (habituellement "),mn=l("code"),fn=n("O"),Pe=n(") aux "),vn=l("em"),mt=n("tokens"),Ca=n(" qui n\u2019appartiennent \xE0 aucun morceau."),Gn=p(),j(gs.$$.fragment),Ws=p(),rs=l("p"),Ms=n("Bien s\xFBr, il existe de nombreux autres types de probl\xE8mes de classification de "),Ns=l("em"),Pt=n("tokens"),Xs=n(". Ce ne sont l\xE0 que quelques exemples repr\xE9sentatifs. Dans cette section, nous allons "),hn=l("em"),Dt=n("finetuner"),Zs=n(" un mod\xE8le (BERT) sur la t\xE2che de NER. Il sera alors capable de calculer des pr\xE9dictions comme celle-ci :"),Un=p(),je=l("iframe"),Vn=p(),we=l("iframe"),_n=p(),pe=l("a"),is=l("img"),Ks=p(),vt=l("img"),Wn=p(),Ys=l("p"),At=n("Vous pouvez trouver, t\xE9l\xE9charger et v\xE9rifier les pr\xE9cisions de ce mod\xE8le sur le "),us=l("a"),Tt=l("em"),fe=n("Hub"),ya=n(" les pr\xE9dictions du mod\xE8le que nous allons entra\xEEner."),St=p(),Es=l("h2"),Ze=l("a"),Js=l("span"),j(Ae.$$.fragment),za=p(),As=l("span"),Oa=n("Pr\xE9paration des donn\xE9es"),Xn=p(),xe=l("p"),$n=n("Tout d\u2019abord, nous avons besoin d\u2019un jeu de donn\xE9es adapt\xE9 \xE0 la classification des "),gn=l("em"),Zn=n("tokens"),Te=n(". Dans cette section, nous utiliserons le jeu de donn\xE9es "),ht=l("a"),En=n("CoNLL-2003"),qn=n(", qui contient des articles de presse de Reuters."),Kn=p(),j(qs.$$.fragment),kn=p(),Be=l("h3"),ps=l("a"),ks=l("span"),j(_t.$$.fragment),Lt=p(),Ts=l("span"),Yn=n("Le jeu de donn\xE9es CoNLL-2003"),Ce=p(),Se=l("p"),It=n("Pour charger le jeu de donn\xE9es CoNLL-2003, nous utilisons la m\xE9thode "),js=l("code"),Pa=n("load_dataset()"),Ss=n(" de la biblioth\xE8que \u{1F917} "),bt=l("em"),Da=n("Datasets"),Jn=n(" :"),cs=p(),j($t.$$.fragment),Rt=p(),ws=l("p"),Ma=n("Cela va t\xE9l\xE9charger et mettre en cache le jeu de donn\xE9es, comme nous l\u2019avons vu dans "),gt=l("a"),Qs=n("Chapitre 3"),et=n(" pour le jeu de donn\xE9es GLUE MRPC. L\u2019inspection de cet objet nous montre les colonnes pr\xE9sentes dans ce jeu de donn\xE9es et la r\xE9partition entre les ensembles d\u2019entra\xEEnement, de validation et de test :"),st=p(),j(Ke.$$.fragment),jn=p(),j(He.$$.fragment),wn=p(),ie=l("p"),Qn=n("En particulier, nous pouvons voir que le jeu de donn\xE9es contient des \xE9tiquettes pour les trois t\xE2ches que nous avons mentionn\xE9es pr\xE9c\xE9demment : NER, POS et "),$e=l("em"),Na=n("chunking"),xn=n(". Une grande diff\xE9rence avec les autres jeux de donn\xE9es est que les entr\xE9es textuelles ne sont pas pr\xE9sent\xE9s comme des phrases ou des documents, mais comme des listes de mots (la derni\xE8re colonne est appel\xE9e "),Et=l("code"),Aa=n("tokens"),Cn=n(", mais elle contient des mots dans le sens o\xF9 ce sont des entr\xE9es pr\xE9tok\xE9nis\xE9es qui doivent encore passer par le "),qt=l("em"),Ta=n("tokenizer"),yn=n(" pour la tokenisation en sous-mots)."),Ft=p(),Bt=l("p"),zn=n("Regardons le premier \xE9l\xE9ment de l\u2019ensemble d\u2019entra\xEEnement :"),On=p(),j(Ye.$$.fragment),Pn=p(),j(f.$$.fragment),L=p(),Dn=l("p"),Sa=n("Puisque nous voulons effectuer reconna\xEEtre des entit\xE9s nomm\xE9es, nous allons examiner les balises NER :"),Ls=p(),j(be.$$.fragment),Mn=p(),j(xs.$$.fragment),La=p(),Is=l("p"),Ht=n("Ce sont les \xE9tiquettes sous forme d\u2019entiers disponibles pour l\u2019entra\xEEnement mais ne sont pas n\xE9cessairement utiles lorsque nous voulons inspecter les donn\xE9es. Comme pour la classification de texte, nous pouvons acc\xE9der \xE0 la correspondance entre ces entiers et les noms des \xE9tiquettes en regardant l\u2019attribut "),Nn=l("code"),kt=n("features"),Gt=n(" de notre jeu de donn\xE9es :"),Ut=p(),j(Vt.$$.fragment),Rs=p(),j(jt.$$.fragment),Fs=p(),ve=l("p"),Wt=n("Cette colonne contient donc des \xE9l\xE9ments qui sont des s\xE9quences de "),tt=l("code"),ql=n("ClassLabel"),An=n(". Le type des \xE9l\xE9ments de la s\xE9quence se trouve dans l\u2019attribut "),ea=l("code"),Tn=n("feature"),ds=n(" de cette "),Xt=l("code"),sa=n("ner_feature"),ta=n(", et nous pouvons acc\xE9der \xE0 la liste des noms en regardant l\u2019attribut "),na=l("code"),Je=n("names"),kl=n(" de cette "),aa=l("code"),la=n("feature"),jl=n(" :"),wt=p(),j(xt.$$.fragment),Ct=p(),j(Ge.$$.fragment),nt=p(),Bs=l("p"),oa=n("Nous avons d\xE9j\xE0 vu ces \xE9tiquettes au "),Ue=l("a"),wl=n("chapitre 6"),Ia=n(" lorsque nous nous sommes int\xE9ress\xE9s au pipeline "),at=l("code"),Ra=n("token-classification"),Hs=n(" mais nosu pouvons tout de m\xEAme faire un rapide rappel :"),Sn=p(),De=l("ul"),Ve=l("li"),ra=l("code"),ia=n("O"),xl=n(" signifie que le mot ne correspond \xE0 aucune entit\xE9."),Cl=p(),yt=l("li"),Ln=l("code"),Uo=n("B-PER"),ua=n("/"),eo=l("code"),so=n("I-PER"),Zr=n(" signifie que le mot correspond au d\xE9but/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),to=l("em"),Vo=n("personne"),Fa=n("."),Wo=p(),Cs=l("li"),yl=l("code"),lt=n("B-ORG"),Kr=n("/"),Ba=l("code"),Yr=n("I-ORG"),Jr=n(" signifie que le mot correspond au d\xE9but/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),Ha=l("em"),Qr=n("organisation"),ei=n("."),no=p(),Zt=l("li"),ao=l("code"),Xo=n("B-LOC"),Ga=n("/"),zl=l("code"),ys=n("I-LOC"),si=n(" signifie que le mot correspond au d\xE9but/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),Ua=l("em"),ti=n("location"),ni=n("."),lo=p(),Kt=l("li"),oo=l("code"),ro=n("B-MISC"),ai=n("/"),io=l("code"),uo=n("I-MISC"),li=n(" signifie que le mot correspond au d\xE9but/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),po=l("em"),Zo=n("divers"),Va=n("."),co=p(),Yt=l("p"),Ko=n("Maintenant, le d\xE9codage des \xE9tiquettes que nous avons vues pr\xE9c\xE9demment nous donne ceci :"),Wa=p(),j(Xa.$$.fragment),mo=p(),j(zt.$$.fragment),fo=p(),We=l("p"),oi=n("Et pour un exemple m\xE9langeant les \xE9tiquettes "),Za=l("code"),ri=n("B-"),ii=n(" et "),Ka=l("code"),ui=n("I-"),pi=n(", voici ce que le m\xEAme code nous donne sur le quatri\xE8me \xE9l\xE9ment du jeu d\u2019entra\xEEnement :"),vo=p(),j(Gs.$$.fragment),In=p(),pa=l("p"),Ya=n("Comme on peut le voir, les entit\xE9s couvrant deux mots, comme \xAB European Union \xBB et \xAB Werner Zwingmann \xBB, se voient attribuer une \xE9tiquette \u201CB-\u201D pour le premier mot et une \xE9tiquette \u201CI-\u201D pour le second."),Yo=p(),j(Jt.$$.fragment),Jo=p(),Qt=l("h3"),ms=l("a"),ho=l("span"),j(Rn.$$.fragment),ci=p(),_o=l("span"),bo=n("Traitement des donn\xE9es"),Qo=p(),j(Ja.$$.fragment),$o=p(),ye=l("p"),er=n("Comme d\u2019habitude, nos textes doivent \xEAtre convertis en identifiants de "),ca=l("em"),di=n("tokens"),sr=n(" avant que le mod\xE8le puisse leur donner un sens. Comme nous l\u2019avons vu au "),Us=l("a"),Qa=n("chapitre 6"),mi=n(", une grande diff\xE9rence dans le cas des t\xE2ches de classification de "),el=l("em"),fi=n("tokens"),vi=n(" est que nous avons des entr\xE9es pr\xE9tok\xE9nis\xE9es. Heureusement, l\u2019API "),go=l("code"),Vs=n("tokenizer"),hi=n(" peut g\xE9rer cela assez facilement"),sl=l("code"),_i=n(". Nous devons juste avertir le "),bi=n("tokenizer` avec un drapeau sp\xE9cial."),Ol=p(),en=l("p"),$i=n("Pour commencer, nous allons cr\xE9er notre objet "),tl=l("code"),gi=n("tokenizer"),Ei=n(". Comme nous l\u2019avons dit pr\xE9c\xE9demment, nous allons utiliser un mod\xE8le BERT pr\xE9-entra\xEEn\xE9, donc nous allons commencer par t\xE9l\xE9charger et mettre en cache le "),nl=l("em"),qi=n("tokenizer"),ki=n(" associ\xE9 :"),tr=p(),j(Xe.$$.fragment),nr=p(),re=l("p"),ji=n("Vous pouvez remplacer le "),Eo=l("code"),qo=n("model_checkpoint"),wi=n(" par tout autre mod\xE8le que vous pr\xE9f\xE9rez \xE0 partir du ["),ko=l("em"),jo=n("Hub"),xi=n("]"),al=l("a"),wo=n("https://huggingface.co/models"),Ci=n("), ou par un dossier local dans lequel vous avez sauvegard\xE9 un mod\xE8le pr\xE9-entra\xEEn\xE9 et un "),xo=l("em"),ar=n("tokenizer"),Pl=n(". La seule contrainte est que le "),Co=l("em"),lr=n("tokenizer"),ll=n(" doit \xEAtre soutenu par la biblioth\xE8que \u{1F917} "),Dl=l("em"),da=n("Tokenizers"),yi=n(". Il y a donc une version rapide disponible. Vous pouvez voir toutes les architectures qui ont une version rapide dans "),Fn=l("a"),zi=n("ce tableau"),Oi=n(", et pour v\xE9rifier que l\u2019objet "),Ml=l("code"),ol=n("tokenizer"),or=n(" que vous utilisez est bien soutenu par \u{1F917} "),ge=l("em"),Pi=n("Tokenizers"),yo=n(" vous pouvez regarder son attribut "),zo=l("code"),Di=n("is_fast"),Oo=n(" :"),rr=p(),j(rl.$$.fragment),Nl=p(),j(il.$$.fragment),ir=p(),ot=l("p"),Mi=n("Pour tokeniser une entr\xE9e pr\xE9tokenis\xE9e, nous pouvons utiliser notre "),Po=l("code"),Do=n("tokenizer"),Ni=n(" comme d\u2019habitude et juste ajouter "),Mo=l("code"),No=n("is_split_into_words=True"),Ai=n(" :"),ur=p(),j(Bn.$$.fragment),pr=p(),j(ul.$$.fragment),Ao=p(),ne=l("p"),Ti=n("Comme on peut le voir, le "),pl=l("em"),Si=n("tokenizer"),Li=n(" a ajout\xE9 les "),Hn=l("em"),To=n("tokens"),Ii=n(" sp\xE9ciaux utilis\xE9s par le mod\xE8le ("),So=l("code"),cr=n("[CLS]"),i=n(" au d\xE9but et "),h=l("code"),Cu=n("[SEP]"),yu=n(" \xE0 la fin) et n\u2019a pas touch\xE9 \xE0 la plupart des mots. Le mot "),dr=l("code"),sn=n("lamb"),zu=n(", cependant, a \xE9t\xE9 tokenis\xE9 en deux sous-mots, "),mr=l("code"),Ou=n("la"),Pu=n(" et "),ma=l("code"),Du=n("##mb"),Mu=n(". Cela introduit un d\xE9calage entre nos entr\xE9es et les \xE9tiquettes : la liste des \xE9tiquettes n\u2019a que 9 \xE9l\xE9ments, alors que notre entr\xE9e a maintenant 12 "),fa=l("em"),Nu=n("tokens"),Au=n(". Il est facile de tenir compte des "),tn=l("em"),Tu=n("tokens"),Su=n(" sp\xE9ciaux (nous savons qu\u2019ils sont au d\xE9but et \xE0 la fin), mais nous devons \xE9galement nous assurer que nous alignons toutes les \xE9tiquettes avec les mots appropri\xE9s."),Ri=p(),fs=l("p"),Lu=n("Heureusement, comme nous utilisons un "),fr=l("em"),Fi=n("tokenizer"),Iu=n(" rapide, nous avons acc\xE8s aux superpouvoirs des \u{1F917} "),va=l("em"),Ru=n("Tokenizers"),Fu=n(", ce qui signifie que nous pouvons facilement faire correspondre chaque "),Al=l("em"),Bu=n("token"),vr=n(" au mot correspondant (comme on le voit au "),Lo=l("a"),hr=n("Chapitre 6"),Hu=n(") :"),vs=p(),j(Tl.$$.fragment),Bi=p(),j(Sl.$$.fragment),Hi=p(),de=l("p"),Gu=n("Avec un peu de travail, nous pouvons \xE9tendre notre liste d\u2019\xE9tiquettes pour qu\u2019elle corresponde aux "),_r=l("em"),br=n("tokens"),Uu=n(". La premi\xE8re r\xE8gle que nous allons appliquer est que les "),Ll=l("em"),Vu=n("tokens"),$r=n(" sp\xE9ciaux re\xE7oivent une \xE9tiquette de "),gr=l("code"),Wu=n("-100"),nn=n(". En effet, par d\xE9faut, "),Er=l("code"),Xu=n("-100"),Zu=n(" est un indice qui est ignor\xE9 dans la fonction de perte que nous allons utiliser (l\u2019entropie crois\xE9e). Ensuite, chaque "),qr=l("em"),kr=n("token"),Ku=n(" re\xE7oit la m\xEAme \xE9tiquette que le "),Il=l("em"),Yu=n("token"),Ju=n(" qui a commenc\xE9 le mot dans lequel il se trouve puisqu\u2019ils font partie de la m\xEAme entit\xE9. Pour les "),jr=l("em"),wr=n("tokens"),Qu=n(" \xE0 l\u2019int\xE9rieur d\u2019un mot mais pas au d\xE9but, nous rempla\xE7ons le "),Rl=l("code"),ep=n("B-"),sp=n(" par "),xr=l("code"),ha=n("I-"),tp=n(" (puisque le "),Cr=l("em"),np=n("token"),yr=n(" ne commence pas l\u2019entit\xE9) :"),Gi=p(),j(an.$$.fragment),Ui=p(),Io=l("p"),zr=n("Essayons-le sur notre premi\xE8re phrase :"),Vi=p(),j(rt.$$.fragment),Wi=p(),j(Fl.$$.fragment),Xi=p(),qe=l("p"),ap=n("Comme nous pouvons le voir, notre fonction a ajout\xE9 "),Or=l("code"),lp=n("-100"),op=n(" pour les deux "),Pr=l("em"),Bl=n("tokens"),rp=n(" sp\xE9ciaux du d\xE9but et de fin, et un nouveau "),Dr=l("code"),Mr=n("0"),ip=n(" pour notre mot qui a \xE9t\xE9 divis\xE9 en deux "),Nr=l("em"),up=n("tokens"),Hl=n("."),Zi=p(),j(cl.$$.fragment),Ki=p(),ke=l("p"),Ar=n("Pour pr\xE9traiter notre jeu de donn\xE9es, nous devons tokeniser toutes les entr\xE9es et appliquer "),Tr=l("code"),ln=n("align_labels_with_tokens()"),pp=n(" sur toutes les \xE9tiquettes. Pour profiter de la vitesse de notre "),Sr=l("em"),cp=n("tokenizer"),dp=n(" rapide, il est pr\xE9f\xE9rable de tokeniser beaucoup de textes en m\xEAme temps. Nous allons donc \xE9crire une fonction qui traite une liste d\u2019exemples et utiliser la m\xE9thode "),it=l("code"),mp=n("Dataset.map()"),fp=n(" avec l\u2019option "),Lr=l("code"),vp=n("batched=True"),hp=n(". La seule chose qui diff\xE8re de notre exemple pr\xE9c\xE9dent est que la fonction "),Gl=l("code"),_p=n("word_ids()"),Qe=n(" a besoin de r\xE9cup\xE9rer l\u2019index de l\u2019exemple dont nous voulons les identifiants de mots lorsque les entr\xE9es du "),Ir=l("em"),bp=n("tokenizer"),$p=n(" sont des listes de textes (ou dans notre cas, des listes de mots), donc nous l\u2019ajoutons aussi :"),Yi=p(),j(Ul.$$.fragment),Ji=p(),Ro=l("p"),Vl=n("Notez que nous n\u2019avons pas encore rembourr\xE9 nos entr\xE9es. Nous le ferons plus tard lors de la cr\xE9ation des batchs avec un collateur de donn\xE9es."),Qi=p(),Fo=l("p"),gp=n("Nous pouvons maintenant appliquer tout ce pr\xE9traitement en une seule fois sur les autres divisions de notre jeu de donn\xE9es :"),dc=p(),j(eu.$$.fragment),mc=p(),Rr=l("p"),Jc=n("Nous avons fait la partie la plus difficile ! Maintenant que les donn\xE9es ont \xE9t\xE9 pr\xE9trait\xE9es, l\u2019entra\xEEnement ressemblera beaucoup \xE0 ce que nous avons fait dans le "),Ep=l("a"),Qc=n("chapitre 3"),ed=n("."),fc=p(),ml.c(),qp=p(),Bo=l("h3"),Fr=l("a"),Xp=l("span"),j(su.$$.fragment),sd=p(),Zp=l("span"),td=n("Collation des donn\xE9es"),vc=p(),on=l("p"),nd=n("Nous ne pouvons pas simplement utiliser un "),Kp=l("code"),ad=n("DataCollatorWithPadding"),ld=n(" comme dans le "),kp=l("a"),od=n("chapitre 3"),rd=n(" car cela ne fait que rembourrer les entr\xE9es (identifiants d\u2019entr\xE9e, masque d\u2019attention et "),Yp=l("em"),id=n("token"),ud=n(" de type identifiants). Ici, nos \xE9tiquettes doivent \xEAtre rembourr\xE9\xE9s exactement de la m\xEAme mani\xE8re que les entr\xE9es afin qu\u2019elles gardent la m\xEAme taille, en utilisant "),Jp=l("code"),pd=n("-100"),cd=n(" comme valeur afin que les pr\xE9dictions correspondantes soient ignor\xE9es dans le calcul de la perte."),hc=p(),_a=l("p"),dd=n("Tout ceci est fait par un "),tu=l("a"),Qp=l("code"),md=n("DataCollatorForTokenClassification"),fd=n(". Comme le "),ec=l("code"),vd=n("DataCollatorWithPadding"),hd=n(", il prend le "),sc=l("code"),_d=n("tokenizer"),bd=n(" utilis\xE9 pour pr\xE9traiter les entr\xE9es :"),_c=p(),vl.c(),jp=p(),wp=l("p"),$d=n("Pour tester cette fonction sur quelques \xE9chantillons, nous pouvons simplement l\u2019appeler sur une liste d\u2019exemples provenant de notre jeu d\u2019entra\xEEnement tok\xE9nis\xE9 :"),bc=p(),j(nu.$$.fragment),$c=p(),j(au.$$.fragment),gc=p(),xp=l("p"),gd=n("Comparons cela aux \xE9tiquettes des premier et deuxi\xE8me \xE9l\xE9ments de notre jeu de donn\xE9es :"),Ec=p(),j(lu.$$.fragment),qc=p(),j(ou.$$.fragment),kc=p(),_l.c(),Cp=p(),hs&&hs.c(),yp=p(),Ho=l("h3"),Br=l("a"),tc=l("span"),j(ru.$$.fragment),Ed=p(),nc=l("span"),qd=n("M\xE9triques"),jc=p(),$l.c(),zp=p(),j(iu.$$.fragment),wc=p(),Op=l("p"),kd=n("Cette m\xE9trique ne se comporte pas comme la pr\xE9cision standard : elle prend les listes d\u2019\xE9tiquettes comme des cha\xEEnes de caract\xE8res et non comme des entiers. Nous devrons donc d\xE9coder compl\xE8tement les pr\xE9dictions et les \xE9tiquettes avant de les transmettre \xE0 la m\xE9trique. Voyons comment cela fonctionne. Tout d\u2019abord, nous allons obtenir les \xE9tiquettes pour notre premier exemple d\u2019entra\xEEnement :"),xc=p(),j(uu.$$.fragment),Cc=p(),j(pu.$$.fragment),yc=p(),Pp=l("p"),jd=n("Nous pouvons alors cr\xE9er de fausses pr\xE9dictions pour celles-ci en changeant simplement la valeur de l\u2019indice 2 :"),zc=p(),j(cu.$$.fragment),Oc=p(),Dp=l("p"),wd=n("Notez que la m\xE9trique prend une liste de pr\xE9dictions (pas seulement une) et une liste d\u2019\xE9tiquettes. Voici la sortie :"),Pc=p(),j(du.$$.fragment),Dc=p(),El.c(),Mp=p(),_s&&_s.c(),Np=p(),Go=l("h3"),Hr=l("a"),ac=l("span"),j(mu.$$.fragment),xd=p(),Ap=l("span"),Cd=n("Utilisation du mod\xE8le "),lc=l("i"),yd=n("finetun\xE9"),Mc=p(),rn=l("p"),zd=n("Nous vous avons d\xE9j\xE0 montr\xE9 comment vous pouvez utiliser le mod\xE8le "),oc=l("em"),Od=n("finetun\xE9"),Pd=n(" sur le "),rc=l("em"),Dd=n("Hub"),Md=n(" avec le "),ic=l("em"),Nd=n("widget"),Ad=n(" d\u2019inf\xE9rence. Pour l\u2019utiliser localement dans un "),uc=l("code"),Td=n("pipeline"),Sd=n(", vous devez juste sp\xE9cifier l\u2019identifiant de mod\xE8le appropri\xE9 :"),Nc=p(),j(fu.$$.fragment),Ac=p(),j(vu.$$.fragment),Tc=p(),Tp=l("p"),Ld=n("Super ! Notre mod\xE8le fonctionne aussi bien que le mod\xE8le par d\xE9faut pour ce pipeline !"),this.h()},l(t){const m=Uv('[data-svelte="svelte-1phssyn"]',document.head);d=o(m,"META",{name:!0,content:!0}),m.forEach(s),g=c(t),w(v.$$.fragment,t),q=c(t),O=o(t,"H1",{class:!0});var qu=r(O);E=o(qu,"A",{id:!0,class:!0,href:!0});var Sp=r(E);k=o(Sp,"SPAN",{});var pc=r(k);w(D.$$.fragment,pc),pc.forEach(s),Sp.forEach(s),y=c(qu),z=o(qu,"SPAN",{});var Lp=r(z);B=a(Lp,"Classification de "),A=o(Lp,"I",{});var cc=r(A);F=a(cc,"tokens"),cc.forEach(s),Lp.forEach(s),qu.forEach(s),I=c(t),T.l(t),W=c(t),G=o(t,"P",{});var Wl=r(G);S=a(Wl,"La premi\xE8re application que nous allons explorer est la classification de "),X=o(Wl,"EM",{});var Ip=r(X);J=a(Ip,"tokens"),Ip.forEach(s),le=a(Wl,". Cette t\xE2che g\xE9n\xE9rique englobe tous les probl\xE8mes qui peuvent \xEAtre formul\xE9s comme l\u2019attribution d\u2019une \xE9tiquette \xE0 chaque "),N=o(Wl,"EM",{});var Rp=r(N);U=a(Rp,"token"),Rp.forEach(s),se=a(Wl," d\u2019une phrase, tels que :"),Wl.forEach(s),Y=c(t),ee=o(t,"UL",{});var Xl=r(ee);R=o(Xl,"LI",{});var ba=r(R);K=a(ba,"la "),me=o(ba,"STRONG",{});var Lc=r(me);Me=a(Lc,"reconnaissance d\u2019entit\xE9s nomm\xE9es (NER de l\u2019anglais "),he=o(Lc,"EM",{});var em=r(he);H=a(em,"Named Entity Recognition"),em.forEach(s),oe=a(Lc,")"),Lc.forEach(s),Q=a(ba,", c\u2019est-\xE0-dire trouver les entit\xE9s (telles que des personnes, des lieux ou des organisations) dans une phrase. Ce t\xE2che peut \xEAtre formul\xE9e comme l\u2019attribution d\u2019une \xE9tiquette \xE0 chaque "),ue=o(ba,"EM",{});var sm=r(ue);Z=a(sm,"token"),sm.forEach(s),ce=a(ba," faisant parti d\u2019une entit\xE9 en ayant une classe sp\xE9cifique par entit\xE9, et une classe pour les "),ss=o(ba,"EM",{});var tm=r(ss);_e=a(tm,"tokens"),tm.forEach(s),Ee=a(ba," ne faisant pas parti d\u2019entit\xE9."),ba.forEach(s),Os=c(Xl),ze=o(Xl,"LI",{});var Ic=r(ze);Ne=a(Ic,"le "),ts=o(Ic,"STRONG",{});var Id=r(ts);ae=o(Id,"EM",{});var nm=r(ae);bs=a(nm,"part-of-speech tagging"),nm.forEach(s),$s=a(Id," (POS)"),Id.forEach(s),Ot=a(Ic,", c\u2019est-\xE0-dire marquer chaque mot dans une phrase comme correspondant \xE0 une partie particuli\xE8re (comme un nom, un verbe, un adjectif, etc.)."),Ic.forEach(s),Ea=c(Xl),te=o(Xl,"LI",{});var zs=r(te);qa=a(zs,"le "),pn=o(zs,"STRONG",{});var am=r(pn);Ps=o(am,"EM",{});var lm=r(Ps);ka=a(lm,"chunking"),lm.forEach(s),am.forEach(s),ja=a(zs,", c\u2019est-\xE0-dire trouver les "),pt=o(zs,"EM",{});var om=r(pt);ns=a(om,"tokens"),om.forEach(s),cn=a(zs," qui appartiennent \xE0 la m\xEAme entit\xE9. Cette t\xE2che (qui peut \xEAtre combin\xE9e avec le POS ou la NER) peut \xEAtre formul\xE9e comme l\u2019attribution d\u2019une \xE9tiquette (habituellement "),Re=o(zs,"CODE",{});var rm=r(Re);dn=a(rm,"B-"),rm.forEach(s),as=a(zs,") \xE0 tous les "),ct=o(zs,"EM",{});var im=r(ct);Oe=a(im,"tokens"),im.forEach(s),Fe=a(zs," qui sont au d\xE9but d\u2019un morceau, une autre \xE9tiquette (habituellement "),Ds=o(zs,"CODE",{});var um=r(Ds);ls=a(um,"I-"),um.forEach(s),wa=a(zs,") aux "),os=o(zs,"EM",{});var pm=r(os);dt=a(pm,"tokens"),pm.forEach(s),xa=a(zs," qui sont \xE0 l\u2019int\xE9rieur d\u2019un morceau, et une troisi\xE8me \xE9tiquette (habituellement "),mn=o(zs,"CODE",{});var cm=r(mn);fn=a(cm,"O"),cm.forEach(s),Pe=a(zs,") aux "),vn=o(zs,"EM",{});var dm=r(vn);mt=a(dm,"tokens"),dm.forEach(s),Ca=a(zs," qui n\u2019appartiennent \xE0 aucun morceau."),zs.forEach(s),Xl.forEach(s),Gn=c(t),w(gs.$$.fragment,t),Ws=c(t),rs=o(t,"P",{});var Fp=r(rs);Ms=a(Fp,"Bien s\xFBr, il existe de nombreux autres types de probl\xE8mes de classification de "),Ns=o(Fp,"EM",{});var mm=r(Ns);Pt=a(mm,"tokens"),mm.forEach(s),Xs=a(Fp,". Ce ne sont l\xE0 que quelques exemples repr\xE9sentatifs. Dans cette section, nous allons "),hn=o(Fp,"EM",{});var fm=r(hn);Dt=a(fm,"finetuner"),fm.forEach(s),Zs=a(Fp," un mod\xE8le (BERT) sur la t\xE2che de NER. Il sera alors capable de calculer des pr\xE9dictions comme celle-ci :"),Fp.forEach(s),Un=c(t),je=o(t,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),r(je).forEach(s),Vn=c(t),we=o(t,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),r(we).forEach(s),_n=c(t),pe=o(t,"A",{class:!0,href:!0});var Rc=r(pe);is=o(Rc,"IMG",{class:!0,src:!0,alt:!0}),Ks=c(Rc),vt=o(Rc,"IMG",{class:!0,src:!0,alt:!0}),Rc.forEach(s),Wn=c(t),Ys=o(t,"P",{});var Fc=r(Ys);At=a(Fc,"Vous pouvez trouver, t\xE9l\xE9charger et v\xE9rifier les pr\xE9cisions de ce mod\xE8le sur le "),us=o(Fc,"A",{href:!0,rel:!0});var vm=r(us);Tt=o(vm,"EM",{});var hm=r(Tt);fe=a(hm,"Hub"),hm.forEach(s),vm.forEach(s),ya=a(Fc," les pr\xE9dictions du mod\xE8le que nous allons entra\xEEner."),Fc.forEach(s),St=c(t),Es=o(t,"H2",{class:!0});var Bc=r(Es);Ze=o(Bc,"A",{id:!0,class:!0,href:!0});var _m=r(Ze);Js=o(_m,"SPAN",{});var bm=r(Js);w(Ae.$$.fragment,bm),bm.forEach(s),_m.forEach(s),za=c(Bc),As=o(Bc,"SPAN",{});var $m=r(As);Oa=a($m,"Pr\xE9paration des donn\xE9es"),$m.forEach(s),Bc.forEach(s),Xn=c(t),xe=o(t,"P",{});var Bp=r(xe);$n=a(Bp,"Tout d\u2019abord, nous avons besoin d\u2019un jeu de donn\xE9es adapt\xE9 \xE0 la classification des "),gn=o(Bp,"EM",{});var gm=r(gn);Zn=a(gm,"tokens"),gm.forEach(s),Te=a(Bp,". Dans cette section, nous utiliserons le jeu de donn\xE9es "),ht=o(Bp,"A",{href:!0,rel:!0});var Em=r(ht);En=a(Em,"CoNLL-2003"),Em.forEach(s),qn=a(Bp,", qui contient des articles de presse de Reuters."),Bp.forEach(s),Kn=c(t),w(qs.$$.fragment,t),kn=c(t),Be=o(t,"H3",{class:!0});var Hc=r(Be);ps=o(Hc,"A",{id:!0,class:!0,href:!0});var qm=r(ps);ks=o(qm,"SPAN",{});var km=r(ks);w(_t.$$.fragment,km),km.forEach(s),qm.forEach(s),Lt=c(Hc),Ts=o(Hc,"SPAN",{});var jm=r(Ts);Yn=a(jm,"Le jeu de donn\xE9es CoNLL-2003"),jm.forEach(s),Hc.forEach(s),Ce=c(t),Se=o(t,"P",{});var Hp=r(Se);It=a(Hp,"Pour charger le jeu de donn\xE9es CoNLL-2003, nous utilisons la m\xE9thode "),js=o(Hp,"CODE",{});var wm=r(js);Pa=a(wm,"load_dataset()"),wm.forEach(s),Ss=a(Hp," de la biblioth\xE8que \u{1F917} "),bt=o(Hp,"EM",{});var xm=r(bt);Da=a(xm,"Datasets"),xm.forEach(s),Jn=a(Hp," :"),Hp.forEach(s),cs=c(t),w($t.$$.fragment,t),Rt=c(t),ws=o(t,"P",{});var Gc=r(ws);Ma=a(Gc,"Cela va t\xE9l\xE9charger et mettre en cache le jeu de donn\xE9es, comme nous l\u2019avons vu dans "),gt=o(Gc,"A",{href:!0});var Cm=r(gt);Qs=a(Cm,"Chapitre 3"),Cm.forEach(s),et=a(Gc," pour le jeu de donn\xE9es GLUE MRPC. L\u2019inspection de cet objet nous montre les colonnes pr\xE9sentes dans ce jeu de donn\xE9es et la r\xE9partition entre les ensembles d\u2019entra\xEEnement, de validation et de test :"),Gc.forEach(s),st=c(t),w(Ke.$$.fragment,t),jn=c(t),w(He.$$.fragment,t),wn=c(t),ie=o(t,"P",{});var Gr=r(ie);Qn=a(Gr,"En particulier, nous pouvons voir que le jeu de donn\xE9es contient des \xE9tiquettes pour les trois t\xE2ches que nous avons mentionn\xE9es pr\xE9c\xE9demment : NER, POS et "),$e=o(Gr,"EM",{});var ym=r($e);Na=a(ym,"chunking"),ym.forEach(s),xn=a(Gr,". Une grande diff\xE9rence avec les autres jeux de donn\xE9es est que les entr\xE9es textuelles ne sont pas pr\xE9sent\xE9s comme des phrases ou des documents, mais comme des listes de mots (la derni\xE8re colonne est appel\xE9e "),Et=o(Gr,"CODE",{});var zm=r(Et);Aa=a(zm,"tokens"),zm.forEach(s),Cn=a(Gr,", mais elle contient des mots dans le sens o\xF9 ce sont des entr\xE9es pr\xE9tok\xE9nis\xE9es qui doivent encore passer par le "),qt=o(Gr,"EM",{});var Om=r(qt);Ta=a(Om,"tokenizer"),Om.forEach(s),yn=a(Gr," pour la tokenisation en sous-mots)."),Gr.forEach(s),Ft=c(t),Bt=o(t,"P",{});var Pm=r(Bt);zn=a(Pm,"Regardons le premier \xE9l\xE9ment de l\u2019ensemble d\u2019entra\xEEnement :"),Pm.forEach(s),On=c(t),w(Ye.$$.fragment,t),Pn=c(t),w(f.$$.fragment,t),L=c(t),Dn=o(t,"P",{});var Dm=r(Dn);Sa=a(Dm,"Puisque nous voulons effectuer reconna\xEEtre des entit\xE9s nomm\xE9es, nous allons examiner les balises NER :"),Dm.forEach(s),Ls=c(t),w(be.$$.fragment,t),Mn=c(t),w(xs.$$.fragment,t),La=c(t),Is=o(t,"P",{});var Uc=r(Is);Ht=a(Uc,"Ce sont les \xE9tiquettes sous forme d\u2019entiers disponibles pour l\u2019entra\xEEnement mais ne sont pas n\xE9cessairement utiles lorsque nous voulons inspecter les donn\xE9es. Comme pour la classification de texte, nous pouvons acc\xE9der \xE0 la correspondance entre ces entiers et les noms des \xE9tiquettes en regardant l\u2019attribut "),Nn=o(Uc,"CODE",{});var Mm=r(Nn);kt=a(Mm,"features"),Mm.forEach(s),Gt=a(Uc," de notre jeu de donn\xE9es :"),Uc.forEach(s),Ut=c(t),w(Vt.$$.fragment,t),Rs=c(t),w(jt.$$.fragment,t),Fs=c(t),ve=o(t,"P",{});var $a=r(ve);Wt=a($a,"Cette colonne contient donc des \xE9l\xE9ments qui sont des s\xE9quences de "),tt=o($a,"CODE",{});var Nm=r(tt);ql=a(Nm,"ClassLabel"),Nm.forEach(s),An=a($a,". Le type des \xE9l\xE9ments de la s\xE9quence se trouve dans l\u2019attribut "),ea=o($a,"CODE",{});var Am=r(ea);Tn=a(Am,"feature"),Am.forEach(s),ds=a($a," de cette "),Xt=o($a,"CODE",{});var Tm=r(Xt);sa=a(Tm,"ner_feature"),Tm.forEach(s),ta=a($a,", et nous pouvons acc\xE9der \xE0 la liste des noms en regardant l\u2019attribut "),na=o($a,"CODE",{});var Sm=r(na);Je=a(Sm,"names"),Sm.forEach(s),kl=a($a," de cette "),aa=o($a,"CODE",{});var Lm=r(aa);la=a(Lm,"feature"),Lm.forEach(s),jl=a($a," :"),$a.forEach(s),wt=c(t),w(xt.$$.fragment,t),Ct=c(t),w(Ge.$$.fragment,t),nt=c(t),Bs=o(t,"P",{});var Gp=r(Bs);oa=a(Gp,"Nous avons d\xE9j\xE0 vu ces \xE9tiquettes au "),Ue=o(Gp,"A",{href:!0});var Im=r(Ue);wl=a(Im,"chapitre 6"),Im.forEach(s),Ia=a(Gp," lorsque nous nous sommes int\xE9ress\xE9s au pipeline "),at=o(Gp,"CODE",{});var Rm=r(at);Ra=a(Rm,"token-classification"),Rm.forEach(s),Hs=a(Gp," mais nosu pouvons tout de m\xEAme faire un rapide rappel :"),Gp.forEach(s),Sn=c(t),De=o(t,"UL",{});var Zl=r(De);Ve=o(Zl,"LI",{});var Rd=r(Ve);ra=o(Rd,"CODE",{});var Fm=r(ra);ia=a(Fm,"O"),Fm.forEach(s),xl=a(Rd," signifie que le mot ne correspond \xE0 aucune entit\xE9."),Rd.forEach(s),Cl=c(Zl),yt=o(Zl,"LI",{});var ku=r(yt);Ln=o(ku,"CODE",{});var Bm=r(Ln);Uo=a(Bm,"B-PER"),Bm.forEach(s),ua=a(ku,"/"),eo=o(ku,"CODE",{});var Hm=r(eo);so=a(Hm,"I-PER"),Hm.forEach(s),Zr=a(ku," signifie que le mot correspond au d\xE9but/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),to=o(ku,"EM",{});var Gm=r(to);Vo=a(Gm,"personne"),Gm.forEach(s),Fa=a(ku,"."),ku.forEach(s),Wo=c(Zl),Cs=o(Zl,"LI",{});var ju=r(Cs);yl=o(ju,"CODE",{});var Um=r(yl);lt=a(Um,"B-ORG"),Um.forEach(s),Kr=a(ju,"/"),Ba=o(ju,"CODE",{});var Vm=r(Ba);Yr=a(Vm,"I-ORG"),Vm.forEach(s),Jr=a(ju," signifie que le mot correspond au d\xE9but/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),Ha=o(ju,"EM",{});var Wm=r(Ha);Qr=a(Wm,"organisation"),Wm.forEach(s),ei=a(ju,"."),ju.forEach(s),no=c(Zl),Zt=o(Zl,"LI",{});var wu=r(Zt);ao=o(wu,"CODE",{});var Xm=r(ao);Xo=a(Xm,"B-LOC"),Xm.forEach(s),Ga=a(wu,"/"),zl=o(wu,"CODE",{});var Zm=r(zl);ys=a(Zm,"I-LOC"),Zm.forEach(s),si=a(wu," signifie que le mot correspond au d\xE9but/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),Ua=o(wu,"EM",{});var Km=r(Ua);ti=a(Km,"location"),Km.forEach(s),ni=a(wu,"."),wu.forEach(s),lo=c(Zl),Kt=o(Zl,"LI",{});var xu=r(Kt);oo=o(xu,"CODE",{});var Ym=r(oo);ro=a(Ym,"B-MISC"),Ym.forEach(s),ai=a(xu,"/"),io=o(xu,"CODE",{});var Jm=r(io);uo=a(Jm,"I-MISC"),Jm.forEach(s),li=a(xu," signifie que le mot correspond au d\xE9but/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),po=o(xu,"EM",{});var Qm=r(po);Zo=a(Qm,"divers"),Qm.forEach(s),Va=a(xu,"."),xu.forEach(s),Zl.forEach(s),co=c(t),Yt=o(t,"P",{});var ef=r(Yt);Ko=a(ef,"Maintenant, le d\xE9codage des \xE9tiquettes que nous avons vues pr\xE9c\xE9demment nous donne ceci :"),ef.forEach(s),Wa=c(t),w(Xa.$$.fragment,t),mo=c(t),w(zt.$$.fragment,t),fo=c(t),We=o(t,"P",{});var Up=r(We);oi=a(Up,"Et pour un exemple m\xE9langeant les \xE9tiquettes "),Za=o(Up,"CODE",{});var sf=r(Za);ri=a(sf,"B-"),sf.forEach(s),ii=a(Up," et "),Ka=o(Up,"CODE",{});var tf=r(Ka);ui=a(tf,"I-"),tf.forEach(s),pi=a(Up,", voici ce que le m\xEAme code nous donne sur le quatri\xE8me \xE9l\xE9ment du jeu d\u2019entra\xEEnement :"),Up.forEach(s),vo=c(t),w(Gs.$$.fragment,t),In=c(t),pa=o(t,"P",{});var nf=r(pa);Ya=a(nf,"Comme on peut le voir, les entit\xE9s couvrant deux mots, comme \xAB European Union \xBB et \xAB Werner Zwingmann \xBB, se voient attribuer une \xE9tiquette \u201CB-\u201D pour le premier mot et une \xE9tiquette \u201CI-\u201D pour le second."),nf.forEach(s),Yo=c(t),w(Jt.$$.fragment,t),Jo=c(t),Qt=o(t,"H3",{class:!0});var Vc=r(Qt);ms=o(Vc,"A",{id:!0,class:!0,href:!0});var af=r(ms);ho=o(af,"SPAN",{});var lf=r(ho);w(Rn.$$.fragment,lf),lf.forEach(s),af.forEach(s),ci=c(Vc),_o=o(Vc,"SPAN",{});var of=r(_o);bo=a(of,"Traitement des donn\xE9es"),of.forEach(s),Vc.forEach(s),Qo=c(t),w(Ja.$$.fragment,t),$o=c(t),ye=o(t,"P",{});var ga=r(ye);er=a(ga,"Comme d\u2019habitude, nos textes doivent \xEAtre convertis en identifiants de "),ca=o(ga,"EM",{});var rf=r(ca);di=a(rf,"tokens"),rf.forEach(s),sr=a(ga," avant que le mod\xE8le puisse leur donner un sens. Comme nous l\u2019avons vu au "),Us=o(ga,"A",{href:!0});var uf=r(Us);Qa=a(uf,"chapitre 6"),uf.forEach(s),mi=a(ga,", une grande diff\xE9rence dans le cas des t\xE2ches de classification de "),el=o(ga,"EM",{});var pf=r(el);fi=a(pf,"tokens"),pf.forEach(s),vi=a(ga," est que nous avons des entr\xE9es pr\xE9tok\xE9nis\xE9es. Heureusement, l\u2019API "),go=o(ga,"CODE",{});var cf=r(go);Vs=a(cf,"tokenizer"),cf.forEach(s),hi=a(ga," peut g\xE9rer cela assez facilement"),sl=o(ga,"CODE",{});var df=r(sl);_i=a(df,". Nous devons juste avertir le "),df.forEach(s),bi=a(ga,"tokenizer` avec un drapeau sp\xE9cial."),ga.forEach(s),Ol=c(t),en=o(t,"P",{});var Vp=r(en);$i=a(Vp,"Pour commencer, nous allons cr\xE9er notre objet "),tl=o(Vp,"CODE",{});var mf=r(tl);gi=a(mf,"tokenizer"),mf.forEach(s),Ei=a(Vp,". Comme nous l\u2019avons dit pr\xE9c\xE9demment, nous allons utiliser un mod\xE8le BERT pr\xE9-entra\xEEn\xE9, donc nous allons commencer par t\xE9l\xE9charger et mettre en cache le "),nl=o(Vp,"EM",{});var ff=r(nl);qi=a(ff,"tokenizer"),ff.forEach(s),ki=a(Vp," associ\xE9 :"),Vp.forEach(s),tr=c(t),w(Xe.$$.fragment,t),nr=c(t),re=o(t,"P",{});var Le=r(re);ji=a(Le,"Vous pouvez remplacer le "),Eo=o(Le,"CODE",{});var vf=r(Eo);qo=a(vf,"model_checkpoint"),vf.forEach(s),wi=a(Le," par tout autre mod\xE8le que vous pr\xE9f\xE9rez \xE0 partir du ["),ko=o(Le,"EM",{});var hf=r(ko);jo=a(hf,"Hub"),hf.forEach(s),xi=a(Le,"]"),al=o(Le,"A",{href:!0,rel:!0});var _f=r(al);wo=a(_f,"https://huggingface.co/models"),_f.forEach(s),Ci=a(Le,"), ou par un dossier local dans lequel vous avez sauvegard\xE9 un mod\xE8le pr\xE9-entra\xEEn\xE9 et un "),xo=o(Le,"EM",{});var bf=r(xo);ar=a(bf,"tokenizer"),bf.forEach(s),Pl=a(Le,". La seule contrainte est que le "),Co=o(Le,"EM",{});var $f=r(Co);lr=a($f,"tokenizer"),$f.forEach(s),ll=a(Le," doit \xEAtre soutenu par la biblioth\xE8que \u{1F917} "),Dl=o(Le,"EM",{});var gf=r(Dl);da=a(gf,"Tokenizers"),gf.forEach(s),yi=a(Le,". Il y a donc une version rapide disponible. Vous pouvez voir toutes les architectures qui ont une version rapide dans "),Fn=o(Le,"A",{href:!0,rel:!0});var Ef=r(Fn);zi=a(Ef,"ce tableau"),Ef.forEach(s),Oi=a(Le,", et pour v\xE9rifier que l\u2019objet "),Ml=o(Le,"CODE",{});var qf=r(Ml);ol=a(qf,"tokenizer"),qf.forEach(s),or=a(Le," que vous utilisez est bien soutenu par \u{1F917} "),ge=o(Le,"EM",{});var kf=r(ge);Pi=a(kf,"Tokenizers"),kf.forEach(s),yo=a(Le," vous pouvez regarder son attribut "),zo=o(Le,"CODE",{});var jf=r(zo);Di=a(jf,"is_fast"),jf.forEach(s),Oo=a(Le," :"),Le.forEach(s),rr=c(t),w(rl.$$.fragment,t),Nl=c(t),w(il.$$.fragment,t),ir=c(t),ot=o(t,"P",{});var Wp=r(ot);Mi=a(Wp,"Pour tokeniser une entr\xE9e pr\xE9tokenis\xE9e, nous pouvons utiliser notre "),Po=o(Wp,"CODE",{});var wf=r(Po);Do=a(wf,"tokenizer"),wf.forEach(s),Ni=a(Wp," comme d\u2019habitude et juste ajouter "),Mo=o(Wp,"CODE",{});var xf=r(Mo);No=a(xf,"is_split_into_words=True"),xf.forEach(s),Ai=a(Wp," :"),Wp.forEach(s),ur=c(t),w(Bn.$$.fragment,t),pr=c(t),w(ul.$$.fragment,t),Ao=c(t),ne=o(t,"P",{});var es=r(ne);Ti=a(es,"Comme on peut le voir, le "),pl=o(es,"EM",{});var Cf=r(pl);Si=a(Cf,"tokenizer"),Cf.forEach(s),Li=a(es," a ajout\xE9 les "),Hn=o(es,"EM",{});var yf=r(Hn);To=a(yf,"tokens"),yf.forEach(s),Ii=a(es," sp\xE9ciaux utilis\xE9s par le mod\xE8le ("),So=o(es,"CODE",{});var zf=r(So);cr=a(zf,"[CLS]"),zf.forEach(s),i=a(es," au d\xE9but et "),h=o(es,"CODE",{});var Of=r(h);Cu=a(Of,"[SEP]"),Of.forEach(s),yu=a(es," \xE0 la fin) et n\u2019a pas touch\xE9 \xE0 la plupart des mots. Le mot "),dr=o(es,"CODE",{});var Pf=r(dr);sn=a(Pf,"lamb"),Pf.forEach(s),zu=a(es,", cependant, a \xE9t\xE9 tokenis\xE9 en deux sous-mots, "),mr=o(es,"CODE",{});var Df=r(mr);Ou=a(Df,"la"),Df.forEach(s),Pu=a(es," et "),ma=o(es,"CODE",{});var Mf=r(ma);Du=a(Mf,"##mb"),Mf.forEach(s),Mu=a(es,". Cela introduit un d\xE9calage entre nos entr\xE9es et les \xE9tiquettes : la liste des \xE9tiquettes n\u2019a que 9 \xE9l\xE9ments, alors que notre entr\xE9e a maintenant 12 "),fa=o(es,"EM",{});var Nf=r(fa);Nu=a(Nf,"tokens"),Nf.forEach(s),Au=a(es,". Il est facile de tenir compte des "),tn=o(es,"EM",{});var Af=r(tn);Tu=a(Af,"tokens"),Af.forEach(s),Su=a(es," sp\xE9ciaux (nous savons qu\u2019ils sont au d\xE9but et \xE0 la fin), mais nous devons \xE9galement nous assurer que nous alignons toutes les \xE9tiquettes avec les mots appropri\xE9s."),es.forEach(s),Ri=c(t),fs=o(t,"P",{});var Kl=r(fs);Lu=a(Kl,"Heureusement, comme nous utilisons un "),fr=o(Kl,"EM",{});var Tf=r(fr);Fi=a(Tf,"tokenizer"),Tf.forEach(s),Iu=a(Kl," rapide, nous avons acc\xE8s aux superpouvoirs des \u{1F917} "),va=o(Kl,"EM",{});var Sf=r(va);Ru=a(Sf,"Tokenizers"),Sf.forEach(s),Fu=a(Kl,", ce qui signifie que nous pouvons facilement faire correspondre chaque "),Al=o(Kl,"EM",{});var Lf=r(Al);Bu=a(Lf,"token"),Lf.forEach(s),vr=a(Kl," au mot correspondant (comme on le voit au "),Lo=o(Kl,"A",{href:!0});var If=r(Lo);hr=a(If,"Chapitre 6"),If.forEach(s),Hu=a(Kl,") :"),Kl.forEach(s),vs=c(t),w(Tl.$$.fragment,t),Bi=c(t),w(Sl.$$.fragment,t),Hi=c(t),de=o(t,"P",{});var Ie=r(de);Gu=a(Ie,"Avec un peu de travail, nous pouvons \xE9tendre notre liste d\u2019\xE9tiquettes pour qu\u2019elle corresponde aux "),_r=o(Ie,"EM",{});var Rf=r(_r);br=a(Rf,"tokens"),Rf.forEach(s),Uu=a(Ie,". La premi\xE8re r\xE8gle que nous allons appliquer est que les "),Ll=o(Ie,"EM",{});var Ff=r(Ll);Vu=a(Ff,"tokens"),Ff.forEach(s),$r=a(Ie," sp\xE9ciaux re\xE7oivent une \xE9tiquette de "),gr=o(Ie,"CODE",{});var Bf=r(gr);Wu=a(Bf,"-100"),Bf.forEach(s),nn=a(Ie,". En effet, par d\xE9faut, "),Er=o(Ie,"CODE",{});var Hf=r(Er);Xu=a(Hf,"-100"),Hf.forEach(s),Zu=a(Ie," est un indice qui est ignor\xE9 dans la fonction de perte que nous allons utiliser (l\u2019entropie crois\xE9e). Ensuite, chaque "),qr=o(Ie,"EM",{});var Gf=r(qr);kr=a(Gf,"token"),Gf.forEach(s),Ku=a(Ie," re\xE7oit la m\xEAme \xE9tiquette que le "),Il=o(Ie,"EM",{});var Uf=r(Il);Yu=a(Uf,"token"),Uf.forEach(s),Ju=a(Ie," qui a commenc\xE9 le mot dans lequel il se trouve puisqu\u2019ils font partie de la m\xEAme entit\xE9. Pour les "),jr=o(Ie,"EM",{});var Vf=r(jr);wr=a(Vf,"tokens"),Vf.forEach(s),Qu=a(Ie," \xE0 l\u2019int\xE9rieur d\u2019un mot mais pas au d\xE9but, nous rempla\xE7ons le "),Rl=o(Ie,"CODE",{});var Wf=r(Rl);ep=a(Wf,"B-"),Wf.forEach(s),sp=a(Ie," par "),xr=o(Ie,"CODE",{});var Xf=r(xr);ha=a(Xf,"I-"),Xf.forEach(s),tp=a(Ie," (puisque le "),Cr=o(Ie,"EM",{});var Zf=r(Cr);np=a(Zf,"token"),Zf.forEach(s),yr=a(Ie," ne commence pas l\u2019entit\xE9) :"),Ie.forEach(s),Gi=c(t),w(an.$$.fragment,t),Ui=c(t),Io=o(t,"P",{});var Kf=r(Io);zr=a(Kf,"Essayons-le sur notre premi\xE8re phrase :"),Kf.forEach(s),Vi=c(t),w(rt.$$.fragment,t),Wi=c(t),w(Fl.$$.fragment,t),Xi=c(t),qe=o(t,"P",{});var Yl=r(qe);ap=a(Yl,"Comme nous pouvons le voir, notre fonction a ajout\xE9 "),Or=o(Yl,"CODE",{});var Yf=r(Or);lp=a(Yf,"-100"),Yf.forEach(s),op=a(Yl," pour les deux "),Pr=o(Yl,"EM",{});var Jf=r(Pr);Bl=a(Jf,"tokens"),Jf.forEach(s),rp=a(Yl," sp\xE9ciaux du d\xE9but et de fin, et un nouveau "),Dr=o(Yl,"CODE",{});var Qf=r(Dr);Mr=a(Qf,"0"),Qf.forEach(s),ip=a(Yl," pour notre mot qui a \xE9t\xE9 divis\xE9 en deux "),Nr=o(Yl,"EM",{});var ev=r(Nr);up=a(ev,"tokens"),ev.forEach(s),Hl=a(Yl,"."),Yl.forEach(s),Zi=c(t),w(cl.$$.fragment,t),Ki=c(t),ke=o(t,"P",{});var un=r(ke);Ar=a(un,"Pour pr\xE9traiter notre jeu de donn\xE9es, nous devons tokeniser toutes les entr\xE9es et appliquer "),Tr=o(un,"CODE",{});var sv=r(Tr);ln=a(sv,"align_labels_with_tokens()"),sv.forEach(s),pp=a(un," sur toutes les \xE9tiquettes. Pour profiter de la vitesse de notre "),Sr=o(un,"EM",{});var tv=r(Sr);cp=a(tv,"tokenizer"),tv.forEach(s),dp=a(un," rapide, il est pr\xE9f\xE9rable de tokeniser beaucoup de textes en m\xEAme temps. Nous allons donc \xE9crire une fonction qui traite une liste d\u2019exemples et utiliser la m\xE9thode "),it=o(un,"CODE",{});var nv=r(it);mp=a(nv,"Dataset.map()"),nv.forEach(s),fp=a(un," avec l\u2019option "),Lr=o(un,"CODE",{});var av=r(Lr);vp=a(av,"batched=True"),av.forEach(s),hp=a(un,". La seule chose qui diff\xE8re de notre exemple pr\xE9c\xE9dent est que la fonction "),Gl=o(un,"CODE",{});var lv=r(Gl);_p=a(lv,"word_ids()"),lv.forEach(s),Qe=a(un," a besoin de r\xE9cup\xE9rer l\u2019index de l\u2019exemple dont nous voulons les identifiants de mots lorsque les entr\xE9es du "),Ir=o(un,"EM",{});var ov=r(Ir);bp=a(ov,"tokenizer"),ov.forEach(s),$p=a(un," sont des listes de textes (ou dans notre cas, des listes de mots), donc nous l\u2019ajoutons aussi :"),un.forEach(s),Yi=c(t),w(Ul.$$.fragment,t),Ji=c(t),Ro=o(t,"P",{});var rv=r(Ro);Vl=a(rv,"Notez que nous n\u2019avons pas encore rembourr\xE9 nos entr\xE9es. Nous le ferons plus tard lors de la cr\xE9ation des batchs avec un collateur de donn\xE9es."),rv.forEach(s),Qi=c(t),Fo=o(t,"P",{});var iv=r(Fo);gp=a(iv,"Nous pouvons maintenant appliquer tout ce pr\xE9traitement en une seule fois sur les autres divisions de notre jeu de donn\xE9es :"),iv.forEach(s),dc=c(t),w(eu.$$.fragment,t),mc=c(t),Rr=o(t,"P",{});var Wc=r(Rr);Jc=a(Wc,"Nous avons fait la partie la plus difficile ! Maintenant que les donn\xE9es ont \xE9t\xE9 pr\xE9trait\xE9es, l\u2019entra\xEEnement ressemblera beaucoup \xE0 ce que nous avons fait dans le "),Ep=o(Wc,"A",{href:!0});var uv=r(Ep);Qc=a(uv,"chapitre 3"),uv.forEach(s),ed=a(Wc,"."),Wc.forEach(s),fc=c(t),ml.l(t),qp=c(t),Bo=o(t,"H3",{class:!0});var Xc=r(Bo);Fr=o(Xc,"A",{id:!0,class:!0,href:!0});var pv=r(Fr);Xp=o(pv,"SPAN",{});var cv=r(Xp);w(su.$$.fragment,cv),cv.forEach(s),pv.forEach(s),sd=c(Xc),Zp=o(Xc,"SPAN",{});var dv=r(Zp);td=a(dv,"Collation des donn\xE9es"),dv.forEach(s),Xc.forEach(s),vc=c(t),on=o(t,"P",{});var Jl=r(on);nd=a(Jl,"Nous ne pouvons pas simplement utiliser un "),Kp=o(Jl,"CODE",{});var mv=r(Kp);ad=a(mv,"DataCollatorWithPadding"),mv.forEach(s),ld=a(Jl," comme dans le "),kp=o(Jl,"A",{href:!0});var fv=r(kp);od=a(fv,"chapitre 3"),fv.forEach(s),rd=a(Jl," car cela ne fait que rembourrer les entr\xE9es (identifiants d\u2019entr\xE9e, masque d\u2019attention et "),Yp=o(Jl,"EM",{});var vv=r(Yp);id=a(vv,"token"),vv.forEach(s),ud=a(Jl," de type identifiants). Ici, nos \xE9tiquettes doivent \xEAtre rembourr\xE9\xE9s exactement de la m\xEAme mani\xE8re que les entr\xE9es afin qu\u2019elles gardent la m\xEAme taille, en utilisant "),Jp=o(Jl,"CODE",{});var hv=r(Jp);pd=a(hv,"-100"),hv.forEach(s),cd=a(Jl," comme valeur afin que les pr\xE9dictions correspondantes soient ignor\xE9es dans le calcul de la perte."),Jl.forEach(s),hc=c(t),_a=o(t,"P",{});var Ur=r(_a);dd=a(Ur,"Tout ceci est fait par un "),tu=o(Ur,"A",{href:!0,rel:!0});var _v=r(tu);Qp=o(_v,"CODE",{});var bv=r(Qp);md=a(bv,"DataCollatorForTokenClassification"),bv.forEach(s),_v.forEach(s),fd=a(Ur,". Comme le "),ec=o(Ur,"CODE",{});var $v=r(ec);vd=a($v,"DataCollatorWithPadding"),$v.forEach(s),hd=a(Ur,", il prend le "),sc=o(Ur,"CODE",{});var gv=r(sc);_d=a(gv,"tokenizer"),gv.forEach(s),bd=a(Ur," utilis\xE9 pour pr\xE9traiter les entr\xE9es :"),Ur.forEach(s),_c=c(t),vl.l(t),jp=c(t),wp=o(t,"P",{});var Ev=r(wp);$d=a(Ev,"Pour tester cette fonction sur quelques \xE9chantillons, nous pouvons simplement l\u2019appeler sur une liste d\u2019exemples provenant de notre jeu d\u2019entra\xEEnement tok\xE9nis\xE9 :"),Ev.forEach(s),bc=c(t),w(nu.$$.fragment,t),$c=c(t),w(au.$$.fragment,t),gc=c(t),xp=o(t,"P",{});var qv=r(xp);gd=a(qv,"Comparons cela aux \xE9tiquettes des premier et deuxi\xE8me \xE9l\xE9ments de notre jeu de donn\xE9es :"),qv.forEach(s),Ec=c(t),w(lu.$$.fragment,t),qc=c(t),w(ou.$$.fragment,t),kc=c(t),_l.l(t),Cp=c(t),hs&&hs.l(t),yp=c(t),Ho=o(t,"H3",{class:!0});var Zc=r(Ho);Br=o(Zc,"A",{id:!0,class:!0,href:!0});var kv=r(Br);tc=o(kv,"SPAN",{});var jv=r(tc);w(ru.$$.fragment,jv),jv.forEach(s),kv.forEach(s),Ed=c(Zc),nc=o(Zc,"SPAN",{});var wv=r(nc);qd=a(wv,"M\xE9triques"),wv.forEach(s),Zc.forEach(s),jc=c(t),$l.l(t),zp=c(t),w(iu.$$.fragment,t),wc=c(t),Op=o(t,"P",{});var xv=r(Op);kd=a(xv,"Cette m\xE9trique ne se comporte pas comme la pr\xE9cision standard : elle prend les listes d\u2019\xE9tiquettes comme des cha\xEEnes de caract\xE8res et non comme des entiers. Nous devrons donc d\xE9coder compl\xE8tement les pr\xE9dictions et les \xE9tiquettes avant de les transmettre \xE0 la m\xE9trique. Voyons comment cela fonctionne. Tout d\u2019abord, nous allons obtenir les \xE9tiquettes pour notre premier exemple d\u2019entra\xEEnement :"),xv.forEach(s),xc=c(t),w(uu.$$.fragment,t),Cc=c(t),w(pu.$$.fragment,t),yc=c(t),Pp=o(t,"P",{});var Cv=r(Pp);jd=a(Cv,"Nous pouvons alors cr\xE9er de fausses pr\xE9dictions pour celles-ci en changeant simplement la valeur de l\u2019indice 2 :"),Cv.forEach(s),zc=c(t),w(cu.$$.fragment,t),Oc=c(t),Dp=o(t,"P",{});var yv=r(Dp);wd=a(yv,"Notez que la m\xE9trique prend une liste de pr\xE9dictions (pas seulement une) et une liste d\u2019\xE9tiquettes. Voici la sortie :"),yv.forEach(s),Pc=c(t),w(du.$$.fragment,t),Dc=c(t),El.l(t),Mp=c(t),_s&&_s.l(t),Np=c(t),Go=o(t,"H3",{class:!0});var Kc=r(Go);Hr=o(Kc,"A",{id:!0,class:!0,href:!0});var zv=r(Hr);ac=o(zv,"SPAN",{});var Ov=r(ac);w(mu.$$.fragment,Ov),Ov.forEach(s),zv.forEach(s),xd=c(Kc),Ap=o(Kc,"SPAN",{});var Fd=r(Ap);Cd=a(Fd,"Utilisation du mod\xE8le "),lc=o(Fd,"I",{});var Pv=r(lc);yd=a(Pv,"finetun\xE9"),Pv.forEach(s),Fd.forEach(s),Kc.forEach(s),Mc=c(t),rn=o(t,"P",{});var Ql=r(rn);zd=a(Ql,"Nous vous avons d\xE9j\xE0 montr\xE9 comment vous pouvez utiliser le mod\xE8le "),oc=o(Ql,"EM",{});var Dv=r(oc);Od=a(Dv,"finetun\xE9"),Dv.forEach(s),Pd=a(Ql," sur le "),rc=o(Ql,"EM",{});var Mv=r(rc);Dd=a(Mv,"Hub"),Mv.forEach(s),Md=a(Ql," avec le "),ic=o(Ql,"EM",{});var Nv=r(ic);Nd=a(Nv,"widget"),Nv.forEach(s),Ad=a(Ql," d\u2019inf\xE9rence. Pour l\u2019utiliser localement dans un "),uc=o(Ql,"CODE",{});var Av=r(uc);Td=a(Av,"pipeline"),Av.forEach(s),Sd=a(Ql,", vous devez juste sp\xE9cifier l\u2019identifiant de mod\xE8le appropri\xE9 :"),Ql.forEach(s),Nc=c(t),w(fu.$$.fragment,t),Ac=c(t),w(vu.$$.fragment,t),Tc=c(t),Tp=o(t,"P",{});var Tv=r(Tp);Ld=a(Tv,"Super ! Notre mod\xE8le fonctionne aussi bien que le mod\xE8le par d\xE9faut pour ce pipeline !"),Tv.forEach(s),this.h()},h(){_(d,"name","hf:doc:metadata"),_(d,"content",JSON.stringify(vh)),_(E,"id","classification-de-itokensi"),_(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(E,"href","#classification-de-itokensi"),_(O,"class","relative group"),Yc(je.src,ft="https://hf.space/gradioiframe/course-demos/bert-finetuned-ner/+")||_(je,"src",ft),_(je,"frameborder","0"),_(je,"height","350"),_(je,"title","Gradio app"),_(je,"class","block dark:hidden container p-0 flex-grow space-iframe"),_(je,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),_(je,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),Yc(we.src,Mt="https://hf.space/gradioiframe/course-demos/bert-finetuned-ner-darkmode/+")||_(we,"src",Mt),_(we,"frameborder","0"),_(we,"height","350"),_(we,"title","Gradio app"),_(we,"class","hidden dark:block container p-0 flex-grow space-iframe"),_(we,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),_(we,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),_(is,"class","block dark:hidden lg:w-3/5"),Yc(is.src,bn="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/model-eval-bert-finetuned-ner.png")||_(is,"src",bn),_(is,"alt","One-hot encoded labels for question answering."),_(vt,"class","hidden dark:block lg:w-3/5"),Yc(vt.src,Nt="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/model-eval-bert-finetuned-ner-dark.png")||_(vt,"src",Nt),_(vt,"alt","One-hot encoded labels for question answering."),_(pe,"class","flex justify-center"),_(pe,"href","/huggingface-course/bert-finetuned-ner"),_(us,"href","https://huggingface.co/huggingface-course/bert-finetuned-ner?text=My+nom+est+Sylvain+et+je+travaille+%C3%A0+Hugging+Face+in+Brooklyn"),_(us,"rel","nofollow"),_(Ze,"id","prparation-des-donnes"),_(Ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Ze,"href","#prparation-des-donnes"),_(Es,"class","relative group"),_(ht,"href","https://huggingface.co/datasets/conll2003"),_(ht,"rel","nofollow"),_(ps,"id","le-jeu-de-donnes-conll2003"),_(ps,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(ps,"href","#le-jeu-de-donnes-conll2003"),_(Be,"class","relative group"),_(gt,"href","/course/fr/chapter3"),_(Ue,"href","/course/fr/chapter6/3"),_(ms,"id","traitement-des-donnes"),_(ms,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(ms,"href","#traitement-des-donnes"),_(Qt,"class","relative group"),_(Us,"href","/course/fr/chapter6/"),_(al,"href","https://huggingface.co/models"),_(al,"rel","nofollow"),_(Fn,"href","https://huggingface.co/transformers/#supported-frameworks"),_(Fn,"rel","nofollow"),_(Lo,"href","/course/fr/chapter6/3"),_(Ep,"href","/course/fr/chapter3"),_(Fr,"id","collation-des-donnes"),_(Fr,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Fr,"href","#collation-des-donnes"),_(Bo,"class","relative group"),_(kp,"href","/course/fr/chapter3"),_(tu,"href","https://huggingface.co/transformers/main_classes/data_collator.html#datacollatorfortokenclassification"),_(tu,"rel","nofollow"),_(Br,"id","mtriques"),_(Br,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Br,"href","#mtriques"),_(Ho,"class","relative group"),_(Hr,"id","utilisation-du-modle-ifinetuni"),_(Hr,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Hr,"href","#utilisation-du-modle-ifinetuni"),_(Go,"class","relative group")},m(t,m){e(document.head,d),u(t,g,m),x(v,t,m),u(t,q,m),u(t,O,m),e(O,E),e(E,k),x(D,k,null),e(O,y),e(O,z),e(z,B),e(z,A),e(A,F),u(t,I,m),hu[P].m(t,m),u(t,W,m),u(t,G,m),e(G,S),e(G,X),e(X,J),e(G,le),e(G,N),e(N,U),e(G,se),u(t,Y,m),u(t,ee,m),e(ee,R),e(R,K),e(R,me),e(me,Me),e(me,he),e(he,H),e(me,oe),e(R,Q),e(R,ue),e(ue,Z),e(R,ce),e(R,ss),e(ss,_e),e(R,Ee),e(ee,Os),e(ee,ze),e(ze,Ne),e(ze,ts),e(ts,ae),e(ae,bs),e(ts,$s),e(ze,Ot),e(ee,Ea),e(ee,te),e(te,qa),e(te,pn),e(pn,Ps),e(Ps,ka),e(te,ja),e(te,pt),e(pt,ns),e(te,cn),e(te,Re),e(Re,dn),e(te,as),e(te,ct),e(ct,Oe),e(te,Fe),e(te,Ds),e(Ds,ls),e(te,wa),e(te,os),e(os,dt),e(te,xa),e(te,mn),e(mn,fn),e(te,Pe),e(te,vn),e(vn,mt),e(te,Ca),u(t,Gn,m),x(gs,t,m),u(t,Ws,m),u(t,rs,m),e(rs,Ms),e(rs,Ns),e(Ns,Pt),e(rs,Xs),e(rs,hn),e(hn,Dt),e(rs,Zs),u(t,Un,m),u(t,je,m),u(t,Vn,m),u(t,we,m),u(t,_n,m),u(t,pe,m),e(pe,is),e(pe,Ks),e(pe,vt),u(t,Wn,m),u(t,Ys,m),e(Ys,At),e(Ys,us),e(us,Tt),e(Tt,fe),e(Ys,ya),u(t,St,m),u(t,Es,m),e(Es,Ze),e(Ze,Js),x(Ae,Js,null),e(Es,za),e(Es,As),e(As,Oa),u(t,Xn,m),u(t,xe,m),e(xe,$n),e(xe,gn),e(gn,Zn),e(xe,Te),e(xe,ht),e(ht,En),e(xe,qn),u(t,Kn,m),x(qs,t,m),u(t,kn,m),u(t,Be,m),e(Be,ps),e(ps,ks),x(_t,ks,null),e(Be,Lt),e(Be,Ts),e(Ts,Yn),u(t,Ce,m),u(t,Se,m),e(Se,It),e(Se,js),e(js,Pa),e(Se,Ss),e(Se,bt),e(bt,Da),e(Se,Jn),u(t,cs,m),x($t,t,m),u(t,Rt,m),u(t,ws,m),e(ws,Ma),e(ws,gt),e(gt,Qs),e(ws,et),u(t,st,m),x(Ke,t,m),u(t,jn,m),x(He,t,m),u(t,wn,m),u(t,ie,m),e(ie,Qn),e(ie,$e),e($e,Na),e(ie,xn),e(ie,Et),e(Et,Aa),e(ie,Cn),e(ie,qt),e(qt,Ta),e(ie,yn),u(t,Ft,m),u(t,Bt,m),e(Bt,zn),u(t,On,m),x(Ye,t,m),u(t,Pn,m),x(f,t,m),u(t,L,m),u(t,Dn,m),e(Dn,Sa),u(t,Ls,m),x(be,t,m),u(t,Mn,m),x(xs,t,m),u(t,La,m),u(t,Is,m),e(Is,Ht),e(Is,Nn),e(Nn,kt),e(Is,Gt),u(t,Ut,m),x(Vt,t,m),u(t,Rs,m),x(jt,t,m),u(t,Fs,m),u(t,ve,m),e(ve,Wt),e(ve,tt),e(tt,ql),e(ve,An),e(ve,ea),e(ea,Tn),e(ve,ds),e(ve,Xt),e(Xt,sa),e(ve,ta),e(ve,na),e(na,Je),e(ve,kl),e(ve,aa),e(aa,la),e(ve,jl),u(t,wt,m),x(xt,t,m),u(t,Ct,m),x(Ge,t,m),u(t,nt,m),u(t,Bs,m),e(Bs,oa),e(Bs,Ue),e(Ue,wl),e(Bs,Ia),e(Bs,at),e(at,Ra),e(Bs,Hs),u(t,Sn,m),u(t,De,m),e(De,Ve),e(Ve,ra),e(ra,ia),e(Ve,xl),e(De,Cl),e(De,yt),e(yt,Ln),e(Ln,Uo),e(yt,ua),e(yt,eo),e(eo,so),e(yt,Zr),e(yt,to),e(to,Vo),e(yt,Fa),e(De,Wo),e(De,Cs),e(Cs,yl),e(yl,lt),e(Cs,Kr),e(Cs,Ba),e(Ba,Yr),e(Cs,Jr),e(Cs,Ha),e(Ha,Qr),e(Cs,ei),e(De,no),e(De,Zt),e(Zt,ao),e(ao,Xo),e(Zt,Ga),e(Zt,zl),e(zl,ys),e(Zt,si),e(Zt,Ua),e(Ua,ti),e(Zt,ni),e(De,lo),e(De,Kt),e(Kt,oo),e(oo,ro),e(Kt,ai),e(Kt,io),e(io,uo),e(Kt,li),e(Kt,po),e(po,Zo),e(Kt,Va),u(t,co,m),u(t,Yt,m),e(Yt,Ko),u(t,Wa,m),x(Xa,t,m),u(t,mo,m),x(zt,t,m),u(t,fo,m),u(t,We,m),e(We,oi),e(We,Za),e(Za,ri),e(We,ii),e(We,Ka),e(Ka,ui),e(We,pi),u(t,vo,m),x(Gs,t,m),u(t,In,m),u(t,pa,m),e(pa,Ya),u(t,Yo,m),x(Jt,t,m),u(t,Jo,m),u(t,Qt,m),e(Qt,ms),e(ms,ho),x(Rn,ho,null),e(Qt,ci),e(Qt,_o),e(_o,bo),u(t,Qo,m),x(Ja,t,m),u(t,$o,m),u(t,ye,m),e(ye,er),e(ye,ca),e(ca,di),e(ye,sr),e(ye,Us),e(Us,Qa),e(ye,mi),e(ye,el),e(el,fi),e(ye,vi),e(ye,go),e(go,Vs),e(ye,hi),e(ye,sl),e(sl,_i),e(ye,bi),u(t,Ol,m),u(t,en,m),e(en,$i),e(en,tl),e(tl,gi),e(en,Ei),e(en,nl),e(nl,qi),e(en,ki),u(t,tr,m),x(Xe,t,m),u(t,nr,m),u(t,re,m),e(re,ji),e(re,Eo),e(Eo,qo),e(re,wi),e(re,ko),e(ko,jo),e(re,xi),e(re,al),e(al,wo),e(re,Ci),e(re,xo),e(xo,ar),e(re,Pl),e(re,Co),e(Co,lr),e(re,ll),e(re,Dl),e(Dl,da),e(re,yi),e(re,Fn),e(Fn,zi),e(re,Oi),e(re,Ml),e(Ml,ol),e(re,or),e(re,ge),e(ge,Pi),e(re,yo),e(re,zo),e(zo,Di),e(re,Oo),u(t,rr,m),x(rl,t,m),u(t,Nl,m),x(il,t,m),u(t,ir,m),u(t,ot,m),e(ot,Mi),e(ot,Po),e(Po,Do),e(ot,Ni),e(ot,Mo),e(Mo,No),e(ot,Ai),u(t,ur,m),x(Bn,t,m),u(t,pr,m),x(ul,t,m),u(t,Ao,m),u(t,ne,m),e(ne,Ti),e(ne,pl),e(pl,Si),e(ne,Li),e(ne,Hn),e(Hn,To),e(ne,Ii),e(ne,So),e(So,cr),e(ne,i),e(ne,h),e(h,Cu),e(ne,yu),e(ne,dr),e(dr,sn),e(ne,zu),e(ne,mr),e(mr,Ou),e(ne,Pu),e(ne,ma),e(ma,Du),e(ne,Mu),e(ne,fa),e(fa,Nu),e(ne,Au),e(ne,tn),e(tn,Tu),e(ne,Su),u(t,Ri,m),u(t,fs,m),e(fs,Lu),e(fs,fr),e(fr,Fi),e(fs,Iu),e(fs,va),e(va,Ru),e(fs,Fu),e(fs,Al),e(Al,Bu),e(fs,vr),e(fs,Lo),e(Lo,hr),e(fs,Hu),u(t,vs,m),x(Tl,t,m),u(t,Bi,m),x(Sl,t,m),u(t,Hi,m),u(t,de,m),e(de,Gu),e(de,_r),e(_r,br),e(de,Uu),e(de,Ll),e(Ll,Vu),e(de,$r),e(de,gr),e(gr,Wu),e(de,nn),e(de,Er),e(Er,Xu),e(de,Zu),e(de,qr),e(qr,kr),e(de,Ku),e(de,Il),e(Il,Yu),e(de,Ju),e(de,jr),e(jr,wr),e(de,Qu),e(de,Rl),e(Rl,ep),e(de,sp),e(de,xr),e(xr,ha),e(de,tp),e(de,Cr),e(Cr,np),e(de,yr),u(t,Gi,m),x(an,t,m),u(t,Ui,m),u(t,Io,m),e(Io,zr),u(t,Vi,m),x(rt,t,m),u(t,Wi,m),x(Fl,t,m),u(t,Xi,m),u(t,qe,m),e(qe,ap),e(qe,Or),e(Or,lp),e(qe,op),e(qe,Pr),e(Pr,Bl),e(qe,rp),e(qe,Dr),e(Dr,Mr),e(qe,ip),e(qe,Nr),e(Nr,up),e(qe,Hl),u(t,Zi,m),x(cl,t,m),u(t,Ki,m),u(t,ke,m),e(ke,Ar),e(ke,Tr),e(Tr,ln),e(ke,pp),e(ke,Sr),e(Sr,cp),e(ke,dp),e(ke,it),e(it,mp),e(ke,fp),e(ke,Lr),e(Lr,vp),e(ke,hp),e(ke,Gl),e(Gl,_p),e(ke,Qe),e(ke,Ir),e(Ir,bp),e(ke,$p),u(t,Yi,m),x(Ul,t,m),u(t,Ji,m),u(t,Ro,m),e(Ro,Vl),u(t,Qi,m),u(t,Fo,m),e(Fo,gp),u(t,dc,m),x(eu,t,m),u(t,mc,m),u(t,Rr,m),e(Rr,Jc),e(Rr,Ep),e(Ep,Qc),e(Rr,ed),u(t,fc,m),_u[dl].m(t,m),u(t,qp,m),u(t,Bo,m),e(Bo,Fr),e(Fr,Xp),x(su,Xp,null),e(Bo,sd),e(Bo,Zp),e(Zp,td),u(t,vc,m),u(t,on,m),e(on,nd),e(on,Kp),e(Kp,ad),e(on,ld),e(on,kp),e(kp,od),e(on,rd),e(on,Yp),e(Yp,id),e(on,ud),e(on,Jp),e(Jp,pd),e(on,cd),u(t,hc,m),u(t,_a,m),e(_a,dd),e(_a,tu),e(tu,Qp),e(Qp,md),e(_a,fd),e(_a,ec),e(ec,vd),e(_a,hd),e(_a,sc),e(sc,_d),e(_a,bd),u(t,_c,m),bu[fl].m(t,m),u(t,jp,m),u(t,wp,m),e(wp,$d),u(t,bc,m),x(nu,t,m),u(t,$c,m),x(au,t,m),u(t,gc,m),u(t,xp,m),e(xp,gd),u(t,Ec,m),x(lu,t,m),u(t,qc,m),x(ou,t,m),u(t,kc,m),$u[hl].m(t,m),u(t,Cp,m),hs&&hs.m(t,m),u(t,yp,m),u(t,Ho,m),e(Ho,Br),e(Br,tc),x(ru,tc,null),e(Ho,Ed),e(Ho,nc),e(nc,qd),u(t,jc,m),gu[bl].m(t,m),u(t,zp,m),x(iu,t,m),u(t,wc,m),u(t,Op,m),e(Op,kd),u(t,xc,m),x(uu,t,m),u(t,Cc,m),x(pu,t,m),u(t,yc,m),u(t,Pp,m),e(Pp,jd),u(t,zc,m),x(cu,t,m),u(t,Oc,m),u(t,Dp,m),e(Dp,wd),u(t,Pc,m),x(du,t,m),u(t,Dc,m),Eu[gl].m(t,m),u(t,Mp,m),_s&&_s.m(t,m),u(t,Np,m),u(t,Go,m),e(Go,Hr),e(Hr,ac),x(mu,ac,null),e(Go,xd),e(Go,Ap),e(Ap,Cd),e(Ap,lc),e(lc,yd),u(t,Mc,m),u(t,rn,m),e(rn,zd),e(rn,oc),e(oc,Od),e(rn,Pd),e(rn,rc),e(rc,Dd),e(rn,Md),e(rn,ic),e(ic,Nd),e(rn,Ad),e(rn,uc),e(uc,Td),e(rn,Sd),u(t,Nc,m),x(fu,t,m),u(t,Ac,m),x(vu,t,m),u(t,Tc,m),u(t,Tp,m),e(Tp,Ld),Sc=!0},p(t,[m]){const qu={};m&1&&(qu.fw=t[0]),v.$set(qu);let Sp=P;P=Hd(t),P!==Sp&&(Wr(),$(hu[Sp],1,1,()=>{hu[Sp]=null}),Vr(),T=hu[P],T||(T=hu[P]=Bd[P](t),T.c()),b(T,1),T.m(W.parentNode,W));const pc={};m&2&&(pc.$$scope={dirty:m,ctx:t}),qs.$set(pc);const Lp={};m&2&&(Lp.$$scope={dirty:m,ctx:t}),Jt.$set(Lp);const cc={};m&2&&(cc.$$scope={dirty:m,ctx:t}),cl.$set(cc);let Wl=dl;dl=Ud(t),dl!==Wl&&(Wr(),$(_u[Wl],1,1,()=>{_u[Wl]=null}),Vr(),ml=_u[dl],ml||(ml=_u[dl]=Gd[dl](t),ml.c()),b(ml,1),ml.m(qp.parentNode,qp));let Ip=fl;fl=Wd(t),fl!==Ip&&(Wr(),$(bu[Ip],1,1,()=>{bu[Ip]=null}),Vr(),vl=bu[fl],vl||(vl=bu[fl]=Vd[fl](t),vl.c()),b(vl,1),vl.m(jp.parentNode,jp));let Rp=hl;hl=Zd(t),hl!==Rp&&(Wr(),$($u[Rp],1,1,()=>{$u[Rp]=null}),Vr(),_l=$u[hl],_l||(_l=$u[hl]=Xd[hl](t),_l.c()),b(_l,1),_l.m(Cp.parentNode,Cp)),t[0]==="tf"?hs?m&1&&b(hs,1):(hs=Iv(t),hs.c(),b(hs,1),hs.m(yp.parentNode,yp)):hs&&(Wr(),$(hs,1,1,()=>{hs=null}),Vr());let Xl=bl;bl=Yd(t),bl!==Xl&&(Wr(),$(gu[Xl],1,1,()=>{gu[Xl]=null}),Vr(),$l=gu[bl],$l||($l=gu[bl]=Kd[bl](t),$l.c()),b($l,1),$l.m(zp.parentNode,zp));let ba=gl;gl=Qd(t),gl!==ba&&(Wr(),$(Eu[ba],1,1,()=>{Eu[ba]=null}),Vr(),El=Eu[gl],El||(El=Eu[gl]=Jd[gl](t),El.c()),b(El,1),El.m(Mp.parentNode,Mp)),t[0]==="pt"?_s?m&1&&b(_s,1):(_s=Rv(t),_s.c(),b(_s,1),_s.m(Np.parentNode,Np)):_s&&(Wr(),$(_s,1,1,()=>{_s=null}),Vr())},i(t){Sc||(b(v.$$.fragment,t),b(D.$$.fragment,t),b(T),b(gs.$$.fragment,t),b(Ae.$$.fragment,t),b(qs.$$.fragment,t),b(_t.$$.fragment,t),b($t.$$.fragment,t),b(Ke.$$.fragment,t),b(He.$$.fragment,t),b(Ye.$$.fragment,t),b(f.$$.fragment,t),b(be.$$.fragment,t),b(xs.$$.fragment,t),b(Vt.$$.fragment,t),b(jt.$$.fragment,t),b(xt.$$.fragment,t),b(Ge.$$.fragment,t),b(Xa.$$.fragment,t),b(zt.$$.fragment,t),b(Gs.$$.fragment,t),b(Jt.$$.fragment,t),b(Rn.$$.fragment,t),b(Ja.$$.fragment,t),b(Xe.$$.fragment,t),b(rl.$$.fragment,t),b(il.$$.fragment,t),b(Bn.$$.fragment,t),b(ul.$$.fragment,t),b(Tl.$$.fragment,t),b(Sl.$$.fragment,t),b(an.$$.fragment,t),b(rt.$$.fragment,t),b(Fl.$$.fragment,t),b(cl.$$.fragment,t),b(Ul.$$.fragment,t),b(eu.$$.fragment,t),b(ml),b(su.$$.fragment,t),b(vl),b(nu.$$.fragment,t),b(au.$$.fragment,t),b(lu.$$.fragment,t),b(ou.$$.fragment,t),b(_l),b(hs),b(ru.$$.fragment,t),b($l),b(iu.$$.fragment,t),b(uu.$$.fragment,t),b(pu.$$.fragment,t),b(cu.$$.fragment,t),b(du.$$.fragment,t),b(El),b(_s),b(mu.$$.fragment,t),b(fu.$$.fragment,t),b(vu.$$.fragment,t),Sc=!0)},o(t){$(v.$$.fragment,t),$(D.$$.fragment,t),$(T),$(gs.$$.fragment,t),$(Ae.$$.fragment,t),$(qs.$$.fragment,t),$(_t.$$.fragment,t),$($t.$$.fragment,t),$(Ke.$$.fragment,t),$(He.$$.fragment,t),$(Ye.$$.fragment,t),$(f.$$.fragment,t),$(be.$$.fragment,t),$(xs.$$.fragment,t),$(Vt.$$.fragment,t),$(jt.$$.fragment,t),$(xt.$$.fragment,t),$(Ge.$$.fragment,t),$(Xa.$$.fragment,t),$(zt.$$.fragment,t),$(Gs.$$.fragment,t),$(Jt.$$.fragment,t),$(Rn.$$.fragment,t),$(Ja.$$.fragment,t),$(Xe.$$.fragment,t),$(rl.$$.fragment,t),$(il.$$.fragment,t),$(Bn.$$.fragment,t),$(ul.$$.fragment,t),$(Tl.$$.fragment,t),$(Sl.$$.fragment,t),$(an.$$.fragment,t),$(rt.$$.fragment,t),$(Fl.$$.fragment,t),$(cl.$$.fragment,t),$(Ul.$$.fragment,t),$(eu.$$.fragment,t),$(ml),$(su.$$.fragment,t),$(vl),$(nu.$$.fragment,t),$(au.$$.fragment,t),$(lu.$$.fragment,t),$(ou.$$.fragment,t),$(_l),$(hs),$(ru.$$.fragment,t),$($l),$(iu.$$.fragment,t),$(uu.$$.fragment,t),$(pu.$$.fragment,t),$(cu.$$.fragment,t),$(du.$$.fragment,t),$(El),$(_s),$(mu.$$.fragment,t),$(fu.$$.fragment,t),$(vu.$$.fragment,t),Sc=!1},d(t){s(d),t&&s(g),C(v,t),t&&s(q),t&&s(O),C(D),t&&s(I),hu[P].d(t),t&&s(W),t&&s(G),t&&s(Y),t&&s(ee),t&&s(Gn),C(gs,t),t&&s(Ws),t&&s(rs),t&&s(Un),t&&s(je),t&&s(Vn),t&&s(we),t&&s(_n),t&&s(pe),t&&s(Wn),t&&s(Ys),t&&s(St),t&&s(Es),C(Ae),t&&s(Xn),t&&s(xe),t&&s(Kn),C(qs,t),t&&s(kn),t&&s(Be),C(_t),t&&s(Ce),t&&s(Se),t&&s(cs),C($t,t),t&&s(Rt),t&&s(ws),t&&s(st),C(Ke,t),t&&s(jn),C(He,t),t&&s(wn),t&&s(ie),t&&s(Ft),t&&s(Bt),t&&s(On),C(Ye,t),t&&s(Pn),C(f,t),t&&s(L),t&&s(Dn),t&&s(Ls),C(be,t),t&&s(Mn),C(xs,t),t&&s(La),t&&s(Is),t&&s(Ut),C(Vt,t),t&&s(Rs),C(jt,t),t&&s(Fs),t&&s(ve),t&&s(wt),C(xt,t),t&&s(Ct),C(Ge,t),t&&s(nt),t&&s(Bs),t&&s(Sn),t&&s(De),t&&s(co),t&&s(Yt),t&&s(Wa),C(Xa,t),t&&s(mo),C(zt,t),t&&s(fo),t&&s(We),t&&s(vo),C(Gs,t),t&&s(In),t&&s(pa),t&&s(Yo),C(Jt,t),t&&s(Jo),t&&s(Qt),C(Rn),t&&s(Qo),C(Ja,t),t&&s($o),t&&s(ye),t&&s(Ol),t&&s(en),t&&s(tr),C(Xe,t),t&&s(nr),t&&s(re),t&&s(rr),C(rl,t),t&&s(Nl),C(il,t),t&&s(ir),t&&s(ot),t&&s(ur),C(Bn,t),t&&s(pr),C(ul,t),t&&s(Ao),t&&s(ne),t&&s(Ri),t&&s(fs),t&&s(vs),C(Tl,t),t&&s(Bi),C(Sl,t),t&&s(Hi),t&&s(de),t&&s(Gi),C(an,t),t&&s(Ui),t&&s(Io),t&&s(Vi),C(rt,t),t&&s(Wi),C(Fl,t),t&&s(Xi),t&&s(qe),t&&s(Zi),C(cl,t),t&&s(Ki),t&&s(ke),t&&s(Yi),C(Ul,t),t&&s(Ji),t&&s(Ro),t&&s(Qi),t&&s(Fo),t&&s(dc),C(eu,t),t&&s(mc),t&&s(Rr),t&&s(fc),_u[dl].d(t),t&&s(qp),t&&s(Bo),C(su),t&&s(vc),t&&s(on),t&&s(hc),t&&s(_a),t&&s(_c),bu[fl].d(t),t&&s(jp),t&&s(wp),t&&s(bc),C(nu,t),t&&s($c),C(au,t),t&&s(gc),t&&s(xp),t&&s(Ec),C(lu,t),t&&s(qc),C(ou,t),t&&s(kc),$u[hl].d(t),t&&s(Cp),hs&&hs.d(t),t&&s(yp),t&&s(Ho),C(ru),t&&s(jc),gu[bl].d(t),t&&s(zp),C(iu,t),t&&s(wc),t&&s(Op),t&&s(xc),C(uu,t),t&&s(Cc),C(pu,t),t&&s(yc),t&&s(Pp),t&&s(zc),C(cu,t),t&&s(Oc),t&&s(Dp),t&&s(Pc),C(du,t),t&&s(Dc),Eu[gl].d(t),t&&s(Mp),_s&&_s.d(t),t&&s(Np),t&&s(Go),C(mu),t&&s(Mc),t&&s(rn),t&&s(Nc),C(fu,t),t&&s(Ac),C(vu,t),t&&s(Tc),t&&s(Tp)}}}const vh={local:"classification-de-itokensi",sections:[{local:"prparation-des-donnes",sections:[{local:"le-jeu-de-donnes-conll2003",title:"Le jeu de donn\xE9es CoNLL-2003"},{local:"traitement-des-donnes",title:"Traitement des donn\xE9es"}],title:"Pr\xE9paration des donn\xE9es"},{local:"ifinetuningi-du-modle-avec-lapi-trainer",title:"<i>Finetuning</i> du mod\xE8le avec l'API `Trainer`"},{local:"ifinetuningi-du-modle-avec-keras",sections:[{local:"collation-des-donnes",title:"Collation des donn\xE9es"},{local:"dfinir-le-modle",title:"D\xE9finir le mod\xE8le"},{local:"ifinetuningi-du-modle",title:"<i>Finetuning</i> du mod\xE8le"},{local:"mtriques",title:"M\xE9triques"},{local:"dfinir-le-modle",title:"D\xE9finir le mod\xE8le"},{local:"ifinetuningi-du-modle",title:"<i>Finetuning</i> du mod\xE8le"}],title:"<i>Finetuning</i> du mod\xE8le avec Keras"},{local:"une-boucle-dentranement-personnalise",sections:[{local:"prparer-tout-pour-lentranement",title:"Pr\xE9parer tout pour l'entra\xEEnement"},{local:"boucle-dentranement",title:"Boucle d'entra\xEEnement"},{local:"utilisation-du-modle-ifinetuni",title:"Utilisation du mod\xE8le <i>finetun\xE9</i>"}],title:"Une boucle d'entra\xEEnement personnalis\xE9e"}],title:"Classification de <i>tokens</i>"};function hh(V,d,g){let v="pt";return Vv(()=>{const q=new URLSearchParams(window.location.search);g(0,v=q.get("fw")||"pt")}),[v]}class jh extends Bv{constructor(d){super();Hv(this,d,hh,fh,Gv,{})}}export{jh as default,vh as metadata};
