<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;giri&quot;,&quot;title&quot;:&quot;Giriş&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/course/pr_139/tr/_app/assets/pages/__layout.svelte-836a922b.css">
	<link rel="modulepreload" href="/docs/course/pr_139/tr/_app/start-1a489f9f.js">
	<link rel="modulepreload" href="/docs/course/pr_139/tr/_app/chunks/vendor-f4a867ed.js">
	<link rel="modulepreload" href="/docs/course/pr_139/tr/_app/chunks/paths-4b3c6e7e.js">
	<link rel="modulepreload" href="/docs/course/pr_139/tr/_app/pages/__layout.svelte-065f68ce.js">
	<link rel="modulepreload" href="/docs/course/pr_139/tr/_app/pages/chapter2/1.mdx-78afafb1.js">
	<link rel="modulepreload" href="/docs/course/pr_139/tr/_app/chunks/IconCopyLink-d27af064.js"> 





<h1 class="relative group"><a id="giri" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#giri"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Giriş
	</span></h1>

<p><a href="/course/chapter1">Birinci bölümde</a> gördüğünüz gibi, Transformer modelleri genellikle oldukça büyüktür. Milyonlarca, hatta milyarlarca, parametreleri olan bu modellerin eğitimi ve üretime geçirilmesi oldukça karmaşık bir girişimdir. Bunun yanısıra, hemen hemen her gün, herbirinin kendine özgü uygulaması olan yeni modellerin yayınlaması, bu yeni modellerinin hepsini birden denemeyi daha da zor bir hale getirmektedir.</p>
<p>🤗 Transformers kütüphanesi bu sorunu çözmek için oluşturuldu. Bu kütüphanenin amacı, herhangi bir Transformer modelini tek bir API (uygulama programı arabirimi) aracılığı ile yükleme, eğitme, ve kaydetmeyi sağlamaktır. Kütüphanenin başlıca özellikleri şunlardır:</p>
<ul><li><strong>Kullanım kolaylığı</strong>: En son geliştirilen NLP modellerini indirme, yükleme ve kullanma yalnızca iki satır kod ile yapılabilir.</li>
<li><strong>Esneklik</strong>: Bütün modeller temelinde sadece ya PyTorch <code>nn.Module</code> ya da TensorFlow <code>tf.keras.Model</code> sınıfıdır ve her bir model, ait olduğu kütüphanesindeki diğer herhangi bir model gibi işlenebilir.</li>
<li><strong>Sadelik</strong>: Kütüphane içerisinde neredeyse hiç bir soyutlama yapılmamaktadır. “Hersey tek bir dosya içerisinde” ifadesi, kütüphanenin ana kavramını oluşturuyor. Bir modelin “forward pass” aşaması, kodun anlaşılır olması ve kolayca modifiye edilebilmesini sağlamak amacı ile tamamiyle tek bir dosya içerisinde tanımlanır. </li></ul>
<p>Bu son özellik 🤗 Transformers kütüphanesini diğer makine öğrenmesi kütüphanelerinden oldukça farklı kılmaktadır. Modeller dosyalar arasında paylaşılan modüller üzerinde kurulmamıştır. Bunun yerine, her bir model kendine ait katmanlara sahiptir. Bu özellik, modelleri ulaşılabilir ve anlaşılır hale getirmenin yanısıra, diğer modelleri etkilemeden, tek bir model üzerinde kolayca deneyler yapabilmenize olanak sağlamaktadır.</p>
<p>Bu bölüm, bir model ve simgeleleştirici (tokenizer) kullanarak, birinci bölümde tanıtılan <code>pipeline()</code> fonksiyonunun bir kopyasını yapmak için baştan sona (end-to-end) uygulayacağımız bir örnekle başlamaktadır.
Bunun ardından, kütüphanenin model API’ından bahsedeceğiz: Model ve konfigürasyon sınıflarına detaylıca bakıp, bir modeli nasıl yükleyebileceğinizi ve bir modelin sayısal giriş verilerini nasıl çıkış öngörüleri olarak işlediğini göreceğiz. </p>
<p>Daha sonra, <code>pipeline()</code> fonksiyonunun diğer ana parçası olan simgeleştirici API’ına göz atacağız. Simgeleştiriciler, sinir ağının metni sayısal giriş verilerine ve gerektiğinde bu sayısal verileri tekrar metne dönüştüren ilk ve son işlem aşamalarından sorumludur. Son olarak, birden fazla cümleyi hazır bir grup halinde bir modele nasıl gönderebileceğinizi gösterip, <code>tokenizer()</code> fonksiyonuna yakından bakarak bu bölümü tamamlayacağız. </p>


<div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400">⚠️ Model Hub ve 🤗 Transformers kütüphanesinde yeralan bütün özelliklerden yararlanabilmeniz icin, <a href="https://huggingface.co/join">bir hesap oluşturmanızı</a> tavsiye ediyoruz.
</div>


		<script type="module" data-hydrate="1o13zbw">
		import { start } from "/docs/course/pr_139/tr/_app/start-1a489f9f.js";
		start({
			target: document.querySelector('[data-hydrate="1o13zbw"]').parentNode,
			paths: {"base":"/docs/course/pr_139/tr","assets":"/docs/course/pr_139/tr"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/course/pr_139/tr/_app/pages/__layout.svelte-065f68ce.js"),
						import("/docs/course/pr_139/tr/_app/pages/chapter2/1.mdx-78afafb1.js")
				],
				params: {}
			}
		});
	</script>
