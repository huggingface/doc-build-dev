import{S as Ko,i as Xo,s as Zo,e as o,k as u,w as Oe,t as l,M as et,c as t,d as r,m as f,a as s,x as Be,h as n,b as i,N as Yo,G as a,g as d,y as Qe,L as at,q as Ue,o as Je,B as Ve,v as rt}from"../../chunks/vendor-hf-doc-builder.js";import{Y as ot}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Ta}from"../../chunks/IconCopyLink-hf-doc-builder.js";function tt(eo){let y,We,_,$,be,j,Na,ye,Ia,Ye,E,q,_e,D,$a,Ee,qa,Ke,x,Xe,p,Ha,k,Sa,Ma,F,ja,Da,z,xa,ka,C,Fa,za,G,Ca,Ga,R,Ra,Oa,Ze,w,H,we,O,Ba,Le,Qa,ea,de,Ua,aa,L,B,ao,Ja,Q,ro,ra,h,U,Va,J,Wa,Ya,Ka,Pe,Xa,Za,Ae,er,oa,ue,ar,ta,g,Te,rr,or,v,tr,V,sr,lr,W,nr,ir,Y,cr,dr,P,ur,K,fr,pr,X,mr,hr,sa,S,gr,Z,vr,br,la,A,M,Ne,ee,yr,Ie,_r,na,fe,Er,ia,ae,$e,wr,Lr,ca,re,qe,Pr,Ar,da,T,He,Tr,Nr,Se,oe,Ir,$r,ua,te,Me,qr,Hr,fa,se,je,Sr,Mr,pa,N,De,jr,Dr,le,xr,kr,ma,I,xe,Fr,zr,ne,Cr,Gr,ha,pe,Rr,ga,b,ie,Or,ke,Br,Qr,Ur,Fe,Jr,Vr,ze,Wr,va;return j=new Ta({}),D=new Ta({}),x=new ot({props:{id:"00GKzGyWFEs"}}),O=new Ta({}),ee=new Ta({}),{c(){y=o("meta"),We=u(),_=o("h1"),$=o("a"),be=o("span"),Oe(j.$$.fragment),Na=u(),ye=o("span"),Ia=l("Introducci\xF3n"),Ye=u(),E=o("h2"),q=o("a"),_e=o("span"),Oe(D.$$.fragment),$a=u(),Ee=o("span"),qa=l("\xA1Te damos la bienvenida al curso de \u{1F917}!"),Ke=u(),Oe(x.$$.fragment),Xe=u(),p=o("p"),Ha=l("Este curso te ense\xF1ar\xE1 sobre procesamiento de lenguaje natural (PLN) usando librer\xEDas del ecosistema "),k=o("a"),Sa=l("Hugging Face"),Ma=l(" - "),F=o("a"),ja=l("\u{1F917} Transformers"),Da=l(", "),z=o("a"),xa=l("\u{1F917} Datasets"),ka=l(", "),C=o("a"),Fa=l("\u{1F917} Tokenizers"),za=l(" y "),G=o("a"),Ca=l("\u{1F917} Accelerate"),Ga=l(" \u2014 as\xED como el "),R=o("a"),Ra=l("Hub de Hugging Face"),Oa=l(". El curso es completamente gratuito y sin anuncios."),Ze=u(),w=o("h2"),H=o("a"),we=o("span"),Oe(O.$$.fragment),Ba=u(),Le=o("span"),Qa=l("\xBFQu\xE9 esperar?"),ea=u(),de=o("p"),Ua=l("Esta es una peque\xF1a descripci\xF3n del curso:"),aa=u(),L=o("div"),B=o("img"),Ja=u(),Q=o("img"),ra=u(),h=o("ul"),U=o("li"),Va=l("Los cap\xEDtulos 1 a 4 ofrecen una introducci\xF3n a los conceptos principales de la librer\xEDa \u{1F917} Transformers. Al final de esta secci\xF3n del curso, estar\xE1s familiarizado con la manera en que trabajan los Transformadores y sabr\xE1s c\xF3mo usar un modelo del "),J=o("a"),Wa=l("Hub de Hugging Face"),Ya=l(", ajustarlo a tu conjunto de datos y compartir tus resultados en el Hub."),Ka=u(),Pe=o("li"),Xa=l("Los cap\xEDtulos 5 a 8 ense\xF1an lo b\xE1sico de \u{1F917} Datasets y \u{1F917} Tokenizers antes de entrar en tareas cl\xE1sicas de PLN. Al final de esta secci\xF3n, podr\xE1s abordar por ti mismo los problemas m\xE1s comunes de PLN."),Za=u(),Ae=o("li"),er=l("Los cap\xEDtulos 9 al 12 van m\xE1s all\xE1 del PLN y exploran c\xF3mo los Transformadores pueden abordar tareas de procesamiento del habla y visi\xF3n por computador. A lo largo del camino, aprender\xE1s a construir y compartir demos de tus modelos, as\xED como optimizarlos para entornos de producci\xF3n. Al final de esta secci\xF3n, estar\xE1s listo para aplicar \u{1F917} Transformers a (casi) cualquier problema de Machine Learning."),oa=u(),ue=o("p"),ar=l("Este curso:"),ta=u(),g=o("ul"),Te=o("li"),rr=l("Requiere amplio conocimiento de Python"),or=u(),v=o("li"),tr=l("Deber\xEDa ser tomado despu\xE9s de un curso de introducci\xF3n a deep learning, como "),V=o("a"),sr=l("Practical Deep Learning for Coders"),lr=l(" de "),W=o("a"),nr=l("fast.ai\u2019s"),ir=l(" o alguno de los programas desarrollados por "),Y=o("a"),cr=l("DeepLearning.AI"),dr=u(),P=o("li"),ur=l("No necesita conocimiento previo de "),K=o("a"),fr=l("PyTorch"),pr=l(" o "),X=o("a"),mr=l("TensorFlow"),hr=l(", aunque un nivel de familiaridad con alguno de los dos podr\xEDa ser \xFAtil"),sa=u(),S=o("p"),gr=l("Despu\xE9s de que hayas completado este curso, te recomendamos revisar la "),Z=o("a"),vr=l("Especializaci\xF3n en Procesamiento de Lenguaje Natural"),br=l(" de DeepLearning.AI, que cubre un gran n\xFAmero de modelos tradicionales de PLN como Naive Bayes y LSTMs."),la=u(),A=o("h2"),M=o("a"),Ne=o("span"),Oe(ee.$$.fragment),yr=u(),Ie=o("span"),_r=l("\xBFQui\xE9nes somos?"),na=u(),fe=o("p"),Er=l("Acerca de los autores:"),ia=u(),ae=o("p"),$e=o("strong"),wr=l("Matthew Carrigan"),Lr=l(" es Ingeniero de Machine Learning en Hugging Face. Vive en Dublin, Irlanda y anteriormente trabaj\xF3 como Ingeniero ML en Parse.ly y como investigador post-doctoral en Trinity College Dublin. No cree que vamos a alcanzar una Inteligencia Artificial General escalando arquitecturas existentes, pero en todo caso tiene grandes expectativas sobre la inmortalidad rob\xF3tica."),ca=u(),re=o("p"),qe=o("strong"),Pr=l("Lysandre Debut"),Ar=l(" es Ingeniero de Machine Learning en Hugging Face y ha trabajado en la librer\xEDa \u{1F917} Transformers desde sus etapas de desarrollo m\xE1s tempranas. Su objetivo es hacer que el PLN sea accesible para todos a trav\xE9s del desarrollo de herramientas con una API muy simple."),da=u(),T=o("p"),He=o("strong"),Tr=l("Sylvain Gugger"),Nr=l(" es Ingeniero de Investigaci\xF3n en Hugging Face y uno de los principales mantenedores de la librer\xEDa \u{1F917} Transformers. Anteriormente fue Cient\xEDfico de Investigaci\xF3n en fast.ai y escribi\xF3 "),Se=o("em"),oe=o("a"),Ir=l("Deep Learning for Coders with fastai and PyTorch"),$r=l(" junto con Jeremy Howard. El foco principal de su investigaci\xF3n es hacer el deep learning m\xE1s accesible, al dise\xF1ar y mejorar t\xE9cnicas que permiten un entrenamiento r\xE1pido de modelos con recursos limitados."),ua=u(),te=o("p"),Me=o("strong"),qr=l("Merve Noyan"),Hr=l(" es Promotora de Desarrolladores en Hugging Face, trabaja en el desarrollo de herramientas y construcci\xF3n de contenido relacionado, con el f\xEDn de democratizar el machine learning para todos."),fa=u(),se=o("p"),je=o("strong"),Sr=l("Lucile Saulnier"),Mr=l(" es Ingeniera de Machine Learning en Hugging Face, donde desarrolla y apoya el uso de herramientas de c\xF3digo abierto. Ella est\xE1 activamente involucrada en varios proyectos de investigaci\xF3n en el campo del Procesamiento de Lenguaje Natural como entrenamiento colaborativo y BigScience."),pa=u(),N=o("p"),De=o("strong"),jr=l("Lewis Tunstall"),Dr=l("  es Ingeniero de Machine Learning en Hugging Face, enfocado en desarrollar herramientas de c\xF3digo abierto y hacerlas accesibles a la comunidad en general. Tambi\xE9n es coautor de un pr\xF3ximo "),le=o("a"),xr=l("libro de O\u2019Reilly sobre Transformadores"),kr=l("."),ma=u(),I=o("p"),xe=o("strong"),Fr=l("Leandro von Werra"),zr=l("  es Ingeniero de Machine Learning en el equipo de c\xF3digo abierto en Hugging Face y coautor de un pr\xF3ximo "),ne=o("a"),Cr=l("libro de O\u2019Reilly sobre Transformadores"),Gr=l(". Tiene varios a\xF1os de experiencia en la industria llevando modelos de PLN a producci\xF3n, trabajando a lo largo de todo el entorno de Machine Learning."),ha=u(),pe=o("p"),Rr=l("\xBFEst\xE1s listo para comenzar? En este cap\xEDtulo vas a aprender:"),ga=u(),b=o("ul"),ie=o("li"),Or=l("C\xF3mo usar la funci\xF3n "),ke=o("code"),Br=l("pipeline()"),Qr=l(" para resolver tareas de PLN como la generaci\xF3n y clasificaci\xF3n de texto"),Ur=u(),Fe=o("li"),Jr=l("Sobre la arquitectura de los Transformadores"),Vr=u(),ze=o("li"),Wr=l("C\xF3mo distinguir entre las arquitecturas de codificador, decodificador y codificador-decofidicador, adem\xE1s de sus casos de uso"),this.h()},l(e){const c=et('[data-svelte="svelte-1phssyn"]',document.head);y=t(c,"META",{name:!0,content:!0}),c.forEach(r),We=f(e),_=t(e,"H1",{class:!0});var ba=s(_);$=t(ba,"A",{id:!0,class:!0,href:!0});var oo=s($);be=t(oo,"SPAN",{});var to=s(be);Be(j.$$.fragment,to),to.forEach(r),oo.forEach(r),Na=f(ba),ye=t(ba,"SPAN",{});var so=s(ye);Ia=n(so,"Introducci\xF3n"),so.forEach(r),ba.forEach(r),Ye=f(e),E=t(e,"H2",{class:!0});var ya=s(E);q=t(ya,"A",{id:!0,class:!0,href:!0});var lo=s(q);_e=t(lo,"SPAN",{});var no=s(_e);Be(D.$$.fragment,no),no.forEach(r),lo.forEach(r),$a=f(ya),Ee=t(ya,"SPAN",{});var io=s(Ee);qa=n(io,"\xA1Te damos la bienvenida al curso de \u{1F917}!"),io.forEach(r),ya.forEach(r),Ke=f(e),Be(x.$$.fragment,e),Xe=f(e),p=t(e,"P",{});var m=s(p);Ha=n(m,"Este curso te ense\xF1ar\xE1 sobre procesamiento de lenguaje natural (PLN) usando librer\xEDas del ecosistema "),k=t(m,"A",{href:!0,rel:!0});var co=s(k);Sa=n(co,"Hugging Face"),co.forEach(r),Ma=n(m," - "),F=t(m,"A",{href:!0,rel:!0});var uo=s(F);ja=n(uo,"\u{1F917} Transformers"),uo.forEach(r),Da=n(m,", "),z=t(m,"A",{href:!0,rel:!0});var fo=s(z);xa=n(fo,"\u{1F917} Datasets"),fo.forEach(r),ka=n(m,", "),C=t(m,"A",{href:!0,rel:!0});var po=s(C);Fa=n(po,"\u{1F917} Tokenizers"),po.forEach(r),za=n(m," y "),G=t(m,"A",{href:!0,rel:!0});var mo=s(G);Ca=n(mo,"\u{1F917} Accelerate"),mo.forEach(r),Ga=n(m," \u2014 as\xED como el "),R=t(m,"A",{href:!0,rel:!0});var ho=s(R);Ra=n(ho,"Hub de Hugging Face"),ho.forEach(r),Oa=n(m,". El curso es completamente gratuito y sin anuncios."),m.forEach(r),Ze=f(e),w=t(e,"H2",{class:!0});var _a=s(w);H=t(_a,"A",{id:!0,class:!0,href:!0});var go=s(H);we=t(go,"SPAN",{});var vo=s(we);Be(O.$$.fragment,vo),vo.forEach(r),go.forEach(r),Ba=f(_a),Le=t(_a,"SPAN",{});var bo=s(Le);Qa=n(bo,"\xBFQu\xE9 esperar?"),bo.forEach(r),_a.forEach(r),ea=f(e),de=t(e,"P",{});var yo=s(de);Ua=n(yo,"Esta es una peque\xF1a descripci\xF3n del curso:"),yo.forEach(r),aa=f(e),L=t(e,"DIV",{class:!0});var Ea=s(L);B=t(Ea,"IMG",{class:!0,src:!0,alt:!0}),Ja=f(Ea),Q=t(Ea,"IMG",{class:!0,src:!0,alt:!0}),Ea.forEach(r),ra=f(e),h=t(e,"UL",{});var me=s(h);U=t(me,"LI",{});var wa=s(U);Va=n(wa,"Los cap\xEDtulos 1 a 4 ofrecen una introducci\xF3n a los conceptos principales de la librer\xEDa \u{1F917} Transformers. Al final de esta secci\xF3n del curso, estar\xE1s familiarizado con la manera en que trabajan los Transformadores y sabr\xE1s c\xF3mo usar un modelo del "),J=t(wa,"A",{href:!0,rel:!0});var _o=s(J);Wa=n(_o,"Hub de Hugging Face"),_o.forEach(r),Ya=n(wa,", ajustarlo a tu conjunto de datos y compartir tus resultados en el Hub."),wa.forEach(r),Ka=f(me),Pe=t(me,"LI",{});var Eo=s(Pe);Xa=n(Eo,"Los cap\xEDtulos 5 a 8 ense\xF1an lo b\xE1sico de \u{1F917} Datasets y \u{1F917} Tokenizers antes de entrar en tareas cl\xE1sicas de PLN. Al final de esta secci\xF3n, podr\xE1s abordar por ti mismo los problemas m\xE1s comunes de PLN."),Eo.forEach(r),Za=f(me),Ae=t(me,"LI",{});var wo=s(Ae);er=n(wo,"Los cap\xEDtulos 9 al 12 van m\xE1s all\xE1 del PLN y exploran c\xF3mo los Transformadores pueden abordar tareas de procesamiento del habla y visi\xF3n por computador. A lo largo del camino, aprender\xE1s a construir y compartir demos de tus modelos, as\xED como optimizarlos para entornos de producci\xF3n. Al final de esta secci\xF3n, estar\xE1s listo para aplicar \u{1F917} Transformers a (casi) cualquier problema de Machine Learning."),wo.forEach(r),me.forEach(r),oa=f(e),ue=t(e,"P",{});var Lo=s(ue);ar=n(Lo,"Este curso:"),Lo.forEach(r),ta=f(e),g=t(e,"UL",{});var he=s(g);Te=t(he,"LI",{});var Po=s(Te);rr=n(Po,"Requiere amplio conocimiento de Python"),Po.forEach(r),or=f(he),v=t(he,"LI",{});var ce=s(v);tr=n(ce,"Deber\xEDa ser tomado despu\xE9s de un curso de introducci\xF3n a deep learning, como "),V=t(ce,"A",{href:!0,rel:!0});var Ao=s(V);sr=n(Ao,"Practical Deep Learning for Coders"),Ao.forEach(r),lr=n(ce," de "),W=t(ce,"A",{href:!0,rel:!0});var To=s(W);nr=n(To,"fast.ai\u2019s"),To.forEach(r),ir=n(ce," o alguno de los programas desarrollados por "),Y=t(ce,"A",{href:!0,rel:!0});var No=s(Y);cr=n(No,"DeepLearning.AI"),No.forEach(r),ce.forEach(r),dr=f(he),P=t(he,"LI",{});var ge=s(P);ur=n(ge,"No necesita conocimiento previo de "),K=t(ge,"A",{href:!0,rel:!0});var Io=s(K);fr=n(Io,"PyTorch"),Io.forEach(r),pr=n(ge," o "),X=t(ge,"A",{href:!0,rel:!0});var $o=s(X);mr=n($o,"TensorFlow"),$o.forEach(r),hr=n(ge,", aunque un nivel de familiaridad con alguno de los dos podr\xEDa ser \xFAtil"),ge.forEach(r),he.forEach(r),sa=f(e),S=t(e,"P",{});var La=s(S);gr=n(La,"Despu\xE9s de que hayas completado este curso, te recomendamos revisar la "),Z=t(La,"A",{href:!0,rel:!0});var qo=s(Z);vr=n(qo,"Especializaci\xF3n en Procesamiento de Lenguaje Natural"),qo.forEach(r),br=n(La," de DeepLearning.AI, que cubre un gran n\xFAmero de modelos tradicionales de PLN como Naive Bayes y LSTMs."),La.forEach(r),la=f(e),A=t(e,"H2",{class:!0});var Pa=s(A);M=t(Pa,"A",{id:!0,class:!0,href:!0});var Ho=s(M);Ne=t(Ho,"SPAN",{});var So=s(Ne);Be(ee.$$.fragment,So),So.forEach(r),Ho.forEach(r),yr=f(Pa),Ie=t(Pa,"SPAN",{});var Mo=s(Ie);_r=n(Mo,"\xBFQui\xE9nes somos?"),Mo.forEach(r),Pa.forEach(r),na=f(e),fe=t(e,"P",{});var jo=s(fe);Er=n(jo,"Acerca de los autores:"),jo.forEach(r),ia=f(e),ae=t(e,"P",{});var Yr=s(ae);$e=t(Yr,"STRONG",{});var Do=s($e);wr=n(Do,"Matthew Carrigan"),Do.forEach(r),Lr=n(Yr," es Ingeniero de Machine Learning en Hugging Face. Vive en Dublin, Irlanda y anteriormente trabaj\xF3 como Ingeniero ML en Parse.ly y como investigador post-doctoral en Trinity College Dublin. No cree que vamos a alcanzar una Inteligencia Artificial General escalando arquitecturas existentes, pero en todo caso tiene grandes expectativas sobre la inmortalidad rob\xF3tica."),Yr.forEach(r),ca=f(e),re=t(e,"P",{});var Kr=s(re);qe=t(Kr,"STRONG",{});var xo=s(qe);Pr=n(xo,"Lysandre Debut"),xo.forEach(r),Ar=n(Kr," es Ingeniero de Machine Learning en Hugging Face y ha trabajado en la librer\xEDa \u{1F917} Transformers desde sus etapas de desarrollo m\xE1s tempranas. Su objetivo es hacer que el PLN sea accesible para todos a trav\xE9s del desarrollo de herramientas con una API muy simple."),Kr.forEach(r),da=f(e),T=t(e,"P",{});var Ce=s(T);He=t(Ce,"STRONG",{});var ko=s(He);Tr=n(ko,"Sylvain Gugger"),ko.forEach(r),Nr=n(Ce," es Ingeniero de Investigaci\xF3n en Hugging Face y uno de los principales mantenedores de la librer\xEDa \u{1F917} Transformers. Anteriormente fue Cient\xEDfico de Investigaci\xF3n en fast.ai y escribi\xF3 "),Se=t(Ce,"EM",{});var Fo=s(Se);oe=t(Fo,"A",{href:!0,rel:!0});var zo=s(oe);Ir=n(zo,"Deep Learning for Coders with fastai and PyTorch"),zo.forEach(r),Fo.forEach(r),$r=n(Ce," junto con Jeremy Howard. El foco principal de su investigaci\xF3n es hacer el deep learning m\xE1s accesible, al dise\xF1ar y mejorar t\xE9cnicas que permiten un entrenamiento r\xE1pido de modelos con recursos limitados."),Ce.forEach(r),ua=f(e),te=t(e,"P",{});var Xr=s(te);Me=t(Xr,"STRONG",{});var Co=s(Me);qr=n(Co,"Merve Noyan"),Co.forEach(r),Hr=n(Xr," es Promotora de Desarrolladores en Hugging Face, trabaja en el desarrollo de herramientas y construcci\xF3n de contenido relacionado, con el f\xEDn de democratizar el machine learning para todos."),Xr.forEach(r),fa=f(e),se=t(e,"P",{});var Zr=s(se);je=t(Zr,"STRONG",{});var Go=s(je);Sr=n(Go,"Lucile Saulnier"),Go.forEach(r),Mr=n(Zr," es Ingeniera de Machine Learning en Hugging Face, donde desarrolla y apoya el uso de herramientas de c\xF3digo abierto. Ella est\xE1 activamente involucrada en varios proyectos de investigaci\xF3n en el campo del Procesamiento de Lenguaje Natural como entrenamiento colaborativo y BigScience."),Zr.forEach(r),pa=f(e),N=t(e,"P",{});var Ge=s(N);De=t(Ge,"STRONG",{});var Ro=s(De);jr=n(Ro,"Lewis Tunstall"),Ro.forEach(r),Dr=n(Ge,"  es Ingeniero de Machine Learning en Hugging Face, enfocado en desarrollar herramientas de c\xF3digo abierto y hacerlas accesibles a la comunidad en general. Tambi\xE9n es coautor de un pr\xF3ximo "),le=t(Ge,"A",{href:!0,rel:!0});var Oo=s(le);xr=n(Oo,"libro de O\u2019Reilly sobre Transformadores"),Oo.forEach(r),kr=n(Ge,"."),Ge.forEach(r),ma=f(e),I=t(e,"P",{});var Re=s(I);xe=t(Re,"STRONG",{});var Bo=s(xe);Fr=n(Bo,"Leandro von Werra"),Bo.forEach(r),zr=n(Re,"  es Ingeniero de Machine Learning en el equipo de c\xF3digo abierto en Hugging Face y coautor de un pr\xF3ximo "),ne=t(Re,"A",{href:!0,rel:!0});var Qo=s(ne);Cr=n(Qo,"libro de O\u2019Reilly sobre Transformadores"),Qo.forEach(r),Gr=n(Re,". Tiene varios a\xF1os de experiencia en la industria llevando modelos de PLN a producci\xF3n, trabajando a lo largo de todo el entorno de Machine Learning."),Re.forEach(r),ha=f(e),pe=t(e,"P",{});var Uo=s(pe);Rr=n(Uo,"\xBFEst\xE1s listo para comenzar? En este cap\xEDtulo vas a aprender:"),Uo.forEach(r),ga=f(e),b=t(e,"UL",{});var ve=s(b);ie=t(ve,"LI",{});var Aa=s(ie);Or=n(Aa,"C\xF3mo usar la funci\xF3n "),ke=t(Aa,"CODE",{});var Jo=s(ke);Br=n(Jo,"pipeline()"),Jo.forEach(r),Qr=n(Aa," para resolver tareas de PLN como la generaci\xF3n y clasificaci\xF3n de texto"),Aa.forEach(r),Ur=f(ve),Fe=t(ve,"LI",{});var Vo=s(Fe);Jr=n(Vo,"Sobre la arquitectura de los Transformadores"),Vo.forEach(r),Vr=f(ve),ze=t(ve,"LI",{});var Wo=s(ze);Wr=n(Wo,"C\xF3mo distinguir entre las arquitecturas de codificador, decodificador y codificador-decofidicador, adem\xE1s de sus casos de uso"),Wo.forEach(r),ve.forEach(r),this.h()},h(){i(y,"name","hf:doc:metadata"),i(y,"content",JSON.stringify(st)),i($,"id","introduccin"),i($,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i($,"href","#introduccin"),i(_,"class","relative group"),i(q,"id","te-damos-la-bienvenida-al-curso-de"),i(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(q,"href","#te-damos-la-bienvenida-al-curso-de"),i(E,"class","relative group"),i(k,"href","https://huggingface.co/"),i(k,"rel","nofollow"),i(F,"href","https://github.com/huggingface/transformers"),i(F,"rel","nofollow"),i(z,"href","https://github.com/huggingface/datasets"),i(z,"rel","nofollow"),i(C,"href","https://github.com/huggingface/tokenizers"),i(C,"rel","nofollow"),i(G,"href","https://github.com/huggingface/accelerate"),i(G,"rel","nofollow"),i(R,"href","https://huggingface.co/models"),i(R,"rel","nofollow"),i(H,"id","qu-esperar"),i(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(H,"href","#qu-esperar"),i(w,"class","relative group"),i(B,"class","block dark:hidden"),Yo(B.src,ao="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg")||i(B,"src",ao),i(B,"alt","Brief overview of the chapters of the course."),i(Q,"class","hidden dark:block"),Yo(Q.src,ro="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg")||i(Q,"src",ro),i(Q,"alt","Brief overview of the chapters of the course."),i(L,"class","flex justify-center"),i(J,"href","https://huggingface.co/models"),i(J,"rel","nofollow"),i(V,"href","https://course.fast.ai/"),i(V,"rel","nofollow"),i(W,"href","https://www.fast.ai/"),i(W,"rel","nofollow"),i(Y,"href","https://www.deeplearning.ai/"),i(Y,"rel","nofollow"),i(K,"href","https://pytorch.org/"),i(K,"rel","nofollow"),i(X,"href","https://www.tensorflow.org/"),i(X,"rel","nofollow"),i(Z,"href","https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-PLN-2-hugging_face-page-PLN-refresh"),i(Z,"rel","nofollow"),i(M,"id","quines-somos"),i(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(M,"href","#quines-somos"),i(A,"class","relative group"),i(oe,"href","https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/"),i(oe,"rel","nofollow"),i(le,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098103231/"),i(le,"rel","nofollow"),i(ne,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098103231/"),i(ne,"rel","nofollow")},m(e,c){a(document.head,y),d(e,We,c),d(e,_,c),a(_,$),a($,be),Qe(j,be,null),a(_,Na),a(_,ye),a(ye,Ia),d(e,Ye,c),d(e,E,c),a(E,q),a(q,_e),Qe(D,_e,null),a(E,$a),a(E,Ee),a(Ee,qa),d(e,Ke,c),Qe(x,e,c),d(e,Xe,c),d(e,p,c),a(p,Ha),a(p,k),a(k,Sa),a(p,Ma),a(p,F),a(F,ja),a(p,Da),a(p,z),a(z,xa),a(p,ka),a(p,C),a(C,Fa),a(p,za),a(p,G),a(G,Ca),a(p,Ga),a(p,R),a(R,Ra),a(p,Oa),d(e,Ze,c),d(e,w,c),a(w,H),a(H,we),Qe(O,we,null),a(w,Ba),a(w,Le),a(Le,Qa),d(e,ea,c),d(e,de,c),a(de,Ua),d(e,aa,c),d(e,L,c),a(L,B),a(L,Ja),a(L,Q),d(e,ra,c),d(e,h,c),a(h,U),a(U,Va),a(U,J),a(J,Wa),a(U,Ya),a(h,Ka),a(h,Pe),a(Pe,Xa),a(h,Za),a(h,Ae),a(Ae,er),d(e,oa,c),d(e,ue,c),a(ue,ar),d(e,ta,c),d(e,g,c),a(g,Te),a(Te,rr),a(g,or),a(g,v),a(v,tr),a(v,V),a(V,sr),a(v,lr),a(v,W),a(W,nr),a(v,ir),a(v,Y),a(Y,cr),a(g,dr),a(g,P),a(P,ur),a(P,K),a(K,fr),a(P,pr),a(P,X),a(X,mr),a(P,hr),d(e,sa,c),d(e,S,c),a(S,gr),a(S,Z),a(Z,vr),a(S,br),d(e,la,c),d(e,A,c),a(A,M),a(M,Ne),Qe(ee,Ne,null),a(A,yr),a(A,Ie),a(Ie,_r),d(e,na,c),d(e,fe,c),a(fe,Er),d(e,ia,c),d(e,ae,c),a(ae,$e),a($e,wr),a(ae,Lr),d(e,ca,c),d(e,re,c),a(re,qe),a(qe,Pr),a(re,Ar),d(e,da,c),d(e,T,c),a(T,He),a(He,Tr),a(T,Nr),a(T,Se),a(Se,oe),a(oe,Ir),a(T,$r),d(e,ua,c),d(e,te,c),a(te,Me),a(Me,qr),a(te,Hr),d(e,fa,c),d(e,se,c),a(se,je),a(je,Sr),a(se,Mr),d(e,pa,c),d(e,N,c),a(N,De),a(De,jr),a(N,Dr),a(N,le),a(le,xr),a(N,kr),d(e,ma,c),d(e,I,c),a(I,xe),a(xe,Fr),a(I,zr),a(I,ne),a(ne,Cr),a(I,Gr),d(e,ha,c),d(e,pe,c),a(pe,Rr),d(e,ga,c),d(e,b,c),a(b,ie),a(ie,Or),a(ie,ke),a(ke,Br),a(ie,Qr),a(b,Ur),a(b,Fe),a(Fe,Jr),a(b,Vr),a(b,ze),a(ze,Wr),va=!0},p:at,i(e){va||(Ue(j.$$.fragment,e),Ue(D.$$.fragment,e),Ue(x.$$.fragment,e),Ue(O.$$.fragment,e),Ue(ee.$$.fragment,e),va=!0)},o(e){Je(j.$$.fragment,e),Je(D.$$.fragment,e),Je(x.$$.fragment,e),Je(O.$$.fragment,e),Je(ee.$$.fragment,e),va=!1},d(e){r(y),e&&r(We),e&&r(_),Ve(j),e&&r(Ye),e&&r(E),Ve(D),e&&r(Ke),Ve(x,e),e&&r(Xe),e&&r(p),e&&r(Ze),e&&r(w),Ve(O),e&&r(ea),e&&r(de),e&&r(aa),e&&r(L),e&&r(ra),e&&r(h),e&&r(oa),e&&r(ue),e&&r(ta),e&&r(g),e&&r(sa),e&&r(S),e&&r(la),e&&r(A),Ve(ee),e&&r(na),e&&r(fe),e&&r(ia),e&&r(ae),e&&r(ca),e&&r(re),e&&r(da),e&&r(T),e&&r(ua),e&&r(te),e&&r(fa),e&&r(se),e&&r(pa),e&&r(N),e&&r(ma),e&&r(I),e&&r(ha),e&&r(pe),e&&r(ga),e&&r(b)}}}const st={local:"introduccin",sections:[{local:"te-damos-la-bienvenida-al-curso-de",title:"\xA1Te damos la bienvenida al curso de \u{1F917}!"},{local:"qu-esperar",title:"\xBFQu\xE9 esperar?"},{local:"quines-somos",title:"\xBFQui\xE9nes somos?"}],title:"Introducci\xF3n"};function lt(eo){return rt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class dt extends Ko{constructor(y){super();Xo(this,y,lt,tt,Zo,{})}}export{dt as default,st as metadata};
