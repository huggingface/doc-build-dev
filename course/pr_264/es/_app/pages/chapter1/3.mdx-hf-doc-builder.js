import{S as Sp,i as Op,s as Hp,e as r,k as c,w as $,t,M as Cp,c as l,d as a,m as u,a as i,x as v,h as n,b as m,N as Lp,G as s,g as p,y as b,q as _,o as E,B as x,v as zp}from"../../chunks/vendor-hf-doc-builder.js";import{T as Fe}from"../../chunks/Tip-hf-doc-builder.js";import{Y as Np}from"../../chunks/Youtube-hf-doc-builder.js";import{I as M}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as H}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as Dp}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";function Rp(L){let d,j,f,q,w,h,g,y,A,I,T;return{c(){d=r("p"),j=t("\u{1F440} Ves el bot\xF3n "),f=r("em"),q=t("Open in Colab"),w=t(" en la parte superior derecha? Haz clic en \xE9l para abrir un cuaderno de Google Colab con todos los ejemplos de c\xF3digo de esta secci\xF3n. Este bot\xF3n aparecer\xE1 en cualquier secci\xF3n que tenga ejemplos de c\xF3digo."),h=c(),g=r("p"),y=t("Si quieres ejecutar los ejemplos localmente, te recomendamos revisar la "),A=r("a"),I=t("configuraci\xF3n"),T=t("."),this.h()},l(P){d=l(P,"P",{});var k=i(d);j=n(k,"\u{1F440} Ves el bot\xF3n "),f=l(k,"EM",{});var D=i(f);q=n(D,"Open in Colab"),D.forEach(a),w=n(k," en la parte superior derecha? Haz clic en \xE9l para abrir un cuaderno de Google Colab con todos los ejemplos de c\xF3digo de esta secci\xF3n. Este bot\xF3n aparecer\xE1 en cualquier secci\xF3n que tenga ejemplos de c\xF3digo."),k.forEach(a),h=u(P),g=l(P,"P",{});var C=i(g);y=n(C,"Si quieres ejecutar los ejemplos localmente, te recomendamos revisar la "),A=l(C,"A",{href:!0});var S=i(A);I=n(S,"configuraci\xF3n"),S.forEach(a),T=n(C,"."),C.forEach(a),this.h()},h(){m(A,"href","/course/chapter0")},m(P,k){p(P,d,k),s(d,j),s(d,f),s(f,q),s(d,w),p(P,h,k),p(P,g,k),s(g,y),s(g,A),s(A,I),s(g,T)},d(P){P&&a(d),P&&a(h),P&&a(g)}}}function Fp(L){let d,j,f,q,w;return{c(){d=r("p"),j=t("\u26A0\uFE0F El Hub de Hugging Face no se limita a Transformadores. \xA1Cualquiera puede compartir los tipos de modelos o conjuntos de datos que quiera! \xA1"),f=r("a"),q=t("Crea una cuenta de huggingface.co"),w=t(" para beneficiarte de todas las funciones disponibles!"),this.h()},l(h){d=l(h,"P",{});var g=i(d);j=n(g,"\u26A0\uFE0F El Hub de Hugging Face no se limita a Transformadores. \xA1Cualquiera puede compartir los tipos de modelos o conjuntos de datos que quiera! \xA1"),f=l(g,"A",{href:!0});var y=i(f);q=n(y,"Crea una cuenta de huggingface.co"),y.forEach(a),w=n(g," para beneficiarte de todas las funciones disponibles!"),g.forEach(a),this.h()},h(){m(f,"href","https://huggingface.co/join")},m(h,g){p(h,d,g),s(d,j),s(d,f),s(f,q),s(d,w)},d(h){h&&a(d)}}}function Mp(L){let d,j,f,q,w;return{c(){d=r("p"),j=t("\u270F\uFE0F "),f=r("strong"),q=t("\xA1Pru\xE9balo!"),w=t(" Juega con tus propias secuencias y etiquetas, y observa c\xF3mo se comporta el modelo.")},l(h){d=l(h,"P",{});var g=i(d);j=n(g,"\u270F\uFE0F "),f=l(g,"STRONG",{});var y=i(f);q=n(y,"\xA1Pru\xE9balo!"),y.forEach(a),w=n(g," Juega con tus propias secuencias y etiquetas, y observa c\xF3mo se comporta el modelo."),g.forEach(a)},m(h,g){p(h,d,g),s(d,j),s(d,f),s(f,q),s(d,w)},d(h){h&&a(d)}}}function Gp(L){let d,j,f,q,w,h,g,y,A,I,T;return{c(){d=r("p"),j=t("\u270F\uFE0F "),f=r("strong"),q=t("\xA1Pru\xE9balo!"),w=t(" Usa los argumentos "),h=r("code"),g=t("num_return_sequences"),y=t(" y "),A=r("code"),I=t("max_length"),T=t(" para generar dos oraciones de 15 palabras cada una.")},l(P){d=l(P,"P",{});var k=i(d);j=n(k,"\u270F\uFE0F "),f=l(k,"STRONG",{});var D=i(f);q=n(D,"\xA1Pru\xE9balo!"),D.forEach(a),w=n(k," Usa los argumentos "),h=l(k,"CODE",{});var C=i(h);g=n(C,"num_return_sequences"),C.forEach(a),y=n(k," y "),A=l(k,"CODE",{});var S=i(A);I=n(S,"max_length"),S.forEach(a),T=n(k," para generar dos oraciones de 15 palabras cada una."),k.forEach(a)},m(P,k){p(P,d,k),s(d,j),s(d,f),s(f,q),s(d,w),s(d,h),s(h,g),s(d,y),s(d,A),s(A,I),s(d,T)},d(P){P&&a(d)}}}function Up(L){let d,j,f,q,w;return{c(){d=r("p"),j=t("\u270F\uFE0F "),f=r("strong"),q=t("\xA1Pru\xE9balo!"),w=t(" Usa los filtros para encontrar un modelo de generaci\xF3n de texto para un idioma diferente. \xA1Si\xE9ntete libre de jugar con el widget y \xFAsalo en un pipeline!")},l(h){d=l(h,"P",{});var g=i(d);j=n(g,"\u270F\uFE0F "),f=l(g,"STRONG",{});var y=i(f);q=n(y,"\xA1Pru\xE9balo!"),y.forEach(a),w=n(g," Usa los filtros para encontrar un modelo de generaci\xF3n de texto para un idioma diferente. \xA1Si\xE9ntete libre de jugar con el widget y \xFAsalo en un pipeline!"),g.forEach(a)},m(h,g){p(h,d,g),s(d,j),s(d,f),s(f,q),s(d,w)},d(h){h&&a(d)}}}function Bp(L){let d,j,f,q,w,h,g,y,A,I,T,P,k,D;return{c(){d=r("p"),j=t("\u270F\uFE0F "),f=r("strong"),q=t("\xA1Pru\xE9balo!"),w=t(" Busca el modelo "),h=r("code"),g=t("bert-base-cased"),y=t(" en el Hub e identifica su "),A=r("em"),I=t("mask token"),T=t(" en el widget de la API de Inferencia. \xBFQu\xE9 predice este modelo para la oraci\xF3n que est\xE1 en el ejemplo de "),P=r("code"),k=t("pipeline"),D=t(" anterior?")},l(C){d=l(C,"P",{});var S=i(d);j=n(S,"\u270F\uFE0F "),f=l(S,"STRONG",{});var Ha=i(f);q=n(Ha,"\xA1Pru\xE9balo!"),Ha.forEach(a),w=n(S," Busca el modelo "),h=l(S,"CODE",{});var Me=i(h);g=n(Me,"bert-base-cased"),Me.forEach(a),y=n(S," en el Hub e identifica su "),A=l(S,"EM",{});var G=i(A);I=n(G,"mask token"),G.forEach(a),T=n(S," en el widget de la API de Inferencia. \xBFQu\xE9 predice este modelo para la oraci\xF3n que est\xE1 en el ejemplo de "),P=l(S,"CODE",{});var Ge=i(P);k=n(Ge,"pipeline"),Ge.forEach(a),D=n(S," anterior?"),S.forEach(a)},m(C,S){p(C,d,S),s(d,j),s(d,f),s(f,q),s(d,w),s(d,h),s(h,g),s(d,y),s(d,A),s(A,I),s(d,T),s(d,P),s(P,k),s(d,D)},d(C){C&&a(d)}}}function Vp(L){let d,j,f,q,w,h,g,y;return{c(){d=r("p"),j=t("\u270F\uFE0F "),f=r("strong"),q=t("\xA1Pru\xE9balo!"),w=t(" Busca en el Model Hub un modelo capaz de hacer etiquetado "),h=r("em"),g=t("part-of-speech"),y=t(" (que se abrevia usualmente como POS) en Ingl\xE9s. \xBFQu\xE9 predice este modelo para la oraci\xF3n en el ejemplo de arriba?")},l(A){d=l(A,"P",{});var I=i(d);j=n(I,"\u270F\uFE0F "),f=l(I,"STRONG",{});var T=i(f);q=n(T,"\xA1Pru\xE9balo!"),T.forEach(a),w=n(I," Busca en el Model Hub un modelo capaz de hacer etiquetado "),h=l(I,"EM",{});var P=i(h);g=n(P,"part-of-speech"),P.forEach(a),y=n(I," (que se abrevia usualmente como POS) en Ingl\xE9s. \xBFQu\xE9 predice este modelo para la oraci\xF3n en el ejemplo de arriba?"),I.forEach(a)},m(A,I){p(A,d,I),s(d,j),s(d,f),s(f,q),s(d,w),s(d,h),s(h,g),s(d,y)},d(A){A&&a(d)}}}function Qp(L){let d,j,f,q,w;return{c(){d=r("p"),j=t("\u270F\uFE0F "),f=r("strong"),q=t("\xA1Pru\xE9balo!"),w=t(" Busca modelos de traducci\xF3n en otros idiomas e intenta traducir la oraci\xF3n anterior en varios de ellos.")},l(h){d=l(h,"P",{});var g=i(d);j=n(g,"\u270F\uFE0F "),f=l(g,"STRONG",{});var y=i(f);q=n(y,"\xA1Pru\xE9balo!"),y.forEach(a),w=n(g," Busca modelos de traducci\xF3n en otros idiomas e intenta traducir la oraci\xF3n anterior en varios de ellos."),g.forEach(a)},m(h,g){p(h,d,g),s(d,j),s(d,f),s(f,q),s(d,w)},d(h){h&&a(d)}}}function Wp(L){let d,j,f,q,w,h,g,y,A,I,T,P,k,D,C,S,Ha,Me,G,Ge,Z,ie,es,Ue,rn,as,ln,vo,Ca,pn,bo,pe,Ul,_o,U,cn,Be,un,dn,Ve,mn,fn,Eo,ce,xo,La,hn,qo,K,ue,ss,Qe,gn,os,$n,wo,We,jo,de,vn,ts,bn,_n,yo,Ye,ko,Je,Po,za,En,Ao,Ze,Io,Ke,To,me,xn,ns,qn,wn,So,Na,jn,Oo,B,rs,yn,kn,ls,Pn,An,is,In,Ho,fe,Tn,Xe,Sn,On,Co,O,Da,ps,Hn,Cn,Ln,cs,us,zn,Nn,Ra,ds,Dn,Rn,Fn,ms,fs,Mn,Gn,hs,gs,Un,Bn,$s,vs,Vn,Qn,bs,_s,Wn,Yn,Es,xs,Jn,Zn,qs,ws,Kn,Lo,Fa,Xn,zo,X,he,js,ea,er,ys,ar,No,ge,sr,ks,or,tr,Do,aa,Ro,sa,Fo,$e,nr,Ps,rr,lr,Mo,ve,Go,ee,be,As,oa,ir,Is,pr,Uo,_e,cr,Ts,ur,dr,Bo,ta,Vo,na,Qo,V,mr,Ss,fr,hr,Os,gr,$r,Wo,Ee,Yo,ae,xe,Hs,ra,vr,Cs,br,Jo,Q,_r,la,Er,xr,ia,qr,wr,Zo,qe,jr,pa,Ls,yr,kr,Ko,ca,Xo,ua,et,we,Pr,zs,Ar,Ir,at,Ma,Tr,st,je,ot,se,ye,Ns,da,Sr,Ds,Or,tt,ke,Hr,ma,Cr,Lr,nt,Pe,zr,fa,Nr,Dr,rt,oe,Ae,Rs,ha,Rr,Fs,Fr,lt,Ie,Mr,Ms,Gr,Ur,it,ga,pt,$a,ct,R,Br,Gs,Vr,Qr,Us,Wr,Yr,Bs,Jr,Zr,ut,Te,dt,te,Se,Vs,va,Kr,Qs,Xr,mt,Ga,el,ft,ba,ht,_a,gt,Ua,al,$t,N,sl,Ws,ol,tl,Ys,nl,rl,Js,ll,il,Zs,pl,cl,Ks,ul,dl,vt,Oe,bt,ne,He,Xs,Ea,ml,eo,fl,_t,Ce,hl,ao,gl,$l,Et,xa,xt,qa,qt,Ba,vl,wt,re,Le,so,wa,bl,oo,_l,jt,Va,El,yt,ja,kt,ya,Pt,W,xl,to,ql,wl,no,jl,yl,At,le,ze,ro,ka,kl,lo,Pl,It,Y,Al,io,Il,Tl,Pa,Sl,Ol,Tt,Aa,St,Ia,Ot,J,Hl,po,Cl,Ll,co,zl,Nl,Ht,Ne,Ct,De,Dl,uo,Rl,Fl,Lt;return h=new M({}),T=new Dp({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter1/section3.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter1/section3.ipynb"}]}}),G=new Fe({props:{$$slots:{default:[Rp]},$$scope:{ctx:L}}}),Ue=new M({}),ce=new Fe({props:{$$slots:{default:[Fp]},$$scope:{ctx:L}}}),Qe=new M({}),We=new Np({props:{id:"tiZFewofSLM"}}),Ye=new H({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>)
classifier(<span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>)`}}),Je=new H({props:{code:"[{'label': 'POSITIVE', 'score': 0.9598047137260437}]",highlighted:'[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;POSITIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9598047137260437</span>}]'}}),Ze=new H({props:{code:`classifier(
    ["I've been waiting for a HuggingFace course my whole life.", "I hate this so much!"]
)`,highlighted:`classifier(
    [<span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>, <span class="hljs-string">&quot;I hate this so much!&quot;</span>]
)`}}),Ke=new H({props:{code:`[{'label': 'POSITIVE', 'score': 0.9598047137260437},
 {'label': 'NEGATIVE', 'score': 0.9994558095932007}]`,highlighted:`[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;POSITIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9598047137260437</span>},
 {<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;NEGATIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9994558095932007</span>}]`}}),ea=new M({}),aa=new H({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

classifier = pipeline(<span class="hljs-string">&quot;zero-shot-classification&quot;</span>)
classifier(
    <span class="hljs-string">&quot;This is a course about the Transformers library&quot;</span>,
    candidate_labels=[<span class="hljs-string">&quot;education&quot;</span>, <span class="hljs-string">&quot;politics&quot;</span>, <span class="hljs-string">&quot;business&quot;</span>],
)`}}),sa=new H({props:{code:`{'sequence': 'This is a course about the Transformers library',
 'labels': ['education', 'business', 'politics'],
 'scores': [0.8445963859558105, 0.111976258456707, 0.043427448719739914]}`,highlighted:`{<span class="hljs-string">&#x27;sequence&#x27;</span>: <span class="hljs-string">&#x27;This is a course about the Transformers library&#x27;</span>,
 <span class="hljs-string">&#x27;labels&#x27;</span>: [<span class="hljs-string">&#x27;education&#x27;</span>, <span class="hljs-string">&#x27;business&#x27;</span>, <span class="hljs-string">&#x27;politics&#x27;</span>],
 <span class="hljs-string">&#x27;scores&#x27;</span>: [<span class="hljs-number">0.8445963859558105</span>, <span class="hljs-number">0.111976258456707</span>, <span class="hljs-number">0.043427448719739914</span>]}`}}),ve=new Fe({props:{$$slots:{default:[Mp]},$$scope:{ctx:L}}}),oa=new M({}),ta=new H({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

generator = pipeline(<span class="hljs-string">&quot;text-generation&quot;</span>)
generator(<span class="hljs-string">&quot;In this course, we will teach you how to&quot;</span>)`}}),na=new H({props:{code:`[{'generated_text': 'In this course, we will teach you how to understand and use '
                    'data flow and data interchange when handling user data. We '
                    'will be working with one or more of the most commonly used '
                    'data flows \u2014 data flows of various types, as seen by the '
                    'HTTP'}]`,highlighted:`[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;In this course, we will teach you how to understand and use &#x27;</span>
                    <span class="hljs-string">&#x27;data flow and data interchange when handling user data. We &#x27;</span>
                    <span class="hljs-string">&#x27;will be working with one or more of the most commonly used &#x27;</span>
                    <span class="hljs-string">&#x27;data flows \u2014 data flows of various types, as seen by the &#x27;</span>
                    <span class="hljs-string">&#x27;HTTP&#x27;</span>}]`}}),Ee=new Fe({props:{$$slots:{default:[Gp]},$$scope:{ctx:L}}}),ra=new M({}),ca=new H({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

generator = pipeline(<span class="hljs-string">&quot;text-generation&quot;</span>, model=<span class="hljs-string">&quot;distilgpt2&quot;</span>)
generator(
    <span class="hljs-string">&quot;In this course, we will teach you how to&quot;</span>,
    max_length=<span class="hljs-number">30</span>,
    num_return_sequences=<span class="hljs-number">2</span>,
)`}}),ua=new H({props:{code:`[{'generated_text': 'In this course, we will teach you how to manipulate the world and '
                    'move your mental and physical capabilities to your advantage.'},
 {'generated_text': 'In this course, we will teach you how to become an expert and '
                    'practice realtime, and with a hands on experience on both real '
                    'time and real'}]`,highlighted:`[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;In this course, we will teach you how to manipulate the world and &#x27;</span>
                    <span class="hljs-string">&#x27;move your mental and physical capabilities to your advantage.&#x27;</span>},
 {<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&#x27;In this course, we will teach you how to become an expert and &#x27;</span>
                    <span class="hljs-string">&#x27;practice realtime, and with a hands on experience on both real &#x27;</span>
                    <span class="hljs-string">&#x27;time and real&#x27;</span>}]`}}),je=new Fe({props:{$$slots:{default:[Up]},$$scope:{ctx:L}}}),da=new M({}),ha=new M({}),ga=new H({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

unmasker = pipeline(<span class="hljs-string">&quot;fill-mask&quot;</span>)
unmasker(<span class="hljs-string">&quot;This course will teach you all about &lt;mask&gt; models.&quot;</span>, top_k=<span class="hljs-number">2</span>)`}}),$a=new H({props:{code:`[{'sequence': 'This course will teach you all about mathematical models.',
  'score': 0.19619831442832947,
  'token': 30412,
  'token_str': ' mathematical'},
 {'sequence': 'This course will teach you all about computational models.',
  'score': 0.04052725434303284,
  'token': 38163,
  'token_str': ' computational'}]`,highlighted:`[{<span class="hljs-string">&#x27;sequence&#x27;</span>: <span class="hljs-string">&#x27;This course will teach you all about mathematical models.&#x27;</span>,
  <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.19619831442832947</span>,
  <span class="hljs-string">&#x27;token&#x27;</span>: <span class="hljs-number">30412</span>,
  <span class="hljs-string">&#x27;token_str&#x27;</span>: <span class="hljs-string">&#x27; mathematical&#x27;</span>},
 {<span class="hljs-string">&#x27;sequence&#x27;</span>: <span class="hljs-string">&#x27;This course will teach you all about computational models.&#x27;</span>,
  <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.04052725434303284</span>,
  <span class="hljs-string">&#x27;token&#x27;</span>: <span class="hljs-number">38163</span>,
  <span class="hljs-string">&#x27;token_str&#x27;</span>: <span class="hljs-string">&#x27; computational&#x27;</span>}]`}}),Te=new Fe({props:{$$slots:{default:[Bp]},$$scope:{ctx:L}}}),va=new M({}),ba=new H({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

ner = pipeline(<span class="hljs-string">&quot;ner&quot;</span>, grouped_entities=<span class="hljs-literal">True</span>)
ner(<span class="hljs-string">&quot;My name is Sylvain and I work at Hugging Face in Brooklyn.&quot;</span>)`}}),_a=new H({props:{code:`[{'entity_group': 'PER', 'score': 0.99816, 'word': 'Sylvain', 'start': 11, 'end': 18}, 
 {'entity_group': 'ORG', 'score': 0.97960, 'word': 'Hugging Face', 'start': 33, 'end': 45}, 
 {'entity_group': 'LOC', 'score': 0.99321, 'word': 'Brooklyn', 'start': 49, 'end': 57}
]`,highlighted:`[{<span class="hljs-string">&#x27;entity_group&#x27;</span>: <span class="hljs-string">&#x27;PER&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.99816</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;Sylvain&#x27;</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">11</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">18</span>}, 
 {<span class="hljs-string">&#x27;entity_group&#x27;</span>: <span class="hljs-string">&#x27;ORG&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.97960</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;Hugging Face&#x27;</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">33</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">45</span>}, 
 {<span class="hljs-string">&#x27;entity_group&#x27;</span>: <span class="hljs-string">&#x27;LOC&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.99321</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;Brooklyn&#x27;</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">49</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">57</span>}
]`}}),Oe=new Fe({props:{$$slots:{default:[Vp]},$$scope:{ctx:L}}}),Ea=new M({}),xa=new H({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

question_answerer = pipeline(<span class="hljs-string">&quot;question-answering&quot;</span>)
question_answerer(
    question=<span class="hljs-string">&quot;Where do I work?&quot;</span>,
    context=<span class="hljs-string">&quot;My name is Sylvain and I work at Hugging Face in Brooklyn&quot;</span>,
)`}}),qa=new H({props:{code:"{'score': 0.6385916471481323, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}",highlighted:'{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.6385916471481323</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">33</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">45</span>, <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;Hugging Face&#x27;</span>}'}}),wa=new M({}),ja=new H({props:{code:`
`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

summarizer = pipeline(<span class="hljs-string">&quot;summarization&quot;</span>)
summarizer(
    <span class="hljs-string">&quot;&quot;&quot;
    America has changed dramatically during recent years. Not only has the number of 
    graduates in traditional engineering disciplines such as mechanical, civil, 
    electrical, chemical, and aeronautical engineering declined, but in most of 
    the premier American universities engineering curricula now concentrate on 
    and encourage largely the study of engineering science. As a result, there 
    are declining offerings in engineering subjects dealing with infrastructure, 
    the environment, and related issues, and greater concentration on high 
    technology subjects, largely supporting increasingly complex scientific 
    developments. While the latter is important, it should not be at the expense 
    of more traditional engineering.

    Rapidly developing economies such as China and India, as well as other 
    industrial countries in Europe and Asia, continue to encourage and advance 
    the teaching of engineering. Both China and India, respectively, graduate 
    six and eight times as many traditional engineers as does the United States. 
    Other industrial countries at minimum maintain their output, while America 
    suffers an increasingly serious decline in the number of engineering graduates 
    and a lack of well-educated engineers.
&quot;&quot;&quot;</span>
)`}}),ya=new H({props:{code:`[{'summary_text': ' America has changed dramatically during recent years . The '
                  'number of engineering graduates in the U.S. has declined in '
                  'traditional engineering disciplines such as mechanical, civil '
                  ', electrical, chemical, and aeronautical engineering . Rapidly '
                  'developing economies such as China and India, as well as other '
                  'industrial countries in Europe and Asia, continue to encourage '
                  'and advance engineering .'}]`,highlighted:`[{<span class="hljs-string">&#x27;summary_text&#x27;</span>: <span class="hljs-string">&#x27; America has changed dramatically during recent years . The &#x27;</span>
                  <span class="hljs-string">&#x27;number of engineering graduates in the U.S. has declined in &#x27;</span>
                  <span class="hljs-string">&#x27;traditional engineering disciplines such as mechanical, civil &#x27;</span>
                  <span class="hljs-string">&#x27;, electrical, chemical, and aeronautical engineering . Rapidly &#x27;</span>
                  <span class="hljs-string">&#x27;developing economies such as China and India, as well as other &#x27;</span>
                  <span class="hljs-string">&#x27;industrial countries in Europe and Asia, continue to encourage &#x27;</span>
                  <span class="hljs-string">&#x27;and advance engineering .&#x27;</span>}]`}}),ka=new M({}),Aa=new H({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

translator = pipeline(<span class="hljs-string">&quot;translation&quot;</span>, model=<span class="hljs-string">&quot;Helsinki-NLP/opus-mt-fr-en&quot;</span>)
translator(<span class="hljs-string">&quot;Ce cours est produit par Hugging Face.&quot;</span>)`}}),Ia=new H({props:{code:"[{'translation_text': 'This course is produced by Hugging Face.'}]",highlighted:'[{<span class="hljs-string">&#x27;translation_text&#x27;</span>: <span class="hljs-string">&#x27;This course is produced by Hugging Face.&#x27;</span>}]'}}),Ne=new Fe({props:{$$slots:{default:[Qp]},$$scope:{ctx:L}}}),{c(){d=r("meta"),j=c(),f=r("h1"),q=r("a"),w=r("span"),$(h.$$.fragment),g=c(),y=r("span"),A=t("Transformadores, \xBFqu\xE9 pueden hacer?"),I=c(),$(T.$$.fragment),P=c(),k=r("p"),D=t("En esta secci\xF3n, veremos qu\xE9 pueden hacer los Transformadores y usaremos nuestra primera herramienta de la librer\xEDa \u{1F917} Transformers: la funci\xF3n "),C=r("code"),S=t("pipeline()"),Ha=t("."),Me=c(),$(G.$$.fragment),Ge=c(),Z=r("h2"),ie=r("a"),es=r("span"),$(Ue.$$.fragment),rn=c(),as=r("span"),ln=t("\xA1Los Transformadores est\xE1n en todas partes!"),vo=c(),Ca=r("p"),pn=t("Los Transformadores se usan para resolver todo tipo de tareas de PLN, como las mencionadas en la secci\xF3n anterior. Aqu\xED te mostramos algunas de las compa\xF1\xEDas y organizaciones que usan Hugging Face y Transformadores, que tambi\xE9n contribuyen de vuelta a la comunidad al compartir sus modelos:"),bo=c(),pe=r("img"),_o=c(),U=r("p"),cn=t("La "),Be=r("a"),un=t("librer\xEDa \u{1F917} Transformers"),dn=t(" provee la funcionalidad de crear y usar estos modelos compartidos. El "),Ve=r("a"),mn=t("Hub de Modelos"),fn=t(" contiene miles de modelos preentrenados que cualquiera puede descargar y usar. \xA1T\xFA tambi\xE9n puedes subir tus propios modelos al Hub!"),Eo=c(),$(ce.$$.fragment),xo=c(),La=r("p"),hn=t("Antes de ver c\xF3mo funcionan internamente los Transformadores, veamos un par de ejemplos sobre c\xF3mo pueden ser usados para resolver tareas de PLN."),qo=c(),K=r("h2"),ue=r("a"),ss=r("span"),$(Qe.$$.fragment),gn=c(),os=r("span"),$n=t("Trabajando con pipelines"),wo=c(),$(We.$$.fragment),jo=c(),de=r("p"),vn=t("El objeto m\xE1s b\xE1sico en la librer\xEDa \u{1F917} Transformers es la funci\xF3n "),ts=r("code"),bn=t("pipeline()"),_n=t(". Esta funci\xF3n conecta un modelo con los pasos necesarios para su preprocesamiento y posprocesamiento, permiti\xE9ndonos introducir de manera directa cualquier texto y obtener una respuesta inteligible:"),yo=c(),$(Ye.$$.fragment),ko=c(),$(Je.$$.fragment),Po=c(),za=r("p"),En=t("\xA1Incluso podemos pasar varias oraciones!"),Ao=c(),$(Ze.$$.fragment),Io=c(),$(Ke.$$.fragment),To=c(),me=r("p"),xn=t("Por defecto, este pipeline selecciona un modelo particular preentrenado que ha sido ajustado para el an\xE1lisis de sentimientos en Ingl\xE9s. El modelo se descarga y se almacena en el cach\xE9 cuando creas el objeto "),ns=r("code"),qn=t("classifier"),wn=t(". Si vuelves a ejecutar el comando, se usar\xE1 el modelo almacenado en cach\xE9 y no habr\xE1 necesidad de descargarlo de nuevo."),So=c(),Na=r("p"),jn=t("Hay tres pasos principales que ocurren cuando pasas un texto a un pipeline:"),Oo=c(),B=r("ol"),rs=r("li"),yn=t("El texto es preprocesado en un formato que el modelo puede entender."),kn=c(),ls=r("li"),Pn=t("La entrada preprocesada se pasa al modelo."),An=c(),is=r("li"),In=t("Las predicciones del modelo son posprocesadas, de tal manera que las puedas entender."),Ho=c(),fe=r("p"),Tn=t("Algunos de los "),Xe=r("a"),Sn=t("pipelines disponibles"),On=t(" son:"),Co=c(),O=r("ul"),Da=r("li"),ps=r("code"),Hn=t("feature-extraction"),Cn=t(" (obtener la representaci\xF3n vectorial de un texto)"),Ln=c(),cs=r("li"),us=r("code"),zn=t("fill-mask"),Nn=c(),Ra=r("li"),ds=r("code"),Dn=t("ner"),Rn=t(" (reconocimiento de entidades nombradas)"),Fn=c(),ms=r("li"),fs=r("code"),Mn=t("question-answering"),Gn=c(),hs=r("li"),gs=r("code"),Un=t("sentiment-analysis"),Bn=c(),$s=r("li"),vs=r("code"),Vn=t("summarization"),Qn=c(),bs=r("li"),_s=r("code"),Wn=t("text-generation"),Yn=c(),Es=r("li"),xs=r("code"),Jn=t("translation"),Zn=c(),qs=r("li"),ws=r("code"),Kn=t("zero-shot-classification"),Lo=c(),Fa=r("p"),Xn=t("\xA1Veamos algunas de ellas!"),zo=c(),X=r("h2"),he=r("a"),js=r("span"),$(ea.$$.fragment),er=c(),ys=r("span"),ar=t("Clasificaci\xF3n *zero-shot*"),No=c(),ge=r("p"),sr=t("Empezaremos abordando una tarea m\xE1s compleja, en la que necesitamos clasificar textos que no han sido etiquetados. Este es un escenario com\xFAn en proyectos de la vida real porque anotar texto usualmente requiere mucho tiempo y dominio del tema. Para este caso de uso, el pipeline "),ks=r("code"),or=t("zero-shot-classification"),tr=t(" es muy poderoso: permite que especifiques qu\xE9 etiquetas usar para la clasificaci\xF3n, para que no dependas de las etiquetas del modelo preentrenado. Ya viste c\xF3mo el modelo puede clasificar una oraci\xF3n como positiva o negativa usando esas dos etiquetas \u2014 pero tambi\xE9n puede clasificar el texto usando cualquier otro conjunto de etiquetas que definas."),Do=c(),$(aa.$$.fragment),Ro=c(),$(sa.$$.fragment),Fo=c(),$e=r("p"),nr=t("Este pipeline se llama "),Ps=r("em"),rr=t("zero-shot"),lr=t(" porque no necesitas ajustar el modelo con tus datos para usarlo. \xA1Puede devolver directamente puntajes de probabilidad para cualquier lista de de etiquetas que escojas!"),Mo=c(),$(ve.$$.fragment),Go=c(),ee=r("h2"),be=r("a"),As=r("span"),$(oa.$$.fragment),ir=c(),Is=r("span"),pr=t("Generaci\xF3n de texto"),Uo=c(),_e=r("p"),cr=t("Ahora veamos c\xF3mo usar un pipeline para generar texto. La idea es que proporciones una indicaci\xF3n ("),Ts=r("em"),ur=t("prompt"),dr=t(") y el modelo la va a completar autom\xE1ticamente al generar el texto restante. Esto es parecido a la funci\xF3n de texto predictivo que est\xE1 presente en muchos tel\xE9fonos. La generaci\xF3n de texto involucra aleat\xF3riedad, por lo que es normal que no obtengas el mismo resultado que se muestra abajo."),Bo=c(),$(ta.$$.fragment),Vo=c(),$(na.$$.fragment),Qo=c(),V=r("p"),mr=t("Puedes controlar cu\xE1ntas secuencias diferentes se generan con el argumento "),Ss=r("code"),fr=t("num_return_sequences"),hr=t(" y la longitud total del texto de salida con el argumento "),Os=r("code"),gr=t("max_length"),$r=t("."),Wo=c(),$(Ee.$$.fragment),Yo=c(),ae=r("h2"),xe=r("a"),Hs=r("span"),$(ra.$$.fragment),vr=c(),Cs=r("span"),br=t("Usa cualquier modelo del Hub en un pipeline"),Jo=c(),Q=r("p"),_r=t("Los ejemplos anteriores usaban el modelo por defecto para cada tarea, pero tambi\xE9n puedes escoger un modelo particular del Hub y usarlo en un pipeline para una tarea espec\xEDfica - por ejemplo, la generaci\xF3n de texto. Ve al "),la=r("a"),Er=t("Hub de Modelos"),xr=t(" y haz clic en la etiqueta correspondiente en la parte izquierda para mostrar \xFAnicamente los modelos soportados para esa tarea. Deber\xEDas ver una p\xE1gina "),ia=r("a"),qr=t("como esta"),wr=t("."),Zo=c(),qe=r("p"),jr=t("\xA1Intentemos con el modelo "),pa=r("a"),Ls=r("code"),yr=t("distilgpt2"),kr=t("! Puedes cargarlo en el mismo pipeline de la siguiente manera:"),Ko=c(),$(ca.$$.fragment),Xo=c(),$(ua.$$.fragment),et=c(),we=r("p"),Pr=t("Puedes refinar tu b\xFAsqueda de un modelo haciendo clic en las etiquetas de idioma y escoger uno que genere textos en otro idioma. El Hub de Modelos tambi\xE9n contiene puntos de control ("),zs=r("em"),Ar=t("checkpoints"),Ir=t(") para modelos que soportan m\xFAltiples lenguajes."),at=c(),Ma=r("p"),Tr=t("Una vez has seleccionado un modelo haciendo clic en \xE9l, ver\xE1s que hay un widget que te permite probarlo directamente en l\xEDnea. De esta manera puedes probar r\xE1pidamente las capacidades del modelo antes de descargarlo."),st=c(),$(je.$$.fragment),ot=c(),se=r("h3"),ye=r("a"),Ns=r("span"),$(da.$$.fragment),Sr=c(),Ds=r("span"),Or=t("La API de Inferencia"),tt=c(),ke=r("p"),Hr=t("Todos los modelos pueden ser probados directamente en tu navegador usando la API de Inferencia, que est\xE1 disponible en el "),ma=r("a"),Cr=t("sitio web"),Lr=t(" de Hugging Face. Puedes jugar con el modelo directamente en esta p\xE1gina al pasar tu texto personalizado como entrada y ver c\xF3mo lo procesa."),nt=c(),Pe=r("p"),zr=t("La API de Inferencia que hace funcionar al widget tambi\xE9n est\xE1 disponible como un producto pago, algo \xFAtil si lo necesitas para tus flujos de trabajo. Dir\xEDgete a la "),fa=r("a"),Nr=t("p\xE1gina de precios"),Dr=t(" para m\xE1s detalles."),rt=c(),oe=r("h2"),Ae=r("a"),Rs=r("span"),$(ha.$$.fragment),Rr=c(),Fs=r("span"),Fr=t("Llenado de ocultos (*Mask filling*)"),lt=c(),Ie=r("p"),Mr=t("El siguiente pipeline con el que vas a trabajar es "),Ms=r("code"),Gr=t("fill-mask"),Ur=t(". La idea de esta tarea es llenar los espacios en blanco de un texto dado:"),it=c(),$(ga.$$.fragment),pt=c(),$($a.$$.fragment),ct=c(),R=r("p"),Br=t("El argumento "),Gs=r("code"),Vr=t("top_k"),Qr=t(" controla el n\xFAmero de posibilidades que se van a mostrar. Nota que en este caso el modelo llena la palabra especial "),Us=r("code"),Wr=t("<mask>"),Yr=t(", que se denomina com\xFAnmente como "),Bs=r("em"),Jr=t("mask token"),Zr=t(". Otros modelos pueden tener diferentes tokens, por lo que es una buena idea verificar la palabra especial adecuada cuando est\xE9s explorando diferentes modelos. Una manera de confirmar es revisar la palabra usada en el widget."),ut=c(),$(Te.$$.fragment),dt=c(),te=r("h2"),Se=r("a"),Vs=r("span"),$(va.$$.fragment),Kr=c(),Qs=r("span"),Xr=t("Reconocimiento de entidades nombradas"),mt=c(),Ga=r("p"),el=t("El reconocimiento de entidades nombradas (REN) es una tarea en la que el modelo tiene que encontrar cu\xE1les partes del texto introducido corresponden a entidades como personas, ubicaciones u organizaciones. Veamos un ejemplo:"),ft=c(),$(ba.$$.fragment),ht=c(),$(_a.$$.fragment),gt=c(),Ua=r("p"),al=t("En este caso el modelo identific\xF3 correctamente que Sylvain es una persona (PER), Hugging Face una organizaci\xF3n (ORG) y Brooklyn una ubicaci\xF3n (LOC)."),$t=c(),N=r("p"),sl=t("Pasamos la opci\xF3n "),Ws=r("code"),ol=t("grouped_entities=True"),tl=t(" en la funci\xF3n de creaci\xF3n del pipeline para decirle que agrupe las partes de la oraci\xF3n que corresponden a la misma entidad: Aqu\xED el modelo agrup\xF3 correctamente \u201CHugging\u201D y \u201CFace\u201D como una sola organizaci\xF3n, a pesar de que su nombre est\xE1 compuesto de varias palabras. De hecho, como veremos en el siguente cap\xEDtulo, el preprocesamiento puede incluso dividir palabras en partes m\xE1s peque\xF1as. Por ejemplo, \u2018Sylvain\u2019 se separa en cuatro piezas: "),Ys=r("code"),nl=t("S"),rl=t(", "),Js=r("code"),ll=t("##yl"),il=t(", "),Zs=r("code"),pl=t("##va"),cl=t(" y"),Ks=r("code"),ul=t("##in"),dl=t(". En el paso de prosprocesamiento, el pipeline reagrupa de manera exitosa dichas piezas."),vt=c(),$(Oe.$$.fragment),bt=c(),ne=r("h2"),He=r("a"),Xs=r("span"),$(Ea.$$.fragment),ml=c(),eo=r("span"),fl=t("Responder preguntas"),_t=c(),Ce=r("p"),hl=t("El pipeline "),ao=r("code"),gl=t("question-answering"),$l=t(" responde preguntas usando informaci\xF3n de un contexto dado:"),Et=c(),$(xa.$$.fragment),xt=c(),$(qa.$$.fragment),qt=c(),Ba=r("p"),vl=t("Observa que este pipeline funciona extrayendo informaci\xF3n del contexto ofrecido; m\xE1s no genera la respuesta."),wt=c(),re=r("h2"),Le=r("a"),so=r("span"),$(wa.$$.fragment),bl=c(),oo=r("span"),_l=t("Resumir (*Summarization*)"),jt=c(),Va=r("p"),El=t("Resumir es la tarea de reducir un texto en uno m\xE1s corto, conservando todos (o la mayor parte de) los aspectos importantes mencionados. Aqu\xED va un ejemplo:"),yt=c(),$(ja.$$.fragment),kt=c(),$(ya.$$.fragment),Pt=c(),W=r("p"),xl=t("Similar a la generaci\xF3n de textos, puedes especificar los argumentos "),to=r("code"),ql=t("max-length"),wl=t(" o "),no=r("code"),jl=t("min_length"),yl=t(" para definir la longitud del resultado."),At=c(),le=r("h2"),ze=r("a"),ro=r("span"),$(ka.$$.fragment),kl=c(),lo=r("span"),Pl=t("Traducci\xF3n"),It=c(),Y=r("p"),Al=t("Para la traducci\xF3n, puedes usar el modelo por defecto si indicas una pareja de idiomas en el nombre de la tarea (como "),io=r("code"),Il=t('"translation_en_to_fr"'),Tl=t("), pero la forma m\xE1s sencilla es escoger el modelo que quieres usar en el "),Pa=r("a"),Sl=t("Hub de Modelos"),Ol=t(". Aqu\xED intentaremos traducir de Franc\xE9s a Ingl\xE9s:"),Tt=c(),$(Aa.$$.fragment),St=c(),$(Ia.$$.fragment),Ot=c(),J=r("p"),Hl=t("Al igual que los pipelines de generaci\xF3n de textos y resumen, puedes especificar una longitud m\xE1xima ("),po=r("code"),Cl=t("max_length"),Ll=t(") o m\xEDnima ("),co=r("code"),zl=t("min_length"),Nl=t(") para el resultado."),Ht=c(),$(Ne.$$.fragment),Ct=c(),De=r("p"),Dl=t("Los pipelines vistos hasta el momento son principalmente para fines demostrativos. Fueron programados para tareas espec\xEDficas y no pueden desarrollar variaciones de ellas. En el siguiente cap\xEDtulo, aprender\xE1s qu\xE9 est\xE1 detr\xE1s de una funci\xF3n "),uo=r("code"),Rl=t("pipeline()"),Fl=t(" y c\xF3mo personalizar su comportamiento."),this.h()},l(e){const o=Cp('[data-svelte="svelte-1phssyn"]',document.head);d=l(o,"META",{name:!0,content:!0}),o.forEach(a),j=u(e),f=l(e,"H1",{class:!0});var Ta=i(f);q=l(Ta,"A",{id:!0,class:!0,href:!0});var mo=i(q);w=l(mo,"SPAN",{});var fo=i(w);v(h.$$.fragment,fo),fo.forEach(a),mo.forEach(a),g=u(Ta),y=l(Ta,"SPAN",{});var ho=i(y);A=n(ho,"Transformadores, \xBFqu\xE9 pueden hacer?"),ho.forEach(a),Ta.forEach(a),I=u(e),v(T.$$.fragment,e),P=u(e),k=l(e,"P",{});var Sa=i(k);D=n(Sa,"En esta secci\xF3n, veremos qu\xE9 pueden hacer los Transformadores y usaremos nuestra primera herramienta de la librer\xEDa \u{1F917} Transformers: la funci\xF3n "),C=l(Sa,"CODE",{});var go=i(C);S=n(go,"pipeline()"),go.forEach(a),Ha=n(Sa,"."),Sa.forEach(a),Me=u(e),v(G.$$.fragment,e),Ge=u(e),Z=l(e,"H2",{class:!0});var Oa=i(Z);ie=l(Oa,"A",{id:!0,class:!0,href:!0});var $o=i(ie);es=l($o,"SPAN",{});var Bl=i(es);v(Ue.$$.fragment,Bl),Bl.forEach(a),$o.forEach(a),rn=u(Oa),as=l(Oa,"SPAN",{});var Vl=i(as);ln=n(Vl,"\xA1Los Transformadores est\xE1n en todas partes!"),Vl.forEach(a),Oa.forEach(a),vo=u(e),Ca=l(e,"P",{});var Ql=i(Ca);pn=n(Ql,"Los Transformadores se usan para resolver todo tipo de tareas de PLN, como las mencionadas en la secci\xF3n anterior. Aqu\xED te mostramos algunas de las compa\xF1\xEDas y organizaciones que usan Hugging Face y Transformadores, que tambi\xE9n contribuyen de vuelta a la comunidad al compartir sus modelos:"),Ql.forEach(a),bo=u(e),pe=l(e,"IMG",{src:!0,alt:!0,width:!0}),_o=u(e),U=l(e,"P",{});var Qa=i(U);cn=n(Qa,"La "),Be=l(Qa,"A",{href:!0,rel:!0});var Wl=i(Be);un=n(Wl,"librer\xEDa \u{1F917} Transformers"),Wl.forEach(a),dn=n(Qa," provee la funcionalidad de crear y usar estos modelos compartidos. El "),Ve=l(Qa,"A",{href:!0,rel:!0});var Yl=i(Ve);mn=n(Yl,"Hub de Modelos"),Yl.forEach(a),fn=n(Qa," contiene miles de modelos preentrenados que cualquiera puede descargar y usar. \xA1T\xFA tambi\xE9n puedes subir tus propios modelos al Hub!"),Qa.forEach(a),Eo=u(e),v(ce.$$.fragment,e),xo=u(e),La=l(e,"P",{});var Jl=i(La);hn=n(Jl,"Antes de ver c\xF3mo funcionan internamente los Transformadores, veamos un par de ejemplos sobre c\xF3mo pueden ser usados para resolver tareas de PLN."),Jl.forEach(a),qo=u(e),K=l(e,"H2",{class:!0});var zt=i(K);ue=l(zt,"A",{id:!0,class:!0,href:!0});var Zl=i(ue);ss=l(Zl,"SPAN",{});var Kl=i(ss);v(Qe.$$.fragment,Kl),Kl.forEach(a),Zl.forEach(a),gn=u(zt),os=l(zt,"SPAN",{});var Xl=i(os);$n=n(Xl,"Trabajando con pipelines"),Xl.forEach(a),zt.forEach(a),wo=u(e),v(We.$$.fragment,e),jo=u(e),de=l(e,"P",{});var Nt=i(de);vn=n(Nt,"El objeto m\xE1s b\xE1sico en la librer\xEDa \u{1F917} Transformers es la funci\xF3n "),ts=l(Nt,"CODE",{});var ei=i(ts);bn=n(ei,"pipeline()"),ei.forEach(a),_n=n(Nt,". Esta funci\xF3n conecta un modelo con los pasos necesarios para su preprocesamiento y posprocesamiento, permiti\xE9ndonos introducir de manera directa cualquier texto y obtener una respuesta inteligible:"),Nt.forEach(a),yo=u(e),v(Ye.$$.fragment,e),ko=u(e),v(Je.$$.fragment,e),Po=u(e),za=l(e,"P",{});var ai=i(za);En=n(ai,"\xA1Incluso podemos pasar varias oraciones!"),ai.forEach(a),Ao=u(e),v(Ze.$$.fragment,e),Io=u(e),v(Ke.$$.fragment,e),To=u(e),me=l(e,"P",{});var Dt=i(me);xn=n(Dt,"Por defecto, este pipeline selecciona un modelo particular preentrenado que ha sido ajustado para el an\xE1lisis de sentimientos en Ingl\xE9s. El modelo se descarga y se almacena en el cach\xE9 cuando creas el objeto "),ns=l(Dt,"CODE",{});var si=i(ns);qn=n(si,"classifier"),si.forEach(a),wn=n(Dt,". Si vuelves a ejecutar el comando, se usar\xE1 el modelo almacenado en cach\xE9 y no habr\xE1 necesidad de descargarlo de nuevo."),Dt.forEach(a),So=u(e),Na=l(e,"P",{});var oi=i(Na);jn=n(oi,"Hay tres pasos principales que ocurren cuando pasas un texto a un pipeline:"),oi.forEach(a),Oo=u(e),B=l(e,"OL",{});var Wa=i(B);rs=l(Wa,"LI",{});var ti=i(rs);yn=n(ti,"El texto es preprocesado en un formato que el modelo puede entender."),ti.forEach(a),kn=u(Wa),ls=l(Wa,"LI",{});var ni=i(ls);Pn=n(ni,"La entrada preprocesada se pasa al modelo."),ni.forEach(a),An=u(Wa),is=l(Wa,"LI",{});var ri=i(is);In=n(ri,"Las predicciones del modelo son posprocesadas, de tal manera que las puedas entender."),ri.forEach(a),Wa.forEach(a),Ho=u(e),fe=l(e,"P",{});var Rt=i(fe);Tn=n(Rt,"Algunos de los "),Xe=l(Rt,"A",{href:!0,rel:!0});var li=i(Xe);Sn=n(li,"pipelines disponibles"),li.forEach(a),On=n(Rt," son:"),Rt.forEach(a),Co=u(e),O=l(e,"UL",{});var z=i(O);Da=l(z,"LI",{});var Ml=i(Da);ps=l(Ml,"CODE",{});var ii=i(ps);Hn=n(ii,"feature-extraction"),ii.forEach(a),Cn=n(Ml," (obtener la representaci\xF3n vectorial de un texto)"),Ml.forEach(a),Ln=u(z),cs=l(z,"LI",{});var pi=i(cs);us=l(pi,"CODE",{});var ci=i(us);zn=n(ci,"fill-mask"),ci.forEach(a),pi.forEach(a),Nn=u(z),Ra=l(z,"LI",{});var Gl=i(Ra);ds=l(Gl,"CODE",{});var ui=i(ds);Dn=n(ui,"ner"),ui.forEach(a),Rn=n(Gl," (reconocimiento de entidades nombradas)"),Gl.forEach(a),Fn=u(z),ms=l(z,"LI",{});var di=i(ms);fs=l(di,"CODE",{});var mi=i(fs);Mn=n(mi,"question-answering"),mi.forEach(a),di.forEach(a),Gn=u(z),hs=l(z,"LI",{});var fi=i(hs);gs=l(fi,"CODE",{});var hi=i(gs);Un=n(hi,"sentiment-analysis"),hi.forEach(a),fi.forEach(a),Bn=u(z),$s=l(z,"LI",{});var gi=i($s);vs=l(gi,"CODE",{});var $i=i(vs);Vn=n($i,"summarization"),$i.forEach(a),gi.forEach(a),Qn=u(z),bs=l(z,"LI",{});var vi=i(bs);_s=l(vi,"CODE",{});var bi=i(_s);Wn=n(bi,"text-generation"),bi.forEach(a),vi.forEach(a),Yn=u(z),Es=l(z,"LI",{});var _i=i(Es);xs=l(_i,"CODE",{});var Ei=i(xs);Jn=n(Ei,"translation"),Ei.forEach(a),_i.forEach(a),Zn=u(z),qs=l(z,"LI",{});var xi=i(qs);ws=l(xi,"CODE",{});var qi=i(ws);Kn=n(qi,"zero-shot-classification"),qi.forEach(a),xi.forEach(a),z.forEach(a),Lo=u(e),Fa=l(e,"P",{});var wi=i(Fa);Xn=n(wi,"\xA1Veamos algunas de ellas!"),wi.forEach(a),zo=u(e),X=l(e,"H2",{class:!0});var Ft=i(X);he=l(Ft,"A",{id:!0,class:!0,href:!0});var ji=i(he);js=l(ji,"SPAN",{});var yi=i(js);v(ea.$$.fragment,yi),yi.forEach(a),ji.forEach(a),er=u(Ft),ys=l(Ft,"SPAN",{});var ki=i(ys);ar=n(ki,"Clasificaci\xF3n *zero-shot*"),ki.forEach(a),Ft.forEach(a),No=u(e),ge=l(e,"P",{});var Mt=i(ge);sr=n(Mt,"Empezaremos abordando una tarea m\xE1s compleja, en la que necesitamos clasificar textos que no han sido etiquetados. Este es un escenario com\xFAn en proyectos de la vida real porque anotar texto usualmente requiere mucho tiempo y dominio del tema. Para este caso de uso, el pipeline "),ks=l(Mt,"CODE",{});var Pi=i(ks);or=n(Pi,"zero-shot-classification"),Pi.forEach(a),tr=n(Mt," es muy poderoso: permite que especifiques qu\xE9 etiquetas usar para la clasificaci\xF3n, para que no dependas de las etiquetas del modelo preentrenado. Ya viste c\xF3mo el modelo puede clasificar una oraci\xF3n como positiva o negativa usando esas dos etiquetas \u2014 pero tambi\xE9n puede clasificar el texto usando cualquier otro conjunto de etiquetas que definas."),Mt.forEach(a),Do=u(e),v(aa.$$.fragment,e),Ro=u(e),v(sa.$$.fragment,e),Fo=u(e),$e=l(e,"P",{});var Gt=i($e);nr=n(Gt,"Este pipeline se llama "),Ps=l(Gt,"EM",{});var Ai=i(Ps);rr=n(Ai,"zero-shot"),Ai.forEach(a),lr=n(Gt," porque no necesitas ajustar el modelo con tus datos para usarlo. \xA1Puede devolver directamente puntajes de probabilidad para cualquier lista de de etiquetas que escojas!"),Gt.forEach(a),Mo=u(e),v(ve.$$.fragment,e),Go=u(e),ee=l(e,"H2",{class:!0});var Ut=i(ee);be=l(Ut,"A",{id:!0,class:!0,href:!0});var Ii=i(be);As=l(Ii,"SPAN",{});var Ti=i(As);v(oa.$$.fragment,Ti),Ti.forEach(a),Ii.forEach(a),ir=u(Ut),Is=l(Ut,"SPAN",{});var Si=i(Is);pr=n(Si,"Generaci\xF3n de texto"),Si.forEach(a),Ut.forEach(a),Uo=u(e),_e=l(e,"P",{});var Bt=i(_e);cr=n(Bt,"Ahora veamos c\xF3mo usar un pipeline para generar texto. La idea es que proporciones una indicaci\xF3n ("),Ts=l(Bt,"EM",{});var Oi=i(Ts);ur=n(Oi,"prompt"),Oi.forEach(a),dr=n(Bt,") y el modelo la va a completar autom\xE1ticamente al generar el texto restante. Esto es parecido a la funci\xF3n de texto predictivo que est\xE1 presente en muchos tel\xE9fonos. La generaci\xF3n de texto involucra aleat\xF3riedad, por lo que es normal que no obtengas el mismo resultado que se muestra abajo."),Bt.forEach(a),Bo=u(e),v(ta.$$.fragment,e),Vo=u(e),v(na.$$.fragment,e),Qo=u(e),V=l(e,"P",{});var Ya=i(V);mr=n(Ya,"Puedes controlar cu\xE1ntas secuencias diferentes se generan con el argumento "),Ss=l(Ya,"CODE",{});var Hi=i(Ss);fr=n(Hi,"num_return_sequences"),Hi.forEach(a),hr=n(Ya," y la longitud total del texto de salida con el argumento "),Os=l(Ya,"CODE",{});var Ci=i(Os);gr=n(Ci,"max_length"),Ci.forEach(a),$r=n(Ya,"."),Ya.forEach(a),Wo=u(e),v(Ee.$$.fragment,e),Yo=u(e),ae=l(e,"H2",{class:!0});var Vt=i(ae);xe=l(Vt,"A",{id:!0,class:!0,href:!0});var Li=i(xe);Hs=l(Li,"SPAN",{});var zi=i(Hs);v(ra.$$.fragment,zi),zi.forEach(a),Li.forEach(a),vr=u(Vt),Cs=l(Vt,"SPAN",{});var Ni=i(Cs);br=n(Ni,"Usa cualquier modelo del Hub en un pipeline"),Ni.forEach(a),Vt.forEach(a),Jo=u(e),Q=l(e,"P",{});var Ja=i(Q);_r=n(Ja,"Los ejemplos anteriores usaban el modelo por defecto para cada tarea, pero tambi\xE9n puedes escoger un modelo particular del Hub y usarlo en un pipeline para una tarea espec\xEDfica - por ejemplo, la generaci\xF3n de texto. Ve al "),la=l(Ja,"A",{href:!0,rel:!0});var Di=i(la);Er=n(Di,"Hub de Modelos"),Di.forEach(a),xr=n(Ja," y haz clic en la etiqueta correspondiente en la parte izquierda para mostrar \xFAnicamente los modelos soportados para esa tarea. Deber\xEDas ver una p\xE1gina "),ia=l(Ja,"A",{href:!0,rel:!0});var Ri=i(ia);qr=n(Ri,"como esta"),Ri.forEach(a),wr=n(Ja,"."),Ja.forEach(a),Zo=u(e),qe=l(e,"P",{});var Qt=i(qe);jr=n(Qt,"\xA1Intentemos con el modelo "),pa=l(Qt,"A",{href:!0,rel:!0});var Fi=i(pa);Ls=l(Fi,"CODE",{});var Mi=i(Ls);yr=n(Mi,"distilgpt2"),Mi.forEach(a),Fi.forEach(a),kr=n(Qt,"! Puedes cargarlo en el mismo pipeline de la siguiente manera:"),Qt.forEach(a),Ko=u(e),v(ca.$$.fragment,e),Xo=u(e),v(ua.$$.fragment,e),et=u(e),we=l(e,"P",{});var Wt=i(we);Pr=n(Wt,"Puedes refinar tu b\xFAsqueda de un modelo haciendo clic en las etiquetas de idioma y escoger uno que genere textos en otro idioma. El Hub de Modelos tambi\xE9n contiene puntos de control ("),zs=l(Wt,"EM",{});var Gi=i(zs);Ar=n(Gi,"checkpoints"),Gi.forEach(a),Ir=n(Wt,") para modelos que soportan m\xFAltiples lenguajes."),Wt.forEach(a),at=u(e),Ma=l(e,"P",{});var Ui=i(Ma);Tr=n(Ui,"Una vez has seleccionado un modelo haciendo clic en \xE9l, ver\xE1s que hay un widget que te permite probarlo directamente en l\xEDnea. De esta manera puedes probar r\xE1pidamente las capacidades del modelo antes de descargarlo."),Ui.forEach(a),st=u(e),v(je.$$.fragment,e),ot=u(e),se=l(e,"H3",{class:!0});var Yt=i(se);ye=l(Yt,"A",{id:!0,class:!0,href:!0});var Bi=i(ye);Ns=l(Bi,"SPAN",{});var Vi=i(Ns);v(da.$$.fragment,Vi),Vi.forEach(a),Bi.forEach(a),Sr=u(Yt),Ds=l(Yt,"SPAN",{});var Qi=i(Ds);Or=n(Qi,"La API de Inferencia"),Qi.forEach(a),Yt.forEach(a),tt=u(e),ke=l(e,"P",{});var Jt=i(ke);Hr=n(Jt,"Todos los modelos pueden ser probados directamente en tu navegador usando la API de Inferencia, que est\xE1 disponible en el "),ma=l(Jt,"A",{href:!0,rel:!0});var Wi=i(ma);Cr=n(Wi,"sitio web"),Wi.forEach(a),Lr=n(Jt," de Hugging Face. Puedes jugar con el modelo directamente en esta p\xE1gina al pasar tu texto personalizado como entrada y ver c\xF3mo lo procesa."),Jt.forEach(a),nt=u(e),Pe=l(e,"P",{});var Zt=i(Pe);zr=n(Zt,"La API de Inferencia que hace funcionar al widget tambi\xE9n est\xE1 disponible como un producto pago, algo \xFAtil si lo necesitas para tus flujos de trabajo. Dir\xEDgete a la "),fa=l(Zt,"A",{href:!0,rel:!0});var Yi=i(fa);Nr=n(Yi,"p\xE1gina de precios"),Yi.forEach(a),Dr=n(Zt," para m\xE1s detalles."),Zt.forEach(a),rt=u(e),oe=l(e,"H2",{class:!0});var Kt=i(oe);Ae=l(Kt,"A",{id:!0,class:!0,href:!0});var Ji=i(Ae);Rs=l(Ji,"SPAN",{});var Zi=i(Rs);v(ha.$$.fragment,Zi),Zi.forEach(a),Ji.forEach(a),Rr=u(Kt),Fs=l(Kt,"SPAN",{});var Ki=i(Fs);Fr=n(Ki,"Llenado de ocultos (*Mask filling*)"),Ki.forEach(a),Kt.forEach(a),lt=u(e),Ie=l(e,"P",{});var Xt=i(Ie);Mr=n(Xt,"El siguiente pipeline con el que vas a trabajar es "),Ms=l(Xt,"CODE",{});var Xi=i(Ms);Gr=n(Xi,"fill-mask"),Xi.forEach(a),Ur=n(Xt,". La idea de esta tarea es llenar los espacios en blanco de un texto dado:"),Xt.forEach(a),it=u(e),v(ga.$$.fragment,e),pt=u(e),v($a.$$.fragment,e),ct=u(e),R=l(e,"P",{});var Re=i(R);Br=n(Re,"El argumento "),Gs=l(Re,"CODE",{});var ep=i(Gs);Vr=n(ep,"top_k"),ep.forEach(a),Qr=n(Re," controla el n\xFAmero de posibilidades que se van a mostrar. Nota que en este caso el modelo llena la palabra especial "),Us=l(Re,"CODE",{});var ap=i(Us);Wr=n(ap,"<mask>"),ap.forEach(a),Yr=n(Re,", que se denomina com\xFAnmente como "),Bs=l(Re,"EM",{});var sp=i(Bs);Jr=n(sp,"mask token"),sp.forEach(a),Zr=n(Re,". Otros modelos pueden tener diferentes tokens, por lo que es una buena idea verificar la palabra especial adecuada cuando est\xE9s explorando diferentes modelos. Una manera de confirmar es revisar la palabra usada en el widget."),Re.forEach(a),ut=u(e),v(Te.$$.fragment,e),dt=u(e),te=l(e,"H2",{class:!0});var en=i(te);Se=l(en,"A",{id:!0,class:!0,href:!0});var op=i(Se);Vs=l(op,"SPAN",{});var tp=i(Vs);v(va.$$.fragment,tp),tp.forEach(a),op.forEach(a),Kr=u(en),Qs=l(en,"SPAN",{});var np=i(Qs);Xr=n(np,"Reconocimiento de entidades nombradas"),np.forEach(a),en.forEach(a),mt=u(e),Ga=l(e,"P",{});var rp=i(Ga);el=n(rp,"El reconocimiento de entidades nombradas (REN) es una tarea en la que el modelo tiene que encontrar cu\xE1les partes del texto introducido corresponden a entidades como personas, ubicaciones u organizaciones. Veamos un ejemplo:"),rp.forEach(a),ft=u(e),v(ba.$$.fragment,e),ht=u(e),v(_a.$$.fragment,e),gt=u(e),Ua=l(e,"P",{});var lp=i(Ua);al=n(lp,"En este caso el modelo identific\xF3 correctamente que Sylvain es una persona (PER), Hugging Face una organizaci\xF3n (ORG) y Brooklyn una ubicaci\xF3n (LOC)."),lp.forEach(a),$t=u(e),N=l(e,"P",{});var F=i(N);sl=n(F,"Pasamos la opci\xF3n "),Ws=l(F,"CODE",{});var ip=i(Ws);ol=n(ip,"grouped_entities=True"),ip.forEach(a),tl=n(F," en la funci\xF3n de creaci\xF3n del pipeline para decirle que agrupe las partes de la oraci\xF3n que corresponden a la misma entidad: Aqu\xED el modelo agrup\xF3 correctamente \u201CHugging\u201D y \u201CFace\u201D como una sola organizaci\xF3n, a pesar de que su nombre est\xE1 compuesto de varias palabras. De hecho, como veremos en el siguente cap\xEDtulo, el preprocesamiento puede incluso dividir palabras en partes m\xE1s peque\xF1as. Por ejemplo, \u2018Sylvain\u2019 se separa en cuatro piezas: "),Ys=l(F,"CODE",{});var pp=i(Ys);nl=n(pp,"S"),pp.forEach(a),rl=n(F,", "),Js=l(F,"CODE",{});var cp=i(Js);ll=n(cp,"##yl"),cp.forEach(a),il=n(F,", "),Zs=l(F,"CODE",{});var up=i(Zs);pl=n(up,"##va"),up.forEach(a),cl=n(F," y"),Ks=l(F,"CODE",{});var dp=i(Ks);ul=n(dp,"##in"),dp.forEach(a),dl=n(F,". En el paso de prosprocesamiento, el pipeline reagrupa de manera exitosa dichas piezas."),F.forEach(a),vt=u(e),v(Oe.$$.fragment,e),bt=u(e),ne=l(e,"H2",{class:!0});var an=i(ne);He=l(an,"A",{id:!0,class:!0,href:!0});var mp=i(He);Xs=l(mp,"SPAN",{});var fp=i(Xs);v(Ea.$$.fragment,fp),fp.forEach(a),mp.forEach(a),ml=u(an),eo=l(an,"SPAN",{});var hp=i(eo);fl=n(hp,"Responder preguntas"),hp.forEach(a),an.forEach(a),_t=u(e),Ce=l(e,"P",{});var sn=i(Ce);hl=n(sn,"El pipeline "),ao=l(sn,"CODE",{});var gp=i(ao);gl=n(gp,"question-answering"),gp.forEach(a),$l=n(sn," responde preguntas usando informaci\xF3n de un contexto dado:"),sn.forEach(a),Et=u(e),v(xa.$$.fragment,e),xt=u(e),v(qa.$$.fragment,e),qt=u(e),Ba=l(e,"P",{});var $p=i(Ba);vl=n($p,"Observa que este pipeline funciona extrayendo informaci\xF3n del contexto ofrecido; m\xE1s no genera la respuesta."),$p.forEach(a),wt=u(e),re=l(e,"H2",{class:!0});var on=i(re);Le=l(on,"A",{id:!0,class:!0,href:!0});var vp=i(Le);so=l(vp,"SPAN",{});var bp=i(so);v(wa.$$.fragment,bp),bp.forEach(a),vp.forEach(a),bl=u(on),oo=l(on,"SPAN",{});var _p=i(oo);_l=n(_p,"Resumir (*Summarization*)"),_p.forEach(a),on.forEach(a),jt=u(e),Va=l(e,"P",{});var Ep=i(Va);El=n(Ep,"Resumir es la tarea de reducir un texto en uno m\xE1s corto, conservando todos (o la mayor parte de) los aspectos importantes mencionados. Aqu\xED va un ejemplo:"),Ep.forEach(a),yt=u(e),v(ja.$$.fragment,e),kt=u(e),v(ya.$$.fragment,e),Pt=u(e),W=l(e,"P",{});var Za=i(W);xl=n(Za,"Similar a la generaci\xF3n de textos, puedes especificar los argumentos "),to=l(Za,"CODE",{});var xp=i(to);ql=n(xp,"max-length"),xp.forEach(a),wl=n(Za," o "),no=l(Za,"CODE",{});var qp=i(no);jl=n(qp,"min_length"),qp.forEach(a),yl=n(Za," para definir la longitud del resultado."),Za.forEach(a),At=u(e),le=l(e,"H2",{class:!0});var tn=i(le);ze=l(tn,"A",{id:!0,class:!0,href:!0});var wp=i(ze);ro=l(wp,"SPAN",{});var jp=i(ro);v(ka.$$.fragment,jp),jp.forEach(a),wp.forEach(a),kl=u(tn),lo=l(tn,"SPAN",{});var yp=i(lo);Pl=n(yp,"Traducci\xF3n"),yp.forEach(a),tn.forEach(a),It=u(e),Y=l(e,"P",{});var Ka=i(Y);Al=n(Ka,"Para la traducci\xF3n, puedes usar el modelo por defecto si indicas una pareja de idiomas en el nombre de la tarea (como "),io=l(Ka,"CODE",{});var kp=i(io);Il=n(kp,'"translation_en_to_fr"'),kp.forEach(a),Tl=n(Ka,"), pero la forma m\xE1s sencilla es escoger el modelo que quieres usar en el "),Pa=l(Ka,"A",{href:!0,rel:!0});var Pp=i(Pa);Sl=n(Pp,"Hub de Modelos"),Pp.forEach(a),Ol=n(Ka,". Aqu\xED intentaremos traducir de Franc\xE9s a Ingl\xE9s:"),Ka.forEach(a),Tt=u(e),v(Aa.$$.fragment,e),St=u(e),v(Ia.$$.fragment,e),Ot=u(e),J=l(e,"P",{});var Xa=i(J);Hl=n(Xa,"Al igual que los pipelines de generaci\xF3n de textos y resumen, puedes especificar una longitud m\xE1xima ("),po=l(Xa,"CODE",{});var Ap=i(po);Cl=n(Ap,"max_length"),Ap.forEach(a),Ll=n(Xa,") o m\xEDnima ("),co=l(Xa,"CODE",{});var Ip=i(co);zl=n(Ip,"min_length"),Ip.forEach(a),Nl=n(Xa,") para el resultado."),Xa.forEach(a),Ht=u(e),v(Ne.$$.fragment,e),Ct=u(e),De=l(e,"P",{});var nn=i(De);Dl=n(nn,"Los pipelines vistos hasta el momento son principalmente para fines demostrativos. Fueron programados para tareas espec\xEDficas y no pueden desarrollar variaciones de ellas. En el siguiente cap\xEDtulo, aprender\xE1s qu\xE9 est\xE1 detr\xE1s de una funci\xF3n "),uo=l(nn,"CODE",{});var Tp=i(uo);Rl=n(Tp,"pipeline()"),Tp.forEach(a),Fl=n(nn," y c\xF3mo personalizar su comportamiento."),nn.forEach(a),this.h()},h(){m(d,"name","hf:doc:metadata"),m(d,"content",JSON.stringify(Yp)),m(q,"id","transformadores-qu-pueden-hacer"),m(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(q,"href","#transformadores-qu-pueden-hacer"),m(f,"class","relative group"),m(ie,"id","los-transformadores-estn-en-todas-partes"),m(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ie,"href","#los-transformadores-estn-en-todas-partes"),m(Z,"class","relative group"),Lp(pe.src,Ul="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/companies.PNG")||m(pe,"src",Ul),m(pe,"alt","Companies using Hugging Face"),m(pe,"width","100%"),m(Be,"href","https://github.com/huggingface/transformers"),m(Be,"rel","nofollow"),m(Ve,"href","https://huggingface.co/models"),m(Ve,"rel","nofollow"),m(ue,"id","trabajando-con-pipelines"),m(ue,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ue,"href","#trabajando-con-pipelines"),m(K,"class","relative group"),m(Xe,"href","https://huggingface.co/transformers/main_classes/pipelines.html"),m(Xe,"rel","nofollow"),m(he,"id","clasificacin-zeroshot"),m(he,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(he,"href","#clasificacin-zeroshot"),m(X,"class","relative group"),m(be,"id","generacin-de-texto"),m(be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(be,"href","#generacin-de-texto"),m(ee,"class","relative group"),m(xe,"id","usa-cualquier-modelo-del-hub-en-un-pipeline"),m(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(xe,"href","#usa-cualquier-modelo-del-hub-en-un-pipeline"),m(ae,"class","relative group"),m(la,"href","https://huggingface.co/models"),m(la,"rel","nofollow"),m(ia,"href","https://huggingface.co/models?pipeline_tag=text-generation"),m(ia,"rel","nofollow"),m(pa,"href","https://huggingface.co/distilgpt2"),m(pa,"rel","nofollow"),m(ye,"id","la-api-de-inferencia"),m(ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ye,"href","#la-api-de-inferencia"),m(se,"class","relative group"),m(ma,"href","https://huggingface.co/"),m(ma,"rel","nofollow"),m(fa,"href","https://huggingface.co/pricing"),m(fa,"rel","nofollow"),m(Ae,"id","llenado-de-ocultos-mask-filling"),m(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Ae,"href","#llenado-de-ocultos-mask-filling"),m(oe,"class","relative group"),m(Se,"id","reconocimiento-de-entidades-nombradas"),m(Se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Se,"href","#reconocimiento-de-entidades-nombradas"),m(te,"class","relative group"),m(He,"id","responder-preguntas"),m(He,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(He,"href","#responder-preguntas"),m(ne,"class","relative group"),m(Le,"id","resumir-summarization"),m(Le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(Le,"href","#resumir-summarization"),m(re,"class","relative group"),m(ze,"id","traduccin"),m(ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ze,"href","#traduccin"),m(le,"class","relative group"),m(Pa,"href","https://huggingface.co/models"),m(Pa,"rel","nofollow")},m(e,o){s(document.head,d),p(e,j,o),p(e,f,o),s(f,q),s(q,w),b(h,w,null),s(f,g),s(f,y),s(y,A),p(e,I,o),b(T,e,o),p(e,P,o),p(e,k,o),s(k,D),s(k,C),s(C,S),s(k,Ha),p(e,Me,o),b(G,e,o),p(e,Ge,o),p(e,Z,o),s(Z,ie),s(ie,es),b(Ue,es,null),s(Z,rn),s(Z,as),s(as,ln),p(e,vo,o),p(e,Ca,o),s(Ca,pn),p(e,bo,o),p(e,pe,o),p(e,_o,o),p(e,U,o),s(U,cn),s(U,Be),s(Be,un),s(U,dn),s(U,Ve),s(Ve,mn),s(U,fn),p(e,Eo,o),b(ce,e,o),p(e,xo,o),p(e,La,o),s(La,hn),p(e,qo,o),p(e,K,o),s(K,ue),s(ue,ss),b(Qe,ss,null),s(K,gn),s(K,os),s(os,$n),p(e,wo,o),b(We,e,o),p(e,jo,o),p(e,de,o),s(de,vn),s(de,ts),s(ts,bn),s(de,_n),p(e,yo,o),b(Ye,e,o),p(e,ko,o),b(Je,e,o),p(e,Po,o),p(e,za,o),s(za,En),p(e,Ao,o),b(Ze,e,o),p(e,Io,o),b(Ke,e,o),p(e,To,o),p(e,me,o),s(me,xn),s(me,ns),s(ns,qn),s(me,wn),p(e,So,o),p(e,Na,o),s(Na,jn),p(e,Oo,o),p(e,B,o),s(B,rs),s(rs,yn),s(B,kn),s(B,ls),s(ls,Pn),s(B,An),s(B,is),s(is,In),p(e,Ho,o),p(e,fe,o),s(fe,Tn),s(fe,Xe),s(Xe,Sn),s(fe,On),p(e,Co,o),p(e,O,o),s(O,Da),s(Da,ps),s(ps,Hn),s(Da,Cn),s(O,Ln),s(O,cs),s(cs,us),s(us,zn),s(O,Nn),s(O,Ra),s(Ra,ds),s(ds,Dn),s(Ra,Rn),s(O,Fn),s(O,ms),s(ms,fs),s(fs,Mn),s(O,Gn),s(O,hs),s(hs,gs),s(gs,Un),s(O,Bn),s(O,$s),s($s,vs),s(vs,Vn),s(O,Qn),s(O,bs),s(bs,_s),s(_s,Wn),s(O,Yn),s(O,Es),s(Es,xs),s(xs,Jn),s(O,Zn),s(O,qs),s(qs,ws),s(ws,Kn),p(e,Lo,o),p(e,Fa,o),s(Fa,Xn),p(e,zo,o),p(e,X,o),s(X,he),s(he,js),b(ea,js,null),s(X,er),s(X,ys),s(ys,ar),p(e,No,o),p(e,ge,o),s(ge,sr),s(ge,ks),s(ks,or),s(ge,tr),p(e,Do,o),b(aa,e,o),p(e,Ro,o),b(sa,e,o),p(e,Fo,o),p(e,$e,o),s($e,nr),s($e,Ps),s(Ps,rr),s($e,lr),p(e,Mo,o),b(ve,e,o),p(e,Go,o),p(e,ee,o),s(ee,be),s(be,As),b(oa,As,null),s(ee,ir),s(ee,Is),s(Is,pr),p(e,Uo,o),p(e,_e,o),s(_e,cr),s(_e,Ts),s(Ts,ur),s(_e,dr),p(e,Bo,o),b(ta,e,o),p(e,Vo,o),b(na,e,o),p(e,Qo,o),p(e,V,o),s(V,mr),s(V,Ss),s(Ss,fr),s(V,hr),s(V,Os),s(Os,gr),s(V,$r),p(e,Wo,o),b(Ee,e,o),p(e,Yo,o),p(e,ae,o),s(ae,xe),s(xe,Hs),b(ra,Hs,null),s(ae,vr),s(ae,Cs),s(Cs,br),p(e,Jo,o),p(e,Q,o),s(Q,_r),s(Q,la),s(la,Er),s(Q,xr),s(Q,ia),s(ia,qr),s(Q,wr),p(e,Zo,o),p(e,qe,o),s(qe,jr),s(qe,pa),s(pa,Ls),s(Ls,yr),s(qe,kr),p(e,Ko,o),b(ca,e,o),p(e,Xo,o),b(ua,e,o),p(e,et,o),p(e,we,o),s(we,Pr),s(we,zs),s(zs,Ar),s(we,Ir),p(e,at,o),p(e,Ma,o),s(Ma,Tr),p(e,st,o),b(je,e,o),p(e,ot,o),p(e,se,o),s(se,ye),s(ye,Ns),b(da,Ns,null),s(se,Sr),s(se,Ds),s(Ds,Or),p(e,tt,o),p(e,ke,o),s(ke,Hr),s(ke,ma),s(ma,Cr),s(ke,Lr),p(e,nt,o),p(e,Pe,o),s(Pe,zr),s(Pe,fa),s(fa,Nr),s(Pe,Dr),p(e,rt,o),p(e,oe,o),s(oe,Ae),s(Ae,Rs),b(ha,Rs,null),s(oe,Rr),s(oe,Fs),s(Fs,Fr),p(e,lt,o),p(e,Ie,o),s(Ie,Mr),s(Ie,Ms),s(Ms,Gr),s(Ie,Ur),p(e,it,o),b(ga,e,o),p(e,pt,o),b($a,e,o),p(e,ct,o),p(e,R,o),s(R,Br),s(R,Gs),s(Gs,Vr),s(R,Qr),s(R,Us),s(Us,Wr),s(R,Yr),s(R,Bs),s(Bs,Jr),s(R,Zr),p(e,ut,o),b(Te,e,o),p(e,dt,o),p(e,te,o),s(te,Se),s(Se,Vs),b(va,Vs,null),s(te,Kr),s(te,Qs),s(Qs,Xr),p(e,mt,o),p(e,Ga,o),s(Ga,el),p(e,ft,o),b(ba,e,o),p(e,ht,o),b(_a,e,o),p(e,gt,o),p(e,Ua,o),s(Ua,al),p(e,$t,o),p(e,N,o),s(N,sl),s(N,Ws),s(Ws,ol),s(N,tl),s(N,Ys),s(Ys,nl),s(N,rl),s(N,Js),s(Js,ll),s(N,il),s(N,Zs),s(Zs,pl),s(N,cl),s(N,Ks),s(Ks,ul),s(N,dl),p(e,vt,o),b(Oe,e,o),p(e,bt,o),p(e,ne,o),s(ne,He),s(He,Xs),b(Ea,Xs,null),s(ne,ml),s(ne,eo),s(eo,fl),p(e,_t,o),p(e,Ce,o),s(Ce,hl),s(Ce,ao),s(ao,gl),s(Ce,$l),p(e,Et,o),b(xa,e,o),p(e,xt,o),b(qa,e,o),p(e,qt,o),p(e,Ba,o),s(Ba,vl),p(e,wt,o),p(e,re,o),s(re,Le),s(Le,so),b(wa,so,null),s(re,bl),s(re,oo),s(oo,_l),p(e,jt,o),p(e,Va,o),s(Va,El),p(e,yt,o),b(ja,e,o),p(e,kt,o),b(ya,e,o),p(e,Pt,o),p(e,W,o),s(W,xl),s(W,to),s(to,ql),s(W,wl),s(W,no),s(no,jl),s(W,yl),p(e,At,o),p(e,le,o),s(le,ze),s(ze,ro),b(ka,ro,null),s(le,kl),s(le,lo),s(lo,Pl),p(e,It,o),p(e,Y,o),s(Y,Al),s(Y,io),s(io,Il),s(Y,Tl),s(Y,Pa),s(Pa,Sl),s(Y,Ol),p(e,Tt,o),b(Aa,e,o),p(e,St,o),b(Ia,e,o),p(e,Ot,o),p(e,J,o),s(J,Hl),s(J,po),s(po,Cl),s(J,Ll),s(J,co),s(co,zl),s(J,Nl),p(e,Ht,o),b(Ne,e,o),p(e,Ct,o),p(e,De,o),s(De,Dl),s(De,uo),s(uo,Rl),s(De,Fl),Lt=!0},p(e,[o]){const Ta={};o&2&&(Ta.$$scope={dirty:o,ctx:e}),G.$set(Ta);const mo={};o&2&&(mo.$$scope={dirty:o,ctx:e}),ce.$set(mo);const fo={};o&2&&(fo.$$scope={dirty:o,ctx:e}),ve.$set(fo);const ho={};o&2&&(ho.$$scope={dirty:o,ctx:e}),Ee.$set(ho);const Sa={};o&2&&(Sa.$$scope={dirty:o,ctx:e}),je.$set(Sa);const go={};o&2&&(go.$$scope={dirty:o,ctx:e}),Te.$set(go);const Oa={};o&2&&(Oa.$$scope={dirty:o,ctx:e}),Oe.$set(Oa);const $o={};o&2&&($o.$$scope={dirty:o,ctx:e}),Ne.$set($o)},i(e){Lt||(_(h.$$.fragment,e),_(T.$$.fragment,e),_(G.$$.fragment,e),_(Ue.$$.fragment,e),_(ce.$$.fragment,e),_(Qe.$$.fragment,e),_(We.$$.fragment,e),_(Ye.$$.fragment,e),_(Je.$$.fragment,e),_(Ze.$$.fragment,e),_(Ke.$$.fragment,e),_(ea.$$.fragment,e),_(aa.$$.fragment,e),_(sa.$$.fragment,e),_(ve.$$.fragment,e),_(oa.$$.fragment,e),_(ta.$$.fragment,e),_(na.$$.fragment,e),_(Ee.$$.fragment,e),_(ra.$$.fragment,e),_(ca.$$.fragment,e),_(ua.$$.fragment,e),_(je.$$.fragment,e),_(da.$$.fragment,e),_(ha.$$.fragment,e),_(ga.$$.fragment,e),_($a.$$.fragment,e),_(Te.$$.fragment,e),_(va.$$.fragment,e),_(ba.$$.fragment,e),_(_a.$$.fragment,e),_(Oe.$$.fragment,e),_(Ea.$$.fragment,e),_(xa.$$.fragment,e),_(qa.$$.fragment,e),_(wa.$$.fragment,e),_(ja.$$.fragment,e),_(ya.$$.fragment,e),_(ka.$$.fragment,e),_(Aa.$$.fragment,e),_(Ia.$$.fragment,e),_(Ne.$$.fragment,e),Lt=!0)},o(e){E(h.$$.fragment,e),E(T.$$.fragment,e),E(G.$$.fragment,e),E(Ue.$$.fragment,e),E(ce.$$.fragment,e),E(Qe.$$.fragment,e),E(We.$$.fragment,e),E(Ye.$$.fragment,e),E(Je.$$.fragment,e),E(Ze.$$.fragment,e),E(Ke.$$.fragment,e),E(ea.$$.fragment,e),E(aa.$$.fragment,e),E(sa.$$.fragment,e),E(ve.$$.fragment,e),E(oa.$$.fragment,e),E(ta.$$.fragment,e),E(na.$$.fragment,e),E(Ee.$$.fragment,e),E(ra.$$.fragment,e),E(ca.$$.fragment,e),E(ua.$$.fragment,e),E(je.$$.fragment,e),E(da.$$.fragment,e),E(ha.$$.fragment,e),E(ga.$$.fragment,e),E($a.$$.fragment,e),E(Te.$$.fragment,e),E(va.$$.fragment,e),E(ba.$$.fragment,e),E(_a.$$.fragment,e),E(Oe.$$.fragment,e),E(Ea.$$.fragment,e),E(xa.$$.fragment,e),E(qa.$$.fragment,e),E(wa.$$.fragment,e),E(ja.$$.fragment,e),E(ya.$$.fragment,e),E(ka.$$.fragment,e),E(Aa.$$.fragment,e),E(Ia.$$.fragment,e),E(Ne.$$.fragment,e),Lt=!1},d(e){a(d),e&&a(j),e&&a(f),x(h),e&&a(I),x(T,e),e&&a(P),e&&a(k),e&&a(Me),x(G,e),e&&a(Ge),e&&a(Z),x(Ue),e&&a(vo),e&&a(Ca),e&&a(bo),e&&a(pe),e&&a(_o),e&&a(U),e&&a(Eo),x(ce,e),e&&a(xo),e&&a(La),e&&a(qo),e&&a(K),x(Qe),e&&a(wo),x(We,e),e&&a(jo),e&&a(de),e&&a(yo),x(Ye,e),e&&a(ko),x(Je,e),e&&a(Po),e&&a(za),e&&a(Ao),x(Ze,e),e&&a(Io),x(Ke,e),e&&a(To),e&&a(me),e&&a(So),e&&a(Na),e&&a(Oo),e&&a(B),e&&a(Ho),e&&a(fe),e&&a(Co),e&&a(O),e&&a(Lo),e&&a(Fa),e&&a(zo),e&&a(X),x(ea),e&&a(No),e&&a(ge),e&&a(Do),x(aa,e),e&&a(Ro),x(sa,e),e&&a(Fo),e&&a($e),e&&a(Mo),x(ve,e),e&&a(Go),e&&a(ee),x(oa),e&&a(Uo),e&&a(_e),e&&a(Bo),x(ta,e),e&&a(Vo),x(na,e),e&&a(Qo),e&&a(V),e&&a(Wo),x(Ee,e),e&&a(Yo),e&&a(ae),x(ra),e&&a(Jo),e&&a(Q),e&&a(Zo),e&&a(qe),e&&a(Ko),x(ca,e),e&&a(Xo),x(ua,e),e&&a(et),e&&a(we),e&&a(at),e&&a(Ma),e&&a(st),x(je,e),e&&a(ot),e&&a(se),x(da),e&&a(tt),e&&a(ke),e&&a(nt),e&&a(Pe),e&&a(rt),e&&a(oe),x(ha),e&&a(lt),e&&a(Ie),e&&a(it),x(ga,e),e&&a(pt),x($a,e),e&&a(ct),e&&a(R),e&&a(ut),x(Te,e),e&&a(dt),e&&a(te),x(va),e&&a(mt),e&&a(Ga),e&&a(ft),x(ba,e),e&&a(ht),x(_a,e),e&&a(gt),e&&a(Ua),e&&a($t),e&&a(N),e&&a(vt),x(Oe,e),e&&a(bt),e&&a(ne),x(Ea),e&&a(_t),e&&a(Ce),e&&a(Et),x(xa,e),e&&a(xt),x(qa,e),e&&a(qt),e&&a(Ba),e&&a(wt),e&&a(re),x(wa),e&&a(jt),e&&a(Va),e&&a(yt),x(ja,e),e&&a(kt),x(ya,e),e&&a(Pt),e&&a(W),e&&a(At),e&&a(le),x(ka),e&&a(It),e&&a(Y),e&&a(Tt),x(Aa,e),e&&a(St),x(Ia,e),e&&a(Ot),e&&a(J),e&&a(Ht),x(Ne,e),e&&a(Ct),e&&a(De)}}}const Yp={local:"transformadores-qu-pueden-hacer",sections:[{local:"los-transformadores-estn-en-todas-partes",title:"\xA1Los Transformadores est\xE1n en todas partes!"},{local:"trabajando-con-pipelines",title:"Trabajando con pipelines"},{local:"clasificacin-zeroshot",title:"Clasificaci\xF3n *zero-shot*"},{local:"generacin-de-texto",title:"Generaci\xF3n de texto"},{local:"usa-cualquier-modelo-del-hub-en-un-pipeline",sections:[{local:"la-api-de-inferencia",title:"La API de Inferencia"}],title:"Usa cualquier modelo del Hub en un pipeline"},{local:"llenado-de-ocultos-mask-filling",title:"Llenado de ocultos (*Mask filling*)"},{local:"reconocimiento-de-entidades-nombradas",title:"Reconocimiento de entidades nombradas"},{local:"responder-preguntas",title:"Responder preguntas"},{local:"resumir-summarization",title:"Resumir (*Summarization*)"},{local:"traduccin",title:"Traducci\xF3n"}],title:"Transformadores, \xBFqu\xE9 pueden hacer?"};function Jp(L){return zp(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class oc extends Sp{constructor(d){super();Op(this,d,Jp,Wp,Hp,{})}}export{oc as default,Yp as metadata};
