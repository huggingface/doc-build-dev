import{S as Ls,i as Ys,s as Ks,e as d,k as _,w as A,t as i,M as Qs,c as m,d as a,m as h,x as M,a as u,h as l,b as j,G as s,g as c,y as O,o as b,p as Ie,q as $,B as P,v as Ws,n as Re}from"../../chunks/vendor-hf-doc-builder.js";import{Y as Gs}from"../../chunks/Youtube-hf-doc-builder.js";import{I as vo}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as D}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as Js}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as Xs}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function Zs(k){let r,n;return r=new Js({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter2/section3_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter2/section3_tf.ipynb"}]}}),{c(){A(r.$$.fragment)},l(o){M(r.$$.fragment,o)},m(o,f){O(r,o,f),n=!0},i(o){n||($(r.$$.fragment,o),n=!0)},o(o){b(r.$$.fragment,o),n=!1},d(o){P(r,o)}}}function et(k){let r,n;return r=new Js({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter2/section3_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter2/section3_pt.ipynb"}]}}),{c(){A(r.$$.fragment)},l(o){M(r.$$.fragment,o)},m(o,f){O(r,o,f),n=!0},i(o){n||($(r.$$.fragment,o),n=!0)},o(o){b(r.$$.fragment,o),n=!1},d(o){P(r,o)}}}function ot(k){let r,n;return r=new Gs({props:{id:"d3JVgghSOew"}}),{c(){A(r.$$.fragment)},l(o){M(r.$$.fragment,o)},m(o,f){O(r,o,f),n=!0},i(o){n||($(r.$$.fragment,o),n=!0)},o(o){b(r.$$.fragment,o),n=!1},d(o){P(r,o)}}}function at(k){let r,n;return r=new Gs({props:{id:"AhChOFRegn4"}}),{c(){A(r.$$.fragment)},l(o){M(r.$$.fragment,o)},m(o,f){O(r,o,f),n=!0},i(o){n||($(r.$$.fragment,o),n=!0)},o(o){b(r.$$.fragment,o),n=!1},d(o){P(r,o)}}}function rt(k){let r,n,o,f,w,E,q,z,y,g,C;return{c(){r=d("p"),n=i("Nesta se\xE7\xE3o, vamos analisar mais de perto a cria\xE7\xE3o e a utiliza\xE7\xE3o de um modelo. Vamos utilizar a classe "),o=d("code"),f=i("TFAutoModel"),w=i(", que \xE9 \xFAtil quando voc\xEA quer instanciar qualquer modelo a partir de um checkpoint."),E=_(),q=d("p"),z=i("A classe "),y=d("code"),g=i("TFAutoModel"),C=i(" e todas as classes filhas s\xE3o na verdade simples  wrapper sobre a grande variedade de modelos dispon\xEDveis na biblioteca. \xC9 um wrapper inteligente, pois pode automaticamente \u201Cadivinhar\u201D a arquitetura apropriada do modelo para seu checkpoint, e ent\xE3o instancia um modelo com esta arquitetura.")},l(p){r=m(p,"P",{});var v=u(r);n=l(v,"Nesta se\xE7\xE3o, vamos analisar mais de perto a cria\xE7\xE3o e a utiliza\xE7\xE3o de um modelo. Vamos utilizar a classe "),o=m(v,"CODE",{});var T=u(o);f=l(T,"TFAutoModel"),T.forEach(a),w=l(v,", que \xE9 \xFAtil quando voc\xEA quer instanciar qualquer modelo a partir de um checkpoint."),v.forEach(a),E=h(p),q=m(p,"P",{});var B=u(q);z=l(B,"A classe "),y=m(B,"CODE",{});var N=u(y);g=l(N,"TFAutoModel"),N.forEach(a),C=l(B," e todas as classes filhas s\xE3o na verdade simples  wrapper sobre a grande variedade de modelos dispon\xEDveis na biblioteca. \xC9 um wrapper inteligente, pois pode automaticamente \u201Cadivinhar\u201D a arquitetura apropriada do modelo para seu checkpoint, e ent\xE3o instancia um modelo com esta arquitetura."),B.forEach(a)},m(p,v){c(p,r,v),s(r,n),s(r,o),s(o,f),s(r,w),c(p,E,v),c(p,q,v),s(q,z),s(q,y),s(y,g),s(q,C)},d(p){p&&a(r),p&&a(E),p&&a(q)}}}function st(k){let r,n,o,f,w,E,q,z,y,g,C;return{c(){r=d("p"),n=i("Nesta se\xE7\xE3o, vamos analisar mais de perto a cria\xE7\xE3o e a utiliza\xE7\xE3o de um modelo. Vamos utilizar a classe "),o=d("code"),f=i("AutoModel"),w=i(", que \xE9 \xFAtil quando voc\xEA quer instanciar qualquer modelo a partir de um checkpoint."),E=_(),q=d("p"),z=i("A classe "),y=d("code"),g=i("AutoModel"),C=i(" e todas as classes filhas s\xE3o na verdade simples wrapper sobre a grande variedade de modelos dispon\xEDveis na biblioteca. \xC9 um wrapper inteligente, pois pode automaticamente \u201Cadivinhar\u201D a arquitetura apropriada do modelo para seu checkpoint, e ent\xE3o instancia um modelo com esta arquitetura.")},l(p){r=m(p,"P",{});var v=u(r);n=l(v,"Nesta se\xE7\xE3o, vamos analisar mais de perto a cria\xE7\xE3o e a utiliza\xE7\xE3o de um modelo. Vamos utilizar a classe "),o=m(v,"CODE",{});var T=u(o);f=l(T,"AutoModel"),T.forEach(a),w=l(v,", que \xE9 \xFAtil quando voc\xEA quer instanciar qualquer modelo a partir de um checkpoint."),v.forEach(a),E=h(p),q=m(p,"P",{});var B=u(q);z=l(B,"A classe "),y=m(B,"CODE",{});var N=u(y);g=l(N,"AutoModel"),N.forEach(a),C=l(B," e todas as classes filhas s\xE3o na verdade simples wrapper sobre a grande variedade de modelos dispon\xEDveis na biblioteca. \xC9 um wrapper inteligente, pois pode automaticamente \u201Cadivinhar\u201D a arquitetura apropriada do modelo para seu checkpoint, e ent\xE3o instancia um modelo com esta arquitetura."),B.forEach(a)},m(p,v){c(p,r,v),s(r,n),s(r,o),s(o,f),s(r,w),c(p,E,v),c(p,q,v),s(q,z),s(q,y),s(y,g),s(q,C)},d(p){p&&a(r),p&&a(E),p&&a(q)}}}function tt(k){let r,n;return r=new D({props:{code:`
`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, TFBertModel

<span class="hljs-comment"># Construindo a configura\xE7\xE3o</span>
config = BertConfig()

<span class="hljs-comment"># Construindo o modelo a partir da configura\xE7\xE3o</span>
model = TFBertModel(config)`}}),{c(){A(r.$$.fragment)},l(o){M(r.$$.fragment,o)},m(o,f){O(r,o,f),n=!0},i(o){n||($(r.$$.fragment,o),n=!0)},o(o){b(r.$$.fragment,o),n=!1},d(o){P(r,o)}}}function it(k){let r,n;return r=new D({props:{code:`
`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, BertModel

<span class="hljs-comment"># Construindo a configura\xE7\xE3o</span>
config = BertConfig()

<span class="hljs-comment"># Construindo o modelo a partir da configura\xE7\xE3o</span>
model = BertModel(config)`}}),{c(){A(r.$$.fragment)},l(o){M(r.$$.fragment,o)},m(o,f){O(r,o,f),n=!0},i(o){n||($(r.$$.fragment,o),n=!0)},o(o){b(r.$$.fragment,o),n=!1},d(o){P(r,o)}}}function lt(k){let r,n;return r=new D({props:{code:`
`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, TFBertModel

config = BertConfig()
model = TFBertModel(config)

<span class="hljs-comment"># O modelo \xE9 inicializado aleatoriamente!</span>`}}),{c(){A(r.$$.fragment)},l(o){M(r.$$.fragment,o)},m(o,f){O(r,o,f),n=!0},i(o){n||($(r.$$.fragment,o),n=!0)},o(o){b(r.$$.fragment,o),n=!1},d(o){P(r,o)}}}function nt(k){let r,n;return r=new D({props:{code:`
`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertConfig, BertModel

config = BertConfig()
model = BertModel(config)

<span class="hljs-comment"># O modelo \xE9 inicializado aleatoriamente!</span>`}}),{c(){A(r.$$.fragment)},l(o){M(r.$$.fragment,o)},m(o,f){O(r,o,f),n=!0},i(o){n||($(r.$$.fragment,o),n=!0)},o(o){b(r.$$.fragment,o),n=!1},d(o){P(r,o)}}}function dt(k){let r,n,o,f,w,E,q,z,y,g,C;return r=new D({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFBertModel

model = TFBertModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)`}}),{c(){A(r.$$.fragment),n=_(),o=d("p"),f=i("Como voc\xEA viu anteriormente, poder\xEDamos substituir o "),w=d("code"),E=i("TFBertModel"),q=i(" pela classe equivalente ao "),z=d("code"),y=i("TFAutoModel"),g=i(". Faremos isto de agora em diante, pois isto produz um c\xF3digo generalista a partir de um checkpoint; se seu c\xF3digo funciona para checkpoint, ele deve funcionar perfeitamente com outro. Isto se aplica mesmo que a arquitetura seja diferente, desde que o checkpoint tenha sido treinado para uma tarefa semelhante (por exemplo, uma tarefa de an\xE1lise de sentimento).")},l(p){M(r.$$.fragment,p),n=h(p),o=m(p,"P",{});var v=u(o);f=l(v,"Como voc\xEA viu anteriormente, poder\xEDamos substituir o "),w=m(v,"CODE",{});var T=u(w);E=l(T,"TFBertModel"),T.forEach(a),q=l(v," pela classe equivalente ao "),z=m(v,"CODE",{});var B=u(z);y=l(B,"TFAutoModel"),B.forEach(a),g=l(v,". Faremos isto de agora em diante, pois isto produz um c\xF3digo generalista a partir de um checkpoint; se seu c\xF3digo funciona para checkpoint, ele deve funcionar perfeitamente com outro. Isto se aplica mesmo que a arquitetura seja diferente, desde que o checkpoint tenha sido treinado para uma tarefa semelhante (por exemplo, uma tarefa de an\xE1lise de sentimento)."),v.forEach(a)},m(p,v){O(r,p,v),c(p,n,v),c(p,o,v),s(o,f),s(o,w),s(w,E),s(o,q),s(o,z),s(z,y),s(o,g),C=!0},i(p){C||($(r.$$.fragment,p),C=!0)},o(p){b(r.$$.fragment,p),C=!1},d(p){P(r,p),p&&a(n),p&&a(o)}}}function mt(k){let r,n,o,f,w,E,q,z,y,g,C;return r=new D({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertModel

model = BertModel.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)`}}),{c(){A(r.$$.fragment),n=_(),o=d("p"),f=i("Como voc\xEA viu anteriormente, poder\xEDamos substituir o "),w=d("code"),E=i("BertModel"),q=i(" pela classe equivalente ao "),z=d("code"),y=i("AutoModel"),g=i(". Faremos isto de agora em diante, pois isto produz um c\xF3digo generalista a partir de um checkpoint; se seu c\xF3digo funciona para checkpoint, ele deve funcionar perfeitamente com outro. Isto se aplica mesmo que a arquitetura seja diferente, desde que o checkpoint tenha sido treinado para uma tarefa semelhante (por exemplo, uma tarefa de an\xE1lise de sentimento).")},l(p){M(r.$$.fragment,p),n=h(p),o=m(p,"P",{});var v=u(o);f=l(v,"Como voc\xEA viu anteriormente, poder\xEDamos substituir o "),w=m(v,"CODE",{});var T=u(w);E=l(T,"BertModel"),T.forEach(a),q=l(v," pela classe equivalente ao "),z=m(v,"CODE",{});var B=u(z);y=l(B,"AutoModel"),B.forEach(a),g=l(v,". Faremos isto de agora em diante, pois isto produz um c\xF3digo generalista a partir de um checkpoint; se seu c\xF3digo funciona para checkpoint, ele deve funcionar perfeitamente com outro. Isto se aplica mesmo que a arquitetura seja diferente, desde que o checkpoint tenha sido treinado para uma tarefa semelhante (por exemplo, uma tarefa de an\xE1lise de sentimento)."),v.forEach(a)},m(p,v){O(r,p,v),c(p,n,v),c(p,o,v),s(o,f),s(o,w),s(w,E),s(o,q),s(o,z),s(z,y),s(o,g),C=!0},i(p){C||($(r.$$.fragment,p),C=!0)},o(p){b(r.$$.fragment,p),C=!1},d(p){P(r,p),p&&a(n),p&&a(o)}}}function ct(k){let r,n;return r=new D({props:{code:"",highlighted:`ls path_no_seu_computador

<span class="hljs-built_in">config</span>.<span class="hljs-keyword">json </span>tf_model.h5`}}),{c(){A(r.$$.fragment)},l(o){M(r.$$.fragment,o)},m(o,f){O(r,o,f),n=!0},i(o){n||($(r.$$.fragment,o),n=!0)},o(o){b(r.$$.fragment,o),n=!1},d(o){P(r,o)}}}function ut(k){let r,n;return r=new D({props:{code:"",highlighted:`ls path_no_seu_computador

<span class="hljs-built_in">config</span>.<span class="hljs-keyword">json </span>pytorch_model.<span class="hljs-keyword">bin</span>`}}),{c(){A(r.$$.fragment)},l(o){M(r.$$.fragment,o)},m(o,f){O(r,o,f),n=!0},i(o){n||($(r.$$.fragment,o),n=!0)},o(o){b(r.$$.fragment,o),n=!1},d(o){P(r,o)}}}function pt(k){let r,n,o,f,w,E,q,z;return{c(){r=d("p"),n=i("O arquivo "),o=d("em"),f=i("tf_model.h5"),w=i(" \xE9 conhecido como o "),E=d("em"),q=i("dicion\xE1rio de estado"),z=i("; ele cont\xE9m todos os pesos do seu modelo. Os dois arquivos andam de m\xE3os dadas; a configura\xE7\xE3o \xE9 necess\xE1ria para conhecer a arquitetura de seu modelo, enquanto os pesos do modelo s\xE3o os par\xE2metros de seu modelo.")},l(y){r=m(y,"P",{});var g=u(r);n=l(g,"O arquivo "),o=m(g,"EM",{});var C=u(o);f=l(C,"tf_model.h5"),C.forEach(a),w=l(g," \xE9 conhecido como o "),E=m(g,"EM",{});var p=u(E);q=l(p,"dicion\xE1rio de estado"),p.forEach(a),z=l(g,"; ele cont\xE9m todos os pesos do seu modelo. Os dois arquivos andam de m\xE3os dadas; a configura\xE7\xE3o \xE9 necess\xE1ria para conhecer a arquitetura de seu modelo, enquanto os pesos do modelo s\xE3o os par\xE2metros de seu modelo."),g.forEach(a)},m(y,g){c(y,r,g),s(r,n),s(r,o),s(o,f),s(r,w),s(r,E),s(E,q),s(r,z)},d(y){y&&a(r)}}}function ft(k){let r,n,o,f,w,E,q,z;return{c(){r=d("p"),n=i("O arquivo "),o=d("em"),f=i("pytorch_model.bin"),w=i(" \xE9 conhecido como o "),E=d("em"),q=i("dicion\xE1rio de estado"),z=i("; ele cont\xE9m todos os pesos do seu modelo. Os dois arquivos andam de m\xE3os dadas; a configura\xE7\xE3o \xE9 necess\xE1ria para conhecer a arquitetura de seu modelo, enquanto os pesos do modelo s\xE3o os par\xE2metros de seu modelo.")},l(y){r=m(y,"P",{});var g=u(r);n=l(g,"O arquivo "),o=m(g,"EM",{});var C=u(o);f=l(C,"pytorch_model.bin"),C.forEach(a),w=l(g," \xE9 conhecido como o "),E=m(g,"EM",{});var p=u(E);q=l(p,"dicion\xE1rio de estado"),p.forEach(a),z=l(g,"; ele cont\xE9m todos os pesos do seu modelo. Os dois arquivos andam de m\xE3os dadas; a configura\xE7\xE3o \xE9 necess\xE1ria para conhecer a arquitetura de seu modelo, enquanto os pesos do modelo s\xE3o os par\xE2metros de seu modelo."),g.forEach(a)},m(y,g){c(y,r,g),s(r,n),s(r,o),s(o,f),s(r,w),s(r,E),s(E,q),s(r,z)},d(y){y&&a(r)}}}function _t(k){let r,n;return r=new D({props:{code:"",highlighted:`<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

model_inputs = tf.constant(encoded_sequences)`}}),{c(){A(r.$$.fragment)},l(o){M(r.$$.fragment,o)},m(o,f){O(r,o,f),n=!0},i(o){n||($(r.$$.fragment,o),n=!0)},o(o){b(r.$$.fragment,o),n=!1},d(o){P(r,o)}}}function ht(k){let r,n;return r=new D({props:{code:"",highlighted:`<span class="hljs-keyword">import</span> torch

model_inputs = torch.tensor(encoded_sequences)`}}),{c(){A(r.$$.fragment)},l(o){M(r.$$.fragment,o)},m(o,f){O(r,o,f),n=!0},i(o){n||($(r.$$.fragment,o),n=!0)},o(o){b(r.$$.fragment,o),n=!1},d(o){P(r,o)}}}function vt(k){let r,n,o,f,w,E,q,z,y,g,C,p,v,T,B,N,H,Ve,Ue,Ge,Pa,Ro,X,te,bo,ke,Ta,$o,Ba,Vo,Je,Na,Uo,I,R,Le,Ye,Da,Go,qe,Jo,ge,Lo,x,xa,ko,Fa,Sa,qo,Ha,Ia,go,Ra,Va,Yo,Z,ie,Eo,Ee,Ua,wo,Ga,Ko,Ke,Ja,Qo,V,U,Qe,le,La,We,Ya,Ka,Wo,ne,Qa,zo,Wa,Xa,Xo,G,J,Xe,F,Za,yo,er,or,jo,ar,rr,we,sr,tr,Zo,de,ir,Co,lr,nr,ea,S,dr,Ao,mr,cr,Mo,ur,pr,Oo,fr,_r,oa,me,hr,ze,vr,br,aa,ee,ce,Po,ye,$r,To,kr,ra,W,qr,Bo,gr,Er,No,wr,zr,sa,je,ta,Ze,yr,ia,L,Y,eo,ue,jr,Do,Cr,Ar,la,oo,oe,pe,xo,Ce,Mr,Fo,Or,na,ao,Pr,da,ro,Tr,ma,so,Br,ca,Ae,ua,fe,Nr,So,Dr,xr,pa,Me,fa,to,Fr,_a,K,Q,io,ae,_e,Ho,Oe,Sr,Io,Hr,ha,lo,Ir,va,Pe,ba,no,Rr,$a;o=new Xs({props:{fw:k[0]}}),z=new vo({});const Vr=[et,Zs],Te=[];function Ur(e,t){return e[0]==="pt"?0:1}v=Ur(k),T=Te[v]=Vr[v](k);const Gr=[at,ot],Be=[];function Jr(e,t){return e[0]==="pt"?0:1}N=Jr(k),H=Be[N]=Gr[N](k);function Lr(e,t){return e[0]==="pt"?st:rt}let ka=Lr(k),re=ka(k);ke=new vo({});const Yr=[it,tt],Ne=[];function Kr(e,t){return e[0]==="pt"?0:1}I=Kr(k),R=Ne[I]=Yr[I](k),qe=new D({props:{code:"print(config)",highlighted:'<span class="hljs-built_in">print</span>(config)'}}),ge=new D({props:{code:`BertConfig {
  [...]
  "hidden_size": 768,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  [...]
}`,highlighted:`BertConfig {
  [...]
  <span class="hljs-string">&quot;hidden_size&quot;</span>: <span class="hljs-number">768</span>,
  <span class="hljs-string">&quot;intermediate_size&quot;</span>: <span class="hljs-number">3072</span>,
  <span class="hljs-string">&quot;max_position_embeddings&quot;</span>: <span class="hljs-number">512</span>,
  <span class="hljs-string">&quot;num_attention_heads&quot;</span>: <span class="hljs-number">12</span>,
  <span class="hljs-string">&quot;num_hidden_layers&quot;</span>: <span class="hljs-number">12</span>,
  [...]
}`}}),Ee=new vo({});const Qr=[nt,lt],De=[];function Wr(e,t){return e[0]==="pt"?0:1}V=Wr(k),U=De[V]=Qr[V](k);const Xr=[mt,dt],xe=[];function Zr(e,t){return e[0]==="pt"?0:1}G=Zr(k),J=xe[G]=Xr[G](k),ye=new vo({}),je=new D({props:{code:'model.save_pretrained("path_no_seu_computador")',highlighted:'model.save_pretrained(<span class="hljs-string">&quot;path_no_seu_computador&quot;</span>)'}});const es=[ut,ct],Fe=[];function os(e,t){return e[0]==="pt"?0:1}L=os(k),Y=Fe[L]=es[L](k);function as(e,t){return e[0]==="pt"?ft:pt}let qa=as(k),se=qa(k);Ce=new vo({}),Ae=new D({props:{code:'sequences = ["Hello!", "Cool.", "Nice!"]',highlighted:'sequences = [<span class="hljs-string">&quot;Hello!&quot;</span>, <span class="hljs-string">&quot;Cool.&quot;</span>, <span class="hljs-string">&quot;Nice!&quot;</span>]'}}),Me=new D({props:{code:`encoded_sequences = [
    [101, 7592, 999, 102],
    [101, 4658, 1012, 102],
    [101, 3835, 999, 102],
]`,highlighted:`encoded_sequences = [
    [<span class="hljs-number">101</span>, <span class="hljs-number">7592</span>, <span class="hljs-number">999</span>, <span class="hljs-number">102</span>],
    [<span class="hljs-number">101</span>, <span class="hljs-number">4658</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>],
    [<span class="hljs-number">101</span>, <span class="hljs-number">3835</span>, <span class="hljs-number">999</span>, <span class="hljs-number">102</span>],
]`}});const rs=[ht,_t],Se=[];function ss(e,t){return e[0]==="pt"?0:1}return K=ss(k),Q=Se[K]=rs[K](k),Oe=new vo({}),Pe=new D({props:{code:"output = model(model_inputs)",highlighted:"output = model(model_inputs)"}}),{c(){r=d("meta"),n=_(),A(o.$$.fragment),f=_(),w=d("h1"),E=d("a"),q=d("span"),A(z.$$.fragment),y=_(),g=d("span"),C=i("Modelos"),p=_(),T.c(),B=_(),H.c(),Ve=_(),re.c(),Ue=_(),Ge=d("p"),Pa=i("Entretanto, se voc\xEA conhece o tipo de modelo que deseja usar, pode usar diretamente a classe que define sua arquitetura. Vamos dar uma olhada em como isto funciona com um modelo BERT."),Ro=_(),X=d("h2"),te=d("a"),bo=d("span"),A(ke.$$.fragment),Ta=_(),$o=d("span"),Ba=i("Criando um Transformer"),Vo=_(),Je=d("p"),Na=i("A primeira coisa que precisamos fazer para inicializar um modelo BERT \xE9 carregar um objeto de configura\xE7\xE3o:"),Uo=_(),R.c(),Le=_(),Ye=d("p"),Da=i("A configura\xE7\xE3o cont\xE9m muitos atributos que s\xE3o usados para construir o modelo:"),Go=_(),A(qe.$$.fragment),Jo=_(),A(ge.$$.fragment),Lo=_(),x=d("p"),xa=i("Embora voc\xEA ainda n\xE3o tenha visto o que todos esses atributos fazem, voc\xEA deve reconhecer alguns deles: o atributo "),ko=d("code"),Fa=i("hidden_size"),Sa=i(" define o tamanho do vetor "),qo=d("code"),Ha=i("hidden_states"),Ia=i(", e o "),go=d("code"),Ra=i("num_hidden_layers"),Va=i("  define o n\xFAmero de camadas que o Transformer possui."),Yo=_(),Z=d("h3"),ie=d("a"),Eo=d("span"),A(Ee.$$.fragment),Ua=_(),wo=d("span"),Ga=i("Diferentes m\xE9todos de inicializar o modelo"),Ko=_(),Ke=d("p"),Ja=i("A cria\xE7\xE3o de um modelo a partir da configura\xE7\xE3o padr\xE3o o inicializa com valores aleat\xF3rios:"),Qo=_(),U.c(),Qe=_(),le=d("p"),La=i("O modelo pode ser utilizado neste estado, mas produzir\xE1 sa\xEDdas err\xF4neas; ele precisa ser treinado primeiro. Poder\xEDamos treinar o modelo a partir do zero na tarefa em m\xE3os, mas como voc\xEA viu em "),We=d("a"),Ya=i("Cap\xEDtulo 1"),Ka=i(", isto exigiria muito tempo e muitos dados, e teria um impacto ambiental n\xE3o negligenci\xE1vel. Para evitar esfor\xE7os desnecess\xE1rios e duplicados, normalmente \xE9 poss\xEDvel compartilhar e reutilizar modelos que j\xE1 foram treinados."),Wo=_(),ne=d("p"),Qa=i("Carregar um Transformer j\xE1 treinado \xE9 simples - podemos fazer isso utilizando o m\xE9todo "),zo=d("code"),Wa=i("from_pretrained()"),Xa=i(":"),Xo=_(),J.c(),Xe=_(),F=d("p"),Za=i("No exemplo de c\xF3digo acima n\xE3o utilizamos "),yo=d("code"),er=i("BertConfig"),or=i(", e em vez disso carregamos um modelo pr\xE9-treinado atrav\xE9s do identificador "),jo=d("code"),ar=i("bert-base-cased"),rr=i(". Este \xE9 um checkpoint do modelo que foi treinado pelos pr\xF3prios autores do BERT; voc\xEA pode encontrar mais detalhes sobre ele em seu "),we=d("a"),sr=i("model card"),tr=i("."),Zo=_(),de=d("p"),ir=i("Este modelo agora \xE9 inicializado com todos os pesos do checkpoint. Ele pode ser usado diretamente para infer\xEAncia sobre as tarefas nas quais foi treinado, e tamb\xE9m pode ser "),Co=d("em"),lr=i("fine-tuned"),nr=i(" (aperfei\xE7oado) em uma nova tarefa. Treinando com pesos pr\xE9-treinados e n\xE3o do zero, podemos rapidamente alcan\xE7ar bons resultados."),ea=_(),S=d("p"),dr=i("Os pesos foram baixados e armazenados em cache (logo, para as futuras chamadas do m\xE9todo "),Ao=d("code"),mr=i("from_pretrained()"),cr=i(" n\xE3o ser\xE1 realizado o download novamente) em sua respectiva pasta, que tem como padr\xE3o o path "),Mo=d("em"),ur=i("~/.cache/huggingface/transformers"),pr=i(". Voc\xEA pode personalizar sua pasta de cache definindo a vari\xE1vel de ambiente "),Oo=d("code"),fr=i("HF_HOME"),_r=i("."),oa=_(),me=d("p"),hr=i("O identificador usado para carregar o modelo pode ser o identificador de qualquer modelo no Model Hub, desde que seja compat\xEDvel com a arquitetura BERT. A lista completa dos checkpoints BERT dispon\xEDveis podem ser encontrada [aqui]."),ze=d("a"),vr=i("https://huggingface.co/models?filter=bert"),br=i(")."),aa=_(),ee=d("h3"),ce=d("a"),Po=d("span"),A(ye.$$.fragment),$r=_(),To=d("span"),kr=i("M\xE9todos para salvar/armazenar o modelo"),ra=_(),W=d("p"),qr=i("Salvar um modelo \xE9 t\xE3o f\xE1cil quanto carregar um - utilizamos o m\xE9todo "),Bo=d("code"),gr=i("save_pretrained()"),Er=i(", que \xE9 an\xE1logo ao m\xE9todo "),No=d("code"),wr=i("from_pretrained()"),zr=i(":"),sa=_(),A(je.$$.fragment),ta=_(),Ze=d("p"),yr=i("Isto salva dois arquivos em seu disco:"),ia=_(),Y.c(),eo=_(),ue=d("p"),jr=i("Se voc\xEA der uma olhada no arquivo "),Do=d("em"),Cr=i("config.json"),Ar=i(", voc\xEA reconhecer\xE1 os atributos necess\xE1rios para construir a arquitetura modelo. Este arquivo tamb\xE9m cont\xE9m alguns metadados, como a origem do checkpoint e a vers\xE3o \u{1F917} Transformers que voc\xEA estava usando quando salvou o checkpoint pela \xFAltima vez."),la=_(),se.c(),oo=_(),oe=d("h2"),pe=d("a"),xo=d("span"),A(Ce.$$.fragment),Mr=_(),Fo=d("span"),Or=i("Usando um modelo de Transformer para infer\xEAncia"),na=_(),ao=d("p"),Pr=i("Agora que voc\xEA sabe como carregar e salvar um modelo, vamos tentar us\xE1-lo para fazer algumas predi\xE7\xF5es. Os Transformers s\xF3 podem processar n\xFAmeros - n\xFAmeros que o tokenizer gera. Mas antes de discutirmos os tokenizers, vamos explorar quais entradas o modelo aceita."),da=_(),ro=d("p"),Tr=i("Os Tokenizers podem se encarregar de lan\xE7ar as entradas nos tensores da estrutura apropriada, mas para ajud\xE1-lo a entender o que est\xE1 acontecendo, vamos dar uma r\xE1pida olhada no que deve ser feito antes de enviar as entradas para o modelo."),ma=_(),so=d("p"),Br=i("Digamos que temos um par de sequ\xEAncias:"),ca=_(),A(Ae.$$.fragment),ua=_(),fe=d("p"),Nr=i("O tokenizer os converte em \xEDndices de vocabul\xE1rio que s\xE3o normalmente chamados de "),So=d("em"),Dr=i("IDs de entrada"),xr=i(". Cada sequ\xEAncia \xE9 agora uma lista de n\xFAmeros! A sa\xEDda resultante \xE9:"),pa=_(),A(Me.$$.fragment),fa=_(),to=d("p"),Fr=i("Esta \xE9 uma lista de sequ\xEAncias codificadas: uma lista de listas. Os tensores s\xF3 aceitam shapes (tamanhos) retangulares (pense em matrizes). Esta \u201Cmatriz\u201D j\xE1 \xE9 de forma retangular, portanto, convert\xEA-la em um tensor \xE9 f\xE1cil:"),_a=_(),Q.c(),io=_(),ae=d("h3"),_e=d("a"),Ho=d("span"),A(Oe.$$.fragment),Sr=_(),Io=d("span"),Hr=i("Usando os tensores como entradas para o modelo"),ha=_(),lo=d("p"),Ir=i("Fazer uso dos tensores com o modelo \xE9 extremamente simples - chamamos apenas o modelo com os inputs:"),va=_(),A(Pe.$$.fragment),ba=_(),no=d("p"),Rr=i("Embora o modelo aceite muitos argumentos diferentes, apenas os IDs de entrada s\xE3o necess\xE1rios. Explicaremos o que os outros argumentos fazem e quando eles s\xE3o necess\xE1rios mais tarde, mas primeiro precisamos olhar mais de perto os tokenizers que constroem as entradas que um Transformer pode compreender."),this.h()},l(e){const t=Qs('[data-svelte="svelte-1phssyn"]',document.head);r=m(t,"META",{name:!0,content:!0}),t.forEach(a),n=h(e),M(o.$$.fragment,e),f=h(e),w=m(e,"H1",{class:!0});var He=u(w);E=m(He,"A",{id:!0,class:!0,href:!0});var mo=u(E);q=m(mo,"SPAN",{});var co=u(q);M(z.$$.fragment,co),co.forEach(a),mo.forEach(a),y=h(He),g=m(He,"SPAN",{});var uo=u(g);C=l(uo,"Modelos"),uo.forEach(a),He.forEach(a),p=h(e),T.l(e),B=h(e),H.l(e),Ve=h(e),re.l(e),Ue=h(e),Ge=m(e,"P",{});var po=u(Ge);Pa=l(po,"Entretanto, se voc\xEA conhece o tipo de modelo que deseja usar, pode usar diretamente a classe que define sua arquitetura. Vamos dar uma olhada em como isto funciona com um modelo BERT."),po.forEach(a),Ro=h(e),X=m(e,"H2",{class:!0});var he=u(X);te=m(he,"A",{id:!0,class:!0,href:!0});var fo=u(te);bo=m(fo,"SPAN",{});var _o=u(bo);M(ke.$$.fragment,_o),_o.forEach(a),fo.forEach(a),Ta=h(he),$o=m(he,"SPAN",{});var ts=u($o);Ba=l(ts,"Criando um Transformer"),ts.forEach(a),he.forEach(a),Vo=h(e),Je=m(e,"P",{});var is=u(Je);Na=l(is,"A primeira coisa que precisamos fazer para inicializar um modelo BERT \xE9 carregar um objeto de configura\xE7\xE3o:"),is.forEach(a),Uo=h(e),R.l(e),Le=h(e),Ye=m(e,"P",{});var ls=u(Ye);Da=l(ls,"A configura\xE7\xE3o cont\xE9m muitos atributos que s\xE3o usados para construir o modelo:"),ls.forEach(a),Go=h(e),M(qe.$$.fragment,e),Jo=h(e),M(ge.$$.fragment,e),Lo=h(e),x=m(e,"P",{});var ve=u(x);xa=l(ve,"Embora voc\xEA ainda n\xE3o tenha visto o que todos esses atributos fazem, voc\xEA deve reconhecer alguns deles: o atributo "),ko=m(ve,"CODE",{});var ns=u(ko);Fa=l(ns,"hidden_size"),ns.forEach(a),Sa=l(ve," define o tamanho do vetor "),qo=m(ve,"CODE",{});var ds=u(qo);Ha=l(ds,"hidden_states"),ds.forEach(a),Ia=l(ve,", e o "),go=m(ve,"CODE",{});var ms=u(go);Ra=l(ms,"num_hidden_layers"),ms.forEach(a),Va=l(ve,"  define o n\xFAmero de camadas que o Transformer possui."),ve.forEach(a),Yo=h(e),Z=m(e,"H3",{class:!0});var ga=u(Z);ie=m(ga,"A",{id:!0,class:!0,href:!0});var cs=u(ie);Eo=m(cs,"SPAN",{});var us=u(Eo);M(Ee.$$.fragment,us),us.forEach(a),cs.forEach(a),Ua=h(ga),wo=m(ga,"SPAN",{});var ps=u(wo);Ga=l(ps,"Diferentes m\xE9todos de inicializar o modelo"),ps.forEach(a),ga.forEach(a),Ko=h(e),Ke=m(e,"P",{});var fs=u(Ke);Ja=l(fs,"A cria\xE7\xE3o de um modelo a partir da configura\xE7\xE3o padr\xE3o o inicializa com valores aleat\xF3rios:"),fs.forEach(a),Qo=h(e),U.l(e),Qe=h(e),le=m(e,"P",{});var Ea=u(le);La=l(Ea,"O modelo pode ser utilizado neste estado, mas produzir\xE1 sa\xEDdas err\xF4neas; ele precisa ser treinado primeiro. Poder\xEDamos treinar o modelo a partir do zero na tarefa em m\xE3os, mas como voc\xEA viu em "),We=m(Ea,"A",{href:!0});var _s=u(We);Ya=l(_s,"Cap\xEDtulo 1"),_s.forEach(a),Ka=l(Ea,", isto exigiria muito tempo e muitos dados, e teria um impacto ambiental n\xE3o negligenci\xE1vel. Para evitar esfor\xE7os desnecess\xE1rios e duplicados, normalmente \xE9 poss\xEDvel compartilhar e reutilizar modelos que j\xE1 foram treinados."),Ea.forEach(a),Wo=h(e),ne=m(e,"P",{});var wa=u(ne);Qa=l(wa,"Carregar um Transformer j\xE1 treinado \xE9 simples - podemos fazer isso utilizando o m\xE9todo "),zo=m(wa,"CODE",{});var hs=u(zo);Wa=l(hs,"from_pretrained()"),hs.forEach(a),Xa=l(wa,":"),wa.forEach(a),Xo=h(e),J.l(e),Xe=h(e),F=m(e,"P",{});var be=u(F);Za=l(be,"No exemplo de c\xF3digo acima n\xE3o utilizamos "),yo=m(be,"CODE",{});var vs=u(yo);er=l(vs,"BertConfig"),vs.forEach(a),or=l(be,", e em vez disso carregamos um modelo pr\xE9-treinado atrav\xE9s do identificador "),jo=m(be,"CODE",{});var bs=u(jo);ar=l(bs,"bert-base-cased"),bs.forEach(a),rr=l(be,". Este \xE9 um checkpoint do modelo que foi treinado pelos pr\xF3prios autores do BERT; voc\xEA pode encontrar mais detalhes sobre ele em seu "),we=m(be,"A",{href:!0,rel:!0});var $s=u(we);sr=l($s,"model card"),$s.forEach(a),tr=l(be,"."),be.forEach(a),Zo=h(e),de=m(e,"P",{});var za=u(de);ir=l(za,"Este modelo agora \xE9 inicializado com todos os pesos do checkpoint. Ele pode ser usado diretamente para infer\xEAncia sobre as tarefas nas quais foi treinado, e tamb\xE9m pode ser "),Co=m(za,"EM",{});var ks=u(Co);lr=l(ks,"fine-tuned"),ks.forEach(a),nr=l(za," (aperfei\xE7oado) em uma nova tarefa. Treinando com pesos pr\xE9-treinados e n\xE3o do zero, podemos rapidamente alcan\xE7ar bons resultados."),za.forEach(a),ea=h(e),S=m(e,"P",{});var $e=u(S);dr=l($e,"Os pesos foram baixados e armazenados em cache (logo, para as futuras chamadas do m\xE9todo "),Ao=m($e,"CODE",{});var qs=u(Ao);mr=l(qs,"from_pretrained()"),qs.forEach(a),cr=l($e," n\xE3o ser\xE1 realizado o download novamente) em sua respectiva pasta, que tem como padr\xE3o o path "),Mo=m($e,"EM",{});var gs=u(Mo);ur=l(gs,"~/.cache/huggingface/transformers"),gs.forEach(a),pr=l($e,". Voc\xEA pode personalizar sua pasta de cache definindo a vari\xE1vel de ambiente "),Oo=m($e,"CODE",{});var Es=u(Oo);fr=l(Es,"HF_HOME"),Es.forEach(a),_r=l($e,"."),$e.forEach(a),oa=h(e),me=m(e,"P",{});var ya=u(me);hr=l(ya,"O identificador usado para carregar o modelo pode ser o identificador de qualquer modelo no Model Hub, desde que seja compat\xEDvel com a arquitetura BERT. A lista completa dos checkpoints BERT dispon\xEDveis podem ser encontrada [aqui]."),ze=m(ya,"A",{href:!0,rel:!0});var ws=u(ze);vr=l(ws,"https://huggingface.co/models?filter=bert"),ws.forEach(a),br=l(ya,")."),ya.forEach(a),aa=h(e),ee=m(e,"H3",{class:!0});var ja=u(ee);ce=m(ja,"A",{id:!0,class:!0,href:!0});var zs=u(ce);Po=m(zs,"SPAN",{});var ys=u(Po);M(ye.$$.fragment,ys),ys.forEach(a),zs.forEach(a),$r=h(ja),To=m(ja,"SPAN",{});var js=u(To);kr=l(js,"M\xE9todos para salvar/armazenar o modelo"),js.forEach(a),ja.forEach(a),ra=h(e),W=m(e,"P",{});var ho=u(W);qr=l(ho,"Salvar um modelo \xE9 t\xE3o f\xE1cil quanto carregar um - utilizamos o m\xE9todo "),Bo=m(ho,"CODE",{});var Cs=u(Bo);gr=l(Cs,"save_pretrained()"),Cs.forEach(a),Er=l(ho,", que \xE9 an\xE1logo ao m\xE9todo "),No=m(ho,"CODE",{});var As=u(No);wr=l(As,"from_pretrained()"),As.forEach(a),zr=l(ho,":"),ho.forEach(a),sa=h(e),M(je.$$.fragment,e),ta=h(e),Ze=m(e,"P",{});var Ms=u(Ze);yr=l(Ms,"Isto salva dois arquivos em seu disco:"),Ms.forEach(a),ia=h(e),Y.l(e),eo=h(e),ue=m(e,"P",{});var Ca=u(ue);jr=l(Ca,"Se voc\xEA der uma olhada no arquivo "),Do=m(Ca,"EM",{});var Os=u(Do);Cr=l(Os,"config.json"),Os.forEach(a),Ar=l(Ca,", voc\xEA reconhecer\xE1 os atributos necess\xE1rios para construir a arquitetura modelo. Este arquivo tamb\xE9m cont\xE9m alguns metadados, como a origem do checkpoint e a vers\xE3o \u{1F917} Transformers que voc\xEA estava usando quando salvou o checkpoint pela \xFAltima vez."),Ca.forEach(a),la=h(e),se.l(e),oo=h(e),oe=m(e,"H2",{class:!0});var Aa=u(oe);pe=m(Aa,"A",{id:!0,class:!0,href:!0});var Ps=u(pe);xo=m(Ps,"SPAN",{});var Ts=u(xo);M(Ce.$$.fragment,Ts),Ts.forEach(a),Ps.forEach(a),Mr=h(Aa),Fo=m(Aa,"SPAN",{});var Bs=u(Fo);Or=l(Bs,"Usando um modelo de Transformer para infer\xEAncia"),Bs.forEach(a),Aa.forEach(a),na=h(e),ao=m(e,"P",{});var Ns=u(ao);Pr=l(Ns,"Agora que voc\xEA sabe como carregar e salvar um modelo, vamos tentar us\xE1-lo para fazer algumas predi\xE7\xF5es. Os Transformers s\xF3 podem processar n\xFAmeros - n\xFAmeros que o tokenizer gera. Mas antes de discutirmos os tokenizers, vamos explorar quais entradas o modelo aceita."),Ns.forEach(a),da=h(e),ro=m(e,"P",{});var Ds=u(ro);Tr=l(Ds,"Os Tokenizers podem se encarregar de lan\xE7ar as entradas nos tensores da estrutura apropriada, mas para ajud\xE1-lo a entender o que est\xE1 acontecendo, vamos dar uma r\xE1pida olhada no que deve ser feito antes de enviar as entradas para o modelo."),Ds.forEach(a),ma=h(e),so=m(e,"P",{});var xs=u(so);Br=l(xs,"Digamos que temos um par de sequ\xEAncias:"),xs.forEach(a),ca=h(e),M(Ae.$$.fragment,e),ua=h(e),fe=m(e,"P",{});var Ma=u(fe);Nr=l(Ma,"O tokenizer os converte em \xEDndices de vocabul\xE1rio que s\xE3o normalmente chamados de "),So=m(Ma,"EM",{});var Fs=u(So);Dr=l(Fs,"IDs de entrada"),Fs.forEach(a),xr=l(Ma,". Cada sequ\xEAncia \xE9 agora uma lista de n\xFAmeros! A sa\xEDda resultante \xE9:"),Ma.forEach(a),pa=h(e),M(Me.$$.fragment,e),fa=h(e),to=m(e,"P",{});var Ss=u(to);Fr=l(Ss,"Esta \xE9 uma lista de sequ\xEAncias codificadas: uma lista de listas. Os tensores s\xF3 aceitam shapes (tamanhos) retangulares (pense em matrizes). Esta \u201Cmatriz\u201D j\xE1 \xE9 de forma retangular, portanto, convert\xEA-la em um tensor \xE9 f\xE1cil:"),Ss.forEach(a),_a=h(e),Q.l(e),io=h(e),ae=m(e,"H3",{class:!0});var Oa=u(ae);_e=m(Oa,"A",{id:!0,class:!0,href:!0});var Hs=u(_e);Ho=m(Hs,"SPAN",{});var Is=u(Ho);M(Oe.$$.fragment,Is),Is.forEach(a),Hs.forEach(a),Sr=h(Oa),Io=m(Oa,"SPAN",{});var Rs=u(Io);Hr=l(Rs,"Usando os tensores como entradas para o modelo"),Rs.forEach(a),Oa.forEach(a),ha=h(e),lo=m(e,"P",{});var Vs=u(lo);Ir=l(Vs,"Fazer uso dos tensores com o modelo \xE9 extremamente simples - chamamos apenas o modelo com os inputs:"),Vs.forEach(a),va=h(e),M(Pe.$$.fragment,e),ba=h(e),no=m(e,"P",{});var Us=u(no);Rr=l(Us,"Embora o modelo aceite muitos argumentos diferentes, apenas os IDs de entrada s\xE3o necess\xE1rios. Explicaremos o que os outros argumentos fazem e quando eles s\xE3o necess\xE1rios mais tarde, mas primeiro precisamos olhar mais de perto os tokenizers que constroem as entradas que um Transformer pode compreender."),Us.forEach(a),this.h()},h(){j(r,"name","hf:doc:metadata"),j(r,"content",JSON.stringify(bt)),j(E,"id","modelos"),j(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),j(E,"href","#modelos"),j(w,"class","relative group"),j(te,"id","criando-um-transformer"),j(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),j(te,"href","#criando-um-transformer"),j(X,"class","relative group"),j(ie,"id","diferentes-mtodos-de-inicializar-o-modelo"),j(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),j(ie,"href","#diferentes-mtodos-de-inicializar-o-modelo"),j(Z,"class","relative group"),j(We,"href","/course/pt/chapter1"),j(we,"href","https://huggingface.co/bert-base-cased"),j(we,"rel","nofollow"),j(ze,"href","https://huggingface.co/models?filter=bert"),j(ze,"rel","nofollow"),j(ce,"id","mtodos-para-salvararmazenar-o-modelo"),j(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),j(ce,"href","#mtodos-para-salvararmazenar-o-modelo"),j(ee,"class","relative group"),j(pe,"id","usando-um-modelo-de-transformer-para-inferncia"),j(pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),j(pe,"href","#usando-um-modelo-de-transformer-para-inferncia"),j(oe,"class","relative group"),j(_e,"id","usando-os-tensores-como-entradas-para-o-modelo"),j(_e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),j(_e,"href","#usando-os-tensores-como-entradas-para-o-modelo"),j(ae,"class","relative group")},m(e,t){s(document.head,r),c(e,n,t),O(o,e,t),c(e,f,t),c(e,w,t),s(w,E),s(E,q),O(z,q,null),s(w,y),s(w,g),s(g,C),c(e,p,t),Te[v].m(e,t),c(e,B,t),Be[N].m(e,t),c(e,Ve,t),re.m(e,t),c(e,Ue,t),c(e,Ge,t),s(Ge,Pa),c(e,Ro,t),c(e,X,t),s(X,te),s(te,bo),O(ke,bo,null),s(X,Ta),s(X,$o),s($o,Ba),c(e,Vo,t),c(e,Je,t),s(Je,Na),c(e,Uo,t),Ne[I].m(e,t),c(e,Le,t),c(e,Ye,t),s(Ye,Da),c(e,Go,t),O(qe,e,t),c(e,Jo,t),O(ge,e,t),c(e,Lo,t),c(e,x,t),s(x,xa),s(x,ko),s(ko,Fa),s(x,Sa),s(x,qo),s(qo,Ha),s(x,Ia),s(x,go),s(go,Ra),s(x,Va),c(e,Yo,t),c(e,Z,t),s(Z,ie),s(ie,Eo),O(Ee,Eo,null),s(Z,Ua),s(Z,wo),s(wo,Ga),c(e,Ko,t),c(e,Ke,t),s(Ke,Ja),c(e,Qo,t),De[V].m(e,t),c(e,Qe,t),c(e,le,t),s(le,La),s(le,We),s(We,Ya),s(le,Ka),c(e,Wo,t),c(e,ne,t),s(ne,Qa),s(ne,zo),s(zo,Wa),s(ne,Xa),c(e,Xo,t),xe[G].m(e,t),c(e,Xe,t),c(e,F,t),s(F,Za),s(F,yo),s(yo,er),s(F,or),s(F,jo),s(jo,ar),s(F,rr),s(F,we),s(we,sr),s(F,tr),c(e,Zo,t),c(e,de,t),s(de,ir),s(de,Co),s(Co,lr),s(de,nr),c(e,ea,t),c(e,S,t),s(S,dr),s(S,Ao),s(Ao,mr),s(S,cr),s(S,Mo),s(Mo,ur),s(S,pr),s(S,Oo),s(Oo,fr),s(S,_r),c(e,oa,t),c(e,me,t),s(me,hr),s(me,ze),s(ze,vr),s(me,br),c(e,aa,t),c(e,ee,t),s(ee,ce),s(ce,Po),O(ye,Po,null),s(ee,$r),s(ee,To),s(To,kr),c(e,ra,t),c(e,W,t),s(W,qr),s(W,Bo),s(Bo,gr),s(W,Er),s(W,No),s(No,wr),s(W,zr),c(e,sa,t),O(je,e,t),c(e,ta,t),c(e,Ze,t),s(Ze,yr),c(e,ia,t),Fe[L].m(e,t),c(e,eo,t),c(e,ue,t),s(ue,jr),s(ue,Do),s(Do,Cr),s(ue,Ar),c(e,la,t),se.m(e,t),c(e,oo,t),c(e,oe,t),s(oe,pe),s(pe,xo),O(Ce,xo,null),s(oe,Mr),s(oe,Fo),s(Fo,Or),c(e,na,t),c(e,ao,t),s(ao,Pr),c(e,da,t),c(e,ro,t),s(ro,Tr),c(e,ma,t),c(e,so,t),s(so,Br),c(e,ca,t),O(Ae,e,t),c(e,ua,t),c(e,fe,t),s(fe,Nr),s(fe,So),s(So,Dr),s(fe,xr),c(e,pa,t),O(Me,e,t),c(e,fa,t),c(e,to,t),s(to,Fr),c(e,_a,t),Se[K].m(e,t),c(e,io,t),c(e,ae,t),s(ae,_e),s(_e,Ho),O(Oe,Ho,null),s(ae,Sr),s(ae,Io),s(Io,Hr),c(e,ha,t),c(e,lo,t),s(lo,Ir),c(e,va,t),O(Pe,e,t),c(e,ba,t),c(e,no,t),s(no,Rr),$a=!0},p(e,[t]){const He={};t&1&&(He.fw=e[0]),o.$set(He);let mo=v;v=Ur(e),v!==mo&&(Re(),b(Te[mo],1,1,()=>{Te[mo]=null}),Ie(),T=Te[v],T||(T=Te[v]=Vr[v](e),T.c()),$(T,1),T.m(B.parentNode,B));let co=N;N=Jr(e),N!==co&&(Re(),b(Be[co],1,1,()=>{Be[co]=null}),Ie(),H=Be[N],H||(H=Be[N]=Gr[N](e),H.c()),$(H,1),H.m(Ve.parentNode,Ve)),ka!==(ka=Lr(e))&&(re.d(1),re=ka(e),re&&(re.c(),re.m(Ue.parentNode,Ue)));let uo=I;I=Kr(e),I!==uo&&(Re(),b(Ne[uo],1,1,()=>{Ne[uo]=null}),Ie(),R=Ne[I],R||(R=Ne[I]=Yr[I](e),R.c()),$(R,1),R.m(Le.parentNode,Le));let po=V;V=Wr(e),V!==po&&(Re(),b(De[po],1,1,()=>{De[po]=null}),Ie(),U=De[V],U||(U=De[V]=Qr[V](e),U.c()),$(U,1),U.m(Qe.parentNode,Qe));let he=G;G=Zr(e),G!==he&&(Re(),b(xe[he],1,1,()=>{xe[he]=null}),Ie(),J=xe[G],J||(J=xe[G]=Xr[G](e),J.c()),$(J,1),J.m(Xe.parentNode,Xe));let fo=L;L=os(e),L!==fo&&(Re(),b(Fe[fo],1,1,()=>{Fe[fo]=null}),Ie(),Y=Fe[L],Y||(Y=Fe[L]=es[L](e),Y.c()),$(Y,1),Y.m(eo.parentNode,eo)),qa!==(qa=as(e))&&(se.d(1),se=qa(e),se&&(se.c(),se.m(oo.parentNode,oo)));let _o=K;K=ss(e),K!==_o&&(Re(),b(Se[_o],1,1,()=>{Se[_o]=null}),Ie(),Q=Se[K],Q||(Q=Se[K]=rs[K](e),Q.c()),$(Q,1),Q.m(io.parentNode,io))},i(e){$a||($(o.$$.fragment,e),$(z.$$.fragment,e),$(T),$(H),$(ke.$$.fragment,e),$(R),$(qe.$$.fragment,e),$(ge.$$.fragment,e),$(Ee.$$.fragment,e),$(U),$(J),$(ye.$$.fragment,e),$(je.$$.fragment,e),$(Y),$(Ce.$$.fragment,e),$(Ae.$$.fragment,e),$(Me.$$.fragment,e),$(Q),$(Oe.$$.fragment,e),$(Pe.$$.fragment,e),$a=!0)},o(e){b(o.$$.fragment,e),b(z.$$.fragment,e),b(T),b(H),b(ke.$$.fragment,e),b(R),b(qe.$$.fragment,e),b(ge.$$.fragment,e),b(Ee.$$.fragment,e),b(U),b(J),b(ye.$$.fragment,e),b(je.$$.fragment,e),b(Y),b(Ce.$$.fragment,e),b(Ae.$$.fragment,e),b(Me.$$.fragment,e),b(Q),b(Oe.$$.fragment,e),b(Pe.$$.fragment,e),$a=!1},d(e){a(r),e&&a(n),P(o,e),e&&a(f),e&&a(w),P(z),e&&a(p),Te[v].d(e),e&&a(B),Be[N].d(e),e&&a(Ve),re.d(e),e&&a(Ue),e&&a(Ge),e&&a(Ro),e&&a(X),P(ke),e&&a(Vo),e&&a(Je),e&&a(Uo),Ne[I].d(e),e&&a(Le),e&&a(Ye),e&&a(Go),P(qe,e),e&&a(Jo),P(ge,e),e&&a(Lo),e&&a(x),e&&a(Yo),e&&a(Z),P(Ee),e&&a(Ko),e&&a(Ke),e&&a(Qo),De[V].d(e),e&&a(Qe),e&&a(le),e&&a(Wo),e&&a(ne),e&&a(Xo),xe[G].d(e),e&&a(Xe),e&&a(F),e&&a(Zo),e&&a(de),e&&a(ea),e&&a(S),e&&a(oa),e&&a(me),e&&a(aa),e&&a(ee),P(ye),e&&a(ra),e&&a(W),e&&a(sa),P(je,e),e&&a(ta),e&&a(Ze),e&&a(ia),Fe[L].d(e),e&&a(eo),e&&a(ue),e&&a(la),se.d(e),e&&a(oo),e&&a(oe),P(Ce),e&&a(na),e&&a(ao),e&&a(da),e&&a(ro),e&&a(ma),e&&a(so),e&&a(ca),P(Ae,e),e&&a(ua),e&&a(fe),e&&a(pa),P(Me,e),e&&a(fa),e&&a(to),e&&a(_a),Se[K].d(e),e&&a(io),e&&a(ae),P(Oe),e&&a(ha),e&&a(lo),e&&a(va),P(Pe,e),e&&a(ba),e&&a(no)}}}const bt={local:"modelos",sections:[{local:"criando-um-transformer",sections:[{local:"diferentes-mtodos-de-inicializar-o-modelo",title:"Diferentes m\xE9todos de inicializar o modelo"},{local:"mtodos-para-salvararmazenar-o-modelo",title:"M\xE9todos para salvar/armazenar o modelo"}],title:"Criando um Transformer"},{local:"usando-um-modelo-de-transformer-para-inferncia",sections:[{local:"usando-os-tensores-como-entradas-para-o-modelo",title:"Usando os tensores como entradas para o modelo"}],title:"Usando um modelo de Transformer para infer\xEAncia"}],title:"Modelos"};function $t(k,r,n){let o="pt";return Ws(()=>{const f=new URLSearchParams(window.location.search);n(0,o=f.get("fw")||"pt")}),[o]}class yt extends Ls{constructor(r){super();Ys(this,r,$t,vt,Ks,{})}}export{yt as default,bt as metadata};
