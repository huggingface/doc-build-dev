import{S as ge,i as Pe,s as xe,e as s,k as c,w as Le,t as m,M as ye,c as r,d as a,m as p,a as t,x as Te,h as f,b as d,G as o,g as i,y as $e,L as Ae,q as qe,o as Me,B as Oe,v as Ie}from"../../chunks/vendor-hf-doc-builder.js";import{I as Se}from"../../chunks/IconCopyLink-hf-doc-builder.js";function ke(re){let u,G,h,v,A,w,J,q,j,C,_,z,M,D,F,b,y,K,N,T,Q,R,$,V,U,n,O,g,W,Y,I,P,Z,ee,S,x,ae,oe,k,L,se,X;return w=new Se({}),{c(){u=s("meta"),G=c(),h=s("h1"),v=s("a"),A=s("span"),Le(w.$$.fragment),J=c(),q=s("span"),j=m("Modelos decodificadores"),C=c(),_=s("p"),z=m("Os modelos de decodificador usam apenas o decodificador de um modelo Transformer. Em cada etapa, para uma determinada palavra, as camadas de aten\xE7\xE3o s\xF3 podem acessar as palavras posicionadas antes dela na frase. Esses modelos geralmente s\xE3o chamados de\xA0"),M=s("em"),D=m("modelos auto-regressivos"),F=m("."),b=c(),y=s("p"),K=m("O pr\xE9-treinamento de modelos de decodificadores geralmente gira em torno de prever a pr\xF3xima palavra na frase."),N=c(),T=s("p"),Q=m("Esses modelos s\xE3o mais adequados para tarefas que envolvem gera\xE7\xE3o de texto."),R=c(),$=s("p"),V=m("Os representantes desta fam\xEDlia de modelos incluem:"),U=c(),n=s("ul"),O=s("li"),g=s("a"),W=m("CTRL"),Y=c(),I=s("li"),P=s("a"),Z=m("GPT"),ee=c(),S=s("li"),x=s("a"),ae=m("GPT-2"),oe=c(),k=s("li"),L=s("a"),se=m("Transformer XL"),this.h()},l(e){const l=ye('[data-svelte="svelte-1phssyn"]',document.head);u=r(l,"META",{name:!0,content:!0}),l.forEach(a),G=p(e),h=r(e,"H1",{class:!0});var B=t(h);v=r(B,"A",{id:!0,class:!0,href:!0});var te=t(v);A=r(te,"SPAN",{});var le=t(A);Te(w.$$.fragment,le),le.forEach(a),te.forEach(a),J=p(B),q=r(B,"SPAN",{});var de=t(q);j=f(de,"Modelos decodificadores"),de.forEach(a),B.forEach(a),C=p(e),_=r(e,"P",{});var H=t(_);z=f(H,"Os modelos de decodificador usam apenas o decodificador de um modelo Transformer. Em cada etapa, para uma determinada palavra, as camadas de aten\xE7\xE3o s\xF3 podem acessar as palavras posicionadas antes dela na frase. Esses modelos geralmente s\xE3o chamados de\xA0"),M=r(H,"EM",{});var ne=t(M);D=f(ne,"modelos auto-regressivos"),ne.forEach(a),F=f(H,"."),H.forEach(a),b=p(e),y=r(e,"P",{});var ie=t(y);K=f(ie,"O pr\xE9-treinamento de modelos de decodificadores geralmente gira em torno de prever a pr\xF3xima palavra na frase."),ie.forEach(a),N=p(e),T=r(e,"P",{});var me=t(T);Q=f(me,"Esses modelos s\xE3o mais adequados para tarefas que envolvem gera\xE7\xE3o de texto."),me.forEach(a),R=p(e),$=r(e,"P",{});var fe=t($);V=f(fe,"Os representantes desta fam\xEDlia de modelos incluem:"),fe.forEach(a),U=p(e),n=r(e,"UL",{});var E=t(n);O=r(E,"LI",{});var ce=t(O);g=r(ce,"A",{href:!0,rel:!0});var pe=t(g);W=f(pe,"CTRL"),pe.forEach(a),ce.forEach(a),Y=p(E),I=r(E,"LI",{});var ue=t(I);P=r(ue,"A",{href:!0,rel:!0});var he=t(P);Z=f(he,"GPT"),he.forEach(a),ue.forEach(a),ee=p(E),S=r(E,"LI",{});var ve=t(S);x=r(ve,"A",{href:!0,rel:!0});var _e=t(x);ae=f(_e,"GPT-2"),_e.forEach(a),ve.forEach(a),oe=p(E),k=r(E,"LI",{});var Ee=t(k);L=r(Ee,"A",{href:!0,rel:!0});var we=t(L);se=f(we,"Transformer XL"),we.forEach(a),Ee.forEach(a),E.forEach(a),this.h()},h(){d(u,"name","hf:doc:metadata"),d(u,"content",JSON.stringify(Ge)),d(v,"id","modelos-decodificadores"),d(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(v,"href","#modelos-decodificadores"),d(h,"class","relative group"),d(g,"href","https://huggingface.co/transformers/model_doc/ctrl.html"),d(g,"rel","nofollow"),d(P,"href","https://huggingface.co/transformers/model_doc/gpt.html"),d(P,"rel","nofollow"),d(x,"href","https://huggingface.co/transformers/model_doc/gpt2.html"),d(x,"rel","nofollow"),d(L,"href","https://huggingface.co/transformers/model_doc/transfo-xl.html"),d(L,"rel","nofollow")},m(e,l){o(document.head,u),i(e,G,l),i(e,h,l),o(h,v),o(v,A),$e(w,A,null),o(h,J),o(h,q),o(q,j),i(e,C,l),i(e,_,l),o(_,z),o(_,M),o(M,D),o(_,F),i(e,b,l),i(e,y,l),o(y,K),i(e,N,l),i(e,T,l),o(T,Q),i(e,R,l),i(e,$,l),o($,V),i(e,U,l),i(e,n,l),o(n,O),o(O,g),o(g,W),o(n,Y),o(n,I),o(I,P),o(P,Z),o(n,ee),o(n,S),o(S,x),o(x,ae),o(n,oe),o(n,k),o(k,L),o(L,se),X=!0},p:Ae,i(e){X||(qe(w.$$.fragment,e),X=!0)},o(e){Me(w.$$.fragment,e),X=!1},d(e){a(u),e&&a(G),e&&a(h),Oe(w),e&&a(C),e&&a(_),e&&a(b),e&&a(y),e&&a(N),e&&a(T),e&&a(R),e&&a($),e&&a(U),e&&a(n)}}}const Ge={local:"modelos-decodificadores",title:"Modelos decodificadores"};function Ce(re){return Ie(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Re extends ge{constructor(u){super();Pe(this,u,Ce,ke,xe,{})}}export{Re as default,Ge as metadata};
