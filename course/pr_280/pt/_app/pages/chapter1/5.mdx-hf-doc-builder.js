import{S as Ie,i as Se,s as ke,e as t,k as m,w as be,t as c,M as Ce,c as r,d as a,m as f,a as s,x as qe,h as p,b as d,G as o,g as n,y as Pe,L as Ne,q as Be,o as Oe,B as Me,v as Ue}from"../../chunks/vendor-hf-doc-builder.js";import{Y as ze}from"../../chunks/Youtube-hf-doc-builder.js";import{I as De}from"../../chunks/IconCopyLink-hf-doc-builder.js";function Je(me){let h,C,_,v,q,g,Q,P,F,N,w,U,E,K,B,V,W,z,T,X,D,y,Z,J,b,ee,Y,i,O,$,ae,oe,M,x,te,re,I,A,se,le,S,L,de,ie,k,R,ne,j;return g=new De({}),w=new ze({props:{id:"MUqNwgPjJvQ"}}),{c(){h=t("meta"),C=m(),_=t("h1"),v=t("a"),q=t("span"),be(g.$$.fragment),Q=m(),P=t("span"),F=c("Modelos decodificadores"),N=m(),be(w.$$.fragment),U=m(),E=t("p"),K=c("Os modelos de encoder (decodificadores) usam apenas o encoder de um modelo Transformer. Em cada est\xE1gio, as camadas de aten\xE7\xE3o podem acessar todas as palavras da frase inicial. Esses modelos geralmente s\xE3o caracterizados como tendo aten\xE7\xE3o \u201Cbidirecional\u201D e s\xE3o frequentemente chamados de "),B=t("em"),V=c("modelos de codifica\xE7\xE3o autom\xE1tica"),W=c("."),z=m(),T=t("p"),X=c("O pr\xE9-treinamento desses modelos geralmente gira em torno de corromper de alguma forma uma determinada frase (por exemplo, mascarando palavras aleat\xF3rias nela) e encarregando o modelo de encontrar ou reconstruir a frase inicial."),D=m(),y=t("p"),Z=c("Os modelos de codificador s\xE3o mais adequados para tarefas que exigem uma compreens\xE3o da senten\xE7a completa, como classifica\xE7\xE3o de senten\xE7a, reconhecimento de entidade nomeada (e, mais geralmente, classifica\xE7\xE3o de palavras) e resposta extrativa de perguntas."),J=m(),b=t("p"),ee=c("Os representantes desta fam\xEDlia de modelos incluem:"),Y=m(),i=t("ul"),O=t("li"),$=t("a"),ae=c("ALBERT"),oe=m(),M=t("li"),x=t("a"),te=c("BERT"),re=m(),I=t("li"),A=t("a"),se=c("DistilBERT"),le=m(),S=t("li"),L=t("a"),de=c("ELECTRA"),ie=m(),k=t("li"),R=t("a"),ne=c("RoBERTa"),this.h()},l(e){const l=Ce('[data-svelte="svelte-1phssyn"]',document.head);h=r(l,"META",{name:!0,content:!0}),l.forEach(a),C=f(e),_=r(e,"H1",{class:!0});var G=s(_);v=r(G,"A",{id:!0,class:!0,href:!0});var ce=s(v);q=r(ce,"SPAN",{});var fe=s(q);qe(g.$$.fragment,fe),fe.forEach(a),ce.forEach(a),Q=f(G),P=r(G,"SPAN",{});var pe=s(P);F=p(pe,"Modelos decodificadores"),pe.forEach(a),G.forEach(a),N=f(e),qe(w.$$.fragment,e),U=f(e),E=r(e,"P",{});var H=s(E);K=p(H,"Os modelos de encoder (decodificadores) usam apenas o encoder de um modelo Transformer. Em cada est\xE1gio, as camadas de aten\xE7\xE3o podem acessar todas as palavras da frase inicial. Esses modelos geralmente s\xE3o caracterizados como tendo aten\xE7\xE3o \u201Cbidirecional\u201D e s\xE3o frequentemente chamados de "),B=r(H,"EM",{});var ue=s(B);V=p(ue,"modelos de codifica\xE7\xE3o autom\xE1tica"),ue.forEach(a),W=p(H,"."),H.forEach(a),z=f(e),T=r(e,"P",{});var he=s(T);X=p(he,"O pr\xE9-treinamento desses modelos geralmente gira em torno de corromper de alguma forma uma determinada frase (por exemplo, mascarando palavras aleat\xF3rias nela) e encarregando o modelo de encontrar ou reconstruir a frase inicial."),he.forEach(a),D=f(e),y=r(e,"P",{});var _e=s(y);Z=p(_e,"Os modelos de codificador s\xE3o mais adequados para tarefas que exigem uma compreens\xE3o da senten\xE7a completa, como classifica\xE7\xE3o de senten\xE7a, reconhecimento de entidade nomeada (e, mais geralmente, classifica\xE7\xE3o de palavras) e resposta extrativa de perguntas."),_e.forEach(a),J=f(e),b=r(e,"P",{});var ve=s(b);ee=p(ve,"Os representantes desta fam\xEDlia de modelos incluem:"),ve.forEach(a),Y=f(e),i=r(e,"UL",{});var u=s(i);O=r(u,"LI",{});var Ee=s(O);$=r(Ee,"A",{href:!0,rel:!0});var ge=s($);ae=p(ge,"ALBERT"),ge.forEach(a),Ee.forEach(a),oe=f(u),M=r(u,"LI",{});var we=s(M);x=r(we,"A",{href:!0,rel:!0});var $e=s(x);te=p($e,"BERT"),$e.forEach(a),we.forEach(a),re=f(u),I=r(u,"LI",{});var xe=s(I);A=r(xe,"A",{href:!0,rel:!0});var Ae=s(A);se=p(Ae,"DistilBERT"),Ae.forEach(a),xe.forEach(a),le=f(u),S=r(u,"LI",{});var Le=s(S);L=r(Le,"A",{href:!0,rel:!0});var Re=s(L);de=p(Re,"ELECTRA"),Re.forEach(a),Le.forEach(a),ie=f(u),k=r(u,"LI",{});var Te=s(k);R=r(Te,"A",{href:!0,rel:!0});var ye=s(R);ne=p(ye,"RoBERTa"),ye.forEach(a),Te.forEach(a),u.forEach(a),this.h()},h(){d(h,"name","hf:doc:metadata"),d(h,"content",JSON.stringify(Ye)),d(v,"id","modelos-decodificadores"),d(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),d(v,"href","#modelos-decodificadores"),d(_,"class","relative group"),d($,"href","https://huggingface.co/transformers/model_doc/albert.html"),d($,"rel","nofollow"),d(x,"href","https://huggingface.co/transformers/model_doc/bert.html"),d(x,"rel","nofollow"),d(A,"href","https://huggingface.co/transformers/model_doc/distilbert.html"),d(A,"rel","nofollow"),d(L,"href","https://huggingface.co/transformers/model_doc/electra.html"),d(L,"rel","nofollow"),d(R,"href","https://huggingface.co/transformers/model_doc/roberta.html"),d(R,"rel","nofollow")},m(e,l){o(document.head,h),n(e,C,l),n(e,_,l),o(_,v),o(v,q),Pe(g,q,null),o(_,Q),o(_,P),o(P,F),n(e,N,l),Pe(w,e,l),n(e,U,l),n(e,E,l),o(E,K),o(E,B),o(B,V),o(E,W),n(e,z,l),n(e,T,l),o(T,X),n(e,D,l),n(e,y,l),o(y,Z),n(e,J,l),n(e,b,l),o(b,ee),n(e,Y,l),n(e,i,l),o(i,O),o(O,$),o($,ae),o(i,oe),o(i,M),o(M,x),o(x,te),o(i,re),o(i,I),o(I,A),o(A,se),o(i,le),o(i,S),o(S,L),o(L,de),o(i,ie),o(i,k),o(k,R),o(R,ne),j=!0},p:Ne,i(e){j||(Be(g.$$.fragment,e),Be(w.$$.fragment,e),j=!0)},o(e){Oe(g.$$.fragment,e),Oe(w.$$.fragment,e),j=!1},d(e){a(h),e&&a(C),e&&a(_),Me(g),e&&a(N),Me(w,e),e&&a(U),e&&a(E),e&&a(z),e&&a(T),e&&a(D),e&&a(y),e&&a(J),e&&a(b),e&&a(Y),e&&a(i)}}}const Ye={local:"modelos-decodificadores",title:"Modelos decodificadores"};function je(me){return Ue(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Fe extends Ie{constructor(h){super();Se(this,h,je,Je,ke,{})}}export{Fe as default,Ye as metadata};
