import{S as kn,i as xn,s as _n,e as r,k as f,w as b,t as L,l as vn,M as bn,c as i,d as t,m as h,x as w,a,h as N,b as l,G as n,g as d,y,o as g,p as qn,q as k,B as A,v as wn,n as gn}from"../../chunks/vendor-hf-doc-builder.js";import{I as C}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as Ut}from"../../chunks/CodeBlock-hf-doc-builder.js";import{Q as H}from"../../chunks/Question-hf-doc-builder.js";import{F as yn}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function An(Q){let p,c,v,m,z,x,S,E,q,P;return m=new C({}),q=new H({props:{choices:[{text:"Un mod\xE8le qui s'entra\xEEne automatiquement sur vos donn\xE9es",explain:"Vous confondez cela avec notre produit <a href='https://huggingface.co/autotrain>AutoTrain</a>"},{text:"Un objet qui renvoie la bonne architecture bas\xE9e sur le <i>checkpoint</i> .",explain:"Exactement : <code>TFAutoModel</code> a seulement besoin de conna\xEEtre le <i>checkpoint</i> \xE0 partir duquel il doit s'initialiser pour retourner \xE0 la bonne architecture.",correct:!0},{text:"Un mod\xE8le qui d\xE9tecte automatiquement la langue utilis\xE9e pour ses entr\xE9es afin de charger les bonnes pond\xE9rations.",explain:"Bien que certains <i>checkpoints</i> et mod\xE8les soient capables de g\xE9rer plusieurs langues, il n'existe pas d'outils int\xE9gr\xE9s pour la s\xE9lection automatique des <i>checkpoints</i> en fonction de la langue. Vous devez vous rendre sur le <a href='https://huggingface.co/models'>Hub des mod\xE8les</a> pour trouver le meilleur <i>checkpoint</i> pour votre t\xE2che !"}]}}),{c(){p=r("h3"),c=r("a"),v=r("span"),b(m.$$.fragment),z=f(),x=r("span"),S=L("5. What is an AutoModel?"),E=f(),b(q.$$.fragment),this.h()},l(o){p=i(o,"H3",{class:!0});var _=a(p);c=i(_,"A",{id:!0,class:!0,href:!0});var s=a(c);v=i(s,"SPAN",{});var $=a(v);w(m.$$.fragment,$),$.forEach(t),s.forEach(t),z=h(_),x=i(_,"SPAN",{});var j=a(x);S=N(j,"5. What is an AutoModel?"),j.forEach(t),_.forEach(t),E=h(o),w(q.$$.fragment,o),this.h()},h(){l(c,"id","5.-what-is-an-automodel?"),l(c,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(c,"href","#5.-what-is-an-automodel?"),l(p,"class","relative group")},m(o,_){d(o,p,_),n(p,c),n(c,v),y(m,v,null),n(p,z),n(p,x),n(x,S),d(o,E,_),y(q,o,_),P=!0},i(o){P||(k(m.$$.fragment,o),k(q.$$.fragment,o),P=!0)},o(o){g(m.$$.fragment,o),g(q.$$.fragment,o),P=!1},d(o){o&&t(p),A(m),o&&t(E),A(q,o)}}}function En(Q){let p,c,v,m,z,x,S,E,q,P;return m=new C({}),q=new H({props:{choices:[{text:"Un mod\xE8le qui s'entra\xEEne automatiquement sur vos donn\xE9es",explain:"Vous confondez cela avec notre produit <a href='https://huggingface.co/autotrain>AutoTrain</a>"},{text:"Un objet qui renvoie la bonne architecture bas\xE9e sur le <i>checkpoint</i> .",explain:"Exactement : <code>AutoModel</code> a seulement besoin de conna\xEEtre le <i>checkpoint</i> \xE0 partir duquel il doit s'initialiser pour retourner \xE0 la bonne architecture.",correct:!0},{text:"Un mod\xE8le qui d\xE9tecte automatiquement la langue utilis\xE9e pour ses entr\xE9es afin de charger les bonnes pond\xE9rations.",explain:"Bien que certains <i>checkpoints</i> et mod\xE8les soient capables de g\xE9rer plusieurs langues, il n'existe pas d'outils int\xE9gr\xE9s pour la s\xE9lection automatique des <i>checkpoints</i> en fonction de la langue. Vous devez vous rendre sur le <a href='https://huggingface.co/models'>Hub des mod\xE8les</a> pour trouver le meilleur <i>checkpoint</i> pour votre t\xE2che !"}]}}),{c(){p=r("h3"),c=r("a"),v=r("span"),b(m.$$.fragment),z=f(),x=r("span"),S=L("5. Qu\u2019est-ce qu\u2019un AutoModel?"),E=f(),b(q.$$.fragment),this.h()},l(o){p=i(o,"H3",{class:!0});var _=a(p);c=i(_,"A",{id:!0,class:!0,href:!0});var s=a(c);v=i(s,"SPAN",{});var $=a(v);w(m.$$.fragment,$),$.forEach(t),s.forEach(t),z=h(_),x=i(_,"SPAN",{});var j=a(x);S=N(j,"5. Qu\u2019est-ce qu\u2019un AutoModel?"),j.forEach(t),_.forEach(t),E=h(o),w(q.$$.fragment,o),this.h()},h(){l(c,"id","5.-qu\u2019est-ce-qu\u2019un-automodel?"),l(c,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(c,"href","#5.-qu\u2019est-ce-qu\u2019un-automodel?"),l(p,"class","relative group")},m(o,_){d(o,p,_),n(p,c),n(c,v),y(m,v,null),n(p,z),n(p,x),n(x,S),d(o,E,_),y(q,o,_),P=!0},i(o){P||(k(m.$$.fragment,o),k(q.$$.fragment,o),P=!0)},o(o){g(m.$$.fragment,o),g(q.$$.fragment,o),P=!1},d(o){o&&t(p),A(m),o&&t(E),A(q,o)}}}function zn(Q){let p,c,v,m,z,x,S,E,q,P,o,_;return m=new C({}),q=new Ut({props:{code:`
`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModel

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;gpt2&quot;</span>)

encoded = tokenizer(<span class="hljs-string">&quot;Hey!&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
result = model(**encoded)`}}),o=new H({props:{choices:[{text:"Non, \xE7a semble correct.",explain:"Malheureusement, coupler un mod\xE8le avec un <i>tokenizer</i> qui a \xE9t\xE9 entra\xEEn\xE9 avec un <i>checkpoint</i> diff\xE9rent est rarement une bonne id\xE9e. Le mod\xE8le n'a pas \xE9t\xE9 entra\xEEn\xE9 pour donner du sens \xE0 la sortie de ce <i>tokenizer</i> donc la sortie du mod\xE8le (s'il peut m\xEAme fonctionner !) n'aura aucun sens."},{text:" Le <i>tokenizer</i> et le mod\xE8le doivent toujours provenir du m\xEAme <i>checkpoint</i>.",explain:"",correct:!0},{text:" C'est une bonne pratique de faire du <i>padding</i> et de troncage avec le <i>tokenizer</i> car chaque entr\xE9e est un batch.",explain:"Il est vrai que chaque entr\xE9e de mod\xE8le doit \xEAtre un batch. Cependant, tronquer ou compl\xE9ter cette s\xE9quence n'aurait pas n\xE9cessairement de sens puisqu'il n'y en a qu'une seule. Il s'agit l\xE0 de techniques permettant de mettre en batch une liste de phrases."}]}}),{c(){p=r("h3"),c=r("a"),v=r("span"),b(m.$$.fragment),z=f(),x=r("span"),S=L("10. Y a-t-il un probl\xE8me avec le code suivant ?"),E=f(),b(q.$$.fragment),P=f(),b(o.$$.fragment),this.h()},l(s){p=i(s,"H3",{class:!0});var $=a(p);c=i($,"A",{id:!0,class:!0,href:!0});var j=a(c);v=i(j,"SPAN",{});var M=a(v);w(m.$$.fragment,M),M.forEach(t),j.forEach(t),z=h($),x=i($,"SPAN",{});var F=a(x);S=N(F,"10. Y a-t-il un probl\xE8me avec le code suivant ?"),F.forEach(t),$.forEach(t),E=h(s),w(q.$$.fragment,s),P=h(s),w(o.$$.fragment,s),this.h()},h(){l(c,"id","10.-y-a-t-il-un-probl\xE8me-avec-le-code-suivant-?"),l(c,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(c,"href","#10.-y-a-t-il-un-probl\xE8me-avec-le-code-suivant-?"),l(p,"class","relative group")},m(s,$){d(s,p,$),n(p,c),n(c,v),y(m,v,null),n(p,z),n(p,x),n(x,S),d(s,E,$),y(q,s,$),d(s,P,$),y(o,s,$),_=!0},i(s){_||(k(m.$$.fragment,s),k(q.$$.fragment,s),k(o.$$.fragment,s),_=!0)},o(s){g(m.$$.fragment,s),g(q.$$.fragment,s),g(o.$$.fragment,s),_=!1},d(s){s&&t(p),A(m),s&&t(E),A(q,s),s&&t(P),A(o,s)}}}function Pn(Q){let p,c,v,m,z,x,S,E,q,P,o,_;return m=new C({}),q=new Ut({props:{code:`
`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModel

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
model = AutoModel.from_pretrained(<span class="hljs-string">&quot;gpt2&quot;</span>)

encoded = tokenizer(<span class="hljs-string">&quot;Hey!&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
result = model(**encoded)`}}),o=new H({props:{choices:[{text:"Non, \xE7a semble correct.",explain:"Malheureusement, coupler un mod\xE8le avec un <i>tokenizer</i> qui a \xE9t\xE9 entra\xEEn\xE9 avec un <i>checkpoint</i> diff\xE9rent est rarement une bonne id\xE9e. Le mod\xE8le n'a pas \xE9t\xE9 entra\xEEn\xE9 pour donner du sens \xE0 la sortie de ce <i>tokenizer</i> donc la sortie du mod\xE8le (s'il peut m\xEAme fonctionner !) n'aura aucun sens."},{text:" Le <i>tokenizer</i> et le mod\xE8le doivent toujours provenir du m\xEAme <i>checkpoint</i>.",explain:"",correct:!0},{text:" C'est une bonne pratique de faire du <i>padding</i> et de troncage avec le <i>tokenizer</i> car chaque entr\xE9e est un batch.",explain:"Il est vrai que chaque entr\xE9e de mod\xE8le doit \xEAtre un batch. Cependant, tronquer ou compl\xE9ter cette s\xE9quence n'aurait pas n\xE9cessairement de sens puisqu'il n'y en a qu'une seule. Il s'agit l\xE0 de techniques permettant de mettre en batch une liste de phrases."}]}}),{c(){p=r("h3"),c=r("a"),v=r("span"),b(m.$$.fragment),z=f(),x=r("span"),S=L("10. Y a-t-il un probl\xE8me avec le code suivant ?"),E=f(),b(q.$$.fragment),P=f(),b(o.$$.fragment),this.h()},l(s){p=i(s,"H3",{class:!0});var $=a(p);c=i($,"A",{id:!0,class:!0,href:!0});var j=a(c);v=i(j,"SPAN",{});var M=a(v);w(m.$$.fragment,M),M.forEach(t),j.forEach(t),z=h($),x=i($,"SPAN",{});var F=a(x);S=N(F,"10. Y a-t-il un probl\xE8me avec le code suivant ?"),F.forEach(t),$.forEach(t),E=h(s),w(q.$$.fragment,s),P=h(s),w(o.$$.fragment,s),this.h()},h(){l(c,"id","10.-y-a-t-il-un-probl\xE8me-avec-le-code-suivant-?"),l(c,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(c,"href","#10.-y-a-t-il-un-probl\xE8me-avec-le-code-suivant-?"),l(p,"class","relative group")},m(s,$){d(s,p,$),n(p,c),n(c,v),y(m,v,null),n(p,z),n(p,x),n(x,S),d(s,E,$),y(q,s,$),d(s,P,$),y(o,s,$),_=!0},i(s){_||(k(m.$$.fragment,s),k(q.$$.fragment,s),k(o.$$.fragment,s),_=!0)},o(s){g(m.$$.fragment,s),g(q.$$.fragment,s),g(o.$$.fragment,s),_=!1},d(s){s&&t(p),A(m),s&&t(E),A(q,s),s&&t(P),A(o,s)}}}function Sn(Q){let p,c,v,m,z,x,S,E,q,P,o,_,s,$,j,M,F,Pe,gt,Ve,se,Ye,O,J,Se,re,kt,ie,xt,Le,_t,bt,We,oe,De,V,K,Ne,ae,wt,je,yt,Re,le,Ge,Y,X,Me,ue,At,Ce,Et,Je,pe,Ke,T,I,ye,W,Z,He,ce,zt,Qe,Pt,Xe,de,Ze,D,ee,Te,fe,St,Ie,Lt,et,he,tt,R,te,Ue,me,Nt,$e,jt,Be,Mt,Ct,nt,ve,st,G,ne,Fe,qe,Ht,ge,Qt,Oe,Tt,It,rt,ke,it,xe,ot,U,B,Ae,at;v=new yn({props:{fw:Q[0]}}),E=new C({}),M=new C({}),se=new H({props:{choices:[{text:" Tout d'abord, le mod\xE8le, qui traite le texte et renvoie des pr\xE9dictions brutes. Puis le <i>tokenizer</i> donne un sens \xE0 ces pr\xE9dictions et les reconvertit en texte si n\xE9cessaire.",explain:" Le mod\xE8le ne peut pas comprendre le texte ! Le <i>tokenizer</i> doit d'abord tokeniser le texte et le convertir en identifiants afin qu'il soit compr\xE9hensible par le mod\xE8le."},{text:" Tout d'abord, le <i>tokenizer</i>, qui traite le texte et renvoie des identifiants. Puis le mod\xE8le traite ces identifiants et produit une pr\xE9diction, qui peut \xEAtre du texte.",explain:" La pr\xE9diction du mod\xE8le ne peut pas \xEAtre du texte imm\xE9diatement. Le <i>tokenizer</i> doit \xEAtre utilis\xE9 afin de reconvertir la pr\xE9diction en texte !"},{text:" Le <i>tokenizer</i> traite le texte et renvoie des identifiants. Le mod\xE8le traite ces identifiants et produit une pr\xE9diction. Le <i>tokenizer</i> peut alors \xEAtre utilis\xE9 \xE0 nouveau pour reconvertir ces pr\xE9dictions en texte.",explain:" Le <i>tokenizer</i> peut \xEAtre utilis\xE9 \xE0 la fois pour la tokenisation et la d\xE9-tok\xE9nisation.",correct:!0}]}}),re=new C({}),oe=new H({props:{choices:[{text:"2: la longueur de la s\xE9quence et la taille du batch",explain:"Le tenseur produit par le mod\xE8le poss\xE8de une troisi\xE8me dimension : la taille cach\xE9e."},{text:"2: la longueur de la s\xE9quence et la taille cach\xE9e",explain:"Tous les <i>transformers</i>  g\xE8rent les batchs, m\xEAme avec une seule s\xE9quence ce serait une taille de batch de 1 !"},{text:"3: la longueur de la s\xE9quence, la taille du batch et la taille cach\xE9e.",explain:"",correct:!0}]}}),ae=new C({}),le=new H({props:{choices:[{text:"WordPiece",explain:"Oui, c'est un exemple de tokenisation en sous-mots !",correct:!0},{text:"La tokenization bas\xE9e sur les caract\xE8res",explain:"La tokenization bas\xE9e sur les caract\xE8res n\u2019est pas un type de tokenisation en sous-mots."},{text:"D\xE9coupage sur les espaces et la ponctuation",explain:"C\u2019est une tokenisation bas\xE9e sur les mots !"},{text:"BPE",explain:"Oui, c'est un exemple de tokenisation en sous-mots !",correct:!0},{text:"Unigram",explain:"Oui, c'est un exemple de tokenisation en sous-mots !",correct:!0},{text:"Aucune des propositions ci-dessus",explain:""}]}}),ue=new C({}),pe=new H({props:{choices:[{text:" Un composant du <i>transformer</i>  de base qui redirige les tenseurs vers leurs couches correctes.",explain:"Il n'y a pas de tel composant."},{text:"\xC9galement connu sous le nom de m\xE9canisme d'auto-attention, il adapte la repr\xE9sentation d'un <i>token</i>  en fonction des autres <i>tokens</i>  de la s\xE9quence.",explain:"La couche d'auto-attention contient des t\xEAtes d'attention mais ce ne sont pas des t\xEAtes d'adaptation."},{text:"Un composant suppl\xE9mentaire, g\xE9n\xE9ralement constitu\xE9 d'une ou plusieurs couches, pour convertir les pr\xE9dictions du <i>transformer</i>  en une sortie sp\xE9cifique \xE0 la t\xE2che.",explain:"Les t\xEAtes d'adaptation, aussi appel\xE9es simplement t\xEAtes, se pr\xE9sentent sous diff\xE9rentes formes : t\xEAtes de mod\xE9lisation du langage, t\xEAtes de r\xE9ponse aux questions, t\xEAtes de classification des s\xE9quences, etc.",correct:!0}]}});const Bt=[En,An],_e=[];function Ft(e,u){return e[0]==="pt"?0:1}T=Ft(Q),I=_e[T]=Bt[T](Q),ce=new C({}),de=new H({props:{choices:[{text:"La troncature",explain:" La troncature est une fa\xE7on correcte d'\xE9galiser les s\xE9quences pour qu'elles s'inscrivent dans une forme rectangulaire. Mais est-ce la seule ?",correct:!0},{text:"Retourner les tenseurs",explain:"Alors que les autres techniques vous permettent de renvoyer des tenseurs rectangulaires, retourner les tenseurs n'est pas utile lorsque vous mettez en batch des s\xE9quences."},{text:"Le <i>padding</i>",explain:"Le <i>padding</i> est une fa\xE7on correcte d'\xE9galiser les s\xE9quences pour qu'elles tiennent dans une forme rectangulaire. Mais est-ce le seul moyen ?",correct:!0},{text:"Les masques d'attention ",explain:"Les masques d'attention sont d'une importance capitale lorsqu'on manipule des s\xE9quences de longueurs diff\xE9rentes. Ce n'est cependant pas la seule technique \xE0 laquelle il faut faire attention.",correct:!0}]}}),fe=new C({}),he=new H({props:{choices:[{text:"Elle adoucit les logits pour qu'ils soient plus fiables.",explain:"La fonction SoftMax n'affecte pas la fiabilit\xE9 des r\xE9sultats."},{text:"Elle applique une limite inf\xE9rieure et sup\xE9rieure pour qu'ils soient compr\xE9hensibles.",explain:"Les valeurs r\xE9sultantes sont comprises entre 0 et 1. Ce n'est cependant pas la seule raison pour laquelle nous utilisons une fonction SoftMax.",correct:!0},{text:"La somme totale des sorties est alors \xE9gale \xE0 1, ce qui permet une interpr\xE9tation probabiliste.",explain:"Mais ce n'est pas la seule raison pour laquelle nous utilisons une fonction SoftMax.",correct:!0}]}}),me=new C({}),ve=new H({props:{choices:[{text:"<code>encode</code>, car elle peut encoder du texte en identifiants et des identifiants en pr\xE9dictions.",explain:"Bien que la m\xE9thode <code>encode</code> existe sur les <i>tokenizer</i>, elle n'existe pas sur les mod\xE8les."},{text:"Appeler directement l'objet tokenizer",explain:"La m\xE9thode <code>__call__</code> du <i>tokenizer</i> est une m\xE9thode tr\xE8s puissante qui peut traiter \xE0 peu pr\xE8s tout. C'est \xE9galement la m\xE9thode utilis\xE9e pour r\xE9cup\xE9rer les pr\xE9dictions d'un mod\xE8le.",correct:!0},{text:"<code>pad</code>",explain:"Le <i>padding</i> est tr\xE8s utile mais ce n'est qu'une partie de l'API <i>tokenizer</i>."},{text:"<code>tokenize</code>",explain:"La m\xE9thode <code>tokenize</code> est est sans doute l'une des m\xE9thodes les plus utiles, mais elle ne constitue pas le c\u0153ur de l'API <i>tokenizer</i>."}]}}),qe=new C({}),ke=new Ut({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
result = tokenizer.tokenize(<span class="hljs-string">&quot;Hello!&quot;</span>)`}}),xe=new H({props:{choices:[{text:"Une liste de cha\xEEnes de caract\xE8res, chaque cha\xEEne \xE9tant un <i>token</i>.",explain:"Convertissez cela en identifiants, et donnez-les \xE0 un mod\xE8le !",correct:!0},{text:"Une liste d'identifiants",explain:"C'est \xE0 cela que la m\xE9thode <code>__call__</code> ou la m\xE9thode <code>convert_tokens_to_ids</code> sert !"},{text:"Une cha\xEEne contenant tous les <i>tokens</i>",explain:"Ce serait sous-optimal car le but est de diviser la cha\xEEne de caract\xE8res en plusieurs \xE9l\xE9ments."}]}});const Ot=[Pn,zn],be=[];function Vt(e,u){return e[0]==="pt"?0:1}return U=Vt(Q),B=be[U]=Ot[U](Q),{c(){p=r("meta"),c=f(),b(v.$$.fragment),m=f(),z=r("h1"),x=r("a"),S=r("span"),b(E.$$.fragment),q=f(),P=r("span"),o=L("Quiz de fin de chapitre"),_=f(),s=r("h3"),$=r("a"),j=r("span"),b(M.$$.fragment),F=f(),Pe=r("span"),gt=L("1. Quel est l\u2019ordre du pipeline de mod\xE9lisation du langage ?"),Ve=f(),b(se.$$.fragment),Ye=f(),O=r("h3"),J=r("a"),Se=r("span"),b(re.$$.fragment),kt=f(),ie=r("span"),xt=L("2. Combien de dimensions le tenseur produit par le "),Le=r("i"),_t=L("transformer"),bt=L(" de base poss\xE8de-t-il et quelles sont-elles ?"),We=f(),b(oe.$$.fragment),De=f(),V=r("h3"),K=r("a"),Ne=r("span"),b(ae.$$.fragment),wt=f(),je=r("span"),yt=L("3. Lequel des \xE9l\xE9ments suivants est un exemple de tokenisation en sous-mots ?"),Re=f(),b(le.$$.fragment),Ge=f(),Y=r("h3"),X=r("a"),Me=r("span"),b(ue.$$.fragment),At=f(),Ce=r("span"),Et=L("4. Qu\u2019est-ce qu\u2019une t\xEAte de mod\xE8le ?"),Je=f(),b(pe.$$.fragment),Ke=f(),I.c(),ye=f(),W=r("h3"),Z=r("a"),He=r("span"),b(ce.$$.fragment),zt=f(),Qe=r("span"),Pt=L("6. Quelles sont les techniques \xE0 conna\xEEtre lors de la mise en batch de s\xE9quences de longueurs diff\xE9rentes ?"),Xe=f(),b(de.$$.fragment),Ze=f(),D=r("h3"),ee=r("a"),Te=r("span"),b(fe.$$.fragment),St=f(),Ie=r("span"),Lt=L("7. Quel est l\u2019int\xE9r\xEAt d\u2019appliquer une fonction SoftMax aux logits produits par un mod\xE8le de classification de s\xE9quences ?"),et=f(),b(he.$$.fragment),tt=f(),R=r("h3"),te=r("a"),Ue=r("span"),b(me.$$.fragment),Nt=f(),$e=r("span"),jt=L("8. Autour de quelle m\xE9thode s\u2019articule la majeure partie de l\u2019API "),Be=r("i"),Mt=L("tokenizer"),Ct=L(" ?"),nt=f(),b(ve.$$.fragment),st=f(),G=r("h3"),ne=r("a"),Fe=r("span"),b(qe.$$.fragment),Ht=f(),ge=r("span"),Qt=L("9. Que contient la variable "),Oe=r("code"),Tt=L("result"),It=L(" dans cet exemple de code ?"),rt=f(),b(ke.$$.fragment),it=f(),b(xe.$$.fragment),ot=f(),B.c(),Ae=vn(),this.h()},l(e){const u=bn('[data-svelte="svelte-1phssyn"]',document.head);p=i(u,"META",{name:!0,content:!0}),u.forEach(t),c=h(e),w(v.$$.fragment,e),m=h(e),z=i(e,"H1",{class:!0});var we=a(z);x=i(we,"A",{id:!0,class:!0,href:!0});var Ee=a(x);S=i(Ee,"SPAN",{});var ze=a(S);w(E.$$.fragment,ze),ze.forEach(t),Ee.forEach(t),q=h(we),P=i(we,"SPAN",{});var Yt=a(P);o=N(Yt,"Quiz de fin de chapitre"),Yt.forEach(t),we.forEach(t),_=h(e),s=i(e,"H3",{class:!0});var lt=a(s);$=i(lt,"A",{id:!0,class:!0,href:!0});var Wt=a($);j=i(Wt,"SPAN",{});var Dt=a(j);w(M.$$.fragment,Dt),Dt.forEach(t),Wt.forEach(t),F=h(lt),Pe=i(lt,"SPAN",{});var Rt=a(Pe);gt=N(Rt,"1. Quel est l\u2019ordre du pipeline de mod\xE9lisation du langage ?"),Rt.forEach(t),lt.forEach(t),Ve=h(e),w(se.$$.fragment,e),Ye=h(e),O=i(e,"H3",{class:!0});var ut=a(O);J=i(ut,"A",{id:!0,class:!0,href:!0});var Gt=a(J);Se=i(Gt,"SPAN",{});var Jt=a(Se);w(re.$$.fragment,Jt),Jt.forEach(t),Gt.forEach(t),kt=h(ut),ie=i(ut,"SPAN",{});var pt=a(ie);xt=N(pt,"2. Combien de dimensions le tenseur produit par le "),Le=i(pt,"I",{});var Kt=a(Le);_t=N(Kt,"transformer"),Kt.forEach(t),bt=N(pt," de base poss\xE8de-t-il et quelles sont-elles ?"),pt.forEach(t),ut.forEach(t),We=h(e),w(oe.$$.fragment,e),De=h(e),V=i(e,"H3",{class:!0});var ct=a(V);K=i(ct,"A",{id:!0,class:!0,href:!0});var Xt=a(K);Ne=i(Xt,"SPAN",{});var Zt=a(Ne);w(ae.$$.fragment,Zt),Zt.forEach(t),Xt.forEach(t),wt=h(ct),je=i(ct,"SPAN",{});var en=a(je);yt=N(en,"3. Lequel des \xE9l\xE9ments suivants est un exemple de tokenisation en sous-mots ?"),en.forEach(t),ct.forEach(t),Re=h(e),w(le.$$.fragment,e),Ge=h(e),Y=i(e,"H3",{class:!0});var dt=a(Y);X=i(dt,"A",{id:!0,class:!0,href:!0});var tn=a(X);Me=i(tn,"SPAN",{});var nn=a(Me);w(ue.$$.fragment,nn),nn.forEach(t),tn.forEach(t),At=h(dt),Ce=i(dt,"SPAN",{});var sn=a(Ce);Et=N(sn,"4. Qu\u2019est-ce qu\u2019une t\xEAte de mod\xE8le ?"),sn.forEach(t),dt.forEach(t),Je=h(e),w(pe.$$.fragment,e),Ke=h(e),I.l(e),ye=h(e),W=i(e,"H3",{class:!0});var ft=a(W);Z=i(ft,"A",{id:!0,class:!0,href:!0});var rn=a(Z);He=i(rn,"SPAN",{});var on=a(He);w(ce.$$.fragment,on),on.forEach(t),rn.forEach(t),zt=h(ft),Qe=i(ft,"SPAN",{});var an=a(Qe);Pt=N(an,"6. Quelles sont les techniques \xE0 conna\xEEtre lors de la mise en batch de s\xE9quences de longueurs diff\xE9rentes ?"),an.forEach(t),ft.forEach(t),Xe=h(e),w(de.$$.fragment,e),Ze=h(e),D=i(e,"H3",{class:!0});var ht=a(D);ee=i(ht,"A",{id:!0,class:!0,href:!0});var ln=a(ee);Te=i(ln,"SPAN",{});var un=a(Te);w(fe.$$.fragment,un),un.forEach(t),ln.forEach(t),St=h(ht),Ie=i(ht,"SPAN",{});var pn=a(Ie);Lt=N(pn,"7. Quel est l\u2019int\xE9r\xEAt d\u2019appliquer une fonction SoftMax aux logits produits par un mod\xE8le de classification de s\xE9quences ?"),pn.forEach(t),ht.forEach(t),et=h(e),w(he.$$.fragment,e),tt=h(e),R=i(e,"H3",{class:!0});var mt=a(R);te=i(mt,"A",{id:!0,class:!0,href:!0});var cn=a(te);Ue=i(cn,"SPAN",{});var dn=a(Ue);w(me.$$.fragment,dn),dn.forEach(t),cn.forEach(t),Nt=h(mt),$e=i(mt,"SPAN",{});var $t=a($e);jt=N($t,"8. Autour de quelle m\xE9thode s\u2019articule la majeure partie de l\u2019API "),Be=i($t,"I",{});var fn=a(Be);Mt=N(fn,"tokenizer"),fn.forEach(t),Ct=N($t," ?"),$t.forEach(t),mt.forEach(t),nt=h(e),w(ve.$$.fragment,e),st=h(e),G=i(e,"H3",{class:!0});var vt=a(G);ne=i(vt,"A",{id:!0,class:!0,href:!0});var hn=a(ne);Fe=i(hn,"SPAN",{});var mn=a(Fe);w(qe.$$.fragment,mn),mn.forEach(t),hn.forEach(t),Ht=h(vt),ge=i(vt,"SPAN",{});var qt=a(ge);Qt=N(qt,"9. Que contient la variable "),Oe=i(qt,"CODE",{});var $n=a(Oe);Tt=N($n,"result"),$n.forEach(t),It=N(qt," dans cet exemple de code ?"),qt.forEach(t),vt.forEach(t),rt=h(e),w(ke.$$.fragment,e),it=h(e),w(xe.$$.fragment,e),ot=h(e),B.l(e),Ae=vn(),this.h()},h(){l(p,"name","hf:doc:metadata"),l(p,"content",JSON.stringify(Ln)),l(x,"id","quiz-de-fin-de-chapitre"),l(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(x,"href","#quiz-de-fin-de-chapitre"),l(z,"class","relative group"),l($,"id","1.-quel-est-l\u2019ordre-du-pipeline-de-mod\xE9lisation-du-langage-?"),l($,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l($,"href","#1.-quel-est-l\u2019ordre-du-pipeline-de-mod\xE9lisation-du-langage-?"),l(s,"class","relative group"),l(J,"id","2.-combien-de-dimensions-le-tenseur-produit-par-le-<i>transformer</i>-de-base-poss\xE8de-t-il-et-quelles-sont-elles-?"),l(J,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(J,"href","#2.-combien-de-dimensions-le-tenseur-produit-par-le-<i>transformer</i>-de-base-poss\xE8de-t-il-et-quelles-sont-elles-?"),l(O,"class","relative group"),l(K,"id","3.-lequel-des-\xE9l\xE9ments-suivants-est-un-exemple-de-tokenisation-en-sous-mots-?"),l(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(K,"href","#3.-lequel-des-\xE9l\xE9ments-suivants-est-un-exemple-de-tokenisation-en-sous-mots-?"),l(V,"class","relative group"),l(X,"id","4.-qu\u2019est-ce-qu\u2019une-t\xEAte-de-mod\xE8le-?"),l(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(X,"href","#4.-qu\u2019est-ce-qu\u2019une-t\xEAte-de-mod\xE8le-?"),l(Y,"class","relative group"),l(Z,"id","6.-quelles-sont-les-techniques-\xE0-conna\xEEtre-lors-de-la-mise-en-batch-de-s\xE9quences-de-longueurs-diff\xE9rentes-?"),l(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(Z,"href","#6.-quelles-sont-les-techniques-\xE0-conna\xEEtre-lors-de-la-mise-en-batch-de-s\xE9quences-de-longueurs-diff\xE9rentes-?"),l(W,"class","relative group"),l(ee,"id","7.-quel-est-l\u2019int\xE9r\xEAt-d\u2019appliquer-une-fonction-softmax-aux-logits-produits-par-un-mod\xE8le-de-classification-de-s\xE9quences-?"),l(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(ee,"href","#7.-quel-est-l\u2019int\xE9r\xEAt-d\u2019appliquer-une-fonction-softmax-aux-logits-produits-par-un-mod\xE8le-de-classification-de-s\xE9quences-?"),l(D,"class","relative group"),l(te,"id","8.-autour-de-quelle-m\xE9thode-s\u2019articule-la-majeure-partie-de-l\u2019api-<i>tokenizer</i>-?"),l(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(te,"href","#8.-autour-de-quelle-m\xE9thode-s\u2019articule-la-majeure-partie-de-l\u2019api-<i>tokenizer</i>-?"),l(R,"class","relative group"),l(ne,"id","9.-que-contient-la-variable-<code>result</code>-dans-cet-exemple-de-code-?"),l(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(ne,"href","#9.-que-contient-la-variable-<code>result</code>-dans-cet-exemple-de-code-?"),l(G,"class","relative group")},m(e,u){n(document.head,p),d(e,c,u),y(v,e,u),d(e,m,u),d(e,z,u),n(z,x),n(x,S),y(E,S,null),n(z,q),n(z,P),n(P,o),d(e,_,u),d(e,s,u),n(s,$),n($,j),y(M,j,null),n(s,F),n(s,Pe),n(Pe,gt),d(e,Ve,u),y(se,e,u),d(e,Ye,u),d(e,O,u),n(O,J),n(J,Se),y(re,Se,null),n(O,kt),n(O,ie),n(ie,xt),n(ie,Le),n(Le,_t),n(ie,bt),d(e,We,u),y(oe,e,u),d(e,De,u),d(e,V,u),n(V,K),n(K,Ne),y(ae,Ne,null),n(V,wt),n(V,je),n(je,yt),d(e,Re,u),y(le,e,u),d(e,Ge,u),d(e,Y,u),n(Y,X),n(X,Me),y(ue,Me,null),n(Y,At),n(Y,Ce),n(Ce,Et),d(e,Je,u),y(pe,e,u),d(e,Ke,u),_e[T].m(e,u),d(e,ye,u),d(e,W,u),n(W,Z),n(Z,He),y(ce,He,null),n(W,zt),n(W,Qe),n(Qe,Pt),d(e,Xe,u),y(de,e,u),d(e,Ze,u),d(e,D,u),n(D,ee),n(ee,Te),y(fe,Te,null),n(D,St),n(D,Ie),n(Ie,Lt),d(e,et,u),y(he,e,u),d(e,tt,u),d(e,R,u),n(R,te),n(te,Ue),y(me,Ue,null),n(R,Nt),n(R,$e),n($e,jt),n($e,Be),n(Be,Mt),n($e,Ct),d(e,nt,u),y(ve,e,u),d(e,st,u),d(e,G,u),n(G,ne),n(ne,Fe),y(qe,Fe,null),n(G,Ht),n(G,ge),n(ge,Qt),n(ge,Oe),n(Oe,Tt),n(ge,It),d(e,rt,u),y(ke,e,u),d(e,it,u),y(xe,e,u),d(e,ot,u),be[U].m(e,u),d(e,Ae,u),at=!0},p(e,[u]){const we={};u&1&&(we.fw=e[0]),v.$set(we);let Ee=T;T=Ft(e),T!==Ee&&(gn(),g(_e[Ee],1,1,()=>{_e[Ee]=null}),qn(),I=_e[T],I||(I=_e[T]=Bt[T](e),I.c()),k(I,1),I.m(ye.parentNode,ye));let ze=U;U=Vt(e),U!==ze&&(gn(),g(be[ze],1,1,()=>{be[ze]=null}),qn(),B=be[U],B||(B=be[U]=Ot[U](e),B.c()),k(B,1),B.m(Ae.parentNode,Ae))},i(e){at||(k(v.$$.fragment,e),k(E.$$.fragment,e),k(M.$$.fragment,e),k(se.$$.fragment,e),k(re.$$.fragment,e),k(oe.$$.fragment,e),k(ae.$$.fragment,e),k(le.$$.fragment,e),k(ue.$$.fragment,e),k(pe.$$.fragment,e),k(I),k(ce.$$.fragment,e),k(de.$$.fragment,e),k(fe.$$.fragment,e),k(he.$$.fragment,e),k(me.$$.fragment,e),k(ve.$$.fragment,e),k(qe.$$.fragment,e),k(ke.$$.fragment,e),k(xe.$$.fragment,e),k(B),at=!0)},o(e){g(v.$$.fragment,e),g(E.$$.fragment,e),g(M.$$.fragment,e),g(se.$$.fragment,e),g(re.$$.fragment,e),g(oe.$$.fragment,e),g(ae.$$.fragment,e),g(le.$$.fragment,e),g(ue.$$.fragment,e),g(pe.$$.fragment,e),g(I),g(ce.$$.fragment,e),g(de.$$.fragment,e),g(fe.$$.fragment,e),g(he.$$.fragment,e),g(me.$$.fragment,e),g(ve.$$.fragment,e),g(qe.$$.fragment,e),g(ke.$$.fragment,e),g(xe.$$.fragment,e),g(B),at=!1},d(e){t(p),e&&t(c),A(v,e),e&&t(m),e&&t(z),A(E),e&&t(_),e&&t(s),A(M),e&&t(Ve),A(se,e),e&&t(Ye),e&&t(O),A(re),e&&t(We),A(oe,e),e&&t(De),e&&t(V),A(ae),e&&t(Re),A(le,e),e&&t(Ge),e&&t(Y),A(ue),e&&t(Je),A(pe,e),e&&t(Ke),_e[T].d(e),e&&t(ye),e&&t(W),A(ce),e&&t(Xe),A(de,e),e&&t(Ze),e&&t(D),A(fe),e&&t(et),A(he,e),e&&t(tt),e&&t(R),A(me),e&&t(nt),A(ve,e),e&&t(st),e&&t(G),A(qe),e&&t(rt),A(ke,e),e&&t(it),A(xe,e),e&&t(ot),be[U].d(e),e&&t(Ae)}}}const Ln={local:"quiz-de-fin-de-chapitre",title:"Quiz de fin de chapitre"};function Nn(Q,p,c){let v="pt";return wn(()=>{const m=new URLSearchParams(window.location.search);c(0,v=m.get("fw")||"pt")}),[v]}class Tn extends kn{constructor(p){super();xn(this,p,Nn,Sn,_n,{})}}export{Tn as default,Ln as metadata};
