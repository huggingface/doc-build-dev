<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;introduccin&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;te-damos-la-bienvenida-al-curso-de&quot;,&quot;title&quot;:&quot;Â¡Te damos la bienvenida al curso de ğŸ¤—!&quot;},{&quot;local&quot;:&quot;qu-esperar&quot;,&quot;title&quot;:&quot;Â¿QuÃ© esperar?&quot;},{&quot;local&quot;:&quot;quines-somos&quot;,&quot;title&quot;:&quot;Â¿QuiÃ©nes somos?&quot;}],&quot;title&quot;:&quot;IntroducciÃ³n&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/course/pr_193/es/_app/assets/pages/__layout.svelte-048423b6.css">
	<link rel="modulepreload" href="/docs/course/pr_193/es/_app/start-8c481fdb.js">
	<link rel="modulepreload" href="/docs/course/pr_193/es/_app/chunks/vendor-1e8b365d.js">
	<link rel="modulepreload" href="/docs/course/pr_193/es/_app/chunks/paths-4b3c6e7e.js">
	<link rel="modulepreload" href="/docs/course/pr_193/es/_app/pages/__layout.svelte-05c2fb0c.js">
	<link rel="modulepreload" href="/docs/course/pr_193/es/_app/pages/chapter1/1.mdx-0dab120b.js">
	<link rel="modulepreload" href="/docs/course/pr_193/es/_app/chunks/Youtube-c2a8cc39.js">
	<link rel="modulepreload" href="/docs/course/pr_193/es/_app/chunks/IconCopyLink-483c28ba.js"> 





<h1 class="relative group"><a id="introduccin" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#introduccin"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>IntroducciÃ³n
	</span></h1>

<h2 class="relative group"><a id="te-damos-la-bienvenida-al-curso-de" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#te-damos-la-bienvenida-al-curso-de"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Â¡Te damos la bienvenida al curso de ğŸ¤—!
	</span></h2>

<iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/00GKzGyWFEs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p>Este curso te enseÃ±arÃ¡ sobre procesamiento de lenguaje natural (PLN) usando librerÃ­as del ecosistema <a href="https://huggingface.co/" rel="nofollow">Hugging Face</a> - <a href="https://github.com/huggingface/transformers" rel="nofollow">ğŸ¤— Transformers</a>, <a href="https://github.com/huggingface/datasets" rel="nofollow">ğŸ¤— Datasets</a>, <a href="https://github.com/huggingface/tokenizers" rel="nofollow">ğŸ¤— Tokenizers</a> y <a href="https://github.com/huggingface/accelerate" rel="nofollow">ğŸ¤— Accelerate</a> â€” asÃ­ como el <a href="https://huggingface.co/models" rel="nofollow">Hub de Hugging Face</a>. El curso es completamente gratuito y sin anuncios.</p>
<h2 class="relative group"><a id="qu-esperar" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#qu-esperar"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Â¿QuÃ© esperar?
	</span></h2>

<p>Esta es una pequeÃ±a descripciÃ³n del curso:</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg" alt="Brief overview of the chapters of the course.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg" alt="Brief overview of the chapters of the course."></div>
<ul><li>Los capÃ­tulos 1 a 4 ofrecen una introducciÃ³n a los conceptos principales de la librerÃ­a ğŸ¤— Transformers. Al final de esta secciÃ³n del curso, estarÃ¡s familiarizado con la manera en que trabajan los Transformadores y sabrÃ¡s cÃ³mo usar un modelo del <a href="https://huggingface.co/models" rel="nofollow">Hub de Hugging Face</a>, ajustarlo a tu conjunto de datos y compartir tus resultados en el Hub.</li>
<li>Los capÃ­tulos 5 a 8 enseÃ±an lo bÃ¡sico de ğŸ¤— Datasets y ğŸ¤— Tokenizers antes de entrar en tareas clÃ¡sicas de PLN. Al final de esta secciÃ³n, podrÃ¡s abordar por ti mismo los problemas mÃ¡s comunes de PLN.</li>
<li>Los capÃ­tulos 9 al 12 van mÃ¡s allÃ¡ del PLN y exploran cÃ³mo los Transformadores pueden abordar tareas de procesamiento del habla y visiÃ³n por computador. A lo largo del camino, aprenderÃ¡s a construir y compartir demos de tus modelos, asÃ­ como optimizarlos para entornos de producciÃ³n. Al final de esta secciÃ³n, estarÃ¡s listo para aplicar ğŸ¤— Transformers a (casi) cualquier problema de Machine Learning.</li></ul>
<p>Este curso:</p>
<ul><li>Requiere amplio conocimiento de Python</li>
<li>DeberÃ­a ser tomado despuÃ©s de un curso de introducciÃ³n a deep learning, como <a href="https://course.fast.ai/" rel="nofollow">Practical Deep Learning for Coders</a> de <a href="https://www.fast.ai/" rel="nofollow">fast.aiâ€™s</a> o alguno de los programas desarrollados por <a href="https://www.deeplearning.ai/" rel="nofollow">DeepLearning.AI</a></li>
<li>No necesita conocimiento previo de <a href="https://pytorch.org/" rel="nofollow">PyTorch</a> o <a href="https://www.tensorflow.org/" rel="nofollow">TensorFlow</a>, aunque un nivel de familiaridad con alguno de los dos podrÃ­a ser Ãºtil</li></ul>
<p>DespuÃ©s de que hayas completado este curso, te recomendamos revisar la <a href="https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-PLN-2-hugging_face-page-PLN-refresh" rel="nofollow">EspecializaciÃ³n en Procesamiento de Lenguaje Natural</a> de DeepLearning.AI, que cubre un gran nÃºmero de modelos tradicionales de PLN como Naive Bayes y LSTMs.</p>
<h2 class="relative group"><a id="quines-somos" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#quines-somos"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Â¿QuiÃ©nes somos?
	</span></h2>

<p>Acerca de los autores:</p>
<p><strong>Matthew Carrigan</strong> es Ingeniero de Machine Learning en Hugging Face. Vive en Dublin, Irlanda y anteriormente trabajÃ³ como Ingeniero ML en Parse.ly y como investigador post-doctoral en Trinity College Dublin. No cree que vamos a alcanzar una Inteligencia Artificial General escalando arquitecturas existentes, pero en todo caso tiene grandes expectativas sobre la inmortalidad robÃ³tica.</p>
<p><strong>Lysandre Debut</strong> es Ingeniero de Machine Learning en Hugging Face y ha trabajado en la librerÃ­a ğŸ¤— Transformers desde sus etapas de desarrollo mÃ¡s tempranas. Su objetivo es hacer que el PLN sea accesible para todos a travÃ©s del desarrollo de herramientas con una API muy simple.</p>
<p><strong>Sylvain Gugger</strong> es Ingeniero de InvestigaciÃ³n en Hugging Face y uno de los principales mantenedores de la librerÃ­a ğŸ¤— Transformers. Anteriormente fue CientÃ­fico de InvestigaciÃ³n en fast.ai y escribiÃ³ <em><a href="https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/" rel="nofollow">Deep Learning for Coders with fastai and PyTorch</a></em> junto con Jeremy Howard. El foco principal de su investigaciÃ³n es hacer el deep learning mÃ¡s accesible, al diseÃ±ar y mejorar tÃ©cnicas que permiten un entrenamiento rÃ¡pido de modelos con recursos limitados.</p>
<p><strong>Merve Noyan</strong> es Promotora de Desarrolladores en Hugging Face, trabaja en el desarrollo de herramientas y construcciÃ³n de contenido relacionado, con el fÃ­n de democratizar el machine learning para todos.</p>
<p><strong>Lucile Saulnier</strong> es Ingeniera de Machine Learning en Hugging Face, donde desarrolla y apoya el uso de herramientas de cÃ³digo abierto. Ella estÃ¡ activamente involucrada en varios proyectos de investigaciÃ³n en el campo del Procesamiento de Lenguaje Natural como entrenamiento colaborativo y BigScience.</p>
<p><strong>Lewis Tunstall</strong>  es Ingeniero de Machine Learning en Hugging Face, enfocado en desarrollar herramientas de cÃ³digo abierto y hacerlas accesibles a la comunidad en general. TambiÃ©n es coautor de un prÃ³ximo <a href="https://www.oreilly.com/library/view/natural-language-processing/9781098103231/" rel="nofollow">libro de Oâ€™Reilly sobre Transformadores</a>.</p>
<p><strong>Leandro von Werra</strong>  es Ingeniero de Machine Learning en el equipo de cÃ³digo abierto en Hugging Face y coautor de un prÃ³ximo <a href="https://www.oreilly.com/library/view/natural-language-processing/9781098103231/" rel="nofollow">libro de Oâ€™Reilly sobre Transformadores</a>. Tiene varios aÃ±os de experiencia en la industria llevando modelos de PLN a producciÃ³n, trabajando a lo largo de todo el entorno de Machine Learning. </p>
<p>Â¿EstÃ¡s listo para comenzar? En este capÃ­tulo vas a aprender:</p>
<ul><li>CÃ³mo usar la funciÃ³n <code>pipeline()</code> para resolver tareas de PLN como la generaciÃ³n y clasificaciÃ³n de texto</li>
<li>Sobre la arquitectura de los Transformadores</li>
<li>CÃ³mo distinguir entre las arquitecturas de codificador, decodificador y codificador-decofidicador, ademÃ¡s de sus casos de uso</li></ul>


		<script type="module" data-hydrate="1yu8n75">
		import { start } from "/docs/course/pr_193/es/_app/start-8c481fdb.js";
		start({
			target: document.querySelector('[data-hydrate="1yu8n75"]').parentNode,
			paths: {"base":"/docs/course/pr_193/es","assets":"/docs/course/pr_193/es"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/course/pr_193/es/_app/pages/__layout.svelte-05c2fb0c.js"),
						import("/docs/course/pr_193/es/_app/pages/chapter1/1.mdx-0dab120b.js")
				],
				params: {}
			}
		});
	</script>
