import{S as vo,i as $o,s as go,e as s,k as p,w,t as O,l as po,M as xo,c as n,d as a,m as f,x as z,a as i,h as j,b as l,G as o,g as c,y as E,o as g,p as fo,q as x,B as A,v as ko,n as ho}from"../../chunks/vendor-hf-doc-builder.js";import{I as C}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as Ma}from"../../chunks/CodeBlock-hf-doc-builder.js";import{Q as H}from"../../chunks/Question-hf-doc-builder.js";import{F as _o}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function bo(Q){let d,u,$,h,N,v,S,_,y,P,b,k,t;return h=new C({}),k=new H({props:{choices:[{text:"Um modelo que treina automaticamente com seus dados",explain:"Incorreto. Voc\xEA est\xE1 confundindo isto com nosso produto de <a href='https://huggingface.co/autonlp'>AutoNLP</a>?"},{text:"Um objeto que devolve a arquitetura correta com base em um checkpoint",explain:"Exatamente: o <code>TFAutoModel</code> s\xF3 precisa saber o checkpoint para saber como inicializar ent\xE3o devolver a arquitetura correta.",correct:!0},{text:"Um modelo que detecta automaticamente a linguagem utilizada para suas entradas a fim de carregar os pesos corretos",explain:"Incorreto; embora alguns checkpoints e modelos sejam capazes de lidar com v\xE1rios idiomas, n\xE3o h\xE1 ferramentas embutidas para sele\xE7\xE3o autom\xE1tica de checkpoints de acordo com o idioma. Voc\xEA deve ir para o  <a href='https://huggingface.co/models'>Model Hub</a> para encontrar o melhor checkpoint para realizar sua tarefa!"}]}}),{c(){d=s("h3"),u=s("a"),$=s("span"),w(h.$$.fragment),N=p(),v=s("span"),S=O("5. O que seria um "),_=s("code"),y=O("TFAutoModel"),P=O("?"),b=p(),w(k.$$.fragment),this.h()},l(r){d=n(r,"H3",{class:!0});var q=i(d);u=n(q,"A",{id:!0,class:!0,href:!0});var T=i(u);$=n(T,"SPAN",{});var I=i($);z(h.$$.fragment,I),I.forEach(a),T.forEach(a),N=f(q),v=n(q,"SPAN",{});var M=i(v);S=j(M,"5. O que seria um "),_=n(M,"CODE",{});var V=i(_);y=j(V,"TFAutoModel"),V.forEach(a),P=j(M,"?"),M.forEach(a),q.forEach(a),b=f(r),z(k.$$.fragment,r),this.h()},h(){l(u,"id","5.-o-que-seria-um-<code>tfautomodel</code>?"),l(u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(u,"href","#5.-o-que-seria-um-<code>tfautomodel</code>?"),l(d,"class","relative group")},m(r,q){c(r,d,q),o(d,u),o(u,$),E(h,$,null),o(d,N),o(d,v),o(v,S),o(v,_),o(_,y),o(v,P),c(r,b,q),E(k,r,q),t=!0},i(r){t||(x(h.$$.fragment,r),x(k.$$.fragment,r),t=!0)},o(r){g(h.$$.fragment,r),g(k.$$.fragment,r),t=!1},d(r){r&&a(d),A(h),r&&a(b),A(k,r)}}}function qo(Q){let d,u,$,h,N,v,S,_,y,P,b,k,t;return h=new C({}),k=new H({props:{choices:[{text:"Um modelo que treina automaticamente com seus dados",explain:"Incorreto. Voc\xEA est\xE1 confundindo isto com nosso produto de <a href='https://huggingface.co/autonlp'>AutoNLP</a>?"},{text:"Um objeto que devolve a arquitetura correta com base em um checkpoint",explain:"Exatamente: o <code>AutoModel</code> s\xF3 precisa saber o checkpoint para saber como inicializar ent\xE3o devolver a arquitetura correta.",correct:!0},{text:"Um modelo que detecta automaticamente a linguagem utilizada para suas entradas a fim de carregar os pesos corretos",explain:"Incorreto; embora alguns checkpoints e modelos sejam capazes de lidar com v\xE1rios idiomas, n\xE3o h\xE1 ferramentas embutidas para sele\xE7\xE3o autom\xE1tica de checkpoints de acordo com o idioma. Voc\xEA deve ir para o  <a href='https://huggingface.co/models'>Model Hub</a> para encontrar o melhor checkpoint para realizar sua tarefa!"}]}}),{c(){d=s("h3"),u=s("a"),$=s("span"),w(h.$$.fragment),N=p(),v=s("span"),S=O("5. O que seria um "),_=s("code"),y=O("AutoModel"),P=O("?"),b=p(),w(k.$$.fragment),this.h()},l(r){d=n(r,"H3",{class:!0});var q=i(d);u=n(q,"A",{id:!0,class:!0,href:!0});var T=i(u);$=n(T,"SPAN",{});var I=i($);z(h.$$.fragment,I),I.forEach(a),T.forEach(a),N=f(q),v=n(q,"SPAN",{});var M=i(v);S=j(M,"5. O que seria um "),_=n(M,"CODE",{});var V=i(_);y=j(V,"AutoModel"),V.forEach(a),P=j(M,"?"),M.forEach(a),q.forEach(a),b=f(r),z(k.$$.fragment,r),this.h()},h(){l(u,"id","5.-o-que-seria-um-<code>automodel</code>?"),l(u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(u,"href","#5.-o-que-seria-um-<code>automodel</code>?"),l(d,"class","relative group")},m(r,q){c(r,d,q),o(d,u),o(u,$),E(h,$,null),o(d,N),o(d,v),o(v,S),o(v,_),o(_,y),o(v,P),c(r,b,q),E(k,r,q),t=!0},i(r){t||(x(h.$$.fragment,r),x(k.$$.fragment,r),t=!0)},o(r){g(h.$$.fragment,r),g(k.$$.fragment,r),t=!1},d(r){r&&a(d),A(h),r&&a(b),A(k,r)}}}function wo(Q){let d,u,$,h,N,v,S,_,y,P,b,k;return h=new C({}),y=new Ma({props:{code:`
`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModel

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;gpt2&quot;</span>)

encoded = tokenizer(<span class="hljs-string">&quot;Hey!&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
result = model(**encoded)`}}),b=new H({props:{choices:[{text:"N\xE3o, parece correto.",explain:"Infelizmente, acoplar um modelo com um tokenizer que foi treinado com um checkpoint diferente raramente \xE9 uma boa ideia. O modelo n\xE3o foi treinado para fazer sentido a partir da sa\xEDda deste tokenizer, ent\xE3o a sa\xEDda do modelo (isto se ele realmente funcionar!) n\xE3o far\xE1 nenhum sentido."},{text:"O tokenizer e o modelo devem ser sempre a partir do mesmo checkpoint.",explain:"Correto!",correct:!0},{text:"\xC9 uma boa pr\xE1tica realizar o padding e truncar com o tokenizer, pois cada entrada \xE9 um batch.",explain:"\xC9 verdade que cada entrada do modelo precisa ser um batch. Entretanto, truncando ou realizando o padding desta sequ\xEAncia n\xE3o faria necessariamente sentido, pois existe apenas uma delas, e estas s\xE3o t\xE9cnicas para criar batches de uma lista de senten\xE7as."}]}}),{c(){d=s("h3"),u=s("a"),$=s("span"),w(h.$$.fragment),N=p(),v=s("span"),S=O("10. Tem algo errado com o c\xF3digo abaixo?"),_=p(),w(y.$$.fragment),P=p(),w(b.$$.fragment),this.h()},l(t){d=n(t,"H3",{class:!0});var r=i(d);u=n(r,"A",{id:!0,class:!0,href:!0});var q=i(u);$=n(q,"SPAN",{});var T=i($);z(h.$$.fragment,T),T.forEach(a),q.forEach(a),N=f(r),v=n(r,"SPAN",{});var I=i(v);S=j(I,"10. Tem algo errado com o c\xF3digo abaixo?"),I.forEach(a),r.forEach(a),_=f(t),z(y.$$.fragment,t),P=f(t),z(b.$$.fragment,t),this.h()},h(){l(u,"id","10.-tem-algo-errado-com-o-c\xF3digo-abaixo?"),l(u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(u,"href","#10.-tem-algo-errado-com-o-c\xF3digo-abaixo?"),l(d,"class","relative group")},m(t,r){c(t,d,r),o(d,u),o(u,$),E(h,$,null),o(d,N),o(d,v),o(v,S),c(t,_,r),E(y,t,r),c(t,P,r),E(b,t,r),k=!0},i(t){k||(x(h.$$.fragment,t),x(y.$$.fragment,t),x(b.$$.fragment,t),k=!0)},o(t){g(h.$$.fragment,t),g(y.$$.fragment,t),g(b.$$.fragment,t),k=!1},d(t){t&&a(d),A(h),t&&a(_),A(y,t),t&&a(P),A(b,t)}}}function zo(Q){let d,u,$,h,N,v,S,_,y,P,b,k;return h=new C({}),y=new Ma({props:{code:`
`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModel

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
model = AutoModel.from_pretrained(<span class="hljs-string">&quot;gpt2&quot;</span>)

encoded = tokenizer(<span class="hljs-string">&quot;Hey!&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
result = model(**encoded)`}}),b=new H({props:{choices:[{text:"N\xE3o, parece correto.",explain:"Infelizmente, acoplar um modelo com um tokenizer que foi treinado com um checkpoint diferente raramente \xE9 uma boa ideia. O modelo n\xE3o foi treinado para fazer sentido a partir da sa\xEDda deste tokenizer, ent\xE3o a sa\xEDda do modelo (isto se ele realmente funcionar!) n\xE3o far\xE1 nenhum sentido."},{text:"O tokenizer e o modelo devem ser sempre a partir do mesmo checkpoint.",explain:"Correto!",correct:!0},{text:"\xC9 uma boa pr\xE1tica realizar o padding e truncar com o tokenizer, pois cada entrada \xE9 um batch.",explain:"\xC9 verdade que cada entrada do modelo precisa ser um batch. Entretanto, truncando ou realizando o padding desta sequ\xEAncia n\xE3o faria necessariamente sentido, pois existe apenas uma delas, e estas s\xE3o t\xE9cnicas para criar batches de uma lista de senten\xE7as."}]}}),{c(){d=s("h3"),u=s("a"),$=s("span"),w(h.$$.fragment),N=p(),v=s("span"),S=O("10. Tem algo errado com o c\xF3digo abaixo?"),_=p(),w(y.$$.fragment),P=p(),w(b.$$.fragment),this.h()},l(t){d=n(t,"H3",{class:!0});var r=i(d);u=n(r,"A",{id:!0,class:!0,href:!0});var q=i(u);$=n(q,"SPAN",{});var T=i($);z(h.$$.fragment,T),T.forEach(a),q.forEach(a),N=f(r),v=n(r,"SPAN",{});var I=i(v);S=j(I,"10. Tem algo errado com o c\xF3digo abaixo?"),I.forEach(a),r.forEach(a),_=f(t),z(y.$$.fragment,t),P=f(t),z(b.$$.fragment,t),this.h()},h(){l(u,"id","10.-tem-algo-errado-com-o-c\xF3digo-abaixo?"),l(u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(u,"href","#10.-tem-algo-errado-com-o-c\xF3digo-abaixo?"),l(d,"class","relative group")},m(t,r){c(t,d,r),o(d,u),o(u,$),E(h,$,null),o(d,N),o(d,v),o(v,S),c(t,_,r),E(y,t,r),c(t,P,r),E(b,t,r),k=!0},i(t){k||(x(h.$$.fragment,t),x(y.$$.fragment,t),x(b.$$.fragment,t),k=!0)},o(t){g(h.$$.fragment,t),g(y.$$.fragment,t),g(b.$$.fragment,t),k=!1},d(t){t&&a(d),A(h),t&&a(_),A(y,t),t&&a(P),A(b,t)}}}function Eo(Q){let d,u,$,h,N,v,S,_,y,P,b,k,t,r,q,T,I,M,V,Ve,se,Be,B,Y,Pe,ne,ga,Se,xa,Re,ie,Ge,R,Z,Oe,le,ka,je,_a,Je,me,We,G,ee,Te,de,ba,ue,qa,Ie,wa,za,Ke,ce,Xe,U,D,Ee,J,ae,Me,pe,Ea,Ce,Aa,Ye,fe,Ze,W,oe,He,he,ya,Qe,Na,ea,ve,aa,K,te,Ue,$e,Pa,De,Sa,oa,ge,ta,X,re,Fe,xe,Oa,ke,ja,Le,Ta,Ia,ra,_e,sa,be,na,F,L,Ae,ia;$=new _o({props:{fw:Q[0]}}),_=new C({}),T=new C({}),se=new H({props:{choices:[{text:"Primeiro, o modelo trata de textos e devolve previs\xF5es em bruto. O tokenizer, ent\xE3o, tr\xE1s sentido a estas previs\xF5es e as converte de volta ao texto quando necess\xE1rio.",explain:"O modelo n\xE3o consegue entender o texto! O tokenizer deve primeiro simbolizar o texto e convert\xEA-lo em IDs para que seja compreens\xEDvel pelo modelo."},{text:"Primeiro, o tokenizer trata de textos e devolve as identifica\xE7\xF5es (IDs). O modelo lida com estas identifica\xE7\xF5es e produz uma predi\xE7\xE3o, que pode ser algum texto.",explain:"A predi\xE7\xE3o do modelo n\xE3o pode ser feita de imediato. O tokenizer tem que ser usado para converter a predi\xE7\xE3o de volta ao texto!"},{text:"O tokenizer trata de textos e devolve os IDs. O modelo lida com estes IDs e produz uma predi\xE7\xE3o. O tokenizer pode ent\xE3o ser usado mais uma vez para converter estas previs\xF5es de volta para algum texto.",explain:"Correto! O tokenizer pode ser usado tanto para a tokeniza\xE7\xE3o quanto para a destokeniza\xE7\xE3o.",correct:!0}]}}),ne=new C({}),ie=new H({props:{choices:[{text:"2: O comprimento da sequ\xEAncia e o tamanho do batch (lote)",explain:"Falso! A sa\xEDda do tensor pelo modelo tem uma terceira dimens\xE3o: o tamanho das camadas ocultas"},{text:"2: O comprimento da sequ\xEAncia e o tamanho das camadas ocultas",explain:"Falso! Todos os Transformer lidam com batches, mesmo com uma \xFAnica sequ\xEAncia; isso seria um tamanho de batch de 1!"},{text:"3: O comprimento da sequ\xEAncia, o tamanho do batch (lote) e o tamanho das camadas ocultas",explain:"Correto!",correct:!0}]}}),le=new C({}),me=new H({props:{choices:[{text:"WordPiece",explain:"Exatamente, este \xE9 um exemplo de Tokeniza\xE7\xE3o por sub-palavra!",correct:!0},{text:"Character-based tokenization",explain:"Character-based tokenization n\xE3o \xE9 uma tokeniza\xE7\xE3o por sub-palavra!."},{text:"Divis\xE3o no espa\xE7o em branco e pontua\xE7\xE3o",explain:"Esse \xE9 um esquema de tokenization baseado em palavras!"},{text:"BPE",explain:"Exatamente, este \xE9 um exemplo de Tokeniza\xE7\xE3o por sub-palavra!",correct:!0},{text:"Unigram",explain:"Exatamente, este \xE9 um exemplo de Tokeniza\xE7\xE3o por sub-palavra!",correct:!0},{text:"Nenhuma das acimas",explain:"Errado!"}]}}),de=new C({}),ce=new H({props:{choices:[{text:"Um componente dos transformers de base que redireciona os tensores para suas camadas corretas",explain:"Incorreto! N\xE3o existe tal componente."},{text:"Tamb\xE9m conhecido como mecanismo de auto-aten\xE7\xE3o (*self-attention*), ele adapta a representa\xE7\xE3o de um s\xEDmbolo de acordo com os outros tokens da sequ\xEAncia",explain:"Incorreto! A camada de auto-aten\xE7\xE3o cont\xE9m 'attention heads', mas estas n\xE3o s\xE3o as heads de adapta\xE7\xE3o."},{text:"Um componente adicional, geralmente composto de uma ou poucas camadas, para converter as previs\xF5es do Transformer em uma sa\xEDda espec\xEDfica de tarefa",explain:"\xC9 isso mesmo. As heads de adapta\xE7\xE3o, tamb\xE9m conhecidos simplesmente como heads, surgem em diferentes formas: heads de modelagem de linguagem, heads de resposta a perguntas, heads de classifica\xE7\xE3o de sequ\xEAncia.. ",correct:!0}]}});const Ca=[qo,bo],qe=[];function Ha(e,m){return e[0]==="pt"?0:1}U=Ha(Q),D=qe[U]=Ca[U](Q),pe=new C({}),fe=new H({props:{choices:[{text:"Truncar",explain:"Sim, a truncagem \xE9 uma forma correta de sequ\xEAncias de sa\xEDda noturna para que elas se encaixem em forma retangular.No entanto, seria a \xFAnica?",correct:!0},{text:"Retornar tensores",explain:"Enquanto as outras t\xE9cnicas permitem retornar tensores retangulares, retornar tensores n\xE3o \xE9 \xFAtil quando realizar batches de sequ\xEAncias juntas."},{text:"Padding",explain:"Sim, padding \xE9 uma forma correta para as sequ\xEAncias de sa\xEDda para que elas se encaixem em uma forma retangular. No entanto, seria a \xFAnica?",correct:!0},{text:"Attention masking",explain:"Exatamente! As attention masks s\xE3o de primordial import\xE2ncia quando se trata de sequ\xEAncias de diferentes tamanhos. No entanto, essa n\xE3o \xE9 a \xFAnica t\xE9cnica a ser conhecida.",correct:!0}]}}),he=new C({}),ve=new H({props:{choices:[{text:"Suaviza os logits para que sejam mais confi\xE1veis.",explain:"N\xE3o, a fun\xE7\xE3o SoftMax n\xE3o afeta a confiabilidade dos resultados."},{text:"Aplica um limite inferior e um limite superior para que eles sejam compreens\xEDveis.",explain:"Correto! Os valores resultantes est\xE3o vinculados entre 0 e 1. Mas essa n\xE3o \xE9 a \xFAnica raz\xE3o pela qual usamos uma fun\xE7\xE3o SoftMax.",correct:!0},{text:"A soma total da sa\xEDda \xE9 1, resultando em uma poss\xEDvel interpreta\xE7\xE3o probabil\xEDstica.",explain:"Correto! Mas essa n\xE3o \xE9 a \xFAnica raz\xE3o pela qual usamos uma fun\xE7\xE3o SoftMax.",correct:!0}]}}),$e=new C({}),ge=new H({props:{choices:[{text:"<code>encode</code>, pois pode codificar texto em IDs e IDs em predi\xE7\xF5es",explain:"Errado! O m\xE9todo <code>encode</code> existe na tokeniza\xE7\xE3o, por\xE9m n\xE3o existe nos modelos."},{text:"Chamando diretamente o objeto de tokeniza\xE7\xE3o (tokenizer).",explain:"Exatamente! O m\xE9todo <code>__call__</code> do tokenizer \xE9 um m\xE9todo muito poderoso que pode lidar com praticamente qualquer coisa. \xC9 tamb\xE9m o m\xE9todo usado para recuperar as predi\xE7\xF5es de um modelo.",correct:!0},{text:"<code>padding</code>",explain:"Errado! O padding \xE9 muito \xFAtil, mas \xE9 apenas uma parte da API do tokenizer."},{text:"<code>tokenize</code>",explain:"O m\xE9todo <code>tokenize</code> \xE9 indiscutivelmente um dos m\xE9todos mais \xFAteis, mas n\xE3o \xE9 o n\xFAcleo do API do tokenizer."}]}}),xe=new C({}),_e=new Ma({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
result = tokenizer.tokenize(<span class="hljs-string">&quot;Hello!&quot;</span>)`}}),be=new H({props:{choices:[{text:"Uma lista de strings, sendo cada uma delas um token",explain:"Exatamente! Converta isto em IDs, e envie-os para um modelo!",correct:!0},{text:"Uma lista de IDs",explain:"Incorreto; isto \xE9 o para o os m\xE9todos <code>__call__</code> ou <code>convert_tokens_to_ids</code>!"},{text:"Uma string contendo todos os tokens ",explain:"Isto seria sub\xF3timo, pois o objetivo \xE9 dividir a string em v\xE1rios tokens."}]}});const Qa=[zo,wo],we=[];function Ua(e,m){return e[0]==="pt"?0:1}return F=Ua(Q),L=we[F]=Qa[F](Q),{c(){d=s("meta"),u=p(),w($.$$.fragment),h=p(),N=s("h1"),v=s("a"),S=s("span"),w(_.$$.fragment),y=p(),P=s("span"),b=O("Question\xE1rio de fim de cap\xEDtulo"),k=p(),t=s("h3"),r=s("a"),q=s("span"),w(T.$$.fragment),I=p(),M=s("span"),V=O("1. Qual \xE9 a ordem do pipeline para a modelagem de linguagem?"),Ve=p(),w(se.$$.fragment),Be=p(),B=s("h3"),Y=s("a"),Pe=s("span"),w(ne.$$.fragment),ga=p(),Se=s("span"),xa=O("2. Quantas dimens\xF5es tem o tensor do Transformer de base, e quais s\xE3o elas?"),Re=p(),w(ie.$$.fragment),Ge=p(),R=s("h3"),Z=s("a"),Oe=s("span"),w(le.$$.fragment),ka=p(),je=s("span"),_a=O("3. Qual dos seguintes \xE9 um exemplo de Tokeniza\xE7\xE3o por sub-palavras?"),Je=p(),w(me.$$.fragment),We=p(),G=s("h3"),ee=s("a"),Te=s("span"),w(de.$$.fragment),ba=p(),ue=s("span"),qa=O("4. O que \xE9 uma "),Ie=s("em"),wa=O("model head"),za=O("?"),Ke=p(),w(ce.$$.fragment),Xe=p(),D.c(),Ee=p(),J=s("h3"),ae=s("a"),Me=s("span"),w(pe.$$.fragment),Ea=p(),Ce=s("span"),Aa=O("6. Quais s\xE3o as t\xE9cnicas a serem observadas quando realizar batches com sequ\xEAncias de diferentes tamanhos?"),Ye=p(),w(fe.$$.fragment),Ze=p(),W=s("h3"),oe=s("a"),He=s("span"),w(he.$$.fragment),ya=p(),Qe=s("span"),Na=O("7. Qual \xE9 o objetivo de aplicar uma fun\xE7\xE3o SoftMax \xE0 sa\xEDda de logits para um modelo de classifica\xE7\xE3o sequencial??"),ea=p(),w(ve.$$.fragment),aa=p(),K=s("h3"),te=s("a"),Ue=s("span"),w($e.$$.fragment),Pa=p(),De=s("span"),Sa=O("8. Qual \xE9 o m\xE9todo core da API tokenizer?"),oa=p(),w(ge.$$.fragment),ta=p(),X=s("h3"),re=s("a"),Fe=s("span"),w(xe.$$.fragment),Oa=p(),ke=s("span"),ja=O("9. O que a vari\xE1vel "),Le=s("code"),Ta=O("result"),Ia=O(" cont\xE9m nesta peda\xE7o de c\xF3digo?"),ra=p(),w(_e.$$.fragment),sa=p(),w(be.$$.fragment),na=p(),L.c(),Ae=po(),this.h()},l(e){const m=xo('[data-svelte="svelte-1phssyn"]',document.head);d=n(m,"META",{name:!0,content:!0}),m.forEach(a),u=f(e),z($.$$.fragment,e),h=f(e),N=n(e,"H1",{class:!0});var ze=i(N);v=n(ze,"A",{id:!0,class:!0,href:!0});var ye=i(v);S=n(ye,"SPAN",{});var Ne=i(S);z(_.$$.fragment,Ne),Ne.forEach(a),ye.forEach(a),y=f(ze),P=n(ze,"SPAN",{});var Da=i(P);b=j(Da,"Question\xE1rio de fim de cap\xEDtulo"),Da.forEach(a),ze.forEach(a),k=f(e),t=n(e,"H3",{class:!0});var la=i(t);r=n(la,"A",{id:!0,class:!0,href:!0});var Fa=i(r);q=n(Fa,"SPAN",{});var La=i(q);z(T.$$.fragment,La),La.forEach(a),Fa.forEach(a),I=f(la),M=n(la,"SPAN",{});var Va=i(M);V=j(Va,"1. Qual \xE9 a ordem do pipeline para a modelagem de linguagem?"),Va.forEach(a),la.forEach(a),Ve=f(e),z(se.$$.fragment,e),Be=f(e),B=n(e,"H3",{class:!0});var ma=i(B);Y=n(ma,"A",{id:!0,class:!0,href:!0});var Ba=i(Y);Pe=n(Ba,"SPAN",{});var Ra=i(Pe);z(ne.$$.fragment,Ra),Ra.forEach(a),Ba.forEach(a),ga=f(ma),Se=n(ma,"SPAN",{});var Ga=i(Se);xa=j(Ga,"2. Quantas dimens\xF5es tem o tensor do Transformer de base, e quais s\xE3o elas?"),Ga.forEach(a),ma.forEach(a),Re=f(e),z(ie.$$.fragment,e),Ge=f(e),R=n(e,"H3",{class:!0});var da=i(R);Z=n(da,"A",{id:!0,class:!0,href:!0});var Ja=i(Z);Oe=n(Ja,"SPAN",{});var Wa=i(Oe);z(le.$$.fragment,Wa),Wa.forEach(a),Ja.forEach(a),ka=f(da),je=n(da,"SPAN",{});var Ka=i(je);_a=j(Ka,"3. Qual dos seguintes \xE9 um exemplo de Tokeniza\xE7\xE3o por sub-palavras?"),Ka.forEach(a),da.forEach(a),Je=f(e),z(me.$$.fragment,e),We=f(e),G=n(e,"H3",{class:!0});var ua=i(G);ee=n(ua,"A",{id:!0,class:!0,href:!0});var Xa=i(ee);Te=n(Xa,"SPAN",{});var Ya=i(Te);z(de.$$.fragment,Ya),Ya.forEach(a),Xa.forEach(a),ba=f(ua),ue=n(ua,"SPAN",{});var ca=i(ue);qa=j(ca,"4. O que \xE9 uma "),Ie=n(ca,"EM",{});var Za=i(Ie);wa=j(Za,"model head"),Za.forEach(a),za=j(ca,"?"),ca.forEach(a),ua.forEach(a),Ke=f(e),z(ce.$$.fragment,e),Xe=f(e),D.l(e),Ee=f(e),J=n(e,"H3",{class:!0});var pa=i(J);ae=n(pa,"A",{id:!0,class:!0,href:!0});var eo=i(ae);Me=n(eo,"SPAN",{});var ao=i(Me);z(pe.$$.fragment,ao),ao.forEach(a),eo.forEach(a),Ea=f(pa),Ce=n(pa,"SPAN",{});var oo=i(Ce);Aa=j(oo,"6. Quais s\xE3o as t\xE9cnicas a serem observadas quando realizar batches com sequ\xEAncias de diferentes tamanhos?"),oo.forEach(a),pa.forEach(a),Ye=f(e),z(fe.$$.fragment,e),Ze=f(e),W=n(e,"H3",{class:!0});var fa=i(W);oe=n(fa,"A",{id:!0,class:!0,href:!0});var to=i(oe);He=n(to,"SPAN",{});var ro=i(He);z(he.$$.fragment,ro),ro.forEach(a),to.forEach(a),ya=f(fa),Qe=n(fa,"SPAN",{});var so=i(Qe);Na=j(so,"7. Qual \xE9 o objetivo de aplicar uma fun\xE7\xE3o SoftMax \xE0 sa\xEDda de logits para um modelo de classifica\xE7\xE3o sequencial??"),so.forEach(a),fa.forEach(a),ea=f(e),z(ve.$$.fragment,e),aa=f(e),K=n(e,"H3",{class:!0});var ha=i(K);te=n(ha,"A",{id:!0,class:!0,href:!0});var no=i(te);Ue=n(no,"SPAN",{});var io=i(Ue);z($e.$$.fragment,io),io.forEach(a),no.forEach(a),Pa=f(ha),De=n(ha,"SPAN",{});var lo=i(De);Sa=j(lo,"8. Qual \xE9 o m\xE9todo core da API tokenizer?"),lo.forEach(a),ha.forEach(a),oa=f(e),z(ge.$$.fragment,e),ta=f(e),X=n(e,"H3",{class:!0});var va=i(X);re=n(va,"A",{id:!0,class:!0,href:!0});var mo=i(re);Fe=n(mo,"SPAN",{});var uo=i(Fe);z(xe.$$.fragment,uo),uo.forEach(a),mo.forEach(a),Oa=f(va),ke=n(va,"SPAN",{});var $a=i(ke);ja=j($a,"9. O que a vari\xE1vel "),Le=n($a,"CODE",{});var co=i(Le);Ta=j(co,"result"),co.forEach(a),Ia=j($a," cont\xE9m nesta peda\xE7o de c\xF3digo?"),$a.forEach(a),va.forEach(a),ra=f(e),z(_e.$$.fragment,e),sa=f(e),z(be.$$.fragment,e),na=f(e),L.l(e),Ae=po(),this.h()},h(){l(d,"name","hf:doc:metadata"),l(d,"content",JSON.stringify(Ao)),l(v,"id","questionrio-de-fim-de-captulo"),l(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(v,"href","#questionrio-de-fim-de-captulo"),l(N,"class","relative group"),l(r,"id","1.-qual-\xE9-a-ordem-do-pipeline-para-a-modelagem-de-linguagem?"),l(r,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(r,"href","#1.-qual-\xE9-a-ordem-do-pipeline-para-a-modelagem-de-linguagem?"),l(t,"class","relative group"),l(Y,"id","2.-quantas-dimens\xF5es-tem-o-tensor-do-transformer-de-base,-e-quais-s\xE3o-elas?"),l(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(Y,"href","#2.-quantas-dimens\xF5es-tem-o-tensor-do-transformer-de-base,-e-quais-s\xE3o-elas?"),l(B,"class","relative group"),l(Z,"id","3.-qual-dos-seguintes-\xE9-um-exemplo-de-tokeniza\xE7\xE3o-por-sub-palavras?"),l(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(Z,"href","#3.-qual-dos-seguintes-\xE9-um-exemplo-de-tokeniza\xE7\xE3o-por-sub-palavras?"),l(R,"class","relative group"),l(ee,"id","4.-o-que-\xE9-uma-<em>model-head</em>?"),l(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(ee,"href","#4.-o-que-\xE9-uma-<em>model-head</em>?"),l(G,"class","relative group"),l(ae,"id","6.-quais-s\xE3o-as-t\xE9cnicas-a-serem-observadas-quando-realizar-batches-com-sequ\xEAncias-de-diferentes-tamanhos?"),l(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(ae,"href","#6.-quais-s\xE3o-as-t\xE9cnicas-a-serem-observadas-quando-realizar-batches-com-sequ\xEAncias-de-diferentes-tamanhos?"),l(J,"class","relative group"),l(oe,"id","7.-qual-\xE9-o-objetivo-de-aplicar-uma-fun\xE7\xE3o-softmax-\xE0-sa\xEDda-de-logits-para-um-modelo-de-classifica\xE7\xE3o-sequencial??"),l(oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(oe,"href","#7.-qual-\xE9-o-objetivo-de-aplicar-uma-fun\xE7\xE3o-softmax-\xE0-sa\xEDda-de-logits-para-um-modelo-de-classifica\xE7\xE3o-sequencial??"),l(W,"class","relative group"),l(te,"id","8.-qual-\xE9-o-m\xE9todo-core-da-api-tokenizer?"),l(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(te,"href","#8.-qual-\xE9-o-m\xE9todo-core-da-api-tokenizer?"),l(K,"class","relative group"),l(re,"id","9.-o-que-a-vari\xE1vel-<code>result</code>-cont\xE9m-nesta-peda\xE7o-de-c\xF3digo?"),l(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(re,"href","#9.-o-que-a-vari\xE1vel-<code>result</code>-cont\xE9m-nesta-peda\xE7o-de-c\xF3digo?"),l(X,"class","relative group")},m(e,m){o(document.head,d),c(e,u,m),E($,e,m),c(e,h,m),c(e,N,m),o(N,v),o(v,S),E(_,S,null),o(N,y),o(N,P),o(P,b),c(e,k,m),c(e,t,m),o(t,r),o(r,q),E(T,q,null),o(t,I),o(t,M),o(M,V),c(e,Ve,m),E(se,e,m),c(e,Be,m),c(e,B,m),o(B,Y),o(Y,Pe),E(ne,Pe,null),o(B,ga),o(B,Se),o(Se,xa),c(e,Re,m),E(ie,e,m),c(e,Ge,m),c(e,R,m),o(R,Z),o(Z,Oe),E(le,Oe,null),o(R,ka),o(R,je),o(je,_a),c(e,Je,m),E(me,e,m),c(e,We,m),c(e,G,m),o(G,ee),o(ee,Te),E(de,Te,null),o(G,ba),o(G,ue),o(ue,qa),o(ue,Ie),o(Ie,wa),o(ue,za),c(e,Ke,m),E(ce,e,m),c(e,Xe,m),qe[U].m(e,m),c(e,Ee,m),c(e,J,m),o(J,ae),o(ae,Me),E(pe,Me,null),o(J,Ea),o(J,Ce),o(Ce,Aa),c(e,Ye,m),E(fe,e,m),c(e,Ze,m),c(e,W,m),o(W,oe),o(oe,He),E(he,He,null),o(W,ya),o(W,Qe),o(Qe,Na),c(e,ea,m),E(ve,e,m),c(e,aa,m),c(e,K,m),o(K,te),o(te,Ue),E($e,Ue,null),o(K,Pa),o(K,De),o(De,Sa),c(e,oa,m),E(ge,e,m),c(e,ta,m),c(e,X,m),o(X,re),o(re,Fe),E(xe,Fe,null),o(X,Oa),o(X,ke),o(ke,ja),o(ke,Le),o(Le,Ta),o(ke,Ia),c(e,ra,m),E(_e,e,m),c(e,sa,m),E(be,e,m),c(e,na,m),we[F].m(e,m),c(e,Ae,m),ia=!0},p(e,[m]){const ze={};m&1&&(ze.fw=e[0]),$.$set(ze);let ye=U;U=Ha(e),U!==ye&&(ho(),g(qe[ye],1,1,()=>{qe[ye]=null}),fo(),D=qe[U],D||(D=qe[U]=Ca[U](e),D.c()),x(D,1),D.m(Ee.parentNode,Ee));let Ne=F;F=Ua(e),F!==Ne&&(ho(),g(we[Ne],1,1,()=>{we[Ne]=null}),fo(),L=we[F],L||(L=we[F]=Qa[F](e),L.c()),x(L,1),L.m(Ae.parentNode,Ae))},i(e){ia||(x($.$$.fragment,e),x(_.$$.fragment,e),x(T.$$.fragment,e),x(se.$$.fragment,e),x(ne.$$.fragment,e),x(ie.$$.fragment,e),x(le.$$.fragment,e),x(me.$$.fragment,e),x(de.$$.fragment,e),x(ce.$$.fragment,e),x(D),x(pe.$$.fragment,e),x(fe.$$.fragment,e),x(he.$$.fragment,e),x(ve.$$.fragment,e),x($e.$$.fragment,e),x(ge.$$.fragment,e),x(xe.$$.fragment,e),x(_e.$$.fragment,e),x(be.$$.fragment,e),x(L),ia=!0)},o(e){g($.$$.fragment,e),g(_.$$.fragment,e),g(T.$$.fragment,e),g(se.$$.fragment,e),g(ne.$$.fragment,e),g(ie.$$.fragment,e),g(le.$$.fragment,e),g(me.$$.fragment,e),g(de.$$.fragment,e),g(ce.$$.fragment,e),g(D),g(pe.$$.fragment,e),g(fe.$$.fragment,e),g(he.$$.fragment,e),g(ve.$$.fragment,e),g($e.$$.fragment,e),g(ge.$$.fragment,e),g(xe.$$.fragment,e),g(_e.$$.fragment,e),g(be.$$.fragment,e),g(L),ia=!1},d(e){a(d),e&&a(u),A($,e),e&&a(h),e&&a(N),A(_),e&&a(k),e&&a(t),A(T),e&&a(Ve),A(se,e),e&&a(Be),e&&a(B),A(ne),e&&a(Re),A(ie,e),e&&a(Ge),e&&a(R),A(le),e&&a(Je),A(me,e),e&&a(We),e&&a(G),A(de),e&&a(Ke),A(ce,e),e&&a(Xe),qe[U].d(e),e&&a(Ee),e&&a(J),A(pe),e&&a(Ye),A(fe,e),e&&a(Ze),e&&a(W),A(he),e&&a(ea),A(ve,e),e&&a(aa),e&&a(K),A($e),e&&a(oa),A(ge,e),e&&a(ta),e&&a(X),A(xe),e&&a(ra),A(_e,e),e&&a(sa),A(be,e),e&&a(na),we[F].d(e),e&&a(Ae)}}}const Ao={local:"questionrio-de-fim-de-captulo",title:"Question\xE1rio de fim de cap\xEDtulo"};function yo(Q,d,u){let $="pt";return ko(()=>{const h=new URLSearchParams(window.location.search);u(0,$=h.get("fw")||"pt")}),[$]}class To extends vo{constructor(d){super();$o(this,d,yo,Eo,go,{})}}export{To as default,Ao as metadata};
