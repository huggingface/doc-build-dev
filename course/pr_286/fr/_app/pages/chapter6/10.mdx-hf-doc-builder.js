import{S as rn,i as an,s as on,e as n,k as u,w as m,t as d,M as ln,c as s,d as t,m as p,a as r,x as f,h as c,b as o,G as i,g as l,y as h,L as un,q as v,o as $,B as g,v as pn}from"../../chunks/vendor-hf-doc-builder.js";import{I as x}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{Q as q}from"../../chunks/Question-hf-doc-builder.js";function dn(zi){let k,Ve,z,Q,ze,V,It,we,Qt,Ge,qe,Lt,Re,w,L,_e,G,Ut,R,Ht,Ee,Bt,Wt,Je,J,Fe,_,U,ye,F,jt,K,Dt,be,Ot,Tt,Ke,X,Xe,E,H,Pe,Y,Mt,Z,Vt,Ce,Gt,Rt,Ye,ee,Ze,y,B,Ae,te,Jt,b,Ft,Se,Kt,Xt,Ne,Yt,Zt,et,ie,tt,P,W,Ie,ne,ei,se,ti,Qe,ii,ni,it,re,nt,C,j,Le,ae,si,Ue,ri,st,oe,rt,A,D,He,le,ai,ue,oi,Be,li,ui,at,pe,ot,S,O,We,de,pi,ce,di,je,ci,mi,lt,me,ut,N,T,De,fe,fi,he,hi,Oe,vi,$i,pt,ve,dt,I,M,Te,$e,gi,ge,xi,Me,qi,ki,ct,xe,mt;return V=new x({}),G=new x({}),J=new q({props:{choices:[{text:"Lorsque votre jeu de donn\xE9es est similaire \xE0 celui utilis\xE9 par un mod\xE8le pr\xE9-entra\xEEn\xE9 existant et que vous voulez pr\xE9-entra\xEEner un nouveau mod\xE8le",explain:"Dans ce cas, pour \xE9conomiser du temps et des ressources de calcul, il est pr\xE9f\xE9rable d'utiliser le m\xEAme <i>tokenizer</i> que le mod\xE8le pr\xE9-entra\xEEn\xE9 et de <i>finetuner</i> ce mod\xE8le \xE0 la place."},{text:"Lorsque votre jeu de donn\xE9es est similaire \xE0 celui utilis\xE9 par un mod\xE8le pr\xE9-entra\xEEn\xE9 existant et que vous souhaitez <i>finetuner</i> un nouveau mod\xE8le en utilisant ce mod\xE8le pr\xE9-entra\xEEn\xE9.",explain:"Pour <i>finetuner</i> un mod\xE8le \xE0 partir d'un mod\xE8le pr\xE9-entra\xEEn\xE9, vous devez toujours utiliser le m\xEAme <i>tokenizer</i>."},{text:"Lorsque votre jeu de donn\xE9es est diff\xE9rent de celui utilis\xE9 par un mod\xE8le pr\xE9-entra\xEEn\xE9 existant et que vous souhaitez pr\xE9-entra\xEEner un nouveau mod\xE8le.",explain:"Dans ce cas, il n'y a aucun avantage \xE0 utiliser le m\xEAme <i>tokenizer</i>.",correct:!0},{text:"Lorsque votre jeu de donn\xE9es est diff\xE9rent de celui utilis\xE9 par un mod\xE8le pr\xE9-entra\xEEn\xE9 existant mais que vous souhaitez <i>finetuner</i> un nouveau mod\xE8le en utilisant ce mod\xE8le pr\xE9-entra\xEEn\xE9.",explain:"Pour <i>finetuner</i> un mod\xE8le \xE0 partir d'un mod\xE8le pr\xE9-entra\xEEn\xE9, vous devez toujours utiliser le m\xEAme <i>tokenizer</i>."}]}}),F=new x({}),X=new q({props:{choices:[{text:"C'est le seul type que la m\xE9thode <code>train_new_from_iterator()</code> accepte.",explain:"Une liste de listes de textes est un type particulier de g\xE9n\xE9rateur de listes de textes, la m\xE9thode l'acceptera donc aussi. Essayez \xE0 nouveau !"},{text:"Vous \xE9viterez de charger l'ensemble des donn\xE9es en m\xE9moire en une seule fois.",explain:"Chaque batch de textes sera lib\xE9r\xE9 de la m\xE9moire lorsque vous it\xE9rerez et le gain sera particuli\xE8rement visible si vous utilisez des \u{1F917} <i>Datasets</i> pour stocker vos textes.",correct:!0},{text:"Cela permettra \xE0 la biblioth\xE8que \u{1F917} <i>Tokenizers</i> d'utiliser le multitraitement.",explain:"Il utilisera le multiprocesseur dans tous les cas."},{text:"Le <i>tokenizer</i> que vous entra\xEEnez g\xE9n\xE9rera de meilleurs textes.",explain:"Le <i>tokenizer</i> ne g\xE9n\xE8re pas de texte. Vous le confondez avec un mod\xE8le de langage ?"}]}}),Y=new x({}),ee=new q({props:{choices:[{text:"Il peut traiter les entr\xE9es plus rapidement qu'un <i>tokenizer</i> lent lorsque vous faites des batchs d'entr\xE9es.",explain:"Gr\xE2ce au parall\xE9lisme impl\xE9ment\xE9 dans Rust, il sera plus rapide sur les batchs d'entr\xE9es. Quel autre avantage pouvez-vous imaginer ?",correct:!0},{text:"Les <i>tokenizers</i> rapides sont toujours plus rapides que leurs homologues lents.",explain:"Un <i>tokenizer</i> rapide peut en fait \xEAtre plus lent si vous ne lui donnez qu'un seul ou tr\xE8s peu de textes, car il ne peut pas utiliser le parall\xE9lisme."},{text:"Il peut appliquer le <i>padding</i> et la troncature.",explain:"C'est vrai, mais les <i>tokenizers</i> lents le font aussi."},{text:"Il poss\xE8de des fonctionnalit\xE9s suppl\xE9mentaires qui vous permettent d'associer les <i>tokens</i> \xE0 l'extrait de texte qui les a cr\xE9\xE9s.",explain:"En effet, c'est ce qu'on appelle des correspondances d'<i>offset</i>. Ce n'est pas le seul avantage, cependant.",correct:!0}]}}),te=new x({}),ie=new q({props:{choices:[{text:"Les entit\xE9s ayant la m\xEAme \xE9tiquette sont fusionn\xE9es en une seule entit\xE9.",explain:"C'est un peu trop simplifier les choses. Essayez encore !"},{text:"Il existe une \xE9tiquette pour le d\xE9but d'une entit\xE9 et une \xE9tiquette pour la suite d'une entit\xE9.",explain:" ",correct:!0},{text:"Dans un mot donn\xE9, tant que le premier <i>token</i> porte l'\xE9tiquette de l'entit\xE9, le mot entier est consid\xE9r\xE9 comme \xE9tiquet\xE9 avec cette entit\xE9.",explain:"C'est une strat\xE9gie pour g\xE9rer les entit\xE9s. Quelles autres r\xE9ponses s'appliquent ici ?",correct:!0},{text:"Lorsqu'un <i>token</i> a l'\xE9tiquette d'une entit\xE9 donn\xE9e, tout autre <i>token</i> suivant ayant la m\xEAme \xE9tiquette est consid\xE9r\xE9 comme faisant partie de la m\xEAme entit\xE9, \xE0 moins qu'il ne soit \xE9tiquet\xE9 comme le d\xE9but d'une nouvelle entit\xE9.",explain:"C'est la fa\xE7on la plus courante de regrouper des entit\xE9s, mais ce n'est pas la seule bonne r\xE9ponse.",correct:!0}]}}),ne=new x({}),re=new q({props:{choices:[{text:"Ce n'est pas vraiment le cas car il tronque le long contexte \xE0 la longueur maximale accept\xE9e par le mod\xE8le.",explain:"Il existe une astuce que vous pouvez utiliser pour g\xE9rer les longs contextes. Vous en souvenez-vous ?"},{text:"Il divise le contexte en plusieurs parties et fait la moyenne des r\xE9sultats obtenus.",explain:"Cela n'aurait pas de sens de faire la moyenne des r\xE9sultats car certaines parties du contexte n'incluront pas la r\xE9ponse."},{text:"Il divise le contexte en plusieurs parties (avec chevauchement) et trouve le score maximum pour une r\xE9ponse dans chaque partie.",explain:"C'est la bonne r\xE9ponse !",correct:!0},{text:"Il divise le contexte en plusieurs parties (sans chevauchemen par souci d'efficacit\xE9) et trouve le score maximum pour une r\xE9ponse dans chaque partie.",explain:"Il comprend un certain chevauchement entre les parties pour \xE9viter une situation o\xF9 la r\xE9ponse serait divis\xE9e en deux parties."}]}}),ae=new x({}),oe=new q({props:{choices:[{text:"C'est le nettoyage que le <i>tokenizer</i> effectue sur les textes lors des \xE9tapes initiales.",explain:"Par exemple, il peut s'agir de supprimer les accents ou les espaces, ou de mettre les entr\xE9es en minuscules.",correct:!0},{text:"Il s'agit d'une technique d'augmentation de donn\xE9es qui consiste \xE0 rendre le texte plus normal en supprimant les mots rares.",explain:"Essayez encore."},{text:"C'est l'\xE9tape finale du post-traitement o\xF9 le <i>tokenizer</i> ajoute les <i>tokens</i> sp\xE9ciaux.",explain:"Cette \xE9tape est simplement appel\xE9e post-traitement."},{text:"C'est lorsque les ench\xE2ssements sont faits avec une moyenne nulle et un \xE9cart-type de 1, en soustrayant la moyenne et en divisant par l'\xE9cart-type.",explain:"Ce processus est commun\xE9ment appel\xE9 normalisation lorsqu'il est appliqu\xE9 aux valeurs des pixels en vision par ordinateur, mais ce n'est pas ce que signifie la normalisation en NLP."}]}}),le=new x({}),pe=new q({props:{choices:[{text:"C'est l'\xE9tape qui pr\xE9c\xE8de la tok\xE9nisation, o\xF9 l'augmentation des donn\xE9es (comme le masquage al\xE9atoire) est appliqu\xE9e.",explain:"Cette \xE9tape fait partie du pr\xE9traitement."},{text:"C'est l'\xE9tape avant la tok\xE9nisation, o\xF9 les op\xE9rations de nettoyage souhait\xE9es sont appliqu\xE9es au texte.",explain:"C'est l'\xE9tape de normalisation."},{text:"C'est l'\xE9tape qui pr\xE9c\xE8de l'application du mod\xE8le <i>tokenizer</i>, pour diviser l'entr\xE9e en mots.",explain:"C'est la bonne r\xE9ponse !",correct:!0},{text:"Il s'agit de l'\xE9tape pr\xE9c\xE9dant l'application du mod\xE8le <i>tokenizer</i>, qui divise l'entr\xE9e en <i>tokens</i>.",explain:"La division en <i>tokens</i> est le travail du mod\xE8le <i>tokenizer</i>."}]}}),de=new x({}),me=new q({props:{choices:[{text:"BPE est un algorithme de tok\xE9nisation en sous-mots qui part d'un petit vocabulaire et apprend des r\xE8gles de fusion.",explain:"C'est le cas en effet !",correct:!0},{text:"BPE est un algorithme de tok\xE9nisation en sous-mots qui part d'un grand vocabulaire et en retire progressivement les <i>tokens</i>.",explain:"C'est l'approche adopt\xE9e par un algorithme de tok\xE9nisation diff\xE9rent."},{text:"Un <i>tokenizer</i> BPE apprend les r\xE8gles de fusion en fusionnant la paire de <i>tokens</i> la plus fr\xE9quente.",explain:"C'est exact !",correct:!0},{text:"Un <i>tokenizer</i> BPE apprend une r\xE8gle de fusion en fusionnant la paire de <i>tokens</i> qui maximise un score qui privil\xE9gie les paires fr\xE9quentes avec des parties individuelles moins fr\xE9quentes.",explain:"C'est la strat\xE9gie appliqu\xE9e par un autre algorithme de tokenization."},{text:"BPE tokenise les mots en sous-mots en les divisant en caract\xE8res, puis en appliquant les r\xE8gles de fusion.",explain:" ",correct:!0},{text:"BPE tokenise les mots en sous-mots en trouvant le plus long sous-mot du vocabulaire en commen\xE7ant par le d\xE9but, puis en r\xE9p\xE9tant le processus pour le reste du texte.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."}]}}),fe=new x({}),ve=new q({props:{choices:[{text:"WordPiece est un algorithme de tok\xE9nisation en sous-mots qui part d'un petit vocabulaire et apprend des r\xE8gles de fusion.",explain:"C'est le cas en effet !",correct:!0},{text:"WordPiece est un algorithme de tok\xE9nisation en sous-mots qui part d'un grand vocabulaire et en retire progressivement les <i>tokens</i>.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."},{text:"WordPiece Les <i>tokenizer</i> apprennent les r\xE8gles de fusion en fusionnant la paire de <i>tokens</i> la plus fr\xE9quente.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."},{text:"Un <i>tokenizer</i> WordPiece apprend une r\xE8gle de fusion en fusionnant la paire de <i>tokens</i> qui maximise un score qui privil\xE9gie les paires fr\xE9quentes avec des parties individuelles moins fr\xE9quentes.",explain:" ",correct:!0},{text:"WordPiece tokenise les mots en sous-mots en trouvant la segmentation en <i>tokens</i> la plus probable, selon le mod\xE8le.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."},{text:"WordPiece tokenise les mots en sous-mots en trouvant le plus long sous-mot du vocabulaire en commen\xE7ant par le d\xE9but, puis en r\xE9p\xE9tant le processus pour le reste du texte.",explain:"C'est ainsi que WordPiece proc\xE8de pour l'encodage.",correct:!0}]}}),$e=new x({}),xe=new q({props:{choices:[{text:"Unigram est un algorithme de tok\xE9nisation en sous-mots qui part d'un petit vocabulaire et apprend des r\xE8gles de fusion.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."},{text:"Unigram est un algorithme de tok\xE9nisation en sous-mots qui part d'un grand vocabulaire et en retire progressivement les <i>tokens</i>.",explain:" ",correct:!0},{text:"Unigram adapte son vocabulaire en minimisant une perte calcul\xE9e sur l'ensemble du corpus.",explain:" ",correct:!0},{text:"Unigram adapte son vocabulaire en conservant les sous-mots les plus fr\xE9quents.",explain:" "},{text:"Unigram segmente les mots en sous-mots en trouvant la segmentation la plus probable en <i>tokens</i>, selon le mod\xE8le.",explain:" ",correct:!0},{text:"Unigram d\xE9compose les mots en sous-mots en les divisant en caract\xE8res puis en appliquant les r\xE8gles de fusion.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."}]}}),{c(){k=n("meta"),Ve=u(),z=n("h1"),Q=n("a"),ze=n("span"),m(V.$$.fragment),It=u(),we=n("span"),Qt=d("Quiz de fin de chapitre"),Ge=u(),qe=n("p"),Lt=d("Testons ce que vous avez appris dans ce chapitre !"),Re=u(),w=n("h3"),L=n("a"),_e=n("span"),m(G.$$.fragment),Ut=u(),R=n("span"),Ht=d("1. Quand devez-vous entra\xEEner un nouveau "),Ee=n("i"),Bt=d("tokenizer"),Wt=d(" ?"),Je=u(),m(J.$$.fragment),Fe=u(),_=n("h3"),U=n("a"),ye=n("span"),m(F.$$.fragment),jt=u(),K=n("span"),Dt=d("2. Quel est l\u2019avantage d\u2019utiliser un g\xE9n\xE9rateur de listes par rapport \xE0 une liste de listes lors de l\u2019utilisation de "),be=n("code"),Ot=d("train_new_from_iterator()"),Tt=d(" ?"),Ke=u(),m(X.$$.fragment),Xe=u(),E=n("h3"),H=n("a"),Pe=n("span"),m(Y.$$.fragment),Mt=u(),Z=n("span"),Vt=d("3. Quels sont les avantages d\u2019utiliser un "),Ce=n("i"),Gt=d("tokenizer"),Rt=d(" \xAB rapide \xBB ?"),Ye=u(),m(ee.$$.fragment),Ze=u(),y=n("h3"),B=n("a"),Ae=n("span"),m(te.$$.fragment),Jt=u(),b=n("span"),Ft=d("4. Comment le pipeline "),Se=n("code"),Kt=d("token-classification"),Xt=d(" g\xE8re-t-il les entit\xE9s qui s\u2019\xE9tendent sur plusieurs "),Ne=n("i"),Yt=d("tokens"),Zt=d(" ?"),et=u(),m(ie.$$.fragment),tt=u(),P=n("h3"),W=n("a"),Ie=n("span"),m(ne.$$.fragment),ei=u(),se=n("span"),ti=d("5. Comment le pipeline "),Qe=n("code"),ii=d("question-answering"),ni=d(" g\xE8re-t-il les contextes longs ?"),it=u(),m(re.$$.fragment),nt=u(),C=n("h3"),j=n("a"),Le=n("span"),m(ae.$$.fragment),si=u(),Ue=n("span"),ri=d("6. Qu\u2019est-ce que la normalisation ?"),st=u(),m(oe.$$.fragment),rt=u(),A=n("h3"),D=n("a"),He=n("span"),m(le.$$.fragment),ai=u(),ue=n("span"),oi=d("7. Qu\u2019est-ce que la pr\xE9-tok\xE9nisation pour un "),Be=n("i"),li=d("tokenizer"),ui=d(" en sous-mots ?"),at=u(),m(pe.$$.fragment),ot=u(),S=n("h3"),O=n("a"),We=n("span"),m(de.$$.fragment),pi=u(),ce=n("span"),di=d("8. S\xE9lectionnez les phrases qui s\u2019appliquent au "),je=n("i"),ci=d("tokenizer"),mi=d(" BPE."),lt=u(),m(me.$$.fragment),ut=u(),N=n("h3"),T=n("a"),De=n("span"),m(fe.$$.fragment),fi=u(),he=n("span"),hi=d("9. S\xE9lectionnez les phrases qui s\u2019appliquent au "),Oe=n("i"),vi=d("tokenizer"),$i=d(" WordPiece."),pt=u(),m(ve.$$.fragment),dt=u(),I=n("h3"),M=n("a"),Te=n("span"),m($e.$$.fragment),gi=u(),ge=n("span"),xi=d("10. S\xE9lectionnez les phrases qui s\u2019appliquent au "),Me=n("i"),qi=d("tokenizer"),ki=d(" Unigram."),ct=u(),m(xe.$$.fragment),this.h()},l(e){const a=ln('[data-svelte="svelte-1phssyn"]',document.head);k=s(a,"META",{name:!0,content:!0}),a.forEach(t),Ve=p(e),z=s(e,"H1",{class:!0});var ft=r(z);Q=s(ft,"A",{id:!0,class:!0,href:!0});var wi=r(Q);ze=s(wi,"SPAN",{});var _i=r(ze);f(V.$$.fragment,_i),_i.forEach(t),wi.forEach(t),It=p(ft),we=s(ft,"SPAN",{});var Ei=r(we);Qt=c(Ei,"Quiz de fin de chapitre"),Ei.forEach(t),ft.forEach(t),Ge=p(e),qe=s(e,"P",{});var yi=r(qe);Lt=c(yi,"Testons ce que vous avez appris dans ce chapitre !"),yi.forEach(t),Re=p(e),w=s(e,"H3",{class:!0});var ht=r(w);L=s(ht,"A",{id:!0,class:!0,href:!0});var bi=r(L);_e=s(bi,"SPAN",{});var Pi=r(_e);f(G.$$.fragment,Pi),Pi.forEach(t),bi.forEach(t),Ut=p(ht),R=s(ht,"SPAN",{});var vt=r(R);Ht=c(vt,"1. Quand devez-vous entra\xEEner un nouveau "),Ee=s(vt,"I",{});var Ci=r(Ee);Bt=c(Ci,"tokenizer"),Ci.forEach(t),Wt=c(vt," ?"),vt.forEach(t),ht.forEach(t),Je=p(e),f(J.$$.fragment,e),Fe=p(e),_=s(e,"H3",{class:!0});var $t=r(_);U=s($t,"A",{id:!0,class:!0,href:!0});var Ai=r(U);ye=s(Ai,"SPAN",{});var Si=r(ye);f(F.$$.fragment,Si),Si.forEach(t),Ai.forEach(t),jt=p($t),K=s($t,"SPAN",{});var gt=r(K);Dt=c(gt,"2. Quel est l\u2019avantage d\u2019utiliser un g\xE9n\xE9rateur de listes par rapport \xE0 une liste de listes lors de l\u2019utilisation de "),be=s(gt,"CODE",{});var Ni=r(be);Ot=c(Ni,"train_new_from_iterator()"),Ni.forEach(t),Tt=c(gt," ?"),gt.forEach(t),$t.forEach(t),Ke=p(e),f(X.$$.fragment,e),Xe=p(e),E=s(e,"H3",{class:!0});var xt=r(E);H=s(xt,"A",{id:!0,class:!0,href:!0});var Ii=r(H);Pe=s(Ii,"SPAN",{});var Qi=r(Pe);f(Y.$$.fragment,Qi),Qi.forEach(t),Ii.forEach(t),Mt=p(xt),Z=s(xt,"SPAN",{});var qt=r(Z);Vt=c(qt,"3. Quels sont les avantages d\u2019utiliser un "),Ce=s(qt,"I",{});var Li=r(Ce);Gt=c(Li,"tokenizer"),Li.forEach(t),Rt=c(qt," \xAB rapide \xBB ?"),qt.forEach(t),xt.forEach(t),Ye=p(e),f(ee.$$.fragment,e),Ze=p(e),y=s(e,"H3",{class:!0});var kt=r(y);B=s(kt,"A",{id:!0,class:!0,href:!0});var Ui=r(B);Ae=s(Ui,"SPAN",{});var Hi=r(Ae);f(te.$$.fragment,Hi),Hi.forEach(t),Ui.forEach(t),Jt=p(kt),b=s(kt,"SPAN",{});var ke=r(b);Ft=c(ke,"4. Comment le pipeline "),Se=s(ke,"CODE",{});var Bi=r(Se);Kt=c(Bi,"token-classification"),Bi.forEach(t),Xt=c(ke," g\xE8re-t-il les entit\xE9s qui s\u2019\xE9tendent sur plusieurs "),Ne=s(ke,"I",{});var Wi=r(Ne);Yt=c(Wi,"tokens"),Wi.forEach(t),Zt=c(ke," ?"),ke.forEach(t),kt.forEach(t),et=p(e),f(ie.$$.fragment,e),tt=p(e),P=s(e,"H3",{class:!0});var zt=r(P);W=s(zt,"A",{id:!0,class:!0,href:!0});var ji=r(W);Ie=s(ji,"SPAN",{});var Di=r(Ie);f(ne.$$.fragment,Di),Di.forEach(t),ji.forEach(t),ei=p(zt),se=s(zt,"SPAN",{});var wt=r(se);ti=c(wt,"5. Comment le pipeline "),Qe=s(wt,"CODE",{});var Oi=r(Qe);ii=c(Oi,"question-answering"),Oi.forEach(t),ni=c(wt," g\xE8re-t-il les contextes longs ?"),wt.forEach(t),zt.forEach(t),it=p(e),f(re.$$.fragment,e),nt=p(e),C=s(e,"H3",{class:!0});var _t=r(C);j=s(_t,"A",{id:!0,class:!0,href:!0});var Ti=r(j);Le=s(Ti,"SPAN",{});var Mi=r(Le);f(ae.$$.fragment,Mi),Mi.forEach(t),Ti.forEach(t),si=p(_t),Ue=s(_t,"SPAN",{});var Vi=r(Ue);ri=c(Vi,"6. Qu\u2019est-ce que la normalisation ?"),Vi.forEach(t),_t.forEach(t),st=p(e),f(oe.$$.fragment,e),rt=p(e),A=s(e,"H3",{class:!0});var Et=r(A);D=s(Et,"A",{id:!0,class:!0,href:!0});var Gi=r(D);He=s(Gi,"SPAN",{});var Ri=r(He);f(le.$$.fragment,Ri),Ri.forEach(t),Gi.forEach(t),ai=p(Et),ue=s(Et,"SPAN",{});var yt=r(ue);oi=c(yt,"7. Qu\u2019est-ce que la pr\xE9-tok\xE9nisation pour un "),Be=s(yt,"I",{});var Ji=r(Be);li=c(Ji,"tokenizer"),Ji.forEach(t),ui=c(yt," en sous-mots ?"),yt.forEach(t),Et.forEach(t),at=p(e),f(pe.$$.fragment,e),ot=p(e),S=s(e,"H3",{class:!0});var bt=r(S);O=s(bt,"A",{id:!0,class:!0,href:!0});var Fi=r(O);We=s(Fi,"SPAN",{});var Ki=r(We);f(de.$$.fragment,Ki),Ki.forEach(t),Fi.forEach(t),pi=p(bt),ce=s(bt,"SPAN",{});var Pt=r(ce);di=c(Pt,"8. S\xE9lectionnez les phrases qui s\u2019appliquent au "),je=s(Pt,"I",{});var Xi=r(je);ci=c(Xi,"tokenizer"),Xi.forEach(t),mi=c(Pt," BPE."),Pt.forEach(t),bt.forEach(t),lt=p(e),f(me.$$.fragment,e),ut=p(e),N=s(e,"H3",{class:!0});var Ct=r(N);T=s(Ct,"A",{id:!0,class:!0,href:!0});var Yi=r(T);De=s(Yi,"SPAN",{});var Zi=r(De);f(fe.$$.fragment,Zi),Zi.forEach(t),Yi.forEach(t),fi=p(Ct),he=s(Ct,"SPAN",{});var At=r(he);hi=c(At,"9. S\xE9lectionnez les phrases qui s\u2019appliquent au "),Oe=s(At,"I",{});var en=r(Oe);vi=c(en,"tokenizer"),en.forEach(t),$i=c(At," WordPiece."),At.forEach(t),Ct.forEach(t),pt=p(e),f(ve.$$.fragment,e),dt=p(e),I=s(e,"H3",{class:!0});var St=r(I);M=s(St,"A",{id:!0,class:!0,href:!0});var tn=r(M);Te=s(tn,"SPAN",{});var nn=r(Te);f($e.$$.fragment,nn),nn.forEach(t),tn.forEach(t),gi=p(St),ge=s(St,"SPAN",{});var Nt=r(ge);xi=c(Nt,"10. S\xE9lectionnez les phrases qui s\u2019appliquent au "),Me=s(Nt,"I",{});var sn=r(Me);qi=c(sn,"tokenizer"),sn.forEach(t),ki=c(Nt," Unigram."),Nt.forEach(t),St.forEach(t),ct=p(e),f(xe.$$.fragment,e),this.h()},h(){o(k,"name","hf:doc:metadata"),o(k,"content",JSON.stringify(cn)),o(Q,"id","quiz-de-fin-de-chapitre"),o(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(Q,"href","#quiz-de-fin-de-chapitre"),o(z,"class","relative group"),o(L,"id","1.-quand-devez-vous-entra\xEEner-un-nouveau-<i>tokenizer</i>-?"),o(L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(L,"href","#1.-quand-devez-vous-entra\xEEner-un-nouveau-<i>tokenizer</i>-?"),o(w,"class","relative group"),o(U,"id","2.-quel-est-l\u2019avantage-d\u2019utiliser-un-g\xE9n\xE9rateur-de-listes-par-rapport-\xE0-une-liste-de-listes-lors-de-l\u2019utilisation-de-<code>train_new_from_iterator()</code>-?"),o(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(U,"href","#2.-quel-est-l\u2019avantage-d\u2019utiliser-un-g\xE9n\xE9rateur-de-listes-par-rapport-\xE0-une-liste-de-listes-lors-de-l\u2019utilisation-de-<code>train_new_from_iterator()</code>-?"),o(_,"class","relative group"),o(H,"id","3.-quels-sont-les-avantages-d\u2019utiliser-un-<i>tokenizer</i>-\xAB-rapide-\xBB-?"),o(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(H,"href","#3.-quels-sont-les-avantages-d\u2019utiliser-un-<i>tokenizer</i>-\xAB-rapide-\xBB-?"),o(E,"class","relative group"),o(B,"id","4.-comment-le-pipeline-<code>token-classification</code>-g\xE8re-t-il-les-entit\xE9s-qui-s\u2019\xE9tendent-sur-plusieurs-<i>tokens</i>-?"),o(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(B,"href","#4.-comment-le-pipeline-<code>token-classification</code>-g\xE8re-t-il-les-entit\xE9s-qui-s\u2019\xE9tendent-sur-plusieurs-<i>tokens</i>-?"),o(y,"class","relative group"),o(W,"id","5.-comment-le-pipeline-<code>question-answering</code>-g\xE8re-t-il-les-contextes-longs-?"),o(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(W,"href","#5.-comment-le-pipeline-<code>question-answering</code>-g\xE8re-t-il-les-contextes-longs-?"),o(P,"class","relative group"),o(j,"id","6.-qu\u2019est-ce-que-la-normalisation-?"),o(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(j,"href","#6.-qu\u2019est-ce-que-la-normalisation-?"),o(C,"class","relative group"),o(D,"id","7.-qu\u2019est-ce-que-la-pr\xE9-tok\xE9nisation-pour-un-<i>tokenizer</i>-en-sous-mots-?"),o(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(D,"href","#7.-qu\u2019est-ce-que-la-pr\xE9-tok\xE9nisation-pour-un-<i>tokenizer</i>-en-sous-mots-?"),o(A,"class","relative group"),o(O,"id","8.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-bpe."),o(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(O,"href","#8.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-bpe."),o(S,"class","relative group"),o(T,"id","9.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-wordpiece."),o(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(T,"href","#9.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-wordpiece."),o(N,"class","relative group"),o(M,"id","10.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-unigram."),o(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(M,"href","#10.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-unigram."),o(I,"class","relative group")},m(e,a){i(document.head,k),l(e,Ve,a),l(e,z,a),i(z,Q),i(Q,ze),h(V,ze,null),i(z,It),i(z,we),i(we,Qt),l(e,Ge,a),l(e,qe,a),i(qe,Lt),l(e,Re,a),l(e,w,a),i(w,L),i(L,_e),h(G,_e,null),i(w,Ut),i(w,R),i(R,Ht),i(R,Ee),i(Ee,Bt),i(R,Wt),l(e,Je,a),h(J,e,a),l(e,Fe,a),l(e,_,a),i(_,U),i(U,ye),h(F,ye,null),i(_,jt),i(_,K),i(K,Dt),i(K,be),i(be,Ot),i(K,Tt),l(e,Ke,a),h(X,e,a),l(e,Xe,a),l(e,E,a),i(E,H),i(H,Pe),h(Y,Pe,null),i(E,Mt),i(E,Z),i(Z,Vt),i(Z,Ce),i(Ce,Gt),i(Z,Rt),l(e,Ye,a),h(ee,e,a),l(e,Ze,a),l(e,y,a),i(y,B),i(B,Ae),h(te,Ae,null),i(y,Jt),i(y,b),i(b,Ft),i(b,Se),i(Se,Kt),i(b,Xt),i(b,Ne),i(Ne,Yt),i(b,Zt),l(e,et,a),h(ie,e,a),l(e,tt,a),l(e,P,a),i(P,W),i(W,Ie),h(ne,Ie,null),i(P,ei),i(P,se),i(se,ti),i(se,Qe),i(Qe,ii),i(se,ni),l(e,it,a),h(re,e,a),l(e,nt,a),l(e,C,a),i(C,j),i(j,Le),h(ae,Le,null),i(C,si),i(C,Ue),i(Ue,ri),l(e,st,a),h(oe,e,a),l(e,rt,a),l(e,A,a),i(A,D),i(D,He),h(le,He,null),i(A,ai),i(A,ue),i(ue,oi),i(ue,Be),i(Be,li),i(ue,ui),l(e,at,a),h(pe,e,a),l(e,ot,a),l(e,S,a),i(S,O),i(O,We),h(de,We,null),i(S,pi),i(S,ce),i(ce,di),i(ce,je),i(je,ci),i(ce,mi),l(e,lt,a),h(me,e,a),l(e,ut,a),l(e,N,a),i(N,T),i(T,De),h(fe,De,null),i(N,fi),i(N,he),i(he,hi),i(he,Oe),i(Oe,vi),i(he,$i),l(e,pt,a),h(ve,e,a),l(e,dt,a),l(e,I,a),i(I,M),i(M,Te),h($e,Te,null),i(I,gi),i(I,ge),i(ge,xi),i(ge,Me),i(Me,qi),i(ge,ki),l(e,ct,a),h(xe,e,a),mt=!0},p:un,i(e){mt||(v(V.$$.fragment,e),v(G.$$.fragment,e),v(J.$$.fragment,e),v(F.$$.fragment,e),v(X.$$.fragment,e),v(Y.$$.fragment,e),v(ee.$$.fragment,e),v(te.$$.fragment,e),v(ie.$$.fragment,e),v(ne.$$.fragment,e),v(re.$$.fragment,e),v(ae.$$.fragment,e),v(oe.$$.fragment,e),v(le.$$.fragment,e),v(pe.$$.fragment,e),v(de.$$.fragment,e),v(me.$$.fragment,e),v(fe.$$.fragment,e),v(ve.$$.fragment,e),v($e.$$.fragment,e),v(xe.$$.fragment,e),mt=!0)},o(e){$(V.$$.fragment,e),$(G.$$.fragment,e),$(J.$$.fragment,e),$(F.$$.fragment,e),$(X.$$.fragment,e),$(Y.$$.fragment,e),$(ee.$$.fragment,e),$(te.$$.fragment,e),$(ie.$$.fragment,e),$(ne.$$.fragment,e),$(re.$$.fragment,e),$(ae.$$.fragment,e),$(oe.$$.fragment,e),$(le.$$.fragment,e),$(pe.$$.fragment,e),$(de.$$.fragment,e),$(me.$$.fragment,e),$(fe.$$.fragment,e),$(ve.$$.fragment,e),$($e.$$.fragment,e),$(xe.$$.fragment,e),mt=!1},d(e){t(k),e&&t(Ve),e&&t(z),g(V),e&&t(Ge),e&&t(qe),e&&t(Re),e&&t(w),g(G),e&&t(Je),g(J,e),e&&t(Fe),e&&t(_),g(F),e&&t(Ke),g(X,e),e&&t(Xe),e&&t(E),g(Y),e&&t(Ye),g(ee,e),e&&t(Ze),e&&t(y),g(te),e&&t(et),g(ie,e),e&&t(tt),e&&t(P),g(ne),e&&t(it),g(re,e),e&&t(nt),e&&t(C),g(ae),e&&t(st),g(oe,e),e&&t(rt),e&&t(A),g(le),e&&t(at),g(pe,e),e&&t(ot),e&&t(S),g(de),e&&t(lt),g(me,e),e&&t(ut),e&&t(N),g(fe),e&&t(pt),g(ve,e),e&&t(dt),e&&t(I),g($e),e&&t(ct),g(xe,e)}}}const cn={local:"quiz-de-fin-de-chapitre",title:"Quiz de fin de chapitre"};function mn(zi){return pn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class $n extends rn{constructor(k){super();an(this,k,mn,dn,on,{})}}export{$n as default,cn as metadata};
