import{S as kt,i as gt,s as _t,e as p,k as f,w as g,t as l,l as ct,M as bt,c as u,d as s,m,x as _,a as c,h as i,b as I,G as n,g as r,y as b,o as d,p as ft,q as k,B as $,v as $t,n as mt}from"../../chunks/vendor-hf-doc-builder.js";import{I as ht}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as j}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as dt}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as qt}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function wt(v){let a,h;return a=new dt({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter2/section6_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter2/section6_tf.ipynb"}]}}),{c(){g(a.$$.fragment)},l(o){_(a.$$.fragment,o)},m(o,q){b(a,o,q),h=!0},i(o){h||(k(a.$$.fragment,o),h=!0)},o(o){d(a.$$.fragment,o),h=!1},d(o){$(a,o)}}}function jt(v){let a,h;return a=new dt({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter2/section6_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter2/section6_pt.ipynb"}]}}),{c(){g(a.$$.fragment)},l(o){_(a.$$.fragment,o)},m(o,q){b(a,o,q),h=!0},i(o){h||(k(a.$$.fragment,o),h=!0)},o(o){d(a.$$.fragment,o),h=!1},d(o){$(a,o)}}}function vt(v){let a,h;return a=new j({props:{code:`import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)
sequences = ["I've been waiting for a HuggingFace course my whole life.", "So have I!"]

tokens = tokenizer(sequences, padding=True, truncation=True, return_tensors="tf")
output = model(**tokens)`,highlighted:`<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)
sequences = [<span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>, <span class="hljs-string">&quot;So have I!&quot;</span>]

tokens = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)
output = model(**tokens)`}}),{c(){g(a.$$.fragment)},l(o){_(a.$$.fragment,o)},m(o,q){b(a,o,q),h=!0},i(o){h||(k(a.$$.fragment,o),h=!0)},o(o){d(a.$$.fragment,o),h=!1},d(o){$(a,o)}}}function zt(v){let a,h;return a=new j({props:{code:`import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
sequences = ["I've been waiting for a HuggingFace course my whole life.", "So have I!"]

tokens = tokenizer(sequences, padding=True, truncation=True, return_tensors="pt")
output = model(**tokens)`,highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
sequences = [<span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>, <span class="hljs-string">&quot;So have I!&quot;</span>]

tokens = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
output = model(**tokens)`}}),{c(){g(a.$$.fragment)},l(o){_(a.$$.fragment,o)},m(o,q){b(a,o,q),h=!0},i(o){h||(k(a.$$.fragment,o),h=!0)},o(o){d(a.$$.fragment,o),h=!1},d(o){$(a,o)}}}function yt(v){let a,h,o,q,B,ns,Te,z,y,se,te,os,Ie,C,rs,me,as,ls,Se,M,Pe,S,is,he,ps,us,de,cs,fs,Ae,ne,ms,Fe,O,De,oe,hs,Ce,L,xe,re,ds,He,G,Re,ae,ks,Ne,J,Be,w,ke,gs,_s,ge,bs,$s,_e,qs,ws,be,js,vs,Me,U,Oe,A,x,$e,K,zs,qe,ys,Le,le,Es,Ge,Q,Je,V,Ue,ie,Ts,Ke,W,Qe,X,Ve,P,Is,we,Ss,Ps,je,As,Fs,We,F,H,ve,Y,Ds,ze,Cs,Xe,R,xs,ye,Hs,Rs,Ye,E,T,pe,Ze;o=new qt({props:{fw:v[0]}});const Ns=[jt,wt],Z=[];function Bs(e,t){return e[0]==="pt"?0:1}z=Bs(v),y=Z[z]=Ns[z](v),M=new j({props:{code:`from transformers import AutoTokenizer

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

model_inputs = tokenizer(sequence)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

sequence = <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>

model_inputs = tokenizer(sequence)`}}),O=new j({props:{code:`sequence = "I've been waiting for a HuggingFace course my whole life."

model_inputs = tokenizer(sequence)`,highlighted:`sequence = <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>

model_inputs = tokenizer(sequence)`}}),L=new j({props:{code:`sequences = ["I've been waiting for a HuggingFace course my whole life.", "So have I!"]

model_inputs = tokenizer(sequences)`,highlighted:`sequences = [<span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>, <span class="hljs-string">&quot;So have I!&quot;</span>]

model_inputs = tokenizer(sequences)`}}),G=new j({props:{code:`# \u0E08\u0E30\u0E40\u0E15\u0E34\u0E21\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E44\u0E1B\u0E08\u0E19\u0E16\u0E36\u0E07\u0E04\u0E27\u0E32\u0E21\u0E22\u0E32\u0E27\u0E17\u0E35\u0E48\u0E22\u0E32\u0E27\u0E17\u0E35\u0E48\u0E2A\u0E38\u0E14\u0E02\u0E2D\u0E07\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04
model_inputs = tokenizer(sequences, padding="longest")

# \u0E08\u0E30\u0E40\u0E15\u0E34\u0E21\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E44\u0E1B\u0E08\u0E19\u0E16\u0E36\u0E07\u0E04\u0E27\u0E32\u0E21\u0E22\u0E32\u0E27\u0E17\u0E35\u0E48\u0E22\u0E32\u0E27\u0E17\u0E35\u0E48\u0E2A\u0E38\u0E14\u0E17\u0E35\u0E48\u0E42\u0E21\u0E40\u0E14\u0E25\u0E23\u0E31\u0E1A\u0E44\u0E14\u0E49
# (512 for BERT or DistilBERT)
model_inputs = tokenizer(sequences, padding="max_length")

# \u0E08\u0E30\u0E40\u0E15\u0E34\u0E21\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E44\u0E1B\u0E08\u0E19\u0E16\u0E36\u0E07\u0E04\u0E27\u0E32\u0E21\u0E22\u0E32\u0E27\u0E17\u0E35\u0E48\u0E22\u0E32\u0E27\u0E17\u0E35\u0E48\u0E2A\u0E38\u0E14\u0E17\u0E35\u0E48\u0E23\u0E30\u0E1A\u0E38\u0E44\u0E27\u0E49
model_inputs = tokenizer(sequences, padding="max_length", max_length=8)`,highlighted:`<span class="hljs-comment"># \u0E08\u0E30\u0E40\u0E15\u0E34\u0E21\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E44\u0E1B\u0E08\u0E19\u0E16\u0E36\u0E07\u0E04\u0E27\u0E32\u0E21\u0E22\u0E32\u0E27\u0E17\u0E35\u0E48\u0E22\u0E32\u0E27\u0E17\u0E35\u0E48\u0E2A\u0E38\u0E14\u0E02\u0E2D\u0E07\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04</span>
model_inputs = tokenizer(sequences, padding=<span class="hljs-string">&quot;longest&quot;</span>)

<span class="hljs-comment"># \u0E08\u0E30\u0E40\u0E15\u0E34\u0E21\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E44\u0E1B\u0E08\u0E19\u0E16\u0E36\u0E07\u0E04\u0E27\u0E32\u0E21\u0E22\u0E32\u0E27\u0E17\u0E35\u0E48\u0E22\u0E32\u0E27\u0E17\u0E35\u0E48\u0E2A\u0E38\u0E14\u0E17\u0E35\u0E48\u0E42\u0E21\u0E40\u0E14\u0E25\u0E23\u0E31\u0E1A\u0E44\u0E14\u0E49</span>
<span class="hljs-comment"># (512 for BERT or DistilBERT)</span>
model_inputs = tokenizer(sequences, padding=<span class="hljs-string">&quot;max_length&quot;</span>)

<span class="hljs-comment"># \u0E08\u0E30\u0E40\u0E15\u0E34\u0E21\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E44\u0E1B\u0E08\u0E19\u0E16\u0E36\u0E07\u0E04\u0E27\u0E32\u0E21\u0E22\u0E32\u0E27\u0E17\u0E35\u0E48\u0E22\u0E32\u0E27\u0E17\u0E35\u0E48\u0E2A\u0E38\u0E14\u0E17\u0E35\u0E48\u0E23\u0E30\u0E1A\u0E38\u0E44\u0E27\u0E49</span>
model_inputs = tokenizer(sequences, padding=<span class="hljs-string">&quot;max_length&quot;</span>, max_length=<span class="hljs-number">8</span>)`}}),J=new j({props:{code:`sequences = ["I've been waiting for a HuggingFace course my whole life.", "So have I!"]

# \u0E08\u0E30\u0E15\u0E31\u0E14\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E17\u0E35\u0E48\u0E21\u0E35\u0E04\u0E27\u0E32\u0E21\u0E22\u0E32\u0E27\u0E40\u0E01\u0E34\u0E19\u0E01\u0E27\u0E48\u0E32\u0E04\u0E27\u0E32\u0E21\u0E22\u0E32\u0E27\u0E17\u0E35\u0E48\u0E42\u0E21\u0E40\u0E14\u0E25\u0E23\u0E31\u0E1A\u0E44\u0E14\u0E49
# (512 for BERT or DistilBERT)
model_inputs = tokenizer(sequences, truncation=True)

# \u0E08\u0E30\u0E15\u0E31\u0E14\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E17\u0E35\u0E48\u0E21\u0E35\u0E04\u0E27\u0E32\u0E21\u0E22\u0E32\u0E27\u0E40\u0E01\u0E34\u0E19\u0E01\u0E27\u0E48\u0E32\u0E04\u0E27\u0E32\u0E21\u0E22\u0E32\u0E27\u0E17\u0E35\u0E48\u0E23\u0E30\u0E1A\u0E38\u0E44\u0E27\u0E49
model_inputs = tokenizer(sequences, max_length=8, truncation=True)`,highlighted:`sequences = [<span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>, <span class="hljs-string">&quot;So have I!&quot;</span>]

<span class="hljs-comment"># \u0E08\u0E30\u0E15\u0E31\u0E14\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E17\u0E35\u0E48\u0E21\u0E35\u0E04\u0E27\u0E32\u0E21\u0E22\u0E32\u0E27\u0E40\u0E01\u0E34\u0E19\u0E01\u0E27\u0E48\u0E32\u0E04\u0E27\u0E32\u0E21\u0E22\u0E32\u0E27\u0E17\u0E35\u0E48\u0E42\u0E21\u0E40\u0E14\u0E25\u0E23\u0E31\u0E1A\u0E44\u0E14\u0E49</span>
<span class="hljs-comment"># (512 for BERT or DistilBERT)</span>
model_inputs = tokenizer(sequences, truncation=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># \u0E08\u0E30\u0E15\u0E31\u0E14\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E17\u0E35\u0E48\u0E21\u0E35\u0E04\u0E27\u0E32\u0E21\u0E22\u0E32\u0E27\u0E40\u0E01\u0E34\u0E19\u0E01\u0E27\u0E48\u0E32\u0E04\u0E27\u0E32\u0E21\u0E22\u0E32\u0E27\u0E17\u0E35\u0E48\u0E23\u0E30\u0E1A\u0E38\u0E44\u0E27\u0E49</span>
model_inputs = tokenizer(sequences, max_length=<span class="hljs-number">8</span>, truncation=<span class="hljs-literal">True</span>)`}}),U=new j({props:{code:`sequences = ["I've been waiting for a HuggingFace course my whole life.", "So have I!"]

# Returns PyTorch tensors
model_inputs = tokenizer(sequences, padding=True, return_tensors="pt")

# Returns TensorFlow tensors
model_inputs = tokenizer(sequences, padding=True, return_tensors="tf")

# Returns NumPy arrays
model_inputs = tokenizer(sequences, padding=True, return_tensors="np")`,highlighted:`sequences = [<span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>, <span class="hljs-string">&quot;So have I!&quot;</span>]

<span class="hljs-comment"># Returns PyTorch tensors</span>
model_inputs = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)

<span class="hljs-comment"># Returns TensorFlow tensors</span>
model_inputs = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)

<span class="hljs-comment"># Returns NumPy arrays</span>
model_inputs = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;np&quot;</span>)`}}),K=new ht({}),Q=new j({props:{code:`sequence = "I've been waiting for a HuggingFace course my whole life."

model_inputs = tokenizer(sequence)
print(model_inputs["input_ids"])

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)
print(ids)`,highlighted:`sequence = <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>

model_inputs = tokenizer(sequence)
<span class="hljs-built_in">print</span>(model_inputs[<span class="hljs-string">&quot;input_ids&quot;</span>])

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)
<span class="hljs-built_in">print</span>(ids)`}}),V=new j({props:{code:`[101, 1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012, 102]
[1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012]`,highlighted:`[<span class="hljs-number">101</span>, <span class="hljs-number">1045</span>, <span class="hljs-number">1005</span>, <span class="hljs-number">2310</span>, <span class="hljs-number">2042</span>, <span class="hljs-number">3403</span>, <span class="hljs-number">2005</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">17662</span>, <span class="hljs-number">12172</span>, <span class="hljs-number">2607</span>, <span class="hljs-number">2026</span>, <span class="hljs-number">2878</span>, <span class="hljs-number">2166</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>]
[<span class="hljs-number">1045</span>, <span class="hljs-number">1005</span>, <span class="hljs-number">2310</span>, <span class="hljs-number">2042</span>, <span class="hljs-number">3403</span>, <span class="hljs-number">2005</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">17662</span>, <span class="hljs-number">12172</span>, <span class="hljs-number">2607</span>, <span class="hljs-number">2026</span>, <span class="hljs-number">2878</span>, <span class="hljs-number">2166</span>, <span class="hljs-number">1012</span>]`}}),W=new j({props:{code:`print(tokenizer.decode(model_inputs["input_ids"]))
print(tokenizer.decode(ids))`,highlighted:`<span class="hljs-built_in">print</span>(tokenizer.decode(model_inputs[<span class="hljs-string">&quot;input_ids&quot;</span>]))
<span class="hljs-built_in">print</span>(tokenizer.decode(ids))`}}),X=new j({props:{code:`"[CLS] i've been waiting for a huggingface course my whole life. [SEP]"
"i've been waiting for a huggingface course my whole life."`,highlighted:`<span class="hljs-string">&quot;[CLS] i&#x27;ve been waiting for a huggingface course my whole life. [SEP]&quot;</span>
<span class="hljs-string">&quot;i&#x27;ve been waiting for a huggingface course my whole life.&quot;</span>`}}),Y=new ht({});const Ms=[zt,vt],ee=[];function Os(e,t){return e[0]==="pt"?0:1}return E=Os(v),T=ee[E]=Ms[E](v),{c(){a=p("meta"),h=f(),g(o.$$.fragment),q=f(),B=p("h1"),ns=l("\u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E17\u0E38\u0E01\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E40\u0E02\u0E49\u0E32\u0E14\u0E49\u0E27\u0E22\u0E01\u0E31\u0E19"),Te=f(),y.c(),se=f(),te=p("p"),os=l("\u0E43\u0E19\u0E2A\u0E2D\u0E07\u0E2A\u0E32\u0E21 sections \u0E17\u0E35\u0E48\u0E1C\u0E48\u0E32\u0E19\u0E21\u0E32 \u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E1E\u0E22\u0E32\u0E22\u0E32\u0E21\u0E17\u0E33\u0E17\u0E38\u0E01\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E14\u0E49\u0E27\u0E22\u0E21\u0E37\u0E2D\u0E02\u0E2D\u0E07\u0E40\u0E23\u0E32\u0E40\u0E2D\u0E07 \u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E25\u0E2D\u0E07\u0E28\u0E36\u0E01\u0E29\u0E32\u0E27\u0E48\u0E32 tokenizer \u0E19\u0E31\u0E49\u0E19\u0E17\u0E33\u0E07\u0E32\u0E19\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E44\u0E23\u0E41\u0E25\u0E30\u0E27\u0E34\u0E18\u0E35\u0E01\u0E32\u0E23 tokenization, \u0E41\u0E1B\u0E25\u0E07\u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E44\u0E1B\u0E40\u0E1B\u0E47\u0E19 input IDs, \u0E01\u0E32\u0E23\u0E40\u0E15\u0E34\u0E21(padding), \u0E01\u0E32\u0E23\u0E15\u0E31\u0E14(truncation), \u0E41\u0E25\u0E30 attention masks"),Ie=f(),C=p("p"),rs=l("\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E44\u0E23\u0E01\u0E47\u0E15\u0E32\u0E21 \u0E40\u0E2B\u0E21\u0E37\u0E2D\u0E19\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E40\u0E2B\u0E47\u0E19\u0E43\u0E19 section 2, \u{1F917} Transformers API \u0E19\u0E31\u0E49\u0E19\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E08\u0E31\u0E14\u0E01\u0E32\u0E23\u0E01\u0E31\u0E1A\u0E2A\u0E34\u0E48\u0E07\u0E15\u0E48\u0E32\u0E07\u0E46\u0E40\u0E2B\u0E25\u0E48\u0E32\u0E19\u0E31\u0E49\u0E19\u0E43\u0E2B\u0E49\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E14\u0E49\u0E27\u0E22 high-level \u0E1F\u0E31\u0E07\u0E01\u0E4C\u0E0A\u0E31\u0E19\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E08\u0E30\u0E25\u0E07\u0E25\u0E36\u0E07\u0E43\u0E19\u0E23\u0E32\u0E22\u0E25\u0E30\u0E40\u0E2D\u0E35\u0E22\u0E14\u0E01\u0E31\u0E19\u0E43\u0E19\u0E17\u0E35\u0E48\u0E19\u0E35\u0E48 \u0E40\u0E21\u0E37\u0E48\u0E2D\u0E04\u0E38\u0E13\u0E40\u0E23\u0E35\u0E22\u0E01\u0E43\u0E0A\u0E49\u0E07\u0E32\u0E19 "),me=p("code"),as=l("tokenizer"),ls=l(" \u0E02\u0E2D\u0E07\u0E04\u0E38\u0E13\u0E15\u0E23\u0E07\u0E46\u0E01\u0E31\u0E1A\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E2B\u0E19\u0E36\u0E48\u0E07\u0E46, \u0E04\u0E38\u0E13\u0E44\u0E14\u0E49\u0E2D\u0E34\u0E19\u0E1E\u0E38\u0E15\u0E17\u0E35\u0E48\u0E1E\u0E23\u0E49\u0E2D\u0E21\u0E08\u0E30\u0E43\u0E2A\u0E48\u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E22\u0E31\u0E07\u0E42\u0E21\u0E40\u0E14\u0E25\u0E01\u0E25\u0E31\u0E1A\u0E21\u0E32:"),Se=f(),g(M.$$.fragment),Pe=f(),S=p("p"),is=l("\u0E43\u0E19\u0E17\u0E35\u0E48\u0E19\u0E35\u0E49 \u0E15\u0E31\u0E27\u0E41\u0E1B\u0E23 "),he=p("code"),ps=l("model_inputs"),us=l(" \u0E19\u0E31\u0E49\u0E19\u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E14\u0E49\u0E27\u0E22\u0E17\u0E38\u0E01\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E17\u0E35\u0E48\u0E08\u0E33\u0E40\u0E1B\u0E47\u0E19\u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A\u0E42\u0E21\u0E40\u0E14\u0E25\u0E17\u0E35\u0E48\u0E08\u0E30\u0E17\u0E33\u0E07\u0E32\u0E19\u0E44\u0E14\u0E49\u0E40\u0E1B\u0E47\u0E19\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E14\u0E35 \u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A DistilBERT \u0E19\u0E31\u0E49\u0E19\u0E23\u0E27\u0E21\u0E44\u0E1B\u0E16\u0E36\u0E07 input IDs \u0E41\u0E25\u0E30 attention mask \u0E14\u0E49\u0E27\u0E22 \u0E2A\u0E48\u0E27\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25\u0E2D\u0E37\u0E48\u0E19\u0E46\u0E17\u0E35\u0E48\u0E23\u0E2D\u0E07\u0E23\u0E31\u0E1A\u0E2D\u0E34\u0E19\u0E1E\u0E38\u0E15\u0E15\u0E48\u0E32\u0E07\u0E46\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E40\u0E15\u0E34\u0E21\u0E01\u0E47\u0E08\u0E30\u0E44\u0E14\u0E49\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E17\u0E4C\u0E40\u0E2B\u0E25\u0E48\u0E32\u0E19\u0E31\u0E49\u0E19\u0E08\u0E32\u0E01 "),de=p("code"),cs=l("tokenizer"),fs=l(" object \u0E14\u0E49\u0E27\u0E22"),Ae=f(),ne=p("p"),ms=l("\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E08\u0E30\u0E44\u0E14\u0E49\u0E40\u0E2B\u0E47\u0E19\u0E43\u0E19\u0E1A\u0E32\u0E07\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E14\u0E49\u0E32\u0E19\u0E25\u0E48\u0E32\u0E07\u0E19\u0E35\u0E49 \u0E27\u0E34\u0E18\u0E35\u0E19\u0E35\u0E49\u0E40\u0E1B\u0E47\u0E19\u0E27\u0E34\u0E18\u0E35\u0E17\u0E35\u0E48\u0E17\u0E23\u0E07\u0E1E\u0E25\u0E31\u0E07\u0E21\u0E32\u0E01 \u0E2D\u0E31\u0E19\u0E14\u0E31\u0E1A\u0E41\u0E23\u0E01 \u0E21\u0E31\u0E19\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E17\u0E35\u0E48\u0E08\u0E30 tokenize \u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E40\u0E1E\u0E35\u0E22\u0E07\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E40\u0E14\u0E35\u0E22\u0E27\u0E44\u0E14\u0E49:"),Fe=f(),g(O.$$.fragment),De=f(),oe=p("p"),hs=l("\u0E21\u0E31\u0E19\u0E22\u0E31\u0E07\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E08\u0E31\u0E14\u0E01\u0E32\u0E23\u0E01\u0E31\u0E1A\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E2B\u0E25\u0E32\u0E22\u0E46\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E44\u0E14\u0E49\u0E43\u0E19\u0E04\u0E23\u0E32\u0E27\u0E40\u0E14\u0E35\u0E22\u0E27\u0E01\u0E31\u0E19 \u0E42\u0E14\u0E22\u0E17\u0E35\u0E48\u0E44\u0E21\u0E48\u0E21\u0E35\u0E2D\u0E30\u0E44\u0E23\u0E40\u0E1B\u0E25\u0E35\u0E48\u0E22\u0E19\u0E43\u0E19  API \u0E40\u0E25\u0E22:"),Ce=f(),g(L.$$.fragment),xe=f(),re=p("p"),ds=l("\u0E21\u0E31\u0E19\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E17\u0E35\u0E48\u0E08\u0E30\u0E40\u0E15\u0E34\u0E21(padding) \u0E43\u0E2B\u0E49\u0E2A\u0E2D\u0E14\u0E04\u0E25\u0E49\u0E2D\u0E07\u0E01\u0E31\u0E1A\u0E2B\u0E25\u0E32\u0E22\u0E46\u0E27\u0E31\u0E15\u0E16\u0E38\u0E1B\u0E23\u0E30\u0E2A\u0E07\u0E04\u0E4C:"),He=f(),g(G.$$.fragment),Re=f(),ae=p("p"),ks=l("\u0E21\u0E31\u0E19\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E15\u0E31\u0E14\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E44\u0E14\u0E49\u0E2D\u0E35\u0E01\u0E14\u0E49\u0E27\u0E22:"),Ne=f(),g(J.$$.fragment),Be=f(),w=p("p"),ke=p("code"),gs=l("tokenizer"),_s=l(" object \u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E17\u0E35\u0E48\u0E08\u0E30\u0E08\u0E31\u0E14\u0E01\u0E32\u0E23\u0E01\u0E31\u0E1A\u0E01\u0E32\u0E23\u0E41\u0E1B\u0E25\u0E07\u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E44\u0E1B\u0E40\u0E1B\u0E47\u0E19 tensors \u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A framework \u0E17\u0E35\u0E48\u0E40\u0E09\u0E1E\u0E32\u0E30\u0E40\u0E08\u0E32\u0E30\u0E08\u0E07\u0E44\u0E14\u0E49 \u0E0B\u0E36\u0E48\u0E07\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E17\u0E35\u0E48\u0E08\u0E30\u0E2A\u0E48\u0E07\u0E40\u0E02\u0E49\u0E32\u0E42\u0E21\u0E40\u0E14\u0E25\u0E44\u0E14\u0E49\u0E17\u0E31\u0E19\u0E17\u0E35 \u0E22\u0E01\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E40\u0E0A\u0E48\u0E19 \u0E43\u0E19\u0E42\u0E04\u0E49\u0E14\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E19\u0E35\u0E49 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E2A\u0E31\u0E48\u0E07\u0E43\u0E2B\u0E49 tokenizer \u0E2A\u0E48\u0E07 tensors \u0E08\u0E32\u0E01 frameworks \u0E15\u0E48\u0E32\u0E07\u0E46 \u0E01\u0E31\u0E19 \u2014 "),ge=p("code"),bs=l('"pt"'),$s=l(" \u0E43\u0E2B\u0E49 PyTorch tensors, "),_e=p("code"),qs=l('"tf"'),ws=l(" \u0E43\u0E2B\u0E49 TensorFlow tensors, and "),be=p("code"),js=l('"np"'),vs=l(" \u0E43\u0E2B\u0E49 NumPy arrays:"),Me=f(),g(U.$$.fragment),Oe=f(),A=p("h2"),x=p("a"),$e=p("span"),g(K.$$.fragment),zs=f(),qe=p("span"),ys=l("tokens \u0E1E\u0E34\u0E40\u0E28\u0E29"),Le=f(),le=p("p"),Es=l("\u0E16\u0E49\u0E32\u0E40\u0E23\u0E32\u0E14\u0E39\u0E17\u0E35\u0E48 input IDs \u0E17\u0E35\u0E48\u0E44\u0E14\u0E49\u0E08\u0E32\u0E01 tokenizer \u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E2B\u0E47\u0E19\u0E44\u0E14\u0E49\u0E27\u0E48\u0E32\u0E21\u0E31\u0E19\u0E04\u0E48\u0E2D\u0E19\u0E02\u0E49\u0E32\u0E07\u0E41\u0E15\u0E01\u0E15\u0E48\u0E32\u0E07\u0E44\u0E1B\u0E08\u0E32\u0E01\u0E2A\u0E34\u0E48\u0E07\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E40\u0E04\u0E22\u0E44\u0E14\u0E49\u0E01\u0E48\u0E2D\u0E19\u0E2B\u0E19\u0E49\u0E32\u0E19\u0E35\u0E49:"),Ge=f(),g(Q.$$.fragment),Je=f(),g(V.$$.fragment),Ue=f(),ie=p("p"),Ts=l("\u0E21\u0E35\u0E2B\u0E19\u0E36\u0E48\u0E07 token ID \u0E44\u0E14\u0E49\u0E16\u0E39\u0E01\u0E43\u0E2A\u0E48\u0E40\u0E02\u0E49\u0E32\u0E21\u0E32\u0E14\u0E49\u0E32\u0E19\u0E2B\u0E19\u0E49\u0E32\u0E2A\u0E38\u0E14 \u0E41\u0E25\u0E30\u0E2D\u0E35\u0E01\u0E2B\u0E19\u0E36\u0E48\u0E07 token ID \u0E43\u0E2A\u0E48\u0E14\u0E49\u0E32\u0E19\u0E2B\u0E25\u0E31\u0E07\u0E2A\u0E38\u0E14 \u0E21\u0E32\u0E16\u0E2D\u0E14\u0E23\u0E2B\u0E31\u0E2A\u0E2A\u0E2D\u0E07\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E02\u0E2D\u0E07 IDs \u0E14\u0E49\u0E32\u0E19\u0E1A\u0E19\u0E14\u0E39\u0E27\u0E48\u0E32\u0E21\u0E31\u0E19\u0E40\u0E01\u0E35\u0E48\u0E22\u0E01\u0E31\u0E1A\u0E2D\u0E30\u0E44\u0E23:"),Ke=f(),g(W.$$.fragment),Qe=f(),g(X.$$.fragment),Ve=f(),P=p("p"),Is=l("tokenizer \u0E17\u0E33\u0E01\u0E32\u0E23\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E04\u0E33\u0E1E\u0E34\u0E40\u0E28\u0E29 "),we=p("code"),Ss=l("[CLS]"),Ps=l(" \u0E17\u0E35\u0E48\u0E14\u0E49\u0E32\u0E19\u0E2B\u0E19\u0E49\u0E32\u0E2A\u0E38\u0E14 \u0E41\u0E25\u0E30\u0E04\u0E33\u0E1E\u0E34\u0E40\u0E28\u0E29 "),je=p("code"),As=l("[SEP]"),Fs=l(" \u0E17\u0E35\u0E48\u0E14\u0E49\u0E32\u0E19\u0E2B\u0E25\u0E31\u0E07\u0E2A\u0E38\u0E14 \u0E19\u0E31\u0E49\u0E19\u0E01\u0E47\u0E40\u0E1E\u0E23\u0E32\u0E30\u0E27\u0E48\u0E32\u0E42\u0E21\u0E40\u0E14\u0E25\u0E19\u0E31\u0E49\u0E19\u0E44\u0E14\u0E49\u0E1C\u0E48\u0E32\u0E19\u0E01\u0E32\u0E23\u0E40\u0E17\u0E23\u0E19\u0E21\u0E32\u0E41\u0E1A\u0E1A\u0E19\u0E31\u0E49\u0E19 \u0E14\u0E31\u0E07\u0E19\u0E31\u0E49\u0E19\u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E43\u0E2B\u0E49\u0E44\u0E14\u0E49\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E17\u0E4C\u0E40\u0E14\u0E35\u0E22\u0E27\u0E01\u0E31\u0E19\u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A\u0E01\u0E32\u0E23\u0E2D\u0E19\u0E38\u0E21\u0E32\u0E19(inference) \u0E40\u0E23\u0E32\u0E08\u0E33\u0E40\u0E1B\u0E47\u0E19\u0E15\u0E49\u0E2D\u0E07\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E21\u0E31\u0E19\u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E40\u0E0A\u0E48\u0E19\u0E40\u0E14\u0E35\u0E22\u0E27\u0E01\u0E31\u0E19 \u0E41\u0E15\u0E48\u0E01\u0E47\u0E15\u0E49\u0E2D\u0E07\u0E15\u0E23\u0E30\u0E2B\u0E19\u0E31\u0E01\u0E27\u0E48\u0E32\u0E1A\u0E32\u0E07\u0E42\u0E21\u0E40\u0E14\u0E25\u0E19\u0E31\u0E49\u0E19\u0E44\u0E21\u0E48\u0E44\u0E14\u0E49\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E04\u0E33\u0E1E\u0E34\u0E40\u0E28\u0E29 \u0E2B\u0E23\u0E37\u0E2D \u0E43\u0E2A\u0E48\u0E04\u0E33\u0E17\u0E35\u0E48\u0E15\u0E48\u0E32\u0E07\u0E2D\u0E2D\u0E01\u0E44\u0E1B; \u0E42\u0E21\u0E40\u0E14\u0E25\u0E2D\u0E32\u0E08\u0E08\u0E30\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E04\u0E33\u0E1E\u0E34\u0E40\u0E28\u0E29\u0E40\u0E2B\u0E25\u0E48\u0E32\u0E19\u0E35\u0E49\u0E41\u0E04\u0E48\u0E40\u0E09\u0E1E\u0E32\u0E30\u0E14\u0E49\u0E32\u0E19\u0E2B\u0E19\u0E49\u0E32\u0E2A\u0E38\u0E14 \u0E2B\u0E23\u0E37\u0E2D \u0E14\u0E49\u0E32\u0E19\u0E2B\u0E25\u0E31\u0E07\u0E2A\u0E38\u0E14\u0E40\u0E17\u0E48\u0E32\u0E19\u0E31\u0E49\u0E19 \u0E44\u0E21\u0E48\u0E27\u0E48\u0E32\u0E08\u0E30\u0E43\u0E19\u0E01\u0E23\u0E13\u0E35\u0E43\u0E14\u0E46 tokenizer \u0E23\u0E39\u0E49\u0E27\u0E48\u0E32\u0E2D\u0E31\u0E19\u0E44\u0E2B\u0E19\u0E40\u0E1B\u0E47\u0E19\u0E2D\u0E31\u0E19\u0E17\u0E35\u0E48\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E32\u0E23\u0E41\u0E25\u0E30\u0E21\u0E31\u0E19\u0E08\u0E30\u0E08\u0E31\u0E14\u0E01\u0E32\u0E23\u0E43\u0E2B\u0E49\u0E04\u0E38\u0E13\u0E40\u0E2D\u0E07:"),We=f(),F=p("h2"),H=p("a"),ve=p("span"),g(Y.$$.fragment),Ds=f(),ze=p("span"),Cs=l("\u0E2A\u0E23\u0E38\u0E1B: \u0E08\u0E32\u0E01 tokenizer \u0E44\u0E1B\u0E22\u0E31\u0E07\u0E42\u0E21\u0E40\u0E14\u0E25"),Xe=f(),R=p("p"),xs=l("\u0E16\u0E36\u0E07\u0E15\u0E23\u0E07\u0E19\u0E35\u0E49\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E40\u0E2B\u0E47\u0E19\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E41\u0E15\u0E48\u0E25\u0E30\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E17\u0E31\u0E49\u0E07\u0E2B\u0E21\u0E14\u0E17\u0E35\u0E48 "),ye=p("code"),Hs=l("tokenizer"),Rs=l(" \u0E43\u0E0A\u0E49\u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E1B\u0E23\u0E30\u0E21\u0E27\u0E25\u0E1C\u0E25\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21 \u0E40\u0E23\u0E32\u0E21\u0E32\u0E14\u0E39\u0E01\u0E31\u0E19\u0E04\u0E23\u0E31\u0E49\u0E07\u0E2A\u0E38\u0E14\u0E17\u0E49\u0E32\u0E22\u0E27\u0E48\u0E32\u0E21\u0E31\u0E19\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E08\u0E31\u0E14\u0E01\u0E32\u0E23\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E2B\u0E25\u0E32\u0E22\u0E46\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04 (padding!), \u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E22\u0E32\u0E27\u0E46, \u0E41\u0E25\u0E30 tensors \u0E2B\u0E25\u0E32\u0E22\u0E46 \u0E1B\u0E23\u0E30\u0E40\u0E20\u0E17\u0E44\u0E14\u0E49\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E44\u0E23\u0E14\u0E49\u0E27\u0E22 API \u0E2B\u0E25\u0E31\u0E01\u0E02\u0E2D\u0E07\u0E21\u0E31\u0E19:"),Ye=f(),T.c(),pe=ct(),this.h()},l(e){const t=bt('[data-svelte="svelte-1phssyn"]',document.head);a=u(t,"META",{name:!0,content:!0}),t.forEach(s),h=m(e),_(o.$$.fragment,e),q=m(e),B=u(e,"H1",{id:!0});var Ee=c(B);ns=i(Ee,"\u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E17\u0E38\u0E01\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E40\u0E02\u0E49\u0E32\u0E14\u0E49\u0E27\u0E22\u0E01\u0E31\u0E19"),Ee.forEach(s),Te=m(e),y.l(e),se=m(e),te=u(e,"P",{});var ue=c(te);os=i(ue,"\u0E43\u0E19\u0E2A\u0E2D\u0E07\u0E2A\u0E32\u0E21 sections \u0E17\u0E35\u0E48\u0E1C\u0E48\u0E32\u0E19\u0E21\u0E32 \u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E1E\u0E22\u0E32\u0E22\u0E32\u0E21\u0E17\u0E33\u0E17\u0E38\u0E01\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E14\u0E49\u0E27\u0E22\u0E21\u0E37\u0E2D\u0E02\u0E2D\u0E07\u0E40\u0E23\u0E32\u0E40\u0E2D\u0E07 \u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E25\u0E2D\u0E07\u0E28\u0E36\u0E01\u0E29\u0E32\u0E27\u0E48\u0E32 tokenizer \u0E19\u0E31\u0E49\u0E19\u0E17\u0E33\u0E07\u0E32\u0E19\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E44\u0E23\u0E41\u0E25\u0E30\u0E27\u0E34\u0E18\u0E35\u0E01\u0E32\u0E23 tokenization, \u0E41\u0E1B\u0E25\u0E07\u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E44\u0E1B\u0E40\u0E1B\u0E47\u0E19 input IDs, \u0E01\u0E32\u0E23\u0E40\u0E15\u0E34\u0E21(padding), \u0E01\u0E32\u0E23\u0E15\u0E31\u0E14(truncation), \u0E41\u0E25\u0E30 attention masks"),ue.forEach(s),Ie=m(e),C=u(e,"P",{});var N=c(C);rs=i(N,"\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E44\u0E23\u0E01\u0E47\u0E15\u0E32\u0E21 \u0E40\u0E2B\u0E21\u0E37\u0E2D\u0E19\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E40\u0E2B\u0E47\u0E19\u0E43\u0E19 section 2, \u{1F917} Transformers API \u0E19\u0E31\u0E49\u0E19\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E08\u0E31\u0E14\u0E01\u0E32\u0E23\u0E01\u0E31\u0E1A\u0E2A\u0E34\u0E48\u0E07\u0E15\u0E48\u0E32\u0E07\u0E46\u0E40\u0E2B\u0E25\u0E48\u0E32\u0E19\u0E31\u0E49\u0E19\u0E43\u0E2B\u0E49\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E14\u0E49\u0E27\u0E22 high-level \u0E1F\u0E31\u0E07\u0E01\u0E4C\u0E0A\u0E31\u0E19\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E08\u0E30\u0E25\u0E07\u0E25\u0E36\u0E07\u0E43\u0E19\u0E23\u0E32\u0E22\u0E25\u0E30\u0E40\u0E2D\u0E35\u0E22\u0E14\u0E01\u0E31\u0E19\u0E43\u0E19\u0E17\u0E35\u0E48\u0E19\u0E35\u0E48 \u0E40\u0E21\u0E37\u0E48\u0E2D\u0E04\u0E38\u0E13\u0E40\u0E23\u0E35\u0E22\u0E01\u0E43\u0E0A\u0E49\u0E07\u0E32\u0E19 "),me=u(N,"CODE",{});var Ls=c(me);as=i(Ls,"tokenizer"),Ls.forEach(s),ls=i(N," \u0E02\u0E2D\u0E07\u0E04\u0E38\u0E13\u0E15\u0E23\u0E07\u0E46\u0E01\u0E31\u0E1A\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E2B\u0E19\u0E36\u0E48\u0E07\u0E46, \u0E04\u0E38\u0E13\u0E44\u0E14\u0E49\u0E2D\u0E34\u0E19\u0E1E\u0E38\u0E15\u0E17\u0E35\u0E48\u0E1E\u0E23\u0E49\u0E2D\u0E21\u0E08\u0E30\u0E43\u0E2A\u0E48\u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E22\u0E31\u0E07\u0E42\u0E21\u0E40\u0E14\u0E25\u0E01\u0E25\u0E31\u0E1A\u0E21\u0E32:"),N.forEach(s),Se=m(e),_(M.$$.fragment,e),Pe=m(e),S=u(e,"P",{});var ce=c(S);is=i(ce,"\u0E43\u0E19\u0E17\u0E35\u0E48\u0E19\u0E35\u0E49 \u0E15\u0E31\u0E27\u0E41\u0E1B\u0E23 "),he=u(ce,"CODE",{});var Gs=c(he);ps=i(Gs,"model_inputs"),Gs.forEach(s),us=i(ce," \u0E19\u0E31\u0E49\u0E19\u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E14\u0E49\u0E27\u0E22\u0E17\u0E38\u0E01\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E17\u0E35\u0E48\u0E08\u0E33\u0E40\u0E1B\u0E47\u0E19\u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A\u0E42\u0E21\u0E40\u0E14\u0E25\u0E17\u0E35\u0E48\u0E08\u0E30\u0E17\u0E33\u0E07\u0E32\u0E19\u0E44\u0E14\u0E49\u0E40\u0E1B\u0E47\u0E19\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E14\u0E35 \u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A DistilBERT \u0E19\u0E31\u0E49\u0E19\u0E23\u0E27\u0E21\u0E44\u0E1B\u0E16\u0E36\u0E07 input IDs \u0E41\u0E25\u0E30 attention mask \u0E14\u0E49\u0E27\u0E22 \u0E2A\u0E48\u0E27\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25\u0E2D\u0E37\u0E48\u0E19\u0E46\u0E17\u0E35\u0E48\u0E23\u0E2D\u0E07\u0E23\u0E31\u0E1A\u0E2D\u0E34\u0E19\u0E1E\u0E38\u0E15\u0E15\u0E48\u0E32\u0E07\u0E46\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E40\u0E15\u0E34\u0E21\u0E01\u0E47\u0E08\u0E30\u0E44\u0E14\u0E49\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E17\u0E4C\u0E40\u0E2B\u0E25\u0E48\u0E32\u0E19\u0E31\u0E49\u0E19\u0E08\u0E32\u0E01 "),de=u(ce,"CODE",{});var Js=c(de);cs=i(Js,"tokenizer"),Js.forEach(s),fs=i(ce," object \u0E14\u0E49\u0E27\u0E22"),ce.forEach(s),Ae=m(e),ne=u(e,"P",{});var Us=c(ne);ms=i(Us,"\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E08\u0E30\u0E44\u0E14\u0E49\u0E40\u0E2B\u0E47\u0E19\u0E43\u0E19\u0E1A\u0E32\u0E07\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E14\u0E49\u0E32\u0E19\u0E25\u0E48\u0E32\u0E07\u0E19\u0E35\u0E49 \u0E27\u0E34\u0E18\u0E35\u0E19\u0E35\u0E49\u0E40\u0E1B\u0E47\u0E19\u0E27\u0E34\u0E18\u0E35\u0E17\u0E35\u0E48\u0E17\u0E23\u0E07\u0E1E\u0E25\u0E31\u0E07\u0E21\u0E32\u0E01 \u0E2D\u0E31\u0E19\u0E14\u0E31\u0E1A\u0E41\u0E23\u0E01 \u0E21\u0E31\u0E19\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E17\u0E35\u0E48\u0E08\u0E30 tokenize \u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E40\u0E1E\u0E35\u0E22\u0E07\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E40\u0E14\u0E35\u0E22\u0E27\u0E44\u0E14\u0E49:"),Us.forEach(s),Fe=m(e),_(O.$$.fragment,e),De=m(e),oe=u(e,"P",{});var Ks=c(oe);hs=i(Ks,"\u0E21\u0E31\u0E19\u0E22\u0E31\u0E07\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E08\u0E31\u0E14\u0E01\u0E32\u0E23\u0E01\u0E31\u0E1A\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E2B\u0E25\u0E32\u0E22\u0E46\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E44\u0E14\u0E49\u0E43\u0E19\u0E04\u0E23\u0E32\u0E27\u0E40\u0E14\u0E35\u0E22\u0E27\u0E01\u0E31\u0E19 \u0E42\u0E14\u0E22\u0E17\u0E35\u0E48\u0E44\u0E21\u0E48\u0E21\u0E35\u0E2D\u0E30\u0E44\u0E23\u0E40\u0E1B\u0E25\u0E35\u0E48\u0E22\u0E19\u0E43\u0E19  API \u0E40\u0E25\u0E22:"),Ks.forEach(s),Ce=m(e),_(L.$$.fragment,e),xe=m(e),re=u(e,"P",{});var Qs=c(re);ds=i(Qs,"\u0E21\u0E31\u0E19\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E17\u0E35\u0E48\u0E08\u0E30\u0E40\u0E15\u0E34\u0E21(padding) \u0E43\u0E2B\u0E49\u0E2A\u0E2D\u0E14\u0E04\u0E25\u0E49\u0E2D\u0E07\u0E01\u0E31\u0E1A\u0E2B\u0E25\u0E32\u0E22\u0E46\u0E27\u0E31\u0E15\u0E16\u0E38\u0E1B\u0E23\u0E30\u0E2A\u0E07\u0E04\u0E4C:"),Qs.forEach(s),He=m(e),_(G.$$.fragment,e),Re=m(e),ae=u(e,"P",{});var Vs=c(ae);ks=i(Vs,"\u0E21\u0E31\u0E19\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E15\u0E31\u0E14\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E44\u0E14\u0E49\u0E2D\u0E35\u0E01\u0E14\u0E49\u0E27\u0E22:"),Vs.forEach(s),Ne=m(e),_(J.$$.fragment,e),Be=m(e),w=u(e,"P",{});var D=c(w);ke=u(D,"CODE",{});var Ws=c(ke);gs=i(Ws,"tokenizer"),Ws.forEach(s),_s=i(D," object \u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E17\u0E35\u0E48\u0E08\u0E30\u0E08\u0E31\u0E14\u0E01\u0E32\u0E23\u0E01\u0E31\u0E1A\u0E01\u0E32\u0E23\u0E41\u0E1B\u0E25\u0E07\u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E44\u0E1B\u0E40\u0E1B\u0E47\u0E19 tensors \u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A framework \u0E17\u0E35\u0E48\u0E40\u0E09\u0E1E\u0E32\u0E30\u0E40\u0E08\u0E32\u0E30\u0E08\u0E07\u0E44\u0E14\u0E49 \u0E0B\u0E36\u0E48\u0E07\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E17\u0E35\u0E48\u0E08\u0E30\u0E2A\u0E48\u0E07\u0E40\u0E02\u0E49\u0E32\u0E42\u0E21\u0E40\u0E14\u0E25\u0E44\u0E14\u0E49\u0E17\u0E31\u0E19\u0E17\u0E35 \u0E22\u0E01\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E40\u0E0A\u0E48\u0E19 \u0E43\u0E19\u0E42\u0E04\u0E49\u0E14\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E19\u0E35\u0E49 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E2A\u0E31\u0E48\u0E07\u0E43\u0E2B\u0E49 tokenizer \u0E2A\u0E48\u0E07 tensors \u0E08\u0E32\u0E01 frameworks \u0E15\u0E48\u0E32\u0E07\u0E46 \u0E01\u0E31\u0E19 \u2014 "),ge=u(D,"CODE",{});var Xs=c(ge);bs=i(Xs,'"pt"'),Xs.forEach(s),$s=i(D," \u0E43\u0E2B\u0E49 PyTorch tensors, "),_e=u(D,"CODE",{});var Ys=c(_e);qs=i(Ys,'"tf"'),Ys.forEach(s),ws=i(D," \u0E43\u0E2B\u0E49 TensorFlow tensors, and "),be=u(D,"CODE",{});var Zs=c(be);js=i(Zs,'"np"'),Zs.forEach(s),vs=i(D," \u0E43\u0E2B\u0E49 NumPy arrays:"),D.forEach(s),Me=m(e),_(U.$$.fragment,e),Oe=m(e),A=u(e,"H2",{class:!0});var es=c(A);x=u(es,"A",{id:!0,class:!0,href:!0});var et=c(x);$e=u(et,"SPAN",{});var st=c($e);_(K.$$.fragment,st),st.forEach(s),et.forEach(s),zs=m(es),qe=u(es,"SPAN",{});var tt=c(qe);ys=i(tt,"tokens \u0E1E\u0E34\u0E40\u0E28\u0E29"),tt.forEach(s),es.forEach(s),Le=m(e),le=u(e,"P",{});var nt=c(le);Es=i(nt,"\u0E16\u0E49\u0E32\u0E40\u0E23\u0E32\u0E14\u0E39\u0E17\u0E35\u0E48 input IDs \u0E17\u0E35\u0E48\u0E44\u0E14\u0E49\u0E08\u0E32\u0E01 tokenizer \u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E2B\u0E47\u0E19\u0E44\u0E14\u0E49\u0E27\u0E48\u0E32\u0E21\u0E31\u0E19\u0E04\u0E48\u0E2D\u0E19\u0E02\u0E49\u0E32\u0E07\u0E41\u0E15\u0E01\u0E15\u0E48\u0E32\u0E07\u0E44\u0E1B\u0E08\u0E32\u0E01\u0E2A\u0E34\u0E48\u0E07\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E40\u0E04\u0E22\u0E44\u0E14\u0E49\u0E01\u0E48\u0E2D\u0E19\u0E2B\u0E19\u0E49\u0E32\u0E19\u0E35\u0E49:"),nt.forEach(s),Ge=m(e),_(Q.$$.fragment,e),Je=m(e),_(V.$$.fragment,e),Ue=m(e),ie=u(e,"P",{});var ot=c(ie);Ts=i(ot,"\u0E21\u0E35\u0E2B\u0E19\u0E36\u0E48\u0E07 token ID \u0E44\u0E14\u0E49\u0E16\u0E39\u0E01\u0E43\u0E2A\u0E48\u0E40\u0E02\u0E49\u0E32\u0E21\u0E32\u0E14\u0E49\u0E32\u0E19\u0E2B\u0E19\u0E49\u0E32\u0E2A\u0E38\u0E14 \u0E41\u0E25\u0E30\u0E2D\u0E35\u0E01\u0E2B\u0E19\u0E36\u0E48\u0E07 token ID \u0E43\u0E2A\u0E48\u0E14\u0E49\u0E32\u0E19\u0E2B\u0E25\u0E31\u0E07\u0E2A\u0E38\u0E14 \u0E21\u0E32\u0E16\u0E2D\u0E14\u0E23\u0E2B\u0E31\u0E2A\u0E2A\u0E2D\u0E07\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E02\u0E2D\u0E07 IDs \u0E14\u0E49\u0E32\u0E19\u0E1A\u0E19\u0E14\u0E39\u0E27\u0E48\u0E32\u0E21\u0E31\u0E19\u0E40\u0E01\u0E35\u0E48\u0E22\u0E01\u0E31\u0E1A\u0E2D\u0E30\u0E44\u0E23:"),ot.forEach(s),Ke=m(e),_(W.$$.fragment,e),Qe=m(e),_(X.$$.fragment,e),Ve=m(e),P=u(e,"P",{});var fe=c(P);Is=i(fe,"tokenizer \u0E17\u0E33\u0E01\u0E32\u0E23\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E04\u0E33\u0E1E\u0E34\u0E40\u0E28\u0E29 "),we=u(fe,"CODE",{});var rt=c(we);Ss=i(rt,"[CLS]"),rt.forEach(s),Ps=i(fe," \u0E17\u0E35\u0E48\u0E14\u0E49\u0E32\u0E19\u0E2B\u0E19\u0E49\u0E32\u0E2A\u0E38\u0E14 \u0E41\u0E25\u0E30\u0E04\u0E33\u0E1E\u0E34\u0E40\u0E28\u0E29 "),je=u(fe,"CODE",{});var at=c(je);As=i(at,"[SEP]"),at.forEach(s),Fs=i(fe," \u0E17\u0E35\u0E48\u0E14\u0E49\u0E32\u0E19\u0E2B\u0E25\u0E31\u0E07\u0E2A\u0E38\u0E14 \u0E19\u0E31\u0E49\u0E19\u0E01\u0E47\u0E40\u0E1E\u0E23\u0E32\u0E30\u0E27\u0E48\u0E32\u0E42\u0E21\u0E40\u0E14\u0E25\u0E19\u0E31\u0E49\u0E19\u0E44\u0E14\u0E49\u0E1C\u0E48\u0E32\u0E19\u0E01\u0E32\u0E23\u0E40\u0E17\u0E23\u0E19\u0E21\u0E32\u0E41\u0E1A\u0E1A\u0E19\u0E31\u0E49\u0E19 \u0E14\u0E31\u0E07\u0E19\u0E31\u0E49\u0E19\u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E43\u0E2B\u0E49\u0E44\u0E14\u0E49\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E17\u0E4C\u0E40\u0E14\u0E35\u0E22\u0E27\u0E01\u0E31\u0E19\u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A\u0E01\u0E32\u0E23\u0E2D\u0E19\u0E38\u0E21\u0E32\u0E19(inference) \u0E40\u0E23\u0E32\u0E08\u0E33\u0E40\u0E1B\u0E47\u0E19\u0E15\u0E49\u0E2D\u0E07\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E21\u0E31\u0E19\u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E40\u0E0A\u0E48\u0E19\u0E40\u0E14\u0E35\u0E22\u0E27\u0E01\u0E31\u0E19 \u0E41\u0E15\u0E48\u0E01\u0E47\u0E15\u0E49\u0E2D\u0E07\u0E15\u0E23\u0E30\u0E2B\u0E19\u0E31\u0E01\u0E27\u0E48\u0E32\u0E1A\u0E32\u0E07\u0E42\u0E21\u0E40\u0E14\u0E25\u0E19\u0E31\u0E49\u0E19\u0E44\u0E21\u0E48\u0E44\u0E14\u0E49\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E04\u0E33\u0E1E\u0E34\u0E40\u0E28\u0E29 \u0E2B\u0E23\u0E37\u0E2D \u0E43\u0E2A\u0E48\u0E04\u0E33\u0E17\u0E35\u0E48\u0E15\u0E48\u0E32\u0E07\u0E2D\u0E2D\u0E01\u0E44\u0E1B; \u0E42\u0E21\u0E40\u0E14\u0E25\u0E2D\u0E32\u0E08\u0E08\u0E30\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E04\u0E33\u0E1E\u0E34\u0E40\u0E28\u0E29\u0E40\u0E2B\u0E25\u0E48\u0E32\u0E19\u0E35\u0E49\u0E41\u0E04\u0E48\u0E40\u0E09\u0E1E\u0E32\u0E30\u0E14\u0E49\u0E32\u0E19\u0E2B\u0E19\u0E49\u0E32\u0E2A\u0E38\u0E14 \u0E2B\u0E23\u0E37\u0E2D \u0E14\u0E49\u0E32\u0E19\u0E2B\u0E25\u0E31\u0E07\u0E2A\u0E38\u0E14\u0E40\u0E17\u0E48\u0E32\u0E19\u0E31\u0E49\u0E19 \u0E44\u0E21\u0E48\u0E27\u0E48\u0E32\u0E08\u0E30\u0E43\u0E19\u0E01\u0E23\u0E13\u0E35\u0E43\u0E14\u0E46 tokenizer \u0E23\u0E39\u0E49\u0E27\u0E48\u0E32\u0E2D\u0E31\u0E19\u0E44\u0E2B\u0E19\u0E40\u0E1B\u0E47\u0E19\u0E2D\u0E31\u0E19\u0E17\u0E35\u0E48\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E32\u0E23\u0E41\u0E25\u0E30\u0E21\u0E31\u0E19\u0E08\u0E30\u0E08\u0E31\u0E14\u0E01\u0E32\u0E23\u0E43\u0E2B\u0E49\u0E04\u0E38\u0E13\u0E40\u0E2D\u0E07:"),fe.forEach(s),We=m(e),F=u(e,"H2",{class:!0});var ss=c(F);H=u(ss,"A",{id:!0,class:!0,href:!0});var lt=c(H);ve=u(lt,"SPAN",{});var it=c(ve);_(Y.$$.fragment,it),it.forEach(s),lt.forEach(s),Ds=m(ss),ze=u(ss,"SPAN",{});var pt=c(ze);Cs=i(pt,"\u0E2A\u0E23\u0E38\u0E1B: \u0E08\u0E32\u0E01 tokenizer \u0E44\u0E1B\u0E22\u0E31\u0E07\u0E42\u0E21\u0E40\u0E14\u0E25"),pt.forEach(s),ss.forEach(s),Xe=m(e),R=u(e,"P",{});var ts=c(R);xs=i(ts,"\u0E16\u0E36\u0E07\u0E15\u0E23\u0E07\u0E19\u0E35\u0E49\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E40\u0E2B\u0E47\u0E19\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E41\u0E15\u0E48\u0E25\u0E30\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E17\u0E31\u0E49\u0E07\u0E2B\u0E21\u0E14\u0E17\u0E35\u0E48 "),ye=u(ts,"CODE",{});var ut=c(ye);Hs=i(ut,"tokenizer"),ut.forEach(s),Rs=i(ts," \u0E43\u0E0A\u0E49\u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E1B\u0E23\u0E30\u0E21\u0E27\u0E25\u0E1C\u0E25\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21 \u0E40\u0E23\u0E32\u0E21\u0E32\u0E14\u0E39\u0E01\u0E31\u0E19\u0E04\u0E23\u0E31\u0E49\u0E07\u0E2A\u0E38\u0E14\u0E17\u0E49\u0E32\u0E22\u0E27\u0E48\u0E32\u0E21\u0E31\u0E19\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E08\u0E31\u0E14\u0E01\u0E32\u0E23\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E2B\u0E25\u0E32\u0E22\u0E46\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04 (padding!), \u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E22\u0E32\u0E27\u0E46, \u0E41\u0E25\u0E30 tensors \u0E2B\u0E25\u0E32\u0E22\u0E46 \u0E1B\u0E23\u0E30\u0E40\u0E20\u0E17\u0E44\u0E14\u0E49\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E44\u0E23\u0E14\u0E49\u0E27\u0E22 API \u0E2B\u0E25\u0E31\u0E01\u0E02\u0E2D\u0E07\u0E21\u0E31\u0E19:"),ts.forEach(s),Ye=m(e),T.l(e),pe=ct(),this.h()},h(){I(a,"name","hf:doc:metadata"),I(a,"content",JSON.stringify(Et)),I(B,"id",""),I(x,"id","tokens"),I(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),I(x,"href","#tokens"),I(A,"class","relative group"),I(H,"id","tokenizer"),I(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),I(H,"href","#tokenizer"),I(F,"class","relative group")},m(e,t){n(document.head,a),r(e,h,t),b(o,e,t),r(e,q,t),r(e,B,t),n(B,ns),r(e,Te,t),Z[z].m(e,t),r(e,se,t),r(e,te,t),n(te,os),r(e,Ie,t),r(e,C,t),n(C,rs),n(C,me),n(me,as),n(C,ls),r(e,Se,t),b(M,e,t),r(e,Pe,t),r(e,S,t),n(S,is),n(S,he),n(he,ps),n(S,us),n(S,de),n(de,cs),n(S,fs),r(e,Ae,t),r(e,ne,t),n(ne,ms),r(e,Fe,t),b(O,e,t),r(e,De,t),r(e,oe,t),n(oe,hs),r(e,Ce,t),b(L,e,t),r(e,xe,t),r(e,re,t),n(re,ds),r(e,He,t),b(G,e,t),r(e,Re,t),r(e,ae,t),n(ae,ks),r(e,Ne,t),b(J,e,t),r(e,Be,t),r(e,w,t),n(w,ke),n(ke,gs),n(w,_s),n(w,ge),n(ge,bs),n(w,$s),n(w,_e),n(_e,qs),n(w,ws),n(w,be),n(be,js),n(w,vs),r(e,Me,t),b(U,e,t),r(e,Oe,t),r(e,A,t),n(A,x),n(x,$e),b(K,$e,null),n(A,zs),n(A,qe),n(qe,ys),r(e,Le,t),r(e,le,t),n(le,Es),r(e,Ge,t),b(Q,e,t),r(e,Je,t),b(V,e,t),r(e,Ue,t),r(e,ie,t),n(ie,Ts),r(e,Ke,t),b(W,e,t),r(e,Qe,t),b(X,e,t),r(e,Ve,t),r(e,P,t),n(P,Is),n(P,we),n(we,Ss),n(P,Ps),n(P,je),n(je,As),n(P,Fs),r(e,We,t),r(e,F,t),n(F,H),n(H,ve),b(Y,ve,null),n(F,Ds),n(F,ze),n(ze,Cs),r(e,Xe,t),r(e,R,t),n(R,xs),n(R,ye),n(ye,Hs),n(R,Rs),r(e,Ye,t),ee[E].m(e,t),r(e,pe,t),Ze=!0},p(e,[t]){const Ee={};t&1&&(Ee.fw=e[0]),o.$set(Ee);let ue=z;z=Bs(e),z!==ue&&(mt(),d(Z[ue],1,1,()=>{Z[ue]=null}),ft(),y=Z[z],y||(y=Z[z]=Ns[z](e),y.c()),k(y,1),y.m(se.parentNode,se));let N=E;E=Os(e),E!==N&&(mt(),d(ee[N],1,1,()=>{ee[N]=null}),ft(),T=ee[E],T||(T=ee[E]=Ms[E](e),T.c()),k(T,1),T.m(pe.parentNode,pe))},i(e){Ze||(k(o.$$.fragment,e),k(y),k(M.$$.fragment,e),k(O.$$.fragment,e),k(L.$$.fragment,e),k(G.$$.fragment,e),k(J.$$.fragment,e),k(U.$$.fragment,e),k(K.$$.fragment,e),k(Q.$$.fragment,e),k(V.$$.fragment,e),k(W.$$.fragment,e),k(X.$$.fragment,e),k(Y.$$.fragment,e),k(T),Ze=!0)},o(e){d(o.$$.fragment,e),d(y),d(M.$$.fragment,e),d(O.$$.fragment,e),d(L.$$.fragment,e),d(G.$$.fragment,e),d(J.$$.fragment,e),d(U.$$.fragment,e),d(K.$$.fragment,e),d(Q.$$.fragment,e),d(V.$$.fragment,e),d(W.$$.fragment,e),d(X.$$.fragment,e),d(Y.$$.fragment,e),d(T),Ze=!1},d(e){s(a),e&&s(h),$(o,e),e&&s(q),e&&s(B),e&&s(Te),Z[z].d(e),e&&s(se),e&&s(te),e&&s(Ie),e&&s(C),e&&s(Se),$(M,e),e&&s(Pe),e&&s(S),e&&s(Ae),e&&s(ne),e&&s(Fe),$(O,e),e&&s(De),e&&s(oe),e&&s(Ce),$(L,e),e&&s(xe),e&&s(re),e&&s(He),$(G,e),e&&s(Re),e&&s(ae),e&&s(Ne),$(J,e),e&&s(Be),e&&s(w),e&&s(Me),$(U,e),e&&s(Oe),e&&s(A),$(K),e&&s(Le),e&&s(le),e&&s(Ge),$(Q,e),e&&s(Je),$(V,e),e&&s(Ue),e&&s(ie),e&&s(Ke),$(W,e),e&&s(Qe),$(X,e),e&&s(Ve),e&&s(P),e&&s(We),e&&s(F),$(Y),e&&s(Xe),e&&s(R),e&&s(Ye),ee[E].d(e),e&&s(pe)}}}const Et={local:"",sections:[{local:"tokens",title:"tokens \u0E1E\u0E34\u0E40\u0E28\u0E29"},{local:"tokenizer",title:"\u0E2A\u0E23\u0E38\u0E1B: \u0E08\u0E32\u0E01 tokenizer \u0E44\u0E1B\u0E22\u0E31\u0E07\u0E42\u0E21\u0E40\u0E14\u0E25"}],title:"\u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E17\u0E38\u0E01\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E40\u0E02\u0E49\u0E32\u0E14\u0E49\u0E27\u0E22\u0E01\u0E31\u0E19"};function Tt(v,a,h){let o="pt";return $t(()=>{const q=new URLSearchParams(window.location.search);h(0,o=q.get("fw")||"pt")}),[o]}class Dt extends kt{constructor(a){super();gt(this,a,Tt,yt,_t,{})}}export{Dt as default,Et as metadata};
