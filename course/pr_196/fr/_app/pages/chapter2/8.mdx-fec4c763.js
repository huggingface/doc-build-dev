import{S as kr,i as gr,s as xr,e as s,k as f,w as b,t as L,l as $r,M as _r,c as o,d as t,m,x as w,a,h as N,b as l,F as r,g as d,y as A,o as k,p as vr,q as g,B as y,v as br,n as qr}from"../../chunks/vendor-1e8b365d.js";import{I as T}from"../../chunks/IconCopyLink-483c28ba.js";import{C as Ut}from"../../chunks/CodeBlock-e5764662.js";import{Q as H}from"../../chunks/Question-31426fe2.js";import{F as wr}from"../../chunks/FrameworkSwitchCourse-7f8f0f31.js";function Ar(C){let p,c,v,h,E,x,S,z,q,P;return h=new T({}),q=new H({props:{choices:[{text:"Un mod\xE8le qui s'entra\xEEne automatiquement sur vos donn\xE9es",explain:"Vous confondez cela avec notre produit <a href='https://huggingface.co/autotrain>AutoTrain</a>"},{text:"Un objet qui renvoie la bonne architecture bas\xE9e sur le <i>checkpoint</i> .",explain:"Exactement : <code>TFAutoModel</code> a seulement besoin de conna\xEEtre le <i>checkpoint</i> \xE0 partir duquel il doit s'initialiser pour retourner \xE0 la bonne architecture.",correct:!0},{text:"Un mod\xE8le qui d\xE9tecte automatiquement la langue utilis\xE9e pour ses entr\xE9es afin de charger les bonnes pond\xE9rations.",explain:"Bien que certains <i>checkpoints</i> et mod\xE8les soient capables de g\xE9rer plusieurs langues, il n'existe pas d'outils int\xE9gr\xE9s pour la s\xE9lection automatique des <i>checkpoints</i> en fonction de la langue. Vous devez vous rendre sur le <a href='https://huggingface.co/models'>Hub des mod\xE8les</a> pour trouver le meilleur <i>checkpoint</i> pour votre t\xE2che !"}]}}),{c(){p=s("h3"),c=s("a"),v=s("span"),b(h.$$.fragment),E=f(),x=s("span"),S=L("5. What is an AutoModel?"),z=f(),b(q.$$.fragment),this.h()},l(i){p=o(i,"H3",{class:!0});var _=a(p);c=o(_,"A",{id:!0,class:!0,href:!0});var n=a(c);v=o(n,"SPAN",{});var $=a(v);w(h.$$.fragment,$),$.forEach(t),n.forEach(t),E=m(_),x=o(_,"SPAN",{});var M=a(x);S=N(M,"5. What is an AutoModel?"),M.forEach(t),_.forEach(t),z=m(i),w(q.$$.fragment,i),this.h()},h(){l(c,"id","5.-what-is-an-automodel?"),l(c,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(c,"href","#5.-what-is-an-automodel?"),l(p,"class","relative group")},m(i,_){d(i,p,_),r(p,c),r(c,v),A(h,v,null),r(p,E),r(p,x),r(x,S),d(i,z,_),A(q,i,_),P=!0},i(i){P||(g(h.$$.fragment,i),g(q.$$.fragment,i),P=!0)},o(i){k(h.$$.fragment,i),k(q.$$.fragment,i),P=!1},d(i){i&&t(p),y(h),i&&t(z),y(q,i)}}}function yr(C){let p,c,v,h,E,x,S,z,q,P;return h=new T({}),q=new H({props:{choices:[{text:"Un mod\xE8le qui s'entra\xEEne automatiquement sur vos donn\xE9es",explain:"Vous confondez cela avec notre produit <a href='https://huggingface.co/autotrain>AutoTrain</a>"},{text:"Un objet qui renvoie la bonne architecture bas\xE9e sur le <i>checkpoint</i> .",explain:"Exactement : <code>AutoModel</code> a seulement besoin de conna\xEEtre le <i>checkpoint</i> \xE0 partir duquel il doit s'initialiser pour retourner \xE0 la bonne architecture.",correct:!0},{text:"Un mod\xE8le qui d\xE9tecte automatiquement la langue utilis\xE9e pour ses entr\xE9es afin de charger les bonnes pond\xE9rations.",explain:"Bien que certains <i>checkpoints</i> et mod\xE8les soient capables de g\xE9rer plusieurs langues, il n'existe pas d'outils int\xE9gr\xE9s pour la s\xE9lection automatique des <i>checkpoints</i> en fonction de la langue. Vous devez vous rendre sur le <a href='https://huggingface.co/models'>Hub des mod\xE8les</a> pour trouver le meilleur <i>checkpoint</i> pour votre t\xE2che !"}]}}),{c(){p=s("h3"),c=s("a"),v=s("span"),b(h.$$.fragment),E=f(),x=s("span"),S=L("5. Qu\u2019est-ce qu\u2019un AutoModel?"),z=f(),b(q.$$.fragment),this.h()},l(i){p=o(i,"H3",{class:!0});var _=a(p);c=o(_,"A",{id:!0,class:!0,href:!0});var n=a(c);v=o(n,"SPAN",{});var $=a(v);w(h.$$.fragment,$),$.forEach(t),n.forEach(t),E=m(_),x=o(_,"SPAN",{});var M=a(x);S=N(M,"5. Qu\u2019est-ce qu\u2019un AutoModel?"),M.forEach(t),_.forEach(t),z=m(i),w(q.$$.fragment,i),this.h()},h(){l(c,"id","5.-qu\u2019est-ce-qu\u2019un-automodel?"),l(c,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(c,"href","#5.-qu\u2019est-ce-qu\u2019un-automodel?"),l(p,"class","relative group")},m(i,_){d(i,p,_),r(p,c),r(c,v),A(h,v,null),r(p,E),r(p,x),r(x,S),d(i,z,_),A(q,i,_),P=!0},i(i){P||(g(h.$$.fragment,i),g(q.$$.fragment,i),P=!0)},o(i){k(h.$$.fragment,i),k(q.$$.fragment,i),P=!1},d(i){i&&t(p),y(h),i&&t(z),y(q,i)}}}function zr(C){let p,c,v,h,E,x,S,z,q,P,i,_;return h=new T({}),q=new Ut({props:{code:`from transformers import AutoTokenizer, TFAutoModel

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
model = TFAutoModel.from_pretrained("gpt2")

encoded = tokenizer("Hey!", return_tensors="pt")
result = model(**encoded)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModel

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;gpt2&quot;</span>)

encoded = tokenizer(<span class="hljs-string">&quot;Hey!&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
result = model(**encoded)`}}),i=new H({props:{choices:[{text:"Non, \xE7a semble correct.",explain:"Malheureusement, coupler un mod\xE8le avec un <i>tokenizer</i> qui a \xE9t\xE9 entra\xEEn\xE9 avec un <i>checkpoint</i> diff\xE9rent est rarement une bonne id\xE9e. Le mod\xE8le n'a pas \xE9t\xE9 entra\xEEn\xE9 pour donner du sens \xE0 la sortie de ce <i>tokenizer</i> donc la sortie du mod\xE8le (s'il peut m\xEAme fonctionner !) n'aura aucun sens."},{text:" Le <i>tokenizer</i> et le mod\xE8le doivent toujours provenir du m\xEAme <i>checkpoint</i>.",explain:"",correct:!0},{text:" C'est une bonne pratique de faire du <i>padding</i> et de troncage avec le <i>tokenizer</i> car chaque entr\xE9e est un batch.",explain:"Il est vrai que chaque entr\xE9e de mod\xE8le doit \xEAtre un batch. Cependant, tronquer ou compl\xE9ter cette s\xE9quence n'aurait pas n\xE9cessairement de sens puisqu'il n'y en a qu'une seule. Il s'agit l\xE0 de techniques permettant de mettre en batch une liste de phrases."}]}}),{c(){p=s("h3"),c=s("a"),v=s("span"),b(h.$$.fragment),E=f(),x=s("span"),S=L("10. Y a-t-il un probl\xE8me avec le code suivant ?"),z=f(),b(q.$$.fragment),P=f(),b(i.$$.fragment),this.h()},l(n){p=o(n,"H3",{class:!0});var $=a(p);c=o($,"A",{id:!0,class:!0,href:!0});var M=a(c);v=o(M,"SPAN",{});var j=a(v);w(h.$$.fragment,j),j.forEach(t),M.forEach(t),E=m($),x=o($,"SPAN",{});var B=a(x);S=N(B,"10. Y a-t-il un probl\xE8me avec le code suivant ?"),B.forEach(t),$.forEach(t),z=m(n),w(q.$$.fragment,n),P=m(n),w(i.$$.fragment,n),this.h()},h(){l(c,"id","10.-y-a-t-il-un-probl\xE8me-avec-le-code-suivant-?"),l(c,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(c,"href","#10.-y-a-t-il-un-probl\xE8me-avec-le-code-suivant-?"),l(p,"class","relative group")},m(n,$){d(n,p,$),r(p,c),r(c,v),A(h,v,null),r(p,E),r(p,x),r(x,S),d(n,z,$),A(q,n,$),d(n,P,$),A(i,n,$),_=!0},i(n){_||(g(h.$$.fragment,n),g(q.$$.fragment,n),g(i.$$.fragment,n),_=!0)},o(n){k(h.$$.fragment,n),k(q.$$.fragment,n),k(i.$$.fragment,n),_=!1},d(n){n&&t(p),y(h),n&&t(z),y(q,n),n&&t(P),y(i,n)}}}function Er(C){let p,c,v,h,E,x,S,z,q,P,i,_;return h=new T({}),q=new Ut({props:{code:`from transformers import AutoTokenizer, AutoModel

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
model = AutoModel.from_pretrained("gpt2")

encoded = tokenizer("Hey!", return_tensors="pt")
result = model(**encoded)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModel

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
model = AutoModel.from_pretrained(<span class="hljs-string">&quot;gpt2&quot;</span>)

encoded = tokenizer(<span class="hljs-string">&quot;Hey!&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
result = model(**encoded)`}}),i=new H({props:{choices:[{text:"Non, \xE7a semble correct.",explain:"Malheureusement, coupler un mod\xE8le avec un <i>tokenizer</i> qui a \xE9t\xE9 entra\xEEn\xE9 avec un <i>checkpoint</i> diff\xE9rent est rarement une bonne id\xE9e. Le mod\xE8le n'a pas \xE9t\xE9 entra\xEEn\xE9 pour donner du sens \xE0 la sortie de ce <i>tokenizer</i> donc la sortie du mod\xE8le (s'il peut m\xEAme fonctionner !) n'aura aucun sens."},{text:" Le <i>tokenizer</i> et le mod\xE8le doivent toujours provenir du m\xEAme <i>checkpoint</i>.",explain:"",correct:!0},{text:" C'est une bonne pratique de faire du <i>padding</i> et de troncage avec le <i>tokenizer</i> car chaque entr\xE9e est un batch.",explain:"Il est vrai que chaque entr\xE9e de mod\xE8le doit \xEAtre un batch. Cependant, tronquer ou compl\xE9ter cette s\xE9quence n'aurait pas n\xE9cessairement de sens puisqu'il n'y en a qu'une seule. Il s'agit l\xE0 de techniques permettant de mettre en batch une liste de phrases."}]}}),{c(){p=s("h3"),c=s("a"),v=s("span"),b(h.$$.fragment),E=f(),x=s("span"),S=L("10. Y a-t-il un probl\xE8me avec le code suivant ?"),z=f(),b(q.$$.fragment),P=f(),b(i.$$.fragment),this.h()},l(n){p=o(n,"H3",{class:!0});var $=a(p);c=o($,"A",{id:!0,class:!0,href:!0});var M=a(c);v=o(M,"SPAN",{});var j=a(v);w(h.$$.fragment,j),j.forEach(t),M.forEach(t),E=m($),x=o($,"SPAN",{});var B=a(x);S=N(B,"10. Y a-t-il un probl\xE8me avec le code suivant ?"),B.forEach(t),$.forEach(t),z=m(n),w(q.$$.fragment,n),P=m(n),w(i.$$.fragment,n),this.h()},h(){l(c,"id","10.-y-a-t-il-un-probl\xE8me-avec-le-code-suivant-?"),l(c,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(c,"href","#10.-y-a-t-il-un-probl\xE8me-avec-le-code-suivant-?"),l(p,"class","relative group")},m(n,$){d(n,p,$),r(p,c),r(c,v),A(h,v,null),r(p,E),r(p,x),r(x,S),d(n,z,$),A(q,n,$),d(n,P,$),A(i,n,$),_=!0},i(n){_||(g(h.$$.fragment,n),g(q.$$.fragment,n),g(i.$$.fragment,n),_=!0)},o(n){k(h.$$.fragment,n),k(q.$$.fragment,n),k(i.$$.fragment,n),_=!1},d(n){n&&t(p),y(h),n&&t(z),y(q,n),n&&t(P),y(i,n)}}}function Pr(C){let p,c,v,h,E,x,S,z,q,P,i,_,n,$,M,j,B,Pe,kt,Ve,ne,Ye,O,G,Se,se,gt,oe,xt,Le,_t,bt,We,ie,De,V,K,Ne,ae,wt,Me,At,Re,le,Je,Y,X,je,ue,yt,Te,zt,Ge,pe,Ke,Q,I,Ae,W,Z,He,ce,Et,Ce,Pt,Xe,de,Ze,D,ee,Qe,fe,St,Ie,Lt,et,me,tt,R,te,Ue,he,Nt,$e,Mt,Fe,jt,Tt,rt,ve,nt,J,re,Be,qe,Ht,ke,Ct,Oe,Qt,It,st,ge,ot,xe,it,U,F,ye,at;v=new wr({props:{fw:C[0]}}),z=new T({}),j=new T({}),ne=new H({props:{choices:[{text:" Tout d'abord, le mod\xE8le, qui traite le texte et renvoie des pr\xE9dictions brutes. Puis le <i>tokenizer</i> donne un sens \xE0 ces pr\xE9dictions et les reconvertit en texte si n\xE9cessaire.",explain:" Le mod\xE8le ne peut pas comprendre le texte ! Le <i>tokenizer</i> doit d'abord tokeniser le texte et le convertir en identifiants afin qu'il soit compr\xE9hensible par le mod\xE8le."},{text:" Tout d'abord, le <i>tokenizer</i>, qui traite le texte et renvoie des identifiants. Puis le mod\xE8le traite ces identifiants et produit une pr\xE9diction, qui peut \xEAtre du texte.",explain:" La pr\xE9diction du mod\xE8le ne peut pas \xEAtre du texte imm\xE9diatement. Le <i>tokenizer</i> doit \xEAtre utilis\xE9 afin de reconvertir la pr\xE9diction en texte !"},{text:" Le <i>tokenizer</i> traite le texte et renvoie des identifiants. Le mod\xE8le traite ces identifiants et produit une pr\xE9diction. Le <i>tokenizer</i> peut alors \xEAtre utilis\xE9 \xE0 nouveau pour reconvertir ces pr\xE9dictions en texte.",explain:" Le <i>tokenizer</i> peut \xEAtre utilis\xE9 \xE0 la fois pour la tokenisation et la d\xE9-tok\xE9nisation.",correct:!0}]}}),se=new T({}),ie=new H({props:{choices:[{text:"2: la longueur de la s\xE9quence et la taille du batch",explain:"Le tenseur produit par le mod\xE8le poss\xE8de une troisi\xE8me dimension : la taille cach\xE9e."},{text:"2: la longueur de la s\xE9quence et la taille cach\xE9e",explain:"Tous les <i>transformers</i>  g\xE8rent les batchs, m\xEAme avec une seule s\xE9quence ce serait une taille de batch de 1 !"},{text:"3: la longueur de la s\xE9quence, la taille du batch et la taille cach\xE9e.",explain:"",correct:!0}]}}),ae=new T({}),le=new H({props:{choices:[{text:"WordPiece",explain:"Oui, c'est un exemple de tokenisation en sous-mots !",correct:!0},{text:"La tokenization bas\xE9e sur les caract\xE8res",explain:"La tokenization bas\xE9e sur les caract\xE8res n\u2019est pas un type de tokenisation en sous-mots."},{text:"D\xE9coupage sur les espaces et la ponctuation",explain:"C\u2019est une tokenisation bas\xE9e sur les mots !"},{text:"BPE",explain:"Oui, c'est un exemple de tokenisation en sous-mots !",correct:!0},{text:"Unigram",explain:"Oui, c'est un exemple de tokenisation en sous-mots !",correct:!0},{text:"Aucune des propositions ci-dessus",explain:""}]}}),ue=new T({}),pe=new H({props:{choices:[{text:" Un composant du <i>transformer</i>  de base qui redirige les tenseurs vers leurs couches correctes.",explain:"Il n'y a pas de tel composant."},{text:"\xC9galement connu sous le nom de m\xE9canisme d'auto-attention, il adapte la repr\xE9sentation d'un <i>token</i>  en fonction des autres <i>tokens</i>  de la s\xE9quence.",explain:"La couche d'auto-attention contient des t\xEAtes d'attention mais ce ne sont pas des t\xEAtes d'adaptation."},{text:"Un composant suppl\xE9mentaire, g\xE9n\xE9ralement constitu\xE9 d'une ou plusieurs couches, pour convertir les pr\xE9dictions du <i>transformer</i>  en une sortie sp\xE9cifique \xE0 la t\xE2che.",explain:"Les t\xEAtes d'adaptation, aussi appel\xE9es simplement t\xEAtes, se pr\xE9sentent sous diff\xE9rentes formes : t\xEAtes de mod\xE9lisation du langage, t\xEAtes de r\xE9ponse aux questions, t\xEAtes de classification des s\xE9quences, etc.",correct:!0}]}});const Ft=[yr,Ar],_e=[];function Bt(e,u){return e[0]==="pt"?0:1}Q=Bt(C),I=_e[Q]=Ft[Q](C),ce=new T({}),de=new H({props:{choices:[{text:"La troncature",explain:" La troncature est une fa\xE7on correcte d'\xE9galiser les s\xE9quences pour qu'elles s'inscrivent dans une forme rectangulaire. Mais est-ce la seule ?",correct:!0},{text:"Retourner les tenseurs",explain:"Alors que les autres techniques vous permettent de renvoyer des tenseurs rectangulaires, retourner les tenseurs n'est pas utile lorsque vous mettez en batch des s\xE9quences."},{text:"Le <i>padding</i>",explain:"Le <i>padding</i> est une fa\xE7on correcte d'\xE9galiser les s\xE9quences pour qu'elles tiennent dans une forme rectangulaire. Mais est-ce le seul moyen ?",correct:!0},{text:"Les masques d'attention ",explain:"Les masques d'attention sont d'une importance capitale lorsqu'on manipule des s\xE9quences de longueurs diff\xE9rentes. Ce n'est cependant pas la seule technique \xE0 laquelle il faut faire attention.",correct:!0}]}}),fe=new T({}),me=new H({props:{choices:[{text:"Elle adoucit les logits pour qu'ils soient plus fiables.",explain:"La fonction SoftMax n'affecte pas la fiabilit\xE9 des r\xE9sultats."},{text:"Elle applique une limite inf\xE9rieure et sup\xE9rieure pour qu'ils soient compr\xE9hensibles.",explain:"Les valeurs r\xE9sultantes sont comprises entre 0 et 1. Ce n'est cependant pas la seule raison pour laquelle nous utilisons une fonction SoftMax.",correct:!0},{text:"La somme totale des sorties est alors \xE9gale \xE0 1, ce qui permet une interpr\xE9tation probabiliste.",explain:"Mais ce n'est pas la seule raison pour laquelle nous utilisons une fonction SoftMax.",correct:!0}]}}),he=new T({}),ve=new H({props:{choices:[{text:"<code>encode</code>, car elle peut encoder du texte en identifiants et des identifiants en pr\xE9dictions.",explain:"Bien que la m\xE9thode <code>encode</code> existe sur les <i>tokenizer</i>, elle n'existe pas sur les mod\xE8les."},{text:"Appeler directement l'objet tokenizer",explain:"La m\xE9thode <code>__call__</code> du <i>tokenizer</i> est une m\xE9thode tr\xE8s puissante qui peut traiter \xE0 peu pr\xE8s tout. C'est \xE9galement la m\xE9thode utilis\xE9e pour r\xE9cup\xE9rer les pr\xE9dictions d'un mod\xE8le.",correct:!0},{text:"<code>pad</code>",explain:"Le <i>padding</i> est tr\xE8s utile mais ce n'est qu'une partie de l'API <i>tokenizer</i>."},{text:"<code>tokenize</code>",explain:"La m\xE9thode <code>tokenize</code> est est sans doute l'une des m\xE9thodes les plus utiles, mais elle ne constitue pas le c\u0153ur de l'API <i>tokenizer</i>."}]}}),qe=new T({}),ge=new Ut({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
result = tokenizer.tokenize("Hello!")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
result = tokenizer.tokenize(<span class="hljs-string">&quot;Hello!&quot;</span>)`}}),xe=new H({props:{choices:[{text:"Une liste de cha\xEEnes de caract\xE8res, chaque cha\xEEne \xE9tant un <i>token</i>.",explain:"Convertissez cela en identifiants, et donnez-les \xE0 un mod\xE8le !",correct:!0},{text:"Une liste d'identifiants",explain:"C'est \xE0 cela que la m\xE9thode <code>__call__</code> ou la m\xE9thode <code>convert_tokens_to_ids</code> sert !"},{text:"Une cha\xEEne contenant tous les <i>tokens</i>",explain:"Ce serait sous-optimal car le but est de diviser la cha\xEEne de caract\xE8res en plusieurs \xE9l\xE9ments."}]}});const Ot=[Er,zr],be=[];function Vt(e,u){return e[0]==="pt"?0:1}return U=Vt(C),F=be[U]=Ot[U](C),{c(){p=s("meta"),c=f(),b(v.$$.fragment),h=f(),E=s("h1"),x=s("a"),S=s("span"),b(z.$$.fragment),q=f(),P=s("span"),i=L("Quiz de fin de chapitre"),_=f(),n=s("h3"),$=s("a"),M=s("span"),b(j.$$.fragment),B=f(),Pe=s("span"),kt=L("1. Quel est l\u2019ordre du pipeline de mod\xE9lisation du langage ?"),Ve=f(),b(ne.$$.fragment),Ye=f(),O=s("h3"),G=s("a"),Se=s("span"),b(se.$$.fragment),gt=f(),oe=s("span"),xt=L("2. Combien de dimensions le tenseur produit par le "),Le=s("i"),_t=L("transformer"),bt=L(" de base poss\xE8de-t-il et quelles sont-elles ?"),We=f(),b(ie.$$.fragment),De=f(),V=s("h3"),K=s("a"),Ne=s("span"),b(ae.$$.fragment),wt=f(),Me=s("span"),At=L("3. Lequel des \xE9l\xE9ments suivants est un exemple de tokenisation en sous-mots ?"),Re=f(),b(le.$$.fragment),Je=f(),Y=s("h3"),X=s("a"),je=s("span"),b(ue.$$.fragment),yt=f(),Te=s("span"),zt=L("4. Qu\u2019est-ce qu\u2019une t\xEAte de mod\xE8le ?"),Ge=f(),b(pe.$$.fragment),Ke=f(),I.c(),Ae=f(),W=s("h3"),Z=s("a"),He=s("span"),b(ce.$$.fragment),Et=f(),Ce=s("span"),Pt=L("6. Quelles sont les techniques \xE0 conna\xEEtre lors de la mise en batch de s\xE9quences de longueurs diff\xE9rentes ?"),Xe=f(),b(de.$$.fragment),Ze=f(),D=s("h3"),ee=s("a"),Qe=s("span"),b(fe.$$.fragment),St=f(),Ie=s("span"),Lt=L("7. Quel est l\u2019int\xE9r\xEAt d\u2019appliquer une fonction SoftMax aux logits produits par un mod\xE8le de classification de s\xE9quences ?"),et=f(),b(me.$$.fragment),tt=f(),R=s("h3"),te=s("a"),Ue=s("span"),b(he.$$.fragment),Nt=f(),$e=s("span"),Mt=L("8. Autour de quelle m\xE9thode s\u2019articule la majeure partie de l\u2019API "),Fe=s("i"),jt=L("tokenizer"),Tt=L(" ?"),rt=f(),b(ve.$$.fragment),nt=f(),J=s("h3"),re=s("a"),Be=s("span"),b(qe.$$.fragment),Ht=f(),ke=s("span"),Ct=L("9. Que contient la variable "),Oe=s("code"),Qt=L("result"),It=L(" dans cet exemple de code ?"),st=f(),b(ge.$$.fragment),ot=f(),b(xe.$$.fragment),it=f(),F.c(),ye=$r(),this.h()},l(e){const u=_r('[data-svelte="svelte-1phssyn"]',document.head);p=o(u,"META",{name:!0,content:!0}),u.forEach(t),c=m(e),w(v.$$.fragment,e),h=m(e),E=o(e,"H1",{class:!0});var we=a(E);x=o(we,"A",{id:!0,class:!0,href:!0});var ze=a(x);S=o(ze,"SPAN",{});var Ee=a(S);w(z.$$.fragment,Ee),Ee.forEach(t),ze.forEach(t),q=m(we),P=o(we,"SPAN",{});var Yt=a(P);i=N(Yt,"Quiz de fin de chapitre"),Yt.forEach(t),we.forEach(t),_=m(e),n=o(e,"H3",{class:!0});var lt=a(n);$=o(lt,"A",{id:!0,class:!0,href:!0});var Wt=a($);M=o(Wt,"SPAN",{});var Dt=a(M);w(j.$$.fragment,Dt),Dt.forEach(t),Wt.forEach(t),B=m(lt),Pe=o(lt,"SPAN",{});var Rt=a(Pe);kt=N(Rt,"1. Quel est l\u2019ordre du pipeline de mod\xE9lisation du langage ?"),Rt.forEach(t),lt.forEach(t),Ve=m(e),w(ne.$$.fragment,e),Ye=m(e),O=o(e,"H3",{class:!0});var ut=a(O);G=o(ut,"A",{id:!0,class:!0,href:!0});var Jt=a(G);Se=o(Jt,"SPAN",{});var Gt=a(Se);w(se.$$.fragment,Gt),Gt.forEach(t),Jt.forEach(t),gt=m(ut),oe=o(ut,"SPAN",{});var pt=a(oe);xt=N(pt,"2. Combien de dimensions le tenseur produit par le "),Le=o(pt,"I",{});var Kt=a(Le);_t=N(Kt,"transformer"),Kt.forEach(t),bt=N(pt," de base poss\xE8de-t-il et quelles sont-elles ?"),pt.forEach(t),ut.forEach(t),We=m(e),w(ie.$$.fragment,e),De=m(e),V=o(e,"H3",{class:!0});var ct=a(V);K=o(ct,"A",{id:!0,class:!0,href:!0});var Xt=a(K);Ne=o(Xt,"SPAN",{});var Zt=a(Ne);w(ae.$$.fragment,Zt),Zt.forEach(t),Xt.forEach(t),wt=m(ct),Me=o(ct,"SPAN",{});var er=a(Me);At=N(er,"3. Lequel des \xE9l\xE9ments suivants est un exemple de tokenisation en sous-mots ?"),er.forEach(t),ct.forEach(t),Re=m(e),w(le.$$.fragment,e),Je=m(e),Y=o(e,"H3",{class:!0});var dt=a(Y);X=o(dt,"A",{id:!0,class:!0,href:!0});var tr=a(X);je=o(tr,"SPAN",{});var rr=a(je);w(ue.$$.fragment,rr),rr.forEach(t),tr.forEach(t),yt=m(dt),Te=o(dt,"SPAN",{});var nr=a(Te);zt=N(nr,"4. Qu\u2019est-ce qu\u2019une t\xEAte de mod\xE8le ?"),nr.forEach(t),dt.forEach(t),Ge=m(e),w(pe.$$.fragment,e),Ke=m(e),I.l(e),Ae=m(e),W=o(e,"H3",{class:!0});var ft=a(W);Z=o(ft,"A",{id:!0,class:!0,href:!0});var sr=a(Z);He=o(sr,"SPAN",{});var or=a(He);w(ce.$$.fragment,or),or.forEach(t),sr.forEach(t),Et=m(ft),Ce=o(ft,"SPAN",{});var ir=a(Ce);Pt=N(ir,"6. Quelles sont les techniques \xE0 conna\xEEtre lors de la mise en batch de s\xE9quences de longueurs diff\xE9rentes ?"),ir.forEach(t),ft.forEach(t),Xe=m(e),w(de.$$.fragment,e),Ze=m(e),D=o(e,"H3",{class:!0});var mt=a(D);ee=o(mt,"A",{id:!0,class:!0,href:!0});var ar=a(ee);Qe=o(ar,"SPAN",{});var lr=a(Qe);w(fe.$$.fragment,lr),lr.forEach(t),ar.forEach(t),St=m(mt),Ie=o(mt,"SPAN",{});var ur=a(Ie);Lt=N(ur,"7. Quel est l\u2019int\xE9r\xEAt d\u2019appliquer une fonction SoftMax aux logits produits par un mod\xE8le de classification de s\xE9quences ?"),ur.forEach(t),mt.forEach(t),et=m(e),w(me.$$.fragment,e),tt=m(e),R=o(e,"H3",{class:!0});var ht=a(R);te=o(ht,"A",{id:!0,class:!0,href:!0});var pr=a(te);Ue=o(pr,"SPAN",{});var cr=a(Ue);w(he.$$.fragment,cr),cr.forEach(t),pr.forEach(t),Nt=m(ht),$e=o(ht,"SPAN",{});var $t=a($e);Mt=N($t,"8. Autour de quelle m\xE9thode s\u2019articule la majeure partie de l\u2019API "),Fe=o($t,"I",{});var dr=a(Fe);jt=N(dr,"tokenizer"),dr.forEach(t),Tt=N($t," ?"),$t.forEach(t),ht.forEach(t),rt=m(e),w(ve.$$.fragment,e),nt=m(e),J=o(e,"H3",{class:!0});var vt=a(J);re=o(vt,"A",{id:!0,class:!0,href:!0});var fr=a(re);Be=o(fr,"SPAN",{});var mr=a(Be);w(qe.$$.fragment,mr),mr.forEach(t),fr.forEach(t),Ht=m(vt),ke=o(vt,"SPAN",{});var qt=a(ke);Ct=N(qt,"9. Que contient la variable "),Oe=o(qt,"CODE",{});var hr=a(Oe);Qt=N(hr,"result"),hr.forEach(t),It=N(qt," dans cet exemple de code ?"),qt.forEach(t),vt.forEach(t),st=m(e),w(ge.$$.fragment,e),ot=m(e),w(xe.$$.fragment,e),it=m(e),F.l(e),ye=$r(),this.h()},h(){l(p,"name","hf:doc:metadata"),l(p,"content",JSON.stringify(Sr)),l(x,"id","quiz-de-fin-de-chapitre"),l(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(x,"href","#quiz-de-fin-de-chapitre"),l(E,"class","relative group"),l($,"id","1.-quel-est-l\u2019ordre-du-pipeline-de-mod\xE9lisation-du-langage-?"),l($,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l($,"href","#1.-quel-est-l\u2019ordre-du-pipeline-de-mod\xE9lisation-du-langage-?"),l(n,"class","relative group"),l(G,"id","2.-combien-de-dimensions-le-tenseur-produit-par-le-<i>transformer</i>-de-base-poss\xE8de-t-il-et-quelles-sont-elles-?"),l(G,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(G,"href","#2.-combien-de-dimensions-le-tenseur-produit-par-le-<i>transformer</i>-de-base-poss\xE8de-t-il-et-quelles-sont-elles-?"),l(O,"class","relative group"),l(K,"id","3.-lequel-des-\xE9l\xE9ments-suivants-est-un-exemple-de-tokenisation-en-sous-mots-?"),l(K,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(K,"href","#3.-lequel-des-\xE9l\xE9ments-suivants-est-un-exemple-de-tokenisation-en-sous-mots-?"),l(V,"class","relative group"),l(X,"id","4.-qu\u2019est-ce-qu\u2019une-t\xEAte-de-mod\xE8le-?"),l(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(X,"href","#4.-qu\u2019est-ce-qu\u2019une-t\xEAte-de-mod\xE8le-?"),l(Y,"class","relative group"),l(Z,"id","6.-quelles-sont-les-techniques-\xE0-conna\xEEtre-lors-de-la-mise-en-batch-de-s\xE9quences-de-longueurs-diff\xE9rentes-?"),l(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(Z,"href","#6.-quelles-sont-les-techniques-\xE0-conna\xEEtre-lors-de-la-mise-en-batch-de-s\xE9quences-de-longueurs-diff\xE9rentes-?"),l(W,"class","relative group"),l(ee,"id","7.-quel-est-l\u2019int\xE9r\xEAt-d\u2019appliquer-une-fonction-softmax-aux-logits-produits-par-un-mod\xE8le-de-classification-de-s\xE9quences-?"),l(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(ee,"href","#7.-quel-est-l\u2019int\xE9r\xEAt-d\u2019appliquer-une-fonction-softmax-aux-logits-produits-par-un-mod\xE8le-de-classification-de-s\xE9quences-?"),l(D,"class","relative group"),l(te,"id","8.-autour-de-quelle-m\xE9thode-s\u2019articule-la-majeure-partie-de-l\u2019api-<i>tokenizer</i>-?"),l(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(te,"href","#8.-autour-de-quelle-m\xE9thode-s\u2019articule-la-majeure-partie-de-l\u2019api-<i>tokenizer</i>-?"),l(R,"class","relative group"),l(re,"id","9.-que-contient-la-variable-<code>result</code>-dans-cet-exemple-de-code-?"),l(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(re,"href","#9.-que-contient-la-variable-<code>result</code>-dans-cet-exemple-de-code-?"),l(J,"class","relative group")},m(e,u){r(document.head,p),d(e,c,u),A(v,e,u),d(e,h,u),d(e,E,u),r(E,x),r(x,S),A(z,S,null),r(E,q),r(E,P),r(P,i),d(e,_,u),d(e,n,u),r(n,$),r($,M),A(j,M,null),r(n,B),r(n,Pe),r(Pe,kt),d(e,Ve,u),A(ne,e,u),d(e,Ye,u),d(e,O,u),r(O,G),r(G,Se),A(se,Se,null),r(O,gt),r(O,oe),r(oe,xt),r(oe,Le),r(Le,_t),r(oe,bt),d(e,We,u),A(ie,e,u),d(e,De,u),d(e,V,u),r(V,K),r(K,Ne),A(ae,Ne,null),r(V,wt),r(V,Me),r(Me,At),d(e,Re,u),A(le,e,u),d(e,Je,u),d(e,Y,u),r(Y,X),r(X,je),A(ue,je,null),r(Y,yt),r(Y,Te),r(Te,zt),d(e,Ge,u),A(pe,e,u),d(e,Ke,u),_e[Q].m(e,u),d(e,Ae,u),d(e,W,u),r(W,Z),r(Z,He),A(ce,He,null),r(W,Et),r(W,Ce),r(Ce,Pt),d(e,Xe,u),A(de,e,u),d(e,Ze,u),d(e,D,u),r(D,ee),r(ee,Qe),A(fe,Qe,null),r(D,St),r(D,Ie),r(Ie,Lt),d(e,et,u),A(me,e,u),d(e,tt,u),d(e,R,u),r(R,te),r(te,Ue),A(he,Ue,null),r(R,Nt),r(R,$e),r($e,Mt),r($e,Fe),r(Fe,jt),r($e,Tt),d(e,rt,u),A(ve,e,u),d(e,nt,u),d(e,J,u),r(J,re),r(re,Be),A(qe,Be,null),r(J,Ht),r(J,ke),r(ke,Ct),r(ke,Oe),r(Oe,Qt),r(ke,It),d(e,st,u),A(ge,e,u),d(e,ot,u),A(xe,e,u),d(e,it,u),be[U].m(e,u),d(e,ye,u),at=!0},p(e,[u]){const we={};u&1&&(we.fw=e[0]),v.$set(we);let ze=Q;Q=Bt(e),Q!==ze&&(qr(),k(_e[ze],1,1,()=>{_e[ze]=null}),vr(),I=_e[Q],I||(I=_e[Q]=Ft[Q](e),I.c()),g(I,1),I.m(Ae.parentNode,Ae));let Ee=U;U=Vt(e),U!==Ee&&(qr(),k(be[Ee],1,1,()=>{be[Ee]=null}),vr(),F=be[U],F||(F=be[U]=Ot[U](e),F.c()),g(F,1),F.m(ye.parentNode,ye))},i(e){at||(g(v.$$.fragment,e),g(z.$$.fragment,e),g(j.$$.fragment,e),g(ne.$$.fragment,e),g(se.$$.fragment,e),g(ie.$$.fragment,e),g(ae.$$.fragment,e),g(le.$$.fragment,e),g(ue.$$.fragment,e),g(pe.$$.fragment,e),g(I),g(ce.$$.fragment,e),g(de.$$.fragment,e),g(fe.$$.fragment,e),g(me.$$.fragment,e),g(he.$$.fragment,e),g(ve.$$.fragment,e),g(qe.$$.fragment,e),g(ge.$$.fragment,e),g(xe.$$.fragment,e),g(F),at=!0)},o(e){k(v.$$.fragment,e),k(z.$$.fragment,e),k(j.$$.fragment,e),k(ne.$$.fragment,e),k(se.$$.fragment,e),k(ie.$$.fragment,e),k(ae.$$.fragment,e),k(le.$$.fragment,e),k(ue.$$.fragment,e),k(pe.$$.fragment,e),k(I),k(ce.$$.fragment,e),k(de.$$.fragment,e),k(fe.$$.fragment,e),k(me.$$.fragment,e),k(he.$$.fragment,e),k(ve.$$.fragment,e),k(qe.$$.fragment,e),k(ge.$$.fragment,e),k(xe.$$.fragment,e),k(F),at=!1},d(e){t(p),e&&t(c),y(v,e),e&&t(h),e&&t(E),y(z),e&&t(_),e&&t(n),y(j),e&&t(Ve),y(ne,e),e&&t(Ye),e&&t(O),y(se),e&&t(We),y(ie,e),e&&t(De),e&&t(V),y(ae),e&&t(Re),y(le,e),e&&t(Je),e&&t(Y),y(ue),e&&t(Ge),y(pe,e),e&&t(Ke),_e[Q].d(e),e&&t(Ae),e&&t(W),y(ce),e&&t(Xe),y(de,e),e&&t(Ze),e&&t(D),y(fe),e&&t(et),y(me,e),e&&t(tt),e&&t(R),y(he),e&&t(rt),y(ve,e),e&&t(nt),e&&t(J),y(qe),e&&t(st),y(ge,e),e&&t(ot),y(xe,e),e&&t(it),be[U].d(e),e&&t(ye)}}}const Sr={local:"quiz-de-fin-de-chapitre",title:"Quiz de fin de chapitre"};function Lr(C,p,c){let v="pt";return br(()=>{const h=new URLSearchParams(window.location.search);c(0,v=h.get("fw")||"pt")}),[v]}class Cr extends kr{constructor(p){super();gr(this,p,Lr,Pr,xr,{})}}export{Cr as default,Sr as metadata};
