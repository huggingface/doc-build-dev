import{S as Vi,i as Fi,s as Qi,e as i,k as u,w as f,t,M as Li,c as l,d as o,m as d,a as p,x as _,h as r,b as m,N as Wa,G as s,g as n,y as h,q as g,o as b,B as v,v as Ri}from"../../chunks/vendor-hf-doc-builder.js";import{T as vn}from"../../chunks/Tip-hf-doc-builder.js";import{Y as wn}from"../../chunks/Youtube-hf-doc-builder.js";import{I as qn}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as q}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as Ui}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";function Bi(Y){let c,E;return{c(){c=i("p"),E=t("\u{1F6A8} Est\xE1 vendo aquela caixa azul em torno de \u201C6 frames\u201D no traceback do Google Colab? Esse \xE9 um recurso especial do Colab, que compacta o traceback em \u201Cquadros\u201D. Se voc\xEA n\xE3o conseguir encontrar a fonte de um erro, certifique-se de expandir o rastreamento completo clicando nessas duas pequenas setas.")},l(w){c=l(w,"P",{});var $=p(c);E=r($,"\u{1F6A8} Est\xE1 vendo aquela caixa azul em torno de \u201C6 frames\u201D no traceback do Google Colab? Esse \xE9 um recurso especial do Colab, que compacta o traceback em \u201Cquadros\u201D. Se voc\xEA n\xE3o conseguir encontrar a fonte de um erro, certifique-se de expandir o rastreamento completo clicando nessas duas pequenas setas."),$.forEach(o)},m(w,$){n(w,c,$),s(c,E)},d(w){w&&o(c)}}}function Ji(Y){let c,E,w,$,C,k,A,D,N,X,M;return{c(){c=i("p"),E=t("\u{1F4A1} Se voc\xEA encontrar uma mensagem de erro dif\xEDcil de entender, basta copiar e colar a mensagem na barra de pesquisa do Google ou "),w=i("a"),$=t("Stack Overflow"),C=t(" (sim, s\xE9rio!). H\xE1 uma boa chance de voc\xEA n\xE3o ser a primeira pessoa a encontrar o erro, e essa \xE9 uma boa maneira de encontrar solu\xE7\xF5es que outras pessoas da comunidade postaram. Por exemplo, pesquisar por "),k=i("code"),A=t("OSError: Can't load config for"),D=t(" no Stack Overflow fornece v\xE1rios "),N=i("a"),X=t("hits"),M=t(" que poderia ser usado como ponto de partida para resolver o problema."),this.h()},l(G){c=l(G,"P",{});var x=p(c);E=r(x,"\u{1F4A1} Se voc\xEA encontrar uma mensagem de erro dif\xEDcil de entender, basta copiar e colar a mensagem na barra de pesquisa do Google ou "),w=l(x,"A",{href:!0,rel:!0});var io=p(w);$=r(io,"Stack Overflow"),io.forEach(o),C=r(x," (sim, s\xE9rio!). H\xE1 uma boa chance de voc\xEA n\xE3o ser a primeira pessoa a encontrar o erro, e essa \xE9 uma boa maneira de encontrar solu\xE7\xF5es que outras pessoas da comunidade postaram. Por exemplo, pesquisar por "),k=l(x,"CODE",{});var B=p(k);A=r(B,"OSError: Can't load config for"),B.forEach(o),D=r(x," no Stack Overflow fornece v\xE1rios "),N=l(x,"A",{href:!0,rel:!0});var lo=p(N);X=r(lo,"hits"),lo.forEach(o),M=r(x," que poderia ser usado como ponto de partida para resolver o problema."),x.forEach(o),this.h()},h(){m(w,"href","https://stackoverflow.com/"),m(w,"rel","nofollow"),m(N,"href","https://stackoverflow.com/search?q=OSError%3A+Can%27t+load+config+for+"),m(N,"rel","nofollow")},m(G,x){n(G,c,x),s(c,E),s(c,w),s(w,$),s(c,C),s(c,k),s(k,A),s(c,D),s(c,N),s(N,X),s(c,M)},d(G){G&&o(c)}}}function Wi(Y){let c,E,w,$,C;return{c(){c=i("p"),E=t("\u{1F6A8} A abordagem que estamos tomando aqui n\xE3o \xE9 infal\xEDvel, j\xE1 que nosso colega pode ter ajustado a configura\xE7\xE3o de "),w=i("code"),$=t("distilbert-base-uncased"),C=t(" antes de ajustar o modelo. Na vida real, gostar\xEDamos de verificar com eles primeiro, mas para os prop\xF3sitos desta se\xE7\xE3o, vamos supor que eles usaram a configura\xE7\xE3o padr\xE3o.")},l(k){c=l(k,"P",{});var A=p(c);E=r(A,"\u{1F6A8} A abordagem que estamos tomando aqui n\xE3o \xE9 infal\xEDvel, j\xE1 que nosso colega pode ter ajustado a configura\xE7\xE3o de "),w=l(A,"CODE",{});var D=p(w);$=r(D,"distilbert-base-uncased"),D.forEach(o),C=r(A," antes de ajustar o modelo. Na vida real, gostar\xEDamos de verificar com eles primeiro, mas para os prop\xF3sitos desta se\xE7\xE3o, vamos supor que eles usaram a configura\xE7\xE3o padr\xE3o."),A.forEach(o)},m(k,A){n(k,c,A),s(c,E),s(c,w),s(w,$),s(c,C)},d(k){k&&o(c)}}}function Yi(Y){let c,E,w,$,C,k,A,D,N,X,M,G,x,io,B,lo,Ya,vs,_e,ws,V,Xa,he,Ka,Za,ge,et,ot,qs,be,$s,po,st,ks,ve,xs,K,at,zo,tt,rt,Es,we,js,Z,nt,Co,it,lt,ys,J,ee,Do,qe,pt,Oo,ut,As,uo,dt,Ps,mo,$e,mt,co,ct,ft,zs,oe,_t,So,ht,gt,Cs,ke,Ds,xe,Os,O,bt,To,vt,wt,Io,qt,$t,Ho,kt,xt,Ss,Ee,je,$n,Ts,P,Et,No,jt,yt,Mo,At,Pt,fo,zt,Ct,Go,Dt,Ot,Is,se,Hs,F,St,Vo,Tt,It,Fo,Ht,Nt,Ns,ye,Ms,ae,Gs,_o,Mt,Vs,Ae,Pe,kn,Fs,ho,Gt,Qs,ze,Ce,xn,Ls,go,Vt,Rs,De,Us,Oe,Bs,Q,Ft,Qo,Qt,Lt,Lo,Rt,Ut,Js,Se,Ws,Te,Ys,j,Bt,Ro,Jt,Wt,Uo,Yt,Xt,Bo,Kt,Zt,bo,er,or,Jo,sr,ar,Xs,Ie,Ks,te,Zs,re,tr,Wo,rr,nr,ea,He,oa,ne,ir,Yo,lr,pr,sa,Ne,aa,Me,ta,vo,ur,ra,S,Ge,dr,Xo,mr,cr,fr,Ko,_r,hr,Zo,gr,br,Ve,vr,es,wr,qr,na,wo,$r,ia,W,ie,os,Fe,kr,ss,xr,la,L,Er,as,jr,yr,ts,Ar,Pr,pa,Qe,ua,qo,zr,da,Le,ma,le,Cr,$o,Dr,Or,ca,Re,fa,Ue,_a,ko,Sr,ha,Be,ga,xo,Tr,ba,Je,va,z,Ir,rs,Hr,Nr,ns,Mr,Gr,is,Vr,Fr,ls,Qr,Lr,wa,We,qa,Ye,$a,pe,Rr,ps,Ur,Br,ka,Xe,xa,Ke,Ea,y,Jr,us,Wr,Yr,Eo,Xr,Kr,ds,Zr,en,ms,on,sn,cs,an,tn,ja,Ze,ya,T,rn,fs,nn,ln,_s,pn,un,eo,dn,mn,Aa,oo,so,En,Pa,ue,cn,hs,fn,_n,za,ao,Ca,to,Da,de,hn,ro,gn,bn,Oa;return k=new qn({}),M=new Ui({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter8/section2.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter8/section2.ipynb"}]}}),_e=new wn({props:{id:"DQ-CpJn6Rc4"}}),be=new q({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`}}),ve=new q({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}}),we=new q({props:{code:`from distutils.dir_util import copy_tree
from huggingface_hub import Repository, snapshot_download, create_repo, get_full_repo_name


def copy_repository_template():
    # Clone the repo and extract the local path
    template_repo_id = "lewtun/distilbert-base-uncased-finetuned-squad-d5716d28"
    commit_hash = "be3eaffc28669d7932492681cd5f3e8905e358b4"
    template_repo_dir = snapshot_download(template_repo_id, revision=commit_hash)
    # Create an empty repo on the Hub
    model_name = template_repo_id.split("/")[1]
    create_repo(model_name, exist_ok=True)
    # Clone the empty repo
    new_repo_id = get_full_repo_name(model_name)
    new_repo_dir = model_name
    repo = Repository(local_dir=new_repo_dir, clone_from=new_repo_id)
    # Copy files
    copy_tree(template_repo_dir, new_repo_dir)
    # Push to Hub
    repo.push_to_hub()`,highlighted:`<span class="hljs-keyword">from</span> distutils.dir_util <span class="hljs-keyword">import</span> copy_tree
<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> Repository, snapshot_download, create_repo, get_full_repo_name


<span class="hljs-keyword">def</span> <span class="hljs-title function_">copy_repository_template</span>():
    <span class="hljs-comment"># Clone the repo and extract the local path</span>
    template_repo_id = <span class="hljs-string">&quot;lewtun/distilbert-base-uncased-finetuned-squad-d5716d28&quot;</span>
    commit_hash = <span class="hljs-string">&quot;be3eaffc28669d7932492681cd5f3e8905e358b4&quot;</span>
    template_repo_dir = snapshot_download(template_repo_id, revision=commit_hash)
    <span class="hljs-comment"># Create an empty repo on the Hub</span>
    model_name = template_repo_id.split(<span class="hljs-string">&quot;/&quot;</span>)[<span class="hljs-number">1</span>]
    create_repo(model_name, exist_ok=<span class="hljs-literal">True</span>)
    <span class="hljs-comment"># Clone the empty repo</span>
    new_repo_id = get_full_repo_name(model_name)
    new_repo_dir = model_name
    repo = Repository(local_dir=new_repo_dir, clone_from=new_repo_id)
    <span class="hljs-comment"># Copy files</span>
    copy_tree(template_repo_dir, new_repo_dir)
    <span class="hljs-comment"># Push to Hub</span>
    repo.push_to_hub()`}}),qe=new qn({}),ke=new q({props:{code:`from transformers import pipeline

model_checkpoint = get_full_repo_name("distillbert-base-uncased-finetuned-squad-d5716d28")
reader = pipeline("question-answering", model=model_checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

model_checkpoint = get_full_repo_name(<span class="hljs-string">&quot;distillbert-base-uncased-finetuned-squad-d5716d28&quot;</span>)
reader = pipeline(<span class="hljs-string">&quot;question-answering&quot;</span>, model=model_checkpoint)`}}),xe=new q({props:{code:`"""
OSError: Can't load config for 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28'. Make sure that:

- 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""`,highlighted:`<span class="hljs-string">&quot;&quot;&quot;
OSError: Can&#x27;t load config for &#x27;lewtun/distillbert-base-uncased-finetuned-squad-d5716d28&#x27;. Make sure that:

- &#x27;lewtun/distillbert-base-uncased-finetuned-squad-d5716d28&#x27; is a correct model identifier listed on &#x27;https://huggingface.co/models&#x27;

- or &#x27;lewtun/distillbert-base-uncased-finetuned-squad-d5716d28&#x27; is the correct path to a directory containing a config.json file
&quot;&quot;&quot;</span>`}}),se=new vn({props:{$$slots:{default:[Bi]},$$scope:{ctx:Y}}}),ye=new q({props:{code:`"""
Make sure that:

- 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""`,highlighted:`<span class="hljs-string">&quot;&quot;&quot;
Make sure that:

- &#x27;lewtun/distillbert-base-uncased-finetuned-squad-d5716d28&#x27; is a correct model identifier listed on &#x27;https://huggingface.co/models&#x27;

- or &#x27;lewtun/distillbert-base-uncased-finetuned-squad-d5716d28&#x27; is the correct path to a directory containing a config.json file
&quot;&quot;&quot;</span>`}}),ae=new vn({props:{$$slots:{default:[Ji]},$$scope:{ctx:Y}}}),De=new q({props:{code:`model_checkpoint = get_full_repo_name("distilbert-base-uncased-finetuned-squad-d5716d28")
reader = pipeline("question-answering", model=model_checkpoint)`,highlighted:`model_checkpoint = get_full_repo_name(<span class="hljs-string">&quot;distilbert-base-uncased-finetuned-squad-d5716d28&quot;</span>)
reader = pipeline(<span class="hljs-string">&quot;question-answering&quot;</span>, model=model_checkpoint)`}}),Oe=new q({props:{code:`"""
OSError: Can't load config for 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28'. Make sure that:

- 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""`,highlighted:`<span class="hljs-string">&quot;&quot;&quot;
OSError: Can&#x27;t load config for &#x27;lewtun/distilbert-base-uncased-finetuned-squad-d5716d28&#x27;. Make sure that:

- &#x27;lewtun/distilbert-base-uncased-finetuned-squad-d5716d28&#x27; is a correct model identifier listed on &#x27;https://huggingface.co/models&#x27;

- or &#x27;lewtun/distilbert-base-uncased-finetuned-squad-d5716d28&#x27; is the correct path to a directory containing a config.json file
&quot;&quot;&quot;</span>`}}),Se=new q({props:{code:`from huggingface_hub import list_repo_files

list_repo_files(repo_id=model_checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> list_repo_files

list_repo_files(repo_id=model_checkpoint)`}}),Te=new q({props:{code:"['.gitattributes', 'README.md', 'pytorch_model.bin', 'special_tokens_map.json', 'tokenizer_config.json', 'training_args.bin', 'vocab.txt']",highlighted:'[<span class="hljs-string">&#x27;.gitattributes&#x27;</span>, <span class="hljs-string">&#x27;README.md&#x27;</span>, <span class="hljs-string">&#x27;pytorch_model.bin&#x27;</span>, <span class="hljs-string">&#x27;special_tokens_map.json&#x27;</span>, <span class="hljs-string">&#x27;tokenizer_config.json&#x27;</span>, <span class="hljs-string">&#x27;training_args.bin&#x27;</span>, <span class="hljs-string">&#x27;vocab.txt&#x27;</span>]'}}),Ie=new q({props:{code:`from transformers import AutoConfig

pretrained_checkpoint = "distilbert-base-uncased"
config = AutoConfig.from_pretrained(pretrained_checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

pretrained_checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>
config = AutoConfig.from_pretrained(pretrained_checkpoint)`}}),te=new vn({props:{warning:!0,$$slots:{default:[Wi]},$$scope:{ctx:Y}}}),He=new q({props:{code:'config.push_to_hub(model_checkpoint, commit_message="Add config.json")',highlighted:'config.push_to_hub(model_checkpoint, commit_message=<span class="hljs-string">&quot;Add config.json&quot;</span>)'}}),Ne=new q({props:{code:`reader = pipeline("question-answering", model=model_checkpoint, revision="main")

context = r"""
Extractive Question Answering is the task of extracting an answer from a text
given a question. An example of a question answering dataset is the SQuAD
dataset, which is entirely based on that task. If you would like to fine-tune a
model on a SQuAD task, you may leverage the
examples/pytorch/question-answering/run_squad.py script.

\u{1F917} Transformers is interoperable with the PyTorch, TensorFlow, and JAX
frameworks, so you can use your favourite tools for a wide variety of tasks!
"""

question = "What is extractive question answering?"
reader(question=question, context=context)`,highlighted:`reader = pipeline(<span class="hljs-string">&quot;question-answering&quot;</span>, model=model_checkpoint, revision=<span class="hljs-string">&quot;main&quot;</span>)

context = <span class="hljs-string">r&quot;&quot;&quot;
Extractive Question Answering is the task of extracting an answer from a text
given a question. An example of a question answering dataset is the SQuAD
dataset, which is entirely based on that task. If you would like to fine-tune a
model on a SQuAD task, you may leverage the
examples/pytorch/question-answering/run_squad.py script.

\u{1F917} Transformers is interoperable with the PyTorch, TensorFlow, and JAX
frameworks, so you can use your favourite tools for a wide variety of tasks!
&quot;&quot;&quot;</span>

question = <span class="hljs-string">&quot;What is extractive question answering?&quot;</span>
reader(question=question, context=context)`}}),Me=new q({props:{code:`{'score': 0.38669535517692566,
 'start': 34,
 'end': 95,
 'answer': 'the task of extracting an answer from a text given a question'}`,highlighted:`{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.38669535517692566</span>,
 <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">34</span>,
 <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">95</span>,
 <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;the task of extracting an answer from a text given a question&#x27;</span>}`}}),Fe=new qn({}),Qe=new q({props:{code:`tokenizer = reader.tokenizer
model = reader.model`,highlighted:`tokenizer = reader.tokenizer
model = reader.model`}}),Le=new q({props:{code:'question = "Which frameworks can I use?"',highlighted:'question = <span class="hljs-string">&quot;Which frameworks can I use?&quot;</span>'}}),Re=new q({props:{code:`import torch

inputs = tokenizer(question, context, add_special_tokens=True)
input_ids = inputs["input_ids"][0]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
# Get the most likely beginning of answer with the argmax of the score
answer_start = torch.argmax(answer_start_scores)
# Get the most likely end of answer with the argmax of the score
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
print(f"Question: {question}")
print(f"Answer: {answer}")`,highlighted:`<span class="hljs-keyword">import</span> torch

inputs = tokenizer(question, context, add_special_tokens=<span class="hljs-literal">True</span>)
input_ids = inputs[<span class="hljs-string">&quot;input_ids&quot;</span>][<span class="hljs-number">0</span>]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
<span class="hljs-comment"># Get the most likely beginning of answer with the argmax of the score</span>
answer_start = torch.argmax(answer_start_scores)
<span class="hljs-comment"># Get the most likely end of answer with the argmax of the score</span>
answer_end = torch.argmax(answer_end_scores) + <span class="hljs-number">1</span>
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Question: <span class="hljs-subst">{question}</span>&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Answer: <span class="hljs-subst">{answer}</span>&quot;</span>)`}}),Ue=new q({props:{code:`"""
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
/var/folders/28/k4cy5q7s2hs92xq7_h89_vgm0000gn/T/ipykernel_75743/2725838073.py in <module>
      1 inputs = tokenizer(question, text, add_special_tokens=True)
      2 input_ids = inputs["input_ids"]
----> 3 outputs = model(**inputs)
      4 answer_start_scores = outputs.start_logits
      5 answer_end_scores = outputs.end_logits

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)
    723         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
    724
--> 725         distilbert_output = self.distilbert(
    726             input_ids=input_ids,
    727             attention_mask=attention_mask,

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError("You cannot specify both input_ids and inputs_embeds at the same time")
    472         elif input_ids is not None:
--> 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: 'list' object has no attribute 'size'
"""`,highlighted:`<span class="hljs-string">&quot;&quot;&quot;
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
/var/folders/28/k4cy5q7s2hs92xq7_h89_vgm0000gn/T/ipykernel_75743/2725838073.py in &lt;module&gt;
      1 inputs = tokenizer(question, text, add_special_tokens=True)
      2 input_ids = inputs[&quot;input_ids&quot;]
----&gt; 3 outputs = model(**inputs)
      4 answer_start_scores = outputs.start_logits
      5 answer_end_scores = outputs.end_logits

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-&gt; 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)
    723         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
    724
--&gt; 725         distilbert_output = self.distilbert(
    726             input_ids=input_ids,
    727             attention_mask=attention_mask,

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-&gt; 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError(&quot;You cannot specify both input_ids and inputs_embeds at the same time&quot;)
    472         elif input_ids is not None:
--&gt; 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: &#x27;list&#x27; object has no attribute &#x27;size&#x27;
&quot;&quot;&quot;</span>`}}),Be=new wn({props:{id:"rSPyvPw0p9k"}}),Je=new wn({props:{id:"5PkZ4rbHL6c"}}),We=new q({props:{code:'inputs["input_ids"][:5]',highlighted:'inputs[<span class="hljs-string">&quot;input_ids&quot;</span>][:<span class="hljs-number">5</span>]'}}),Ye=new q({props:{code:"[101, 2029, 7705, 2015, 2064]",highlighted:'[<span class="hljs-number">101</span>, <span class="hljs-number">2029</span>, <span class="hljs-number">7705</span>, <span class="hljs-number">2015</span>, <span class="hljs-number">2064</span>]'}}),Xe=new q({props:{code:'type(inputs["input_ids"])',highlighted:'<span class="hljs-built_in">type</span>(inputs[<span class="hljs-string">&quot;input_ids&quot;</span>])'}}),Ke=new q({props:{code:"list",highlighted:'<span class="hljs-built_in">list</span>'}}),Ze=new q({props:{code:`~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError("You cannot specify both input_ids and inputs_embeds at the same time")
    472         elif input_ids is not None:
--> 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: 'list' object has no attribute 'size'`,highlighted:`~<span class="hljs-regexp">/miniconda3/</span>envs<span class="hljs-regexp">/huggingface/</span>lib<span class="hljs-regexp">/python3.8/</span>site-packages<span class="hljs-regexp">/transformers/m</span>odels<span class="hljs-regexp">/distilbert/m</span>odeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    <span class="hljs-number">471</span>             raise ValueError(<span class="hljs-string">&quot;You cannot specify both input_ids and inputs_embeds at the same time&quot;</span>)
    <span class="hljs-number">472</span>         elif input_ids is not None:
--&gt; <span class="hljs-number">473</span>             input_shape = input_ids.<span class="hljs-keyword">size</span>()
    <span class="hljs-number">474</span>         elif inputs_embeds is not None:
    <span class="hljs-number">475</span>             input_shape = inputs_embeds.<span class="hljs-keyword">size</span>()[:-<span class="hljs-number">1</span>]

AttributeError: <span class="hljs-string">&#x27;list&#x27;</span> object has no attribute <span class="hljs-string">&#x27;size&#x27;</span>`}}),ao=new q({props:{code:`inputs = tokenizer(question, context, add_special_tokens=True, return_tensors="pt")
input_ids = inputs["input_ids"][0]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
# Get the most likely beginning of answer with the argmax of the score
answer_start = torch.argmax(answer_start_scores)
# Get the most likely end of answer with the argmax of the score
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
print(f"Question: {question}")
print(f"Answer: {answer}")`,highlighted:`inputs = tokenizer(question, context, add_special_tokens=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
input_ids = inputs[<span class="hljs-string">&quot;input_ids&quot;</span>][<span class="hljs-number">0</span>]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
<span class="hljs-comment"># Get the most likely beginning of answer with the argmax of the score</span>
answer_start = torch.argmax(answer_start_scores)
<span class="hljs-comment"># Get the most likely end of answer with the argmax of the score</span>
answer_end = torch.argmax(answer_end_scores) + <span class="hljs-number">1</span>
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Question: <span class="hljs-subst">{question}</span>&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Answer: <span class="hljs-subst">{answer}</span>&quot;</span>)`}}),to=new q({props:{code:`"""
Question: Which frameworks can I use?
Answer: pytorch, tensorflow, and jax
"""`,highlighted:`<span class="hljs-string">&quot;&quot;&quot;
Question: Which frameworks can I use?
Answer: pytorch, tensorflow, and jax
&quot;&quot;&quot;</span>`}}),{c(){c=i("meta"),E=u(),w=i("h1"),$=i("a"),C=i("span"),f(k.$$.fragment),A=u(),D=i("span"),N=t("O que fazer quando ocorrer um erro"),X=u(),f(M.$$.fragment),G=u(),x=i("p"),io=t("Nesta se\xE7\xE3o, veremos alguns erros comuns que podem ocorrer ao tentar gerar previs\xF5es de seu modelo Transformer rec\xE9m treinado. Isso ir\xE1 prepar\xE1-lo para a "),B=i("a"),lo=t("se\xE7\xE3o 4"),Ya=t(", onde exploraremos como debugar a pr\xF3pria fase de treinamento."),vs=u(),f(_e.$$.fragment),ws=u(),V=i("p"),Xa=t("Preparamos um "),he=i("a"),Ka=t("reposit\xF3rio modelo"),Za=t(" para esta se\xE7\xE3o e, se voc\xEA quiser executar o c\xF3digo neste cap\xEDtulo, Primeiro, voc\xEA precisar\xE1 copiar o modelo para sua conta no "),ge=i("a"),et=t("Hugging Face Hub"),ot=t(". Para fazer isso, primeiro fa\xE7a login executando o seguinte em um notebook Jupyter:"),qs=u(),f(be.$$.fragment),$s=u(),po=i("p"),st=t("ou usando seu terminal favorito:"),ks=u(),f(ve.$$.fragment),xs=u(),K=i("p"),at=t("Isso solicitar\xE1 que voc\xEA insira seu nome de usu\xE1rio e senha e salvar\xE1 um token em "),zo=i("em"),tt=t("~/.cache/huggingface/"),rt=t(". Depois de fazer login, voc\xEA pode copiar o reposit\xF3rio de modelos com a seguinte fun\xE7\xE3o:"),Es=u(),f(we.$$.fragment),js=u(),Z=i("p"),nt=t("Agora, quando voc\xEA chamar "),Co=i("code"),it=t("copy_repository_template()"),lt=t(", ele criar\xE1 uma c\xF3pia do reposit\xF3rio de modelos em sua conta."),ys=u(),J=i("h2"),ee=i("a"),Do=i("span"),f(qe.$$.fragment),pt=u(),Oo=i("span"),ut=t("Debugando o pipeline de \u{1F917} Transformers"),As=u(),uo=i("p"),dt=t("Para iniciar nossa jornada no maravilhoso mundo de debug de modelos Transformer, considere o seguinte cen\xE1rio: voc\xEA est\xE1 trabalhando com um colega em um projeto de resposta a perguntas para ajudar os clientes de um site de com\xE9rcio eletr\xF4nico a encontrar respostas sobre produtos de consumo. Seu colega lhe envia uma mensagem como:"),Ps=u(),mo=i("blockquote"),$e=i("p"),mt=t("Bom dia! Acabei de fazer um experimento usando as t\xE9cnicas do "),co=i("a"),ct=t("Cap\xEDtulo 7"),ft=t(" do curso Hugging Face e obtive \xF3timos resultados no SQuAD! Acho que podemos usar esse modelo como checkpoint para o nosso projeto. O ID do modelo no Hub \xE9 \u201Clewtun/distillbert-base-uncased-finetuned-squad-d5716d28\u201D. Fique a vontade para testar :)"),zs=u(),oe=i("p"),_t=t("e a primeira coisa que voc\xEA pensa \xE9 carregar o modelo usando o "),So=i("code"),ht=t("pipeline"),gt=t(" de \u{1F917} Transformers:"),Cs=u(),f(ke.$$.fragment),Ds=u(),f(xe.$$.fragment),Os=u(),O=i("p"),bt=t("Oh n\xE3o, algo parece ter dado errado! Se voc\xEA \xE9 novo em programa\xE7\xE3o, esse tipo de erro pode parecer um pouco enigm\xE1tico no come\xE7o (o que \xE9 mesmo um "),To=i("code"),vt=t("OSError"),wt=t("?!). O erro exibido aqui \xE9 apenas a \xFAltima parte de um relat\xF3rio de erros muito maior chamado "),Io=i("em"),qt=t("Python traceback"),$t=t(" (tamb\xE9m conhecido como "),Ho=i("strong"),kt=t("stack trace"),xt=t("). Por exemplo, se voc\xEA estiver executando este c\xF3digo no Google Colab, dever\xE1 ver algo como a captura de tela a seguir:"),Ss=u(),Ee=i("div"),je=i("img"),Ts=u(),P=i("p"),Et=t("H\xE1 muitas informa\xE7\xF5es contidas nesses relat\xF3rios, ent\xE3o vamos percorrer as partes principais juntos. A primeira coisa a notar \xE9 que os tracebacks devem ser lidos "),No=i("em"),jt=t("de baixo para cima"),yt=t(". Isso pode soar estranho se voc\xEA est\xE1 acostumado a ler texto em ingl\xEAs de cima para baixo, mas reflete o fato de que o traceback mostra a sequ\xEAncia de chamadas de fun\xE7\xE3o que o "),Mo=i("code"),At=t("pipeline"),Pt=t(" faz ao baixar o modelo e o tokenizer. (Confira o "),fo=i("a"),zt=t("Cap\xEDtulo 2"),Ct=t(" para mais detalhes sobre como o "),Go=i("code"),Dt=t("pipeline"),Ot=t(" funciona nos bastidores.)"),Is=u(),f(se.$$.fragment),Hs=u(),F=i("p"),St=t("Isso significa que a \xFAltima linha do traceback indica a \xFAltima mensagem de erro e fornece o nome da exce\xE7\xE3o que foi gerada. Nesse caso, o tipo de exce\xE7\xE3o \xE9 "),Vo=i("code"),Tt=t("OSError"),It=t(", que indica um erro relacionado ao sistema. Se lermos a mensagem de erro que a acompanha, veremos que parece haver um problema com o arquivo "),Fo=i("em"),Ht=t("config.json"),Nt=t(" do modelo e recebemos duas sugest\xF5es para corrigi-lo:"),Ns=u(),f(ye.$$.fragment),Ms=u(),f(ae.$$.fragment),Gs=u(),_o=i("p"),Mt=t("A primeira sugest\xE3o \xE9 nos pedir para verificar se o ID do modelo est\xE1 realmente correto, ent\xE3o a primeira ordem do dia \xE9 copiar o identificador e col\xE1-lo na barra de pesquisa do Hub:"),Vs=u(),Ae=i("div"),Pe=i("img"),Fs=u(),ho=i("p"),Gt=t("Hmm, realmente parece que o modelo do nosso colega n\xE3o est\xE1 no Hub\u2026 aha, mas h\xE1 um erro de digita\xE7\xE3o no nome do modelo! DistilBERT tem apenas um \u201Cl\u201D em seu nome, ent\xE3o vamos corrigir isso e procurar por \u201Clewtun/distilbert-base-uncased-finetuned-squad-d5716d28\u201D:"),Qs=u(),ze=i("div"),Ce=i("img"),Ls=u(),go=i("p"),Vt=t("Ok, isso teve sucesso. Agora vamos tentar baixar o modelo novamente com o ID do modelo correto:"),Rs=u(),f(De.$$.fragment),Us=u(),f(Oe.$$.fragment),Bs=u(),Q=i("p"),Ft=t("Argh, frustrado novamente - bem-vindo ao cotidiano de um engenheiro de aprendizado de m\xE1quina! Como corrigimos o ID do modelo, o problema deve estar no pr\xF3prio reposit\xF3rio. Uma maneira r\xE1pida de acessar o conte\xFAdo de um reposit\xF3rio no \u{1F917} Hub \xE9 atrav\xE9s da fun\xE7\xE3o "),Qo=i("code"),Qt=t("list_repo_files()"),Lt=t(" da biblioteca "),Lo=i("code"),Rt=t("huggingface_hub"),Ut=t(":"),Js=u(),f(Se.$$.fragment),Ws=u(),f(Te.$$.fragment),Ys=u(),j=i("p"),Bt=t("Interessante \u2014 n\xE3o parece haver um arquivo "),Ro=i("em"),Jt=t("config.json"),Wt=t(" no reposit\xF3rio! N\xE3o \xE9 \xE0 toa que nosso "),Uo=i("code"),Yt=t("pipeline"),Xt=t(" n\xE3o conseguiu carregar o modelo; nosso colega deve ter esquecido de enviar este arquivo para o Hub depois de ajust\xE1-lo. Nesse caso, o problema parece bem simples de corrigir: poder\xEDamos pedir para adicionar o arquivo ou, como podemos ver no ID do modelo, que o modelo pr\xE9-treinado usado foi ["),Bo=i("code"),Kt=t("distilbert-base-uncased"),Zt=t("](https:/ /huggingface.co/distilbert-base-uncased), podemos baixar a configura\xE7\xE3o para este modelo e envi\xE1-la para nosso reposit\xF3rio para ver se isso resolve o problema. Vamos tentar isso. Usando as t\xE9cnicas que aprendemos no "),bo=i("a"),er=t("Cap\xEDtulo 2"),or=t(", podemos baixar a configura\xE7\xE3o do modelo com a classe "),Jo=i("code"),sr=t("AutoConfig"),ar=t(":"),Xs=u(),f(Ie.$$.fragment),Ks=u(),f(te.$$.fragment),Zs=u(),re=i("p"),tr=t("Podemos ent\xE3o enviar isso para o nosso reposit\xF3rio de modelos com a fun\xE7\xE3o "),Wo=i("code"),rr=t("push_to_hub()"),nr=t(" da configura\xE7\xE3o:"),ea=u(),f(He.$$.fragment),oa=u(),ne=i("p"),ir=t("Agora podemos testar se funcionou carregando o modelo do \xFAltimo commit no branch "),Yo=i("code"),lr=t("main"),pr=t(":"),sa=u(),f(Ne.$$.fragment),aa=u(),f(Me.$$.fragment),ta=u(),vo=i("p"),ur=t("Uhuuul, funcionou! Vamos recapitular o que voc\xEA acabou de aprender:"),ra=u(),S=i("ul"),Ge=i("li"),dr=t("As mensagens de erro em Python s\xE3o conhecidas como "),Xo=i("em"),mr=t("tracebacks"),cr=t(" e s\xE3o lidas de baixo para cima. A \xFAltima linha da mensagem de erro geralmente cont\xE9m as informa\xE7\xF5es necess\xE1rias para localizar a origem do problema."),fr=u(),Ko=i("li"),_r=t("Se a \xFAltima linha n\xE3o contiver informa\xE7\xF5es suficientes, suba o traceback e veja se voc\xEA consegue identificar onde no c\xF3digo-fonte o erro ocorre."),hr=u(),Zo=i("li"),gr=t("Se nenhuma das mensagens de erro puder ajud\xE1-lo a debugar o problema, tente pesquisar online uma solu\xE7\xE3o para um problema semelhante."),br=u(),Ve=i("li"),vr=t("O "),es=i("code"),wr=t("huggingface_hub"),qr=t(`
// \u{1F917} Hub?
esta biblioteca fornece um conjunto de ferramentas que voc\xEA pode usar para interagir e debugar reposit\xF3rios no Hub.`),na=u(),wo=i("p"),$r=t("Agora que voc\xEA sabe como debugar um pipeline, vamos dar uma olhada em um exemplo mais complicado no forward pass do pr\xF3prio modelo."),ia=u(),W=i("h2"),ie=i("a"),os=i("span"),f(Fe.$$.fragment),kr=u(),ss=i("span"),xr=t("Debugando o forward pass do seu modelo"),la=u(),L=i("p"),Er=t("Embora o "),as=i("code"),jr=t("pipeline"),yr=t(" seja \xF3timo para a maioria dos aplicativos em que voc\xEA precisa gerar previs\xF5es rapidamente, \xE0s vezes voc\xEA precisar\xE1 acessar os logits do modelo (digamos, se voc\xEA tiver algum p\xF3s-processamento personalizado que gostaria de aplicar). Para ver o que pode dar errado neste caso, vamos primeiro pegar o modelo e o tokenizer do nosso "),ts=i("code"),Ar=t("pipeline"),Pr=t(":"),pa=u(),f(Qe.$$.fragment),ua=u(),qo=i("p"),zr=t("Em seguida, precisamos de uma pergunta, ent\xE3o vamos ver se nossos frameworks favoritos s\xE3o suportados:"),da=u(),f(Le.$$.fragment),ma=u(),le=i("p"),Cr=t("Como vimos no "),$o=i("a"),Dr=t("Cap\xEDtulo 7"),Or=t(", as etapas usuais que precisamos seguir s\xE3o tokenizar as entradas, extrair os logits dos tokens de in\xEDcio e fim e, em seguida, decodificar o intervalo de resposta:"),ca=u(),f(Re.$$.fragment),fa=u(),f(Ue.$$.fragment),_a=u(),ko=i("p"),Sr=t("Oxii, parece que temos um bug em nosso c\xF3digo! Mas n\xE3o temos medo de debugar um pouco. Voc\xEA pode usar o debugger do Python em um notebook:"),ha=u(),f(Be.$$.fragment),ga=u(),xo=i("p"),Tr=t("ou em um terminal:"),ba=u(),f(Je.$$.fragment),va=u(),z=i("p"),Ir=t("Aqui, a leitura da mensagem de erro nos diz que o objeto "),rs=i("code"),Hr=t("'list' n\xE3o tem atributo 'size'"),Nr=t(", e podemos ver uma seta "),ns=i("code"),Mr=t("-->"),Gr=t(" apontando para a linha onde o problema foi levantado em "),is=i("code"),Vr=t("model(**inputs) "),Fr=t(". Voc\xEA pode debugar isso interativamente usando o debugger Python, mas por enquanto vamos simplesmente imprimir uma fatia de "),ls=i("code"),Qr=t("entradas"),Lr=t(" para ver o que temos:"),wa=u(),f(We.$$.fragment),qa=u(),f(Ye.$$.fragment),$a=u(),pe=i("p"),Rr=t("Isso certamente se parece com uma "),ps=i("code"),Ur=t("lista"),Br=t(" comum do Python, mas vamos verificar novamente o tipo:"),ka=u(),f(Xe.$$.fragment),xa=u(),f(Ke.$$.fragment),Ea=u(),y=i("p"),Jr=t("Sim, isso \xE9 uma "),us=i("code"),Wr=t("lista"),Yr=t(" do Python com certeza. Ent\xE3o o que deu errado? Lembre-se do "),Eo=i("a"),Xr=t("Cap\xEDtulo 2"),Kr=t(" que as classes "),ds=i("code"),Zr=t("AutoModelForXxx"),en=t(" em \u{1F917} Transformers operam em "),ms=i("em"),on=t("tensors"),sn=t(" (em PyTorch ou TensorFlow), e uma opera\xE7\xE3o comum \xE9 extrair as dimens\xF5es de um tensor usando "),cs=i("code"),an=t("Tensor.size( )"),tn=t(" em, digamos, PyTorch. Vamos dar outra olhada no traceback, para ver qual linha acionou a exce\xE7\xE3o:"),ja=u(),f(Ze.$$.fragment),ya=u(),T=i("p"),rn=t("Parece que nosso c\xF3digo tentou chamar "),fs=i("code"),nn=t("input_ids.size()"),ln=t(", mas isso claramente n\xE3o funcionar\xE1 para uma "),_s=i("code"),pn=t("list"),un=t(" Python, que \xE9 apenas um cont\xEAiner. Como podemos resolver este problema? Pesquisar a mensagem de erro no Stack Overflow fornece alguns [hits] relevantes ("),eo=i("a"),dn=t("https://stackoverflow.com/search?q=AttributeError%3A+%27list%27+object+has+no+attribute+%27size%27&s=c15ec54c-63cb-481d-a749-408920073e8f"),mn=t("). Clicar no primeiro exibe uma pergunta semelhante \xE0 nossa, com a resposta mostrada na captura de tela abaixo:"),Aa=u(),oo=i("div"),so=i("img"),Pa=u(),ue=i("p"),cn=t("A resposta recomenda que adicionemos "),hs=i("code"),fn=t("return_tensors='pt'"),_n=t(" ao tokenizer, ent\xE3o vamos ver se isso funciona para n\xF3s:"),za=u(),f(ao.$$.fragment),Ca=u(),f(to.$$.fragment),Da=u(),de=i("p"),hn=t("Legal, funcionou! Este \xE9 um \xF3timo exemplo de como o Stack Overflow pode ser \xFAtil: ao identificar um problema semelhante, pudemos nos beneficiar da experi\xEAncia de outras pessoas da comunidade. No entanto, uma pesquisa como essa nem sempre produz uma resposta relevante, ent\xE3o o que voc\xEA pode fazer nesses casos? Felizmente, h\xE1 uma comunidade acolhedora de desenvolvedores nos "),ro=i("a"),gn=t("f\xF3runs do Hugging Face"),bn=t(" que pode ajud\xE1-lo! Na pr\xF3xima se\xE7\xE3o, veremos como voc\xEA pode criar boas perguntas no f\xF3rum que provavelmente ser\xE3o respondidas."),this.h()},l(e){const a=Li('[data-svelte="svelte-1phssyn"]',document.head);c=l(a,"META",{name:!0,content:!0}),a.forEach(o),E=d(e),w=l(e,"H1",{class:!0});var no=p(w);$=l(no,"A",{id:!0,class:!0,href:!0});var gs=p($);C=l(gs,"SPAN",{});var bs=p(C);_(k.$$.fragment,bs),bs.forEach(o),gs.forEach(o),A=d(no),D=l(no,"SPAN",{});var jn=p(D);N=r(jn,"O que fazer quando ocorrer um erro"),jn.forEach(o),no.forEach(o),X=d(e),_(M.$$.fragment,e),G=d(e),x=l(e,"P",{});var Sa=p(x);io=r(Sa,"Nesta se\xE7\xE3o, veremos alguns erros comuns que podem ocorrer ao tentar gerar previs\xF5es de seu modelo Transformer rec\xE9m treinado. Isso ir\xE1 prepar\xE1-lo para a "),B=l(Sa,"A",{href:!0});var yn=p(B);lo=r(yn,"se\xE7\xE3o 4"),yn.forEach(o),Ya=r(Sa,", onde exploraremos como debugar a pr\xF3pria fase de treinamento."),Sa.forEach(o),vs=d(e),_(_e.$$.fragment,e),ws=d(e),V=l(e,"P",{});var jo=p(V);Xa=r(jo,"Preparamos um "),he=l(jo,"A",{href:!0,rel:!0});var An=p(he);Ka=r(An,"reposit\xF3rio modelo"),An.forEach(o),Za=r(jo," para esta se\xE7\xE3o e, se voc\xEA quiser executar o c\xF3digo neste cap\xEDtulo, Primeiro, voc\xEA precisar\xE1 copiar o modelo para sua conta no "),ge=l(jo,"A",{href:!0,rel:!0});var Pn=p(ge);et=r(Pn,"Hugging Face Hub"),Pn.forEach(o),ot=r(jo,". Para fazer isso, primeiro fa\xE7a login executando o seguinte em um notebook Jupyter:"),jo.forEach(o),qs=d(e),_(be.$$.fragment,e),$s=d(e),po=l(e,"P",{});var zn=p(po);st=r(zn,"ou usando seu terminal favorito:"),zn.forEach(o),ks=d(e),_(ve.$$.fragment,e),xs=d(e),K=l(e,"P",{});var Ta=p(K);at=r(Ta,"Isso solicitar\xE1 que voc\xEA insira seu nome de usu\xE1rio e senha e salvar\xE1 um token em "),zo=l(Ta,"EM",{});var Cn=p(zo);tt=r(Cn,"~/.cache/huggingface/"),Cn.forEach(o),rt=r(Ta,". Depois de fazer login, voc\xEA pode copiar o reposit\xF3rio de modelos com a seguinte fun\xE7\xE3o:"),Ta.forEach(o),Es=d(e),_(we.$$.fragment,e),js=d(e),Z=l(e,"P",{});var Ia=p(Z);nt=r(Ia,"Agora, quando voc\xEA chamar "),Co=l(Ia,"CODE",{});var Dn=p(Co);it=r(Dn,"copy_repository_template()"),Dn.forEach(o),lt=r(Ia,", ele criar\xE1 uma c\xF3pia do reposit\xF3rio de modelos em sua conta."),Ia.forEach(o),ys=d(e),J=l(e,"H2",{class:!0});var Ha=p(J);ee=l(Ha,"A",{id:!0,class:!0,href:!0});var On=p(ee);Do=l(On,"SPAN",{});var Sn=p(Do);_(qe.$$.fragment,Sn),Sn.forEach(o),On.forEach(o),pt=d(Ha),Oo=l(Ha,"SPAN",{});var Tn=p(Oo);ut=r(Tn,"Debugando o pipeline de \u{1F917} Transformers"),Tn.forEach(o),Ha.forEach(o),As=d(e),uo=l(e,"P",{});var In=p(uo);dt=r(In,"Para iniciar nossa jornada no maravilhoso mundo de debug de modelos Transformer, considere o seguinte cen\xE1rio: voc\xEA est\xE1 trabalhando com um colega em um projeto de resposta a perguntas para ajudar os clientes de um site de com\xE9rcio eletr\xF4nico a encontrar respostas sobre produtos de consumo. Seu colega lhe envia uma mensagem como:"),In.forEach(o),Ps=d(e),mo=l(e,"BLOCKQUOTE",{});var Hn=p(mo);$e=l(Hn,"P",{});var Na=p($e);mt=r(Na,"Bom dia! Acabei de fazer um experimento usando as t\xE9cnicas do "),co=l(Na,"A",{href:!0});var Nn=p(co);ct=r(Nn,"Cap\xEDtulo 7"),Nn.forEach(o),ft=r(Na," do curso Hugging Face e obtive \xF3timos resultados no SQuAD! Acho que podemos usar esse modelo como checkpoint para o nosso projeto. O ID do modelo no Hub \xE9 \u201Clewtun/distillbert-base-uncased-finetuned-squad-d5716d28\u201D. Fique a vontade para testar :)"),Na.forEach(o),Hn.forEach(o),zs=d(e),oe=l(e,"P",{});var Ma=p(oe);_t=r(Ma,"e a primeira coisa que voc\xEA pensa \xE9 carregar o modelo usando o "),So=l(Ma,"CODE",{});var Mn=p(So);ht=r(Mn,"pipeline"),Mn.forEach(o),gt=r(Ma," de \u{1F917} Transformers:"),Ma.forEach(o),Cs=d(e),_(ke.$$.fragment,e),Ds=d(e),_(xe.$$.fragment,e),Os=d(e),O=l(e,"P",{});var me=p(O);bt=r(me,"Oh n\xE3o, algo parece ter dado errado! Se voc\xEA \xE9 novo em programa\xE7\xE3o, esse tipo de erro pode parecer um pouco enigm\xE1tico no come\xE7o (o que \xE9 mesmo um "),To=l(me,"CODE",{});var Gn=p(To);vt=r(Gn,"OSError"),Gn.forEach(o),wt=r(me,"?!). O erro exibido aqui \xE9 apenas a \xFAltima parte de um relat\xF3rio de erros muito maior chamado "),Io=l(me,"EM",{});var Vn=p(Io);qt=r(Vn,"Python traceback"),Vn.forEach(o),$t=r(me," (tamb\xE9m conhecido como "),Ho=l(me,"STRONG",{});var Fn=p(Ho);kt=r(Fn,"stack trace"),Fn.forEach(o),xt=r(me,"). Por exemplo, se voc\xEA estiver executando este c\xF3digo no Google Colab, dever\xE1 ver algo como a captura de tela a seguir:"),me.forEach(o),Ss=d(e),Ee=l(e,"DIV",{class:!0});var Qn=p(Ee);je=l(Qn,"IMG",{src:!0,alt:!0,width:!0}),Qn.forEach(o),Ts=d(e),P=l(e,"P",{});var R=p(P);Et=r(R,"H\xE1 muitas informa\xE7\xF5es contidas nesses relat\xF3rios, ent\xE3o vamos percorrer as partes principais juntos. A primeira coisa a notar \xE9 que os tracebacks devem ser lidos "),No=l(R,"EM",{});var Ln=p(No);jt=r(Ln,"de baixo para cima"),Ln.forEach(o),yt=r(R,". Isso pode soar estranho se voc\xEA est\xE1 acostumado a ler texto em ingl\xEAs de cima para baixo, mas reflete o fato de que o traceback mostra a sequ\xEAncia de chamadas de fun\xE7\xE3o que o "),Mo=l(R,"CODE",{});var Rn=p(Mo);At=r(Rn,"pipeline"),Rn.forEach(o),Pt=r(R," faz ao baixar o modelo e o tokenizer. (Confira o "),fo=l(R,"A",{href:!0});var Un=p(fo);zt=r(Un,"Cap\xEDtulo 2"),Un.forEach(o),Ct=r(R," para mais detalhes sobre como o "),Go=l(R,"CODE",{});var Bn=p(Go);Dt=r(Bn,"pipeline"),Bn.forEach(o),Ot=r(R," funciona nos bastidores.)"),R.forEach(o),Is=d(e),_(se.$$.fragment,e),Hs=d(e),F=l(e,"P",{});var yo=p(F);St=r(yo,"Isso significa que a \xFAltima linha do traceback indica a \xFAltima mensagem de erro e fornece o nome da exce\xE7\xE3o que foi gerada. Nesse caso, o tipo de exce\xE7\xE3o \xE9 "),Vo=l(yo,"CODE",{});var Jn=p(Vo);Tt=r(Jn,"OSError"),Jn.forEach(o),It=r(yo,", que indica um erro relacionado ao sistema. Se lermos a mensagem de erro que a acompanha, veremos que parece haver um problema com o arquivo "),Fo=l(yo,"EM",{});var Wn=p(Fo);Ht=r(Wn,"config.json"),Wn.forEach(o),Nt=r(yo," do modelo e recebemos duas sugest\xF5es para corrigi-lo:"),yo.forEach(o),Ns=d(e),_(ye.$$.fragment,e),Ms=d(e),_(ae.$$.fragment,e),Gs=d(e),_o=l(e,"P",{});var Yn=p(_o);Mt=r(Yn,"A primeira sugest\xE3o \xE9 nos pedir para verificar se o ID do modelo est\xE1 realmente correto, ent\xE3o a primeira ordem do dia \xE9 copiar o identificador e col\xE1-lo na barra de pesquisa do Hub:"),Yn.forEach(o),Vs=d(e),Ae=l(e,"DIV",{class:!0});var Xn=p(Ae);Pe=l(Xn,"IMG",{src:!0,alt:!0,width:!0}),Xn.forEach(o),Fs=d(e),ho=l(e,"P",{});var Kn=p(ho);Gt=r(Kn,"Hmm, realmente parece que o modelo do nosso colega n\xE3o est\xE1 no Hub\u2026 aha, mas h\xE1 um erro de digita\xE7\xE3o no nome do modelo! DistilBERT tem apenas um \u201Cl\u201D em seu nome, ent\xE3o vamos corrigir isso e procurar por \u201Clewtun/distilbert-base-uncased-finetuned-squad-d5716d28\u201D:"),Kn.forEach(o),Qs=d(e),ze=l(e,"DIV",{class:!0});var Zn=p(ze);Ce=l(Zn,"IMG",{src:!0,alt:!0,width:!0}),Zn.forEach(o),Ls=d(e),go=l(e,"P",{});var ei=p(go);Vt=r(ei,"Ok, isso teve sucesso. Agora vamos tentar baixar o modelo novamente com o ID do modelo correto:"),ei.forEach(o),Rs=d(e),_(De.$$.fragment,e),Us=d(e),_(Oe.$$.fragment,e),Bs=d(e),Q=l(e,"P",{});var Ao=p(Q);Ft=r(Ao,"Argh, frustrado novamente - bem-vindo ao cotidiano de um engenheiro de aprendizado de m\xE1quina! Como corrigimos o ID do modelo, o problema deve estar no pr\xF3prio reposit\xF3rio. Uma maneira r\xE1pida de acessar o conte\xFAdo de um reposit\xF3rio no \u{1F917} Hub \xE9 atrav\xE9s da fun\xE7\xE3o "),Qo=l(Ao,"CODE",{});var oi=p(Qo);Qt=r(oi,"list_repo_files()"),oi.forEach(o),Lt=r(Ao," da biblioteca "),Lo=l(Ao,"CODE",{});var si=p(Lo);Rt=r(si,"huggingface_hub"),si.forEach(o),Ut=r(Ao,":"),Ao.forEach(o),Js=d(e),_(Se.$$.fragment,e),Ws=d(e),_(Te.$$.fragment,e),Ys=d(e),j=l(e,"P",{});var I=p(j);Bt=r(I,"Interessante \u2014 n\xE3o parece haver um arquivo "),Ro=l(I,"EM",{});var ai=p(Ro);Jt=r(ai,"config.json"),ai.forEach(o),Wt=r(I," no reposit\xF3rio! N\xE3o \xE9 \xE0 toa que nosso "),Uo=l(I,"CODE",{});var ti=p(Uo);Yt=r(ti,"pipeline"),ti.forEach(o),Xt=r(I," n\xE3o conseguiu carregar o modelo; nosso colega deve ter esquecido de enviar este arquivo para o Hub depois de ajust\xE1-lo. Nesse caso, o problema parece bem simples de corrigir: poder\xEDamos pedir para adicionar o arquivo ou, como podemos ver no ID do modelo, que o modelo pr\xE9-treinado usado foi ["),Bo=l(I,"CODE",{});var ri=p(Bo);Kt=r(ri,"distilbert-base-uncased"),ri.forEach(o),Zt=r(I,"](https:/ /huggingface.co/distilbert-base-uncased), podemos baixar a configura\xE7\xE3o para este modelo e envi\xE1-la para nosso reposit\xF3rio para ver se isso resolve o problema. Vamos tentar isso. Usando as t\xE9cnicas que aprendemos no "),bo=l(I,"A",{href:!0});var ni=p(bo);er=r(ni,"Cap\xEDtulo 2"),ni.forEach(o),or=r(I,", podemos baixar a configura\xE7\xE3o do modelo com a classe "),Jo=l(I,"CODE",{});var ii=p(Jo);sr=r(ii,"AutoConfig"),ii.forEach(o),ar=r(I,":"),I.forEach(o),Xs=d(e),_(Ie.$$.fragment,e),Ks=d(e),_(te.$$.fragment,e),Zs=d(e),re=l(e,"P",{});var Ga=p(re);tr=r(Ga,"Podemos ent\xE3o enviar isso para o nosso reposit\xF3rio de modelos com a fun\xE7\xE3o "),Wo=l(Ga,"CODE",{});var li=p(Wo);rr=r(li,"push_to_hub()"),li.forEach(o),nr=r(Ga," da configura\xE7\xE3o:"),Ga.forEach(o),ea=d(e),_(He.$$.fragment,e),oa=d(e),ne=l(e,"P",{});var Va=p(ne);ir=r(Va,"Agora podemos testar se funcionou carregando o modelo do \xFAltimo commit no branch "),Yo=l(Va,"CODE",{});var pi=p(Yo);lr=r(pi,"main"),pi.forEach(o),pr=r(Va,":"),Va.forEach(o),sa=d(e),_(Ne.$$.fragment,e),aa=d(e),_(Me.$$.fragment,e),ta=d(e),vo=l(e,"P",{});var ui=p(vo);ur=r(ui,"Uhuuul, funcionou! Vamos recapitular o que voc\xEA acabou de aprender:"),ui.forEach(o),ra=d(e),S=l(e,"UL",{});var ce=p(S);Ge=l(ce,"LI",{});var Fa=p(Ge);dr=r(Fa,"As mensagens de erro em Python s\xE3o conhecidas como "),Xo=l(Fa,"EM",{});var di=p(Xo);mr=r(di,"tracebacks"),di.forEach(o),cr=r(Fa," e s\xE3o lidas de baixo para cima. A \xFAltima linha da mensagem de erro geralmente cont\xE9m as informa\xE7\xF5es necess\xE1rias para localizar a origem do problema."),Fa.forEach(o),fr=d(ce),Ko=l(ce,"LI",{});var mi=p(Ko);_r=r(mi,"Se a \xFAltima linha n\xE3o contiver informa\xE7\xF5es suficientes, suba o traceback e veja se voc\xEA consegue identificar onde no c\xF3digo-fonte o erro ocorre."),mi.forEach(o),hr=d(ce),Zo=l(ce,"LI",{});var ci=p(Zo);gr=r(ci,"Se nenhuma das mensagens de erro puder ajud\xE1-lo a debugar o problema, tente pesquisar online uma solu\xE7\xE3o para um problema semelhante."),ci.forEach(o),br=d(ce),Ve=l(ce,"LI",{});var Qa=p(Ve);vr=r(Qa,"O "),es=l(Qa,"CODE",{});var fi=p(es);wr=r(fi,"huggingface_hub"),fi.forEach(o),qr=r(Qa,`
// \u{1F917} Hub?
esta biblioteca fornece um conjunto de ferramentas que voc\xEA pode usar para interagir e debugar reposit\xF3rios no Hub.`),Qa.forEach(o),ce.forEach(o),na=d(e),wo=l(e,"P",{});var _i=p(wo);$r=r(_i,"Agora que voc\xEA sabe como debugar um pipeline, vamos dar uma olhada em um exemplo mais complicado no forward pass do pr\xF3prio modelo."),_i.forEach(o),ia=d(e),W=l(e,"H2",{class:!0});var La=p(W);ie=l(La,"A",{id:!0,class:!0,href:!0});var hi=p(ie);os=l(hi,"SPAN",{});var gi=p(os);_(Fe.$$.fragment,gi),gi.forEach(o),hi.forEach(o),kr=d(La),ss=l(La,"SPAN",{});var bi=p(ss);xr=r(bi,"Debugando o forward pass do seu modelo"),bi.forEach(o),La.forEach(o),la=d(e),L=l(e,"P",{});var Po=p(L);Er=r(Po,"Embora o "),as=l(Po,"CODE",{});var vi=p(as);jr=r(vi,"pipeline"),vi.forEach(o),yr=r(Po," seja \xF3timo para a maioria dos aplicativos em que voc\xEA precisa gerar previs\xF5es rapidamente, \xE0s vezes voc\xEA precisar\xE1 acessar os logits do modelo (digamos, se voc\xEA tiver algum p\xF3s-processamento personalizado que gostaria de aplicar). Para ver o que pode dar errado neste caso, vamos primeiro pegar o modelo e o tokenizer do nosso "),ts=l(Po,"CODE",{});var wi=p(ts);Ar=r(wi,"pipeline"),wi.forEach(o),Pr=r(Po,":"),Po.forEach(o),pa=d(e),_(Qe.$$.fragment,e),ua=d(e),qo=l(e,"P",{});var qi=p(qo);zr=r(qi,"Em seguida, precisamos de uma pergunta, ent\xE3o vamos ver se nossos frameworks favoritos s\xE3o suportados:"),qi.forEach(o),da=d(e),_(Le.$$.fragment,e),ma=d(e),le=l(e,"P",{});var Ra=p(le);Cr=r(Ra,"Como vimos no "),$o=l(Ra,"A",{href:!0});var $i=p($o);Dr=r($i,"Cap\xEDtulo 7"),$i.forEach(o),Or=r(Ra,", as etapas usuais que precisamos seguir s\xE3o tokenizar as entradas, extrair os logits dos tokens de in\xEDcio e fim e, em seguida, decodificar o intervalo de resposta:"),Ra.forEach(o),ca=d(e),_(Re.$$.fragment,e),fa=d(e),_(Ue.$$.fragment,e),_a=d(e),ko=l(e,"P",{});var ki=p(ko);Sr=r(ki,"Oxii, parece que temos um bug em nosso c\xF3digo! Mas n\xE3o temos medo de debugar um pouco. Voc\xEA pode usar o debugger do Python em um notebook:"),ki.forEach(o),ha=d(e),_(Be.$$.fragment,e),ga=d(e),xo=l(e,"P",{});var xi=p(xo);Tr=r(xi,"ou em um terminal:"),xi.forEach(o),ba=d(e),_(Je.$$.fragment,e),va=d(e),z=l(e,"P",{});var U=p(z);Ir=r(U,"Aqui, a leitura da mensagem de erro nos diz que o objeto "),rs=l(U,"CODE",{});var Ei=p(rs);Hr=r(Ei,"'list' n\xE3o tem atributo 'size'"),Ei.forEach(o),Nr=r(U,", e podemos ver uma seta "),ns=l(U,"CODE",{});var ji=p(ns);Mr=r(ji,"-->"),ji.forEach(o),Gr=r(U," apontando para a linha onde o problema foi levantado em "),is=l(U,"CODE",{});var yi=p(is);Vr=r(yi,"model(**inputs) "),yi.forEach(o),Fr=r(U,". Voc\xEA pode debugar isso interativamente usando o debugger Python, mas por enquanto vamos simplesmente imprimir uma fatia de "),ls=l(U,"CODE",{});var Ai=p(ls);Qr=r(Ai,"entradas"),Ai.forEach(o),Lr=r(U," para ver o que temos:"),U.forEach(o),wa=d(e),_(We.$$.fragment,e),qa=d(e),_(Ye.$$.fragment,e),$a=d(e),pe=l(e,"P",{});var Ua=p(pe);Rr=r(Ua,"Isso certamente se parece com uma "),ps=l(Ua,"CODE",{});var Pi=p(ps);Ur=r(Pi,"lista"),Pi.forEach(o),Br=r(Ua," comum do Python, mas vamos verificar novamente o tipo:"),Ua.forEach(o),ka=d(e),_(Xe.$$.fragment,e),xa=d(e),_(Ke.$$.fragment,e),Ea=d(e),y=l(e,"P",{});var H=p(y);Jr=r(H,"Sim, isso \xE9 uma "),us=l(H,"CODE",{});var zi=p(us);Wr=r(zi,"lista"),zi.forEach(o),Yr=r(H," do Python com certeza. Ent\xE3o o que deu errado? Lembre-se do "),Eo=l(H,"A",{href:!0});var Ci=p(Eo);Xr=r(Ci,"Cap\xEDtulo 2"),Ci.forEach(o),Kr=r(H," que as classes "),ds=l(H,"CODE",{});var Di=p(ds);Zr=r(Di,"AutoModelForXxx"),Di.forEach(o),en=r(H," em \u{1F917} Transformers operam em "),ms=l(H,"EM",{});var Oi=p(ms);on=r(Oi,"tensors"),Oi.forEach(o),sn=r(H," (em PyTorch ou TensorFlow), e uma opera\xE7\xE3o comum \xE9 extrair as dimens\xF5es de um tensor usando "),cs=l(H,"CODE",{});var Si=p(cs);an=r(Si,"Tensor.size( )"),Si.forEach(o),tn=r(H," em, digamos, PyTorch. Vamos dar outra olhada no traceback, para ver qual linha acionou a exce\xE7\xE3o:"),H.forEach(o),ja=d(e),_(Ze.$$.fragment,e),ya=d(e),T=l(e,"P",{});var fe=p(T);rn=r(fe,"Parece que nosso c\xF3digo tentou chamar "),fs=l(fe,"CODE",{});var Ti=p(fs);nn=r(Ti,"input_ids.size()"),Ti.forEach(o),ln=r(fe,", mas isso claramente n\xE3o funcionar\xE1 para uma "),_s=l(fe,"CODE",{});var Ii=p(_s);pn=r(Ii,"list"),Ii.forEach(o),un=r(fe," Python, que \xE9 apenas um cont\xEAiner. Como podemos resolver este problema? Pesquisar a mensagem de erro no Stack Overflow fornece alguns [hits] relevantes ("),eo=l(fe,"A",{href:!0,rel:!0});var Hi=p(eo);dn=r(Hi,"https://stackoverflow.com/search?q=AttributeError%3A+%27list%27+object+has+no+attribute+%27size%27&s=c15ec54c-63cb-481d-a749-408920073e8f"),Hi.forEach(o),mn=r(fe,"). Clicar no primeiro exibe uma pergunta semelhante \xE0 nossa, com a resposta mostrada na captura de tela abaixo:"),fe.forEach(o),Aa=d(e),oo=l(e,"DIV",{class:!0});var Ni=p(oo);so=l(Ni,"IMG",{src:!0,alt:!0,width:!0}),Ni.forEach(o),Pa=d(e),ue=l(e,"P",{});var Ba=p(ue);cn=r(Ba,"A resposta recomenda que adicionemos "),hs=l(Ba,"CODE",{});var Mi=p(hs);fn=r(Mi,"return_tensors='pt'"),Mi.forEach(o),_n=r(Ba," ao tokenizer, ent\xE3o vamos ver se isso funciona para n\xF3s:"),Ba.forEach(o),za=d(e),_(ao.$$.fragment,e),Ca=d(e),_(to.$$.fragment,e),Da=d(e),de=l(e,"P",{});var Ja=p(de);hn=r(Ja,"Legal, funcionou! Este \xE9 um \xF3timo exemplo de como o Stack Overflow pode ser \xFAtil: ao identificar um problema semelhante, pudemos nos beneficiar da experi\xEAncia de outras pessoas da comunidade. No entanto, uma pesquisa como essa nem sempre produz uma resposta relevante, ent\xE3o o que voc\xEA pode fazer nesses casos? Felizmente, h\xE1 uma comunidade acolhedora de desenvolvedores nos "),ro=l(Ja,"A",{href:!0,rel:!0});var Gi=p(ro);gn=r(Gi,"f\xF3runs do Hugging Face"),Gi.forEach(o),bn=r(Ja," que pode ajud\xE1-lo! Na pr\xF3xima se\xE7\xE3o, veremos como voc\xEA pode criar boas perguntas no f\xF3rum que provavelmente ser\xE3o respondidas."),Ja.forEach(o),this.h()},h(){m(c,"name","hf:doc:metadata"),m(c,"content",JSON.stringify(Xi)),m($,"id","o-que-fazer-quando-ocorrer-um-erro"),m($,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m($,"href","#o-que-fazer-quando-ocorrer-um-erro"),m(w,"class","relative group"),m(B,"href","/course/chapter8/section4"),m(he,"href","https://huggingface.co/lewtun/distilbert-base-uncased-finetuned-squad-d5716d28"),m(he,"rel","nofollow"),m(ge,"href","https://huggingface.co"),m(ge,"rel","nofollow"),m(ee,"id","debugando-o-pipeline-de-transformers"),m(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ee,"href","#debugando-o-pipeline-de-transformers"),m(J,"class","relative group"),m(co,"href","/course/chapter7/7"),Wa(je.src,$n="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/traceback.png")||m(je,"src",$n),m(je,"alt","A Python traceback."),m(je,"width","100%"),m(Ee,"class","flex justify-center"),m(fo,"href","/course/chapter2"),Wa(Pe.src,kn="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/wrong-model-id.png")||m(Pe,"src",kn),m(Pe,"alt","The wrong model name."),m(Pe,"width","100%"),m(Ae,"class","flex justify-center"),Wa(Ce.src,xn="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/true-model-id.png")||m(Ce,"src",xn),m(Ce,"alt","The right model name."),m(Ce,"width","100%"),m(ze,"class","flex justify-center"),m(bo,"href","/course/chapter2"),m(ie,"id","debugando-o-forward-pass-do-seu-modelo"),m(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),m(ie,"href","#debugando-o-forward-pass-do-seu-modelo"),m(W,"class","relative group"),m($o,"href","/course/chapter7"),m(Eo,"href","/course/chapter2"),m(eo,"href","https://stackoverflow.com/search?q=AttributeError%3A+%27list%27+object+has+no+attribute+%27size%27&s=c15ec54c-63cb-481d-a749-408920073e8f"),m(eo,"rel","nofollow"),Wa(so.src,En="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/stack-overflow.png")||m(so,"src",En),m(so,"alt","An answer from Stack Overflow."),m(so,"width","100%"),m(oo,"class","flex justify-center"),m(ro,"href","https://discuss.huggingface.co/"),m(ro,"rel","nofollow")},m(e,a){s(document.head,c),n(e,E,a),n(e,w,a),s(w,$),s($,C),h(k,C,null),s(w,A),s(w,D),s(D,N),n(e,X,a),h(M,e,a),n(e,G,a),n(e,x,a),s(x,io),s(x,B),s(B,lo),s(x,Ya),n(e,vs,a),h(_e,e,a),n(e,ws,a),n(e,V,a),s(V,Xa),s(V,he),s(he,Ka),s(V,Za),s(V,ge),s(ge,et),s(V,ot),n(e,qs,a),h(be,e,a),n(e,$s,a),n(e,po,a),s(po,st),n(e,ks,a),h(ve,e,a),n(e,xs,a),n(e,K,a),s(K,at),s(K,zo),s(zo,tt),s(K,rt),n(e,Es,a),h(we,e,a),n(e,js,a),n(e,Z,a),s(Z,nt),s(Z,Co),s(Co,it),s(Z,lt),n(e,ys,a),n(e,J,a),s(J,ee),s(ee,Do),h(qe,Do,null),s(J,pt),s(J,Oo),s(Oo,ut),n(e,As,a),n(e,uo,a),s(uo,dt),n(e,Ps,a),n(e,mo,a),s(mo,$e),s($e,mt),s($e,co),s(co,ct),s($e,ft),n(e,zs,a),n(e,oe,a),s(oe,_t),s(oe,So),s(So,ht),s(oe,gt),n(e,Cs,a),h(ke,e,a),n(e,Ds,a),h(xe,e,a),n(e,Os,a),n(e,O,a),s(O,bt),s(O,To),s(To,vt),s(O,wt),s(O,Io),s(Io,qt),s(O,$t),s(O,Ho),s(Ho,kt),s(O,xt),n(e,Ss,a),n(e,Ee,a),s(Ee,je),n(e,Ts,a),n(e,P,a),s(P,Et),s(P,No),s(No,jt),s(P,yt),s(P,Mo),s(Mo,At),s(P,Pt),s(P,fo),s(fo,zt),s(P,Ct),s(P,Go),s(Go,Dt),s(P,Ot),n(e,Is,a),h(se,e,a),n(e,Hs,a),n(e,F,a),s(F,St),s(F,Vo),s(Vo,Tt),s(F,It),s(F,Fo),s(Fo,Ht),s(F,Nt),n(e,Ns,a),h(ye,e,a),n(e,Ms,a),h(ae,e,a),n(e,Gs,a),n(e,_o,a),s(_o,Mt),n(e,Vs,a),n(e,Ae,a),s(Ae,Pe),n(e,Fs,a),n(e,ho,a),s(ho,Gt),n(e,Qs,a),n(e,ze,a),s(ze,Ce),n(e,Ls,a),n(e,go,a),s(go,Vt),n(e,Rs,a),h(De,e,a),n(e,Us,a),h(Oe,e,a),n(e,Bs,a),n(e,Q,a),s(Q,Ft),s(Q,Qo),s(Qo,Qt),s(Q,Lt),s(Q,Lo),s(Lo,Rt),s(Q,Ut),n(e,Js,a),h(Se,e,a),n(e,Ws,a),h(Te,e,a),n(e,Ys,a),n(e,j,a),s(j,Bt),s(j,Ro),s(Ro,Jt),s(j,Wt),s(j,Uo),s(Uo,Yt),s(j,Xt),s(j,Bo),s(Bo,Kt),s(j,Zt),s(j,bo),s(bo,er),s(j,or),s(j,Jo),s(Jo,sr),s(j,ar),n(e,Xs,a),h(Ie,e,a),n(e,Ks,a),h(te,e,a),n(e,Zs,a),n(e,re,a),s(re,tr),s(re,Wo),s(Wo,rr),s(re,nr),n(e,ea,a),h(He,e,a),n(e,oa,a),n(e,ne,a),s(ne,ir),s(ne,Yo),s(Yo,lr),s(ne,pr),n(e,sa,a),h(Ne,e,a),n(e,aa,a),h(Me,e,a),n(e,ta,a),n(e,vo,a),s(vo,ur),n(e,ra,a),n(e,S,a),s(S,Ge),s(Ge,dr),s(Ge,Xo),s(Xo,mr),s(Ge,cr),s(S,fr),s(S,Ko),s(Ko,_r),s(S,hr),s(S,Zo),s(Zo,gr),s(S,br),s(S,Ve),s(Ve,vr),s(Ve,es),s(es,wr),s(Ve,qr),n(e,na,a),n(e,wo,a),s(wo,$r),n(e,ia,a),n(e,W,a),s(W,ie),s(ie,os),h(Fe,os,null),s(W,kr),s(W,ss),s(ss,xr),n(e,la,a),n(e,L,a),s(L,Er),s(L,as),s(as,jr),s(L,yr),s(L,ts),s(ts,Ar),s(L,Pr),n(e,pa,a),h(Qe,e,a),n(e,ua,a),n(e,qo,a),s(qo,zr),n(e,da,a),h(Le,e,a),n(e,ma,a),n(e,le,a),s(le,Cr),s(le,$o),s($o,Dr),s(le,Or),n(e,ca,a),h(Re,e,a),n(e,fa,a),h(Ue,e,a),n(e,_a,a),n(e,ko,a),s(ko,Sr),n(e,ha,a),h(Be,e,a),n(e,ga,a),n(e,xo,a),s(xo,Tr),n(e,ba,a),h(Je,e,a),n(e,va,a),n(e,z,a),s(z,Ir),s(z,rs),s(rs,Hr),s(z,Nr),s(z,ns),s(ns,Mr),s(z,Gr),s(z,is),s(is,Vr),s(z,Fr),s(z,ls),s(ls,Qr),s(z,Lr),n(e,wa,a),h(We,e,a),n(e,qa,a),h(Ye,e,a),n(e,$a,a),n(e,pe,a),s(pe,Rr),s(pe,ps),s(ps,Ur),s(pe,Br),n(e,ka,a),h(Xe,e,a),n(e,xa,a),h(Ke,e,a),n(e,Ea,a),n(e,y,a),s(y,Jr),s(y,us),s(us,Wr),s(y,Yr),s(y,Eo),s(Eo,Xr),s(y,Kr),s(y,ds),s(ds,Zr),s(y,en),s(y,ms),s(ms,on),s(y,sn),s(y,cs),s(cs,an),s(y,tn),n(e,ja,a),h(Ze,e,a),n(e,ya,a),n(e,T,a),s(T,rn),s(T,fs),s(fs,nn),s(T,ln),s(T,_s),s(_s,pn),s(T,un),s(T,eo),s(eo,dn),s(T,mn),n(e,Aa,a),n(e,oo,a),s(oo,so),n(e,Pa,a),n(e,ue,a),s(ue,cn),s(ue,hs),s(hs,fn),s(ue,_n),n(e,za,a),h(ao,e,a),n(e,Ca,a),h(to,e,a),n(e,Da,a),n(e,de,a),s(de,hn),s(de,ro),s(ro,gn),s(de,bn),Oa=!0},p(e,[a]){const no={};a&2&&(no.$$scope={dirty:a,ctx:e}),se.$set(no);const gs={};a&2&&(gs.$$scope={dirty:a,ctx:e}),ae.$set(gs);const bs={};a&2&&(bs.$$scope={dirty:a,ctx:e}),te.$set(bs)},i(e){Oa||(g(k.$$.fragment,e),g(M.$$.fragment,e),g(_e.$$.fragment,e),g(be.$$.fragment,e),g(ve.$$.fragment,e),g(we.$$.fragment,e),g(qe.$$.fragment,e),g(ke.$$.fragment,e),g(xe.$$.fragment,e),g(se.$$.fragment,e),g(ye.$$.fragment,e),g(ae.$$.fragment,e),g(De.$$.fragment,e),g(Oe.$$.fragment,e),g(Se.$$.fragment,e),g(Te.$$.fragment,e),g(Ie.$$.fragment,e),g(te.$$.fragment,e),g(He.$$.fragment,e),g(Ne.$$.fragment,e),g(Me.$$.fragment,e),g(Fe.$$.fragment,e),g(Qe.$$.fragment,e),g(Le.$$.fragment,e),g(Re.$$.fragment,e),g(Ue.$$.fragment,e),g(Be.$$.fragment,e),g(Je.$$.fragment,e),g(We.$$.fragment,e),g(Ye.$$.fragment,e),g(Xe.$$.fragment,e),g(Ke.$$.fragment,e),g(Ze.$$.fragment,e),g(ao.$$.fragment,e),g(to.$$.fragment,e),Oa=!0)},o(e){b(k.$$.fragment,e),b(M.$$.fragment,e),b(_e.$$.fragment,e),b(be.$$.fragment,e),b(ve.$$.fragment,e),b(we.$$.fragment,e),b(qe.$$.fragment,e),b(ke.$$.fragment,e),b(xe.$$.fragment,e),b(se.$$.fragment,e),b(ye.$$.fragment,e),b(ae.$$.fragment,e),b(De.$$.fragment,e),b(Oe.$$.fragment,e),b(Se.$$.fragment,e),b(Te.$$.fragment,e),b(Ie.$$.fragment,e),b(te.$$.fragment,e),b(He.$$.fragment,e),b(Ne.$$.fragment,e),b(Me.$$.fragment,e),b(Fe.$$.fragment,e),b(Qe.$$.fragment,e),b(Le.$$.fragment,e),b(Re.$$.fragment,e),b(Ue.$$.fragment,e),b(Be.$$.fragment,e),b(Je.$$.fragment,e),b(We.$$.fragment,e),b(Ye.$$.fragment,e),b(Xe.$$.fragment,e),b(Ke.$$.fragment,e),b(Ze.$$.fragment,e),b(ao.$$.fragment,e),b(to.$$.fragment,e),Oa=!1},d(e){o(c),e&&o(E),e&&o(w),v(k),e&&o(X),v(M,e),e&&o(G),e&&o(x),e&&o(vs),v(_e,e),e&&o(ws),e&&o(V),e&&o(qs),v(be,e),e&&o($s),e&&o(po),e&&o(ks),v(ve,e),e&&o(xs),e&&o(K),e&&o(Es),v(we,e),e&&o(js),e&&o(Z),e&&o(ys),e&&o(J),v(qe),e&&o(As),e&&o(uo),e&&o(Ps),e&&o(mo),e&&o(zs),e&&o(oe),e&&o(Cs),v(ke,e),e&&o(Ds),v(xe,e),e&&o(Os),e&&o(O),e&&o(Ss),e&&o(Ee),e&&o(Ts),e&&o(P),e&&o(Is),v(se,e),e&&o(Hs),e&&o(F),e&&o(Ns),v(ye,e),e&&o(Ms),v(ae,e),e&&o(Gs),e&&o(_o),e&&o(Vs),e&&o(Ae),e&&o(Fs),e&&o(ho),e&&o(Qs),e&&o(ze),e&&o(Ls),e&&o(go),e&&o(Rs),v(De,e),e&&o(Us),v(Oe,e),e&&o(Bs),e&&o(Q),e&&o(Js),v(Se,e),e&&o(Ws),v(Te,e),e&&o(Ys),e&&o(j),e&&o(Xs),v(Ie,e),e&&o(Ks),v(te,e),e&&o(Zs),e&&o(re),e&&o(ea),v(He,e),e&&o(oa),e&&o(ne),e&&o(sa),v(Ne,e),e&&o(aa),v(Me,e),e&&o(ta),e&&o(vo),e&&o(ra),e&&o(S),e&&o(na),e&&o(wo),e&&o(ia),e&&o(W),v(Fe),e&&o(la),e&&o(L),e&&o(pa),v(Qe,e),e&&o(ua),e&&o(qo),e&&o(da),v(Le,e),e&&o(ma),e&&o(le),e&&o(ca),v(Re,e),e&&o(fa),v(Ue,e),e&&o(_a),e&&o(ko),e&&o(ha),v(Be,e),e&&o(ga),e&&o(xo),e&&o(ba),v(Je,e),e&&o(va),e&&o(z),e&&o(wa),v(We,e),e&&o(qa),v(Ye,e),e&&o($a),e&&o(pe),e&&o(ka),v(Xe,e),e&&o(xa),v(Ke,e),e&&o(Ea),e&&o(y),e&&o(ja),v(Ze,e),e&&o(ya),e&&o(T),e&&o(Aa),e&&o(oo),e&&o(Pa),e&&o(ue),e&&o(za),v(ao,e),e&&o(Ca),v(to,e),e&&o(Da),e&&o(de)}}}const Xi={local:"o-que-fazer-quando-ocorrer-um-erro",sections:[{local:"debugando-o-pipeline-de-transformers",title:"Debugando o pipeline de \u{1F917} Transformers"},{local:"debugando-o-forward-pass-do-seu-modelo",title:"Debugando o forward pass do seu modelo"}],title:"O que fazer quando ocorrer um erro"};function Ki(Y){return Ri(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class rl extends Vi{constructor(c){super();Fi(this,c,Ki,Yi,Qi,{})}}export{rl as default,Xi as metadata};
