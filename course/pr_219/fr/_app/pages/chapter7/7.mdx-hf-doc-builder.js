import{S as Fb,i as Vb,s as Hb,e as o,t as n,k as d,w as j,c as r,a as l,h as a,d as t,m as c,x as k,g as i,G as s,y as E,q as h,o as v,B as y,b as A,M as Rb,N as Hd,p as un,v as Ub,n as pn}from"../../chunks/vendor-hf-doc-builder.js";import{T as Rd}from"../../chunks/Tip-hf-doc-builder.js";import{Y as Ud}from"../../chunks/Youtube-hf-doc-builder.js";import{I as cs}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as T}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as Bb}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as Qb}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function Gb(H){let p,b;return p=new Bb({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter7/section7_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter7/section7_tf.ipynb"}]}}),{c(){j(p.$$.fragment)},l(f){k(p.$$.fragment,f)},m(f,C){E(p,f,C),b=!0},i(f){b||(h(p.$$.fragment,f),b=!0)},o(f){v(p.$$.fragment,f),b=!1},d(f){y(p,f)}}}function Wb(H){let p,b;return p=new Bb({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter7/section7_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter7/section7_pt.ipynb"}]}}),{c(){j(p.$$.fragment)},l(f){k(p.$$.fragment,f)},m(f,C){E(p,f,C),b=!0},i(f){b||(h(p.$$.fragment,f),b=!0)},o(f){v(p.$$.fragment,f),b=!1},d(f){y(p,f)}}}function Jb(H){let p,b,f,C,S,g,$,q,_,z,x,D,L,N;return{c(){p=o("p"),b=n("\u{1F4A1} Les mod\xE8les \xE0 codeur unique comme BERT ont tendance \xE0 \xEAtre excellents pour extraire les r\xE9ponses \xE0 des questions factuelles comme \u201CQui a invent\xE9 l\u2019architecture Transformer ?\u201D, mais ne sont pas tr\xE8s performants lorsqu\u2019on leur pose des questions ouvertes comme \u201CPourquoi le ciel est-il bleu ?\u201C. Dans ces cas plus difficiles, les mod\xE8les encodeurs-d\xE9codeurs comme T5 et BART sont g\xE9n\xE9ralement utilis\xE9s pour synth\xE9tiser les informations d\u2019une mani\xE8re assez similaire au "),f=o("a"),C=n("r\xE9sum\xE9 de texte"),S=n(". Si vous \xEAtes int\xE9ress\xE9 par ce type de r\xE9ponse aux questions "),g=o("em"),$=n("g\xE9n\xE9ratives"),q=n(", nous vous recommandons de consulter notre "),_=o("a"),z=n("d\xE9mo"),x=n(" bas\xE9e sur le "),D=o("a"),L=n("jeu de donn\xE9es ELI5"),N=n("."),this.h()},l(P){p=r(P,"P",{});var w=l(p);b=a(w,"\u{1F4A1} Les mod\xE8les \xE0 codeur unique comme BERT ont tendance \xE0 \xEAtre excellents pour extraire les r\xE9ponses \xE0 des questions factuelles comme \u201CQui a invent\xE9 l\u2019architecture Transformer ?\u201D, mais ne sont pas tr\xE8s performants lorsqu\u2019on leur pose des questions ouvertes comme \u201CPourquoi le ciel est-il bleu ?\u201C. Dans ces cas plus difficiles, les mod\xE8les encodeurs-d\xE9codeurs comme T5 et BART sont g\xE9n\xE9ralement utilis\xE9s pour synth\xE9tiser les informations d\u2019une mani\xE8re assez similaire au "),f=r(w,"A",{href:!0});var U=l(f);C=a(U,"r\xE9sum\xE9 de texte"),U.forEach(t),S=a(w,". Si vous \xEAtes int\xE9ress\xE9 par ce type de r\xE9ponse aux questions "),g=r(w,"EM",{});var V=l(g);$=a(V,"g\xE9n\xE9ratives"),V.forEach(t),q=a(w,", nous vous recommandons de consulter notre "),_=r(w,"A",{href:!0,rel:!0});var F=l(_);z=a(F,"d\xE9mo"),F.forEach(t),x=a(w," bas\xE9e sur le "),D=r(w,"A",{href:!0,rel:!0});var M=l(D);L=a(M,"jeu de donn\xE9es ELI5"),M.forEach(t),N=a(w,"."),w.forEach(t),this.h()},h(){A(f,"href","/cours/fr/chapter7/5"),A(_,"href","https://yjernite.github.io/lfqa.html"),A(_,"rel","nofollow"),A(D,"href","https://huggingface.co/datasets/eli5"),A(D,"rel","nofollow")},m(P,w){i(P,p,w),s(p,b),s(p,f),s(f,C),s(p,S),s(p,g),s(g,$),s(p,q),s(p,_),s(_,z),s(p,x),s(p,D),s(D,L),s(p,N)},d(P){P&&t(p)}}}function Xb(H){let p,b,f,C,S,g,$,q,_,z,x,D,L,N,P,w,U;return{c(){p=o("p"),b=n("\u270F\uFE0F "),f=o("strong"),C=n("A votre tour !"),S=n(" En utilisant l\u2019architecture XLNet, le "),g=o("em"),$=n("padding"),q=n(" est appliqu\xE9 \xE0 gauche et la question et le contexte sont intervertis. Adaptez tout le code que nous venons de voir \xE0 l\u2019architecture XLNet (et ajoutez "),_=o("code"),z=n("padding=True"),x=n("). Soyez conscient que le token "),D=o("code"),L=n("[CLS]"),N=n(" peut ne pas \xEAtre \xE0 la position 0 avec le "),P=o("em"),w=n("padding"),U=n(" appliqu\xE9.")},l(V){p=r(V,"P",{});var F=l(p);b=a(F,"\u270F\uFE0F "),f=r(F,"STRONG",{});var M=l(f);C=a(M,"A votre tour !"),M.forEach(t),S=a(F," En utilisant l\u2019architecture XLNet, le "),g=r(F,"EM",{});var B=l(g);$=a(B,"padding"),B.forEach(t),q=a(F," est appliqu\xE9 \xE0 gauche et la question et le contexte sont intervertis. Adaptez tout le code que nous venons de voir \xE0 l\u2019architecture XLNet (et ajoutez "),_=r(F,"CODE",{});var G=l(_);z=a(G,"padding=True"),G.forEach(t),x=a(F,"). Soyez conscient que le token "),D=r(F,"CODE",{});var ee=l(D);L=a(ee,"[CLS]"),ee.forEach(t),N=a(F," peut ne pas \xEAtre \xE0 la position 0 avec le "),P=r(F,"EM",{});var Q=l(P);w=a(Q,"padding"),Q.forEach(t),U=a(F," appliqu\xE9."),F.forEach(t)},m(V,F){i(V,p,F),s(p,b),s(p,f),s(f,C),s(p,S),s(p,g),s(g,$),s(p,q),s(p,_),s(_,z),s(p,x),s(p,D),s(D,L),s(p,N),s(p,P),s(P,w),s(p,U)},d(V){V&&t(p)}}}function Kb(H){let p,b,f,C,S,g,$,q,_,z,x,D,L,N;return C=new cs({}),{c(){p=o("h2"),b=o("a"),f=o("span"),j(C.$$.fragment),S=d(),g=o("span"),$=n("*Finetuner* fin du mod\xE8le avec Keras"),q=d(),_=o("p"),z=n("Le code d\u2019entra\xEEnement de cet exemple ressemblera beaucoup au code des sections pr\xE9c\xE9dentes, mais le calcul des m\xE9triques sera un d\xE9fi unique. Puisque nous avons capitonn\xE9 tous les \xE9chantillons \xE0 la longueur maximale que nous avons d\xE9finie, il n\u2019y a pas de collateur de donn\xE9es \xE0 d\xE9finir, donc le calcul de la m\xE9trique est vraiment la seule chose dont nous devons nous soucier. La partie la plus difficile sera de post-traiter les pr\xE9dictions du mod\xE8le en trav\xE9es de texte dans les exemples originaux ; une fois que nous aurons fait cela, la m\xE9trique de la biblioth\xE8que \u{1F917} "),x=o("em"),D=n("Datasets"),L=n(" fera le gros du travail pour nous."),this.h()},l(P){p=r(P,"H2",{class:!0});var w=l(p);b=r(w,"A",{id:!0,class:!0,href:!0});var U=l(b);f=r(U,"SPAN",{});var V=l(f);k(C.$$.fragment,V),V.forEach(t),U.forEach(t),S=c(w),g=r(w,"SPAN",{});var F=l(g);$=a(F,"*Finetuner* fin du mod\xE8le avec Keras"),F.forEach(t),w.forEach(t),q=c(P),_=r(P,"P",{});var M=l(_);z=a(M,"Le code d\u2019entra\xEEnement de cet exemple ressemblera beaucoup au code des sections pr\xE9c\xE9dentes, mais le calcul des m\xE9triques sera un d\xE9fi unique. Puisque nous avons capitonn\xE9 tous les \xE9chantillons \xE0 la longueur maximale que nous avons d\xE9finie, il n\u2019y a pas de collateur de donn\xE9es \xE0 d\xE9finir, donc le calcul de la m\xE9trique est vraiment la seule chose dont nous devons nous soucier. La partie la plus difficile sera de post-traiter les pr\xE9dictions du mod\xE8le en trav\xE9es de texte dans les exemples originaux ; une fois que nous aurons fait cela, la m\xE9trique de la biblioth\xE8que \u{1F917} "),x=r(M,"EM",{});var B=l(x);D=a(B,"Datasets"),B.forEach(t),L=a(M," fera le gros du travail pour nous."),M.forEach(t),this.h()},h(){A(b,"id","finetuner-fin-du-modle-avec-keras"),A(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),A(b,"href","#finetuner-fin-du-modle-avec-keras"),A(p,"class","relative group")},m(P,w){i(P,p,w),s(p,b),s(b,f),E(C,f,null),s(p,S),s(p,g),s(g,$),i(P,q,w),i(P,_,w),s(_,z),s(_,x),s(x,D),s(_,L),N=!0},i(P){N||(h(C.$$.fragment,P),N=!0)},o(P){v(C.$$.fragment,P),N=!1},d(P){P&&t(p),y(C),P&&t(q),P&&t(_)}}}function Yb(H){let p,b,f,C,S,g,$,q,_,z,x,D,L,N,P,w,U,V,F;return C=new cs({}),{c(){p=o("h2"),b=o("a"),f=o("span"),j(C.$$.fragment),S=d(),g=o("span"),$=n("*Finetuner* le mod\xE8le avec l'API "),q=o("code"),_=n("Trainer"),z=d(),x=o("p"),D=n("Le code d\u2019entra\xEEnement pour cet exemple ressemblera beaucoup au code des sections pr\xE9c\xE9dentes \u2014 la chose la plus difficile sera d\u2019\xE9crire la fonction "),L=o("code"),N=n("compute_metrics()"),P=n(". Puisque nous avons capitonn\xE9 tous les \xE9chantillons \xE0 la longueur maximale que nous avons fix\xE9e, il n\u2019y a pas de collateur de donn\xE9es \xE0 d\xE9finir, donc ce calcul de m\xE9trique est vraiment la seule chose dont nous devons nous soucier. La partie la plus difficile sera de post-traiter les pr\xE9dictions du mod\xE8le en trav\xE9es de texte dans les exemples originaux ; une fois que nous aurons fait cela, la m\xE9trique de la biblioth\xE8que \u{1F917} "),w=o("em"),U=n("Datasets"),V=n(" fera le gros du travail pour nous."),this.h()},l(M){p=r(M,"H2",{class:!0});var B=l(p);b=r(B,"A",{id:!0,class:!0,href:!0});var G=l(b);f=r(G,"SPAN",{});var ee=l(f);k(C.$$.fragment,ee),ee.forEach(t),G.forEach(t),S=c(B),g=r(B,"SPAN",{});var Q=l(g);$=a(Q,"*Finetuner* le mod\xE8le avec l'API "),q=r(Q,"CODE",{});var W=l(q);_=a(W,"Trainer"),W.forEach(t),Q.forEach(t),B.forEach(t),z=c(M),x=r(M,"P",{});var K=l(x);D=a(K,"Le code d\u2019entra\xEEnement pour cet exemple ressemblera beaucoup au code des sections pr\xE9c\xE9dentes \u2014 la chose la plus difficile sera d\u2019\xE9crire la fonction "),L=r(K,"CODE",{});var Y=l(L);N=a(Y,"compute_metrics()"),Y.forEach(t),P=a(K,". Puisque nous avons capitonn\xE9 tous les \xE9chantillons \xE0 la longueur maximale que nous avons fix\xE9e, il n\u2019y a pas de collateur de donn\xE9es \xE0 d\xE9finir, donc ce calcul de m\xE9trique est vraiment la seule chose dont nous devons nous soucier. La partie la plus difficile sera de post-traiter les pr\xE9dictions du mod\xE8le en trav\xE9es de texte dans les exemples originaux ; une fois que nous aurons fait cela, la m\xE9trique de la biblioth\xE8que \u{1F917} "),w=r(K,"EM",{});var O=l(w);U=a(O,"Datasets"),O.forEach(t),V=a(K," fera le gros du travail pour nous."),K.forEach(t),this.h()},h(){A(b,"id","finetuner-le-modle-avec-lapi-trainer"),A(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),A(b,"href","#finetuner-le-modle-avec-lapi-trainer"),A(p,"class","relative group")},m(M,B){i(M,p,B),s(p,b),s(b,f),E(C,f,null),s(p,S),s(p,g),s(g,$),s(g,q),s(q,_),i(M,z,B),i(M,x,B),s(x,D),s(x,L),s(L,N),s(x,P),s(x,w),s(w,U),s(x,V),F=!0},i(M){F||(h(C.$$.fragment,M),F=!0)},o(M){v(C.$$.fragment,M),F=!1},d(M){M&&t(p),y(C),M&&t(z),M&&t(x)}}}function Zb(H){let p,b;return p=new Ud({props:{id:"VN67ZpN33Ss"}}),{c(){j(p.$$.fragment)},l(f){k(p.$$.fragment,f)},m(f,C){E(p,f,C),b=!0},i(f){b||(h(p.$$.fragment,f),b=!0)},o(f){v(p.$$.fragment,f),b=!1},d(f){y(p,f)}}}function eg(H){let p,b;return p=new Ud({props:{id:"BNy08iIWVJM"}}),{c(){j(p.$$.fragment)},l(f){k(p.$$.fragment,f)},m(f,C){E(p,f,C),b=!0},i(f){b||(h(p.$$.fragment,f),b=!0)},o(f){v(p.$$.fragment,f),b=!1},d(f){y(p,f)}}}function sg(H){let p,b,f,C,S,g,$;return p=new T({props:{code:`import tensorflow as tf
from transformers import TFAutoModelForQuestionAnswering

eval_set_for_model = eval_set.remove_columns(["example_id", "offset_mapping"])
eval_set_for_model.set_format("numpy")

batch = {k: eval_set_for_model[k] for k in eval_set_for_model.column_names}
trained_model = TFAutoModelForQuestionAnswering.from_pretrained(trained_checkpoint)

outputs = trained_model(**batch)`,highlighted:`<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForQuestionAnswering

eval_set_for_model = eval_set.remove_columns([<span class="hljs-string">&quot;example_id&quot;</span>, <span class="hljs-string">&quot;offset_mapping&quot;</span>])
eval_set_for_model.set_format(<span class="hljs-string">&quot;numpy&quot;</span>)

batch = {k: eval_set_for_model[k] <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> eval_set_for_model.column_names}
trained_model = TFAutoModelForQuestionAnswering.from_pretrained(trained_checkpoint)

outputs = trained_model(**batch)`}}),g=new T({props:{code:`start_logits = outputs.start_logits.numpy()
end_logits = outputs.end_logits.numpy()`,highlighted:`start_logits = outputs.start_logits.numpy()
end_logits = outputs.end_logits.numpy()`}}),{c(){j(p.$$.fragment),b=d(),f=o("p"),C=n("Pour faciliter l\u2019exp\xE9rimentation, nous allons convertir ces sorties en tableaux NumPy :"),S=d(),j(g.$$.fragment)},l(q){k(p.$$.fragment,q),b=c(q),f=r(q,"P",{});var _=l(f);C=a(_,"Pour faciliter l\u2019exp\xE9rimentation, nous allons convertir ces sorties en tableaux NumPy :"),_.forEach(t),S=c(q),k(g.$$.fragment,q)},m(q,_){E(p,q,_),i(q,b,_),i(q,f,_),s(f,C),i(q,S,_),E(g,q,_),$=!0},i(q){$||(h(p.$$.fragment,q),h(g.$$.fragment,q),$=!0)},o(q){v(p.$$.fragment,q),v(g.$$.fragment,q),$=!1},d(q){y(p,q),q&&t(b),q&&t(f),q&&t(S),y(g,q)}}}function tg(H){let p,b,f,C,S,g,$,q,_,z;return p=new T({props:{code:`import torch
from transformers import AutoModelForQuestionAnswering

eval_set_for_model = eval_set.remove_columns(["example_id", "offset_mapping"])
eval_set_for_model.set_format("torch")

device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
batch = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}
trained_model = AutoModelForQuestionAnswering.from_pretrained(trained_checkpoint).to(
    device
)

with torch.no_grad():
    outputs = trained_model(**batch)`,highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForQuestionAnswering

eval_set_for_model = eval_set.remove_columns([<span class="hljs-string">&quot;example_id&quot;</span>, <span class="hljs-string">&quot;offset_mapping&quot;</span>])
eval_set_for_model.set_format(<span class="hljs-string">&quot;torch&quot;</span>)

device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)
batch = {k: eval_set_for_model[k].to(device) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> eval_set_for_model.column_names}
trained_model = AutoModelForQuestionAnswering.from_pretrained(trained_checkpoint).to(
    device
)

<span class="hljs-keyword">with</span> torch.no_grad():
    outputs = trained_model(**batch)`}}),_=new T({props:{code:`start_logits = outputs.start_logits.cpu().numpy()
end_logits = outputs.end_logits.cpu().numpy()`,highlighted:`start_logits = outputs.start_logits.cpu().numpy()
end_logits = outputs.end_logits.cpu().numpy()`}}),{c(){j(p.$$.fragment),b=d(),f=o("p"),C=n("Puisque le "),S=o("code"),g=n("Trainer"),$=n(" nous donnera les pr\xE9dictions sous forme de tableaux NumPy, nous r\xE9cup\xE9rons les logits de d\xE9but et de fin et les convertissons dans ce format :"),q=d(),j(_.$$.fragment)},l(x){k(p.$$.fragment,x),b=c(x),f=r(x,"P",{});var D=l(f);C=a(D,"Puisque le "),S=r(D,"CODE",{});var L=l(S);g=a(L,"Trainer"),L.forEach(t),$=a(D," nous donnera les pr\xE9dictions sous forme de tableaux NumPy, nous r\xE9cup\xE9rons les logits de d\xE9but et de fin et les convertissons dans ce format :"),D.forEach(t),q=c(x),k(_.$$.fragment,x)},m(x,D){E(p,x,D),i(x,b,D),i(x,f,D),s(f,C),s(f,S),s(S,g),s(f,$),i(x,q,D),E(_,x,D),z=!0},i(x){z||(h(p.$$.fragment,x),h(_.$$.fragment,x),z=!0)},o(x){v(p.$$.fragment,x),v(_.$$.fragment,x),z=!1},d(x){y(p,x),x&&t(b),x&&t(f),x&&t(q),y(_,x)}}}function ng(H){let p,b,f,C,S;return{c(){p=o("p"),b=n("Maintenant, mettons tout ce que nous venons de faire dans une fonction "),f=o("code"),C=n("compute_metrics()"),S=n(" que nous utiliserons apr\xE8s avoir entra\xEEn\xE9 notre mod\xE8le. Nous aurons besoin de passer un peu plus que juste les logits de sortie, car nous devons chercher dans le jeu de donn\xE9es des caract\xE9ristiques pour le d\xE9calage et dans le jeu de donn\xE9es des exemples pour les contextes originaux :")},l(g){p=r(g,"P",{});var $=l(p);b=a($,"Maintenant, mettons tout ce que nous venons de faire dans une fonction "),f=r($,"CODE",{});var q=l(f);C=a(q,"compute_metrics()"),q.forEach(t),S=a($," que nous utiliserons apr\xE8s avoir entra\xEEn\xE9 notre mod\xE8le. Nous aurons besoin de passer un peu plus que juste les logits de sortie, car nous devons chercher dans le jeu de donn\xE9es des caract\xE9ristiques pour le d\xE9calage et dans le jeu de donn\xE9es des exemples pour les contextes originaux :"),$.forEach(t)},m(g,$){i(g,p,$),s(p,b),s(p,f),s(f,C),s(p,S)},d(g){g&&t(p)}}}function ag(H){let p,b,f,C,S,g,$,q,_,z,x,D,L,N,P,w,U,V,F,M;return{c(){p=o("p"),b=n("Maintenant, mettons tout ce que nous venons de faire dans une fonction "),f=o("code"),C=n("compute_metrics()"),S=n(" que nous utiliserons dans le "),g=o("code"),$=n("Trainer"),q=n(". Normalement, cette fonction "),_=o("code"),z=n("compute_metrics()"),x=n(" re\xE7oit seulement un tuple "),D=o("code"),L=n("eval_preds"),N=n(" avec les logits et les labels. Ici, nous aurons besoin d\u2019un peu plus, car nous devons chercher dans le jeu de donn\xE9es des caract\xE9ristiques pour le d\xE9calage et dans le jeu de donn\xE9es des exemples pour les contextes originaux, donc nous ne serons pas en mesure d\u2019utiliser cette fonction pour obtenir des r\xE9sultats d\u2019\xE9valuation r\xE9guliers pendant l\u2019entra\xEEnement. Nous ne l\u2019utiliserons qu\u2019\xE0 la fin de l\u2019entra\xEEnement pour v\xE9rifier les r\xE9sultats."),P=d(),w=o("p"),U=n("La fonction "),V=o("code"),F=n("compute_metrics()"),M=n(" regroupe les m\xEAmes \xE9tapes que pr\xE9c\xE9demment ; nous ajoutons juste une petite v\xE9rification au cas o\xF9 nous ne trouverions aucune r\xE9ponse valide (dans ce cas nous pr\xE9disons une cha\xEEne vide).")},l(B){p=r(B,"P",{});var G=l(p);b=a(G,"Maintenant, mettons tout ce que nous venons de faire dans une fonction "),f=r(G,"CODE",{});var ee=l(f);C=a(ee,"compute_metrics()"),ee.forEach(t),S=a(G," que nous utiliserons dans le "),g=r(G,"CODE",{});var Q=l(g);$=a(Q,"Trainer"),Q.forEach(t),q=a(G,". Normalement, cette fonction "),_=r(G,"CODE",{});var W=l(_);z=a(W,"compute_metrics()"),W.forEach(t),x=a(G," re\xE7oit seulement un tuple "),D=r(G,"CODE",{});var K=l(D);L=a(K,"eval_preds"),K.forEach(t),N=a(G," avec les logits et les labels. Ici, nous aurons besoin d\u2019un peu plus, car nous devons chercher dans le jeu de donn\xE9es des caract\xE9ristiques pour le d\xE9calage et dans le jeu de donn\xE9es des exemples pour les contextes originaux, donc nous ne serons pas en mesure d\u2019utiliser cette fonction pour obtenir des r\xE9sultats d\u2019\xE9valuation r\xE9guliers pendant l\u2019entra\xEEnement. Nous ne l\u2019utiliserons qu\u2019\xE0 la fin de l\u2019entra\xEEnement pour v\xE9rifier les r\xE9sultats."),G.forEach(t),P=c(B),w=r(B,"P",{});var Y=l(w);U=a(Y,"La fonction "),V=r(Y,"CODE",{});var O=l(V);F=a(O,"compute_metrics()"),O.forEach(t),M=a(Y," regroupe les m\xEAmes \xE9tapes que pr\xE9c\xE9demment ; nous ajoutons juste une petite v\xE9rification au cas o\xF9 nous ne trouverions aucune r\xE9ponse valide (dans ce cas nous pr\xE9disons une cha\xEEne vide)."),Y.forEach(t)},m(B,G){i(B,p,G),s(p,b),s(p,f),s(f,C),s(p,S),s(p,g),s(g,$),s(p,q),s(p,_),s(_,z),s(p,x),s(p,D),s(D,L),s(p,N),i(B,P,G),i(B,w,G),s(w,U),s(w,V),s(V,F),s(w,M)},d(B){B&&t(p),B&&t(P),B&&t(w)}}}function og(H){let p,b,f,C,S,g,$,q;return $=new T({props:{code:"model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)",highlighted:"model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"}}),{c(){p=o("p"),b=n("Nous sommes maintenant pr\xEAts \xE0 entra\xEEner notre mod\xE8le. Cr\xE9ons-le d\u2019abord, en utilisant la classe "),f=o("code"),C=n("TFAutoModelForQuestionAnswering"),S=n(" comme pr\xE9c\xE9demment :"),g=d(),j($.$$.fragment)},l(_){p=r(_,"P",{});var z=l(p);b=a(z,"Nous sommes maintenant pr\xEAts \xE0 entra\xEEner notre mod\xE8le. Cr\xE9ons-le d\u2019abord, en utilisant la classe "),f=r(z,"CODE",{});var x=l(f);C=a(x,"TFAutoModelForQuestionAnswering"),x.forEach(t),S=a(z," comme pr\xE9c\xE9demment :"),z.forEach(t),g=c(_),k($.$$.fragment,_)},m(_,z){i(_,p,z),s(p,b),s(p,f),s(f,C),s(p,S),i(_,g,z),E($,_,z),q=!0},i(_){q||(h($.$$.fragment,_),q=!0)},o(_){v($.$$.fragment,_),q=!1},d(_){_&&t(p),_&&t(g),y($,_)}}}function rg(H){let p,b,f,C,S,g,$,q;return $=new T({props:{code:"model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)",highlighted:"model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"}}),{c(){p=o("p"),b=n("Nous sommes maintenant pr\xEAts \xE0 entra\xEEner notre mod\xE8le. Cr\xE9ons-le d\u2019abord, en utilisant la classe "),f=o("code"),C=n("AutoModelForQuestionAnswering"),S=n(" comme pr\xE9c\xE9demment :"),g=d(),j($.$$.fragment)},l(_){p=r(_,"P",{});var z=l(p);b=a(z,"Nous sommes maintenant pr\xEAts \xE0 entra\xEEner notre mod\xE8le. Cr\xE9ons-le d\u2019abord, en utilisant la classe "),f=r(z,"CODE",{});var x=l(f);C=a(x,"AutoModelForQuestionAnswering"),x.forEach(t),S=a(z," comme pr\xE9c\xE9demment :"),z.forEach(t),g=c(_),k($.$$.fragment,_)},m(_,z){i(_,p,z),s(p,b),s(p,f),s(f,C),s(p,S),i(_,g,z),E($,_,z),q=!0},i(_){q||(h($.$$.fragment,_),q=!0)},o(_){v($.$$.fragment,_),q=!1},d(_){_&&t(p),_&&t(g),y($,_)}}}function lg(H){let p,b,f,C,S,g,$,q,_,z,x,D,L,N,P,w,U,V,F,M,B,G,ee,Q,W,K,Y;return C=new T({props:{code:`from transformers import DefaultDataCollator

data_collator = DefaultDataCollator(return_tensors="tf")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DefaultDataCollator

data_collator = DefaultDataCollator(return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),_=new T({props:{code:`tf_train_dataset = train_dataset.to_tf_dataset(
    columns=[
        "input_ids",
        "start_positions",
        "end_positions",
        "attention_mask",
        "token_type_ids",
    ],
    collate_fn=data_collator,
    shuffle=True,
    batch_size=16,
)
tf_eval_dataset = validation_dataset.to_tf_dataset(
    columns=["input_ids", "attention_mask", "token_type_ids"],
    collate_fn=data_collator,
    shuffle=False,
    batch_size=16,
)`,highlighted:`tf_train_dataset = train_dataset.to_tf_dataset(
    columns=[
        <span class="hljs-string">&quot;input_ids&quot;</span>,
        <span class="hljs-string">&quot;start_positions&quot;</span>,
        <span class="hljs-string">&quot;end_positions&quot;</span>,
        <span class="hljs-string">&quot;attention_mask&quot;</span>,
        <span class="hljs-string">&quot;token_type_ids&quot;</span>,
    ],
    collate_fn=data_collator,
    shuffle=<span class="hljs-literal">True</span>,
    batch_size=<span class="hljs-number">16</span>,
)
tf_eval_dataset = validation_dataset.to_tf_dataset(
    columns=[<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
    collate_fn=data_collator,
    shuffle=<span class="hljs-literal">False</span>,
    batch_size=<span class="hljs-number">16</span>,
)`}}),N=new T({props:{code:`from transformers import create_optimizer
from transformers.keras_callbacks import PushToHubCallback
import tensorflow as tf

# Le nombre d'\xE9tapes d'entra\xEEnement est le nombre d'\xE9chantillons dans le jeu de donn\xE9es, divis\xE9 par la taille du batch, puis multipli\xE9 par le nombre total d'\xE9poques.
# par le nombre total d'\xE9poques. Notez que le jeu de donn\xE9es tf_train_dataset est ici un lot tf.data.Dataset,
# et non le jeu de donn\xE9es original Hugging Face Dataset, donc son len() est d\xE9j\xE0 num_samples // batch_size.
num_train_epochs = 3
num_train_steps = len(tf_train_dataset) * num_train_epochs
optimizer, schedule = create_optimizer(
    init_lr=2e-5,
    num_warmup_steps=0,
    num_train_steps=num_train_steps,
    weight_decay_rate=0.01,
)
model.compile(optimizer=optimizer)

# Entra\xEEner en mixed-precision float16
tf.keras.mixed_precision.set_global_policy("mixed_float16")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer
<span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-comment"># Le nombre d&#x27;\xE9tapes d&#x27;entra\xEEnement est le nombre d&#x27;\xE9chantillons dans le jeu de donn\xE9es, divis\xE9 par la taille du batch, puis multipli\xE9 par le nombre total d&#x27;\xE9poques.</span>
<span class="hljs-comment"># par le nombre total d&#x27;\xE9poques. Notez que le jeu de donn\xE9es tf_train_dataset est ici un lot tf.data.Dataset,</span>
<span class="hljs-comment"># et non le jeu de donn\xE9es original Hugging Face Dataset, donc son len() est d\xE9j\xE0 num_samples // batch_size.</span>
num_train_epochs = <span class="hljs-number">3</span>
num_train_steps = <span class="hljs-built_in">len</span>(tf_train_dataset) * num_train_epochs
optimizer, schedule = create_optimizer(
    init_lr=<span class="hljs-number">2e-5</span>,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_train_steps=num_train_steps,
    weight_decay_rate=<span class="hljs-number">0.01</span>,
)
model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)

<span class="hljs-comment"># Entra\xEEner en mixed-precision float16</span>
tf.keras.mixed_precision.set_global_policy(<span class="hljs-string">&quot;mixed_float16&quot;</span>)`}}),{c(){p=o("p"),b=n("Maintenant que c\u2019est fait, nous pouvons cr\xE9er nos ensembles de donn\xE9es TF. Nous pouvons utiliser le simple collateur de donn\xE9es par d\xE9faut cette fois-ci :"),f=d(),j(C.$$.fragment),S=d(),g=o("p"),$=n("Et maintenant nous cr\xE9ons les jeux de donn\xE9es comme d\u2019habitude."),q=d(),j(_.$$.fragment),z=d(),x=o("p"),D=n("Ensuite, nous configurons nos hyperparam\xE8tres d\u2019entra\xEEnement et compilons notre mod\xE8le :"),L=d(),j(N.$$.fragment),P=d(),w=o("p"),U=n("Enfin, nous sommes pr\xEAts \xE0 nous entra\xEEner avec "),V=o("code"),F=n("model.fit()"),M=n(". Nous utilisons un "),B=o("code"),G=n("PushToHubCallback"),ee=n(" pour t\xE9l\xE9charger le mod\xE8le sur le "),Q=o("em"),W=n("Hub"),K=n(" apr\xE8s chaque \xE9poque.")},l(O){p=r(O,"P",{});var X=l(p);b=a(X,"Maintenant que c\u2019est fait, nous pouvons cr\xE9er nos ensembles de donn\xE9es TF. Nous pouvons utiliser le simple collateur de donn\xE9es par d\xE9faut cette fois-ci :"),X.forEach(t),f=c(O),k(C.$$.fragment,O),S=c(O),g=r(O,"P",{});var $e=l(g);$=a($e,"Et maintenant nous cr\xE9ons les jeux de donn\xE9es comme d\u2019habitude."),$e.forEach(t),q=c(O),k(_.$$.fragment,O),z=c(O),x=r(O,"P",{});var de=l(x);D=a(de,"Ensuite, nous configurons nos hyperparam\xE8tres d\u2019entra\xEEnement et compilons notre mod\xE8le :"),de.forEach(t),L=c(O),k(N.$$.fragment,O),P=c(O),w=r(O,"P",{});var J=l(w);U=a(J,"Enfin, nous sommes pr\xEAts \xE0 nous entra\xEEner avec "),V=r(J,"CODE",{});var se=l(V);F=a(se,"model.fit()"),se.forEach(t),M=a(J,". Nous utilisons un "),B=r(J,"CODE",{});var we=l(B);G=a(we,"PushToHubCallback"),we.forEach(t),ee=a(J," pour t\xE9l\xE9charger le mod\xE8le sur le "),Q=r(J,"EM",{});var ve=l(Q);W=a(ve,"Hub"),ve.forEach(t),K=a(J," apr\xE8s chaque \xE9poque."),J.forEach(t)},m(O,X){i(O,p,X),s(p,b),i(O,f,X),E(C,O,X),i(O,S,X),i(O,g,X),s(g,$),i(O,q,X),E(_,O,X),i(O,z,X),i(O,x,X),s(x,D),i(O,L,X),E(N,O,X),i(O,P,X),i(O,w,X),s(w,U),s(w,V),s(V,F),s(w,M),s(w,B),s(B,G),s(w,ee),s(w,Q),s(Q,W),s(w,K),Y=!0},i(O){Y||(h(C.$$.fragment,O),h(_.$$.fragment,O),h(N.$$.fragment,O),Y=!0)},o(O){v(C.$$.fragment,O),v(_.$$.fragment,O),v(N.$$.fragment,O),Y=!1},d(O){O&&t(p),O&&t(f),y(C,O),O&&t(S),O&&t(g),O&&t(q),y(_,O),O&&t(z),O&&t(x),O&&t(L),y(N,O),O&&t(P),O&&t(w)}}}function ig(H){let p,b,f,C,S,g,$,q,_,z,x,D,L,N,P,w,U,V,F,M,B,G,ee,Q,W,K,Y,O,X,$e,de,J,se,we,ve,re,ms,Xe;return de=new T({props:{code:`from transformers import TrainingArguments

args = TrainingArguments(
    "bert-finetuned-squad",
    evaluation_strategy="no",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
    fp16=True,
    push_to_hub=True,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

args = TrainingArguments(
    <span class="hljs-string">&quot;bert-finetuned-squad&quot;</span>,
    evaluation_strategy=<span class="hljs-string">&quot;no&quot;</span>,
    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    num_train_epochs=<span class="hljs-number">3</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
    fp16=<span class="hljs-literal">True</span>,
    push_to_hub=<span class="hljs-literal">True</span>,
)`}}),{c(){p=o("p"),b=n("Une fois ceci fait, nous pouvons d\xE9finir nos "),f=o("code"),C=n("TrainingArguments"),S=n(". Comme nous l\u2019avons dit lorsque nous avons d\xE9fini notre fonction pour calculer la m\xE9trique, nous ne serons pas en mesure d\u2019avoir une boucle d\u2019\xE9valuation r\xE9guli\xE8re \xE0 cause de la signature de la fonction "),g=o("code"),$=n("compute_metrics()"),q=n(". Nous pourrions \xE9crire notre propre sous-classe de "),_=o("code"),z=n("Trainer"),x=n(" pour faire cela (une approche que vous pouvez trouver dans le "),D=o("a"),L=n("script d\u2019exemple de r\xE9ponse aux questions"),N=n("), mais c\u2019est un peu trop long pour cette section. A la place, nous n\u2019\xE9valuerons le mod\xE8le qu\u2019\xE0 la fin de l\u2019entra\xEEnement et nous vous montrerons comment faire une \xE9valuation r\xE9guli\xE8re dans \u201CUne boucle d\u2019entra\xEEnement personnalis\xE9e\u201D ci-dessous."),P=d(),w=o("p"),U=n("C\u2019est vraiment l\xE0 que l\u2019API "),V=o("code"),F=n("Trainer"),M=n(" montre ses limites et que la biblioth\xE8que \u{1F917} "),B=o("em"),G=n("Accelerate"),ee=n(" brille : personnaliser la classe pour un cas d\u2019utilisation sp\xE9cifique peut \xEAtre p\xE9nible, mais modifier une boucle d\u2019entra\xEEnement enti\xE8rement expos\xE9e est facile."),Q=d(),W=o("p"),K=n("Jetons un coup d\u2019\u0153il  \xE0 notre "),Y=o("code"),O=n("TrainingArguments"),X=n(" :"),$e=d(),j(de.$$.fragment),J=d(),se=o("p"),we=n("Nous avons d\xE9j\xE0 vu la plupart d\u2019entre eux : nous d\xE9finissons quelques hyperparam\xE8tres (comme le taux d\u2019apprentissage, le nombre d\u2019\xE9poques pour lesquelles nous nous entra\xEEnons, et une certaine d\xE9croissance de poids) et nous indiquons que nous voulons sauvegarder le mod\xE8le \xE0 la fin de chaque \xE9poque, sauter l\u2019\xE9valuation, et t\xE9l\xE9charger nos r\xE9sultats vers le Model Hub. Nous activons \xE9galement l\u2019entra\xEEnement en pr\xE9cision mixte avec "),ve=o("code"),re=n("fp16=True"),ms=n(", car cela peut acc\xE9l\xE9rer l\u2019entra\xEEnement sur un GPU r\xE9cent."),this.h()},l(R){p=r(R,"P",{});var Z=l(p);b=a(Z,"Une fois ceci fait, nous pouvons d\xE9finir nos "),f=r(Z,"CODE",{});var fs=l(f);C=a(fs,"TrainingArguments"),fs.forEach(t),S=a(Z,". Comme nous l\u2019avons dit lorsque nous avons d\xE9fini notre fonction pour calculer la m\xE9trique, nous ne serons pas en mesure d\u2019avoir une boucle d\u2019\xE9valuation r\xE9guli\xE8re \xE0 cause de la signature de la fonction "),g=r(Z,"CODE",{});var jt=l(g);$=a(jt,"compute_metrics()"),jt.forEach(t),q=a(Z,". Nous pourrions \xE9crire notre propre sous-classe de "),_=r(Z,"CODE",{});var _s=l(_);z=a(_s,"Trainer"),_s.forEach(t),x=a(Z," pour faire cela (une approche que vous pouvez trouver dans le "),D=r(Z,"A",{href:!0,rel:!0});var Ae=l(D);L=a(Ae,"script d\u2019exemple de r\xE9ponse aux questions"),Ae.forEach(t),N=a(Z,"), mais c\u2019est un peu trop long pour cette section. A la place, nous n\u2019\xE9valuerons le mod\xE8le qu\u2019\xE0 la fin de l\u2019entra\xEEnement et nous vous montrerons comment faire une \xE9valuation r\xE9guli\xE8re dans \u201CUne boucle d\u2019entra\xEEnement personnalis\xE9e\u201D ci-dessous."),Z.forEach(t),P=c(R),w=r(R,"P",{});var Se=l(w);U=a(Se,"C\u2019est vraiment l\xE0 que l\u2019API "),V=r(Se,"CODE",{});var hs=l(V);F=a(hs,"Trainer"),hs.forEach(t),M=a(Se," montre ses limites et que la biblioth\xE8que \u{1F917} "),B=r(Se,"EM",{});var ce=l(B);G=a(ce,"Accelerate"),ce.forEach(t),ee=a(Se," brille : personnaliser la classe pour un cas d\u2019utilisation sp\xE9cifique peut \xEAtre p\xE9nible, mais modifier une boucle d\u2019entra\xEEnement enti\xE8rement expos\xE9e est facile."),Se.forEach(t),Q=c(R),W=r(R,"P",{});var De=l(W);K=a(De,"Jetons un coup d\u2019\u0153il  \xE0 notre "),Y=r(De,"CODE",{});var me=l(Y);O=a(me,"TrainingArguments"),me.forEach(t),X=a(De," :"),De.forEach(t),$e=c(R),k(de.$$.fragment,R),J=c(R),se=r(R,"P",{});var be=l(se);we=a(be,"Nous avons d\xE9j\xE0 vu la plupart d\u2019entre eux : nous d\xE9finissons quelques hyperparam\xE8tres (comme le taux d\u2019apprentissage, le nombre d\u2019\xE9poques pour lesquelles nous nous entra\xEEnons, et une certaine d\xE9croissance de poids) et nous indiquons que nous voulons sauvegarder le mod\xE8le \xE0 la fin de chaque \xE9poque, sauter l\u2019\xE9valuation, et t\xE9l\xE9charger nos r\xE9sultats vers le Model Hub. Nous activons \xE9galement l\u2019entra\xEEnement en pr\xE9cision mixte avec "),ve=r(be,"CODE",{});var Ke=l(ve);re=a(Ke,"fp16=True"),Ke.forEach(t),ms=a(be,", car cela peut acc\xE9l\xE9rer l\u2019entra\xEEnement sur un GPU r\xE9cent."),be.forEach(t),this.h()},h(){A(D,"href","https://github.com/huggingface/transformers/blob/master/examples/pytorch/question-answering/trainer_qa.py"),A(D,"rel","nofollow")},m(R,Z){i(R,p,Z),s(p,b),s(p,f),s(f,C),s(p,S),s(p,g),s(g,$),s(p,q),s(p,_),s(_,z),s(p,x),s(p,D),s(D,L),s(p,N),i(R,P,Z),i(R,w,Z),s(w,U),s(w,V),s(V,F),s(w,M),s(w,B),s(B,G),s(w,ee),i(R,Q,Z),i(R,W,Z),s(W,K),s(W,Y),s(Y,O),s(W,X),i(R,$e,Z),E(de,R,Z),i(R,J,Z),i(R,se,Z),s(se,we),s(se,ve),s(ve,re),s(se,ms),Xe=!0},i(R){Xe||(h(de.$$.fragment,R),Xe=!0)},o(R){v(de.$$.fragment,R),Xe=!1},d(R){R&&t(p),R&&t(P),R&&t(w),R&&t(Q),R&&t(W),R&&t($e),y(de,R),R&&t(J),R&&t(se)}}}function ug(H){let p,b;return p=new T({props:{code:`from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(output_dir="bert-finetuned-squad", tokenizer=tokenizer)

# Nous allons faire la validation apr\xE8s, donc pas de validation au milieu de l'entra\xEEnement.
model.fit(tf_train_dataset, callbacks=[callback], epochs=num_train_epochs)`,highlighted:`<span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback

callback = PushToHubCallback(output_dir=<span class="hljs-string">&quot;bert-finetuned-squad&quot;</span>, tokenizer=tokenizer)

<span class="hljs-comment"># Nous allons faire la validation apr\xE8s, donc pas de validation au milieu de l&#x27;entra\xEEnement.</span>
model.fit(tf_train_dataset, callbacks=[callback], epochs=num_train_epochs)`}}),{c(){j(p.$$.fragment)},l(f){k(p.$$.fragment,f)},m(f,C){E(p,f,C),b=!0},i(f){b||(h(p.$$.fragment,f),b=!0)},o(f){v(p.$$.fragment,f),b=!1},d(f){y(p,f)}}}function pg(H){let p,b,f,C,S,g,$,q,_,z;return p=new Rd({props:{$$slots:{default:[dg]},$$scope:{ctx:H}}}),_=new T({props:{code:`from transformers import Trainer

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=train_dataset,
    eval_dataset=validation_dataset,
    tokenizer=tokenizer,
)
trainer.train()`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=train_dataset,
    eval_dataset=validation_dataset,
    tokenizer=tokenizer,
)
trainer.train()`}}),{c(){j(p.$$.fragment),b=d(),f=o("p"),C=n("Enfin, nous passons tout \xE0 la classe "),S=o("code"),g=n("Trainer"),$=n(" et lan\xE7ons l\u2019entra\xEEnement :"),q=d(),j(_.$$.fragment)},l(x){k(p.$$.fragment,x),b=c(x),f=r(x,"P",{});var D=l(f);C=a(D,"Enfin, nous passons tout \xE0 la classe "),S=r(D,"CODE",{});var L=l(S);g=a(L,"Trainer"),L.forEach(t),$=a(D," et lan\xE7ons l\u2019entra\xEEnement :"),D.forEach(t),q=c(x),k(_.$$.fragment,x)},m(x,D){E(p,x,D),i(x,b,D),i(x,f,D),s(f,C),s(f,S),s(S,g),s(f,$),i(x,q,D),E(_,x,D),z=!0},i(x){z||(h(p.$$.fragment,x),h(_.$$.fragment,x),z=!0)},o(x){v(p.$$.fragment,x),v(_.$$.fragment,x),z=!1},d(x){y(p,x),x&&t(b),x&&t(f),x&&t(q),y(_,x)}}}function dg(H){let p,b,f,C,S;return{c(){p=o("p"),b=n("\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser (donc d\xE9finissez un nouveau nom si vous obtenez une erreur lors de la d\xE9finition de votre "),f=o("code"),C=n("Trainer"),S=n(").")},l(g){p=r(g,"P",{});var $=l(p);b=a($,"\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser (donc d\xE9finissez un nouveau nom si vous obtenez une erreur lors de la d\xE9finition de votre "),f=r($,"CODE",{});var q=l(f);C=a(q,"Trainer"),q.forEach(t),S=a($,")."),$.forEach(t)},m(g,$){i(g,p,$),s(p,b),s(p,f),s(f,C),s(p,S)},d(g){g&&t(p)}}}function cg(H){let p,b,f,C,S,g,$,q,_,z,x,D,L,N;return L=new T({props:{code:`predictions = model.predict(tf_eval_dataset)
compute_metrics(
    predictions["start_logits"],
    predictions["end_logits"],
    validation_dataset,
    raw_datasets["validation"],
)`,highlighted:`predictions = model.predict(tf_eval_dataset)
compute_metrics(
    predictions[<span class="hljs-string">&quot;start_logits&quot;</span>],
    predictions[<span class="hljs-string">&quot;end_logits&quot;</span>],
    validation_dataset,
    raw_datasets[<span class="hljs-string">&quot;validation&quot;</span>],
)`}}),{c(){p=o("p"),b=n("Une fois l\u2019entra\xEEnement termin\xE9, nous pouvons enfin \xE9valuer notre mod\xE8le (et prier pour ne pas avoir d\xE9pens\xE9 tout ce temps de calcul pour rien). La m\xE9thode "),f=o("code"),C=n("predict()"),S=n(" de notre "),g=o("code"),$=n("model"),q=n(" se chargera d\u2019obtenir les pr\xE9dictions, et puisque nous avons fait tout le travail difficile de d\xE9finir une fonction "),_=o("code"),z=n("compute_metrics()"),x=n(" plus t\xF4t, nous pouvons obtenir nos r\xE9sultats en une seule ligne :"),D=d(),j(L.$$.fragment)},l(P){p=r(P,"P",{});var w=l(p);b=a(w,"Une fois l\u2019entra\xEEnement termin\xE9, nous pouvons enfin \xE9valuer notre mod\xE8le (et prier pour ne pas avoir d\xE9pens\xE9 tout ce temps de calcul pour rien). La m\xE9thode "),f=r(w,"CODE",{});var U=l(f);C=a(U,"predict()"),U.forEach(t),S=a(w," de notre "),g=r(w,"CODE",{});var V=l(g);$=a(V,"model"),V.forEach(t),q=a(w," se chargera d\u2019obtenir les pr\xE9dictions, et puisque nous avons fait tout le travail difficile de d\xE9finir une fonction "),_=r(w,"CODE",{});var F=l(_);z=a(F,"compute_metrics()"),F.forEach(t),x=a(w," plus t\xF4t, nous pouvons obtenir nos r\xE9sultats en une seule ligne :"),w.forEach(t),D=c(P),k(L.$$.fragment,P)},m(P,w){i(P,p,w),s(p,b),s(p,f),s(f,C),s(p,S),s(p,g),s(g,$),s(p,q),s(p,_),s(_,z),s(p,x),i(P,D,w),E(L,P,w),N=!0},i(P){N||(h(L.$$.fragment,P),N=!0)},o(P){v(L.$$.fragment,P),N=!1},d(P){P&&t(p),P&&t(D),y(L,P)}}}function mg(H){let p,b,f,C,S,g,$,q,_,z,x,D,L,N;return L=new T({props:{code:`predictions, _ = trainer.predict(validation_dataset)
start_logits, end_logits = predictions
compute_metrics(start_logits, end_logits, validation_dataset, raw_datasets["validation"])`,highlighted:`predictions, _ = trainer.predict(validation_dataset)
start_logits, end_logits = predictions
compute_metrics(start_logits, end_logits, validation_dataset, raw_datasets[<span class="hljs-string">&quot;validation&quot;</span>])`}}),{c(){p=o("p"),b=n("Une fois l\u2019entra\xEEnement termin\xE9, nous pouvons enfin \xE9valuer notre mod\xE8le (et prier pour ne pas avoir d\xE9pens\xE9 tout ce temps de calcul pour rien). La m\xE9thode "),f=o("code"),C=n("predict()"),S=n(" du "),g=o("code"),$=n("Trainer"),q=n(" retournera un tuple o\xF9 les premiers \xE9l\xE9ments seront les pr\xE9dictions du mod\xE8le (ici une paire avec les logits de d\xE9but et de fin). Nous envoyons ceci \xE0 notre fonction "),_=o("code"),z=n("compute_metrics()"),x=n(" :"),D=d(),j(L.$$.fragment)},l(P){p=r(P,"P",{});var w=l(p);b=a(w,"Une fois l\u2019entra\xEEnement termin\xE9, nous pouvons enfin \xE9valuer notre mod\xE8le (et prier pour ne pas avoir d\xE9pens\xE9 tout ce temps de calcul pour rien). La m\xE9thode "),f=r(w,"CODE",{});var U=l(f);C=a(U,"predict()"),U.forEach(t),S=a(w," du "),g=r(w,"CODE",{});var V=l(g);$=a(V,"Trainer"),V.forEach(t),q=a(w," retournera un tuple o\xF9 les premiers \xE9l\xE9ments seront les pr\xE9dictions du mod\xE8le (ici une paire avec les logits de d\xE9but et de fin). Nous envoyons ceci \xE0 notre fonction "),_=r(w,"CODE",{});var F=l(_);z=a(F,"compute_metrics()"),F.forEach(t),x=a(w," :"),w.forEach(t),D=c(P),k(L.$$.fragment,P)},m(P,w){i(P,p,w),s(p,b),s(p,f),s(f,C),s(p,S),s(p,g),s(g,$),s(p,q),s(p,_),s(_,z),s(p,x),i(P,D,w),E(L,P,w),N=!0},i(P){N||(h(L.$$.fragment,P),N=!0)},o(P){v(L.$$.fragment,P),N=!1},d(P){P&&t(p),P&&t(D),y(L,P)}}}function Ob(H){let p,b,f,C,S,g,$,q,_,z,x,D,L,N,P,w,U,V,F;return $=new T({props:{code:'trainer.push_to_hub(commit_message="Training complete")',highlighted:'trainer.push_to_hub(commit_message=<span class="hljs-string">&quot;Training complete&quot;</span>)'}}),D=new T({props:{code:"'https://huggingface.co/sgugger/bert-finetuned-squad/commit/9dcee1fbc25946a6ed4bb32efb1bd71d5fa90b68'",highlighted:'<span class="hljs-string">&#x27;https://huggingface.co/sgugger/bert-finetuned-squad/commit/9dcee1fbc25946a6ed4bb32efb1bd71d5fa90b68&#x27;</span>'}}),{c(){p=o("p"),b=n("Enfin, nous utilisons la m\xE9thode "),f=o("code"),C=n("push_to_hub()"),S=n(" pour nous assurer que nous t\xE9l\xE9chargeons la derni\xE8re version du mod\xE8le :"),g=d(),j($.$$.fragment),q=d(),_=o("p"),z=n("Cela renvoie l\u2019URL du commit qu\u2019il vient de faire, si vous voulez l\u2019inspecter :"),x=d(),j(D.$$.fragment),L=d(),N=o("p"),P=n("Le "),w=o("code"),U=n("Trainer"),V=n(" r\xE9dige \xE9galement une fiche mod\xE8le avec tous les r\xE9sultats de l\u2019\xE9valuation et la t\xE9l\xE9charge.")},l(M){p=r(M,"P",{});var B=l(p);b=a(B,"Enfin, nous utilisons la m\xE9thode "),f=r(B,"CODE",{});var G=l(f);C=a(G,"push_to_hub()"),G.forEach(t),S=a(B," pour nous assurer que nous t\xE9l\xE9chargeons la derni\xE8re version du mod\xE8le :"),B.forEach(t),g=c(M),k($.$$.fragment,M),q=c(M),_=r(M,"P",{});var ee=l(_);z=a(ee,"Cela renvoie l\u2019URL du commit qu\u2019il vient de faire, si vous voulez l\u2019inspecter :"),ee.forEach(t),x=c(M),k(D.$$.fragment,M),L=c(M),N=r(M,"P",{});var Q=l(N);P=a(Q,"Le "),w=r(Q,"CODE",{});var W=l(w);U=a(W,"Trainer"),W.forEach(t),V=a(Q," r\xE9dige \xE9galement une fiche mod\xE8le avec tous les r\xE9sultats de l\u2019\xE9valuation et la t\xE9l\xE9charge."),Q.forEach(t)},m(M,B){i(M,p,B),s(p,b),s(p,f),s(f,C),s(p,S),i(M,g,B),E($,M,B),i(M,q,B),i(M,_,B),s(_,z),i(M,x,B),E(D,M,B),i(M,L,B),i(M,N,B),s(N,P),s(N,w),s(w,U),s(N,V),F=!0},i(M){F||(h($.$$.fragment,M),h(D.$$.fragment,M),F=!0)},o(M){v($.$$.fragment,M),v(D.$$.fragment,M),F=!1},d(M){M&&t(p),M&&t(g),y($,M),M&&t(q),M&&t(_),M&&t(x),y(D,M),M&&t(L),M&&t(N)}}}function fg(H){let p,b,f,C,S;return{c(){p=o("p"),b=n("\u270F\uFE0F "),f=o("strong"),C=n("Votre tour"),S=n(" Essayez un autre mod\xE8le d\u2019architecture pour voir s\u2019il est plus performant dans cette t\xE2che !")},l(g){p=r(g,"P",{});var $=l(p);b=a($,"\u270F\uFE0F "),f=r($,"STRONG",{});var q=l(f);C=a(q,"Votre tour"),q.forEach(t),S=a($," Essayez un autre mod\xE8le d\u2019architecture pour voir s\u2019il est plus performant dans cette t\xE2che !"),$.forEach(t)},m(g,$){i(g,p,$),s(p,b),s(p,f),s(f,C),s(p,S)},d(g){g&&t(p)}}}function Ib(H){let p,b,f,C,S,g,$,q,_,z,x,D,L,N,P,w,U,V,F,M,B,G,ee,Q,W,K,Y,O,X,$e,de,J,se,we,ve,re,ms,Xe,R,Z,fs,jt,_s,Ae,Se,hs,ce,De,me,be,Ke,je,Gn,Me,ao,kt,ze,oo,vs,Vs,Wn,te,ro,dn,Jn,Ye,Te,cn,Hs,mn,fn,lo,Et,bs,io,Rs,uo,po,yt,Us,Xn,gs,co,Kn,qs,xs,$s,ke,ge,_n,hn,mo,vn,bn,fo,Yn,Ze,Zn,qe,ea,es,sa,Qs,Ct,ae,_o,Gs,ho,vo,Pt,Ws,ta,ss,na,At,gn,aa,Js,St,Le,bo,Xs,go,qo,Dt,ws,xo,Mt,ts,js,zt,Ee,oa,ns,ra,Ks,Tt,la,ks,ye,Ce,ia,Ne,$o,qn,wo,Pe,ua,as,pa,Ys,Lt,Nt,jo,Ot,os,Es,xn,le,ko,Zs,Eo,da,rs,ca,ys,$n,wn,yo,jn,ma,Cs,fa,Ps,Co,_a,As,Ss,ls,oe,kn,En,Po,ha,is,va,ne,et,yn,Ao,Cn,Pn,So,An,Sn,Do,Dn,Mn,Mo,ba,us,ga,st,It,Oe,zo,tt,To,Lo,Bt,Ie,No,Ft,nt,qa,Be,zn,xa,at,Tn;return z=new cs({}),Y=new cs({}),ce=new T({props:{code:`from torch.utils.data import DataLoader
from transformers import default_data_collator

train_dataset.set_format("torch")
validation_set = validation_dataset.remove_columns(["example_id", "offset_mapping"])
validation_set.set_format("torch")

train_dataloader = DataLoader(
    train_dataset,
    shuffle=True,
    collate_fn=default_data_collator,
    batch_size=8,
)
eval_dataloader = DataLoader(
    validation_set, collate_fn=default_data_collator, batch_size=8
)`,highlighted:`<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> default_data_collator

train_dataset.set_format(<span class="hljs-string">&quot;torch&quot;</span>)
validation_set = validation_dataset.remove_columns([<span class="hljs-string">&quot;example_id&quot;</span>, <span class="hljs-string">&quot;offset_mapping&quot;</span>])
validation_set.set_format(<span class="hljs-string">&quot;torch&quot;</span>)

train_dataloader = DataLoader(
    train_dataset,
    shuffle=<span class="hljs-literal">True</span>,
    collate_fn=default_data_collator,
    batch_size=<span class="hljs-number">8</span>,
)
eval_dataloader = DataLoader(
    validation_set, collate_fn=default_data_collator, batch_size=<span class="hljs-number">8</span>
)`}}),je=new T({props:{code:"model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)",highlighted:"model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"}}),Vs=new T({props:{code:`from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)`,highlighted:`<span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW

optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">2e-5</span>)`}}),xs=new T({props:{code:`from accelerate import Accelerator

accelerator = Accelerator(fp16=True)
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)`,highlighted:`<span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator

accelerator = Accelerator(fp16=<span class="hljs-literal">True</span>)
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)`}}),Ze=new T({props:{code:`from transformers import get_scheduler

num_train_epochs = 3
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler

num_train_epochs = <span class="hljs-number">3</span>
num_update_steps_per_epoch = <span class="hljs-built_in">len</span>(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    <span class="hljs-string">&quot;linear&quot;</span>,
    optimizer=optimizer,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_training_steps=num_training_steps,
)`}}),Ws=new T({props:{code:`from huggingface_hub import Repository, get_full_repo_name

model_name = "bert-finetuned-squad-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> Repository, get_full_repo_name

model_name = <span class="hljs-string">&quot;bert-finetuned-squad-accelerate&quot;</span>
repo_name = get_full_repo_name(model_name)
repo_name`}}),ss=new T({props:{code:"'sgugger/bert-finetuned-squad-accelerate'",highlighted:'<span class="hljs-string">&#x27;sgugger/bert-finetuned-squad-accelerate&#x27;</span>'}}),Js=new T({props:{code:`output_dir = "bert-finetuned-squad-accelerate"
repo = Repository(output_dir, clone_from=repo_name)`,highlighted:`output_dir = <span class="hljs-string">&quot;bert-finetuned-squad-accelerate&quot;</span>
repo = Repository(output_dir, clone_from=repo_name)`}}),Ee=new cs({}),As=new T({props:{code:`from tqdm.auto import tqdm
import torch

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
    # Entra\xEEnement
    model.train()
    for step, batch in enumerate(train_dataloader):
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # Evaluation
    model.eval()
    start_logits = []
    end_logits = []
    accelerator.print("Evaluation!")
    for batch in tqdm(eval_dataloader):
        with torch.no_grad():
            outputs = model(**batch)

        start_logits.append(accelerator.gather(outputs.start_logits).cpu().numpy())
        end_logits.append(accelerator.gather(outputs.end_logits).cpu().numpy())

    start_logits = np.concatenate(start_logits)
    end_logits = np.concatenate(end_logits)
    start_logits = start_logits[: len(validation_dataset)]
    end_logits = end_logits[: len(validation_dataset)]

    metrics = compute_metrics(
        start_logits, end_logits, validation_dataset, raw_datasets["validation"]
    )
    print(f"epoch {epoch}:", metrics)

    # Sauvegarder et t\xE9l\xE9charger
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=f"Training in progress epoch {epoch}", blocking=False
        )`,highlighted:`<span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm
<span class="hljs-keyword">import</span> torch

progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_train_epochs):
    <span class="hljs-comment"># Entra\xEEnement</span>
    model.train()
    <span class="hljs-keyword">for</span> step, batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_dataloader):
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(<span class="hljs-number">1</span>)

    <span class="hljs-comment"># Evaluation</span>
    model.<span class="hljs-built_in">eval</span>()
    start_logits = []
    end_logits = []
    accelerator.<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Evaluation!&quot;</span>)
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> tqdm(eval_dataloader):
        <span class="hljs-keyword">with</span> torch.no_grad():
            outputs = model(**batch)

        start_logits.append(accelerator.gather(outputs.start_logits).cpu().numpy())
        end_logits.append(accelerator.gather(outputs.end_logits).cpu().numpy())

    start_logits = np.concatenate(start_logits)
    end_logits = np.concatenate(end_logits)
    start_logits = start_logits[: <span class="hljs-built_in">len</span>(validation_dataset)]
    end_logits = end_logits[: <span class="hljs-built_in">len</span>(validation_dataset)]

    metrics = compute_metrics(
        start_logits, end_logits, validation_dataset, raw_datasets[<span class="hljs-string">&quot;validation&quot;</span>]
    )
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;epoch <span class="hljs-subst">{epoch}</span>:&quot;</span>, metrics)

    <span class="hljs-comment"># Sauvegarder et t\xE9l\xE9charger</span>
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    <span class="hljs-keyword">if</span> accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=<span class="hljs-string">f&quot;Training in progress epoch <span class="hljs-subst">{epoch}</span>&quot;</span>, blocking=<span class="hljs-literal">False</span>
        )`}}),is=new T({props:{code:`accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)`,highlighted:`accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)`}}),{c(){p=o("p"),b=n("Si vous voulez plonger un peu plus profond\xE9ment dans la boucle d\u2019entra\xEEnement, nous allons maintenant vous montrer comment faire la m\xEAme chose en utilisant \u{1F917} "),f=o("em"),C=n("Accelerate"),S=n("."),g=d(),$=o("h2"),q=o("a"),_=o("span"),j(z.$$.fragment),x=d(),D=o("span"),L=n("Une boucle d'entra\xEEnement personnalis\xE9e"),N=d(),P=o("p"),w=n("Jetons maintenant un coup d\u2019\u0153il \xE0 la boucle d\u2019entra\xEEnement compl\xE8te, afin que vous puissiez facilement personnaliser les parties dont vous avez besoin. Elle ressemblera beaucoup \xE0 la boucle d\u2019entra\xEEnement du "),U=o("a"),V=n("Chapitre 3"),F=n(", \xE0 l\u2019exception de la boucle d\u2019\xE9valuation. Nous serons en mesure d\u2019\xE9valuer le mod\xE8le r\xE9guli\xE8rement puisque nous ne sommes plus contraints par la classe "),M=o("code"),B=n("Trainer"),G=n("."),ee=d(),Q=o("h3"),W=o("a"),K=o("span"),j(Y.$$.fragment),O=d(),X=o("span"),$e=n("Pr\xE9parer tout pour l'entra\xEEnement"),de=d(),J=o("p"),se=n("Tout d\u2019abord, nous devons construire le "),we=o("code"),ve=n("DataLoader"),re=n("s \xE0 partir de nos jeux de donn\xE9es. Nous d\xE9finissons le format de ces jeux de donn\xE9es \xE0 "),ms=o("code"),Xe=n('"torch"'),R=n(", et supprimons les colonnes dans le jeu de validation qui ne sont pas utilis\xE9es par le mod\xE8le. Ensuite, nous pouvons utiliser le "),Z=o("code"),fs=n("default_data_collator"),jt=n(" fourni par Transformers comme "),_s=o("code"),Ae=n("collate_fn"),Se=n(" et m\xE9langer l\u2019ensemble d\u2019entra\xEEnement, mais pas l\u2019ensemble de validation :"),hs=d(),j(ce.$$.fragment),De=d(),me=o("p"),be=n("Ensuite, nous r\xE9instantifions notre mod\xE8le, afin de nous assurer que nous ne poursuivons pas les r\xE9glages fins pr\xE9c\xE9dents mais que nous repartons du mod\xE8le pr\xE9-entra\xEEn\xE9 de BERT :"),Ke=d(),j(je.$$.fragment),Gn=d(),Me=o("p"),ao=n("Ensuite, nous aurons besoin d\u2019un optimiseur. Comme d\u2019habitude, nous utilisons le classique "),kt=o("code"),ze=n("AdamW"),oo=n(", qui est comme Adam, mais avec une correction dans la fa\xE7on dont la d\xE9croissance du poids est appliqu\xE9e :"),vs=d(),j(Vs.$$.fragment),Wn=d(),te=o("p"),ro=n("Une fois que nous avons tous ces objets, nous pouvons les envoyer \xE0 la m\xE9thode "),dn=o("code"),Jn=n("accelerator.prepare()"),Ye=n(". Rappelez-vous que si vous voulez vous entra\xEEner sur des TPUs dans un "),Te=o("em"),cn=n("notebook"),Hs=n(" de Colab, vous devrez d\xE9placer tout ce code dans une fonction d\u2019entra\xEEnement, et qui ne devrait pas ex\xE9cuter une cellule qui instancie un "),mn=o("code"),fn=n("Accelerator"),lo=n(". Nous pouvons forcer l\u2019entra\xEEnement en pr\xE9cision mixte en passant "),Et=o("code"),bs=n("fp16=True"),io=n(" \xE0 l\u2019"),Rs=o("code"),uo=n("Accelerator"),po=n(" (ou, si vous ex\xE9cutez le code comme un script, assurez-vous de remplir la \u{1F917} "),yt=o("em"),Us=n("Accelerate"),Xn=d(),gs=o("code"),co=n("config"),Kn=n(" de mani\xE8re appropri\xE9e)."),qs=d(),j(xs.$$.fragment),$s=d(),ke=o("p"),ge=n("Comme vous devez le savoir depuis les sections pr\xE9c\xE9dentes, nous ne pouvons utiliser la longueur de "),_n=o("code"),hn=n("train_dataloader"),mo=n(" pour calculer le nombre d\u2019\xE9tapes d\u2019entra\xEEnement qu\u2019apr\xE8s qu\u2019il soit pass\xE9 par la m\xE9thode "),vn=o("code"),bn=n("accelerator.prepare()"),fo=n(". Nous utilisons le m\xEAme programme lin\xE9aire que dans les sections pr\xE9c\xE9dentes :"),Yn=d(),j(Ze.$$.fragment),Zn=d(),qe=o("p"),ea=n("Pour pousser notre mod\xE8le vers le Hub, nous aurons besoin de cr\xE9er un objet "),es=o("code"),sa=n("Repository"),Qs=n(" dans un dossier de travail. Tout d\u2019abord, connectez-vous au Hugging Face Hub, si vous n\u2019\xEAtes pas d\xE9j\xE0 connect\xE9. Nous d\xE9terminerons le nom du d\xE9p\xF4t \xE0 partir de l\u2019ID du mod\xE8le que nous voulons donner \xE0 notre mod\xE8le (n\u2019h\xE9sitez pas \xE0 remplacer le "),Ct=o("code"),ae=n("repo_name"),_o=n(" par votre propre choix ; il doit juste contenir votre nom d\u2019utilisateur, ce que fait la fonction "),Gs=o("code"),ho=n("get_full_repo_name()"),vo=n(") :"),Pt=d(),j(Ws.$$.fragment),ta=d(),j(ss.$$.fragment),na=d(),At=o("p"),gn=n("Ensuite, nous pouvons cloner ce r\xE9f\xE9rentiel dans un dossier local. S\u2019il existe d\xE9j\xE0, ce dossier local doit \xEAtre un clone du r\xE9f\xE9rentiel avec lequel nous travaillons :"),aa=d(),j(Js.$$.fragment),St=d(),Le=o("p"),bo=n("Nous pouvons maintenant t\xE9l\xE9charger tout ce que nous sauvegardons dans "),Xs=o("code"),go=n("output_dir"),qo=n(" en appelant la m\xE9thode "),Dt=o("code"),ws=n("repo.push_to_hub()"),xo=n(". Cela nous aidera \xE0 t\xE9l\xE9charger les mod\xE8les interm\xE9diaires \xE0 la fin de chaque \xE9poque."),Mt=d(),ts=o("h2"),js=o("a"),zt=o("span"),j(Ee.$$.fragment),oa=d(),ns=o("span"),ra=n("Boucle d'entra\xEEnement"),Ks=d(),Tt=o("p"),la=n("Nous sommes maintenant pr\xEAts \xE0 \xE9crire la boucle d\u2019entra\xEEnement compl\xE8te. Apr\xE8s avoir d\xE9fini une barre de progression pour suivre l\u2019\xE9volution de l\u2019entra\xEEnement, la boucle comporte trois parties :"),ks=d(),ye=o("ul"),Ce=o("li"),ia=n("l\u2019entra\xEEnement proprement dit, qui est l\u2019it\xE9ration classique sur le "),Ne=o("code"),$o=n("train_dataloader"),qn=n(", passage en avant du mod\xE8le, puis passage en arri\xE8re et \xE9tape d\u2019optimisation."),wo=d(),Pe=o("li"),ua=n("l\u2019\xE9valuation, dans laquelle nous rassemblons toutes les valeurs pour "),as=o("code"),pa=n("start_logits"),Ys=n(" et "),Lt=o("code"),Nt=n("end_logits"),jo=n(" avant de les convertir en tableaux NumPy. Une fois la boucle d\u2019\xE9valuation termin\xE9e, nous concat\xE9nons tous les r\xE9sultats. Notez que nous devons tronquer parce que l\u2019 "),Ot=o("code"),os=n("Accelerator"),Es=n(" peut avoir ajout\xE9 quelques \xE9chantillons \xE0 la fin pour s\u2019assurer que nous avons le m\xEAme nombre d\u2019exemples dans chaque processus."),xn=d(),le=o("li"),ko=n("sauvegarde et t\xE9l\xE9chargement, o\xF9 nous sauvegardons d\u2019abord le mod\xE8le et le "),Zs=o("em"),Eo=n("tokenizer"),da=n(", puis appelons "),rs=o("code"),ca=n("repo.push_to_hub()"),ys=n(". Comme nous l\u2019avons fait auparavant, nous utilisons l\u2019argument "),$n=o("code"),wn=n("blocking=False"),yo=n(" pour dire \xE0 la biblioth\xE8que \u{1F917} "),jn=o("em"),ma=n("Hub"),Cs=n(" de pousser dans un processus asynchrone. De cette fa\xE7on, l\u2019entra\xEEnement continue normalement et cette (longue) instruction est ex\xE9cut\xE9e en arri\xE8re-plan."),fa=d(),Ps=o("p"),Co=n("Voici le code complet de la boucle d\u2019entra\xEEnement :"),_a=d(),j(As.$$.fragment),Ss=d(),ls=o("p"),oe=n("Au cas o\xF9 ce serait la premi\xE8re fois que vous verriez un mod\xE8le enregistr\xE9 avec \u{1F917} "),kn=o("em"),En=n("Accelerate"),Po=n(", prenons un moment pour inspecter les trois lignes de code qui l\u2019accompagnent :"),ha=d(),j(is.$$.fragment),va=d(),ne=o("p"),et=n("La premi\xE8re ligne est explicite : elle indique \xE0 tous les processus d\u2019attendre que tout le monde soit \xE0 ce stade avant de continuer. C\u2019est pour s\u2019assurer que nous avons le m\xEAme mod\xE8le dans chaque processus avant de sauvegarder. Ensuite, nous prenons le "),yn=o("code"),Ao=n("unwrapped_model"),Cn=n(", qui est le mod\xE8le de base que nous avons d\xE9fini. La m\xE9thode "),Pn=o("code"),So=n("accelerator.prepare()"),An=n(" modifie le mod\xE8le pour qu\u2019il fonctionne dans l\u2019entra\xEEnement distribu\xE9, donc il n\u2019aura plus la m\xE9thode "),Sn=o("code"),Do=n("save_pretrained()"),Dn=n(" ; la m\xE9thode "),Mn=o("code"),Mo=n("accelerator.unwrap_model()"),ba=n(" annule cette \xE9tape. Enfin, nous appelons "),us=o("code"),ga=n("save_pretrained()"),st=n(" mais nous disons \xE0 cette m\xE9thode d\u2019utiliser "),It=o("code"),Oe=n("accelerator.save()"),zo=n(" au lieu de "),tt=o("code"),To=n("torch.save()"),Lo=n("."),Bt=d(),Ie=o("p"),No=n("Une fois ceci fait, vous devriez avoir un mod\xE8le qui produit des r\xE9sultats assez similaires \xE0 celui entra\xEEn\xE9 avec le "),Ft=o("code"),nt=n("Trainer"),qa=n(". Vous pouvez v\xE9rifier le mod\xE8le que nous avons entra\xEEn\xE9 en utilisant ce code \xE0 "),Be=o("a"),zn=o("em"),xa=n("huggingface-course/bert-finetuned-squad-accelerate"),at=n(". Et si vous voulez tester des modifications de la boucle d\u2019entra\xEEnement, vous pouvez les impl\xE9menter directement en modifiant le code ci-dessus !"),this.h()},l(m){p=r(m,"P",{});var I=l(p);b=a(I,"Si vous voulez plonger un peu plus profond\xE9ment dans la boucle d\u2019entra\xEEnement, nous allons maintenant vous montrer comment faire la m\xEAme chose en utilisant \u{1F917} "),f=r(I,"EM",{});var ps=l(f);C=a(ps,"Accelerate"),ps.forEach(t),S=a(I,"."),I.forEach(t),g=c(m),$=r(m,"H2",{class:!0});var $a=l($);q=r($a,"A",{id:!0,class:!0,href:!0});var wa=l(q);_=r(wa,"SPAN",{});var Vr=l(_);k(z.$$.fragment,Vr),Vr.forEach(t),wa.forEach(t),x=c($a),D=r($a,"SPAN",{});var Hr=l(D);L=a(Hr,"Une boucle d'entra\xEEnement personnalis\xE9e"),Hr.forEach(t),$a.forEach(t),N=c(m),P=r(m,"P",{});var Ds=l(P);w=a(Ds,"Jetons maintenant un coup d\u2019\u0153il \xE0 la boucle d\u2019entra\xEEnement compl\xE8te, afin que vous puissiez facilement personnaliser les parties dont vous avez besoin. Elle ressemblera beaucoup \xE0 la boucle d\u2019entra\xEEnement du "),U=r(Ds,"A",{href:!0});var Rr=l(U);V=a(Rr,"Chapitre 3"),Rr.forEach(t),F=a(Ds,", \xE0 l\u2019exception de la boucle d\u2019\xE9valuation. Nous serons en mesure d\u2019\xE9valuer le mod\xE8le r\xE9guli\xE8rement puisque nous ne sommes plus contraints par la classe "),M=r(Ds,"CODE",{});var Ur=l(M);B=a(Ur,"Trainer"),Ur.forEach(t),G=a(Ds,"."),Ds.forEach(t),ee=c(m),Q=r(m,"H3",{class:!0});var Ln=l(Q);W=r(Ln,"A",{id:!0,class:!0,href:!0});var Ms=l(W);K=r(Ms,"SPAN",{});var Vt=l(K);k(Y.$$.fragment,Vt),Vt.forEach(t),Ms.forEach(t),O=c(Ln),X=r(Ln,"SPAN",{});var ii=l(X);$e=a(ii,"Pr\xE9parer tout pour l'entra\xEEnement"),ii.forEach(t),Ln.forEach(t),de=c(m),J=r(m,"P",{});var Fe=l(J);se=a(Fe,"Tout d\u2019abord, nous devons construire le "),we=r(Fe,"CODE",{});var Ht=l(we);ve=a(Ht,"DataLoader"),Ht.forEach(t),re=a(Fe,"s \xE0 partir de nos jeux de donn\xE9es. Nous d\xE9finissons le format de ces jeux de donn\xE9es \xE0 "),ms=r(Fe,"CODE",{});var ui=l(ms);Xe=a(ui,'"torch"'),ui.forEach(t),R=a(Fe,", et supprimons les colonnes dans le jeu de validation qui ne sont pas utilis\xE9es par le mod\xE8le. Ensuite, nous pouvons utiliser le "),Z=r(Fe,"CODE",{});var Oo=l(Z);fs=a(Oo,"default_data_collator"),Oo.forEach(t),jt=a(Fe," fourni par Transformers comme "),_s=r(Fe,"CODE",{});var ds=l(_s);Ae=a(ds,"collate_fn"),ds.forEach(t),Se=a(Fe," et m\xE9langer l\u2019ensemble d\u2019entra\xEEnement, mais pas l\u2019ensemble de validation :"),Fe.forEach(t),hs=c(m),k(ce.$$.fragment,m),De=c(m),me=r(m,"P",{});var Qr=l(me);be=a(Qr,"Ensuite, nous r\xE9instantifions notre mod\xE8le, afin de nous assurer que nous ne poursuivons pas les r\xE9glages fins pr\xE9c\xE9dents mais que nous repartons du mod\xE8le pr\xE9-entra\xEEn\xE9 de BERT :"),Qr.forEach(t),Ke=c(m),k(je.$$.fragment,m),Gn=c(m),Me=r(m,"P",{});var ot=l(Me);ao=a(ot,"Ensuite, nous aurons besoin d\u2019un optimiseur. Comme d\u2019habitude, nous utilisons le classique "),kt=r(ot,"CODE",{});var Gr=l(kt);ze=a(Gr,"AdamW"),Gr.forEach(t),oo=a(ot,", qui est comme Adam, mais avec une correction dans la fa\xE7on dont la d\xE9croissance du poids est appliqu\xE9e :"),ot.forEach(t),vs=c(m),k(Vs.$$.fragment,m),Wn=c(m),te=r(m,"P",{});var pe=l(te);ro=a(pe,"Une fois que nous avons tous ces objets, nous pouvons les envoyer \xE0 la m\xE9thode "),dn=r(pe,"CODE",{});var ja=l(dn);Jn=a(ja,"accelerator.prepare()"),ja.forEach(t),Ye=a(pe,". Rappelez-vous que si vous voulez vous entra\xEEner sur des TPUs dans un "),Te=r(pe,"EM",{});var Wr=l(Te);cn=a(Wr,"notebook"),Wr.forEach(t),Hs=a(pe," de Colab, vous devrez d\xE9placer tout ce code dans une fonction d\u2019entra\xEEnement, et qui ne devrait pas ex\xE9cuter une cellule qui instancie un "),mn=r(pe,"CODE",{});var Jr=l(mn);fn=a(Jr,"Accelerator"),Jr.forEach(t),lo=a(pe,". Nous pouvons forcer l\u2019entra\xEEnement en pr\xE9cision mixte en passant "),Et=r(pe,"CODE",{});var Io=l(Et);bs=a(Io,"fp16=True"),Io.forEach(t),io=a(pe," \xE0 l\u2019"),Rs=r(pe,"CODE",{});var rt=l(Rs);uo=a(rt,"Accelerator"),rt.forEach(t),po=a(pe," (ou, si vous ex\xE9cutez le code comme un script, assurez-vous de remplir la \u{1F917} "),yt=r(pe,"EM",{});var Xr=l(yt);Us=a(Xr,"Accelerate"),Xr.forEach(t),Xn=c(pe),gs=r(pe,"CODE",{});var ka=l(gs);co=a(ka,"config"),ka.forEach(t),Kn=a(pe," de mani\xE8re appropri\xE9e)."),pe.forEach(t),qs=c(m),k(xs.$$.fragment,m),$s=c(m),ke=r(m,"P",{});var Rt=l(ke);ge=a(Rt,"Comme vous devez le savoir depuis les sections pr\xE9c\xE9dentes, nous ne pouvons utiliser la longueur de "),_n=r(Rt,"CODE",{});var Kr=l(_n);hn=a(Kr,"train_dataloader"),Kr.forEach(t),mo=a(Rt," pour calculer le nombre d\u2019\xE9tapes d\u2019entra\xEEnement qu\u2019apr\xE8s qu\u2019il soit pass\xE9 par la m\xE9thode "),vn=r(Rt,"CODE",{});var Bo=l(vn);bn=a(Bo,"accelerator.prepare()"),Bo.forEach(t),fo=a(Rt,". Nous utilisons le m\xEAme programme lin\xE9aire que dans les sections pr\xE9c\xE9dentes :"),Rt.forEach(t),Yn=c(m),k(Ze.$$.fragment,m),Zn=c(m),qe=r(m,"P",{});var ie=l(qe);ea=a(ie,"Pour pousser notre mod\xE8le vers le Hub, nous aurons besoin de cr\xE9er un objet "),es=r(ie,"CODE",{});var Nn=l(es);sa=a(Nn,"Repository"),Nn.forEach(t),Qs=a(ie," dans un dossier de travail. Tout d\u2019abord, connectez-vous au Hugging Face Hub, si vous n\u2019\xEAtes pas d\xE9j\xE0 connect\xE9. Nous d\xE9terminerons le nom du d\xE9p\xF4t \xE0 partir de l\u2019ID du mod\xE8le que nous voulons donner \xE0 notre mod\xE8le (n\u2019h\xE9sitez pas \xE0 remplacer le "),Ct=r(ie,"CODE",{});var Ea=l(Ct);ae=a(Ea,"repo_name"),Ea.forEach(t),_o=a(ie," par votre propre choix ; il doit juste contenir votre nom d\u2019utilisateur, ce que fait la fonction "),Gs=r(ie,"CODE",{});var Yr=l(Gs);ho=a(Yr,"get_full_repo_name()"),Yr.forEach(t),vo=a(ie,") :"),ie.forEach(t),Pt=c(m),k(Ws.$$.fragment,m),ta=c(m),k(ss.$$.fragment,m),na=c(m),At=r(m,"P",{});var Zr=l(At);gn=a(Zr,"Ensuite, nous pouvons cloner ce r\xE9f\xE9rentiel dans un dossier local. S\u2019il existe d\xE9j\xE0, ce dossier local doit \xEAtre un clone du r\xE9f\xE9rentiel avec lequel nous travaillons :"),Zr.forEach(t),aa=c(m),k(Js.$$.fragment,m),St=c(m),Le=r(m,"P",{});var Ut=l(Le);bo=a(Ut,"Nous pouvons maintenant t\xE9l\xE9charger tout ce que nous sauvegardons dans "),Xs=r(Ut,"CODE",{});var On=l(Xs);go=a(On,"output_dir"),On.forEach(t),qo=a(Ut," en appelant la m\xE9thode "),Dt=r(Ut,"CODE",{});var ya=l(Dt);ws=a(ya,"repo.push_to_hub()"),ya.forEach(t),xo=a(Ut,". Cela nous aidera \xE0 t\xE9l\xE9charger les mod\xE8les interm\xE9diaires \xE0 la fin de chaque \xE9poque."),Ut.forEach(t),Mt=c(m),ts=r(m,"H2",{class:!0});var Ca=l(ts);js=r(Ca,"A",{id:!0,class:!0,href:!0});var el=l(js);zt=r(el,"SPAN",{});var sl=l(zt);k(Ee.$$.fragment,sl),sl.forEach(t),el.forEach(t),oa=c(Ca),ns=r(Ca,"SPAN",{});var lt=l(ns);ra=a(lt,"Boucle d'entra\xEEnement"),lt.forEach(t),Ca.forEach(t),Ks=c(m),Tt=r(m,"P",{});var Pa=l(Tt);la=a(Pa,"Nous sommes maintenant pr\xEAts \xE0 \xE9crire la boucle d\u2019entra\xEEnement compl\xE8te. Apr\xE8s avoir d\xE9fini une barre de progression pour suivre l\u2019\xE9volution de l\u2019entra\xEEnement, la boucle comporte trois parties :"),Pa.forEach(t),ks=c(m),ye=r(m,"UL",{});var Qt=l(ye);Ce=r(Qt,"LI",{});var Aa=l(Ce);ia=a(Aa,"l\u2019entra\xEEnement proprement dit, qui est l\u2019it\xE9ration classique sur le "),Ne=r(Aa,"CODE",{});var Sa=l(Ne);$o=a(Sa,"train_dataloader"),Sa.forEach(t),qn=a(Aa,", passage en avant du mod\xE8le, puis passage en arri\xE8re et \xE9tape d\u2019optimisation."),Aa.forEach(t),wo=c(Qt),Pe=r(Qt,"LI",{});var zs=l(Pe);ua=a(zs,"l\u2019\xE9valuation, dans laquelle nous rassemblons toutes les valeurs pour "),as=r(zs,"CODE",{});var tl=l(as);pa=a(tl,"start_logits"),tl.forEach(t),Ys=a(zs," et "),Lt=r(zs,"CODE",{});var nl=l(Lt);Nt=a(nl,"end_logits"),nl.forEach(t),jo=a(zs," avant de les convertir en tableaux NumPy. Une fois la boucle d\u2019\xE9valuation termin\xE9e, nous concat\xE9nons tous les r\xE9sultats. Notez que nous devons tronquer parce que l\u2019 "),Ot=r(zs,"CODE",{});var it=l(Ot);os=a(it,"Accelerator"),it.forEach(t),Es=a(zs," peut avoir ajout\xE9 quelques \xE9chantillons \xE0 la fin pour s\u2019assurer que nous avons le m\xEAme nombre d\u2019exemples dans chaque processus."),zs.forEach(t),xn=c(Qt),le=r(Qt,"LI",{});var xe=l(le);ko=a(xe,"sauvegarde et t\xE9l\xE9chargement, o\xF9 nous sauvegardons d\u2019abord le mod\xE8le et le "),Zs=r(xe,"EM",{});var al=l(Zs);Eo=a(al,"tokenizer"),al.forEach(t),da=a(xe,", puis appelons "),rs=r(xe,"CODE",{});var ol=l(rs);ca=a(ol,"repo.push_to_hub()"),ol.forEach(t),ys=a(xe,". Comme nous l\u2019avons fait auparavant, nous utilisons l\u2019argument "),$n=r(xe,"CODE",{});var Da=l($n);wn=a(Da,"blocking=False"),Da.forEach(t),yo=a(xe," pour dire \xE0 la biblioth\xE8que \u{1F917} "),jn=r(xe,"EM",{});var rl=l(jn);ma=a(rl,"Hub"),rl.forEach(t),Cs=a(xe," de pousser dans un processus asynchrone. De cette fa\xE7on, l\u2019entra\xEEnement continue normalement et cette (longue) instruction est ex\xE9cut\xE9e en arri\xE8re-plan."),xe.forEach(t),Qt.forEach(t),fa=c(m),Ps=r(m,"P",{});var ll=l(Ps);Co=a(ll,"Voici le code complet de la boucle d\u2019entra\xEEnement :"),ll.forEach(t),_a=c(m),k(As.$$.fragment,m),Ss=c(m),ls=r(m,"P",{});var In=l(ls);oe=a(In,"Au cas o\xF9 ce serait la premi\xE8re fois que vous verriez un mod\xE8le enregistr\xE9 avec \u{1F917} "),kn=r(In,"EM",{});var Gt=l(kn);En=a(Gt,"Accelerate"),Gt.forEach(t),Po=a(In,", prenons un moment pour inspecter les trois lignes de code qui l\u2019accompagnent :"),In.forEach(t),ha=c(m),k(is.$$.fragment,m),va=c(m),ne=r(m,"P",{});var ue=l(ne);et=a(ue,"La premi\xE8re ligne est explicite : elle indique \xE0 tous les processus d\u2019attendre que tout le monde soit \xE0 ce stade avant de continuer. C\u2019est pour s\u2019assurer que nous avons le m\xEAme mod\xE8le dans chaque processus avant de sauvegarder. Ensuite, nous prenons le "),yn=r(ue,"CODE",{});var Wt=l(yn);Ao=a(Wt,"unwrapped_model"),Wt.forEach(t),Cn=a(ue,", qui est le mod\xE8le de base que nous avons d\xE9fini. La m\xE9thode "),Pn=r(ue,"CODE",{});var Fo=l(Pn);So=a(Fo,"accelerator.prepare()"),Fo.forEach(t),An=a(ue," modifie le mod\xE8le pour qu\u2019il fonctionne dans l\u2019entra\xEEnement distribu\xE9, donc il n\u2019aura plus la m\xE9thode "),Sn=r(ue,"CODE",{});var fe=l(Sn);Do=a(fe,"save_pretrained()"),fe.forEach(t),Dn=a(ue," ; la m\xE9thode "),Mn=r(ue,"CODE",{});var il=l(Mn);Mo=a(il,"accelerator.unwrap_model()"),il.forEach(t),ba=a(ue," annule cette \xE9tape. Enfin, nous appelons "),us=r(ue,"CODE",{});var Ma=l(us);ga=a(Ma,"save_pretrained()"),Ma.forEach(t),st=a(ue," mais nous disons \xE0 cette m\xE9thode d\u2019utiliser "),It=r(ue,"CODE",{});var ul=l(It);Oe=a(ul,"accelerator.save()"),ul.forEach(t),zo=a(ue," au lieu de "),tt=r(ue,"CODE",{});var pl=l(tt);To=a(pl,"torch.save()"),pl.forEach(t),Lo=a(ue,"."),ue.forEach(t),Bt=c(m),Ie=r(m,"P",{});var Ts=l(Ie);No=a(Ts,"Une fois ceci fait, vous devriez avoir un mod\xE8le qui produit des r\xE9sultats assez similaires \xE0 celui entra\xEEn\xE9 avec le "),Ft=r(Ts,"CODE",{});var dl=l(Ft);nt=a(dl,"Trainer"),dl.forEach(t),qa=a(Ts,". Vous pouvez v\xE9rifier le mod\xE8le que nous avons entra\xEEn\xE9 en utilisant ce code \xE0 "),Be=r(Ts,"A",{href:!0,rel:!0});var cl=l(Be);zn=r(cl,"EM",{});var za=l(zn);xa=a(za,"huggingface-course/bert-finetuned-squad-accelerate"),za.forEach(t),cl.forEach(t),at=a(Ts,". Et si vous voulez tester des modifications de la boucle d\u2019entra\xEEnement, vous pouvez les impl\xE9menter directement en modifiant le code ci-dessus !"),Ts.forEach(t),this.h()},h(){A(q,"id","une-boucle-dentranement-personnalise"),A(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),A(q,"href","#une-boucle-dentranement-personnalise"),A($,"class","relative group"),A(U,"href","/course/fr/chapter3/4"),A(W,"id","prparer-tout-pour-lentranement"),A(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),A(W,"href","#prparer-tout-pour-lentranement"),A(Q,"class","relative group"),A(js,"id","boucle-dentranement"),A(js,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),A(js,"href","#boucle-dentranement"),A(ts,"class","relative group"),A(Be,"href","https://huggingface.co/huggingface-course/bert-finetuned-squad-accelerate"),A(Be,"rel","nofollow")},m(m,I){i(m,p,I),s(p,b),s(p,f),s(f,C),s(p,S),i(m,g,I),i(m,$,I),s($,q),s(q,_),E(z,_,null),s($,x),s($,D),s(D,L),i(m,N,I),i(m,P,I),s(P,w),s(P,U),s(U,V),s(P,F),s(P,M),s(M,B),s(P,G),i(m,ee,I),i(m,Q,I),s(Q,W),s(W,K),E(Y,K,null),s(Q,O),s(Q,X),s(X,$e),i(m,de,I),i(m,J,I),s(J,se),s(J,we),s(we,ve),s(J,re),s(J,ms),s(ms,Xe),s(J,R),s(J,Z),s(Z,fs),s(J,jt),s(J,_s),s(_s,Ae),s(J,Se),i(m,hs,I),E(ce,m,I),i(m,De,I),i(m,me,I),s(me,be),i(m,Ke,I),E(je,m,I),i(m,Gn,I),i(m,Me,I),s(Me,ao),s(Me,kt),s(kt,ze),s(Me,oo),i(m,vs,I),E(Vs,m,I),i(m,Wn,I),i(m,te,I),s(te,ro),s(te,dn),s(dn,Jn),s(te,Ye),s(te,Te),s(Te,cn),s(te,Hs),s(te,mn),s(mn,fn),s(te,lo),s(te,Et),s(Et,bs),s(te,io),s(te,Rs),s(Rs,uo),s(te,po),s(te,yt),s(yt,Us),s(te,Xn),s(te,gs),s(gs,co),s(te,Kn),i(m,qs,I),E(xs,m,I),i(m,$s,I),i(m,ke,I),s(ke,ge),s(ke,_n),s(_n,hn),s(ke,mo),s(ke,vn),s(vn,bn),s(ke,fo),i(m,Yn,I),E(Ze,m,I),i(m,Zn,I),i(m,qe,I),s(qe,ea),s(qe,es),s(es,sa),s(qe,Qs),s(qe,Ct),s(Ct,ae),s(qe,_o),s(qe,Gs),s(Gs,ho),s(qe,vo),i(m,Pt,I),E(Ws,m,I),i(m,ta,I),E(ss,m,I),i(m,na,I),i(m,At,I),s(At,gn),i(m,aa,I),E(Js,m,I),i(m,St,I),i(m,Le,I),s(Le,bo),s(Le,Xs),s(Xs,go),s(Le,qo),s(Le,Dt),s(Dt,ws),s(Le,xo),i(m,Mt,I),i(m,ts,I),s(ts,js),s(js,zt),E(Ee,zt,null),s(ts,oa),s(ts,ns),s(ns,ra),i(m,Ks,I),i(m,Tt,I),s(Tt,la),i(m,ks,I),i(m,ye,I),s(ye,Ce),s(Ce,ia),s(Ce,Ne),s(Ne,$o),s(Ce,qn),s(ye,wo),s(ye,Pe),s(Pe,ua),s(Pe,as),s(as,pa),s(Pe,Ys),s(Pe,Lt),s(Lt,Nt),s(Pe,jo),s(Pe,Ot),s(Ot,os),s(Pe,Es),s(ye,xn),s(ye,le),s(le,ko),s(le,Zs),s(Zs,Eo),s(le,da),s(le,rs),s(rs,ca),s(le,ys),s(le,$n),s($n,wn),s(le,yo),s(le,jn),s(jn,ma),s(le,Cs),i(m,fa,I),i(m,Ps,I),s(Ps,Co),i(m,_a,I),E(As,m,I),i(m,Ss,I),i(m,ls,I),s(ls,oe),s(ls,kn),s(kn,En),s(ls,Po),i(m,ha,I),E(is,m,I),i(m,va,I),i(m,ne,I),s(ne,et),s(ne,yn),s(yn,Ao),s(ne,Cn),s(ne,Pn),s(Pn,So),s(ne,An),s(ne,Sn),s(Sn,Do),s(ne,Dn),s(ne,Mn),s(Mn,Mo),s(ne,ba),s(ne,us),s(us,ga),s(ne,st),s(ne,It),s(It,Oe),s(ne,zo),s(ne,tt),s(tt,To),s(ne,Lo),i(m,Bt,I),i(m,Ie,I),s(Ie,No),s(Ie,Ft),s(Ft,nt),s(Ie,qa),s(Ie,Be),s(Be,zn),s(zn,xa),s(Ie,at),Tn=!0},i(m){Tn||(h(z.$$.fragment,m),h(Y.$$.fragment,m),h(ce.$$.fragment,m),h(je.$$.fragment,m),h(Vs.$$.fragment,m),h(xs.$$.fragment,m),h(Ze.$$.fragment,m),h(Ws.$$.fragment,m),h(ss.$$.fragment,m),h(Js.$$.fragment,m),h(Ee.$$.fragment,m),h(As.$$.fragment,m),h(is.$$.fragment,m),Tn=!0)},o(m){v(z.$$.fragment,m),v(Y.$$.fragment,m),v(ce.$$.fragment,m),v(je.$$.fragment,m),v(Vs.$$.fragment,m),v(xs.$$.fragment,m),v(Ze.$$.fragment,m),v(Ws.$$.fragment,m),v(ss.$$.fragment,m),v(Js.$$.fragment,m),v(Ee.$$.fragment,m),v(As.$$.fragment,m),v(is.$$.fragment,m),Tn=!1},d(m){m&&t(p),m&&t(g),m&&t($),y(z),m&&t(N),m&&t(P),m&&t(ee),m&&t(Q),y(Y),m&&t(de),m&&t(J),m&&t(hs),y(ce,m),m&&t(De),m&&t(me),m&&t(Ke),y(je,m),m&&t(Gn),m&&t(Me),m&&t(vs),y(Vs,m),m&&t(Wn),m&&t(te),m&&t(qs),y(xs,m),m&&t($s),m&&t(ke),m&&t(Yn),y(Ze,m),m&&t(Zn),m&&t(qe),m&&t(Pt),y(Ws,m),m&&t(ta),y(ss,m),m&&t(na),m&&t(At),m&&t(aa),y(Js,m),m&&t(St),m&&t(Le),m&&t(Mt),m&&t(ts),y(Ee),m&&t(Ks),m&&t(Tt),m&&t(ks),m&&t(ye),m&&t(fa),m&&t(Ps),m&&t(_a),y(As,m),m&&t(Ss),m&&t(ls),m&&t(ha),y(is,m),m&&t(va),m&&t(ne),m&&t(Bt),m&&t(Ie)}}}function _g(H){let p,b,f,C,S,g,$,q,_,z,x,D,L,N,P,w,U,V,F,M,B,G,ee,Q,W,K,Y,O,X,$e,de,J,se,we,ve,re,ms,Xe,R,Z,fs,jt,_s,Ae,Se,hs,ce,De,me,be,Ke,je,Gn,Me,ao,kt,ze,oo,vs,Vs,Wn,te,ro,dn,Jn,Ye,Te,cn,Hs,mn,fn,lo,Et,bs,io,Rs,uo,po,yt,Us,Xn,gs,co,Kn,qs,xs,$s,ke,ge,_n,hn,mo,vn,bn,fo,Yn,Ze,Zn,qe,ea,es,sa,Qs,Ct,ae,_o,Gs,ho,vo,Pt,Ws,ta,ss,na,At,gn,aa,Js,St,Le,bo,Xs,go,qo,Dt,ws,xo,Mt,ts,js,zt,Ee,oa,ns,ra,Ks,Tt,la,ks,ye,Ce,ia,Ne,$o,qn,wo,Pe,ua,as,pa,Ys,Lt,Nt,jo,Ot,os,Es,xn,le,ko,Zs,Eo,da,rs,ca,ys,$n,wn,yo,jn,ma,Cs,fa,Ps,Co,_a,As,Ss,ls,oe,kn,En,Po,ha,is,va,ne,et,yn,Ao,Cn,Pn,So,An,Sn,Do,Dn,Mn,Mo,ba,us,ga,st,It,Oe,zo,tt,To,Lo,Bt,Ie,No,Ft,nt,qa,Be,zn,xa,at,Tn,m,I,ps,$a,wa,Vr,Hr,Ds,Rr,Ur,Ln,Ms,Vt,ii,Fe,Ht,ui,Oo,ds,Qr,ot,Gr,pe,ja,Wr,Jr,Io,rt,Xr,ka,Rt,Kr,Bo,ie,Nn,Ea,Yr,Zr,Ut,On,ya,Ca,el,sl,lt,Pa,Qt,Aa,Sa,zs,tl,nl,it,xe,al,ol,Da,rl,ll,In,Gt,ue,Wt,Fo,fe,il,Ma,ul,pl,Ts,dl,cl,za,Qd,Gd,pi,Wd,Jd,di,Xd,Kd,Tu,Ve,Yd,ci,Zd,ec,ml,sc,tc,mi,nc,ac,fi,oc,rc,Lu,Vo,Nu,Ho,Ou,Ls,lc,_i,ic,uc,hi,pc,dc,vi,cc,mc,Iu,Ro,Bu,Uo,Fu,fl,fc,Vu,Qo,Hu,Go,Ru,_l,_c,Uu,hl,hc,Qu,Ta,vl,bi,vc,bc,gc,He,gi,qc,xc,qi,$c,wc,xi,jc,kc,$i,Ec,yc,wi,Cc,Pc,Gu,Re,Ac,ji,Sc,Dc,ki,Mc,zc,Ei,Tc,Lc,yi,Nc,Oc,Wu,Ue,Ic,Ci,Bc,Fc,Pi,Vc,Hc,Ai,Rc,Uc,Si,Qc,Gc,Ju,Wo,Xu,Jo,Ku,Jt,Wc,Di,Jc,Xc,Mi,Kc,Yc,Yu,Xo,Zu,Ko,ep,Xt,Zc,zi,em,sm,Ti,tm,nm,sp,Yo,tp,Zo,np,bl,am,ap,La,op,gl,om,rp,er,lp,ql,rm,ip,Kt,lm,Li,im,um,Ni,pm,dm,up,sr,pp,tr,dp,xl,cm,cp,Bn,Na,Oi,nr,mm,Ii,fm,mp,$l,_m,fp,Ns,hm,Bi,vm,bm,Fi,gm,qm,Vi,xm,$m,_p,ar,hp,wl,wm,vp,or,bp,rr,gp,jl,jm,qp,kl,km,xp,ut,pt,El,Fn,Oa,Hi,lr,Em,Ri,ym,$p,dt,ct,yl,Ia,Cm,ir,Ui,Pm,Am,Sm,wp,Os,ur,Dm,Qi,Mm,zm,Tm,Gi,Lm,Nm,pr,Om,Wi,Im,Bm,Fm,Vn,Vm,Ji,Hm,Rm,Xi,Um,Qm,jp,Is,Gm,Ki,Wm,Jm,Yi,Xm,Km,Zi,Ym,Zm,kp,Ba,ef,eu,sf,tf,Ep,dr,yp,Fa,nf,su,af,of,Cp,cr,Pp,Va,rf,tu,lf,uf,Ap,mt,ft,Cl,Qe,pf,nu,df,cf,au,mf,ff,ou,_f,hf,ru,vf,bf,Sp,mr,Dp,Ha,gf,lu,qf,xf,Mp,Yt,iu,$f,wf,uu,jf,kf,fr,Ef,pu,yf,Cf,zp,Pl,Pf,Tp,_r,Lp,Ra,Af,du,Sf,Df,Np,hr,Op,Al,Mf,Ip,vr,Bp,Sl,zf,Fp,br,Vp,gr,Hp,Dl,Tf,Rp,qr,Up,xr,Qp,Zt,Lf,$r,Nf,Of,cu,If,Bf,Gp,Ml,wr,Wp,zl,Ff,Jp,jr,Xp,kr,Kp,Tl,Vf,Yp,Hn,Ua,mu,Er,Hf,fu,Rf,Zp,_t,ht,Ll,Qa,Uf,_u,Qf,Gf,ed,en,Wf,hu,Jf,Xf,vu,Kf,Yf,sd,yr,td,Ga,Zf,bu,e_,s_,nd,Cr,ad,vt,bt,Nl,Ge,t_,gu,n_,a_,qu,o_,r_,xu,l_,i_,$u,u_,p_,od,gt,qt,Ol,Il,d_,rd,xt,$t,Bl,Pr,ld,Fl,c_,id,Vl,sn,m_,wu,f_,__,ju,h_,v_,ud,Wa,pd,Hl,Rn,Ja,ku,Ar,b_,Eu,g_,dd,Bs,q_,yu,x_,$_,Cu,w_,j_,Pu,k_,E_,cd,Sr,md,Dr,fd,Rl,y_,_d;f=new Qb({props:{fw:H[0]}}),q=new cs({});const D_=[Wb,Gb],Mr=[];function M_(e,u){return e[0]==="pt"?0:1}L=M_(H),N=Mr[L]=D_[L](H),G=new Ud({props:{id:"ajPx5LwJD-I"}}),ce=new Rd({props:{$$slots:{default:[Jb]},$$scope:{ctx:H}}}),je=new cs({}),Hs=new cs({}),Us=new T({props:{code:`from datasets import load_dataset

raw_datasets = load_dataset("squad")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

raw_datasets = load_dataset(<span class="hljs-string">&quot;squad&quot;</span>)`}}),qs=new T({props:{code:"raw_datasets",highlighted:"raw_datasets"}}),$s=new T({props:{code:`DatasetDict({
    train: Dataset({
        features: ['id', 'title', 'context', 'question', 'answers'],
        num_rows: 87599
    })
    validation: Dataset({
        features: ['id', 'title', 'context', 'question', 'answers'],
        num_rows: 10570
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;context&#x27;</span>, <span class="hljs-string">&#x27;question&#x27;</span>, <span class="hljs-string">&#x27;answers&#x27;</span>],
        num_rows: <span class="hljs-number">87599</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;context&#x27;</span>, <span class="hljs-string">&#x27;question&#x27;</span>, <span class="hljs-string">&#x27;answers&#x27;</span>],
        num_rows: <span class="hljs-number">10570</span>
    })
})`}}),es=new T({props:{code:`print("Context: ", raw_datasets["train"][0]["context"])
print("Question: ", raw_datasets["train"][0]["question"])
print("Answer: ", raw_datasets["train"][0]["answers"])`,highlighted:`<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Context: &quot;</span>, raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;context&quot;</span>])
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Question: &quot;</span>, raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;question&quot;</span>])
<span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Answer: &quot;</span>, raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;answers&quot;</span>])`}}),Qs=new T({props:{code:`Context: 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend "Venite Ad Me Omnes". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'
# Sur le plan architectural, l'\xE9cole a un caract\xE8re catholique. Au sommet du d\xF4me dor\xE9 du b\xE2timent principal se trouve une statue dor\xE9e de la Vierge Marie. Imm\xE9diatement devant le b\xE2timent principal et face \xE0 lui, se trouve une statue en cuivre du Christ, les bras lev\xE9s, avec la l\xE9gende "Venite Ad Me Omnes". \xC0 c\xF4t\xE9 du b\xE2timent principal se trouve la basilique du Sacr\xE9-C\u0153ur. Imm\xE9diatement derri\xE8re la basilique se trouve la Grotte, un lieu marial de pri\xE8re et de r\xE9flexion. Il s'agit d'une r\xE9plique de la grotte de Lourdes, en France, o\xF9 la Vierge Marie serait apparue \xE0 Sainte Bernadette Soubirous en 1858. Au bout de l'all\xE9e principale (et dans une ligne directe qui passe par 3 statues et le D\xF4me d'or), se trouve une statue de pierre simple et moderne de Marie'.
Question: 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?' # A qui la Vierge Marie serait-elle apparue en 1858 \xE0 Lourdes, en France ?
Answer: {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}`,highlighted:`Context: <span class="hljs-string">&#x27;Architecturally, the school has a Catholic character. Atop the Main Building\\&#x27;s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend &quot;Venite Ad Me Omnes&quot;. Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.&#x27;</span>
<span class="hljs-comment"># Sur le plan architectural, l&#x27;\xE9cole a un caract\xE8re catholique. Au sommet du d\xF4me dor\xE9 du b\xE2timent principal se trouve une statue dor\xE9e de la Vierge Marie. Imm\xE9diatement devant le b\xE2timent principal et face \xE0 lui, se trouve une statue en cuivre du Christ, les bras lev\xE9s, avec la l\xE9gende &quot;Venite Ad Me Omnes&quot;. \xC0 c\xF4t\xE9 du b\xE2timent principal se trouve la basilique du Sacr\xE9-C\u0153ur. Imm\xE9diatement derri\xE8re la basilique se trouve la Grotte, un lieu marial de pri\xE8re et de r\xE9flexion. Il s&#x27;agit d&#x27;une r\xE9plique de la grotte de Lourdes, en France, o\xF9 la Vierge Marie serait apparue \xE0 Sainte Bernadette Soubirous en 1858. Au bout de l&#x27;all\xE9e principale (et dans une ligne directe qui passe par 3 statues et le D\xF4me d&#x27;or), se trouve une statue de pierre simple et moderne de Marie&#x27;.</span>
Question: <span class="hljs-string">&#x27;To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?&#x27;</span> <span class="hljs-comment"># A qui la Vierge Marie serait-elle apparue en 1858 \xE0 Lourdes, en France ?</span>
Answer: {<span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&#x27;Saint Bernadette Soubirous&#x27;</span>], <span class="hljs-string">&#x27;answer_start&#x27;</span>: [<span class="hljs-number">515</span>]}`}}),Ee=new T({props:{code:'raw_datasets["train"].filter(lambda x: len(x["answers"]["text"]) != 1)',highlighted:'raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x[<span class="hljs-string">&quot;answers&quot;</span>][<span class="hljs-string">&quot;text&quot;</span>]) != <span class="hljs-number">1</span>)'}}),ns=new T({props:{code:`Dataset({
    features: ['id', 'title', 'context', 'question', 'answers'],
    num_rows: 0
})`,highlighted:`Dataset({
    features: [<span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;title&#x27;</span>, <span class="hljs-string">&#x27;context&#x27;</span>, <span class="hljs-string">&#x27;question&#x27;</span>, <span class="hljs-string">&#x27;answers&#x27;</span>],
    num_rows: <span class="hljs-number">0</span>
})`}}),ks=new T({props:{code:`print(raw_datasets["validation"][0]["answers"])
print(raw_datasets["validation"][2]["answers"])`,highlighted:`<span class="hljs-built_in">print</span>(raw_datasets[<span class="hljs-string">&quot;validation&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;answers&quot;</span>])
<span class="hljs-built_in">print</span>(raw_datasets[<span class="hljs-string">&quot;validation&quot;</span>][<span class="hljs-number">2</span>][<span class="hljs-string">&quot;answers&quot;</span>])`}}),Ce=new T({props:{code:`{'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [177, 177, 177]}
{'text': ['Santa Clara, California', "Levi's Stadium", "Levi's Stadium in the San Francisco Bay Area at Santa Clara, California."], 'answer_start': [403, 355, 355]}`,highlighted:`{<span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&#x27;Denver Broncos&#x27;</span>, <span class="hljs-string">&#x27;Denver Broncos&#x27;</span>, <span class="hljs-string">&#x27;Denver Broncos&#x27;</span>], <span class="hljs-string">&#x27;answer_start&#x27;</span>: [<span class="hljs-number">177</span>, <span class="hljs-number">177</span>, <span class="hljs-number">177</span>]}
{<span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&#x27;Santa Clara, California&#x27;</span>, <span class="hljs-string">&quot;Levi&#x27;s Stadium&quot;</span>, <span class="hljs-string">&quot;Levi&#x27;s Stadium in the San Francisco Bay Area at Santa Clara, California.&quot;</span>], <span class="hljs-string">&#x27;answer_start&#x27;</span>: [<span class="hljs-number">403</span>, <span class="hljs-number">355</span>, <span class="hljs-number">355</span>]}`}}),as=new T({props:{code:`print(raw_datasets["validation"][2]["context"])
print(raw_datasets["validation"][2]["question"])`,highlighted:`<span class="hljs-built_in">print</span>(raw_datasets[<span class="hljs-string">&quot;validation&quot;</span>][<span class="hljs-number">2</span>][<span class="hljs-string">&quot;context&quot;</span>])
<span class="hljs-built_in">print</span>(raw_datasets[<span class="hljs-string">&quot;validation&quot;</span>][<span class="hljs-number">2</span>][<span class="hljs-string">&quot;question&quot;</span>])`}}),Ys=new T({props:{code:`'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24\u201310 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the "golden anniversary" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as "Super Bowl L"), so that the logo could prominently feature the Arabic numerals 50.'
# Le Super Bowl 50 \xE9tait un match de football am\xE9ricain visant \xE0 d\xE9terminer le champion de la National Football League (NFL) pour la saison 2015. Les Denver Broncos, champions de la Conf\xE9rence de football am\xE9ricain (AFC), ont battu les Carolina Panthers, champions de la Conf\xE9rence nationale de football (NFC), 24 \xE0 10, pour remporter leur troisi\xE8me titre de Super Bowl. Le match s'est d\xE9roul\xE9 le 7 f\xE9vrier 2016 au Levi\\'s Stadium, dans la baie de San Francisco, \xE0 Santa Clara, en Californie. Comme il s'agissait du 50e Super Bowl, la ligue a mis l'accent sur l'" anniversaire dor\xE9 " avec diverses initiatives sur le th\xE8me de l'or, ainsi qu'en suspendant temporairement la tradition de nommer chaque match du Super Bowl avec des chiffres romains (en vertu de laquelle le match aurait \xE9t\xE9 appel\xE9 " Super Bowl L "), afin que le logo puisse mettre en \xE9vidence les chiffres arabes 50.''
'Where did Super Bowl 50 take place?' # O\xF9 a eu lieu le Super Bowl 50 ?`,highlighted:`<span class="hljs-string">&#x27;Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24\u201310 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\&#x27;s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the &quot;golden anniversary&quot; with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as &quot;Super Bowl L&quot;), so that the logo could prominently feature the Arabic numerals 50.&#x27;</span>
<span class="hljs-comment"># Le Super Bowl 50 \xE9tait un match de football am\xE9ricain visant \xE0 d\xE9terminer le champion de la National Football League (NFL) pour la saison 2015. Les Denver Broncos, champions de la Conf\xE9rence de football am\xE9ricain (AFC), ont battu les Carolina Panthers, champions de la Conf\xE9rence nationale de football (NFC), 24 \xE0 10, pour remporter leur troisi\xE8me titre de Super Bowl. Le match s&#x27;est d\xE9roul\xE9 le 7 f\xE9vrier 2016 au Levi\\&#x27;s Stadium, dans la baie de San Francisco, \xE0 Santa Clara, en Californie. Comme il s&#x27;agissait du 50e Super Bowl, la ligue a mis l&#x27;accent sur l&#x27;&quot; anniversaire dor\xE9 &quot; avec diverses initiatives sur le th\xE8me de l&#x27;or, ainsi qu&#x27;en suspendant temporairement la tradition de nommer chaque match du Super Bowl avec des chiffres romains (en vertu de laquelle le match aurait \xE9t\xE9 appel\xE9 &quot; Super Bowl L &quot;), afin que le logo puisse mettre en \xE9vidence les chiffres arabes 50.&#x27;&#x27;</span>
<span class="hljs-string">&#x27;Where did Super Bowl 50 take place?&#x27;</span> <span class="hljs-comment"># O\xF9 a eu lieu le Super Bowl 50 ?</span>`}}),le=new cs({}),rs=new Ud({props:{id:"qgaM0weJHpA"}}),Ss=new T({props:{code:`from transformers import AutoTokenizer

model_checkpoint = "bert-base-cased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

model_checkpoint = <span class="hljs-string">&quot;bert-base-cased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)`}}),us=new T({props:{code:"tokenizer.is_fast",highlighted:"tokenizer.is_fast"}}),st=new T({props:{code:"True",highlighted:'<span class="hljs-literal">True</span>'}}),nt=new T({props:{code:"[CLS] question [SEP] context [SEP]",highlighted:'<span class="hljs-selector-attr">[CLS]</span> question <span class="hljs-selector-attr">[SEP]</span> context <span class="hljs-selector-attr">[SEP]</span>'}}),at=new T({props:{code:`context = raw_datasets["train"][0]["context"]
question = raw_datasets["train"][0]["question"]

inputs = tokenizer(question, context)
tokenizer.decode(inputs["input_ids"])`,highlighted:`context = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;context&quot;</span>]
question = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;question&quot;</span>]

inputs = tokenizer(question, context)
tokenizer.decode(inputs[<span class="hljs-string">&quot;input_ids&quot;</span>])`}}),m=new T({props:{code:`'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, '
'the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin '
'Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms '
'upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred '
'Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a '
'replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette '
'Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues '
'and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]'

'[CLS] A qui la Vierge Marie serait-elle apparue en 1858 \xE0 Lourdes en France ? [SEP] Architecturalement, '
l'\xE9cole a un caract\xE8re catholique. Au sommet du d\xF4me dor\xE9 du b\xE2timent principal se trouve une statue dor\xE9e de la Vierge '
Marie. Imm\xE9diatement devant le b\xE2timent principal et face \xE0 lui, se trouve une statue en cuivre du Christ, les bras ''lev\xE9s''.
'lev\xE9s avec la l\xE9gende " Venite Ad Me Omnes ". A c\xF4t\xE9 du b\xE2timent principal se trouve la basilique du Sacr\xE9-C\u0153ur.
'C\u0153ur. Imm\xE9diatement derri\xE8re la basilique se trouve la Grotte, un lieu marial de pri\xE8re et de r\xE9flexion. Il s'agit d'une '
'r\xE9plique de la grotte de Lourdes, en France, o\xF9 la Vierge Marie serait apparue \xE0 Sainte Bernadette '
Soubirous en 1858. Au bout de l'all\xE9e principale ( et en ligne directe qui passe par 3 statues '
'et le D\xF4me d'or), se trouve une statue de Marie en pierre, simple et moderne. [SEP]''`,highlighted:`<span class="hljs-string">&#x27;[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, &#x27;</span>
<span class="hljs-string">&#x27;the school has a Catholic character. Atop the Main Building\\&#x27;s gold dome is a golden statue of the Virgin &#x27;</span>
<span class="hljs-string">&#x27;Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms &#x27;</span>
<span class="hljs-string">&#x27;upraised with the legend &quot; Venite Ad Me Omnes &quot;. Next to the Main Building is the Basilica of the Sacred &#x27;</span>
<span class="hljs-string">&#x27;Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a &#x27;</span>
<span class="hljs-string">&#x27;replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette &#x27;</span>
<span class="hljs-string">&#x27;Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues &#x27;</span>
<span class="hljs-string">&#x27;and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]&#x27;</span>

<span class="hljs-string">&#x27;[CLS] A qui la Vierge Marie serait-elle apparue en 1858 \xE0 Lourdes en France ? [SEP] Architecturalement, &#x27;</span>
l<span class="hljs-string">&#x27;\xE9cole a un caract\xE8re catholique. Au sommet du d\xF4me dor\xE9 du b\xE2timent principal se trouve une statue dor\xE9e de la Vierge &#x27;</span>
Marie. Imm\xE9diatement devant le b\xE2timent principal et face \xE0 lui, se trouve une statue en cuivre du Christ, les bras <span class="hljs-string">&#x27;&#x27;</span>lev\xE9s<span class="hljs-string">&#x27;&#x27;</span>.
<span class="hljs-string">&#x27;lev\xE9s avec la l\xE9gende &quot; Venite Ad Me Omnes &quot;. A c\xF4t\xE9 du b\xE2timent principal se trouve la basilique du Sacr\xE9-C\u0153ur.
&#x27;</span>C\u0153ur. Imm\xE9diatement derri\xE8re la basilique se trouve la Grotte, un lieu marial de pri\xE8re et de r\xE9flexion. Il s<span class="hljs-string">&#x27;agit d&#x27;</span>une <span class="hljs-string">&#x27;
&#x27;</span>r\xE9plique de la grotte de Lourdes, en France, o\xF9 la Vierge Marie serait apparue \xE0 Sainte Bernadette <span class="hljs-string">&#x27;
Soubirous en 1858. Au bout de l&#x27;</span><span class="hljs-built_in">all</span>\xE9e principale ( et en ligne directe qui passe par <span class="hljs-number">3</span> statues <span class="hljs-string">&#x27;
&#x27;</span>et le D\xF4me d<span class="hljs-string">&#x27;or), se trouve une statue de Marie en pierre, simple et moderne. [SEP]&#x27;</span><span class="hljs-string">&#x27;</span>`}}),Gt=new T({props:{code:`inputs = tokenizer(
    question,
    context,
    max_length=100,
    truncation="only_second",
    stride=50,
    return_overflowing_tokens=True,
)

for ids in inputs["input_ids"]:
    print(tokenizer.decode(ids))`,highlighted:`inputs = tokenizer(
    question,
    context,
    max_length=<span class="hljs-number">100</span>,
    truncation=<span class="hljs-string">&quot;only_second&quot;</span>,
    stride=<span class="hljs-number">50</span>,
    return_overflowing_tokens=<span class="hljs-literal">True</span>,
)

<span class="hljs-keyword">for</span> ids <span class="hljs-keyword">in</span> inputs[<span class="hljs-string">&quot;input_ids&quot;</span>]:
    <span class="hljs-built_in">print</span>(tokenizer.decode(ids))`}}),Wt=new T({props:{code:`'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basi [SEP]'
'[CLS] A qui la Vierge Marie serait-elle apparue en 1858 \xE0 Lourdes en France ? [SEP] Sur le plan architectural, l'\xE9cole a un caract\xE8re catholique. Au sommet du d\xF4me dor\xE9 du b\xE2timent principal se trouve une statue dor\xE9e de la Vierge Marie. Imm\xE9diatement devant le b\xE2timent principal et face \xE0 lui, se trouve une statue en cuivre du Christ, les bras lev\xE9s, avec la l\xE9gende " Venite Ad Me Omnes ". \xC0 c\xF4t\xE9 du b\xE2timent principal se trouve la basilique du Sacr\xE9-C\u0153ur. Imm\xE9diatement derri\xE8re la basi [SEP]''.

'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin [SEP]'
'[CLS] A qui la Vierge Marie serait-elle apparue en 1858 \xE0 Lourdes en France ? [le b\xE2timent principal et face \xE0 lui, une statue en cuivre du Christ aux bras lev\xE9s avec la l\xE9gende " Venite Ad Me Omnes ". \xC0 c\xF4t\xE9 du b\xE2timent principal se trouve la basilique du Sacr\xE9-C\u0153ur. Imm\xE9diatement derri\xE8re la basilique se trouve la Grotte, un lieu marial de pri\xE8re et de r\xE9flexion. Il s'agit d'une r\xE9plique de la grotte de Lourdes, en France, o\xF9 la Vierge [SEP]''.

'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 [SEP]'
'[CLS] A qui la Vierge Marie serait-elle apparue en 1858 \xE0 Lourdes en France ? [A c\xF4t\xE9 du b\xE2timent principal se trouve la basilique du Sacr\xE9-C\u0153ur. Imm\xE9diatement derri\xE8re la basilique se trouve la Grotte, un lieu marial de pri\xE8re et de r\xE9flexion. Il s'agit d'une r\xE9plique de la grotte de Lourdes, en France, o\xF9 la Vierge Marie serait apparue \xE0 Sainte Bernadette Soubirous en 1858. Au bout de l'all\xE9e principale ( et dans une ligne directe qui relie par 3 [SEP]''.

'[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP]. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive ( and in a direct line that connects through 3 statues and the Gold Dome ), is a simple, modern stone statue of Mary. [SEP]'
'[CLS] A qui la Vierge Marie est-elle pr\xE9tendument apparue en 1858 \xE0 Lourdes France ? [SEP]. Il s'agit d'une r\xE9plique de la grotte de Lourdes, en France, o\xF9 la Vierge Marie serait apparue \xE0 Sainte Bernadette Soubirous en 1858. Au bout de l'all\xE9e principale (et dans une ligne directe qui passe par 3 statues et le D\xF4me d'or), se trouve une simple statue de pierre moderne de Marie. [SEP]'`,highlighted:`<span class="hljs-string">&#x27;[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\\&#x27;s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend &quot; Venite Ad Me Omnes &quot;. Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basi [SEP]&#x27;</span>
<span class="hljs-string">&#x27;[CLS] A qui la Vierge Marie serait-elle apparue en 1858 \xE0 Lourdes en France ? [SEP] Sur le plan architectural, l&#x27;</span>\xE9cole a un caract\xE8re catholique. Au sommet du d\xF4me dor\xE9 du b\xE2timent principal se trouve une statue dor\xE9e de la Vierge Marie. Imm\xE9diatement devant le b\xE2timent principal et face \xE0 lui, se trouve une statue en cuivre du Christ, les bras lev\xE9s, avec la l\xE9gende <span class="hljs-string">&quot; Venite Ad Me Omnes &quot;</span>. \xC0 c\xF4t\xE9 du b\xE2timent principal se trouve la basilique du Sacr\xE9-C\u0153ur. Imm\xE9diatement derri\xE8re la basi [SEP]<span class="hljs-string">&#x27;&#x27;</span>.

<span class="hljs-string">&#x27;[CLS] To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? [SEP] the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend &quot; Venite Ad Me Omnes &quot;. Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin [SEP]&#x27;</span>
<span class="hljs-string">&#x27;[CLS] A qui la Vierge Marie serait-elle apparue en 1858 \xE0 Lourdes en France ? [le b\xE2timent principal et face \xE0 lui, une statue en cuivre du Christ aux bras lev\xE9s avec la l\xE9gende &quot; Venite Ad Me Omnes &quot;. \xC0 c\xF4t\xE9 du b\xE2timent principal se trouve la basilique du Sacr\xE9-C\u0153ur. Imm\xE9diatement derri\xE8re la basilique se trouve la Grotte, un lieu marial de pri\xE8re et de r\xE9flexion. Il s&#x27;</span>agit d<span class="hljs-string">&#x27;une r\xE9plique de la grotte de Lourdes, en France, o\xF9 la Vierge [SEP]&#x27;</span><span class="hljs-string">&#x27;.

&#x27;</span>[CLS] To whom did the Virgin Mary allegedly appear <span class="hljs-keyword">in</span> <span class="hljs-number">1858</span> <span class="hljs-keyword">in</span> Lourdes France? [SEP] Next to the Main Building <span class="hljs-keyword">is</span> the Basilica of the Sacred Heart. Immediately behind the basilica <span class="hljs-keyword">is</span> the Grotto, a Marian place of prayer <span class="hljs-keyword">and</span> reflection. It <span class="hljs-keyword">is</span> a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous <span class="hljs-keyword">in</span> <span class="hljs-number">1858.</span> At the end of the main drive ( <span class="hljs-keyword">and</span> <span class="hljs-keyword">in</span> a direct line that connects through <span class="hljs-number">3</span> [SEP]<span class="hljs-string">&#x27;
&#x27;</span>[CLS] A qui la Vierge Marie serait-elle apparue en <span class="hljs-number">1858</span> \xE0 Lourdes en France ? [A c\xF4t\xE9 du b\xE2timent principal se trouve la basilique du Sacr\xE9-C\u0153ur. Imm\xE9diatement derri\xE8re la basilique se trouve la Grotte, un lieu marial de pri\xE8re et de r\xE9flexion. Il s<span class="hljs-string">&#x27;agit d&#x27;</span>une r\xE9plique de la grotte de Lourdes, en France, o\xF9 la Vierge Marie serait apparue \xE0 Sainte Bernadette Soubirous en <span class="hljs-number">1858.</span> Au bout de l<span class="hljs-string">&#x27;all\xE9e principale ( et dans une ligne directe qui relie par 3 [SEP]&#x27;</span><span class="hljs-string">&#x27;.

&#x27;</span>[CLS] To whom did the Virgin Mary allegedly appear <span class="hljs-keyword">in</span> <span class="hljs-number">1858</span> <span class="hljs-keyword">in</span> Lourdes France? [SEP]. It <span class="hljs-keyword">is</span> a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous <span class="hljs-keyword">in</span> <span class="hljs-number">1858.</span> At the end of the main drive ( <span class="hljs-keyword">and</span> <span class="hljs-keyword">in</span> a direct line that connects through <span class="hljs-number">3</span> statues <span class="hljs-keyword">and</span> the Gold Dome ), <span class="hljs-keyword">is</span> a simple, modern stone statue of Mary. [SEP]<span class="hljs-string">&#x27;
&#x27;</span>[CLS] A qui la Vierge Marie est-elle pr\xE9tendument apparue en <span class="hljs-number">1858</span> \xE0 Lourdes France ? [SEP]. Il s<span class="hljs-string">&#x27;agit d&#x27;</span>une r\xE9plique de la grotte de Lourdes, en France, o\xF9 la Vierge Marie serait apparue \xE0 Sainte Bernadette Soubirous en <span class="hljs-number">1858.</span> Au bout de l<span class="hljs-string">&#x27;all\xE9e principale (et dans une ligne directe qui passe par 3 statues et le D\xF4me d&#x27;</span><span class="hljs-keyword">or</span>), se trouve une simple statue de pierre moderne de Marie. [SEP]<span class="hljs-string">&#x27;</span>`}}),Vo=new T({props:{code:`inputs = tokenizer(
    question,
    context,
    max_length=100,
    truncation="only_second",
    stride=50,
    return_overflowing_tokens=True,
    return_offsets_mapping=True,
)
inputs.keys()`,highlighted:`inputs = tokenizer(
    question,
    context,
    max_length=<span class="hljs-number">100</span>,
    truncation=<span class="hljs-string">&quot;only_second&quot;</span>,
    stride=<span class="hljs-number">50</span>,
    return_overflowing_tokens=<span class="hljs-literal">True</span>,
    return_offsets_mapping=<span class="hljs-literal">True</span>,
)
inputs.keys()`}}),Ho=new T({props:{code:"dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])",highlighted:'dict_keys([<span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>, <span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;offset_mapping&#x27;</span>, <span class="hljs-string">&#x27;overflow_to_sample_mapping&#x27;</span>])'}}),Ro=new T({props:{code:'inputs["overflow_to_sample_mapping"]',highlighted:'inputs[<span class="hljs-string">&quot;overflow_to_sample_mapping&quot;</span>]'}}),Uo=new T({props:{code:"[0, 0, 0, 0]",highlighted:'[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]'}}),Qo=new T({props:{code:`inputs = tokenizer(
    raw_datasets["train"][2:6]["question"],
    raw_datasets["train"][2:6]["context"],
    max_length=100,
    truncation="only_second",
    stride=50,
    return_overflowing_tokens=True,
    return_offsets_mapping=True,
)

print(f"The 4 examples gave {len(inputs['input_ids'])} features.")
print(f"Here is where each comes from: {inputs['overflow_to_sample_mapping']}.")`,highlighted:`inputs = tokenizer(
    raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">2</span>:<span class="hljs-number">6</span>][<span class="hljs-string">&quot;question&quot;</span>],
    raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">2</span>:<span class="hljs-number">6</span>][<span class="hljs-string">&quot;context&quot;</span>],
    max_length=<span class="hljs-number">100</span>,
    truncation=<span class="hljs-string">&quot;only_second&quot;</span>,
    stride=<span class="hljs-number">50</span>,
    return_overflowing_tokens=<span class="hljs-literal">True</span>,
    return_offsets_mapping=<span class="hljs-literal">True</span>,
)

<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;The 4 examples gave <span class="hljs-subst">{<span class="hljs-built_in">len</span>(inputs[<span class="hljs-string">&#x27;input_ids&#x27;</span>])}</span> features.&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Here is where each comes from: <span class="hljs-subst">{inputs[<span class="hljs-string">&#x27;overflow_to_sample_mapping&#x27;</span>]}</span>.&quot;</span>)`}}),Go=new T({props:{code:`'The 4 examples gave 19 features.'
'Here is where each comes from: [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3].'`,highlighted:`<span class="hljs-string">&#x27;The 4 examples gave 19 features.&#x27;</span>
<span class="hljs-string">&#x27;Here is where each comes from: [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3].&#x27;</span>`}}),Wo=new T({props:{code:`answers = raw_datasets["train"][2:6]["answers"]
start_positions = []
end_positions = []

for i, offset in enumerate(inputs["offset_mapping"]):
    sample_idx = inputs["overflow_to_sample_mapping"][i]
    answer = answers[sample_idx]
    start_char = answer["answer_start"][0]
    end_char = answer["answer_start"][0] + len(answer["text"][0])
    sequence_ids = inputs.sequence_ids(i)

    # Trouver le d\xE9but et la fin du contexte
    idx = 0
    while sequence_ids[idx] != 1:
        idx += 1
    context_start = idx
    while sequence_ids[idx] == 1:
        idx += 1
    context_end = idx - 1

    # Si la r\xE9ponse n'est pas enti\xE8rement dans le contexte, l'\xE9tiquette est (0, 0).
    if offset[context_start][0] > start_char or offset[context_end][1] < end_char:
        start_positions.append(0)
        end_positions.append(0)
    else:
        # Otherwise it's the start and end token positions
        idx = context_start
        while idx <= context_end and offset[idx][0] <= start_char:
            idx += 1
        start_positions.append(idx - 1)

        idx = context_end
        while idx >= context_start and offset[idx][1] >= end_char:
            idx -= 1
        end_positions.append(idx + 1)

start_positions, end_positions`,highlighted:`answers = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">2</span>:<span class="hljs-number">6</span>][<span class="hljs-string">&quot;answers&quot;</span>]
start_positions = []
end_positions = []

<span class="hljs-keyword">for</span> i, offset <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(inputs[<span class="hljs-string">&quot;offset_mapping&quot;</span>]):
    sample_idx = inputs[<span class="hljs-string">&quot;overflow_to_sample_mapping&quot;</span>][i]
    answer = answers[sample_idx]
    start_char = answer[<span class="hljs-string">&quot;answer_start&quot;</span>][<span class="hljs-number">0</span>]
    end_char = answer[<span class="hljs-string">&quot;answer_start&quot;</span>][<span class="hljs-number">0</span>] + <span class="hljs-built_in">len</span>(answer[<span class="hljs-string">&quot;text&quot;</span>][<span class="hljs-number">0</span>])
    sequence_ids = inputs.sequence_ids(i)

    <span class="hljs-comment"># Trouver le d\xE9but et la fin du contexte</span>
    idx = <span class="hljs-number">0</span>
    <span class="hljs-keyword">while</span> sequence_ids[idx] != <span class="hljs-number">1</span>:
        idx += <span class="hljs-number">1</span>
    context_start = idx
    <span class="hljs-keyword">while</span> sequence_ids[idx] == <span class="hljs-number">1</span>:
        idx += <span class="hljs-number">1</span>
    context_end = idx - <span class="hljs-number">1</span>

    <span class="hljs-comment"># Si la r\xE9ponse n&#x27;est pas enti\xE8rement dans le contexte, l&#x27;\xE9tiquette est (0, 0).</span>
    <span class="hljs-keyword">if</span> offset[context_start][<span class="hljs-number">0</span>] &gt; start_char <span class="hljs-keyword">or</span> offset[context_end][<span class="hljs-number">1</span>] &lt; end_char:
        start_positions.append(<span class="hljs-number">0</span>)
        end_positions.append(<span class="hljs-number">0</span>)
    <span class="hljs-keyword">else</span>:
        <span class="hljs-comment"># Otherwise it&#x27;s the start and end token positions</span>
        idx = context_start
        <span class="hljs-keyword">while</span> idx &lt;= context_end <span class="hljs-keyword">and</span> offset[idx][<span class="hljs-number">0</span>] &lt;= start_char:
            idx += <span class="hljs-number">1</span>
        start_positions.append(idx - <span class="hljs-number">1</span>)

        idx = context_end
        <span class="hljs-keyword">while</span> idx &gt;= context_start <span class="hljs-keyword">and</span> offset[idx][<span class="hljs-number">1</span>] &gt;= end_char:
            idx -= <span class="hljs-number">1</span>
        end_positions.append(idx + <span class="hljs-number">1</span>)

start_positions, end_positions`}}),Jo=new T({props:{code:`([83, 51, 19, 0, 0, 64, 27, 0, 34, 0, 0, 0, 67, 34, 0, 0, 0, 0, 0],
 [85, 53, 21, 0, 0, 70, 33, 0, 40, 0, 0, 0, 68, 35, 0, 0, 0, 0, 0])`,highlighted:`([<span class="hljs-number">83</span>, <span class="hljs-number">51</span>, <span class="hljs-number">19</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">64</span>, <span class="hljs-number">27</span>, <span class="hljs-number">0</span>, <span class="hljs-number">34</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">67</span>, <span class="hljs-number">34</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 [<span class="hljs-number">85</span>, <span class="hljs-number">53</span>, <span class="hljs-number">21</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">70</span>, <span class="hljs-number">33</span>, <span class="hljs-number">0</span>, <span class="hljs-number">40</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">68</span>, <span class="hljs-number">35</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>])`}}),Xo=new T({props:{code:`idx = 0
sample_idx = inputs["overflow_to_sample_mapping"][idx]
answer = answers[sample_idx]["text"][0]

start = start_positions[idx]
end = end_positions[idx]
labeled_answer = tokenizer.decode(inputs["input_ids"][idx][start : end + 1])

print(f"Theoretical answer: {answer}, labels give: {labeled_answer}")`,highlighted:`idx = <span class="hljs-number">0</span>
sample_idx = inputs[<span class="hljs-string">&quot;overflow_to_sample_mapping&quot;</span>][idx]
answer = answers[sample_idx][<span class="hljs-string">&quot;text&quot;</span>][<span class="hljs-number">0</span>]

start = start_positions[idx]
end = end_positions[idx]
labeled_answer = tokenizer.decode(inputs[<span class="hljs-string">&quot;input_ids&quot;</span>][idx][start : end + <span class="hljs-number">1</span>])

<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Theoretical answer: <span class="hljs-subst">{answer}</span>, labels give: <span class="hljs-subst">{labeled_answer}</span>&quot;</span>)`}}),Ko=new T({props:{code:"'Theoretical answer: the Main Building, labels give: the Main Building'",highlighted:'<span class="hljs-string">&#x27;Theoretical answer: the Main Building, labels give: the Main Building&#x27;</span>'}}),Yo=new T({props:{code:`idx = 4
sample_idx = inputs["overflow_to_sample_mapping"][idx]
answer = answers[sample_idx]["text"][0]

decoded_example = tokenizer.decode(inputs["input_ids"][idx])
print(f"Theoretical answer: {answer}, decoded example: {decoded_example}")`,highlighted:`idx = <span class="hljs-number">4</span>
sample_idx = inputs[<span class="hljs-string">&quot;overflow_to_sample_mapping&quot;</span>][idx]
answer = answers[sample_idx][<span class="hljs-string">&quot;text&quot;</span>][<span class="hljs-number">0</span>]

decoded_example = tokenizer.decode(inputs[<span class="hljs-string">&quot;input_ids&quot;</span>][idx])
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Theoretical answer: <span class="hljs-subst">{answer}</span>, decoded example: <span class="hljs-subst">{decoded_example}</span>&quot;</span>)`}}),Zo=new T({props:{code:`'Theoretical answer: a Marian place of prayer and reflection, decoded example: [CLS] What is the Grotto at Notre Dame? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend " Venite Ad Me Omnes ". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grot [SEP]'`,highlighted:'<span class="hljs-string">&#x27;Theoretical answer: a Marian place of prayer and reflection, decoded example: [CLS] What is the Grotto at Notre Dame? [SEP] Architecturally, the school has a Catholic character. Atop the Main Building\\&#x27;s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend &quot; Venite Ad Me Omnes &quot;. Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grot [SEP]&#x27;</span>'}}),La=new Rd({props:{$$slots:{default:[Xb]},$$scope:{ctx:H}}}),er=new T({props:{code:`max_length = 384
stride = 128


def preprocess_training_examples(examples):
    questions = [q.strip() for q in examples["question"]]
    inputs = tokenizer(
        questions,
        examples["context"],
        max_length=max_length,
        truncation="only_second",
        stride=stride,
        return_overflowing_tokens=True,
        return_offsets_mapping=True,
        padding="max_length",
    )

    offset_mapping = inputs.pop("offset_mapping")
    sample_map = inputs.pop("overflow_to_sample_mapping")
    answers = examples["answers"]
    start_positions = []
    end_positions = []

    for i, offset in enumerate(offset_mapping):
        sample_idx = sample_map[i]
        answer = answers[sample_idx]
        start_char = answer["answer_start"][0]
        end_char = answer["answer_start"][0] + len(answer["text"][0])
        sequence_ids = inputs.sequence_ids(i)

        # Trouver le d\xE9but et la fin du contexte
        idx = 0
        while sequence_ids[idx] != 1:
            idx += 1
        context_start = idx
        while sequence_ids[idx] == 1:
            idx += 1
        context_end = idx - 1

        # Si la r\xE9ponse n'est pas enti\xE8rement dans le contexte, l'\xE9tiquette est (0, 0).
        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:
            start_positions.append(0)
            end_positions.append(0)
        else:
            # Otherwise it's the start and end token positions
            idx = context_start
            while idx <= context_end and offset[idx][0] <= start_char:
                idx += 1
            start_positions.append(idx - 1)

            idx = context_end
            while idx >= context_start and offset[idx][1] >= end_char:
                idx -= 1
            end_positions.append(idx + 1)

    inputs["start_positions"] = start_positions
    inputs["end_positions"] = end_positions
    return inputs`,highlighted:`max_length = <span class="hljs-number">384</span>
stride = <span class="hljs-number">128</span>


<span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_training_examples</span>(<span class="hljs-params">examples</span>):
    questions = [q.strip() <span class="hljs-keyword">for</span> q <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;question&quot;</span>]]
    inputs = tokenizer(
        questions,
        examples[<span class="hljs-string">&quot;context&quot;</span>],
        max_length=max_length,
        truncation=<span class="hljs-string">&quot;only_second&quot;</span>,
        stride=stride,
        return_overflowing_tokens=<span class="hljs-literal">True</span>,
        return_offsets_mapping=<span class="hljs-literal">True</span>,
        padding=<span class="hljs-string">&quot;max_length&quot;</span>,
    )

    offset_mapping = inputs.pop(<span class="hljs-string">&quot;offset_mapping&quot;</span>)
    sample_map = inputs.pop(<span class="hljs-string">&quot;overflow_to_sample_mapping&quot;</span>)
    answers = examples[<span class="hljs-string">&quot;answers&quot;</span>]
    start_positions = []
    end_positions = []

    <span class="hljs-keyword">for</span> i, offset <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(offset_mapping):
        sample_idx = sample_map[i]
        answer = answers[sample_idx]
        start_char = answer[<span class="hljs-string">&quot;answer_start&quot;</span>][<span class="hljs-number">0</span>]
        end_char = answer[<span class="hljs-string">&quot;answer_start&quot;</span>][<span class="hljs-number">0</span>] + <span class="hljs-built_in">len</span>(answer[<span class="hljs-string">&quot;text&quot;</span>][<span class="hljs-number">0</span>])
        sequence_ids = inputs.sequence_ids(i)

        <span class="hljs-comment"># Trouver le d\xE9but et la fin du contexte</span>
        idx = <span class="hljs-number">0</span>
        <span class="hljs-keyword">while</span> sequence_ids[idx] != <span class="hljs-number">1</span>:
            idx += <span class="hljs-number">1</span>
        context_start = idx
        <span class="hljs-keyword">while</span> sequence_ids[idx] == <span class="hljs-number">1</span>:
            idx += <span class="hljs-number">1</span>
        context_end = idx - <span class="hljs-number">1</span>

        <span class="hljs-comment"># Si la r\xE9ponse n&#x27;est pas enti\xE8rement dans le contexte, l&#x27;\xE9tiquette est (0, 0).</span>
        <span class="hljs-keyword">if</span> offset[context_start][<span class="hljs-number">0</span>] &gt; start_char <span class="hljs-keyword">or</span> offset[context_end][<span class="hljs-number">1</span>] &lt; end_char:
            start_positions.append(<span class="hljs-number">0</span>)
            end_positions.append(<span class="hljs-number">0</span>)
        <span class="hljs-keyword">else</span>:
            <span class="hljs-comment"># Otherwise it&#x27;s the start and end token positions</span>
            idx = context_start
            <span class="hljs-keyword">while</span> idx &lt;= context_end <span class="hljs-keyword">and</span> offset[idx][<span class="hljs-number">0</span>] &lt;= start_char:
                idx += <span class="hljs-number">1</span>
            start_positions.append(idx - <span class="hljs-number">1</span>)

            idx = context_end
            <span class="hljs-keyword">while</span> idx &gt;= context_start <span class="hljs-keyword">and</span> offset[idx][<span class="hljs-number">1</span>] &gt;= end_char:
                idx -= <span class="hljs-number">1</span>
            end_positions.append(idx + <span class="hljs-number">1</span>)

    inputs[<span class="hljs-string">&quot;start_positions&quot;</span>] = start_positions
    inputs[<span class="hljs-string">&quot;end_positions&quot;</span>] = end_positions
    <span class="hljs-keyword">return</span> inputs`}}),sr=new T({props:{code:`train_dataset = raw_datasets["train"].map(
    preprocess_training_examples,
    batched=True,
    remove_columns=raw_datasets["train"].column_names,
)
len(raw_datasets["train"]), len(train_dataset)`,highlighted:`train_dataset = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].<span class="hljs-built_in">map</span>(
    preprocess_training_examples,
    batched=<span class="hljs-literal">True</span>,
    remove_columns=raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].column_names,
)
<span class="hljs-built_in">len</span>(raw_datasets[<span class="hljs-string">&quot;train&quot;</span>]), <span class="hljs-built_in">len</span>(train_dataset)`}}),tr=new T({props:{code:"(87599, 88729)",highlighted:'(<span class="hljs-number">87599</span>, <span class="hljs-number">88729</span>)'}}),nr=new cs({}),ar=new T({props:{code:`def preprocess_validation_examples(examples):
    questions = [q.strip() for q in examples["question"]]
    inputs = tokenizer(
        questions,
        examples["context"],
        max_length=max_length,
        truncation="only_second",
        stride=stride,
        return_overflowing_tokens=True,
        return_offsets_mapping=True,
        padding="max_length",
    )

    sample_map = inputs.pop("overflow_to_sample_mapping")
    example_ids = []

    for i in range(len(inputs["input_ids"])):
        sample_idx = sample_map[i]
        example_ids.append(examples["id"][sample_idx])

        sequence_ids = inputs.sequence_ids(i)
        offset = inputs["offset_mapping"][i]
        inputs["offset_mapping"][i] = [
            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)
        ]

    inputs["example_id"] = example_ids
    return inputs`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_validation_examples</span>(<span class="hljs-params">examples</span>):
    questions = [q.strip() <span class="hljs-keyword">for</span> q <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;question&quot;</span>]]
    inputs = tokenizer(
        questions,
        examples[<span class="hljs-string">&quot;context&quot;</span>],
        max_length=max_length,
        truncation=<span class="hljs-string">&quot;only_second&quot;</span>,
        stride=stride,
        return_overflowing_tokens=<span class="hljs-literal">True</span>,
        return_offsets_mapping=<span class="hljs-literal">True</span>,
        padding=<span class="hljs-string">&quot;max_length&quot;</span>,
    )

    sample_map = inputs.pop(<span class="hljs-string">&quot;overflow_to_sample_mapping&quot;</span>)
    example_ids = []

    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(inputs[<span class="hljs-string">&quot;input_ids&quot;</span>])):
        sample_idx = sample_map[i]
        example_ids.append(examples[<span class="hljs-string">&quot;id&quot;</span>][sample_idx])

        sequence_ids = inputs.sequence_ids(i)
        offset = inputs[<span class="hljs-string">&quot;offset_mapping&quot;</span>][i]
        inputs[<span class="hljs-string">&quot;offset_mapping&quot;</span>][i] = [
            o <span class="hljs-keyword">if</span> sequence_ids[k] == <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">for</span> k, o <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(offset)
        ]

    inputs[<span class="hljs-string">&quot;example_id&quot;</span>] = example_ids
    <span class="hljs-keyword">return</span> inputs`}}),or=new T({props:{code:`validation_dataset = raw_datasets["validation"].map(
    preprocess_validation_examples,
    batched=True,
    remove_columns=raw_datasets["validation"].column_names,
)
len(raw_datasets["validation"]), len(validation_dataset)`,highlighted:`validation_dataset = raw_datasets[<span class="hljs-string">&quot;validation&quot;</span>].<span class="hljs-built_in">map</span>(
    preprocess_validation_examples,
    batched=<span class="hljs-literal">True</span>,
    remove_columns=raw_datasets[<span class="hljs-string">&quot;validation&quot;</span>].column_names,
)
<span class="hljs-built_in">len</span>(raw_datasets[<span class="hljs-string">&quot;validation&quot;</span>]), <span class="hljs-built_in">len</span>(validation_dataset)`}}),rr=new T({props:{code:"(10570, 10822)",highlighted:'(<span class="hljs-number">10570</span>, <span class="hljs-number">10822</span>)'}});const z_=[Yb,Kb],zr=[];function T_(e,u){return e[0]==="pt"?0:1}ut=T_(H),pt=zr[ut]=z_[ut](H),lr=new cs({});const L_=[eg,Zb],Tr=[];function N_(e,u){return e[0]==="pt"?0:1}dt=N_(H),ct=Tr[dt]=L_[dt](H),dr=new T({props:{code:`small_eval_set = raw_datasets["validation"].select(range(100))
trained_checkpoint = "distilbert-base-cased-distilled-squad"

tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)
eval_set = small_eval_set.map(
    preprocess_validation_examples,
    batched=True,
    remove_columns=raw_datasets["validation"].column_names,
)`,highlighted:`small_eval_set = raw_datasets[<span class="hljs-string">&quot;validation&quot;</span>].select(<span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>))
trained_checkpoint = <span class="hljs-string">&quot;distilbert-base-cased-distilled-squad&quot;</span>

tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)
eval_set = small_eval_set.<span class="hljs-built_in">map</span>(
    preprocess_validation_examples,
    batched=<span class="hljs-literal">True</span>,
    remove_columns=raw_datasets[<span class="hljs-string">&quot;validation&quot;</span>].column_names,
)`}}),cr=new T({props:{code:"tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)",highlighted:"tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"}});const O_=[tg,sg],Lr=[];function I_(e,u){return e[0]==="pt"?0:1}mt=I_(H),ft=Lr[mt]=O_[mt](H),mr=new T({props:{code:`import collections

example_to_features = collections.defaultdict(list)
for idx, feature in enumerate(eval_set):
    example_to_features[feature["example_id"]].append(idx)`,highlighted:`<span class="hljs-keyword">import</span> collections

example_to_features = collections.defaultdict(<span class="hljs-built_in">list</span>)
<span class="hljs-keyword">for</span> idx, feature <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(eval_set):
    example_to_features[feature[<span class="hljs-string">&quot;example_id&quot;</span>]].append(idx)`}}),_r=new T({props:{code:`import numpy as np

n_best = 20
max_answer_length = 30
predicted_answers = []

for example in small_eval_set:
    example_id = example["id"]
    context = example["context"]
    answers = []

    for feature_index in example_to_features[example_id]:
        start_logit = start_logits[feature_index]
        end_logit = end_logits[feature_index]
        offsets = eval_set["offset_mapping"][feature_index]

        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()
        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()
        for start_index in start_indexes:
            for end_index in end_indexes:
                # Ignore les r\xE9ponses qui ne sont pas enti\xE8rement dans le contexte
                if offsets[start_index] is None or offsets[end_index] is None:
                    continue
                # Ignorer les r\xE9ponses dont la longueur est soit < 0 soit > max_answer_length.
                if (
                    end_index < start_index
                    or end_index - start_index + 1 > max_answer_length
                ):
                    continue

                answers.append(
                    {
                        "text": context[offsets[start_index][0] : offsets[end_index][1]],
                        "logit_score": start_logit[start_index] + end_logit[end_index],
                    }
                )

    best_answer = max(answers, key=lambda x: x["logit_score"])
    predicted_answers.append({"id": example_id, "prediction_text": best_answer["text"]})`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

n_best = <span class="hljs-number">20</span>
max_answer_length = <span class="hljs-number">30</span>
predicted_answers = []

<span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> small_eval_set:
    example_id = example[<span class="hljs-string">&quot;id&quot;</span>]
    context = example[<span class="hljs-string">&quot;context&quot;</span>]
    answers = []

    <span class="hljs-keyword">for</span> feature_index <span class="hljs-keyword">in</span> example_to_features[example_id]:
        start_logit = start_logits[feature_index]
        end_logit = end_logits[feature_index]
        offsets = eval_set[<span class="hljs-string">&quot;offset_mapping&quot;</span>][feature_index]

        start_indexes = np.argsort(start_logit)[-<span class="hljs-number">1</span> : -n_best - <span class="hljs-number">1</span> : -<span class="hljs-number">1</span>].tolist()
        end_indexes = np.argsort(end_logit)[-<span class="hljs-number">1</span> : -n_best - <span class="hljs-number">1</span> : -<span class="hljs-number">1</span>].tolist()
        <span class="hljs-keyword">for</span> start_index <span class="hljs-keyword">in</span> start_indexes:
            <span class="hljs-keyword">for</span> end_index <span class="hljs-keyword">in</span> end_indexes:
                <span class="hljs-comment"># Ignore les r\xE9ponses qui ne sont pas enti\xE8rement dans le contexte</span>
                <span class="hljs-keyword">if</span> offsets[start_index] <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> offsets[end_index] <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
                    <span class="hljs-keyword">continue</span>
                <span class="hljs-comment"># Ignorer les r\xE9ponses dont la longueur est soit &lt; 0 soit &gt; max_answer_length.</span>
                <span class="hljs-keyword">if</span> (
                    end_index &lt; start_index
                    <span class="hljs-keyword">or</span> end_index - start_index + <span class="hljs-number">1</span> &gt; max_answer_length
                ):
                    <span class="hljs-keyword">continue</span>

                answers.append(
                    {
                        <span class="hljs-string">&quot;text&quot;</span>: context[offsets[start_index][<span class="hljs-number">0</span>] : offsets[end_index][<span class="hljs-number">1</span>]],
                        <span class="hljs-string">&quot;logit_score&quot;</span>: start_logit[start_index] + end_logit[end_index],
                    }
                )

    best_answer = <span class="hljs-built_in">max</span>(answers, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&quot;logit_score&quot;</span>])
    predicted_answers.append({<span class="hljs-string">&quot;id&quot;</span>: example_id, <span class="hljs-string">&quot;prediction_text&quot;</span>: best_answer[<span class="hljs-string">&quot;text&quot;</span>]})`}}),hr=new T({props:{code:`from datasets import load_metric

metric = load_metric("squad")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric

metric = load_metric(<span class="hljs-string">&quot;squad&quot;</span>)`}}),vr=new T({props:{code:`theoretical_answers = [
    {"id": ex["id"], "answers": ex["answers"]} for ex in small_eval_set
]`,highlighted:`theoretical_answers = [
    {<span class="hljs-string">&quot;id&quot;</span>: ex[<span class="hljs-string">&quot;id&quot;</span>], <span class="hljs-string">&quot;answers&quot;</span>: ex[<span class="hljs-string">&quot;answers&quot;</span>]} <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> small_eval_set
]`}}),br=new T({props:{code:`print(predicted_answers[0])
print(theoretical_answers[0])`,highlighted:`<span class="hljs-built_in">print</span>(predicted_answers[<span class="hljs-number">0</span>])
<span class="hljs-built_in">print</span>(theoretical_answers[<span class="hljs-number">0</span>])`}}),gr=new T({props:{code:`{'id': '56be4db0acb8001400a502ec', 'prediction_text': 'Denver Broncos'}
{'id': '56be4db0acb8001400a502ec', 'answers': {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'], 'answer_start': [177, 177, 177]}}`,highlighted:`{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-string">&#x27;56be4db0acb8001400a502ec&#x27;</span>, <span class="hljs-string">&#x27;prediction_text&#x27;</span>: <span class="hljs-string">&#x27;Denver Broncos&#x27;</span>}
{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-string">&#x27;56be4db0acb8001400a502ec&#x27;</span>, <span class="hljs-string">&#x27;answers&#x27;</span>: {<span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&#x27;Denver Broncos&#x27;</span>, <span class="hljs-string">&#x27;Denver Broncos&#x27;</span>, <span class="hljs-string">&#x27;Denver Broncos&#x27;</span>], <span class="hljs-string">&#x27;answer_start&#x27;</span>: [<span class="hljs-number">177</span>, <span class="hljs-number">177</span>, <span class="hljs-number">177</span>]}}`}}),qr=new T({props:{code:"metric.compute(predictions=predicted_answers, references=theoretical_answers)",highlighted:"metric.compute(predictions=predicted_answers, references=theoretical_answers)"}}),xr=new T({props:{code:"{'exact_match': 83.0, 'f1': 88.25}",highlighted:'{<span class="hljs-string">&#x27;exact_match&#x27;</span>: <span class="hljs-number">83.0</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">88.25</span>}'}});function B_(e,u){return e[0]==="pt"?ag:ng}let hd=B_(H),Un=hd(H);wr=new T({props:{code:`from tqdm.auto import tqdm


def compute_metrics(start_logits, end_logits, features, examples):
    example_to_features = collections.defaultdict(list)
    for idx, feature in enumerate(features):
        example_to_features[feature["example_id"]].append(idx)

    predicted_answers = []
    for example in tqdm(examples):
        example_id = example["id"]
        context = example["context"]
        answers = []

        # Parcourir en boucle toutes les fonctionnalit\xE9s associ\xE9es \xE0 cet exemple
        for feature_index in example_to_features[example_id]:
            start_logit = start_logits[feature_index]
            end_logit = end_logits[feature_index]
            offsets = features[feature_index]["offset_mapping"]

            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()
            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()
            for start_index in start_indexes:
                for end_index in end_indexes:
                    # Ignore les r\xE9ponses qui ne sont pas enti\xE8rement dans le contexte
                    if offsets[start_index] is None or offsets[end_index] is None:
                        continue
                    # Ignore les r\xE9ponses dont la longueur est soit < 0, soit > max_answer_length.
                    if (
                        end_index < start_index
                        or end_index - start_index + 1 > max_answer_length
                    ):
                        continue

                    answer = {
                        "text": context[offsets[start_index][0] : offsets[end_index][1]],
                        "logit_score": start_logit[start_index] + end_logit[end_index],
                    }
                    answers.append(answer)

        # S\xE9lectionne la r\xE9ponse avec le meilleur score
        if len(answers) > 0:
            best_answer = max(answers, key=lambda x: x["logit_score"])
            predicted_answers.append(
                {"id": example_id, "prediction_text": best_answer["text"]}
            )
        else:
            predicted_answers.append({"id": example_id, "prediction_text": ""})

    theoretical_answers = [{"id": ex["id"], "answers": ex["answers"]} for ex in examples]
    return metric.compute(predictions=predicted_answers, references=theoretical_answers)`,highlighted:`<span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">start_logits, end_logits, features, examples</span>):
    example_to_features = collections.defaultdict(<span class="hljs-built_in">list</span>)
    <span class="hljs-keyword">for</span> idx, feature <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(features):
        example_to_features[feature[<span class="hljs-string">&quot;example_id&quot;</span>]].append(idx)

    predicted_answers = []
    <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> tqdm(examples):
        example_id = example[<span class="hljs-string">&quot;id&quot;</span>]
        context = example[<span class="hljs-string">&quot;context&quot;</span>]
        answers = []

        <span class="hljs-comment"># Parcourir en boucle toutes les fonctionnalit\xE9s associ\xE9es \xE0 cet exemple</span>
        <span class="hljs-keyword">for</span> feature_index <span class="hljs-keyword">in</span> example_to_features[example_id]:
            start_logit = start_logits[feature_index]
            end_logit = end_logits[feature_index]
            offsets = features[feature_index][<span class="hljs-string">&quot;offset_mapping&quot;</span>]

            start_indexes = np.argsort(start_logit)[-<span class="hljs-number">1</span> : -n_best - <span class="hljs-number">1</span> : -<span class="hljs-number">1</span>].tolist()
            end_indexes = np.argsort(end_logit)[-<span class="hljs-number">1</span> : -n_best - <span class="hljs-number">1</span> : -<span class="hljs-number">1</span>].tolist()
            <span class="hljs-keyword">for</span> start_index <span class="hljs-keyword">in</span> start_indexes:
                <span class="hljs-keyword">for</span> end_index <span class="hljs-keyword">in</span> end_indexes:
                    <span class="hljs-comment"># Ignore les r\xE9ponses qui ne sont pas enti\xE8rement dans le contexte</span>
                    <span class="hljs-keyword">if</span> offsets[start_index] <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">or</span> offsets[end_index] <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
                        <span class="hljs-keyword">continue</span>
                    <span class="hljs-comment"># Ignore les r\xE9ponses dont la longueur est soit &lt; 0, soit &gt; max_answer_length.</span>
                    <span class="hljs-keyword">if</span> (
                        end_index &lt; start_index
                        <span class="hljs-keyword">or</span> end_index - start_index + <span class="hljs-number">1</span> &gt; max_answer_length
                    ):
                        <span class="hljs-keyword">continue</span>

                    answer = {
                        <span class="hljs-string">&quot;text&quot;</span>: context[offsets[start_index][<span class="hljs-number">0</span>] : offsets[end_index][<span class="hljs-number">1</span>]],
                        <span class="hljs-string">&quot;logit_score&quot;</span>: start_logit[start_index] + end_logit[end_index],
                    }
                    answers.append(answer)

        <span class="hljs-comment"># S\xE9lectionne la r\xE9ponse avec le meilleur score</span>
        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(answers) &gt; <span class="hljs-number">0</span>:
            best_answer = <span class="hljs-built_in">max</span>(answers, key=<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&quot;logit_score&quot;</span>])
            predicted_answers.append(
                {<span class="hljs-string">&quot;id&quot;</span>: example_id, <span class="hljs-string">&quot;prediction_text&quot;</span>: best_answer[<span class="hljs-string">&quot;text&quot;</span>]}
            )
        <span class="hljs-keyword">else</span>:
            predicted_answers.append({<span class="hljs-string">&quot;id&quot;</span>: example_id, <span class="hljs-string">&quot;prediction_text&quot;</span>: <span class="hljs-string">&quot;&quot;</span>})

    theoretical_answers = [{<span class="hljs-string">&quot;id&quot;</span>: ex[<span class="hljs-string">&quot;id&quot;</span>], <span class="hljs-string">&quot;answers&quot;</span>: ex[<span class="hljs-string">&quot;answers&quot;</span>]} <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> examples]
    <span class="hljs-keyword">return</span> metric.compute(predictions=predicted_answers, references=theoretical_answers)`}}),jr=new T({props:{code:"compute_metrics(start_logits, end_logits, eval_set, small_eval_set)",highlighted:"compute_metrics(start_logits, end_logits, eval_set, small_eval_set)"}}),kr=new T({props:{code:"{'exact_match': 83.0, 'f1': 88.25}",highlighted:'{<span class="hljs-string">&#x27;exact_match&#x27;</span>: <span class="hljs-number">83.0</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">88.25</span>}'}}),Er=new cs({});const F_=[rg,og],Nr=[];function V_(e,u){return e[0]==="pt"?0:1}_t=V_(H),ht=Nr[_t]=F_[_t](H),yr=new T({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`}}),Cr=new T({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}});const H_=[ig,lg],Or=[];function R_(e,u){return e[0]==="pt"?0:1}vt=R_(H),bt=Or[vt]=H_[vt](H);const U_=[pg,ug],Ir=[];function Q_(e,u){return e[0]==="pt"?0:1}gt=Q_(H),qt=Ir[gt]=U_[gt](H);const G_=[mg,cg],Br=[];function W_(e,u){return e[0]==="pt"?0:1}xt=W_(H),$t=Br[xt]=G_[xt](H),Pr=new T({props:{code:"{'exact_match': 81.18259224219489, 'f1': 88.67381321905516}",highlighted:'{<span class="hljs-string">&#x27;exact_match&#x27;</span>: <span class="hljs-number">81.18259224219489</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">88.67381321905516</span>}'}});let _e=H[0]==="pt"&&Ob();Wa=new Rd({props:{$$slots:{default:[fg]},$$scope:{ctx:H}}});let he=H[0]==="pt"&&Ib();return Ar=new cs({}),Sr=new T({props:{code:`from transformers import pipeline

# Replace this with your own checkpoint
model_checkpoint = "huggingface-course/bert-finetuned-squad"
question_answerer = pipeline("question-answering", model=model_checkpoint)

context = """
\u{1F917} Transformers is backed by the three most popular deep learning libraries \u2014 Jax, PyTorch and TensorFlow \u2014 with a seamless integration
between them. It's straightforward to train your models with one before loading them for inference with the other.
"""
question = "Which deep learning libraries back \u{1F917} Transformers?"
question_answerer(question=question, context=context)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-comment"># Replace this with your own checkpoint</span>
model_checkpoint = <span class="hljs-string">&quot;huggingface-course/bert-finetuned-squad&quot;</span>
question_answerer = pipeline(<span class="hljs-string">&quot;question-answering&quot;</span>, model=model_checkpoint)

context = <span class="hljs-string">&quot;&quot;&quot;
\u{1F917} Transformers is backed by the three most popular deep learning libraries \u2014 Jax, PyTorch and TensorFlow \u2014 with a seamless integration
between them. It&#x27;s straightforward to train your models with one before loading them for inference with the other.
&quot;&quot;&quot;</span>
question = <span class="hljs-string">&quot;Which deep learning libraries back \u{1F917} Transformers?&quot;</span>
question_answerer(question=question, context=context)`}}),Dr=new T({props:{code:`{'score': 0.9979003071784973,
 'start': 78,
 'end': 105,
 'answer': 'Jax, PyTorch and TensorFlow'}`,highlighted:`{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9979003071784973</span>,
 <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">78</span>,
 <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">105</span>,
 <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;Jax, PyTorch and TensorFlow&#x27;</span>}`}}),{c(){p=o("meta"),b=d(),j(f.$$.fragment),C=d(),S=o("h1"),g=o("a"),$=o("span"),j(q.$$.fragment),_=d(),z=o("span"),x=n("R\xE9ponse aux questions"),D=d(),N.c(),P=d(),w=o("p"),U=n("Il est temps de s\u2019int\xE9resser \xE0 la r\xE9ponse aux questions ! Cette t\xE2che peut prendre plusieurs formes, mais celle sur laquelle nous allons nous concentrer dans cette section est appel\xE9e r\xE9ponse aux questions "),V=o("em"),F=n("extractives"),M=n(". Il s\u2019agit de poser des questions sur un document et d\u2019identifier les r\xE9ponses sous forme de \u201Cmorceaux de texte\u201D dans le document lui-m\xEAme."),B=d(),j(G.$$.fragment),ee=d(),Q=o("p"),W=n("Nous allons affiner un mod\xE8le BERT sur le "),K=o("a"),Y=n("jeu de donn\xE9es SQuAD"),O=n(", qui consiste en des questions pos\xE9es par des "),X=o("em"),$e=n("crowdworkers"),de=n(" sur un ensemble d\u2019articles de Wikipedia. Cela nous donnera un mod\xE8le capable de calculer des pr\xE9dictions comme celle-ci :"),J=d(),se=o("iframe"),ve=d(),re=o("iframe"),Xe=d(),R=o("p"),Z=n("Il s\u2019agit en fait de la pr\xE9sentation du mod\xE8le qui a \xE9t\xE9 entra\xEEn\xE9 et t\xE9l\xE9charg\xE9 sur le "),fs=o("em"),jt=n("Hub"),_s=n(" \xE0 l\u2019aide du code pr\xE9sent\xE9 dans cette section. Vous pouvez le trouver et v\xE9rifier les pr\xE9dictions "),Ae=o("a"),Se=n("ici"),hs=d(),j(ce.$$.fragment),De=d(),me=o("h2"),be=o("a"),Ke=o("span"),j(je.$$.fragment),Gn=d(),Me=o("span"),ao=n("Pr\xE9paration des donn\xE9es"),kt=d(),ze=o("p"),oo=n("Le jeu de donn\xE9es le plus utilis\xE9 comme r\xE9f\xE9rence acad\xE9mique pour la r\xE9ponse extractive aux questions est "),vs=o("a"),Vs=n("SQuAD"),Wn=n(", c\u2019est donc celui que nous utiliserons ici. Il existe \xE9galement une r\xE9f\xE9rence plus difficile "),te=o("a"),ro=n("SQuAD v2"),dn=n(", qui comprend des questions sans r\xE9ponse. Tant que votre propre jeu de donn\xE9es contient une colonne pour les contextes, une colonne pour les questions et une colonne pour les r\xE9ponses, vous devriez \xEAtre en mesure d\u2019adapter les \xE9tapes ci-dessous."),Jn=d(),Ye=o("h3"),Te=o("a"),cn=o("span"),j(Hs.$$.fragment),mn=d(),fn=o("span"),lo=n("Le jeu de donn\xE9es SQuAD"),Et=d(),bs=o("p"),io=n("Comme d\u2019habitude, nous pouvons t\xE9l\xE9charger et mettre en cache le jeu de donn\xE9es en une seule \xE9tape gr\xE2ce \xE0 "),Rs=o("code"),uo=n("load_dataset()"),po=n(" :"),yt=d(),j(Us.$$.fragment),Xn=d(),gs=o("p"),co=n("Nous pouvons alors jeter un coup d\u2019\u0153il \xE0 cet objet pour en savoir plus sur le jeu de donn\xE9es SQuAD :"),Kn=d(),j(qs.$$.fragment),xs=d(),j($s.$$.fragment),ke=d(),ge=o("p"),_n=n("On dirait que nous avons tout ce dont nous avons besoin avec les champs "),hn=o("code"),mo=n("context"),vn=n(", "),bn=o("code"),fo=n("question"),Yn=n(" et "),Ze=o("code"),Zn=n("answers"),qe=n(", alors imprimons-les pour le premier \xE9l\xE9ment de notre ensemble d\u2019entra\xEEnement :"),ea=d(),j(es.$$.fragment),sa=d(),j(Qs.$$.fragment),Ct=d(),ae=o("p"),_o=n("Les champs "),Gs=o("code"),ho=n("context"),vo=n(" et "),Pt=o("code"),Ws=n("question"),ta=n(" sont tr\xE8s simples \xE0 utiliser. Le champ "),ss=o("code"),na=n("answers"),At=n(" est un peu plus d\xE9licat car il compile un dictionnaire avec deux champs qui sont tous deux des listes. C\u2019est le format qui sera attendu par la m\xE9trique "),gn=o("code"),aa=n("squad"),Js=n(" lors de l\u2019\xE9valuation ; si vous utilisez vos propres donn\xE9es, vous n\u2019avez pas n\xE9cessairement besoin de vous soucier de mettre les r\xE9ponses dans le m\xEAme format. Le champ "),St=o("code"),Le=n("text"),bo=n(" est assez \xE9vident, et le champ "),Xs=o("code"),go=n("answer_start"),qo=n(" contient l\u2019indice du caract\xE8re de d\xE9part de chaque r\xE9ponse dans le contexte."),Dt=d(),ws=o("p"),xo=n("Pendant l\u2019entra\xEEnement, il n\u2019y a qu\u2019une seule r\xE9ponse possible. Nous pouvons v\xE9rifier cela en utilisant la m\xE9thode "),Mt=o("code"),ts=n("Dataset.filter()"),js=n(" :"),zt=d(),j(Ee.$$.fragment),oa=d(),j(ns.$$.fragment),ra=d(),Ks=o("p"),Tt=n("Pour l\u2019\xE9valuation, cependant, il existe plusieurs r\xE9ponses possibles pour chaque \xE9chantillon, qui peuvent \xEAtre identiques ou diff\xE9rentes :"),la=d(),j(ks.$$.fragment),ye=d(),j(Ce.$$.fragment),ia=d(),Ne=o("p"),$o=n("Nous ne nous plongerons pas dans le script d\u2019\xE9valuation car tout sera envelopp\xE9 par une m\xE9trique \u{1F917} "),qn=o("em"),wo=n("Datasets"),Pe=n(" pour nous, mais la version courte est que certaines des questions ont plusieurs r\xE9ponses possibles, et ce script va comparer une r\xE9ponse pr\xE9dite \xE0 toutes les r\xE9ponses acceptables et prendre le meilleur score. Si nous regardons l\u2019\xE9chantillon de l\u2019indice 2, par exemple :"),ua=d(),j(as.$$.fragment),pa=d(),j(Ys.$$.fragment),Lt=d(),Nt=o("p"),jo=n("nous pouvons voir que la r\xE9ponse peut effectivement \xEAtre l\u2019une des trois possibilit\xE9s que nous avons vues pr\xE9c\xE9demment."),Ot=d(),os=o("h3"),Es=o("a"),xn=o("span"),j(le.$$.fragment),ko=d(),Zs=o("span"),Eo=n("Traitement des donn\xE9es d'entra\xEEnement"),da=d(),j(rs.$$.fragment),ca=d(),ys=o("p"),$n=n("Commen\xE7ons par le pr\xE9traitement des donn\xE9es d\u2019entra\xEEnement. La partie la plus difficile sera de g\xE9n\xE9rer des \xE9tiquettes pour la r\xE9ponse \xE0 la question, qui seront les positions de d\xE9but et de fin des "),wn=o("em"),yo=n("tokens"),jn=n(" correspondant \xE0 la r\xE9ponse dans le contexte."),ma=d(),Cs=o("p"),fa=n("Mais ne nous emballons pas. Tout d\u2019abord, nous devons convertir le texte de l\u2019entr\xE9e en identifiants que le mod\xE8le peut comprendre, en utilisant un "),Ps=o("em"),Co=n("tokenizer"),_a=n(" :"),As=d(),j(Ss.$$.fragment),ls=d(),oe=o("p"),kn=n("Comme mentionn\xE9 pr\xE9c\xE9demment, nous allons "),En=o("em"),Po=n("finetuner"),ha=n(" un mod\xE8le BERT, mais vous pouvez utiliser n\u2019importe quel autre type de mod\xE8le tant qu\u2019il a un "),is=o("em"),va=n("tokenizer"),ne=n(" rapide impl\xE9ment\xE9. Vous pouvez voir toutes les architectures qui sont livr\xE9es avec une version rapide dans "),et=o("a"),yn=n("ce grand tableau"),Ao=n(", et pour v\xE9rifier que l\u2019objet "),Cn=o("code"),Pn=n("tokenizer"),So=n(" que vous utilisez est bien soutenu par des \u{1F917} "),An=o("em"),Sn=n("Tokenizers"),Do=n(" vous pouvez regarder son attribut "),Dn=o("code"),Mn=n("is_fast"),Mo=n(" :"),ba=d(),j(us.$$.fragment),ga=d(),j(st.$$.fragment),It=d(),Oe=o("p"),zo=n("Nous pouvons transmettre \xE0 notre "),tt=o("em"),To=n("tokenizer"),Lo=n(" la question et le contexte ensemble, et il ins\xE9rera correctement les "),Bt=o("em"),Ie=n("tokens"),No=n(" sp\xE9ciaux pour former une phrase comme celle-ci :"),Ft=d(),j(nt.$$.fragment),qa=d(),Be=o("p"),zn=n("V\xE9rifions \xE0 nouveau :"),xa=d(),j(at.$$.fragment),Tn=d(),j(m.$$.fragment),I=d(),ps=o("p"),$a=n("Les \xE9tiquettes seront alors l\u2019index des "),wa=o("em"),Vr=n("tokens"),Hr=n(" de d\xE9but et de fin de la r\xE9ponse, et le mod\xE8le sera charg\xE9 de pr\xE9dire un logit de d\xE9but et de fin par "),Ds=o("em"),Rr=n("token"),Ur=n(" dans l\u2019entr\xE9e, les \xE9tiquettes th\xE9oriques \xE9tant les suivantes :"),Ln=d(),Ms=o("div"),Vt=o("img"),Fe=d(),Ht=o("img"),Oo=d(),ds=o("p"),Qr=n("Dans ce cas, le contexte n\u2019est pas trop long, mais certains des exemples de l\u2019ensemble de donn\xE9es ont des contextes tr\xE8s longs qui d\xE9passeront la longueur maximale que nous avons fix\xE9e (qui est de 384 dans ce cas). Comme nous l\u2019avons vu dans le "),ot=o("a"),Gr=n("Chapitre 6"),pe=n(" lorsque nous avons explor\xE9 les internes du pipeline "),ja=o("code"),Wr=n("question-answering"),Jr=n(", nous allons traiter les contextes longs en cr\xE9ant plusieurs caract\xE9ristiques d\u2019entra\xEEnement \xE0 partir d\u2019un \xE9chantillon de notre jeu de donn\xE9es, avec une fen\xEAtre glissante entre eux."),Io=d(),rt=o("p"),Xr=n("Pour voir comment cela fonctionne en utilisant l\u2019exemple actuel, nous pouvons limiter la longueur \xE0 100 et utiliser une fen\xEAtre glissante de 50 "),ka=o("em"),Rt=n("tokens"),Kr=n(". Pour rappel, nous utilisons"),Bo=d(),ie=o("ul"),Nn=o("li"),Ea=o("code"),Yr=n("max_length"),Zr=n(" pour d\xE9finir la longueur maximale (ici 100)"),Ut=d(),On=o("li"),ya=o("code"),Ca=n('truncation="only_second"'),el=n(" pour tronquer le contexte (qui est en deuxi\xE8me position) quand la question avec son contexte est trop longue"),sl=d(),lt=o("li"),Pa=o("code"),Qt=n("stride"),Aa=n(" pour fixer le nombre de "),Sa=o("em"),zs=n("tokens"),tl=n(" se chevauchant entre deux morceaux successifs (ici 50)"),nl=d(),it=o("li"),xe=o("code"),al=n("return_overflowing_tokens=True"),ol=n(" pour indiquer au tokenizer que l\u2019on veut les "),Da=o("em"),rl=n("tokens"),ll=n(" qui d\xE9bordent"),In=d(),j(Gt.$$.fragment),ue=d(),j(Wt.$$.fragment),Fo=d(),fe=o("p"),il=n("Comme nous pouvons le voir, notre exemple a \xE9t\xE9 divis\xE9 en quatre entr\xE9es, chacune d\u2019entre elles contenant la question et une partie du contexte. Notez que la r\xE9ponse \xE0 la question (\u201CBernadette Soubirous\u201D) n\u2019appara\xEEt que dans la troisi\xE8me et derni\xE8re entr\xE9e, donc en traitant les longs contextes de cette fa\xE7on, nous allons cr\xE9er quelques exemples d\u2019entra\xEEnement o\xF9 la r\xE9ponse n\u2019est pas incluse dans le contexte. Pour ces exemples, les \xE9tiquettes seront "),Ma=o("code"),ul=n("start_position = end_position = 0"),pl=n(" (donc nous pr\xE9disons le "),Ts=o("em"),dl=n("token"),cl=d(),za=o("code"),Qd=n("[CLS]"),Gd=n("). Nous d\xE9finirons \xE9galement ces \xE9tiquettes dans le cas malheureux o\xF9 la r\xE9ponse a \xE9t\xE9 tronqu\xE9e de sorte que nous n\u2019avons que le d\xE9but (ou la fin) de celle-ci. Pour les exemples o\xF9 la r\xE9ponse est enti\xE8rement dans le contexte, les \xE9tiquettes seront l\u2019index du "),pi=o("em"),Wd=n("token"),Jd=n(" o\xF9 la r\xE9ponse commence et l\u2019index du "),di=o("em"),Xd=n("token"),Kd=n(" o\xF9 la r\xE9ponse se termine."),Tu=d(),Ve=o("p"),Yd=n("L\u2019ensemble de donn\xE9es nous fournit le caract\xE8re de d\xE9but de la r\xE9ponse dans le contexte, et en ajoutant la longueur de la r\xE9ponse, nous pouvons trouver le caract\xE8re de fin dans le contexte. Pour faire correspondre ces indices aux "),ci=o("em"),Zd=n("tokens"),ec=n(", nous devrons utiliser les mappages d\u2019offset que nous avons \xE9tudi\xE9s au "),ml=o("a"),sc=n("Chapitre 6"),tc=n(". Nous pouvons faire en sorte que notre "),mi=o("em"),nc=n("tokenizer"),ac=n(" renvoie ces index en passant "),fi=o("code"),oc=n("return_offsets_mapping=True"),rc=n(" :"),Lu=d(),j(Vo.$$.fragment),Nu=d(),j(Ho.$$.fragment),Ou=d(),Ls=o("p"),lc=n("Comme nous pouvons le voir, nous r\xE9cup\xE9rons les habituels ID d\u2019entr\xE9e, ID de type de jeton, et masque d\u2019attention, ainsi que le mappage d\u2019offset dont nous avions besoin et une cl\xE9 suppl\xE9mentaire, "),_i=o("code"),ic=n("overflow_to_sample_mapping"),uc=n(". La valeur correspondante nous sera utile lorsque nous tokeniserons plusieurs textes en m\xEAme temps (ce que nous devrions faire pour b\xE9n\xE9ficier du fait que notre "),hi=o("em"),pc=n("tokenizer"),dc=n(" est soutenu par Rust). Puisqu\u2019un \xE9chantillon peut donner plusieurs caract\xE9ristiques, il fait correspondre chaque caract\xE9ristique \xE0 l\u2019exemple d\u2019o\xF9 elle provient. Parce qu\u2019ici nous avons seulement tokenis\xE9 un exemple, nous obtenons une liste de "),vi=o("code"),cc=n("0"),mc=n("s :"),Iu=d(),j(Ro.$$.fragment),Bu=d(),j(Uo.$$.fragment),Fu=d(),fl=o("p"),fc=n("Mais si nous tokenisons plus d\u2019exemples, cela deviendra plus utile :"),Vu=d(),j(Qo.$$.fragment),Hu=d(),j(Go.$$.fragment),Ru=d(),_l=o("p"),_c=n("Comme nous pouvons le voir, les trois premiers exemples (aux indices 2, 3 et 4 de l\u2019ensemble d\u2019entra\xEEnement) ont chacun donn\xE9 quatre caract\xE9ristiques et le dernier exemple (\xE0 l\u2019indice 5 de l\u2019ensemble d\u2019entra\xEEnement) a donn\xE9 7 caract\xE9ristiques."),Uu=d(),hl=o("p"),hc=n("Ces informations seront utiles pour associer chaque caract\xE9ristique obtenue \xE0 son \xE9tiquette correspondante. Comme mentionn\xE9 pr\xE9c\xE9demment, ces \xE9tiquettes sont :"),Qu=d(),Ta=o("ul"),vl=o("li"),bi=o("code"),vc=n("(0, 0)"),bc=n(" si la r\xE9ponse n\u2019est pas dans l\u2019espace correspondant du contexte."),gc=d(),He=o("li"),gi=o("code"),qc=n("(start_position, end_position)"),xc=n(" si la r\xE9ponse est dans l\u2019espace correspondant du contexte, avec "),qi=o("code"),$c=n("start_position"),wc=n(" \xE9tant l\u2019index du "),xi=o("em"),jc=n("token"),kc=n(" (dans les IDs d\u2019entr\xE9e) au d\xE9but de la r\xE9ponse et "),$i=o("code"),Ec=n("end_position"),yc=n(" \xE9tant l\u2019index du "),wi=o("em"),Cc=n("token"),Pc=n(" (dans les IDs d\u2019entr\xE9e) o\xF9 la r\xE9ponse se termine."),Gu=d(),Re=o("p"),Ac=n("Pour d\xE9terminer ce qui est le cas et, le cas \xE9ch\xE9ant, les positions des "),ji=o("em"),Sc=n("tokens"),Dc=n(", nous trouvons d\u2019abord les indices qui commencent et finissent le contexte dans les IDs d\u2019entr\xE9e. Nous pourrions utiliser les IDs du type de "),ki=o("em"),Mc=n("token"),zc=n(" pour le faire, mais puisque ceux-ci n\u2019existent pas n\xE9cessairement pour tous les mod\xE8les (DistilBERT ne les requiert pas, par exemple), nous allons plut\xF4t utiliser la m\xE9thode "),Ei=o("code"),Tc=n("sequence_ids()"),Lc=n(" du "),yi=o("code"),Nc=n("BatchEncoding"),Oc=n(" que notre tokenizer retourne."),Wu=d(),Ue=o("p"),Ic=n("Une fois que nous avons ces indices de "),Ci=o("em"),Bc=n("tokens"),Fc=n(", nous regardons les offsets correspondants, qui sont des tuples de deux entiers repr\xE9sentant l\u2019\xE9tendue des caract\xE8res dans le contexte original. Nous pouvons ainsi d\xE9tecter si le "),Pi=o("em"),Vc=n("chunk"),Hc=n(" du contexte dans cette fonctionnalit\xE9 commence apr\xE8s la r\xE9ponse ou se termine avant que la r\xE9ponse ne commence (dans ce cas, l\u2019\xE9tiquette est "),Ai=o("code"),Rc=n("(0, 0)"),Uc=n("). Si ce n\u2019est pas le cas, nous bouclons pour trouver le premier et le dernier "),Si=o("em"),Qc=n("token"),Gc=n(" de la r\xE9ponse :"),Ju=d(),j(Wo.$$.fragment),Xu=d(),j(Jo.$$.fragment),Ku=d(),Jt=o("p"),Wc=n("Jetons un coup d\u2019\u0153il  \xE0 quelques r\xE9sultats pour v\xE9rifier que notre approche est correcte. Pour la premi\xE8re caract\xE9ristique, nous trouvons "),Di=o("code"),Jc=n("(83, 85)"),Xc=n(" comme \xE9tiquettes, alors comparons la r\xE9ponse th\xE9orique avec l\u2019\xE9tendue d\xE9cod\xE9e des "),Mi=o("em"),Kc=n("tokens"),Yc=n(" de 83 \xE0 85 (inclus) :"),Yu=d(),j(Xo.$$.fragment),Zu=d(),j(Ko.$$.fragment),ep=d(),Xt=o("p"),Zc=n("Donc, c\u2019est une correspondance ! Maintenant, v\xE9rifions l\u2019index 4, o\xF9 nous avons mis les \xE9tiquettes \xE0 "),zi=o("code"),em=n("(0, 0)"),sm=n(", ce qui signifie que la r\xE9ponse n\u2019est pas dans le "),Ti=o("em"),tm=n("chunk"),nm=n(" de contexte de cette caract\xE9ristique :"),sp=d(),j(Yo.$$.fragment),tp=d(),j(Zo.$$.fragment),np=d(),bl=o("p"),am=n("En effet, nous ne voyons pas la r\xE9ponse dans le contexte."),ap=d(),j(La.$$.fragment),op=d(),gl=o("p"),om=n("Maintenant que nous avons vu \xE9tape par \xE9tape comment pr\xE9traiter nos donn\xE9es d\u2019entra\xEEnement, nous pouvons les regrouper dans une fonction que nous appliquerons \xE0 l\u2019ensemble des donn\xE9es d\u2019entra\xEEnement. Nous allons rembourrer chaque caract\xE9ristique \xE0 la longueur maximale que nous avons d\xE9finie, car la plupart des contextes seront longs (et les \xE9chantillons correspondants seront divis\xE9s en plusieurs caract\xE9ristiques), il n\u2019y a donc pas de r\xE9el avantage \xE0 appliquer un rembourrage dynamique ici :"),rp=d(),j(er.$$.fragment),lp=d(),ql=o("p"),rm=n("Notez que nous avons d\xE9fini deux constantes pour d\xE9terminer la longueur maximale utilis\xE9e ainsi que la longueur de la fen\xEAtre glissante, et que nous avons ajout\xE9 un petit nettoyage avant la tok\xE9nisation : certaines des questions dans le jeu de donn\xE9es SQuAD ont des espaces suppl\xE9mentaires au d\xE9but et \xE0 la fin qui n\u2019ajoutent rien (et prennent de la place lors de la tok\xE9nisation si vous utilisez un mod\xE8le comme RoBERTa), donc nous avons supprim\xE9 ces espaces suppl\xE9mentaires."),ip=d(),Kt=o("p"),lm=n("Pour appliquer cette fonction \xE0 l\u2019ensemble de l\u2019entra\xEEnement, nous utilisons la m\xE9thode "),Li=o("code"),im=n("Dataset.map()"),um=n(" avec le flag "),Ni=o("code"),pm=n("batched=True"),dm=n(". C\u2019est n\xE9cessaire ici car nous changeons la longueur de l\u2019ensemble de donn\xE9es (puisqu\u2019un exemple peut donner plusieurs caract\xE9ristiques d\u2019entra\xEEnement) :"),up=d(),j(sr.$$.fragment),pp=d(),j(tr.$$.fragment),dp=d(),xl=o("p"),cm=n("Comme nous pouvons le voir, le pr\xE9traitement a ajout\xE9 environ 1 000 caract\xE9ristiques. Notre ensemble d\u2019entra\xEEnement est maintenant pr\xEAt \xE0 \xEAtre utilis\xE9 - passons au pr\xE9traitement de l\u2019ensemble de validation !"),cp=d(),Bn=o("h3"),Na=o("a"),Oi=o("span"),j(nr.$$.fragment),mm=d(),Ii=o("span"),fm=n("Traitement des donn\xE9es de validation"),mp=d(),$l=o("p"),_m=n("Le pr\xE9traitement des donn\xE9es de validation sera l\xE9g\xE8rement plus facile car nous n\u2019avons pas besoin de g\xE9n\xE9rer des \xE9tiquettes (sauf si nous voulons calculer une perte de validation, mais ce nombre ne nous aidera pas vraiment \xE0 comprendre la qualit\xE9 du mod\xE8le). La vraie joie sera d\u2019interpr\xE9ter les pr\xE9dictions du mod\xE8le dans des \xE9tendues du contexte original. Pour cela, il nous suffit de stocker les mappages de d\xE9calage et un moyen de faire correspondre chaque caract\xE9ristique cr\xE9\xE9e \xE0 l\u2019exemple original dont elle provient. Puisqu\u2019il y a une colonne ID dans l\u2019ensemble de donn\xE9es original, nous utiliserons cet ID."),fp=d(),Ns=o("p"),hm=n("La seule chose que nous allons ajouter ici est un petit nettoyage des mappages de d\xE9calage. Ils contiendront les offsets pour la question et le contexte, mais une fois que nous serons dans la phase de post-traitement, nous n\u2019aurons aucun moyen de savoir quelle partie des IDs d\u2019entr\xE9e correspondait au contexte et quelle partie \xE9tait la question (la m\xE9thode "),Bi=o("code"),vm=n("sequence_ids()"),bm=n(" que nous avons utilis\xE9e n\u2019est disponible que pour la sortie du "),Fi=o("em"),gm=n("tokenizer"),qm=n("). Donc, nous allons mettre les offsets correspondant \xE0 la question \xE0 "),Vi=o("code"),xm=n("None"),$m=n(" :"),_p=d(),j(ar.$$.fragment),hp=d(),wl=o("p"),wm=n("Nous pouvons appliquer cette fonction sur l\u2019ensemble des donn\xE9es de validation comme pr\xE9c\xE9demment :"),vp=d(),j(or.$$.fragment),bp=d(),j(rr.$$.fragment),gp=d(),jl=o("p"),jm=n("Dans ce cas, nous n\u2019avons ajout\xE9 que quelques centaines d\u2019\xE9chantillons, il semble donc que les contextes dans l\u2019ensemble de donn\xE9es de validation soient un peu plus courts."),qp=d(),kl=o("p"),km=n("Maintenant que nous avons pr\xE9trait\xE9 toutes les donn\xE9es, nous pouvons passer \xE0 l\u2019entra\xEEnement."),xp=d(),pt.c(),El=d(),Fn=o("h3"),Oa=o("a"),Hi=o("span"),j(lr.$$.fragment),Em=d(),Ri=o("span"),ym=n("Post-traitement"),$p=d(),ct.c(),yl=d(),Ia=o("p"),Cm=n("Le mod\xE8le produira des logits pour les positions de d\xE9but et de fin de la r\xE9ponse dans les IDs d\u2019entr\xE9e, comme nous l\u2019avons vu lors de notre exploration du "),ir=o("a"),Ui=o("code"),Pm=n("question-answering"),Am=n(" pipeline"),Sm=n(". L\u2019\xE9tape de post-traitement sera similaire \xE0 ce que nous avons fait l\xE0-bas, donc voici un rappel rapide des actions que nous avons prises :"),wp=d(),Os=o("ul"),ur=o("li"),Dm=n("nous avons masqu\xE9 les logits de d\xE9but et de fin correspondant aux "),Qi=o("em"),Mm=n("tokens"),zm=n(" en dehors du contexte,"),Tm=d(),Gi=o("li"),Lm=n("nous avons ensuite converti les logits de d\xE9but et de fin en probabilit\xE9s en utilisant un softmax,"),Nm=d(),pr=o("li"),Om=n("nous avons attribu\xE9 un score \xE0 chaque paire "),Wi=o("code"),Im=n("(start_token, end_token)"),Bm=n(" en prenant le produit des deux probabilit\xE9s correspondantes,"),Fm=d(),Vn=o("li"),Vm=n("nous avons cherch\xE9 la paire avec le score maximum qui donnait une r\xE9ponse valide (par exemple, un "),Ji=o("code"),Hm=n("start_token"),Rm=n(" inf\xE9rieur au "),Xi=o("code"),Um=n("end_token"),Qm=n(")."),jp=d(),Is=o("p"),Gm=n("Ici, nous allons modifier l\xE9g\xE8rement ce processus car nous n\u2019avons pas besoin de calculer les scores r\xE9els (juste la r\xE9ponse pr\xE9dite). Cela signifie que nous pouvons sauter l\u2019\xE9tape du softmax. Pour aller plus vite, nous ne noterons pas non plus toutes les paires "),Ki=o("code"),Wm=n("(start_token, end_token)"),Jm=n(" possibles, mais seulement celles correspondant aux logits "),Yi=o("code"),Xm=n("n_best"),Km=n(" les plus \xE9lev\xE9s (avec "),Zi=o("code"),Ym=n("n_best=20"),Zm=n("). Puisque nous sauterons le softmax, ces scores seront des scores logit, et seront obtenus en prenant la somme des logits de d\xE9but et de fin (au lieu du produit, \xE0 cause de la r\xE8gle \\(\\log(ab) = \\log(a) + \\log(b)))."),kp=d(),Ba=o("p"),ef=n("Pour d\xE9montrer tout cela, nous aurons besoin d\u2019un certain type de pr\xE9dictions. Puisque nous n\u2019avons pas encore entra\xEEn\xE9 notre mod\xE8le, nous allons utiliser le mod\xE8le par d\xE9faut du pipeline d\u2019assurance qualit\xE9 pour g\xE9n\xE9rer quelques pr\xE9dictions sur une petite partie de l\u2019ensemble de validation. Nous pouvons utiliser la m\xEAme fonction de traitement que pr\xE9c\xE9demment ; parce qu\u2019elle repose sur la constante globale "),eu=o("code"),sf=n("tokenizer"),tf=n(", nous devons juste changer cet objet pour le tokenizer du mod\xE8le que nous voulons utiliser temporairement :"),Ep=d(),j(dr.$$.fragment),yp=d(),Fa=o("p"),nf=n("Maintenant que le pr\xE9traitement est termin\xE9, nous changeons le "),su=o("em"),af=n("tokenizer"),of=n(" pour celui que nous avons choisi \xE0 l\u2019origine :"),Cp=d(),j(cr.$$.fragment),Pp=d(),Va=o("p"),rf=n("Nous supprimons ensuite les colonnes de notre "),tu=o("code"),lf=n("eval_set"),uf=n(" qui ne sont pas attendues par le mod\xE8le, nous construisons un lot avec l\u2019ensemble de ce petit ensemble de validation, et nous le passons au mod\xE8le. Si un GPU est disponible, nous l\u2019utilisons pour aller plus vite :"),Ap=d(),ft.c(),Cl=d(),Qe=o("p"),pf=n("Maintenant, nous devons trouver la r\xE9ponse pr\xE9dite pour chaque exemple dans notre "),nu=o("code"),df=n("small_eval_set"),cf=n(". Un exemple peut avoir \xE9t\xE9 divis\xE9 en plusieurs caract\xE9ristiques dans "),au=o("code"),mf=n("eval_set"),ff=n(", donc la premi\xE8re \xE9tape est de faire correspondre chaque exemple dans "),ou=o("code"),_f=n("small_eval_set"),hf=n(" aux caract\xE9ristiques correspondantes dans "),ru=o("code"),vf=n("eval_set"),bf=n(" :"),Sp=d(),j(mr.$$.fragment),Dp=d(),Ha=o("p"),gf=n("Avec cela en main, nous pouvons vraiment nous mettre au travail en parcourant en boucle tous les exemples et, pour chaque exemple, toutes les caract\xE9ristiques associ\xE9es. Comme nous l\u2019avons dit pr\xE9c\xE9demment, nous allons regarder les scores logit pour les "),lu=o("code"),qf=n("n_meilleurs"),xf=n(" logits de d\xE9but et logits de fin, en excluant les positions qui donnent :"),Mp=d(),Yt=o("ul"),iu=o("li"),$f=n("une r\xE9ponse qui ne serait pas dans le contexte."),wf=d(),uu=o("li"),jf=n("une r\xE9ponse avec une longueur n\xE9gative"),kf=d(),fr=o("li"),Ef=n("une r\xE9ponse qui est trop longue (nous limitons les possibilit\xE9s \xE0 "),pu=o("code"),yf=n("max_answer_length=30"),Cf=n(")"),zp=d(),Pl=o("p"),Pf=n("Une fois que nous avons toutes les r\xE9ponses possibles not\xE9es pour un exemple, nous choisissons simplement celle qui a le meilleur score logit :"),Tp=d(),j(_r.$$.fragment),Lp=d(),Ra=o("p"),Af=n("Le format final des r\xE9ponses pr\xE9dites est celui qui sera attendu par la m\xE9trique que nous allons utiliser. Comme d\u2019habitude, nous pouvons le charger \xE0 l\u2019aide de la biblioth\xE8que \u{1F917} "),du=o("em"),Sf=n("Datasets"),Df=n(" :"),Np=d(),j(hr.$$.fragment),Op=d(),Al=o("p"),Mf=n("Cette m\xE9trique attend les r\xE9ponses pr\xE9dites dans le format que nous avons vu ci-dessus (une liste de dictionnaires avec une cl\xE9 pour l\u2019ID de l\u2019exemple et une cl\xE9 pour le texte pr\xE9dit) et les r\xE9ponses th\xE9oriques dans le format ci-dessous (une liste de dictionnaires avec une cl\xE9 pour l\u2019ID de l\u2019exemple et une cl\xE9 pour les r\xE9ponses possibles) :"),Ip=d(),j(vr.$$.fragment),Bp=d(),Sl=o("p"),zf=n("Nous pouvons maintenant v\xE9rifier que nous obtenons des r\xE9sultats raisonnables en examinant le premier \xE9l\xE9ment des deux listes :"),Fp=d(),j(br.$$.fragment),Vp=d(),j(gr.$$.fragment),Hp=d(),Dl=o("p"),Tf=n("Pas trop mal ! Voyons maintenant le score que la m\xE9trique nous donne :"),Rp=d(),j(qr.$$.fragment),Up=d(),j(xr.$$.fragment),Qp=d(),Zt=o("p"),Lf=n("Encore une fois, c\u2019est plut\xF4t bon si l\u2019on consid\xE8re que, selon "),$r=o("a"),Nf=n("son article"),Of=n(", DistilBERT "),cu=o("em"),If=n("finetun\xE9"),Bf=n(" sur SQuAD obtient 79,1 et 86,9 pour ces scores sur l\u2019ensemble des donn\xE9es."),Gp=d(),Un.c(),Ml=d(),j(wr.$$.fragment),Wp=d(),zl=o("p"),Ff=n("Nous pouvons v\xE9rifier que cela fonctionne sur nos pr\xE9dictions :"),Jp=d(),j(jr.$$.fragment),Xp=d(),j(kr.$$.fragment),Kp=d(),Tl=o("p"),Vf=n("C\u2019est bien ! Maintenant, utilisons ceci pour affiner notre mod\xE8le."),Yp=d(),Hn=o("h3"),Ua=o("a"),mu=o("span"),j(Er.$$.fragment),Hf=d(),fu=o("span"),Rf=n("*Finetuning* du mod\xE8le"),Zp=d(),ht.c(),Ll=d(),Qa=o("p"),Uf=n("Comme d\u2019habitude, nous recevons un avertissement indiquant que certains poids ne sont pas utilis\xE9s (ceux de la t\xEAte de pr\xE9-entra\xEEnement) et que d\u2019autres sont initialis\xE9s de mani\xE8re al\xE9atoire (ceux de la t\xEAte de r\xE9ponse aux questions). Vous devriez \xEAtre habitu\xE9 \xE0 cela maintenant, mais cela signifie que ce mod\xE8le n\u2019est pas encore pr\xEAt \xE0 \xEAtre utilis\xE9 et qu\u2019il a besoin d\u2019\xEAtre "),_u=o("em"),Qf=n("finetun\xE9"),Gf=n(". Une bonne chose que nous soyons sur le point de le faire !"),ed=d(),en=o("p"),Wf=n("Pour pouvoir pousser notre mod\xE8le vers le "),hu=o("em"),Jf=n("Hub"),Xf=n(", nous devons nous connecter \xE0 Hugging Face. Si vous ex\xE9cutez ce code dans un "),vu=o("em"),Kf=n("notebook"),Yf=n(", vous pouvez le faire avec la fonction utilitaire suivante, qui affiche un widget o\xF9 vous pouvez entrer vos identifiants de connexion :"),sd=d(),j(yr.$$.fragment),td=d(),Ga=o("p"),Zf=n("Si vous ne travaillez pas dans un "),bu=o("em"),e_=n("notebook"),s_=n(", tapez simplement la ligne suivante dans votre terminal :"),nd=d(),j(Cr.$$.fragment),ad=d(),bt.c(),Nl=d(),Ge=o("p"),t_=n("Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace de noms et nomm\xE9 apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, donc dans notre cas il sera dans "),gu=o("code"),n_=n('"sgugger/bert-finetuned-squad"'),a_=n(". Nous pouvons passer outre en passant un "),qu=o("code"),o_=n("hub_model_id"),r_=n(" ; par exemple, pour pousser le mod\xE8le dans l\u2019organisation "),xu=o("code"),l_=n("huggingface_course"),i_=n(" nous avons utilis\xE9 "),$u=o("code"),u_=n('hub_model_id= "huggingface_course/bert-finetuned-squad"'),p_=n(" (qui est le mod\xE8le que nous avons li\xE9 au d\xE9but de cette section)."),od=d(),qt.c(),Ol=d(),Il=o("p"),d_=n("Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le Hub en arri\xE8re-plan. Ainsi, vous pourrez reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire. L\u2019ensemble de l\u2019entra\xEEnement prend un certain temps (un peu plus d\u2019une heure sur une Titan RTX), vous pouvez donc prendre un caf\xE9 ou relire les parties du cours qui vous ont sembl\xE9 plus difficiles pendant qu\u2019il se d\xE9roule. Notez \xE9galement que d\xE8s que la premi\xE8re \xE9poque est termin\xE9e, vous verrez des poids t\xE9l\xE9charg\xE9s sur le Hub et vous pourrez commencer \xE0 jouer avec votre mod\xE8le sur sa page."),rd=d(),$t.c(),Bl=d(),j(Pr.$$.fragment),ld=d(),Fl=o("p"),c_=n("Super ! \xC0 titre de comparaison, les scores de base indiqu\xE9s dans l\u2019article du BERT pour ce mod\xE8le sont de 80,8 et 88,5, donc nous sommes exactement l\xE0 o\xF9 nous devrions \xEAtre."),id=d(),_e&&_e.c(),Vl=d(),sn=o("p"),m_=n("\xC0 ce stade, vous pouvez utiliser le widget d\u2019inf\xE9rence sur le "),wu=o("em"),f_=n("Hub"),__=n(" du mod\xE8le pour tester le mod\xE8le et le partager avec vos amis, votre famille et vos animaux pr\xE9f\xE9r\xE9s. Vous avez r\xE9ussi \xE0 "),ju=o("em"),h_=n("finetuner"),v_=n(" un mod\xE8le sur une t\xE2che de r\xE9ponse \xE0 une question - f\xE9licitations !"),ud=d(),j(Wa.$$.fragment),pd=d(),he&&he.c(),Hl=d(),Rn=o("h3"),Ja=o("a"),ku=o("span"),j(Ar.$$.fragment),b_=d(),Eu=o("span"),g_=n("Utilisation du mod\xE8le *finetun\xE9*"),dd=d(),Bs=o("p"),q_=n("Nous vous avons d\xE9j\xE0 montr\xE9 comment vous pouvez utiliser le mod\xE8le que nous avons "),yu=o("em"),x_=n("finetun\xE9"),$_=n(" sur le "),Cu=o("em"),w_=n("Hub"),j_=n(" avec le widget d\u2019inf\xE9rence. Pour l\u2019utiliser localement dans un "),Pu=o("code"),k_=n("pipeline"),E_=n(", il suffit de sp\xE9cifier l\u2019identifiant du mod\xE8le :"),cd=d(),j(Sr.$$.fragment),md=d(),j(Dr.$$.fragment),fd=d(),Rl=o("p"),y_=n("Super ! Notre mod\xE8le fonctionne aussi bien que le mod\xE8le par d\xE9faut pour ce pipeline !"),this.h()},l(e){const u=Rb('[data-svelte="svelte-1phssyn"]',document.head);p=r(u,"META",{name:!0,content:!0}),u.forEach(t),b=c(e),k(f.$$.fragment,e),C=c(e),S=r(e,"H1",{class:!0});var Fr=l(S);g=r(Fr,"A",{id:!0,class:!0,href:!0});var Ul=l(g);$=r(Ul,"SPAN",{});var Au=l($);k(q.$$.fragment,Au),Au.forEach(t),Ul.forEach(t),_=c(Fr),z=r(Fr,"SPAN",{});var Su=l(z);x=a(Su,"R\xE9ponse aux questions"),Su.forEach(t),Fr.forEach(t),D=c(e),N.l(e),P=c(e),w=r(e,"P",{});var Xa=l(w);U=a(Xa,"Il est temps de s\u2019int\xE9resser \xE0 la r\xE9ponse aux questions ! Cette t\xE2che peut prendre plusieurs formes, mais celle sur laquelle nous allons nous concentrer dans cette section est appel\xE9e r\xE9ponse aux questions "),V=r(Xa,"EM",{});var Ql=l(V);F=a(Ql,"extractives"),Ql.forEach(t),M=a(Xa,". Il s\u2019agit de poser des questions sur un document et d\u2019identifier les r\xE9ponses sous forme de \u201Cmorceaux de texte\u201D dans le document lui-m\xEAme."),Xa.forEach(t),B=c(e),k(G.$$.fragment,e),ee=c(e),Q=r(e,"P",{});var tn=l(Q);W=a(tn,"Nous allons affiner un mod\xE8le BERT sur le "),K=r(tn,"A",{href:!0,rel:!0});var Gl=l(K);Y=a(Gl,"jeu de donn\xE9es SQuAD"),Gl.forEach(t),O=a(tn,", qui consiste en des questions pos\xE9es par des "),X=r(tn,"EM",{});var Wl=l(X);$e=a(Wl,"crowdworkers"),Wl.forEach(t),de=a(tn," sur un ensemble d\u2019articles de Wikipedia. Cela nous donnera un mod\xE8le capable de calculer des pr\xE9dictions comme celle-ci :"),tn.forEach(t),J=c(e),se=r(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),l(se).forEach(t),ve=c(e),re=r(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),l(re).forEach(t),Xe=c(e),R=r(e,"P",{});var Qn=l(R);Z=a(Qn,"Il s\u2019agit en fait de la pr\xE9sentation du mod\xE8le qui a \xE9t\xE9 entra\xEEn\xE9 et t\xE9l\xE9charg\xE9 sur le "),fs=r(Qn,"EM",{});var Jl=l(fs);jt=a(Jl,"Hub"),Jl.forEach(t),_s=a(Qn," \xE0 l\u2019aide du code pr\xE9sent\xE9 dans cette section. Vous pouvez le trouver et v\xE9rifier les pr\xE9dictions "),Ae=r(Qn,"A",{href:!0,rel:!0});var Du=l(Ae);Se=a(Du,"ici"),Du.forEach(t),Qn.forEach(t),hs=c(e),k(ce.$$.fragment,e),De=c(e),me=r(e,"H2",{class:!0});var vd=l(me);be=r(vd,"A",{id:!0,class:!0,href:!0});var J_=l(be);Ke=r(J_,"SPAN",{});var X_=l(Ke);k(je.$$.fragment,X_),X_.forEach(t),J_.forEach(t),Gn=c(vd),Me=r(vd,"SPAN",{});var K_=l(Me);ao=a(K_,"Pr\xE9paration des donn\xE9es"),K_.forEach(t),vd.forEach(t),kt=c(e),ze=r(e,"P",{});var Xl=l(ze);oo=a(Xl,"Le jeu de donn\xE9es le plus utilis\xE9 comme r\xE9f\xE9rence acad\xE9mique pour la r\xE9ponse extractive aux questions est "),vs=r(Xl,"A",{href:!0,rel:!0});var Y_=l(vs);Vs=a(Y_,"SQuAD"),Y_.forEach(t),Wn=a(Xl,", c\u2019est donc celui que nous utiliserons ici. Il existe \xE9galement une r\xE9f\xE9rence plus difficile "),te=r(Xl,"A",{href:!0,rel:!0});var Z_=l(te);ro=a(Z_,"SQuAD v2"),Z_.forEach(t),dn=a(Xl,", qui comprend des questions sans r\xE9ponse. Tant que votre propre jeu de donn\xE9es contient une colonne pour les contextes, une colonne pour les questions et une colonne pour les r\xE9ponses, vous devriez \xEAtre en mesure d\u2019adapter les \xE9tapes ci-dessous."),Xl.forEach(t),Jn=c(e),Ye=r(e,"H3",{class:!0});var bd=l(Ye);Te=r(bd,"A",{id:!0,class:!0,href:!0});var eh=l(Te);cn=r(eh,"SPAN",{});var sh=l(cn);k(Hs.$$.fragment,sh),sh.forEach(t),eh.forEach(t),mn=c(bd),fn=r(bd,"SPAN",{});var th=l(fn);lo=a(th,"Le jeu de donn\xE9es SQuAD"),th.forEach(t),bd.forEach(t),Et=c(e),bs=r(e,"P",{});var gd=l(bs);io=a(gd,"Comme d\u2019habitude, nous pouvons t\xE9l\xE9charger et mettre en cache le jeu de donn\xE9es en une seule \xE9tape gr\xE2ce \xE0 "),Rs=r(gd,"CODE",{});var nh=l(Rs);uo=a(nh,"load_dataset()"),nh.forEach(t),po=a(gd," :"),gd.forEach(t),yt=c(e),k(Us.$$.fragment,e),Xn=c(e),gs=r(e,"P",{});var ah=l(gs);co=a(ah,"Nous pouvons alors jeter un coup d\u2019\u0153il \xE0 cet objet pour en savoir plus sur le jeu de donn\xE9es SQuAD :"),ah.forEach(t),Kn=c(e),k(qs.$$.fragment,e),xs=c(e),k($s.$$.fragment,e),ke=c(e),ge=r(e,"P",{});var Ka=l(ge);_n=a(Ka,"On dirait que nous avons tout ce dont nous avons besoin avec les champs "),hn=r(Ka,"CODE",{});var oh=l(hn);mo=a(oh,"context"),oh.forEach(t),vn=a(Ka,", "),bn=r(Ka,"CODE",{});var rh=l(bn);fo=a(rh,"question"),rh.forEach(t),Yn=a(Ka," et "),Ze=r(Ka,"CODE",{});var lh=l(Ze);Zn=a(lh,"answers"),lh.forEach(t),qe=a(Ka,", alors imprimons-les pour le premier \xE9l\xE9ment de notre ensemble d\u2019entra\xEEnement :"),Ka.forEach(t),ea=c(e),k(es.$$.fragment,e),sa=c(e),k(Qs.$$.fragment,e),Ct=c(e),ae=r(e,"P",{});var We=l(ae);_o=a(We,"Les champs "),Gs=r(We,"CODE",{});var ih=l(Gs);ho=a(ih,"context"),ih.forEach(t),vo=a(We," et "),Pt=r(We,"CODE",{});var uh=l(Pt);Ws=a(uh,"question"),uh.forEach(t),ta=a(We," sont tr\xE8s simples \xE0 utiliser. Le champ "),ss=r(We,"CODE",{});var ph=l(ss);na=a(ph,"answers"),ph.forEach(t),At=a(We," est un peu plus d\xE9licat car il compile un dictionnaire avec deux champs qui sont tous deux des listes. C\u2019est le format qui sera attendu par la m\xE9trique "),gn=r(We,"CODE",{});var dh=l(gn);aa=a(dh,"squad"),dh.forEach(t),Js=a(We," lors de l\u2019\xE9valuation ; si vous utilisez vos propres donn\xE9es, vous n\u2019avez pas n\xE9cessairement besoin de vous soucier de mettre les r\xE9ponses dans le m\xEAme format. Le champ "),St=r(We,"CODE",{});var ch=l(St);Le=a(ch,"text"),ch.forEach(t),bo=a(We," est assez \xE9vident, et le champ "),Xs=r(We,"CODE",{});var mh=l(Xs);go=a(mh,"answer_start"),mh.forEach(t),qo=a(We," contient l\u2019indice du caract\xE8re de d\xE9part de chaque r\xE9ponse dans le contexte."),We.forEach(t),Dt=c(e),ws=r(e,"P",{});var qd=l(ws);xo=a(qd,"Pendant l\u2019entra\xEEnement, il n\u2019y a qu\u2019une seule r\xE9ponse possible. Nous pouvons v\xE9rifier cela en utilisant la m\xE9thode "),Mt=r(qd,"CODE",{});var fh=l(Mt);ts=a(fh,"Dataset.filter()"),fh.forEach(t),js=a(qd," :"),qd.forEach(t),zt=c(e),k(Ee.$$.fragment,e),oa=c(e),k(ns.$$.fragment,e),ra=c(e),Ks=r(e,"P",{});var _h=l(Ks);Tt=a(_h,"Pour l\u2019\xE9valuation, cependant, il existe plusieurs r\xE9ponses possibles pour chaque \xE9chantillon, qui peuvent \xEAtre identiques ou diff\xE9rentes :"),_h.forEach(t),la=c(e),k(ks.$$.fragment,e),ye=c(e),k(Ce.$$.fragment,e),ia=c(e),Ne=r(e,"P",{});var xd=l(Ne);$o=a(xd,"Nous ne nous plongerons pas dans le script d\u2019\xE9valuation car tout sera envelopp\xE9 par une m\xE9trique \u{1F917} "),qn=r(xd,"EM",{});var hh=l(qn);wo=a(hh,"Datasets"),hh.forEach(t),Pe=a(xd," pour nous, mais la version courte est que certaines des questions ont plusieurs r\xE9ponses possibles, et ce script va comparer une r\xE9ponse pr\xE9dite \xE0 toutes les r\xE9ponses acceptables et prendre le meilleur score. Si nous regardons l\u2019\xE9chantillon de l\u2019indice 2, par exemple :"),xd.forEach(t),ua=c(e),k(as.$$.fragment,e),pa=c(e),k(Ys.$$.fragment,e),Lt=c(e),Nt=r(e,"P",{});var vh=l(Nt);jo=a(vh,"nous pouvons voir que la r\xE9ponse peut effectivement \xEAtre l\u2019une des trois possibilit\xE9s que nous avons vues pr\xE9c\xE9demment."),vh.forEach(t),Ot=c(e),os=r(e,"H3",{class:!0});var $d=l(os);Es=r($d,"A",{id:!0,class:!0,href:!0});var bh=l(Es);xn=r(bh,"SPAN",{});var gh=l(xn);k(le.$$.fragment,gh),gh.forEach(t),bh.forEach(t),ko=c($d),Zs=r($d,"SPAN",{});var qh=l(Zs);Eo=a(qh,"Traitement des donn\xE9es d'entra\xEEnement"),qh.forEach(t),$d.forEach(t),da=c(e),k(rs.$$.fragment,e),ca=c(e),ys=r(e,"P",{});var wd=l(ys);$n=a(wd,"Commen\xE7ons par le pr\xE9traitement des donn\xE9es d\u2019entra\xEEnement. La partie la plus difficile sera de g\xE9n\xE9rer des \xE9tiquettes pour la r\xE9ponse \xE0 la question, qui seront les positions de d\xE9but et de fin des "),wn=r(wd,"EM",{});var xh=l(wn);yo=a(xh,"tokens"),xh.forEach(t),jn=a(wd," correspondant \xE0 la r\xE9ponse dans le contexte."),wd.forEach(t),ma=c(e),Cs=r(e,"P",{});var jd=l(Cs);fa=a(jd,"Mais ne nous emballons pas. Tout d\u2019abord, nous devons convertir le texte de l\u2019entr\xE9e en identifiants que le mod\xE8le peut comprendre, en utilisant un "),Ps=r(jd,"EM",{});var $h=l(Ps);Co=a($h,"tokenizer"),$h.forEach(t),_a=a(jd," :"),jd.forEach(t),As=c(e),k(Ss.$$.fragment,e),ls=c(e),oe=r(e,"P",{});var Je=l(oe);kn=a(Je,"Comme mentionn\xE9 pr\xE9c\xE9demment, nous allons "),En=r(Je,"EM",{});var wh=l(En);Po=a(wh,"finetuner"),wh.forEach(t),ha=a(Je," un mod\xE8le BERT, mais vous pouvez utiliser n\u2019importe quel autre type de mod\xE8le tant qu\u2019il a un "),is=r(Je,"EM",{});var jh=l(is);va=a(jh,"tokenizer"),jh.forEach(t),ne=a(Je," rapide impl\xE9ment\xE9. Vous pouvez voir toutes les architectures qui sont livr\xE9es avec une version rapide dans "),et=r(Je,"A",{href:!0,rel:!0});var kh=l(et);yn=a(kh,"ce grand tableau"),kh.forEach(t),Ao=a(Je,", et pour v\xE9rifier que l\u2019objet "),Cn=r(Je,"CODE",{});var Eh=l(Cn);Pn=a(Eh,"tokenizer"),Eh.forEach(t),So=a(Je," que vous utilisez est bien soutenu par des \u{1F917} "),An=r(Je,"EM",{});var yh=l(An);Sn=a(yh,"Tokenizers"),yh.forEach(t),Do=a(Je," vous pouvez regarder son attribut "),Dn=r(Je,"CODE",{});var Ch=l(Dn);Mn=a(Ch,"is_fast"),Ch.forEach(t),Mo=a(Je," :"),Je.forEach(t),ba=c(e),k(us.$$.fragment,e),ga=c(e),k(st.$$.fragment,e),It=c(e),Oe=r(e,"P",{});var Kl=l(Oe);zo=a(Kl,"Nous pouvons transmettre \xE0 notre "),tt=r(Kl,"EM",{});var Ph=l(tt);To=a(Ph,"tokenizer"),Ph.forEach(t),Lo=a(Kl," la question et le contexte ensemble, et il ins\xE9rera correctement les "),Bt=r(Kl,"EM",{});var Ah=l(Bt);Ie=a(Ah,"tokens"),Ah.forEach(t),No=a(Kl," sp\xE9ciaux pour former une phrase comme celle-ci :"),Kl.forEach(t),Ft=c(e),k(nt.$$.fragment,e),qa=c(e),Be=r(e,"P",{});var Sh=l(Be);zn=a(Sh,"V\xE9rifions \xE0 nouveau :"),Sh.forEach(t),xa=c(e),k(at.$$.fragment,e),Tn=c(e),k(m.$$.fragment,e),I=c(e),ps=r(e,"P",{});var Yl=l(ps);$a=a(Yl,"Les \xE9tiquettes seront alors l\u2019index des "),wa=r(Yl,"EM",{});var Dh=l(wa);Vr=a(Dh,"tokens"),Dh.forEach(t),Hr=a(Yl," de d\xE9but et de fin de la r\xE9ponse, et le mod\xE8le sera charg\xE9 de pr\xE9dire un logit de d\xE9but et de fin par "),Ds=r(Yl,"EM",{});var Mh=l(Ds);Rr=a(Mh,"token"),Mh.forEach(t),Ur=a(Yl," dans l\u2019entr\xE9e, les \xE9tiquettes th\xE9oriques \xE9tant les suivantes :"),Yl.forEach(t),Ln=c(e),Ms=r(e,"DIV",{class:!0});var kd=l(Ms);Vt=r(kd,"IMG",{class:!0,src:!0,alt:!0}),Fe=c(kd),Ht=r(kd,"IMG",{class:!0,src:!0,alt:!0}),kd.forEach(t),Oo=c(e),ds=r(e,"P",{});var Zl=l(ds);Qr=a(Zl,"Dans ce cas, le contexte n\u2019est pas trop long, mais certains des exemples de l\u2019ensemble de donn\xE9es ont des contextes tr\xE8s longs qui d\xE9passeront la longueur maximale que nous avons fix\xE9e (qui est de 384 dans ce cas). Comme nous l\u2019avons vu dans le "),ot=r(Zl,"A",{href:!0});var zh=l(ot);Gr=a(zh,"Chapitre 6"),zh.forEach(t),pe=a(Zl," lorsque nous avons explor\xE9 les internes du pipeline "),ja=r(Zl,"CODE",{});var Th=l(ja);Wr=a(Th,"question-answering"),Th.forEach(t),Jr=a(Zl,", nous allons traiter les contextes longs en cr\xE9ant plusieurs caract\xE9ristiques d\u2019entra\xEEnement \xE0 partir d\u2019un \xE9chantillon de notre jeu de donn\xE9es, avec une fen\xEAtre glissante entre eux."),Zl.forEach(t),Io=c(e),rt=r(e,"P",{});var Ed=l(rt);Xr=a(Ed,"Pour voir comment cela fonctionne en utilisant l\u2019exemple actuel, nous pouvons limiter la longueur \xE0 100 et utiliser une fen\xEAtre glissante de 50 "),ka=r(Ed,"EM",{});var Lh=l(ka);Rt=a(Lh,"tokens"),Lh.forEach(t),Kr=a(Ed,". Pour rappel, nous utilisons"),Ed.forEach(t),Bo=c(e),ie=r(e,"UL",{});var Ya=l(ie);Nn=r(Ya,"LI",{});var C_=l(Nn);Ea=r(C_,"CODE",{});var Nh=l(Ea);Yr=a(Nh,"max_length"),Nh.forEach(t),Zr=a(C_," pour d\xE9finir la longueur maximale (ici 100)"),C_.forEach(t),Ut=c(Ya),On=r(Ya,"LI",{});var P_=l(On);ya=r(P_,"CODE",{});var Oh=l(ya);Ca=a(Oh,'truncation="only_second"'),Oh.forEach(t),el=a(P_," pour tronquer le contexte (qui est en deuxi\xE8me position) quand la question avec son contexte est trop longue"),P_.forEach(t),sl=c(Ya),lt=r(Ya,"LI",{});var Mu=l(lt);Pa=r(Mu,"CODE",{});var Ih=l(Pa);Qt=a(Ih,"stride"),Ih.forEach(t),Aa=a(Mu," pour fixer le nombre de "),Sa=r(Mu,"EM",{});var Bh=l(Sa);zs=a(Bh,"tokens"),Bh.forEach(t),tl=a(Mu," se chevauchant entre deux morceaux successifs (ici 50)"),Mu.forEach(t),nl=c(Ya),it=r(Ya,"LI",{});var zu=l(it);xe=r(zu,"CODE",{});var Fh=l(xe);al=a(Fh,"return_overflowing_tokens=True"),Fh.forEach(t),ol=a(zu," pour indiquer au tokenizer que l\u2019on veut les "),Da=r(zu,"EM",{});var Vh=l(Da);rl=a(Vh,"tokens"),Vh.forEach(t),ll=a(zu," qui d\xE9bordent"),zu.forEach(t),Ya.forEach(t),In=c(e),k(Gt.$$.fragment,e),ue=c(e),k(Wt.$$.fragment,e),Fo=c(e),fe=r(e,"P",{});var Fs=l(fe);il=a(Fs,"Comme nous pouvons le voir, notre exemple a \xE9t\xE9 divis\xE9 en quatre entr\xE9es, chacune d\u2019entre elles contenant la question et une partie du contexte. Notez que la r\xE9ponse \xE0 la question (\u201CBernadette Soubirous\u201D) n\u2019appara\xEEt que dans la troisi\xE8me et derni\xE8re entr\xE9e, donc en traitant les longs contextes de cette fa\xE7on, nous allons cr\xE9er quelques exemples d\u2019entra\xEEnement o\xF9 la r\xE9ponse n\u2019est pas incluse dans le contexte. Pour ces exemples, les \xE9tiquettes seront "),Ma=r(Fs,"CODE",{});var Hh=l(Ma);ul=a(Hh,"start_position = end_position = 0"),Hh.forEach(t),pl=a(Fs," (donc nous pr\xE9disons le "),Ts=r(Fs,"EM",{});var Rh=l(Ts);dl=a(Rh,"token"),Rh.forEach(t),cl=c(Fs),za=r(Fs,"CODE",{});var Uh=l(za);Qd=a(Uh,"[CLS]"),Uh.forEach(t),Gd=a(Fs,"). Nous d\xE9finirons \xE9galement ces \xE9tiquettes dans le cas malheureux o\xF9 la r\xE9ponse a \xE9t\xE9 tronqu\xE9e de sorte que nous n\u2019avons que le d\xE9but (ou la fin) de celle-ci. Pour les exemples o\xF9 la r\xE9ponse est enti\xE8rement dans le contexte, les \xE9tiquettes seront l\u2019index du "),pi=r(Fs,"EM",{});var Qh=l(pi);Wd=a(Qh,"token"),Qh.forEach(t),Jd=a(Fs," o\xF9 la r\xE9ponse commence et l\u2019index du "),di=r(Fs,"EM",{});var Gh=l(di);Xd=a(Gh,"token"),Gh.forEach(t),Kd=a(Fs," o\xF9 la r\xE9ponse se termine."),Fs.forEach(t),Tu=c(e),Ve=r(e,"P",{});var nn=l(Ve);Yd=a(nn,"L\u2019ensemble de donn\xE9es nous fournit le caract\xE8re de d\xE9but de la r\xE9ponse dans le contexte, et en ajoutant la longueur de la r\xE9ponse, nous pouvons trouver le caract\xE8re de fin dans le contexte. Pour faire correspondre ces indices aux "),ci=r(nn,"EM",{});var Wh=l(ci);Zd=a(Wh,"tokens"),Wh.forEach(t),ec=a(nn,", nous devrons utiliser les mappages d\u2019offset que nous avons \xE9tudi\xE9s au "),ml=r(nn,"A",{href:!0});var Jh=l(ml);sc=a(Jh,"Chapitre 6"),Jh.forEach(t),tc=a(nn,". Nous pouvons faire en sorte que notre "),mi=r(nn,"EM",{});var Xh=l(mi);nc=a(Xh,"tokenizer"),Xh.forEach(t),ac=a(nn," renvoie ces index en passant "),fi=r(nn,"CODE",{});var Kh=l(fi);oc=a(Kh,"return_offsets_mapping=True"),Kh.forEach(t),rc=a(nn," :"),nn.forEach(t),Lu=c(e),k(Vo.$$.fragment,e),Nu=c(e),k(Ho.$$.fragment,e),Ou=c(e),Ls=r(e,"P",{});var Za=l(Ls);lc=a(Za,"Comme nous pouvons le voir, nous r\xE9cup\xE9rons les habituels ID d\u2019entr\xE9e, ID de type de jeton, et masque d\u2019attention, ainsi que le mappage d\u2019offset dont nous avions besoin et une cl\xE9 suppl\xE9mentaire, "),_i=r(Za,"CODE",{});var Yh=l(_i);ic=a(Yh,"overflow_to_sample_mapping"),Yh.forEach(t),uc=a(Za,". La valeur correspondante nous sera utile lorsque nous tokeniserons plusieurs textes en m\xEAme temps (ce que nous devrions faire pour b\xE9n\xE9ficier du fait que notre "),hi=r(Za,"EM",{});var Zh=l(hi);pc=a(Zh,"tokenizer"),Zh.forEach(t),dc=a(Za," est soutenu par Rust). Puisqu\u2019un \xE9chantillon peut donner plusieurs caract\xE9ristiques, il fait correspondre chaque caract\xE9ristique \xE0 l\u2019exemple d\u2019o\xF9 elle provient. Parce qu\u2019ici nous avons seulement tokenis\xE9 un exemple, nous obtenons une liste de "),vi=r(Za,"CODE",{});var ev=l(vi);cc=a(ev,"0"),ev.forEach(t),mc=a(Za,"s :"),Za.forEach(t),Iu=c(e),k(Ro.$$.fragment,e),Bu=c(e),k(Uo.$$.fragment,e),Fu=c(e),fl=r(e,"P",{});var sv=l(fl);fc=a(sv,"Mais si nous tokenisons plus d\u2019exemples, cela deviendra plus utile :"),sv.forEach(t),Vu=c(e),k(Qo.$$.fragment,e),Hu=c(e),k(Go.$$.fragment,e),Ru=c(e),_l=r(e,"P",{});var tv=l(_l);_c=a(tv,"Comme nous pouvons le voir, les trois premiers exemples (aux indices 2, 3 et 4 de l\u2019ensemble d\u2019entra\xEEnement) ont chacun donn\xE9 quatre caract\xE9ristiques et le dernier exemple (\xE0 l\u2019indice 5 de l\u2019ensemble d\u2019entra\xEEnement) a donn\xE9 7 caract\xE9ristiques."),tv.forEach(t),Uu=c(e),hl=r(e,"P",{});var nv=l(hl);hc=a(nv,"Ces informations seront utiles pour associer chaque caract\xE9ristique obtenue \xE0 son \xE9tiquette correspondante. Comme mentionn\xE9 pr\xE9c\xE9demment, ces \xE9tiquettes sont :"),nv.forEach(t),Qu=c(e),Ta=r(e,"UL",{});var yd=l(Ta);vl=r(yd,"LI",{});var A_=l(vl);bi=r(A_,"CODE",{});var av=l(bi);vc=a(av,"(0, 0)"),av.forEach(t),bc=a(A_," si la r\xE9ponse n\u2019est pas dans l\u2019espace correspondant du contexte."),A_.forEach(t),gc=c(yd),He=r(yd,"LI",{});var wt=l(He);gi=r(wt,"CODE",{});var ov=l(gi);qc=a(ov,"(start_position, end_position)"),ov.forEach(t),xc=a(wt," si la r\xE9ponse est dans l\u2019espace correspondant du contexte, avec "),qi=r(wt,"CODE",{});var rv=l(qi);$c=a(rv,"start_position"),rv.forEach(t),wc=a(wt," \xE9tant l\u2019index du "),xi=r(wt,"EM",{});var lv=l(xi);jc=a(lv,"token"),lv.forEach(t),kc=a(wt," (dans les IDs d\u2019entr\xE9e) au d\xE9but de la r\xE9ponse et "),$i=r(wt,"CODE",{});var iv=l($i);Ec=a(iv,"end_position"),iv.forEach(t),yc=a(wt," \xE9tant l\u2019index du "),wi=r(wt,"EM",{});var uv=l(wi);Cc=a(uv,"token"),uv.forEach(t),Pc=a(wt," (dans les IDs d\u2019entr\xE9e) o\xF9 la r\xE9ponse se termine."),wt.forEach(t),yd.forEach(t),Gu=c(e),Re=r(e,"P",{});var an=l(Re);Ac=a(an,"Pour d\xE9terminer ce qui est le cas et, le cas \xE9ch\xE9ant, les positions des "),ji=r(an,"EM",{});var pv=l(ji);Sc=a(pv,"tokens"),pv.forEach(t),Dc=a(an,", nous trouvons d\u2019abord les indices qui commencent et finissent le contexte dans les IDs d\u2019entr\xE9e. Nous pourrions utiliser les IDs du type de "),ki=r(an,"EM",{});var dv=l(ki);Mc=a(dv,"token"),dv.forEach(t),zc=a(an," pour le faire, mais puisque ceux-ci n\u2019existent pas n\xE9cessairement pour tous les mod\xE8les (DistilBERT ne les requiert pas, par exemple), nous allons plut\xF4t utiliser la m\xE9thode "),Ei=r(an,"CODE",{});var cv=l(Ei);Tc=a(cv,"sequence_ids()"),cv.forEach(t),Lc=a(an," du "),yi=r(an,"CODE",{});var mv=l(yi);Nc=a(mv,"BatchEncoding"),mv.forEach(t),Oc=a(an," que notre tokenizer retourne."),an.forEach(t),Wu=c(e),Ue=r(e,"P",{});var on=l(Ue);Ic=a(on,"Une fois que nous avons ces indices de "),Ci=r(on,"EM",{});var fv=l(Ci);Bc=a(fv,"tokens"),fv.forEach(t),Fc=a(on,", nous regardons les offsets correspondants, qui sont des tuples de deux entiers repr\xE9sentant l\u2019\xE9tendue des caract\xE8res dans le contexte original. Nous pouvons ainsi d\xE9tecter si le "),Pi=r(on,"EM",{});var _v=l(Pi);Vc=a(_v,"chunk"),_v.forEach(t),Hc=a(on," du contexte dans cette fonctionnalit\xE9 commence apr\xE8s la r\xE9ponse ou se termine avant que la r\xE9ponse ne commence (dans ce cas, l\u2019\xE9tiquette est "),Ai=r(on,"CODE",{});var hv=l(Ai);Rc=a(hv,"(0, 0)"),hv.forEach(t),Uc=a(on,"). Si ce n\u2019est pas le cas, nous bouclons pour trouver le premier et le dernier "),Si=r(on,"EM",{});var vv=l(Si);Qc=a(vv,"token"),vv.forEach(t),Gc=a(on," de la r\xE9ponse :"),on.forEach(t),Ju=c(e),k(Wo.$$.fragment,e),Xu=c(e),k(Jo.$$.fragment,e),Ku=c(e),Jt=r(e,"P",{});var ei=l(Jt);Wc=a(ei,"Jetons un coup d\u2019\u0153il  \xE0 quelques r\xE9sultats pour v\xE9rifier que notre approche est correcte. Pour la premi\xE8re caract\xE9ristique, nous trouvons "),Di=r(ei,"CODE",{});var bv=l(Di);Jc=a(bv,"(83, 85)"),bv.forEach(t),Xc=a(ei," comme \xE9tiquettes, alors comparons la r\xE9ponse th\xE9orique avec l\u2019\xE9tendue d\xE9cod\xE9e des "),Mi=r(ei,"EM",{});var gv=l(Mi);Kc=a(gv,"tokens"),gv.forEach(t),Yc=a(ei," de 83 \xE0 85 (inclus) :"),ei.forEach(t),Yu=c(e),k(Xo.$$.fragment,e),Zu=c(e),k(Ko.$$.fragment,e),ep=c(e),Xt=r(e,"P",{});var si=l(Xt);Zc=a(si,"Donc, c\u2019est une correspondance ! Maintenant, v\xE9rifions l\u2019index 4, o\xF9 nous avons mis les \xE9tiquettes \xE0 "),zi=r(si,"CODE",{});var qv=l(zi);em=a(qv,"(0, 0)"),qv.forEach(t),sm=a(si,", ce qui signifie que la r\xE9ponse n\u2019est pas dans le "),Ti=r(si,"EM",{});var xv=l(Ti);tm=a(xv,"chunk"),xv.forEach(t),nm=a(si," de contexte de cette caract\xE9ristique :"),si.forEach(t),sp=c(e),k(Yo.$$.fragment,e),tp=c(e),k(Zo.$$.fragment,e),np=c(e),bl=r(e,"P",{});var $v=l(bl);am=a($v,"En effet, nous ne voyons pas la r\xE9ponse dans le contexte."),$v.forEach(t),ap=c(e),k(La.$$.fragment,e),op=c(e),gl=r(e,"P",{});var wv=l(gl);om=a(wv,"Maintenant que nous avons vu \xE9tape par \xE9tape comment pr\xE9traiter nos donn\xE9es d\u2019entra\xEEnement, nous pouvons les regrouper dans une fonction que nous appliquerons \xE0 l\u2019ensemble des donn\xE9es d\u2019entra\xEEnement. Nous allons rembourrer chaque caract\xE9ristique \xE0 la longueur maximale que nous avons d\xE9finie, car la plupart des contextes seront longs (et les \xE9chantillons correspondants seront divis\xE9s en plusieurs caract\xE9ristiques), il n\u2019y a donc pas de r\xE9el avantage \xE0 appliquer un rembourrage dynamique ici :"),wv.forEach(t),rp=c(e),k(er.$$.fragment,e),lp=c(e),ql=r(e,"P",{});var jv=l(ql);rm=a(jv,"Notez que nous avons d\xE9fini deux constantes pour d\xE9terminer la longueur maximale utilis\xE9e ainsi que la longueur de la fen\xEAtre glissante, et que nous avons ajout\xE9 un petit nettoyage avant la tok\xE9nisation : certaines des questions dans le jeu de donn\xE9es SQuAD ont des espaces suppl\xE9mentaires au d\xE9but et \xE0 la fin qui n\u2019ajoutent rien (et prennent de la place lors de la tok\xE9nisation si vous utilisez un mod\xE8le comme RoBERTa), donc nous avons supprim\xE9 ces espaces suppl\xE9mentaires."),jv.forEach(t),ip=c(e),Kt=r(e,"P",{});var ti=l(Kt);lm=a(ti,"Pour appliquer cette fonction \xE0 l\u2019ensemble de l\u2019entra\xEEnement, nous utilisons la m\xE9thode "),Li=r(ti,"CODE",{});var kv=l(Li);im=a(kv,"Dataset.map()"),kv.forEach(t),um=a(ti," avec le flag "),Ni=r(ti,"CODE",{});var Ev=l(Ni);pm=a(Ev,"batched=True"),Ev.forEach(t),dm=a(ti,". C\u2019est n\xE9cessaire ici car nous changeons la longueur de l\u2019ensemble de donn\xE9es (puisqu\u2019un exemple peut donner plusieurs caract\xE9ristiques d\u2019entra\xEEnement) :"),ti.forEach(t),up=c(e),k(sr.$$.fragment,e),pp=c(e),k(tr.$$.fragment,e),dp=c(e),xl=r(e,"P",{});var yv=l(xl);cm=a(yv,"Comme nous pouvons le voir, le pr\xE9traitement a ajout\xE9 environ 1 000 caract\xE9ristiques. Notre ensemble d\u2019entra\xEEnement est maintenant pr\xEAt \xE0 \xEAtre utilis\xE9 - passons au pr\xE9traitement de l\u2019ensemble de validation !"),yv.forEach(t),cp=c(e),Bn=r(e,"H3",{class:!0});var Cd=l(Bn);Na=r(Cd,"A",{id:!0,class:!0,href:!0});var Cv=l(Na);Oi=r(Cv,"SPAN",{});var Pv=l(Oi);k(nr.$$.fragment,Pv),Pv.forEach(t),Cv.forEach(t),mm=c(Cd),Ii=r(Cd,"SPAN",{});var Av=l(Ii);fm=a(Av,"Traitement des donn\xE9es de validation"),Av.forEach(t),Cd.forEach(t),mp=c(e),$l=r(e,"P",{});var Sv=l($l);_m=a(Sv,"Le pr\xE9traitement des donn\xE9es de validation sera l\xE9g\xE8rement plus facile car nous n\u2019avons pas besoin de g\xE9n\xE9rer des \xE9tiquettes (sauf si nous voulons calculer une perte de validation, mais ce nombre ne nous aidera pas vraiment \xE0 comprendre la qualit\xE9 du mod\xE8le). La vraie joie sera d\u2019interpr\xE9ter les pr\xE9dictions du mod\xE8le dans des \xE9tendues du contexte original. Pour cela, il nous suffit de stocker les mappages de d\xE9calage et un moyen de faire correspondre chaque caract\xE9ristique cr\xE9\xE9e \xE0 l\u2019exemple original dont elle provient. Puisqu\u2019il y a une colonne ID dans l\u2019ensemble de donn\xE9es original, nous utiliserons cet ID."),Sv.forEach(t),fp=c(e),Ns=r(e,"P",{});var eo=l(Ns);hm=a(eo,"La seule chose que nous allons ajouter ici est un petit nettoyage des mappages de d\xE9calage. Ils contiendront les offsets pour la question et le contexte, mais une fois que nous serons dans la phase de post-traitement, nous n\u2019aurons aucun moyen de savoir quelle partie des IDs d\u2019entr\xE9e correspondait au contexte et quelle partie \xE9tait la question (la m\xE9thode "),Bi=r(eo,"CODE",{});var Dv=l(Bi);vm=a(Dv,"sequence_ids()"),Dv.forEach(t),bm=a(eo," que nous avons utilis\xE9e n\u2019est disponible que pour la sortie du "),Fi=r(eo,"EM",{});var Mv=l(Fi);gm=a(Mv,"tokenizer"),Mv.forEach(t),qm=a(eo,"). Donc, nous allons mettre les offsets correspondant \xE0 la question \xE0 "),Vi=r(eo,"CODE",{});var zv=l(Vi);xm=a(zv,"None"),zv.forEach(t),$m=a(eo," :"),eo.forEach(t),_p=c(e),k(ar.$$.fragment,e),hp=c(e),wl=r(e,"P",{});var Tv=l(wl);wm=a(Tv,"Nous pouvons appliquer cette fonction sur l\u2019ensemble des donn\xE9es de validation comme pr\xE9c\xE9demment :"),Tv.forEach(t),vp=c(e),k(or.$$.fragment,e),bp=c(e),k(rr.$$.fragment,e),gp=c(e),jl=r(e,"P",{});var Lv=l(jl);jm=a(Lv,"Dans ce cas, nous n\u2019avons ajout\xE9 que quelques centaines d\u2019\xE9chantillons, il semble donc que les contextes dans l\u2019ensemble de donn\xE9es de validation soient un peu plus courts."),Lv.forEach(t),qp=c(e),kl=r(e,"P",{});var Nv=l(kl);km=a(Nv,"Maintenant que nous avons pr\xE9trait\xE9 toutes les donn\xE9es, nous pouvons passer \xE0 l\u2019entra\xEEnement."),Nv.forEach(t),xp=c(e),pt.l(e),El=c(e),Fn=r(e,"H3",{class:!0});var Pd=l(Fn);Oa=r(Pd,"A",{id:!0,class:!0,href:!0});var Ov=l(Oa);Hi=r(Ov,"SPAN",{});var Iv=l(Hi);k(lr.$$.fragment,Iv),Iv.forEach(t),Ov.forEach(t),Em=c(Pd),Ri=r(Pd,"SPAN",{});var Bv=l(Ri);ym=a(Bv,"Post-traitement"),Bv.forEach(t),Pd.forEach(t),$p=c(e),ct.l(e),yl=c(e),Ia=r(e,"P",{});var Ad=l(Ia);Cm=a(Ad,"Le mod\xE8le produira des logits pour les positions de d\xE9but et de fin de la r\xE9ponse dans les IDs d\u2019entr\xE9e, comme nous l\u2019avons vu lors de notre exploration du "),ir=r(Ad,"A",{href:!0});var S_=l(ir);Ui=r(S_,"CODE",{});var Fv=l(Ui);Pm=a(Fv,"question-answering"),Fv.forEach(t),Am=a(S_," pipeline"),S_.forEach(t),Sm=a(Ad,". L\u2019\xE9tape de post-traitement sera similaire \xE0 ce que nous avons fait l\xE0-bas, donc voici un rappel rapide des actions que nous avons prises :"),Ad.forEach(t),wp=c(e),Os=r(e,"UL",{});var so=l(Os);ur=r(so,"LI",{});var Sd=l(ur);Dm=a(Sd,"nous avons masqu\xE9 les logits de d\xE9but et de fin correspondant aux "),Qi=r(Sd,"EM",{});var Vv=l(Qi);Mm=a(Vv,"tokens"),Vv.forEach(t),zm=a(Sd," en dehors du contexte,"),Sd.forEach(t),Tm=c(so),Gi=r(so,"LI",{});var Hv=l(Gi);Lm=a(Hv,"nous avons ensuite converti les logits de d\xE9but et de fin en probabilit\xE9s en utilisant un softmax,"),Hv.forEach(t),Nm=c(so),pr=r(so,"LI",{});var Dd=l(pr);Om=a(Dd,"nous avons attribu\xE9 un score \xE0 chaque paire "),Wi=r(Dd,"CODE",{});var Rv=l(Wi);Im=a(Rv,"(start_token, end_token)"),Rv.forEach(t),Bm=a(Dd," en prenant le produit des deux probabilit\xE9s correspondantes,"),Dd.forEach(t),Fm=c(so),Vn=r(so,"LI",{});var ni=l(Vn);Vm=a(ni,"nous avons cherch\xE9 la paire avec le score maximum qui donnait une r\xE9ponse valide (par exemple, un "),Ji=r(ni,"CODE",{});var Uv=l(Ji);Hm=a(Uv,"start_token"),Uv.forEach(t),Rm=a(ni," inf\xE9rieur au "),Xi=r(ni,"CODE",{});var Qv=l(Xi);Um=a(Qv,"end_token"),Qv.forEach(t),Qm=a(ni,")."),ni.forEach(t),so.forEach(t),jp=c(e),Is=r(e,"P",{});var to=l(Is);Gm=a(to,"Ici, nous allons modifier l\xE9g\xE8rement ce processus car nous n\u2019avons pas besoin de calculer les scores r\xE9els (juste la r\xE9ponse pr\xE9dite). Cela signifie que nous pouvons sauter l\u2019\xE9tape du softmax. Pour aller plus vite, nous ne noterons pas non plus toutes les paires "),Ki=r(to,"CODE",{});var Gv=l(Ki);Wm=a(Gv,"(start_token, end_token)"),Gv.forEach(t),Jm=a(to," possibles, mais seulement celles correspondant aux logits "),Yi=r(to,"CODE",{});var Wv=l(Yi);Xm=a(Wv,"n_best"),Wv.forEach(t),Km=a(to," les plus \xE9lev\xE9s (avec "),Zi=r(to,"CODE",{});var Jv=l(Zi);Ym=a(Jv,"n_best=20"),Jv.forEach(t),Zm=a(to,"). Puisque nous sauterons le softmax, ces scores seront des scores logit, et seront obtenus en prenant la somme des logits de d\xE9but et de fin (au lieu du produit, \xE0 cause de la r\xE8gle \\(\\log(ab) = \\log(a) + \\log(b)))."),to.forEach(t),kp=c(e),Ba=r(e,"P",{});var Md=l(Ba);ef=a(Md,"Pour d\xE9montrer tout cela, nous aurons besoin d\u2019un certain type de pr\xE9dictions. Puisque nous n\u2019avons pas encore entra\xEEn\xE9 notre mod\xE8le, nous allons utiliser le mod\xE8le par d\xE9faut du pipeline d\u2019assurance qualit\xE9 pour g\xE9n\xE9rer quelques pr\xE9dictions sur une petite partie de l\u2019ensemble de validation. Nous pouvons utiliser la m\xEAme fonction de traitement que pr\xE9c\xE9demment ; parce qu\u2019elle repose sur la constante globale "),eu=r(Md,"CODE",{});var Xv=l(eu);sf=a(Xv,"tokenizer"),Xv.forEach(t),tf=a(Md,", nous devons juste changer cet objet pour le tokenizer du mod\xE8le que nous voulons utiliser temporairement :"),Md.forEach(t),Ep=c(e),k(dr.$$.fragment,e),yp=c(e),Fa=r(e,"P",{});var zd=l(Fa);nf=a(zd,"Maintenant que le pr\xE9traitement est termin\xE9, nous changeons le "),su=r(zd,"EM",{});var Kv=l(su);af=a(Kv,"tokenizer"),Kv.forEach(t),of=a(zd," pour celui que nous avons choisi \xE0 l\u2019origine :"),zd.forEach(t),Cp=c(e),k(cr.$$.fragment,e),Pp=c(e),Va=r(e,"P",{});var Td=l(Va);rf=a(Td,"Nous supprimons ensuite les colonnes de notre "),tu=r(Td,"CODE",{});var Yv=l(tu);lf=a(Yv,"eval_set"),Yv.forEach(t),uf=a(Td," qui ne sont pas attendues par le mod\xE8le, nous construisons un lot avec l\u2019ensemble de ce petit ensemble de validation, et nous le passons au mod\xE8le. Si un GPU est disponible, nous l\u2019utilisons pour aller plus vite :"),Td.forEach(t),Ap=c(e),ft.l(e),Cl=c(e),Qe=r(e,"P",{});var rn=l(Qe);pf=a(rn,"Maintenant, nous devons trouver la r\xE9ponse pr\xE9dite pour chaque exemple dans notre "),nu=r(rn,"CODE",{});var Zv=l(nu);df=a(Zv,"small_eval_set"),Zv.forEach(t),cf=a(rn,". Un exemple peut avoir \xE9t\xE9 divis\xE9 en plusieurs caract\xE9ristiques dans "),au=r(rn,"CODE",{});var eb=l(au);mf=a(eb,"eval_set"),eb.forEach(t),ff=a(rn,", donc la premi\xE8re \xE9tape est de faire correspondre chaque exemple dans "),ou=r(rn,"CODE",{});var sb=l(ou);_f=a(sb,"small_eval_set"),sb.forEach(t),hf=a(rn," aux caract\xE9ristiques correspondantes dans "),ru=r(rn,"CODE",{});var tb=l(ru);vf=a(tb,"eval_set"),tb.forEach(t),bf=a(rn," :"),rn.forEach(t),Sp=c(e),k(mr.$$.fragment,e),Dp=c(e),Ha=r(e,"P",{});var Ld=l(Ha);gf=a(Ld,"Avec cela en main, nous pouvons vraiment nous mettre au travail en parcourant en boucle tous les exemples et, pour chaque exemple, toutes les caract\xE9ristiques associ\xE9es. Comme nous l\u2019avons dit pr\xE9c\xE9demment, nous allons regarder les scores logit pour les "),lu=r(Ld,"CODE",{});var nb=l(lu);qf=a(nb,"n_meilleurs"),nb.forEach(t),xf=a(Ld," logits de d\xE9but et logits de fin, en excluant les positions qui donnent :"),Ld.forEach(t),Mp=c(e),Yt=r(e,"UL",{});var ai=l(Yt);iu=r(ai,"LI",{});var ab=l(iu);$f=a(ab,"une r\xE9ponse qui ne serait pas dans le contexte."),ab.forEach(t),wf=c(ai),uu=r(ai,"LI",{});var ob=l(uu);jf=a(ob,"une r\xE9ponse avec une longueur n\xE9gative"),ob.forEach(t),kf=c(ai),fr=r(ai,"LI",{});var Nd=l(fr);Ef=a(Nd,"une r\xE9ponse qui est trop longue (nous limitons les possibilit\xE9s \xE0 "),pu=r(Nd,"CODE",{});var rb=l(pu);yf=a(rb,"max_answer_length=30"),rb.forEach(t),Cf=a(Nd,")"),Nd.forEach(t),ai.forEach(t),zp=c(e),Pl=r(e,"P",{});var lb=l(Pl);Pf=a(lb,"Une fois que nous avons toutes les r\xE9ponses possibles not\xE9es pour un exemple, nous choisissons simplement celle qui a le meilleur score logit :"),lb.forEach(t),Tp=c(e),k(_r.$$.fragment,e),Lp=c(e),Ra=r(e,"P",{});var Od=l(Ra);Af=a(Od,"Le format final des r\xE9ponses pr\xE9dites est celui qui sera attendu par la m\xE9trique que nous allons utiliser. Comme d\u2019habitude, nous pouvons le charger \xE0 l\u2019aide de la biblioth\xE8que \u{1F917} "),du=r(Od,"EM",{});var ib=l(du);Sf=a(ib,"Datasets"),ib.forEach(t),Df=a(Od," :"),Od.forEach(t),Np=c(e),k(hr.$$.fragment,e),Op=c(e),Al=r(e,"P",{});var ub=l(Al);Mf=a(ub,"Cette m\xE9trique attend les r\xE9ponses pr\xE9dites dans le format que nous avons vu ci-dessus (une liste de dictionnaires avec une cl\xE9 pour l\u2019ID de l\u2019exemple et une cl\xE9 pour le texte pr\xE9dit) et les r\xE9ponses th\xE9oriques dans le format ci-dessous (une liste de dictionnaires avec une cl\xE9 pour l\u2019ID de l\u2019exemple et une cl\xE9 pour les r\xE9ponses possibles) :"),ub.forEach(t),Ip=c(e),k(vr.$$.fragment,e),Bp=c(e),Sl=r(e,"P",{});var pb=l(Sl);zf=a(pb,"Nous pouvons maintenant v\xE9rifier que nous obtenons des r\xE9sultats raisonnables en examinant le premier \xE9l\xE9ment des deux listes :"),pb.forEach(t),Fp=c(e),k(br.$$.fragment,e),Vp=c(e),k(gr.$$.fragment,e),Hp=c(e),Dl=r(e,"P",{});var db=l(Dl);Tf=a(db,"Pas trop mal ! Voyons maintenant le score que la m\xE9trique nous donne :"),db.forEach(t),Rp=c(e),k(qr.$$.fragment,e),Up=c(e),k(xr.$$.fragment,e),Qp=c(e),Zt=r(e,"P",{});var oi=l(Zt);Lf=a(oi,"Encore une fois, c\u2019est plut\xF4t bon si l\u2019on consid\xE8re que, selon "),$r=r(oi,"A",{href:!0,rel:!0});var cb=l($r);Nf=a(cb,"son article"),cb.forEach(t),Of=a(oi,", DistilBERT "),cu=r(oi,"EM",{});var mb=l(cu);If=a(mb,"finetun\xE9"),mb.forEach(t),Bf=a(oi," sur SQuAD obtient 79,1 et 86,9 pour ces scores sur l\u2019ensemble des donn\xE9es."),oi.forEach(t),Gp=c(e),Un.l(e),Ml=c(e),k(wr.$$.fragment,e),Wp=c(e),zl=r(e,"P",{});var fb=l(zl);Ff=a(fb,"Nous pouvons v\xE9rifier que cela fonctionne sur nos pr\xE9dictions :"),fb.forEach(t),Jp=c(e),k(jr.$$.fragment,e),Xp=c(e),k(kr.$$.fragment,e),Kp=c(e),Tl=r(e,"P",{});var _b=l(Tl);Vf=a(_b,"C\u2019est bien ! Maintenant, utilisons ceci pour affiner notre mod\xE8le."),_b.forEach(t),Yp=c(e),Hn=r(e,"H3",{class:!0});var Id=l(Hn);Ua=r(Id,"A",{id:!0,class:!0,href:!0});var hb=l(Ua);mu=r(hb,"SPAN",{});var vb=l(mu);k(Er.$$.fragment,vb),vb.forEach(t),hb.forEach(t),Hf=c(Id),fu=r(Id,"SPAN",{});var bb=l(fu);Rf=a(bb,"*Finetuning* du mod\xE8le"),bb.forEach(t),Id.forEach(t),Zp=c(e),ht.l(e),Ll=c(e),Qa=r(e,"P",{});var Bd=l(Qa);Uf=a(Bd,"Comme d\u2019habitude, nous recevons un avertissement indiquant que certains poids ne sont pas utilis\xE9s (ceux de la t\xEAte de pr\xE9-entra\xEEnement) et que d\u2019autres sont initialis\xE9s de mani\xE8re al\xE9atoire (ceux de la t\xEAte de r\xE9ponse aux questions). Vous devriez \xEAtre habitu\xE9 \xE0 cela maintenant, mais cela signifie que ce mod\xE8le n\u2019est pas encore pr\xEAt \xE0 \xEAtre utilis\xE9 et qu\u2019il a besoin d\u2019\xEAtre "),_u=r(Bd,"EM",{});var gb=l(_u);Qf=a(gb,"finetun\xE9"),gb.forEach(t),Gf=a(Bd,". Une bonne chose que nous soyons sur le point de le faire !"),Bd.forEach(t),ed=c(e),en=r(e,"P",{});var ri=l(en);Wf=a(ri,"Pour pouvoir pousser notre mod\xE8le vers le "),hu=r(ri,"EM",{});var qb=l(hu);Jf=a(qb,"Hub"),qb.forEach(t),Xf=a(ri,", nous devons nous connecter \xE0 Hugging Face. Si vous ex\xE9cutez ce code dans un "),vu=r(ri,"EM",{});var xb=l(vu);Kf=a(xb,"notebook"),xb.forEach(t),Yf=a(ri,", vous pouvez le faire avec la fonction utilitaire suivante, qui affiche un widget o\xF9 vous pouvez entrer vos identifiants de connexion :"),ri.forEach(t),sd=c(e),k(yr.$$.fragment,e),td=c(e),Ga=r(e,"P",{});var Fd=l(Ga);Zf=a(Fd,"Si vous ne travaillez pas dans un "),bu=r(Fd,"EM",{});var $b=l(bu);e_=a($b,"notebook"),$b.forEach(t),s_=a(Fd,", tapez simplement la ligne suivante dans votre terminal :"),Fd.forEach(t),nd=c(e),k(Cr.$$.fragment,e),ad=c(e),bt.l(e),Nl=c(e),Ge=r(e,"P",{});var ln=l(Ge);t_=a(ln,"Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace de noms et nomm\xE9 apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, donc dans notre cas il sera dans "),gu=r(ln,"CODE",{});var wb=l(gu);n_=a(wb,'"sgugger/bert-finetuned-squad"'),wb.forEach(t),a_=a(ln,". Nous pouvons passer outre en passant un "),qu=r(ln,"CODE",{});var jb=l(qu);o_=a(jb,"hub_model_id"),jb.forEach(t),r_=a(ln," ; par exemple, pour pousser le mod\xE8le dans l\u2019organisation "),xu=r(ln,"CODE",{});var kb=l(xu);l_=a(kb,"huggingface_course"),kb.forEach(t),i_=a(ln," nous avons utilis\xE9 "),$u=r(ln,"CODE",{});var Eb=l($u);u_=a(Eb,'hub_model_id= "huggingface_course/bert-finetuned-squad"'),Eb.forEach(t),p_=a(ln," (qui est le mod\xE8le que nous avons li\xE9 au d\xE9but de cette section)."),ln.forEach(t),od=c(e),qt.l(e),Ol=c(e),Il=r(e,"P",{});var yb=l(Il);d_=a(yb,"Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le Hub en arri\xE8re-plan. Ainsi, vous pourrez reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire. L\u2019ensemble de l\u2019entra\xEEnement prend un certain temps (un peu plus d\u2019une heure sur une Titan RTX), vous pouvez donc prendre un caf\xE9 ou relire les parties du cours qui vous ont sembl\xE9 plus difficiles pendant qu\u2019il se d\xE9roule. Notez \xE9galement que d\xE8s que la premi\xE8re \xE9poque est termin\xE9e, vous verrez des poids t\xE9l\xE9charg\xE9s sur le Hub et vous pourrez commencer \xE0 jouer avec votre mod\xE8le sur sa page."),yb.forEach(t),rd=c(e),$t.l(e),Bl=c(e),k(Pr.$$.fragment,e),ld=c(e),Fl=r(e,"P",{});var Cb=l(Fl);c_=a(Cb,"Super ! \xC0 titre de comparaison, les scores de base indiqu\xE9s dans l\u2019article du BERT pour ce mod\xE8le sont de 80,8 et 88,5, donc nous sommes exactement l\xE0 o\xF9 nous devrions \xEAtre."),Cb.forEach(t),id=c(e),_e&&_e.l(e),Vl=c(e),sn=r(e,"P",{});var li=l(sn);m_=a(li,"\xC0 ce stade, vous pouvez utiliser le widget d\u2019inf\xE9rence sur le "),wu=r(li,"EM",{});var Pb=l(wu);f_=a(Pb,"Hub"),Pb.forEach(t),__=a(li," du mod\xE8le pour tester le mod\xE8le et le partager avec vos amis, votre famille et vos animaux pr\xE9f\xE9r\xE9s. Vous avez r\xE9ussi \xE0 "),ju=r(li,"EM",{});var Ab=l(ju);h_=a(Ab,"finetuner"),Ab.forEach(t),v_=a(li," un mod\xE8le sur une t\xE2che de r\xE9ponse \xE0 une question - f\xE9licitations !"),li.forEach(t),ud=c(e),k(Wa.$$.fragment,e),pd=c(e),he&&he.l(e),Hl=c(e),Rn=r(e,"H3",{class:!0});var Vd=l(Rn);Ja=r(Vd,"A",{id:!0,class:!0,href:!0});var Sb=l(Ja);ku=r(Sb,"SPAN",{});var Db=l(ku);k(Ar.$$.fragment,Db),Db.forEach(t),Sb.forEach(t),b_=c(Vd),Eu=r(Vd,"SPAN",{});var Mb=l(Eu);g_=a(Mb,"Utilisation du mod\xE8le *finetun\xE9*"),Mb.forEach(t),Vd.forEach(t),dd=c(e),Bs=r(e,"P",{});var no=l(Bs);q_=a(no,"Nous vous avons d\xE9j\xE0 montr\xE9 comment vous pouvez utiliser le mod\xE8le que nous avons "),yu=r(no,"EM",{});var zb=l(yu);x_=a(zb,"finetun\xE9"),zb.forEach(t),$_=a(no," sur le "),Cu=r(no,"EM",{});var Tb=l(Cu);w_=a(Tb,"Hub"),Tb.forEach(t),j_=a(no," avec le widget d\u2019inf\xE9rence. Pour l\u2019utiliser localement dans un "),Pu=r(no,"CODE",{});var Lb=l(Pu);k_=a(Lb,"pipeline"),Lb.forEach(t),E_=a(no,", il suffit de sp\xE9cifier l\u2019identifiant du mod\xE8le :"),no.forEach(t),cd=c(e),k(Sr.$$.fragment,e),md=c(e),k(Dr.$$.fragment,e),fd=c(e),Rl=r(e,"P",{});var Nb=l(Rl);y_=a(Nb,"Super ! Notre mod\xE8le fonctionne aussi bien que le mod\xE8le par d\xE9faut pour ce pipeline !"),Nb.forEach(t),this.h()},h(){A(p,"name","hf:doc:metadata"),A(p,"content",JSON.stringify(hg)),A(g,"id","rponse-aux-questions"),A(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),A(g,"href","#rponse-aux-questions"),A(S,"class","relative group"),A(K,"href","https://rajpurkar.github.io/SQuAD-explorer/"),A(K,"rel","nofollow"),Hd(se.src,we="https://hf.space/gradioiframe/course-demos/bert-finetuned-squad/+")||A(se,"src",we),A(se,"frameborder","0"),A(se,"height","450"),A(se,"title","Gradio app"),A(se,"class","block dark:hidden container p-0 flex-grow space-iframe"),A(se,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),A(se,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),Hd(re.src,ms="https://hf.space/gradioiframe/course-demos/bert-finetuned-squad-darkmode/+")||A(re,"src",ms),A(re,"frameborder","0"),A(re,"height","450"),A(re,"title","Gradio app"),A(re,"class","hidden dark:block container p-0 flex-grow space-iframe"),A(re,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),A(re,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),A(Ae,"href","https://huggingface.co/huggingface-course/bert-finetuned-squad?context=%F0%9F%A4%97+Transformers+is+backed+by+the+three+most+popular+deep+learning+libraries+%E2%80%94+Jax%2C+PyTorch+and+TensorFlow+%E2%80%94+with+a+seamless+integration+between+them.+It%27s+straightforward+to+train+your+models+with+one+before+loading+them+for+inference+with+the+other.&question=Which+deep+learning+libraries+back+%F0%9F%A4%97+Transformers%3F"),A(Ae,"rel","nofollow"),A(be,"id","prparation-des-donnes"),A(be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),A(be,"href","#prparation-des-donnes"),A(me,"class","relative group"),A(vs,"href","https://rajpurkar.github.io/SQuAD-explorer/"),A(vs,"rel","nofollow"),A(te,"href","https://huggingface.co/datasets/squad_v2"),A(te,"rel","nofollow"),A(Te,"id","le-jeu-de-donnes-squad"),A(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),A(Te,"href","#le-jeu-de-donnes-squad"),A(Ye,"class","relative group"),A(Es,"id","traitement-des-donnes-dentranement"),A(Es,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),A(Es,"href","#traitement-des-donnes-dentranement"),A(os,"class","relative group"),A(et,"href","https://huggingface.co/transformers/#supported-frameworks"),A(et,"rel","nofollow"),A(Vt,"class","block dark:hidden"),Hd(Vt.src,ii="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/qa_labels.svg")||A(Vt,"src",ii),A(Vt,"alt","One-hot encoded labels for question answering."),A(Ht,"class","hidden dark:block"),Hd(Ht.src,ui="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/qa_labels-dark.svg")||A(Ht,"src",ui),A(Ht,"alt","One-hot encoded labels for question answering."),A(Ms,"class","flex justify-center"),A(ot,"href","/course/fr/chapter6/4"),A(ml,"href","/course/chapter6/4"),A(Na,"id","traitement-des-donnes-de-validation"),A(Na,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),A(Na,"href","#traitement-des-donnes-de-validation"),A(Bn,"class","relative group"),A(Oa,"id","posttraitement"),A(Oa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),A(Oa,"href","#posttraitement"),A(Fn,"class","relative group"),A(ir,"href","/course/chapter6/4"),A($r,"href","https://arxiv.org/abs/1910.01108v2"),A($r,"rel","nofollow"),A(Ua,"id","finetuning-du-modle"),A(Ua,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),A(Ua,"href","#finetuning-du-modle"),A(Hn,"class","relative group"),A(Ja,"id","utilisation-du-modle-finetun"),A(Ja,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),A(Ja,"href","#utilisation-du-modle-finetun"),A(Rn,"class","relative group")},m(e,u){s(document.head,p),i(e,b,u),E(f,e,u),i(e,C,u),i(e,S,u),s(S,g),s(g,$),E(q,$,null),s(S,_),s(S,z),s(z,x),i(e,D,u),Mr[L].m(e,u),i(e,P,u),i(e,w,u),s(w,U),s(w,V),s(V,F),s(w,M),i(e,B,u),E(G,e,u),i(e,ee,u),i(e,Q,u),s(Q,W),s(Q,K),s(K,Y),s(Q,O),s(Q,X),s(X,$e),s(Q,de),i(e,J,u),i(e,se,u),i(e,ve,u),i(e,re,u),i(e,Xe,u),i(e,R,u),s(R,Z),s(R,fs),s(fs,jt),s(R,_s),s(R,Ae),s(Ae,Se),i(e,hs,u),E(ce,e,u),i(e,De,u),i(e,me,u),s(me,be),s(be,Ke),E(je,Ke,null),s(me,Gn),s(me,Me),s(Me,ao),i(e,kt,u),i(e,ze,u),s(ze,oo),s(ze,vs),s(vs,Vs),s(ze,Wn),s(ze,te),s(te,ro),s(ze,dn),i(e,Jn,u),i(e,Ye,u),s(Ye,Te),s(Te,cn),E(Hs,cn,null),s(Ye,mn),s(Ye,fn),s(fn,lo),i(e,Et,u),i(e,bs,u),s(bs,io),s(bs,Rs),s(Rs,uo),s(bs,po),i(e,yt,u),E(Us,e,u),i(e,Xn,u),i(e,gs,u),s(gs,co),i(e,Kn,u),E(qs,e,u),i(e,xs,u),E($s,e,u),i(e,ke,u),i(e,ge,u),s(ge,_n),s(ge,hn),s(hn,mo),s(ge,vn),s(ge,bn),s(bn,fo),s(ge,Yn),s(ge,Ze),s(Ze,Zn),s(ge,qe),i(e,ea,u),E(es,e,u),i(e,sa,u),E(Qs,e,u),i(e,Ct,u),i(e,ae,u),s(ae,_o),s(ae,Gs),s(Gs,ho),s(ae,vo),s(ae,Pt),s(Pt,Ws),s(ae,ta),s(ae,ss),s(ss,na),s(ae,At),s(ae,gn),s(gn,aa),s(ae,Js),s(ae,St),s(St,Le),s(ae,bo),s(ae,Xs),s(Xs,go),s(ae,qo),i(e,Dt,u),i(e,ws,u),s(ws,xo),s(ws,Mt),s(Mt,ts),s(ws,js),i(e,zt,u),E(Ee,e,u),i(e,oa,u),E(ns,e,u),i(e,ra,u),i(e,Ks,u),s(Ks,Tt),i(e,la,u),E(ks,e,u),i(e,ye,u),E(Ce,e,u),i(e,ia,u),i(e,Ne,u),s(Ne,$o),s(Ne,qn),s(qn,wo),s(Ne,Pe),i(e,ua,u),E(as,e,u),i(e,pa,u),E(Ys,e,u),i(e,Lt,u),i(e,Nt,u),s(Nt,jo),i(e,Ot,u),i(e,os,u),s(os,Es),s(Es,xn),E(le,xn,null),s(os,ko),s(os,Zs),s(Zs,Eo),i(e,da,u),E(rs,e,u),i(e,ca,u),i(e,ys,u),s(ys,$n),s(ys,wn),s(wn,yo),s(ys,jn),i(e,ma,u),i(e,Cs,u),s(Cs,fa),s(Cs,Ps),s(Ps,Co),s(Cs,_a),i(e,As,u),E(Ss,e,u),i(e,ls,u),i(e,oe,u),s(oe,kn),s(oe,En),s(En,Po),s(oe,ha),s(oe,is),s(is,va),s(oe,ne),s(oe,et),s(et,yn),s(oe,Ao),s(oe,Cn),s(Cn,Pn),s(oe,So),s(oe,An),s(An,Sn),s(oe,Do),s(oe,Dn),s(Dn,Mn),s(oe,Mo),i(e,ba,u),E(us,e,u),i(e,ga,u),E(st,e,u),i(e,It,u),i(e,Oe,u),s(Oe,zo),s(Oe,tt),s(tt,To),s(Oe,Lo),s(Oe,Bt),s(Bt,Ie),s(Oe,No),i(e,Ft,u),E(nt,e,u),i(e,qa,u),i(e,Be,u),s(Be,zn),i(e,xa,u),E(at,e,u),i(e,Tn,u),E(m,e,u),i(e,I,u),i(e,ps,u),s(ps,$a),s(ps,wa),s(wa,Vr),s(ps,Hr),s(ps,Ds),s(Ds,Rr),s(ps,Ur),i(e,Ln,u),i(e,Ms,u),s(Ms,Vt),s(Ms,Fe),s(Ms,Ht),i(e,Oo,u),i(e,ds,u),s(ds,Qr),s(ds,ot),s(ot,Gr),s(ds,pe),s(ds,ja),s(ja,Wr),s(ds,Jr),i(e,Io,u),i(e,rt,u),s(rt,Xr),s(rt,ka),s(ka,Rt),s(rt,Kr),i(e,Bo,u),i(e,ie,u),s(ie,Nn),s(Nn,Ea),s(Ea,Yr),s(Nn,Zr),s(ie,Ut),s(ie,On),s(On,ya),s(ya,Ca),s(On,el),s(ie,sl),s(ie,lt),s(lt,Pa),s(Pa,Qt),s(lt,Aa),s(lt,Sa),s(Sa,zs),s(lt,tl),s(ie,nl),s(ie,it),s(it,xe),s(xe,al),s(it,ol),s(it,Da),s(Da,rl),s(it,ll),i(e,In,u),E(Gt,e,u),i(e,ue,u),E(Wt,e,u),i(e,Fo,u),i(e,fe,u),s(fe,il),s(fe,Ma),s(Ma,ul),s(fe,pl),s(fe,Ts),s(Ts,dl),s(fe,cl),s(fe,za),s(za,Qd),s(fe,Gd),s(fe,pi),s(pi,Wd),s(fe,Jd),s(fe,di),s(di,Xd),s(fe,Kd),i(e,Tu,u),i(e,Ve,u),s(Ve,Yd),s(Ve,ci),s(ci,Zd),s(Ve,ec),s(Ve,ml),s(ml,sc),s(Ve,tc),s(Ve,mi),s(mi,nc),s(Ve,ac),s(Ve,fi),s(fi,oc),s(Ve,rc),i(e,Lu,u),E(Vo,e,u),i(e,Nu,u),E(Ho,e,u),i(e,Ou,u),i(e,Ls,u),s(Ls,lc),s(Ls,_i),s(_i,ic),s(Ls,uc),s(Ls,hi),s(hi,pc),s(Ls,dc),s(Ls,vi),s(vi,cc),s(Ls,mc),i(e,Iu,u),E(Ro,e,u),i(e,Bu,u),E(Uo,e,u),i(e,Fu,u),i(e,fl,u),s(fl,fc),i(e,Vu,u),E(Qo,e,u),i(e,Hu,u),E(Go,e,u),i(e,Ru,u),i(e,_l,u),s(_l,_c),i(e,Uu,u),i(e,hl,u),s(hl,hc),i(e,Qu,u),i(e,Ta,u),s(Ta,vl),s(vl,bi),s(bi,vc),s(vl,bc),s(Ta,gc),s(Ta,He),s(He,gi),s(gi,qc),s(He,xc),s(He,qi),s(qi,$c),s(He,wc),s(He,xi),s(xi,jc),s(He,kc),s(He,$i),s($i,Ec),s(He,yc),s(He,wi),s(wi,Cc),s(He,Pc),i(e,Gu,u),i(e,Re,u),s(Re,Ac),s(Re,ji),s(ji,Sc),s(Re,Dc),s(Re,ki),s(ki,Mc),s(Re,zc),s(Re,Ei),s(Ei,Tc),s(Re,Lc),s(Re,yi),s(yi,Nc),s(Re,Oc),i(e,Wu,u),i(e,Ue,u),s(Ue,Ic),s(Ue,Ci),s(Ci,Bc),s(Ue,Fc),s(Ue,Pi),s(Pi,Vc),s(Ue,Hc),s(Ue,Ai),s(Ai,Rc),s(Ue,Uc),s(Ue,Si),s(Si,Qc),s(Ue,Gc),i(e,Ju,u),E(Wo,e,u),i(e,Xu,u),E(Jo,e,u),i(e,Ku,u),i(e,Jt,u),s(Jt,Wc),s(Jt,Di),s(Di,Jc),s(Jt,Xc),s(Jt,Mi),s(Mi,Kc),s(Jt,Yc),i(e,Yu,u),E(Xo,e,u),i(e,Zu,u),E(Ko,e,u),i(e,ep,u),i(e,Xt,u),s(Xt,Zc),s(Xt,zi),s(zi,em),s(Xt,sm),s(Xt,Ti),s(Ti,tm),s(Xt,nm),i(e,sp,u),E(Yo,e,u),i(e,tp,u),E(Zo,e,u),i(e,np,u),i(e,bl,u),s(bl,am),i(e,ap,u),E(La,e,u),i(e,op,u),i(e,gl,u),s(gl,om),i(e,rp,u),E(er,e,u),i(e,lp,u),i(e,ql,u),s(ql,rm),i(e,ip,u),i(e,Kt,u),s(Kt,lm),s(Kt,Li),s(Li,im),s(Kt,um),s(Kt,Ni),s(Ni,pm),s(Kt,dm),i(e,up,u),E(sr,e,u),i(e,pp,u),E(tr,e,u),i(e,dp,u),i(e,xl,u),s(xl,cm),i(e,cp,u),i(e,Bn,u),s(Bn,Na),s(Na,Oi),E(nr,Oi,null),s(Bn,mm),s(Bn,Ii),s(Ii,fm),i(e,mp,u),i(e,$l,u),s($l,_m),i(e,fp,u),i(e,Ns,u),s(Ns,hm),s(Ns,Bi),s(Bi,vm),s(Ns,bm),s(Ns,Fi),s(Fi,gm),s(Ns,qm),s(Ns,Vi),s(Vi,xm),s(Ns,$m),i(e,_p,u),E(ar,e,u),i(e,hp,u),i(e,wl,u),s(wl,wm),i(e,vp,u),E(or,e,u),i(e,bp,u),E(rr,e,u),i(e,gp,u),i(e,jl,u),s(jl,jm),i(e,qp,u),i(e,kl,u),s(kl,km),i(e,xp,u),zr[ut].m(e,u),i(e,El,u),i(e,Fn,u),s(Fn,Oa),s(Oa,Hi),E(lr,Hi,null),s(Fn,Em),s(Fn,Ri),s(Ri,ym),i(e,$p,u),Tr[dt].m(e,u),i(e,yl,u),i(e,Ia,u),s(Ia,Cm),s(Ia,ir),s(ir,Ui),s(Ui,Pm),s(ir,Am),s(Ia,Sm),i(e,wp,u),i(e,Os,u),s(Os,ur),s(ur,Dm),s(ur,Qi),s(Qi,Mm),s(ur,zm),s(Os,Tm),s(Os,Gi),s(Gi,Lm),s(Os,Nm),s(Os,pr),s(pr,Om),s(pr,Wi),s(Wi,Im),s(pr,Bm),s(Os,Fm),s(Os,Vn),s(Vn,Vm),s(Vn,Ji),s(Ji,Hm),s(Vn,Rm),s(Vn,Xi),s(Xi,Um),s(Vn,Qm),i(e,jp,u),i(e,Is,u),s(Is,Gm),s(Is,Ki),s(Ki,Wm),s(Is,Jm),s(Is,Yi),s(Yi,Xm),s(Is,Km),s(Is,Zi),s(Zi,Ym),s(Is,Zm),i(e,kp,u),i(e,Ba,u),s(Ba,ef),s(Ba,eu),s(eu,sf),s(Ba,tf),i(e,Ep,u),E(dr,e,u),i(e,yp,u),i(e,Fa,u),s(Fa,nf),s(Fa,su),s(su,af),s(Fa,of),i(e,Cp,u),E(cr,e,u),i(e,Pp,u),i(e,Va,u),s(Va,rf),s(Va,tu),s(tu,lf),s(Va,uf),i(e,Ap,u),Lr[mt].m(e,u),i(e,Cl,u),i(e,Qe,u),s(Qe,pf),s(Qe,nu),s(nu,df),s(Qe,cf),s(Qe,au),s(au,mf),s(Qe,ff),s(Qe,ou),s(ou,_f),s(Qe,hf),s(Qe,ru),s(ru,vf),s(Qe,bf),i(e,Sp,u),E(mr,e,u),i(e,Dp,u),i(e,Ha,u),s(Ha,gf),s(Ha,lu),s(lu,qf),s(Ha,xf),i(e,Mp,u),i(e,Yt,u),s(Yt,iu),s(iu,$f),s(Yt,wf),s(Yt,uu),s(uu,jf),s(Yt,kf),s(Yt,fr),s(fr,Ef),s(fr,pu),s(pu,yf),s(fr,Cf),i(e,zp,u),i(e,Pl,u),s(Pl,Pf),i(e,Tp,u),E(_r,e,u),i(e,Lp,u),i(e,Ra,u),s(Ra,Af),s(Ra,du),s(du,Sf),s(Ra,Df),i(e,Np,u),E(hr,e,u),i(e,Op,u),i(e,Al,u),s(Al,Mf),i(e,Ip,u),E(vr,e,u),i(e,Bp,u),i(e,Sl,u),s(Sl,zf),i(e,Fp,u),E(br,e,u),i(e,Vp,u),E(gr,e,u),i(e,Hp,u),i(e,Dl,u),s(Dl,Tf),i(e,Rp,u),E(qr,e,u),i(e,Up,u),E(xr,e,u),i(e,Qp,u),i(e,Zt,u),s(Zt,Lf),s(Zt,$r),s($r,Nf),s(Zt,Of),s(Zt,cu),s(cu,If),s(Zt,Bf),i(e,Gp,u),Un.m(e,u),i(e,Ml,u),E(wr,e,u),i(e,Wp,u),i(e,zl,u),s(zl,Ff),i(e,Jp,u),E(jr,e,u),i(e,Xp,u),E(kr,e,u),i(e,Kp,u),i(e,Tl,u),s(Tl,Vf),i(e,Yp,u),i(e,Hn,u),s(Hn,Ua),s(Ua,mu),E(Er,mu,null),s(Hn,Hf),s(Hn,fu),s(fu,Rf),i(e,Zp,u),Nr[_t].m(e,u),i(e,Ll,u),i(e,Qa,u),s(Qa,Uf),s(Qa,_u),s(_u,Qf),s(Qa,Gf),i(e,ed,u),i(e,en,u),s(en,Wf),s(en,hu),s(hu,Jf),s(en,Xf),s(en,vu),s(vu,Kf),s(en,Yf),i(e,sd,u),E(yr,e,u),i(e,td,u),i(e,Ga,u),s(Ga,Zf),s(Ga,bu),s(bu,e_),s(Ga,s_),i(e,nd,u),E(Cr,e,u),i(e,ad,u),Or[vt].m(e,u),i(e,Nl,u),i(e,Ge,u),s(Ge,t_),s(Ge,gu),s(gu,n_),s(Ge,a_),s(Ge,qu),s(qu,o_),s(Ge,r_),s(Ge,xu),s(xu,l_),s(Ge,i_),s(Ge,$u),s($u,u_),s(Ge,p_),i(e,od,u),Ir[gt].m(e,u),i(e,Ol,u),i(e,Il,u),s(Il,d_),i(e,rd,u),Br[xt].m(e,u),i(e,Bl,u),E(Pr,e,u),i(e,ld,u),i(e,Fl,u),s(Fl,c_),i(e,id,u),_e&&_e.m(e,u),i(e,Vl,u),i(e,sn,u),s(sn,m_),s(sn,wu),s(wu,f_),s(sn,__),s(sn,ju),s(ju,h_),s(sn,v_),i(e,ud,u),E(Wa,e,u),i(e,pd,u),he&&he.m(e,u),i(e,Hl,u),i(e,Rn,u),s(Rn,Ja),s(Ja,ku),E(Ar,ku,null),s(Rn,b_),s(Rn,Eu),s(Eu,g_),i(e,dd,u),i(e,Bs,u),s(Bs,q_),s(Bs,yu),s(yu,x_),s(Bs,$_),s(Bs,Cu),s(Cu,w_),s(Bs,j_),s(Bs,Pu),s(Pu,k_),s(Bs,E_),i(e,cd,u),E(Sr,e,u),i(e,md,u),E(Dr,e,u),i(e,fd,u),i(e,Rl,u),s(Rl,y_),_d=!0},p(e,[u]){const Fr={};u&1&&(Fr.fw=e[0]),f.$set(Fr);let Ul=L;L=M_(e),L!==Ul&&(pn(),v(Mr[Ul],1,1,()=>{Mr[Ul]=null}),un(),N=Mr[L],N||(N=Mr[L]=D_[L](e),N.c()),h(N,1),N.m(P.parentNode,P));const Au={};u&2&&(Au.$$scope={dirty:u,ctx:e}),ce.$set(Au);const Su={};u&2&&(Su.$$scope={dirty:u,ctx:e}),La.$set(Su);let Xa=ut;ut=T_(e),ut!==Xa&&(pn(),v(zr[Xa],1,1,()=>{zr[Xa]=null}),un(),pt=zr[ut],pt||(pt=zr[ut]=z_[ut](e),pt.c()),h(pt,1),pt.m(El.parentNode,El));let Ql=dt;dt=N_(e),dt!==Ql&&(pn(),v(Tr[Ql],1,1,()=>{Tr[Ql]=null}),un(),ct=Tr[dt],ct||(ct=Tr[dt]=L_[dt](e),ct.c()),h(ct,1),ct.m(yl.parentNode,yl));let tn=mt;mt=I_(e),mt!==tn&&(pn(),v(Lr[tn],1,1,()=>{Lr[tn]=null}),un(),ft=Lr[mt],ft||(ft=Lr[mt]=O_[mt](e),ft.c()),h(ft,1),ft.m(Cl.parentNode,Cl)),hd!==(hd=B_(e))&&(Un.d(1),Un=hd(e),Un&&(Un.c(),Un.m(Ml.parentNode,Ml)));let Gl=_t;_t=V_(e),_t!==Gl&&(pn(),v(Nr[Gl],1,1,()=>{Nr[Gl]=null}),un(),ht=Nr[_t],ht||(ht=Nr[_t]=F_[_t](e),ht.c()),h(ht,1),ht.m(Ll.parentNode,Ll));let Wl=vt;vt=R_(e),vt!==Wl&&(pn(),v(Or[Wl],1,1,()=>{Or[Wl]=null}),un(),bt=Or[vt],bt||(bt=Or[vt]=H_[vt](e),bt.c()),h(bt,1),bt.m(Nl.parentNode,Nl));let Qn=gt;gt=Q_(e),gt!==Qn&&(pn(),v(Ir[Qn],1,1,()=>{Ir[Qn]=null}),un(),qt=Ir[gt],qt||(qt=Ir[gt]=U_[gt](e),qt.c()),h(qt,1),qt.m(Ol.parentNode,Ol));let Jl=xt;xt=W_(e),xt!==Jl&&(pn(),v(Br[Jl],1,1,()=>{Br[Jl]=null}),un(),$t=Br[xt],$t||($t=Br[xt]=G_[xt](e),$t.c()),h($t,1),$t.m(Bl.parentNode,Bl)),e[0]==="pt"?_e?u&1&&h(_e,1):(_e=Ob(),_e.c(),h(_e,1),_e.m(Vl.parentNode,Vl)):_e&&(pn(),v(_e,1,1,()=>{_e=null}),un());const Du={};u&2&&(Du.$$scope={dirty:u,ctx:e}),Wa.$set(Du),e[0]==="pt"?he?u&1&&h(he,1):(he=Ib(),he.c(),h(he,1),he.m(Hl.parentNode,Hl)):he&&(pn(),v(he,1,1,()=>{he=null}),un())},i(e){_d||(h(f.$$.fragment,e),h(q.$$.fragment,e),h(N),h(G.$$.fragment,e),h(ce.$$.fragment,e),h(je.$$.fragment,e),h(Hs.$$.fragment,e),h(Us.$$.fragment,e),h(qs.$$.fragment,e),h($s.$$.fragment,e),h(es.$$.fragment,e),h(Qs.$$.fragment,e),h(Ee.$$.fragment,e),h(ns.$$.fragment,e),h(ks.$$.fragment,e),h(Ce.$$.fragment,e),h(as.$$.fragment,e),h(Ys.$$.fragment,e),h(le.$$.fragment,e),h(rs.$$.fragment,e),h(Ss.$$.fragment,e),h(us.$$.fragment,e),h(st.$$.fragment,e),h(nt.$$.fragment,e),h(at.$$.fragment,e),h(m.$$.fragment,e),h(Gt.$$.fragment,e),h(Wt.$$.fragment,e),h(Vo.$$.fragment,e),h(Ho.$$.fragment,e),h(Ro.$$.fragment,e),h(Uo.$$.fragment,e),h(Qo.$$.fragment,e),h(Go.$$.fragment,e),h(Wo.$$.fragment,e),h(Jo.$$.fragment,e),h(Xo.$$.fragment,e),h(Ko.$$.fragment,e),h(Yo.$$.fragment,e),h(Zo.$$.fragment,e),h(La.$$.fragment,e),h(er.$$.fragment,e),h(sr.$$.fragment,e),h(tr.$$.fragment,e),h(nr.$$.fragment,e),h(ar.$$.fragment,e),h(or.$$.fragment,e),h(rr.$$.fragment,e),h(pt),h(lr.$$.fragment,e),h(ct),h(dr.$$.fragment,e),h(cr.$$.fragment,e),h(ft),h(mr.$$.fragment,e),h(_r.$$.fragment,e),h(hr.$$.fragment,e),h(vr.$$.fragment,e),h(br.$$.fragment,e),h(gr.$$.fragment,e),h(qr.$$.fragment,e),h(xr.$$.fragment,e),h(wr.$$.fragment,e),h(jr.$$.fragment,e),h(kr.$$.fragment,e),h(Er.$$.fragment,e),h(ht),h(yr.$$.fragment,e),h(Cr.$$.fragment,e),h(bt),h(qt),h($t),h(Pr.$$.fragment,e),h(_e),h(Wa.$$.fragment,e),h(he),h(Ar.$$.fragment,e),h(Sr.$$.fragment,e),h(Dr.$$.fragment,e),_d=!0)},o(e){v(f.$$.fragment,e),v(q.$$.fragment,e),v(N),v(G.$$.fragment,e),v(ce.$$.fragment,e),v(je.$$.fragment,e),v(Hs.$$.fragment,e),v(Us.$$.fragment,e),v(qs.$$.fragment,e),v($s.$$.fragment,e),v(es.$$.fragment,e),v(Qs.$$.fragment,e),v(Ee.$$.fragment,e),v(ns.$$.fragment,e),v(ks.$$.fragment,e),v(Ce.$$.fragment,e),v(as.$$.fragment,e),v(Ys.$$.fragment,e),v(le.$$.fragment,e),v(rs.$$.fragment,e),v(Ss.$$.fragment,e),v(us.$$.fragment,e),v(st.$$.fragment,e),v(nt.$$.fragment,e),v(at.$$.fragment,e),v(m.$$.fragment,e),v(Gt.$$.fragment,e),v(Wt.$$.fragment,e),v(Vo.$$.fragment,e),v(Ho.$$.fragment,e),v(Ro.$$.fragment,e),v(Uo.$$.fragment,e),v(Qo.$$.fragment,e),v(Go.$$.fragment,e),v(Wo.$$.fragment,e),v(Jo.$$.fragment,e),v(Xo.$$.fragment,e),v(Ko.$$.fragment,e),v(Yo.$$.fragment,e),v(Zo.$$.fragment,e),v(La.$$.fragment,e),v(er.$$.fragment,e),v(sr.$$.fragment,e),v(tr.$$.fragment,e),v(nr.$$.fragment,e),v(ar.$$.fragment,e),v(or.$$.fragment,e),v(rr.$$.fragment,e),v(pt),v(lr.$$.fragment,e),v(ct),v(dr.$$.fragment,e),v(cr.$$.fragment,e),v(ft),v(mr.$$.fragment,e),v(_r.$$.fragment,e),v(hr.$$.fragment,e),v(vr.$$.fragment,e),v(br.$$.fragment,e),v(gr.$$.fragment,e),v(qr.$$.fragment,e),v(xr.$$.fragment,e),v(wr.$$.fragment,e),v(jr.$$.fragment,e),v(kr.$$.fragment,e),v(Er.$$.fragment,e),v(ht),v(yr.$$.fragment,e),v(Cr.$$.fragment,e),v(bt),v(qt),v($t),v(Pr.$$.fragment,e),v(_e),v(Wa.$$.fragment,e),v(he),v(Ar.$$.fragment,e),v(Sr.$$.fragment,e),v(Dr.$$.fragment,e),_d=!1},d(e){t(p),e&&t(b),y(f,e),e&&t(C),e&&t(S),y(q),e&&t(D),Mr[L].d(e),e&&t(P),e&&t(w),e&&t(B),y(G,e),e&&t(ee),e&&t(Q),e&&t(J),e&&t(se),e&&t(ve),e&&t(re),e&&t(Xe),e&&t(R),e&&t(hs),y(ce,e),e&&t(De),e&&t(me),y(je),e&&t(kt),e&&t(ze),e&&t(Jn),e&&t(Ye),y(Hs),e&&t(Et),e&&t(bs),e&&t(yt),y(Us,e),e&&t(Xn),e&&t(gs),e&&t(Kn),y(qs,e),e&&t(xs),y($s,e),e&&t(ke),e&&t(ge),e&&t(ea),y(es,e),e&&t(sa),y(Qs,e),e&&t(Ct),e&&t(ae),e&&t(Dt),e&&t(ws),e&&t(zt),y(Ee,e),e&&t(oa),y(ns,e),e&&t(ra),e&&t(Ks),e&&t(la),y(ks,e),e&&t(ye),y(Ce,e),e&&t(ia),e&&t(Ne),e&&t(ua),y(as,e),e&&t(pa),y(Ys,e),e&&t(Lt),e&&t(Nt),e&&t(Ot),e&&t(os),y(le),e&&t(da),y(rs,e),e&&t(ca),e&&t(ys),e&&t(ma),e&&t(Cs),e&&t(As),y(Ss,e),e&&t(ls),e&&t(oe),e&&t(ba),y(us,e),e&&t(ga),y(st,e),e&&t(It),e&&t(Oe),e&&t(Ft),y(nt,e),e&&t(qa),e&&t(Be),e&&t(xa),y(at,e),e&&t(Tn),y(m,e),e&&t(I),e&&t(ps),e&&t(Ln),e&&t(Ms),e&&t(Oo),e&&t(ds),e&&t(Io),e&&t(rt),e&&t(Bo),e&&t(ie),e&&t(In),y(Gt,e),e&&t(ue),y(Wt,e),e&&t(Fo),e&&t(fe),e&&t(Tu),e&&t(Ve),e&&t(Lu),y(Vo,e),e&&t(Nu),y(Ho,e),e&&t(Ou),e&&t(Ls),e&&t(Iu),y(Ro,e),e&&t(Bu),y(Uo,e),e&&t(Fu),e&&t(fl),e&&t(Vu),y(Qo,e),e&&t(Hu),y(Go,e),e&&t(Ru),e&&t(_l),e&&t(Uu),e&&t(hl),e&&t(Qu),e&&t(Ta),e&&t(Gu),e&&t(Re),e&&t(Wu),e&&t(Ue),e&&t(Ju),y(Wo,e),e&&t(Xu),y(Jo,e),e&&t(Ku),e&&t(Jt),e&&t(Yu),y(Xo,e),e&&t(Zu),y(Ko,e),e&&t(ep),e&&t(Xt),e&&t(sp),y(Yo,e),e&&t(tp),y(Zo,e),e&&t(np),e&&t(bl),e&&t(ap),y(La,e),e&&t(op),e&&t(gl),e&&t(rp),y(er,e),e&&t(lp),e&&t(ql),e&&t(ip),e&&t(Kt),e&&t(up),y(sr,e),e&&t(pp),y(tr,e),e&&t(dp),e&&t(xl),e&&t(cp),e&&t(Bn),y(nr),e&&t(mp),e&&t($l),e&&t(fp),e&&t(Ns),e&&t(_p),y(ar,e),e&&t(hp),e&&t(wl),e&&t(vp),y(or,e),e&&t(bp),y(rr,e),e&&t(gp),e&&t(jl),e&&t(qp),e&&t(kl),e&&t(xp),zr[ut].d(e),e&&t(El),e&&t(Fn),y(lr),e&&t($p),Tr[dt].d(e),e&&t(yl),e&&t(Ia),e&&t(wp),e&&t(Os),e&&t(jp),e&&t(Is),e&&t(kp),e&&t(Ba),e&&t(Ep),y(dr,e),e&&t(yp),e&&t(Fa),e&&t(Cp),y(cr,e),e&&t(Pp),e&&t(Va),e&&t(Ap),Lr[mt].d(e),e&&t(Cl),e&&t(Qe),e&&t(Sp),y(mr,e),e&&t(Dp),e&&t(Ha),e&&t(Mp),e&&t(Yt),e&&t(zp),e&&t(Pl),e&&t(Tp),y(_r,e),e&&t(Lp),e&&t(Ra),e&&t(Np),y(hr,e),e&&t(Op),e&&t(Al),e&&t(Ip),y(vr,e),e&&t(Bp),e&&t(Sl),e&&t(Fp),y(br,e),e&&t(Vp),y(gr,e),e&&t(Hp),e&&t(Dl),e&&t(Rp),y(qr,e),e&&t(Up),y(xr,e),e&&t(Qp),e&&t(Zt),e&&t(Gp),Un.d(e),e&&t(Ml),y(wr,e),e&&t(Wp),e&&t(zl),e&&t(Jp),y(jr,e),e&&t(Xp),y(kr,e),e&&t(Kp),e&&t(Tl),e&&t(Yp),e&&t(Hn),y(Er),e&&t(Zp),Nr[_t].d(e),e&&t(Ll),e&&t(Qa),e&&t(ed),e&&t(en),e&&t(sd),y(yr,e),e&&t(td),e&&t(Ga),e&&t(nd),y(Cr,e),e&&t(ad),Or[vt].d(e),e&&t(Nl),e&&t(Ge),e&&t(od),Ir[gt].d(e),e&&t(Ol),e&&t(Il),e&&t(rd),Br[xt].d(e),e&&t(Bl),y(Pr,e),e&&t(ld),e&&t(Fl),e&&t(id),_e&&_e.d(e),e&&t(Vl),e&&t(sn),e&&t(ud),y(Wa,e),e&&t(pd),he&&he.d(e),e&&t(Hl),e&&t(Rn),y(Ar),e&&t(dd),e&&t(Bs),e&&t(cd),y(Sr,e),e&&t(md),y(Dr,e),e&&t(fd),e&&t(Rl)}}}const hg={local:"rponse-aux-questions",sections:[{local:"prparation-des-donnes",sections:[{local:"le-jeu-de-donnes-squad",title:"Le jeu de donn\xE9es SQuAD"},{local:"traitement-des-donnes-dentranement",title:"Traitement des donn\xE9es d'entra\xEEnement"},{local:"traitement-des-donnes-de-validation",title:"Traitement des donn\xE9es de validation"}],title:"Pr\xE9paration des donn\xE9es"},{local:"finetuner-le-modle-avec-lapi-trainer",title:"*Finetuner* le mod\xE8le avec l'API `Trainer`"},{local:"finetuner-fin-du-modle-avec-keras",sections:[{local:"posttraitement",title:"Post-traitement"},{local:"finetuning-du-modle",title:"*Finetuning* du mod\xE8le"}],title:"*Finetuner* fin du mod\xE8le avec Keras"},{local:"une-boucle-dentranement-personnalise",sections:[{local:"prparer-tout-pour-lentranement",title:"Pr\xE9parer tout pour l'entra\xEEnement"}],title:"Une boucle d'entra\xEEnement personnalis\xE9e"},{local:"boucle-dentranement",sections:[{local:"utilisation-du-modle-finetun",title:"Utilisation du mod\xE8le *finetun\xE9*"}],title:"Boucle d'entra\xEEnement"}],title:"R\xE9ponse aux questions"};function vg(H,p,b){let f="pt";return Ub(()=>{const C=new URLSearchParams(window.location.search);b(0,f=C.get("fw")||"pt")}),[f]}class kg extends Fb{constructor(p){super();Vb(this,p,vg,_g,Hb,{})}}export{kg as default,hg as metadata};
