import{S as ih,i as uh,s as ph,e as l,w as j,k as p,t as n,c as r,a as o,x as w,d as s,m as c,h as a,b as _,g as u,G as e,y as x,q as b,o as g,B as C,M as ch,N as zc,p as So,v as dh,n as Lo,L as nh}from"../../chunks/vendor-hf-doc-builder.js";import{T as Io}from"../../chunks/Tip-hf-doc-builder.js";import{Y as ah}from"../../chunks/Youtube-hf-doc-builder.js";import{I as ot}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as M}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as oh}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as mh}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function fh(V){let d,E;return d=new oh({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter7/section2_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter7/section2_tf.ipynb"}]}}),{c(){j(d.$$.fragment)},l(h){w(d.$$.fragment,h)},m(h,q){x(d,h,q),E=!0},i(h){E||(b(d.$$.fragment,h),E=!0)},o(h){g(d.$$.fragment,h),E=!1},d(h){C(d,h)}}}function hh(V){let d,E;return d=new oh({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter7/section2_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter7/section2_pt.ipynb"}]}}),{c(){j(d.$$.fragment)},l(h){w(d.$$.fragment,h)},m(h,q){x(d,h,q),E=!0},i(h){E||(b(d.$$.fragment,h),E=!0)},o(h){g(d.$$.fragment,h),E=!1},d(h){C(d,h)}}}function vh(V){let d,E,h,q,z,$,k,O;return{c(){d=l("p"),E=n("\u{1F4A1} Tant que votre jeu de donn\xE9es consiste en des textes divis\xE9s en mots avec leurs \xE9tiquettes correspondantes, vous pourrez adapter les proc\xE9dures de traitement des donn\xE9es d\xE9crites ici \xE0 votre propre jeu de donn\xE9es. Reportez-vous au "),h=l("a"),q=n("Chapitre 5"),z=n(" si vous avez besoin d\u2019un rafra\xEEchissement sur la fa\xE7on de charger vos propres donn\xE9es personnalis\xE9es dans un "),$=l("code"),k=n("Dataset"),O=n("."),this.h()},l(y){d=r(y,"P",{});var P=o(d);E=a(P,"\u{1F4A1} Tant que votre jeu de donn\xE9es consiste en des textes divis\xE9s en mots avec leurs \xE9tiquettes correspondantes, vous pourrez adapter les proc\xE9dures de traitement des donn\xE9es d\xE9crites ici \xE0 votre propre jeu de donn\xE9es. Reportez-vous au "),h=r(P,"A",{href:!0});var H=o(h);q=a(H,"Chapitre 5"),H.forEach(s),z=a(P," si vous avez besoin d\u2019un rafra\xEEchissement sur la fa\xE7on de charger vos propres donn\xE9es personnalis\xE9es dans un "),$=r(P,"CODE",{});var D=o($);k=a(D,"Dataset"),D.forEach(s),O=a(P,"."),P.forEach(s),this.h()},h(){_(h,"href","/course/fr/chapter5")},m(y,P){u(y,d,P),e(d,E),e(d,h),e(h,q),e(d,z),e(d,$),e($,k),e(d,O)},d(y){y&&s(d)}}}function _h(V){let d,E,h,q,z,$,k,O;return{c(){d=l("p"),E=n("\u270F\uFE0F "),h=l("em"),q=n("Votre tour !"),z=n(" Affichez les deux m\xEAmes phrases avec leurs \xE9tiquettes POS ou "),$=l("em"),k=n("chunking"),O=n(".")},l(y){d=r(y,"P",{});var P=o(d);E=a(P,"\u270F\uFE0F "),h=r(P,"EM",{});var H=o(h);q=a(H,"Votre tour !"),H.forEach(s),z=a(P," Affichez les deux m\xEAmes phrases avec leurs \xE9tiquettes POS ou "),$=r(P,"EM",{});var D=o($);k=a(D,"chunking"),D.forEach(s),O=a(P,"."),P.forEach(s)},m(y,P){u(y,d,P),e(d,E),e(d,h),e(h,q),e(d,z),e(d,$),e($,k),e(d,O)},d(y){y&&s(d)}}}function bh(V){let d,E,h,q,z,$,k,O,y,P,H;return{c(){d=l("p"),E=n("\u270F\uFE0F "),h=l("em"),q=n("Votre tour !"),z=n(" Certains chercheurs pr\xE9f\xE8rent n\u2019attribuer qu\u2019un seul label par mot, et attribuer "),$=l("code"),k=n("-100"),O=n(" aux autres sous-"),y=l("em"),P=n("tokens"),H=n(" dans un mot donn\xE9. Ceci afin d\u2019\xE9viter que les longs mots qui se divisent en plusieurs batchs ne contribuent fortement \xE0 la perte. Changez la fonction pr\xE9c\xE9dente pour aligner les \xE9tiquettes avec les ID d\u2019entr\xE9e en suivant cette r\xE8gle.")},l(D){d=r(D,"P",{});var L=o(d);E=a(L,"\u270F\uFE0F "),h=r(L,"EM",{});var R=o(h);q=a(R,"Votre tour !"),R.forEach(s),z=a(L," Certains chercheurs pr\xE9f\xE8rent n\u2019attribuer qu\u2019un seul label par mot, et attribuer "),$=r(L,"CODE",{});var A=o($);k=a(A,"-100"),A.forEach(s),O=a(L," aux autres sous-"),y=r(L,"EM",{});var N=o(y);P=a(N,"tokens"),N.forEach(s),H=a(L," dans un mot donn\xE9. Ceci afin d\u2019\xE9viter que les longs mots qui se divisent en plusieurs batchs ne contribuent fortement \xE0 la perte. Changez la fonction pr\xE9c\xE9dente pour aligner les \xE9tiquettes avec les ID d\u2019entr\xE9e en suivant cette r\xE8gle."),L.forEach(s)},m(D,L){u(D,d,L),e(d,E),e(d,h),e(h,q),e(d,z),e(d,$),e($,k),e(d,O),e(d,y),e(y,P),e(d,H)},d(D){D&&s(d)}}}function $h(V){let d,E,h,q,z,$,k,O,y,P,H;return q=new ot({}),{c(){d=l("h2"),E=l("a"),h=l("span"),j(q.$$.fragment),z=p(),$=l("span"),k=n("*Finetuning* fin du mod\xE8le avec Keras"),O=p(),y=l("p"),P=n("Le code r\xE9el utilisant Keras sera tr\xE8s similaire au pr\xE9c\xE9dent ; les seuls changements sont la fa\xE7on dont les donn\xE9es sont rassembl\xE9es dans un batch et la fonction de calcul de la m\xE9trique."),this.h()},l(D){d=r(D,"H2",{class:!0});var L=o(d);E=r(L,"A",{id:!0,class:!0,href:!0});var R=o(E);h=r(R,"SPAN",{});var A=o(h);w(q.$$.fragment,A),A.forEach(s),R.forEach(s),z=c(L),$=r(L,"SPAN",{});var N=o($);k=a(N,"*Finetuning* fin du mod\xE8le avec Keras"),N.forEach(s),L.forEach(s),O=c(D),y=r(D,"P",{});var Y=o(y);P=a(Y,"Le code r\xE9el utilisant Keras sera tr\xE8s similaire au pr\xE9c\xE9dent ; les seuls changements sont la fa\xE7on dont les donn\xE9es sont rassembl\xE9es dans un batch et la fonction de calcul de la m\xE9trique."),Y.forEach(s),this.h()},h(){_(E,"id","finetuning-fin-du-modle-avec-keras"),_(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(E,"href","#finetuning-fin-du-modle-avec-keras"),_(d,"class","relative group")},m(D,L){u(D,d,L),e(d,E),e(E,h),x(q,h,null),e(d,z),e(d,$),e($,k),u(D,O,L),u(D,y,L),e(y,P),H=!0},i(D){H||(b(q.$$.fragment,D),H=!0)},o(D){g(q.$$.fragment,D),H=!1},d(D){D&&s(d),C(q),D&&s(O),D&&s(y)}}}function gh(V){let d,E,h,q,z,$,k,O,y,P,H,D,L,R,A,N,Y;return q=new ot({}),{c(){d=l("h2"),E=l("a"),h=l("span"),j(q.$$.fragment),z=p(),$=l("span"),k=n("*Finetuning* du mod\xE8le avec l'API "),O=l("code"),y=n("Trainer"),P=n("."),H=p(),D=l("p"),L=n("Le code actuel utilisant le "),R=l("code"),A=n("Trainer"),N=n(" sera le m\xEAme que pr\xE9c\xE9demment ; les seuls changements sont la fa\xE7on dont les donn\xE9es sont rassembl\xE9es dans un batch et la fonction de calcul de la m\xE9trique."),this.h()},l(G){d=r(G,"H2",{class:!0});var X=o(d);E=r(X,"A",{id:!0,class:!0,href:!0});var J=o(E);h=r(J,"SPAN",{});var K=o(h);w(q.$$.fragment,K),K.forEach(s),J.forEach(s),z=c(X),$=r(X,"SPAN",{});var Q=o($);k=a(Q,"*Finetuning* du mod\xE8le avec l'API "),O=r(Q,"CODE",{});var T=o(O);y=a(T,"Trainer"),T.forEach(s),P=a(Q,"."),Q.forEach(s),X.forEach(s),H=c(G),D=r(G,"P",{});var F=o(D);L=a(F,"Le code actuel utilisant le "),R=r(F,"CODE",{});var S=o(R);A=a(S,"Trainer"),S.forEach(s),N=a(F," sera le m\xEAme que pr\xE9c\xE9demment ; les seuls changements sont la fa\xE7on dont les donn\xE9es sont rassembl\xE9es dans un batch et la fonction de calcul de la m\xE9trique."),F.forEach(s),this.h()},h(){_(E,"id","finetuning-du-modle-avec-lapi-trainer"),_(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(E,"href","#finetuning-du-modle-avec-lapi-trainer"),_(d,"class","relative group")},m(G,X){u(G,d,X),e(d,E),e(E,h),x(q,h,null),e(d,z),e(d,$),e($,k),e($,O),e(O,y),e($,P),u(G,H,X),u(G,D,X),e(D,L),e(D,R),e(R,A),e(D,N),Y=!0},i(G){Y||(b(q.$$.fragment,G),Y=!0)},o(G){g(q.$$.fragment,G),Y=!1},d(G){G&&s(d),C(q),G&&s(H),G&&s(D)}}}function Eh(V){let d,E;return d=new M({props:{code:`from transformers import DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(
    tokenizer=tokenizer, return_tensors="tf"
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(
    tokenizer=tokenizer, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>
)`}}),{c(){j(d.$$.fragment)},l(h){w(d.$$.fragment,h)},m(h,q){x(d,h,q),E=!0},i(h){E||(b(d.$$.fragment,h),E=!0)},o(h){g(d.$$.fragment,h),E=!1},d(h){C(d,h)}}}function qh(V){let d,E;return d=new M({props:{code:`from transformers import DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForTokenClassification

data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)`}}),{c(){j(d.$$.fragment)},l(h){w(d.$$.fragment,h)},m(h,q){x(d,h,q),E=!0},i(h){E||(b(d.$$.fragment,h),E=!0)},o(h){g(d.$$.fragment,h),E=!1},d(h){C(d,h)}}}function kh(V){let d,E,h,q,z,$,k,O,y,P,H,D,L,R;return P=new M({props:{code:`tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels", "token_type_ids"],
    collate_fn=data_collator,
    shuffle=True,
    batch_size=16,
)

tf_eval_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "labels", "token_type_ids"],
    collate_fn=data_collator,
    shuffle=False,
    batch_size=16,
)`,highlighted:`tf_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
    collate_fn=data_collator,
    shuffle=<span class="hljs-literal">True</span>,
    batch_size=<span class="hljs-number">16</span>,
)

tf_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
    collate_fn=data_collator,
    shuffle=<span class="hljs-literal">False</span>,
    batch_size=<span class="hljs-number">16</span>,
)`}}),{c(){d=l("p"),E=n("Notre collateur de donn\xE9es est pr\xEAt \xE0 fonctionner ! Maintenant, utilisons-le pour cr\xE9er un "),h=l("code"),q=n("tf.data.Dataset"),z=n(" avec la m\xE9thode "),$=l("code"),k=n("to_tf_dataset()"),O=n("."),y=p(),j(P.$$.fragment),H=p(),D=l("p"),L=n("Prochain arr\xEAt : le mod\xE8le lui-m\xEAme.")},l(A){d=r(A,"P",{});var N=o(d);E=a(N,"Notre collateur de donn\xE9es est pr\xEAt \xE0 fonctionner ! Maintenant, utilisons-le pour cr\xE9er un "),h=r(N,"CODE",{});var Y=o(h);q=a(Y,"tf.data.Dataset"),Y.forEach(s),z=a(N," avec la m\xE9thode "),$=r(N,"CODE",{});var G=o($);k=a(G,"to_tf_dataset()"),G.forEach(s),O=a(N,"."),N.forEach(s),y=c(A),w(P.$$.fragment,A),H=c(A),D=r(A,"P",{});var X=o(D);L=a(X,"Prochain arr\xEAt : le mod\xE8le lui-m\xEAme."),X.forEach(s)},m(A,N){u(A,d,N),e(d,E),e(d,h),e(h,q),e(d,z),e(d,$),e($,k),e(d,O),u(A,y,N),x(P,A,N),u(A,H,N),u(A,D,N),e(D,L),R=!0},i(A){R||(b(P.$$.fragment,A),R=!0)},o(A){g(P.$$.fragment,A),R=!1},d(A){A&&s(d),A&&s(y),C(P,A),A&&s(H),A&&s(D)}}}function jh(V){let d,E,h,q,z;return{c(){d=l("p"),E=n("Comme nous pouvons le voir, le deuxi\xE8me jeu d\u2019\xE9tiquettes a \xE9t\xE9 compl\xE9t\xE9 \xE0 la longueur du premier en utilisant "),h=l("code"),q=n("-100"),z=n("s.")},l($){d=r($,"P",{});var k=o(d);E=a(k,"Comme nous pouvons le voir, le deuxi\xE8me jeu d\u2019\xE9tiquettes a \xE9t\xE9 compl\xE9t\xE9 \xE0 la longueur du premier en utilisant "),h=r(k,"CODE",{});var O=o(h);q=a(O,"-100"),O.forEach(s),z=a(k,"s."),k.forEach(s)},m($,k){u($,d,k),e(d,E),e(d,h),e(h,q),e(d,z)},i:nh,o:nh,d($){$&&s(d)}}}function lh(V){let d,E,h,q,z,$,k,O,y,P,H,D,L,R,A,N,Y,G,X,J,K,Q,T,F,S,W,ae,ve,te,de,he,_e,U,B,Z,we,Ie,xe,ee,le,Ye,ks,Ce,Ee,Rs,re,cn,it,ja,dn,js,wa,mn,ut,xa,fn,hn,Je,pt,Qe,vn,Re,_n,ye,Ae,es,He,Fs,ct,bn,$n,ze,Fn,be,vl,Bn,qe,Nt,gn,ke,ss,En,Bs,dt,qn,ws,ds,Tt,ms,Ca,St,ts,Hn,Oe,Hs,Ge,Fe,kn,ns,ya,jn,Lt,Gs,as,ie,wn,xn,Gn,ls,It,fs,Un,Ue,Vn,xs,Ne,mt,ft,Wn,je,za,Rt,Ve,Oa,ht,Xn,vt,Us,Vs,Pa,_t,rs,Cn,ue,bt,Cs,Ws,Da,hs,ys,Zn,Xs,os,We,yn,$t,Ma,Kn,vs,Zs,gt,_s,Yn,zs,zn,$e,Jn,ge,Et,Ft,Os,Qn,Ks,On,ea,Ps,Bt,qt,Ht,Ds,Ys,Gt;return q=new ot({}),U=new M({props:{code:`id2label = {str(i): label for i, label in enumerate(label_names)}
label2id = {v: k for k, v in id2label.items()}`,highlighted:`id2label = {<span class="hljs-built_in">str</span>(i): label <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(label_names)}
label2id = {v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> id2label.items()}`}}),Ee=new M({props:{code:`from transformers import TFAutoModelForTokenClassification

model = TFAutoModelForTokenClassification.from_pretrained(
    model_checkpoint, id2label=id2label, label2id=label2id,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForTokenClassification

model = TFAutoModelForTokenClassification.from_pretrained(
    model_checkpoint, id2label=id2label, label2id=label2id,
)`}}),Je=new M({props:{code:"model.config.num_labels",highlighted:"model.config.num_labels"}}),Qe=new M({props:{code:"9",highlighted:'<span class="hljs-number">9</span>'}}),Re=new Io({props:{warning:!0,$$slots:{default:[wh]},$$scope:{ctx:V}}}),He=new ot({}),Nt=new M({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`}}),ts=new M({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}}),ls=new M({props:{code:`from transformers import create_optimizer
import tensorflow as tf

# Entra\xEEner en mixed-precision float16
# Commentez cette ligne si vous utilisez un GPU qui ne b\xE9n\xE9ficiera pas de cette fonction
tf.keras.mixed_precision.set_global_policy("mixed_float16")

# Le nombre d'\xE9tapes d'entra\xEEnement est le nombre d'\xE9chantillons dans l'ensemble de donn\xE9es, divis\xE9 par la taille du batch puis multipli\xE9 par le nombre total d'\xE9poques
# par le nombre total d'\xE9poques. Notez que le jeu de donn\xE9es tf_train_dataset est ici un batchtf.data.Dataset,
# et non le jeu de donn\xE9es original Hugging Face Dataset, donc son len() est d\xE9j\xE0 num_samples // batch_size
num_epochs = 3
num_train_steps = len(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
    init_lr=2e-5,
    num_warmup_steps=0,
    num_train_steps=num_train_steps,
    weight_decay_rate=0.01,
)
model.compile(optimizer=optimizer)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-comment"># Entra\xEEner en mixed-precision float16</span>
<span class="hljs-comment"># Commentez cette ligne si vous utilisez un GPU qui ne b\xE9n\xE9ficiera pas de cette fonction</span>
tf.keras.mixed_precision.set_global_policy(<span class="hljs-string">&quot;mixed_float16&quot;</span>)

<span class="hljs-comment"># Le nombre d&#x27;\xE9tapes d&#x27;entra\xEEnement est le nombre d&#x27;\xE9chantillons dans l&#x27;ensemble de donn\xE9es, divis\xE9 par la taille du batch puis multipli\xE9 par le nombre total d&#x27;\xE9poques</span>
<span class="hljs-comment"># par le nombre total d&#x27;\xE9poques. Notez que le jeu de donn\xE9es tf_train_dataset est ici un batchtf.data.Dataset,</span>
<span class="hljs-comment"># et non le jeu de donn\xE9es original Hugging Face Dataset, donc son len() est d\xE9j\xE0 num_samples // batch_size</span>
num_epochs = <span class="hljs-number">3</span>
num_train_steps = <span class="hljs-built_in">len</span>(tf_train_dataset) * num_epochs

optimizer, schedule = create_optimizer(
    init_lr=<span class="hljs-number">2e-5</span>,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_train_steps=num_train_steps,
    weight_decay_rate=<span class="hljs-number">0.01</span>,
)
model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)`}}),rs=new M({props:{code:`from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(output_dir="bert-finetuned-ner", tokenizer=tokenizer)

model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=[callback],
    epochs=num_epochs,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback

callback = PushToHubCallback(output_dir=<span class="hljs-string">&quot;bert-finetuned-ner&quot;</span>, tokenizer=tokenizer)

model.fit(
    tf_train_dataset,
    validation_data=tf_eval_dataset,
    callbacks=[callback],
    epochs=num_epochs,
)`}}),Zs=new Io({props:{$$slots:{default:[xh]},$$scope:{ctx:V}}}),{c(){d=l("h3"),E=l("a"),h=l("span"),j(q.$$.fragment),z=p(),$=l("span"),k=n("D\xE9finir le mod\xE8le"),O=p(),y=l("p"),P=n("Puisque nous travaillons sur un probl\xE8me de classification de "),H=l("em"),D=n("tokens"),L=n(", nous allons utiliser la classe "),R=l("code"),A=n("TFAutoModelForTokenClassification"),N=n(". La principale chose \xE0 retenir lors de la d\xE9finition de ce mod\xE8le est de transmettre des informations sur le nombre de labels que nous avons. La fa\xE7on la plus simple de le faire est de passer ce nombre avec l\u2019argument "),Y=l("code"),G=n("num_labels"),X=n(", mais si nous voulons un joli "),J=l("em"),K=n("widget"),Q=n(" d\u2019inf\xE9rence fonctionnant comme celui que nous avons vu au d\xE9but de cette section, il est pr\xE9f\xE9rable de d\xE9finir les correspondances correctes des \xE9tiquettes \xE0 la place."),T=p(),F=l("p"),S=n("Elles devraient \xEAtre d\xE9finies par deux dictionnaires, "),W=l("code"),ae=n("id2label"),ve=n(" et "),te=l("code"),de=n("label2id"),he=n(", qui contiennent la correspondance de l\u2019ID au label et vice versa :"),_e=p(),j(U.$$.fragment),B=p(),Z=l("p"),we=n("Maintenant, nous pouvons simplement les passer \xE0 la m\xE9thode "),Ie=l("code"),xe=n("TFAutoModelForTokenClassification.from_pretrained()"),ee=n(", et ils seront d\xE9finis dans la configuration du mod\xE8le, puis correctement enregistr\xE9s et t\xE9l\xE9charg\xE9s vers le "),le=l("em"),Ye=n("Hub"),ks=n(" :"),Ce=p(),j(Ee.$$.fragment),Rs=p(),re=l("p"),cn=n("Comme lorsque nous avons d\xE9fini notre "),it=l("code"),ja=n("TFAutoModelForSequenceClassification"),dn=n(" au "),js=l("a"),wa=n("Chapitre 3"),mn=n(", la cr\xE9ation du mod\xE8le \xE9met un avertissement indiquant que certains poids n\u2019ont pas \xE9t\xE9 utilis\xE9s (ceux de la t\xEAte de pr\xE9-entra\xEEnement) et que d\u2019autres poids ont \xE9t\xE9 initialis\xE9s de mani\xE8re al\xE9atoire (ceux de la t\xEAte de classification des nouveaux "),ut=l("em"),xa=n("tokens"),fn=n("), et que ce mod\xE8le doit \xEAtre entra\xEEn\xE9. Nous ferons cela dans une minute, mais v\xE9rifions d\u2019abord que notre mod\xE8le a le bon nombre d\u2019\xE9tiquettes :"),hn=p(),j(Je.$$.fragment),pt=p(),j(Qe.$$.fragment),vn=p(),j(Re.$$.fragment),_n=p(),ye=l("h3"),Ae=l("a"),es=l("span"),j(He.$$.fragment),Fs=p(),ct=l("span"),bn=n("*Finetuning* du mod\xE8le"),$n=p(),ze=l("p"),Fn=n("Nous sommes maintenant pr\xEAts \xE0 entra\xEEner notre mod\xE8le ! Mais nous devons d\u2019abord faire un peu de m\xE9nage : nous devons nous connecter \xE0 Hugging Face et d\xE9finir nos hyperparam\xE8tres d\u2019entra\xEEnement. Si vous travaillez dans un "),be=l("em"),vl=n("notebook"),Bn=n(", il y a une fonction pratique pour vous aider \xE0 le faire :"),qe=p(),j(Nt.$$.fragment),gn=p(),ke=l("p"),ss=n("Cela affichera un "),En=l("em"),Bs=n("widget"),dt=n(" o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),qn=p(),ws=l("p"),ds=n("Si vous ne travaillez pas dans un "),Tt=l("em"),ms=n("notebook"),Ca=n(", tapez simplement la ligne suivante dans votre terminal :"),St=p(),j(ts.$$.fragment),Hn=p(),Oe=l("p"),Hs=n("Apr\xE8s s\u2019\xEAtre connect\xE9, nous pouvons pr\xE9parer tout ce dont nous avons besoin pour compiler notre mod\xE8le. \u{1F917} "),Ge=l("em"),Fe=n("Transformers"),kn=n(" fournit une fonction pratique "),ns=l("code"),ya=n("create_optimizer()"),jn=n(" qui vous donnera un optimiseur "),Lt=l("code"),Gs=n("AdamW"),as=n(" avec des param\xE8tres appropri\xE9s pour la d\xE9croissance du taux des poids et la d\xE9croissance du taux d\u2019apprentissage, les deux am\xE9liorant les performances de votre mod\xE8le par rapport \xE0 l\u2019optimiseur "),ie=l("code"),wn=n("Adam"),xn=n(" int\xE9gr\xE9 :"),Gn=p(),j(ls.$$.fragment),It=p(),fs=l("p"),Un=n("Notez \xE9galement que nous ne fournissons pas d\u2019argument "),Ue=l("code"),Vn=n("loss"),xs=n(" \xE0 "),Ne=l("code"),mt=n("compile()"),ft=n(". C\u2019est parce que les mod\xE8les peuvent en fait calculer la perte en interne. Si vous compilez sans perte et fournissez vos \xE9tiquettes dans le dictionnaire d\u2019entr\xE9e (comme nous le faisons dans nos jeux de donn\xE9es), alors le mod\xE8le s\u2019entra\xEEnera en utilisant cette perte interne, qui sera appropri\xE9e pour la t\xE2che et le type de mod\xE8le que vous avez choisi."),Wn=p(),je=l("p"),za=n("Ensuite, nous d\xE9finissons un "),Rt=l("code"),Ve=n("PushToHubCallback"),Oa=n(" pour t\xE9l\xE9charger notre mod\xE8le vers le "),ht=l("em"),Xn=n("Hub"),vt=n(" pendant l\u2019entra\xEEnement, et nous ajustons le mod\xE8le avec ce "),Us=l("em"),Vs=n("callback"),Pa=n(" :"),_t=p(),j(rs.$$.fragment),Cn=p(),ue=l("p"),bt=n("Vous pouvez sp\xE9cifier le nom complet du r\xE9f\xE9rentiel vers lequel vous voulez pousser avec l\u2019argument "),Cs=l("code"),Ws=n("hub_model_id"),Da=n(" (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),hs=l("a"),ys=l("code"),Zn=n("huggingface-course"),Xs=n(", nous avons ajout\xE9 "),os=l("code"),We=n('hub_model_id="huggingface-course/bert-finetuned-ner"'),yn=n(". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace de noms et nomm\xE9 apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, par exemple "),$t=l("code"),Ma=n('"cool_huggingface_user/bert-finetuned-ner"'),Kn=n("."),vs=p(),j(Zs.$$.fragment),gt=p(),_s=l("p"),Yn=n("Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),zs=l("em"),zn=n("Hub"),$e=n(" en arri\xE8re-plan. De cette fa\xE7on, vous pourrez reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),Jn=p(),ge=l("p"),Et=n("A ce stade, vous pouvez utiliser le "),Ft=l("em"),Os=n("widget"),Qn=n(" d\u2019inf\xE9rence sur le "),Ks=l("em"),On=n("Hub"),ea=n(" pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),Ps=l("em"),Bt=n("finetuner"),qt=n(" un mod\xE8le sur une t\xE2che de classification de "),Ht=l("em"),Ds=n("tokens"),Ys=n(". F\xE9licitations ! Mais quelle est la qualit\xE9 r\xE9elle de notre mod\xE8le ? Nous devons \xE9valuer certaines m\xE9triques pour le d\xE9couvrir."),this.h()},l(f){d=r(f,"H3",{class:!0});var I=o(d);E=r(I,"A",{id:!0,class:!0,href:!0});var Aa=o(E);h=r(Aa,"SPAN",{});var kt=o(h);w(q.$$.fragment,kt),kt.forEach(s),Aa.forEach(s),z=c(I),$=r(I,"SPAN",{});var Ms=o($);k=a(Ms,"D\xE9finir le mod\xE8le"),Ms.forEach(s),I.forEach(s),O=c(f),y=r(f,"P",{});var me=o(y);P=a(me,"Puisque nous travaillons sur un probl\xE8me de classification de "),H=r(me,"EM",{});var Pn=o(H);D=a(Pn,"tokens"),Pn.forEach(s),L=a(me,", nous allons utiliser la classe "),R=r(me,"CODE",{});var fe=o(R);A=a(fe,"TFAutoModelForTokenClassification"),fe.forEach(s),N=a(me,". La principale chose \xE0 retenir lors de la d\xE9finition de ce mod\xE8le est de transmettre des informations sur le nombre de labels que nous avons. La fa\xE7on la plus simple de le faire est de passer ce nombre avec l\u2019argument "),Y=r(me,"CODE",{});var _l=o(Y);G=a(_l,"num_labels"),_l.forEach(s),X=a(me,", mais si nous voulons un joli "),J=r(me,"EM",{});var Ut=o(J);K=a(Ut,"widget"),Ut.forEach(s),Q=a(me," d\u2019inf\xE9rence fonctionnant comme celui que nous avons vu au d\xE9but de cette section, il est pr\xE9f\xE9rable de d\xE9finir les correspondances correctes des \xE9tiquettes \xE0 la place."),me.forEach(s),T=c(f),F=r(f,"P",{});var Vt=o(F);S=a(Vt,"Elles devraient \xEAtre d\xE9finies par deux dictionnaires, "),W=r(Vt,"CODE",{});var Na=o(W);ae=a(Na,"id2label"),Na.forEach(s),ve=a(Vt," et "),te=r(Vt,"CODE",{});var As=o(te);de=a(As,"label2id"),As.forEach(s),he=a(Vt,", qui contiennent la correspondance de l\u2019ID au label et vice versa :"),Vt.forEach(s),_e=c(f),w(U.$$.fragment,f),B=c(f),Z=r(f,"P",{});var Wt=o(Z);we=a(Wt,"Maintenant, nous pouvons simplement les passer \xE0 la m\xE9thode "),Ie=r(Wt,"CODE",{});var Dn=o(Ie);xe=a(Dn,"TFAutoModelForTokenClassification.from_pretrained()"),Dn.forEach(s),ee=a(Wt,", et ils seront d\xE9finis dans la configuration du mod\xE8le, puis correctement enregistr\xE9s et t\xE9l\xE9charg\xE9s vers le "),le=r(Wt,"EM",{});var sa=o(le);Ye=a(sa,"Hub"),sa.forEach(s),ks=a(Wt," :"),Wt.forEach(s),Ce=c(f),w(Ee.$$.fragment,f),Rs=c(f),re=r(f,"P",{});var Js=o(re);cn=a(Js,"Comme lorsque nous avons d\xE9fini notre "),it=r(Js,"CODE",{});var Ta=o(it);ja=a(Ta,"TFAutoModelForSequenceClassification"),Ta.forEach(s),dn=a(Js," au "),js=r(Js,"A",{href:!0});var bs=o(js);wa=a(bs,"Chapitre 3"),bs.forEach(s),mn=a(Js,", la cr\xE9ation du mod\xE8le \xE9met un avertissement indiquant que certains poids n\u2019ont pas \xE9t\xE9 utilis\xE9s (ceux de la t\xEAte de pr\xE9-entra\xEEnement) et que d\u2019autres poids ont \xE9t\xE9 initialis\xE9s de mani\xE8re al\xE9atoire (ceux de la t\xEAte de classification des nouveaux "),ut=r(Js,"EM",{});var jt=o(ut);xa=a(jt,"tokens"),jt.forEach(s),fn=a(Js,"), et que ce mod\xE8le doit \xEAtre entra\xEEn\xE9. Nous ferons cela dans une minute, mais v\xE9rifions d\u2019abord que notre mod\xE8le a le bon nombre d\u2019\xE9tiquettes :"),Js.forEach(s),hn=c(f),w(Je.$$.fragment,f),pt=c(f),w(Qe.$$.fragment,f),vn=c(f),w(Re.$$.fragment,f),_n=c(f),ye=r(f,"H3",{class:!0});var Xt=o(ye);Ae=r(Xt,"A",{id:!0,class:!0,href:!0});var Qs=o(Ae);es=r(Qs,"SPAN",{});var bl=o(es);w(He.$$.fragment,bl),bl.forEach(s),Qs.forEach(s),Fs=c(Xt),ct=r(Xt,"SPAN",{});var ta=o(ct);bn=a(ta,"*Finetuning* du mod\xE8le"),ta.forEach(s),Xt.forEach(s),$n=c(f),ze=r(f,"P",{});var Mn=o(ze);Fn=a(Mn,"Nous sommes maintenant pr\xEAts \xE0 entra\xEEner notre mod\xE8le ! Mais nous devons d\u2019abord faire un peu de m\xE9nage : nous devons nous connecter \xE0 Hugging Face et d\xE9finir nos hyperparam\xE8tres d\u2019entra\xEEnement. Si vous travaillez dans un "),be=r(Mn,"EM",{});var wt=o(be);vl=a(wt,"notebook"),wt.forEach(s),Bn=a(Mn,", il y a une fonction pratique pour vous aider \xE0 le faire :"),Mn.forEach(s),qe=c(f),w(Nt.$$.fragment,f),gn=c(f),ke=r(f,"P",{});var Te=o(ke);ss=a(Te,"Cela affichera un "),En=r(Te,"EM",{});var Zt=o(En);Bs=a(Zt,"widget"),Zt.forEach(s),dt=a(Te," o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),Te.forEach(s),qn=c(f),ws=r(f,"P",{});var xt=o(ws);ds=a(xt,"Si vous ne travaillez pas dans un "),Tt=r(xt,"EM",{});var Ns=o(Tt);ms=a(Ns,"notebook"),Ns.forEach(s),Ca=a(xt,", tapez simplement la ligne suivante dans votre terminal :"),xt.forEach(s),St=c(f),w(ts.$$.fragment,f),Hn=c(f),Oe=r(f,"P",{});var $s=o(Oe);Hs=a($s,"Apr\xE8s s\u2019\xEAtre connect\xE9, nous pouvons pr\xE9parer tout ce dont nous avons besoin pour compiler notre mod\xE8le. \u{1F917} "),Ge=r($s,"EM",{});var Kt=o(Ge);Fe=a(Kt,"Transformers"),Kt.forEach(s),kn=a($s," fournit une fonction pratique "),ns=r($s,"CODE",{});var $l=o(ns);ya=a($l,"create_optimizer()"),$l.forEach(s),jn=a($s," qui vous donnera un optimiseur "),Lt=r($s,"CODE",{});var gl=o(Lt);Gs=a(gl,"AdamW"),gl.forEach(s),as=a($s," avec des param\xE8tres appropri\xE9s pour la d\xE9croissance du taux des poids et la d\xE9croissance du taux d\u2019apprentissage, les deux am\xE9liorant les performances de votre mod\xE8le par rapport \xE0 l\u2019optimiseur "),ie=r($s,"CODE",{});var Ct=o(ie);wn=a(Ct,"Adam"),Ct.forEach(s),xn=a($s," int\xE9gr\xE9 :"),$s.forEach(s),Gn=c(f),w(ls.$$.fragment,f),It=c(f),fs=r(f,"P",{});var Yt=o(fs);Un=a(Yt,"Notez \xE9galement que nous ne fournissons pas d\u2019argument "),Ue=r(Yt,"CODE",{});var El=o(Ue);Vn=a(El,"loss"),El.forEach(s),xs=a(Yt," \xE0 "),Ne=r(Yt,"CODE",{});var na=o(Ne);mt=a(na,"compile()"),na.forEach(s),ft=a(Yt,". C\u2019est parce que les mod\xE8les peuvent en fait calculer la perte en interne. Si vous compilez sans perte et fournissez vos \xE9tiquettes dans le dictionnaire d\u2019entr\xE9e (comme nous le faisons dans nos jeux de donn\xE9es), alors le mod\xE8le s\u2019entra\xEEnera en utilisant cette perte interne, qui sera appropri\xE9e pour la t\xE2che et le type de mod\xE8le que vous avez choisi."),Yt.forEach(s),Wn=c(f),je=r(f,"P",{});var ne=o(je);za=a(ne,"Ensuite, nous d\xE9finissons un "),Rt=r(ne,"CODE",{});var Jt=o(Rt);Ve=a(Jt,"PushToHubCallback"),Jt.forEach(s),Oa=a(ne," pour t\xE9l\xE9charger notre mod\xE8le vers le "),ht=r(ne,"EM",{});var yt=o(ht);Xn=a(yt,"Hub"),yt.forEach(s),vt=a(ne," pendant l\u2019entra\xEEnement, et nous ajustons le mod\xE8le avec ce "),Us=r(ne,"EM",{});var ql=o(Us);Vs=a(ql,"callback"),ql.forEach(s),Pa=a(ne," :"),ne.forEach(s),_t=c(f),w(rs.$$.fragment,f),Cn=c(f),ue=r(f,"P",{});var is=o(ue);bt=a(is,"Vous pouvez sp\xE9cifier le nom complet du r\xE9f\xE9rentiel vers lequel vous voulez pousser avec l\u2019argument "),Cs=r(is,"CODE",{});var Qt=o(Cs);Ws=a(Qt,"hub_model_id"),Qt.forEach(s),Da=a(is," (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),hs=r(is,"A",{href:!0,rel:!0});var gs=o(hs);ys=r(gs,"CODE",{});var us=o(ys);Zn=a(us,"huggingface-course"),us.forEach(s),gs.forEach(s),Xs=a(is,", nous avons ajout\xE9 "),os=r(is,"CODE",{});var kl=o(os);We=a(kl,'hub_model_id="huggingface-course/bert-finetuned-ner"'),kl.forEach(s),yn=a(is,". Par d\xE9faut, le d\xE9p\xF4t utilis\xE9 sera dans votre espace de noms et nomm\xE9 apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, par exemple "),$t=r(is,"CODE",{});var aa=o($t);Ma=a(aa,'"cool_huggingface_user/bert-finetuned-ner"'),aa.forEach(s),Kn=a(is,"."),is.forEach(s),vs=c(f),w(Zs.$$.fragment,f),gt=c(f),_s=r(f,"P",{});var en=o(_s);Yn=a(en,"Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),zs=r(en,"EM",{});var jl=o(zs);zn=a(jl,"Hub"),jl.forEach(s),$e=a(en," en arri\xE8re-plan. De cette fa\xE7on, vous pourrez reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),en.forEach(s),Jn=c(f),ge=r(f,"P",{});var Xe=o(ge);Et=a(Xe,"A ce stade, vous pouvez utiliser le "),Ft=r(Xe,"EM",{});var la=o(Ft);Os=a(la,"widget"),la.forEach(s),Qn=a(Xe," d\u2019inf\xE9rence sur le "),Ks=r(Xe,"EM",{});var wl=o(Ks);On=a(wl,"Hub"),wl.forEach(s),ea=a(Xe," pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 "),Ps=r(Xe,"EM",{});var Sa=o(Ps);Bt=a(Sa,"finetuner"),Sa.forEach(s),qt=a(Xe," un mod\xE8le sur une t\xE2che de classification de "),Ht=r(Xe,"EM",{});var sn=o(Ht);Ds=a(sn,"tokens"),sn.forEach(s),Ys=a(Xe,". F\xE9licitations ! Mais quelle est la qualit\xE9 r\xE9elle de notre mod\xE8le ? Nous devons \xE9valuer certaines m\xE9triques pour le d\xE9couvrir."),Xe.forEach(s),this.h()},h(){_(E,"id","dfinir-le-modle"),_(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(E,"href","#dfinir-le-modle"),_(d,"class","relative group"),_(js,"href","/course/fr/chapter3"),_(Ae,"id","finetuning-du-modle"),_(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Ae,"href","#finetuning-du-modle"),_(ye,"class","relative group"),_(hs,"href","https://huggingface.co/huggingface-course"),_(hs,"rel","nofollow")},m(f,I){u(f,d,I),e(d,E),e(E,h),x(q,h,null),e(d,z),e(d,$),e($,k),u(f,O,I),u(f,y,I),e(y,P),e(y,H),e(H,D),e(y,L),e(y,R),e(R,A),e(y,N),e(y,Y),e(Y,G),e(y,X),e(y,J),e(J,K),e(y,Q),u(f,T,I),u(f,F,I),e(F,S),e(F,W),e(W,ae),e(F,ve),e(F,te),e(te,de),e(F,he),u(f,_e,I),x(U,f,I),u(f,B,I),u(f,Z,I),e(Z,we),e(Z,Ie),e(Ie,xe),e(Z,ee),e(Z,le),e(le,Ye),e(Z,ks),u(f,Ce,I),x(Ee,f,I),u(f,Rs,I),u(f,re,I),e(re,cn),e(re,it),e(it,ja),e(re,dn),e(re,js),e(js,wa),e(re,mn),e(re,ut),e(ut,xa),e(re,fn),u(f,hn,I),x(Je,f,I),u(f,pt,I),x(Qe,f,I),u(f,vn,I),x(Re,f,I),u(f,_n,I),u(f,ye,I),e(ye,Ae),e(Ae,es),x(He,es,null),e(ye,Fs),e(ye,ct),e(ct,bn),u(f,$n,I),u(f,ze,I),e(ze,Fn),e(ze,be),e(be,vl),e(ze,Bn),u(f,qe,I),x(Nt,f,I),u(f,gn,I),u(f,ke,I),e(ke,ss),e(ke,En),e(En,Bs),e(ke,dt),u(f,qn,I),u(f,ws,I),e(ws,ds),e(ws,Tt),e(Tt,ms),e(ws,Ca),u(f,St,I),x(ts,f,I),u(f,Hn,I),u(f,Oe,I),e(Oe,Hs),e(Oe,Ge),e(Ge,Fe),e(Oe,kn),e(Oe,ns),e(ns,ya),e(Oe,jn),e(Oe,Lt),e(Lt,Gs),e(Oe,as),e(Oe,ie),e(ie,wn),e(Oe,xn),u(f,Gn,I),x(ls,f,I),u(f,It,I),u(f,fs,I),e(fs,Un),e(fs,Ue),e(Ue,Vn),e(fs,xs),e(fs,Ne),e(Ne,mt),e(fs,ft),u(f,Wn,I),u(f,je,I),e(je,za),e(je,Rt),e(Rt,Ve),e(je,Oa),e(je,ht),e(ht,Xn),e(je,vt),e(je,Us),e(Us,Vs),e(je,Pa),u(f,_t,I),x(rs,f,I),u(f,Cn,I),u(f,ue,I),e(ue,bt),e(ue,Cs),e(Cs,Ws),e(ue,Da),e(ue,hs),e(hs,ys),e(ys,Zn),e(ue,Xs),e(ue,os),e(os,We),e(ue,yn),e(ue,$t),e($t,Ma),e(ue,Kn),u(f,vs,I),x(Zs,f,I),u(f,gt,I),u(f,_s,I),e(_s,Yn),e(_s,zs),e(zs,zn),e(_s,$e),u(f,Jn,I),u(f,ge,I),e(ge,Et),e(ge,Ft),e(Ft,Os),e(ge,Qn),e(ge,Ks),e(Ks,On),e(ge,ea),e(ge,Ps),e(Ps,Bt),e(ge,qt),e(ge,Ht),e(Ht,Ds),e(ge,Ys),Gt=!0},i(f){Gt||(b(q.$$.fragment,f),b(U.$$.fragment,f),b(Ee.$$.fragment,f),b(Je.$$.fragment,f),b(Qe.$$.fragment,f),b(Re.$$.fragment,f),b(He.$$.fragment,f),b(Nt.$$.fragment,f),b(ts.$$.fragment,f),b(ls.$$.fragment,f),b(rs.$$.fragment,f),b(Zs.$$.fragment,f),Gt=!0)},o(f){g(q.$$.fragment,f),g(U.$$.fragment,f),g(Ee.$$.fragment,f),g(Je.$$.fragment,f),g(Qe.$$.fragment,f),g(Re.$$.fragment,f),g(He.$$.fragment,f),g(Nt.$$.fragment,f),g(ts.$$.fragment,f),g(ls.$$.fragment,f),g(rs.$$.fragment,f),g(Zs.$$.fragment,f),Gt=!1},d(f){f&&s(d),C(q),f&&s(O),f&&s(y),f&&s(T),f&&s(F),f&&s(_e),C(U,f),f&&s(B),f&&s(Z),f&&s(Ce),C(Ee,f),f&&s(Rs),f&&s(re),f&&s(hn),C(Je,f),f&&s(pt),C(Qe,f),f&&s(vn),C(Re,f),f&&s(_n),f&&s(ye),C(He),f&&s($n),f&&s(ze),f&&s(qe),C(Nt,f),f&&s(gn),f&&s(ke),f&&s(qn),f&&s(ws),f&&s(St),C(ts,f),f&&s(Hn),f&&s(Oe),f&&s(Gn),C(ls,f),f&&s(It),f&&s(fs),f&&s(Wn),f&&s(je),f&&s(_t),C(rs,f),f&&s(Cn),f&&s(ue),f&&s(vs),C(Zs,f),f&&s(gt),f&&s(_s),f&&s(Jn),f&&s(ge)}}}function wh(V){let d,E,h,q,z;return{c(){d=l("p"),E=n("\u26A0\uFE0F Si vous avez un mod\xE8le avec le mauvais nombre de labels, vous obtiendrez une erreur obscure en appelant "),h=l("code"),q=n("model.fit()"),z=n(" plus tard. Cela peut \xEAtre ennuyeux \xE0 d\xE9boguer, donc assurez-vous de faire cette v\xE9rification pour confirmer que vous avez le nombre de labels attendu.")},l($){d=r($,"P",{});var k=o(d);E=a(k,"\u26A0\uFE0F Si vous avez un mod\xE8le avec le mauvais nombre de labels, vous obtiendrez une erreur obscure en appelant "),h=r(k,"CODE",{});var O=o(h);q=a(O,"model.fit()"),O.forEach(s),z=a(k," plus tard. Cela peut \xEAtre ennuyeux \xE0 d\xE9boguer, donc assurez-vous de faire cette v\xE9rification pour confirmer que vous avez le nombre de labels attendu."),k.forEach(s)},m($,k){u($,d,k),e(d,E),e(d,h),e(h,q),e(d,z)},d($){$&&s(d)}}}function xh(V){let d,E,h,q,z;return{c(){d=l("p"),E=n("\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de l\u2019appel de "),h=l("code"),q=n("model.fit()"),z=n(" et devrez d\xE9finir un nouveau nom.")},l($){d=r($,"P",{});var k=o(d);E=a(k,"\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de l\u2019appel de "),h=r(k,"CODE",{});var O=o(h);q=a(O,"model.fit()"),O.forEach(s),z=a(k," et devrez d\xE9finir un nouveau nom."),k.forEach(s)},m($,k){u($,d,k),e(d,E),e(d,h),e(h,q),e(d,z)},d($){$&&s(d)}}}function Ch(V){let d,E,h,q,z,$,k,O,y,P,H,D,L,R,A,N,Y,G,X,J,K,Q,T,F;return R=new M({props:{code:"!pip install seqeval",highlighted:"!pip install seqeval"}}),{c(){d=l("p"),E=n("Le cadre traditionnel utilis\xE9 pour \xE9valuer la pr\xE9diction de la classification des "),h=l("em"),q=n("tokens"),z=n(" est "),$=l("a"),k=l("em"),O=n("seqeval"),y=n(". Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que "),P=l("em"),H=n("seqeval"),D=n(" :"),L=p(),j(R.$$.fragment),A=p(),N=l("p"),Y=n("Nous pouvons ensuite le charger via la fonction "),G=l("code"),X=n("load_metric()"),J=n(" comme nous l\u2019avons fait dans le "),K=l("a"),Q=n("Chapitre 3"),T=n(" :"),this.h()},l(S){d=r(S,"P",{});var W=o(d);E=a(W,"Le cadre traditionnel utilis\xE9 pour \xE9valuer la pr\xE9diction de la classification des "),h=r(W,"EM",{});var ae=o(h);q=a(ae,"tokens"),ae.forEach(s),z=a(W," est "),$=r(W,"A",{href:!0,rel:!0});var ve=o($);k=r(ve,"EM",{});var te=o(k);O=a(te,"seqeval"),te.forEach(s),ve.forEach(s),y=a(W,". Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que "),P=r(W,"EM",{});var de=o(P);H=a(de,"seqeval"),de.forEach(s),D=a(W," :"),W.forEach(s),L=c(S),w(R.$$.fragment,S),A=c(S),N=r(S,"P",{});var he=o(N);Y=a(he,"Nous pouvons ensuite le charger via la fonction "),G=r(he,"CODE",{});var _e=o(G);X=a(_e,"load_metric()"),_e.forEach(s),J=a(he," comme nous l\u2019avons fait dans le "),K=r(he,"A",{href:!0});var U=o(K);Q=a(U,"Chapitre 3"),U.forEach(s),T=a(he," :"),he.forEach(s),this.h()},h(){_($,"href","https://github.com/chakki-works/seqeval"),_($,"rel","nofollow"),_(K,"href","/course/fr/chapter3")},m(S,W){u(S,d,W),e(d,E),e(d,h),e(h,q),e(d,z),e(d,$),e($,k),e(k,O),e(d,y),e(d,P),e(P,H),e(d,D),u(S,L,W),x(R,S,W),u(S,A,W),u(S,N,W),e(N,Y),e(N,G),e(G,X),e(N,J),e(N,K),e(K,Q),e(N,T),F=!0},i(S){F||(b(R.$$.fragment,S),F=!0)},o(S){g(R.$$.fragment,S),F=!1},d(S){S&&s(d),S&&s(L),C(R,S),S&&s(A),S&&s(N)}}}function yh(V){let d,E,h,q,z,$,k,O,y,P,H,D,L,R,A,N,Y,G,X,J,K,Q,T,F,S,W,ae,ve,te,de,he,_e,U;return T=new M({props:{code:"!pip install seqeval",highlighted:"!pip install seqeval"}}),{c(){d=l("p"),E=n("Pour que le "),h=l("code"),q=n("Trainer"),z=n(" calcule une m\xE9trique \xE0 chaque \xE9poque, nous devrons d\xE9finir une fonction "),$=l("code"),k=n("compute_metrics()"),O=n(" qui prend les tableaux de pr\xE9dictions et de labels, et retourne un dictionnaire avec les noms et les valeurs des m\xE9triques."),y=p(),P=l("p"),H=n("Le cadre traditionnel utilis\xE9 pour \xE9valuer la pr\xE9diction de la classification des "),D=l("em"),L=n("tokens"),R=n(" est "),A=l("a"),N=l("em"),Y=n("seqeval"),G=n(". Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que "),X=l("em"),J=n("seqeval"),K=n(" :"),Q=p(),j(T.$$.fragment),F=p(),S=l("p"),W=n("Nous pouvons ensuite le charger via la fonction "),ae=l("code"),ve=n("load_metric()"),te=n(" comme nous l\u2019avons fait dans le "),de=l("a"),he=n("Chapitre 3"),_e=n(" :"),this.h()},l(B){d=r(B,"P",{});var Z=o(d);E=a(Z,"Pour que le "),h=r(Z,"CODE",{});var we=o(h);q=a(we,"Trainer"),we.forEach(s),z=a(Z," calcule une m\xE9trique \xE0 chaque \xE9poque, nous devrons d\xE9finir une fonction "),$=r(Z,"CODE",{});var Ie=o($);k=a(Ie,"compute_metrics()"),Ie.forEach(s),O=a(Z," qui prend les tableaux de pr\xE9dictions et de labels, et retourne un dictionnaire avec les noms et les valeurs des m\xE9triques."),Z.forEach(s),y=c(B),P=r(B,"P",{});var xe=o(P);H=a(xe,"Le cadre traditionnel utilis\xE9 pour \xE9valuer la pr\xE9diction de la classification des "),D=r(xe,"EM",{});var ee=o(D);L=a(ee,"tokens"),ee.forEach(s),R=a(xe," est "),A=r(xe,"A",{href:!0,rel:!0});var le=o(A);N=r(le,"EM",{});var Ye=o(N);Y=a(Ye,"seqeval"),Ye.forEach(s),le.forEach(s),G=a(xe,". Pour utiliser cette m\xE9trique, nous devons d\u2019abord installer la biblioth\xE8que "),X=r(xe,"EM",{});var ks=o(X);J=a(ks,"seqeval"),ks.forEach(s),K=a(xe," :"),xe.forEach(s),Q=c(B),w(T.$$.fragment,B),F=c(B),S=r(B,"P",{});var Ce=o(S);W=a(Ce,"Nous pouvons ensuite le charger via la fonction "),ae=r(Ce,"CODE",{});var Ee=o(ae);ve=a(Ee,"load_metric()"),Ee.forEach(s),te=a(Ce," comme nous l\u2019avons fait dans le "),de=r(Ce,"A",{href:!0});var Rs=o(de);he=a(Rs,"Chapitre 3"),Rs.forEach(s),_e=a(Ce," :"),Ce.forEach(s),this.h()},h(){_(A,"href","https://github.com/chakki-works/seqeval"),_(A,"rel","nofollow"),_(de,"href","/course/fr/chapter3")},m(B,Z){u(B,d,Z),e(d,E),e(d,h),e(h,q),e(d,z),e(d,$),e($,k),e(d,O),u(B,y,Z),u(B,P,Z),e(P,H),e(P,D),e(D,L),e(P,R),e(P,A),e(A,N),e(N,Y),e(P,G),e(P,X),e(X,J),e(P,K),u(B,Q,Z),x(T,B,Z),u(B,F,Z),u(B,S,Z),e(S,W),e(S,ae),e(ae,ve),e(S,te),e(S,de),e(de,he),e(S,_e),U=!0},i(B){U||(b(T.$$.fragment,B),U=!0)},o(B){g(T.$$.fragment,B),U=!1},d(B){B&&s(d),B&&s(y),B&&s(P),B&&s(Q),C(T,B),B&&s(F),B&&s(S)}}}function zh(V){let d,E,h,q,z,$,k,O,y,P,H,D,L,R,A,N,Y,G,X,J,K,Q;return N=new M({props:{code:`import numpy as np

all_predictions = []
all_labels = []
for batch in tf_eval_dataset:
    logits = model.predict(batch)["logits"]
    labels = batch["labels"]
    predictions = np.argmax(logits, axis=-1)
    for prediction, label in zip(predictions, labels):
        for predicted_idx, label_idx in zip(prediction, label):
            if label_idx == -100:
                continue
            all_predictions.append(label_names[predicted_idx])
            all_labels.append(label_names[label_idx])
metric.compute(predictions=[all_predictions], references=[all_labels])`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

all_predictions = []
all_labels = []
<span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> tf_eval_dataset:
    logits = model.predict(batch)[<span class="hljs-string">&quot;logits&quot;</span>]
    labels = batch[<span class="hljs-string">&quot;labels&quot;</span>]
    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)
    <span class="hljs-keyword">for</span> prediction, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions, labels):
        <span class="hljs-keyword">for</span> predicted_idx, label_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction, label):
            <span class="hljs-keyword">if</span> label_idx == -<span class="hljs-number">100</span>:
                <span class="hljs-keyword">continue</span>
            all_predictions.append(label_names[predicted_idx])
            all_labels.append(label_names[label_idx])
metric.compute(predictions=[all_predictions], references=[all_labels])`}}),G=new M({props:{code:`{'LOC': {'precision': 0.91, 'recall': 0.92, 'f1': 0.91, 'number': 1668},
 'MISC': {'precision': 0.70, 'recall': 0.79, 'f1': 0.74, 'number': 702},
 'ORG': {'precision': 0.85, 'recall': 0.90, 'f1': 0.88, 'number': 1661},
 'PER': {'precision': 0.95, 'recall': 0.95, 'f1': 0.95, 'number': 1617},
 'overall_precision': 0.87,
 'overall_recall': 0.91,
 'overall_f1': 0.89,
 'overall_accuracy': 0.97}`,highlighted:`{<span class="hljs-string">&#x27;LOC&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">0.91</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.92</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.91</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">1668</span>},
 <span class="hljs-string">&#x27;MISC&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">0.70</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.79</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.74</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">702</span>},
 <span class="hljs-string">&#x27;ORG&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">0.85</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.90</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.88</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">1661</span>},
 <span class="hljs-string">&#x27;PER&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">0.95</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.95</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.95</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">1617</span>},
 <span class="hljs-string">&#x27;overall_precision&#x27;</span>: <span class="hljs-number">0.87</span>,
 <span class="hljs-string">&#x27;overall_recall&#x27;</span>: <span class="hljs-number">0.91</span>,
 <span class="hljs-string">&#x27;overall_f1&#x27;</span>: <span class="hljs-number">0.89</span>,
 <span class="hljs-string">&#x27;overall_accuracy&#x27;</span>: <span class="hljs-number">0.97</span>}`}}),{c(){d=l("p"),E=n("Cela renvoie un batch d\u2019informations ! Nous obtenons la pr\xE9cision, le rappel et le score F1 pour chaque entit\xE9 s\xE9par\xE9e, ainsi que pour l\u2019ensemble. Voyons maintenant ce qui se passe si nous essayons d\u2019utiliser les pr\xE9dictions de notre mod\xE8le pour calculer des scores r\xE9els."),h=p(),q=l("p"),z=n("TensorFlow n\u2019aime pas concat\xE9ner nos pr\xE9dictions ensemble, car elles ont des longueurs de s\xE9quence variables. Cela signifie que nous ne pouvons pas simplement utiliser "),$=l("code"),k=n("model.predict()"),O=n(". Mais cela ne va pas nous arr\xEAter. Nous obtiendrons des pr\xE9dictions un batch \xE0 la fois et les concat\xE9nerons en une grande liste longue au fur et \xE0 mesure, en laissant tomber les "),y=l("em"),P=n("tokens"),H=p(),D=l("code"),L=n("-100"),R=n(" qui indiquent le masquage/le remplissage, puis nous calculerons les m\xE9triques sur la liste \xE0 la fin :"),A=p(),j(N.$$.fragment),Y=p(),j(G.$$.fragment),X=p(),J=l("p"),K=n("Comment s\u2019est comport\xE9 votre mod\xE8le, compar\xE9 au n\xF4tre ? Si vous avez obtenu des chiffres similaires, votre entra\xEEnement a \xE9t\xE9 un succ\xE8s !")},l(T){d=r(T,"P",{});var F=o(d);E=a(F,"Cela renvoie un batch d\u2019informations ! Nous obtenons la pr\xE9cision, le rappel et le score F1 pour chaque entit\xE9 s\xE9par\xE9e, ainsi que pour l\u2019ensemble. Voyons maintenant ce qui se passe si nous essayons d\u2019utiliser les pr\xE9dictions de notre mod\xE8le pour calculer des scores r\xE9els."),F.forEach(s),h=c(T),q=r(T,"P",{});var S=o(q);z=a(S,"TensorFlow n\u2019aime pas concat\xE9ner nos pr\xE9dictions ensemble, car elles ont des longueurs de s\xE9quence variables. Cela signifie que nous ne pouvons pas simplement utiliser "),$=r(S,"CODE",{});var W=o($);k=a(W,"model.predict()"),W.forEach(s),O=a(S,". Mais cela ne va pas nous arr\xEAter. Nous obtiendrons des pr\xE9dictions un batch \xE0 la fois et les concat\xE9nerons en une grande liste longue au fur et \xE0 mesure, en laissant tomber les "),y=r(S,"EM",{});var ae=o(y);P=a(ae,"tokens"),ae.forEach(s),H=c(S),D=r(S,"CODE",{});var ve=o(D);L=a(ve,"-100"),ve.forEach(s),R=a(S," qui indiquent le masquage/le remplissage, puis nous calculerons les m\xE9triques sur la liste \xE0 la fin :"),S.forEach(s),A=c(T),w(N.$$.fragment,T),Y=c(T),w(G.$$.fragment,T),X=c(T),J=r(T,"P",{});var te=o(J);K=a(te,"Comment s\u2019est comport\xE9 votre mod\xE8le, compar\xE9 au n\xF4tre ? Si vous avez obtenu des chiffres similaires, votre entra\xEEnement a \xE9t\xE9 un succ\xE8s !"),te.forEach(s)},m(T,F){u(T,d,F),e(d,E),u(T,h,F),u(T,q,F),e(q,z),e(q,$),e($,k),e(q,O),e(q,y),e(y,P),e(q,H),e(q,D),e(D,L),e(q,R),u(T,A,F),x(N,T,F),u(T,Y,F),x(G,T,F),u(T,X,F),u(T,J,F),e(J,K),Q=!0},i(T){Q||(b(N.$$.fragment,T),b(G.$$.fragment,T),Q=!0)},o(T){g(N.$$.fragment,T),g(G.$$.fragment,T),Q=!1},d(T){T&&s(d),T&&s(h),T&&s(q),T&&s(A),C(N,T),T&&s(Y),C(G,T),T&&s(X),T&&s(J)}}}function Oh(V){let d,E,h,q,z,$,k,O,y,P,H,D,L,R,A,N,Y,G,X,J,K,Q,T,F,S,W,ae,ve,te,de,he,_e;return X=new M({props:{code:`import numpy as np


def compute_metrics(eval_preds):
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)

    # Suppression de l'index ignor\xE9 (tokens sp\xE9ciaux) et conversion en \xE9tiquettes
    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]
    true_predictions = [
        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)
    return {
        "precision": all_metrics["overall_precision"],
        "recall": all_metrics["overall_recall"],
        "f1": all_metrics["overall_f1"],
        "accuracy": all_metrics["overall_accuracy"],
    }`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_preds</span>):
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)

    <span class="hljs-comment"># Suppression de l&#x27;index ignor\xE9 (tokens sp\xE9ciaux) et conversion en \xE9tiquettes</span>
    true_labels = [[label_names[l] <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> label <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels]
    true_predictions = [
        [label_names[p] <span class="hljs-keyword">for</span> (p, l) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction, label) <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>]
        <span class="hljs-keyword">for</span> prediction, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions, labels)
    ]
    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)
    <span class="hljs-keyword">return</span> {
        <span class="hljs-string">&quot;precision&quot;</span>: all_metrics[<span class="hljs-string">&quot;overall_precision&quot;</span>],
        <span class="hljs-string">&quot;recall&quot;</span>: all_metrics[<span class="hljs-string">&quot;overall_recall&quot;</span>],
        <span class="hljs-string">&quot;f1&quot;</span>: all_metrics[<span class="hljs-string">&quot;overall_f1&quot;</span>],
        <span class="hljs-string">&quot;accuracy&quot;</span>: all_metrics[<span class="hljs-string">&quot;overall_accuracy&quot;</span>],
    }`}}),{c(){d=l("p"),E=n("Cela renvoie un batch d\u2019informations ! Nous obtenons la pr\xE9cision, le rappel, et le score F1 pour chaque entit\xE9 s\xE9par\xE9e, ainsi que le score global. Pour notre calcul de m\xE9trique, nous ne garderons que le score global, mais n\u2019h\xE9sitez pas \xE0 modifier la fonction "),h=l("code"),q=n("compute_metrics()"),z=n(" pour retourner toutes les m\xE9triques que vous souhaitez."),$=p(),k=l("p"),O=n("Cette fonction "),y=l("code"),P=n("compute_metrics()"),H=n(" prend d\u2019abord l\u2019argmax des logits pour les convertir en pr\xE9dictions (comme d\u2019habitude, les logits et les probabilit\xE9s sont dans le m\xEAme ordre, donc nous n\u2019avons pas besoin d\u2019appliquer le softmax). Ensuite, nous devons convertir les \xE9tiquettes et les pr\xE9dictions des entiers en cha\xEEnes de caract\xE8res. Nous supprimons toutes les valeurs dont l\u2019\xE9tiquette est "),D=l("code"),L=n("-100"),R=n(", puis nous passons les r\xE9sultats \xE0 la m\xE9thode "),A=l("code"),N=n("metric.compute()"),Y=n(" :"),G=p(),j(X.$$.fragment),J=p(),K=l("p"),Q=n("Maintenant que ceci est fait, nous sommes presque pr\xEAts \xE0 d\xE9finir notre "),T=l("code"),F=n("Trainer"),S=n(". Nous avons juste besoin d\u2019un "),W=l("code"),ae=n("mod\xE8le"),ve=n(" pour "),te=l("em"),de=n("finetuner"),he=n(" !")},l(U){d=r(U,"P",{});var B=o(d);E=a(B,"Cela renvoie un batch d\u2019informations ! Nous obtenons la pr\xE9cision, le rappel, et le score F1 pour chaque entit\xE9 s\xE9par\xE9e, ainsi que le score global. Pour notre calcul de m\xE9trique, nous ne garderons que le score global, mais n\u2019h\xE9sitez pas \xE0 modifier la fonction "),h=r(B,"CODE",{});var Z=o(h);q=a(Z,"compute_metrics()"),Z.forEach(s),z=a(B," pour retourner toutes les m\xE9triques que vous souhaitez."),B.forEach(s),$=c(U),k=r(U,"P",{});var we=o(k);O=a(we,"Cette fonction "),y=r(we,"CODE",{});var Ie=o(y);P=a(Ie,"compute_metrics()"),Ie.forEach(s),H=a(we," prend d\u2019abord l\u2019argmax des logits pour les convertir en pr\xE9dictions (comme d\u2019habitude, les logits et les probabilit\xE9s sont dans le m\xEAme ordre, donc nous n\u2019avons pas besoin d\u2019appliquer le softmax). Ensuite, nous devons convertir les \xE9tiquettes et les pr\xE9dictions des entiers en cha\xEEnes de caract\xE8res. Nous supprimons toutes les valeurs dont l\u2019\xE9tiquette est "),D=r(we,"CODE",{});var xe=o(D);L=a(xe,"-100"),xe.forEach(s),R=a(we,", puis nous passons les r\xE9sultats \xE0 la m\xE9thode "),A=r(we,"CODE",{});var ee=o(A);N=a(ee,"metric.compute()"),ee.forEach(s),Y=a(we," :"),we.forEach(s),G=c(U),w(X.$$.fragment,U),J=c(U),K=r(U,"P",{});var le=o(K);Q=a(le,"Maintenant que ceci est fait, nous sommes presque pr\xEAts \xE0 d\xE9finir notre "),T=r(le,"CODE",{});var Ye=o(T);F=a(Ye,"Trainer"),Ye.forEach(s),S=a(le,". Nous avons juste besoin d\u2019un "),W=r(le,"CODE",{});var ks=o(W);ae=a(ks,"mod\xE8le"),ks.forEach(s),ve=a(le," pour "),te=r(le,"EM",{});var Ce=o(te);de=a(Ce,"finetuner"),Ce.forEach(s),he=a(le," !"),le.forEach(s)},m(U,B){u(U,d,B),e(d,E),e(d,h),e(h,q),e(d,z),u(U,$,B),u(U,k,B),e(k,O),e(k,y),e(y,P),e(k,H),e(k,D),e(D,L),e(k,R),e(k,A),e(A,N),e(k,Y),u(U,G,B),x(X,U,B),u(U,J,B),u(U,K,B),e(K,Q),e(K,T),e(T,F),e(K,S),e(K,W),e(W,ae),e(K,ve),e(K,te),e(te,de),e(K,he),_e=!0},i(U){_e||(b(X.$$.fragment,U),_e=!0)},o(U){g(X.$$.fragment,U),_e=!1},d(U){U&&s(d),U&&s($),U&&s(k),U&&s(G),C(X,U),U&&s(J),U&&s(K)}}}function rh(V){let d,E,h,q,z,$,k,O,y,P,H,D,L,R,A,N,Y,G,X,J,K,Q,T,F,S,W,ae,ve,te,de,he,_e,U,B,Z,we,Ie,xe,ee,le,Ye,ks,Ce,Ee,Rs,re,cn,it,ja,dn,js,wa,mn,ut,xa,fn,hn,Je,pt,Qe,vn,Re,_n,ye,Ae,es,He,Fs,ct,bn,$n,ze,Fn,be,vl,Bn,qe,Nt,gn,ke,ss,En,Bs,dt,qn,ws,ds,Tt,ms,Ca,St,ts,Hn,Oe,Hs,Ge,Fe,kn,ns,ya,jn,Lt,Gs,as,ie,wn,xn,Gn,ls,It,fs,Un,Ue,Vn,xs,Ne,mt,ft,Wn,je,za,Rt,Ve,Oa,ht,Xn,vt,Us,Vs,Pa,_t,rs,Cn,ue,bt,Cs,Ws,Da,hs,ys,Zn,Xs,os,We,yn,$t,Ma,Kn,vs,Zs,gt,_s,Yn,zs,zn,$e,Jn,ge,Et,Ft,Os,Qn,Ks,On,ea,Ps,Bt,qt,Ht,Ds,Ys,Gt,f,I,Aa,kt,Ms,me,Pn,fe,_l,Ut,Vt,Na,As,Wt,Dn,sa,Js,Ta,bs,jt,Xt,Qs,bl,ta,Mn,wt,Te,Zt,xt,Ns,$s,Kt,$l,gl,Ct,Yt,El,na,ne,Jt,yt,ql,is,Qt,gs,us,kl,aa,en,jl,Xe,la,wl,Sa,sn,zt,tn,Ro,Yl,Jl,Fo,Ir,An,Rr,La,Fr,Pe,Ql,er,Bo,sr,tr,Ho,nr,ar,Go,Uo,Ot,Nn,Br,et,lr,rr,Vo,or,ir,Wo,Hr,ra,Xo,Gr,oa,ia,ua,pa,Pt,xl,ur,Ur,Ia,Cl,nn,Zo,yl,Ra,Vr,ca,Ko,Wr,Tn,an,Es,ln,Sn,Fa,pr,cr,Xr,Dt,Ba,zl,qs,Yo,Ha,Jo,Qo,Ga,Ua,Zr,da,ei,Kr,st,Va,si,Ol,ma,ti,dr,Ts,ni,Pl,Wa,Yr,se,ai,mr,fr,li,hr,vr,ri,Xa,oi,Mt,_r,br,ii,$r,gr,ui,Er,qr,pi,Za,Jr,Dl,kr,Qr,Ka,Ml,fa,ci,Ya,di,mi,jr,At,wr,pe,eo,tt,fi,xr,Cr,hi,yr,zr,vi,so,Ln,to,Ja,Al,ce,_i,Qa,bi,$i,el,gi,Ei,Nl,nt,qi,sl,ki,ji,tl,wi,xi,In,Ci,yi,Tl;return q=new ot({}),U=new M({props:{code:`id2label = {str(i): label for i, label in enumerate(label_names)}
label2id = {v: k for k, v in id2label.items()}`,highlighted:`id2label = {<span class="hljs-built_in">str</span>(i): label <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(label_names)}
label2id = {v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> id2label.items()}`}}),Ee=new M({props:{code:`from transformers import AutoModelForTokenClassification

model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint, id2label=id2label, label2id=label2id,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification

model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint, id2label=id2label, label2id=label2id,
)`}}),Je=new M({props:{code:"model.config.num_labels",highlighted:"model.config.num_labels"}}),Qe=new M({props:{code:"9",highlighted:'<span class="hljs-number">9</span>'}}),Re=new Io({props:{warning:!0,$$slots:{default:[Ph]},$$scope:{ctx:V}}}),He=new ot({}),ss=new M({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`}}),Hs=new M({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}}),Gs=new M({props:{code:`from transformers import TrainingArguments

args = TrainingArguments(
    "bert-finetuned-ner",
    evaluation_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
    push_to_hub=True,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

args = TrainingArguments(
    <span class="hljs-string">&quot;bert-finetuned-ner&quot;</span>,
    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    num_train_epochs=<span class="hljs-number">3</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
    push_to_hub=<span class="hljs-literal">True</span>,
)`}}),vt=new Io({props:{$$slots:{default:[Dh]},$$scope:{ctx:V}}}),bt=new M({props:{code:`from transformers import Trainer

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer,
)
trainer.train()`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],
    data_collator=data_collator,
    compute_metrics=compute_metrics,
    tokenizer=tokenizer,
)
trainer.train()`}}),vs=new M({props:{code:'trainer.push_to_hub(commit_message="Training complete")',highlighted:'trainer.push_to_hub(commit_message=<span class="hljs-string">&quot;Training complete&quot;</span>)'}}),zs=new M({props:{code:"'https://huggingface.co/sgugger/bert-finetuned-ner/commit/26ab21e5b1568f9afeccdaed2d8715f571d786ed'",highlighted:'<span class="hljs-string">&#x27;https://huggingface.co/sgugger/bert-finetuned-ner/commit/26ab21e5b1568f9afeccdaed2d8715f571d786ed&#x27;</span>'}}),fe=new ot({}),Qs=new ot({}),ne=new M({props:{code:`from torch.utils.data import DataLoader

train_dataloader = DataLoader(
    tokenized_datasets["train"], shuffle=True, collate_fn=data_collator, batch_size=8,
)
eval_dataloader = DataLoader(
    tokenized_datasets["validation"], collate_fn=data_collator, batch_size=8
)`,highlighted:`<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

train_dataloader = DataLoader(
    tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>], shuffle=<span class="hljs-literal">True</span>, collate_fn=data_collator, batch_size=<span class="hljs-number">8</span>,
)
eval_dataloader = DataLoader(
    tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>], collate_fn=data_collator, batch_size=<span class="hljs-number">8</span>
)`}}),Qt=new M({props:{code:`model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint, id2label=id2label, label2id=label2id,
)`,highlighted:`model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint, id2label=id2label, label2id=label2id,
)`}}),sn=new M({props:{code:`from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)`,highlighted:`<span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW

optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">2e-5</span>)`}}),An=new M({props:{code:`from accelerate import Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)`,highlighted:`<span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)`}}),La=new Io({props:{$$slots:{default:[Mh]},$$scope:{ctx:V}}}),Nn=new M({props:{code:`from transformers import get_scheduler

num_train_epochs = 3
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler

num_train_epochs = <span class="hljs-number">3</span>
num_update_steps_per_epoch = <span class="hljs-built_in">len</span>(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    <span class="hljs-string">&quot;linear&quot;</span>,
    optimizer=optimizer,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_training_steps=num_training_steps,
)`}}),ia=new M({props:{code:`from huggingface_hub import Repository, get_full_repo_name

model_name = "bert-finetuned-ner-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> Repository, get_full_repo_name

model_name = <span class="hljs-string">&quot;bert-finetuned-ner-accelerate&quot;</span>
repo_name = get_full_repo_name(model_name)
repo_name`}}),pa=new M({props:{code:"'sgugger/bert-finetuned-ner-accelerate'",highlighted:'<span class="hljs-string">&#x27;sgugger/bert-finetuned-ner-accelerate&#x27;</span>'}}),Ia=new M({props:{code:`output_dir = "bert-finetuned-ner-accelerate"
repo = Repository(output_dir, clone_from=repo_name)`,highlighted:`output_dir = <span class="hljs-string">&quot;bert-finetuned-ner-accelerate&quot;</span>
repo = Repository(output_dir, clone_from=repo_name)`}}),Sn=new ot({}),Ua=new M({props:{code:`def postprocess(predictions, labels):
    predictions = predictions.detach().cpu().clone().numpy()
    labels = labels.detach().cpu().clone().numpy()

    # Remove ignored index (special tokens) and convert to labels
    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]
    true_predictions = [
        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    return true_labels, true_predictions`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">postprocess</span>(<span class="hljs-params">predictions, labels</span>):
    predictions = predictions.detach().cpu().clone().numpy()
    labels = labels.detach().cpu().clone().numpy()

    <span class="hljs-comment"># Remove ignored index (special tokens) and convert to labels</span>
    true_labels = [[label_names[l] <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> label <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels]
    true_predictions = [
        [label_names[p] <span class="hljs-keyword">for</span> (p, l) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction, label) <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>]
        <span class="hljs-keyword">for</span> prediction, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions, labels)
    ]
    <span class="hljs-keyword">return</span> true_labels, true_predictions`}}),Ka=new M({props:{code:`from tqdm.auto import tqdm
import torch

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
    # Entra\xEEnement
    model.train()
    for batch in train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # Evaluation
    model.eval()
    for batch in eval_dataloader:
        with torch.no_grad():
            outputs = model(**batch)

        predictions = outputs.logits.argmax(dim=-1)
        labels = batch["labels"]

        # N\xE9cessaire pour rembourrer les pr\xE9dictions et les \xE9tiquettes \xE0 rassembler
        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)
        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)

        predictions_gathered = accelerator.gather(predictions)
        labels_gathered = accelerator.gather(labels)

        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)
        metric.add_batch(predictions=true_predictions, references=true_labels)

    results = metric.compute()
    print(
        f"epoch {epoch}:",
        {
            key: results[f"overall_{key}"]
            for key in ["precision", "recall", "f1", "accuracy"]
        },
    )

    # Sauvegarder et t\xE9l\xE9charger
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=f"Training in progress epoch {epoch}", blocking=False
        )`,highlighted:`<span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm
<span class="hljs-keyword">import</span> torch

progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_train_epochs):
    <span class="hljs-comment"># Entra\xEEnement</span>
    model.train()
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(<span class="hljs-number">1</span>)

    <span class="hljs-comment"># Evaluation</span>
    model.<span class="hljs-built_in">eval</span>()
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> eval_dataloader:
        <span class="hljs-keyword">with</span> torch.no_grad():
            outputs = model(**batch)

        predictions = outputs.logits.argmax(dim=-<span class="hljs-number">1</span>)
        labels = batch[<span class="hljs-string">&quot;labels&quot;</span>]

        <span class="hljs-comment"># N\xE9cessaire pour rembourrer les pr\xE9dictions et les \xE9tiquettes \xE0 rassembler</span>
        predictions = accelerator.pad_across_processes(predictions, dim=<span class="hljs-number">1</span>, pad_index=-<span class="hljs-number">100</span>)
        labels = accelerator.pad_across_processes(labels, dim=<span class="hljs-number">1</span>, pad_index=-<span class="hljs-number">100</span>)

        predictions_gathered = accelerator.gather(predictions)
        labels_gathered = accelerator.gather(labels)

        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)
        metric.add_batch(predictions=true_predictions, references=true_labels)

    results = metric.compute()
    <span class="hljs-built_in">print</span>(
        <span class="hljs-string">f&quot;epoch <span class="hljs-subst">{epoch}</span>:&quot;</span>,
        {
            key: results[<span class="hljs-string">f&quot;overall_<span class="hljs-subst">{key}</span>&quot;</span>]
            <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;precision&quot;</span>, <span class="hljs-string">&quot;recall&quot;</span>, <span class="hljs-string">&quot;f1&quot;</span>, <span class="hljs-string">&quot;accuracy&quot;</span>]
        },
    )

    <span class="hljs-comment"># Sauvegarder et t\xE9l\xE9charger</span>
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    <span class="hljs-keyword">if</span> accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=<span class="hljs-string">f&quot;Training in progress epoch <span class="hljs-subst">{epoch}</span>&quot;</span>, blocking=<span class="hljs-literal">False</span>
        )`}}),At=new M({props:{code:`accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)`,highlighted:`accelerator.wait_for_everyone()
unwrapped_model = accelerator.unwrap_model(model)
unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)`}}),{c(){d=l("h3"),E=l("a"),h=l("span"),j(q.$$.fragment),z=p(),$=l("span"),k=n("D\xE9finir le mod\xE8le"),O=p(),y=l("p"),P=n("Puisque nous travaillons sur un probl\xE8me de classification de "),H=l("em"),D=n("tokens"),L=n(", nous allons utiliser la classe "),R=l("code"),A=n("AutoModelForTokenClassification"),N=n(". La principale chose \xE0 retenir lors de la d\xE9finition de ce mod\xE8le est de transmettre des informations sur le nombre de labels que nous avons. La fa\xE7on la plus simple de le faire est de passer ce nombre avec l\u2019argument "),Y=l("code"),G=n("num_labels"),X=n(", mais si nous voulons un joli "),J=l("em"),K=n("widget"),Q=n(" d\u2019inf\xE9rence fonctionnant comme celui que nous avons vu au d\xE9but de cette section, il est pr\xE9f\xE9rable de d\xE9finir les correspondances correctes des \xE9tiquettes \xE0 la place."),T=p(),F=l("p"),S=n("Elles devraient \xEAtre d\xE9finies par deux dictionnaires, "),W=l("code"),ae=n("id2label"),ve=n(" et "),te=l("code"),de=n("label2id"),he=n(", qui contiennent les correspondances entre ID et label et vice versa :"),_e=p(),j(U.$$.fragment),B=p(),Z=l("p"),we=n("Maintenant nous pouvons simplement les passer \xE0 la m\xE9thode "),Ie=l("code"),xe=n("AutoModelForTokenClassification.from_pretrained()"),ee=n(", et ils seront d\xE9finis dans la configuration du mod\xE8le et ensuite correctement sauvegard\xE9s et t\xE9l\xE9charg\xE9s vers le "),le=l("em"),Ye=n("Hub"),ks=n(" :"),Ce=p(),j(Ee.$$.fragment),Rs=p(),re=l("p"),cn=n("Comme lorsque nous avons d\xE9fini notre "),it=l("code"),ja=n("AutoModelForSequenceClassification"),dn=n(" au "),js=l("a"),wa=n("Chapitre 3"),mn=n(", la cr\xE9ation du mod\xE8le \xE9met un avertissement indiquant que certains poids n\u2019ont pas \xE9t\xE9 utilis\xE9s (ceux de la t\xEAte de pr\xE9-entra\xEEnement) et que d\u2019autres poids ont \xE9t\xE9 initialis\xE9s de mani\xE8re al\xE9atoire (ceux de la t\xEAte de classification des nouveaux "),ut=l("em"),xa=n("tokens"),fn=n("), et que ce mod\xE8le doit \xEAtre entra\xEEn\xE9. Nous ferons cela dans une minute, mais v\xE9rifions d\u2019abord que notre mod\xE8le a le bon nombre d\u2019\xE9tiquettes :"),hn=p(),j(Je.$$.fragment),pt=p(),j(Qe.$$.fragment),vn=p(),j(Re.$$.fragment),_n=p(),ye=l("h3"),Ae=l("a"),es=l("span"),j(He.$$.fragment),Fs=p(),ct=l("span"),bn=n("*Finetuning* du mod\xE8le"),$n=p(),ze=l("p"),Fn=n("Nous sommes maintenant pr\xEAts \xE0 entra\xEEner notre mod\xE8le ! Nous devons juste faire deux derni\xE8res choses avant de d\xE9finir notre "),be=l("code"),vl=n("Trainer"),Bn=n(" : se connecter \xE0 Hugging Face et d\xE9finir nos arguments d\u2019entra\xEEnement. Si vous travaillez dans un "),qe=l("em"),Nt=n("notebook"),gn=n(", il y a une fonction pratique pour vous aider \xE0 le faire :"),ke=p(),j(ss.$$.fragment),En=p(),Bs=l("p"),dt=n("Cela affichera un "),qn=l("em"),ws=n("widget"),ds=n(" o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),Tt=p(),ms=l("p"),Ca=n("Si vous ne travaillez pas dans un "),St=l("em"),ts=n("notebook"),Hn=n(", tapez simplement la ligne suivante dans votre terminal :"),Oe=p(),j(Hs.$$.fragment),Ge=p(),Fe=l("p"),kn=n("Une fois ceci fait, nous pouvons d\xE9finir nos "),ns=l("code"),ya=n("TrainingArguments"),jn=n(" :"),Lt=p(),j(Gs.$$.fragment),as=p(),ie=l("p"),wn=n("Vous avez d\xE9j\xE0 vu la plupart d\u2019entre eux : nous d\xE9finissons quelques hyperparam\xE8tres (comme le taux d\u2019apprentissage, le nombre d\u2019\xE9poques \xE0 entra\xEEner, et la d\xE9croissance du poids), et nous sp\xE9cifions "),xn=l("code"),Gn=n("push_to_hub=True"),ls=n(" pour indiquer que nous voulons sauvegarder le mod\xE8le et l\u2019\xE9valuer \xE0 la fin de chaque \xE9poque, et que nous voulons t\xE9l\xE9charger nos r\xE9sultats vers le "),It=l("em"),fs=n("Hub"),Un=n(". Notez que vous pouvez sp\xE9cifier le nom du r\xE9f\xE9rentiel vers lequel vous voulez pousser avec l\u2019argument "),Ue=l("code"),Vn=n("hub_model_id"),xs=n(" (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),Ne=l("a"),mt=l("code"),ft=n("huggingface-course"),Wn=n(", nous avons ajout\xE9 "),je=l("code"),za=n('hub_model_id="huggingface-course/bert-finetuned-ner"``TrainingArguments'),Rt=n(". Par d\xE9faut, le r\xE9f\xE9rentiel utilis\xE9 sera dans votre espace de noms et nomm\xE9 d\u2019apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, donc dans notre cas ce sera "),Ve=l("code"),Oa=n('"sgugger/bert-finetuned-ner"'),ht=n("."),Xn=p(),j(vt.$$.fragment),Us=p(),Vs=l("p"),Pa=n("Enfin, nous passons tout au "),_t=l("code"),rs=n("Trainer"),Cn=n(" et lan\xE7ons l\u2019entra\xEEnement :"),ue=p(),j(bt.$$.fragment),Cs=p(),Ws=l("p"),Da=n("Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),hs=l("em"),ys=n("Hub"),Zn=n(" en arri\xE8re-plan. De cette fa\xE7on, vous serez en mesure de reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),Xs=p(),os=l("p"),We=n("Une fois l\u2019entra\xEEnement termin\xE9, nous utilisons la m\xE9thode "),yn=l("code"),$t=n("push_to_hub()"),Ma=n(" pour nous assurer que nous t\xE9l\xE9chargeons la version la plus r\xE9cente du mod\xE8le :"),Kn=p(),j(vs.$$.fragment),Zs=p(),gt=l("p"),_s=n("Cette commande renvoie l\u2019URL du commit qu\u2019elle vient de faire, si vous voulez l\u2019inspecter :"),Yn=p(),j(zs.$$.fragment),zn=p(),$e=l("p"),Jn=n("Le "),ge=l("code"),Et=n("Trainer"),Ft=n(" r\xE9dige \xE9galement une carte mod\xE8le avec tous les r\xE9sultats de l\u2019\xE9valuation et la t\xE9l\xE9charge. A ce stade, vous pouvez utiliser le "),Os=l("em"),Qn=n("widget"),Ks=n(" d\u2019inf\xE9rence sur le "),On=l("em"),ea=n("Hub"),Ps=n(" pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 affiner un mod\xE8le sur une t\xE2che de classification de "),Bt=l("em"),qt=n("tokens"),Ht=n(". F\xE9licitations !"),Ds=p(),Ys=l("p"),Gt=n("Si vous voulez plonger un peu plus profond\xE9ment dans la boucle d\u2019entra\xEEnement, nous allons maintenant vous montrer comment faire la m\xEAme chose en utilisant \u{1F917} "),f=l("em"),I=n("Accelerate"),Aa=n("."),kt=p(),Ms=l("h2"),me=l("a"),Pn=l("span"),j(fe.$$.fragment),_l=p(),Ut=l("span"),Vt=n("Une boucle d'entra\xEEnement personnalis\xE9e"),Na=p(),As=l("p"),Wt=n("Jetons maintenant un coup d\u2019\u0153il \xE0 la boucle d\u2019entra\xEEnement compl\xE8te, afin que vous puissiez facilement personnaliser les parties dont vous avez besoin. Elle ressemblera beaucoup \xE0 ce que nous avons fait dans le "),Dn=l("a"),sa=n("Chapitre 3"),Js=n(", avec quelques changements pour l\u2019\xE9valuation."),Ta=p(),bs=l("h3"),jt=l("a"),Xt=l("span"),j(Qs.$$.fragment),bl=p(),ta=l("span"),Mn=n("Pr\xE9parer tout pour l'entra\xEEnement"),wt=p(),Te=l("p"),Zt=n("D\u2019abord nous devons construire le "),xt=l("code"),Ns=n("DataLoader"),$s=n("s \xE0 partir de nos jeux de donn\xE9es. Nous allons r\xE9utiliser notre "),Kt=l("code"),$l=n("data_collator"),gl=n(" comme un "),Ct=l("code"),Yt=n("collate_fn"),El=n(" et m\xE9langer l\u2019ensemble d\u2019entra\xEEnement, mais pas l\u2019ensemble de validation :"),na=p(),j(ne.$$.fragment),Jt=p(),yt=l("p"),ql=n("Ensuite, nous r\xE9instantifions notre mod\xE8le, pour nous assurer que nous ne continuons pas le r\xE9glage fin d\u2019avant, mais que nous repartons du mod\xE8le pr\xE9-entra\xEEn\xE9 de BERT :"),is=p(),j(Qt.$$.fragment),gs=p(),us=l("p"),kl=n("Ensuite, nous aurons besoin d\u2019un optimiseur. Nous allons utiliser le classique "),aa=l("code"),en=n("AdamW"),jl=n(", qui est comme "),Xe=l("code"),la=n("Adam"),wl=n(", mais avec un correctif dans la fa\xE7on dont la d\xE9croissance du taux des poids est appliqu\xE9e :"),Sa=p(),j(sn.$$.fragment),zt=p(),tn=l("p"),Ro=n("Une fois que nous avons tous ces objets, nous pouvons les envoyer \xE0 la m\xE9thode "),Yl=l("code"),Jl=n("accelerator.prepare()"),Fo=n(" :"),Ir=p(),j(An.$$.fragment),Rr=p(),j(La.$$.fragment),Fr=p(),Pe=l("p"),Ql=n("Maintenant que nous avons envoy\xE9 notre "),er=l("code"),Bo=n("train_dataloader"),sr=n(" \xE0 "),tr=l("code"),Ho=n("accelerator.prepare()"),nr=n(", nous pouvons utiliser sa longueur pour calculer le nombre d\u2019\xE9tapes d\u2019entra\xEEnement. Rappelez-vous que nous devrions toujours faire cela apr\xE8s avoir pr\xE9par\xE9 le "),ar=l("em"),Go=n("dataloader"),Uo=n(", car cette m\xE9thode modifiera sa longueur. Nous utilisons un programme lin\xE9aire classique du taux d\u2019apprentissage \xE0 0 :"),Ot=p(),j(Nn.$$.fragment),Br=p(),et=l("p"),lr=n("Enfin, pour pousser notre mod\xE8le vers le Hub, nous aurons besoin de cr\xE9er un objet "),rr=l("code"),Vo=n("Repository"),or=n(" dans un dossier de travail. Tout d\u2019abord, connectez-vous \xE0 Hugging Face, si vous n\u2019\xEAtes pas d\xE9j\xE0 connect\xE9. Nous d\xE9terminerons le nom du d\xE9p\xF4t \xE0 partir de l\u2019ID du mod\xE8le que nous voulons donner \xE0 notre mod\xE8le (n\u2019h\xE9sitez pas \xE0 remplacer le "),ir=l("code"),Wo=n("repo_name"),Hr=n(" par votre propre choix ; il doit juste contenir votre nom d\u2019utilisateur, ce que fait la fonction "),ra=l("code"),Xo=n("get_full_repo_name()"),Gr=n(") :"),oa=p(),j(ia.$$.fragment),ua=p(),j(pa.$$.fragment),Pt=p(),xl=l("p"),ur=n("Ensuite, nous pouvons cloner ce r\xE9f\xE9rentiel dans un dossier local. S\u2019il existe d\xE9j\xE0, ce dossier local doit \xEAtre un clone existant du r\xE9f\xE9rentiel avec lequel nous travaillons :"),Ur=p(),j(Ia.$$.fragment),Cl=p(),nn=l("p"),Zo=n("Nous pouvons maintenant t\xE9l\xE9charger tout ce que nous sauvegardons dans "),yl=l("code"),Ra=n("output_dir"),Vr=n(" en appelant la m\xE9thode "),ca=l("code"),Ko=n("repo.push_to_hub()"),Wr=n(". Cela nous aidera \xE0 t\xE9l\xE9charger les mod\xE8les interm\xE9diaires \xE0 la fin de chaque \xE9poque."),Tn=p(),an=l("h3"),Es=l("a"),ln=l("span"),j(Sn.$$.fragment),Fa=p(),pr=l("span"),cr=n("Boucle d'entra\xEEnement"),Xr=p(),Dt=l("p"),Ba=n("Nous sommes maintenant pr\xEAts \xE0 \xE9crire la boucle d\u2019entra\xEEnement compl\xE8te. Pour simplifier sa partie \xE9valuation, nous d\xE9finissons cette fonction "),zl=l("code"),qs=n("postprocess()"),Yo=n(" qui prend les pr\xE9dictions et les \xE9tiquettes et les convertit en listes de cha\xEEnes de caract\xE8res, comme notre objet "),Ha=l("code"),Jo=n("metric"),Qo=n(" l\u2019attend :"),Ga=p(),j(Ua.$$.fragment),Zr=p(),da=l("p"),ei=n("Ensuite, nous pouvons \xE9crire la boucle d\u2019entra\xEEnement. Apr\xE8s avoir d\xE9fini une barre de progression pour suivre l\u2019\xE9volution de l\u2019entra\xEEnement, la boucle comporte trois parties :"),Kr=p(),st=l("ul"),Va=l("li"),si=n("l\u2019entra\xEEnement proprement dit, qui est l\u2019it\xE9ration classique sur le "),Ol=l("code"),ma=n("train_dataloader"),ti=n(", passage en avant du mod\xE8le, puis passage en arri\xE8re et \xE9tape d\u2019optimisation,"),dr=p(),Ts=l("li"),ni=n("l\u2019\xE9valuation, dans laquelle il y a une nouveaut\xE9 apr\xE8s avoir obtenu les sorties de notre mod\xE8le sur un lot : puisque deux processus peuvent avoir padd\xE9 les entr\xE9es et les \xE9tiquettes \xE0 des formes diff\xE9rentes, nous devons utiliser "),Pl=l("code"),Wa=n("accelerator.pad_across_processes()"),Yr=n(" pour rendre les pr\xE9dictions et les \xE9tiquettes de la m\xEAme forme avant d\u2019appeler la m\xE9thode "),se=l("code"),ai=n("gather()"),mr=n(". Si nous ne le faisons pas, l\u2019\xE9valuation va soit se tromper, soit se bloquer pour toujours. Ensuite, nous envoyons les r\xE9sultats \xE0 "),fr=l("code"),li=n("metric.add_batch()"),hr=n(" et appelons "),vr=l("code"),ri=n("metric.compute()"),Xa=n(" une fois que la boucle d\u2019\xE9valuation est termin\xE9e,"),oi=p(),Mt=l("li"),_r=n("sauvegarde et t\xE9l\xE9chargement, o\xF9 nous sauvegardons d\u2019abord le mod\xE8le et le tokenizer, puis appelons "),br=l("code"),ii=n("repo.push_to_hub()"),$r=n(". Remarquez que nous utilisons l\u2019argument "),gr=l("code"),ui=n("blocking=False"),Er=n(" pour indiquer \xE0 la biblioth\xE8que \u{1F917} "),qr=l("em"),pi=n("Hub"),Za=n(" de pousser dans un processus asynchrone. De cette fa\xE7on, l\u2019entra\xEEnement continue normalement et cette (longue) instruction est ex\xE9cut\xE9e en arri\xE8re-plan."),Jr=p(),Dl=l("p"),kr=n("Voici le code complet de la boucle d\u2019entra\xEEnement :"),Qr=p(),j(Ka.$$.fragment),Ml=p(),fa=l("p"),ci=n("Au cas o\xF9 ce serait la premi\xE8re fois que vous verriez un mod\xE8le enregistr\xE9 avec \u{1F917} "),Ya=l("em"),di=n("Accelerate"),mi=n(", prenons un moment pour inspecter les trois lignes de code qui l\u2019accompagnent :"),jr=p(),j(At.$$.fragment),wr=p(),pe=l("p"),eo=n("La premi\xE8re ligne est explicite : elle indique \xE0 tous les processus d\u2019attendre que tout le monde soit \xE0 ce stade avant de continuer. C\u2019est pour s\u2019assurer que nous avons le m\xEAme mod\xE8le dans chaque processus avant de sauvegarder. Ensuite, nous prenons le "),tt=l("code"),fi=n("unwrapped_model"),xr=n(", qui est le mod\xE8le de base que nous avons d\xE9fini. La m\xE9thode "),Cr=l("code"),hi=n("accelerator.prepare()"),yr=n(" modifie le mod\xE8le pour qu\u2019il fonctionne dans l\u2019entra\xEEnement distribu\xE9, donc il n\u2019aura plus la m\xE9thode "),zr=l("code"),vi=n("save_pretrained()"),so=n(" ; la m\xE9thode "),Ln=l("code"),to=n("accelerator.unwrap_model()"),Ja=n(" annule cette \xE9tape. Enfin, nous appelons "),Al=l("code"),ce=n("save_pretrained()"),_i=n(" mais nous disons \xE0 cette m\xE9thode d\u2019utiliser "),Qa=l("code"),bi=n("accelerator.save()"),$i=n(" au lieu de "),el=l("code"),gi=n("torch.save()"),Ei=n("."),Nl=p(),nt=l("p"),qi=n("Une fois ceci fait, vous devriez avoir un mod\xE8le qui produit des r\xE9sultats assez similaires \xE0 celui entra\xEEn\xE9 avec le "),sl=l("code"),ki=n("Trainer"),ji=n(". Vous pouvez v\xE9rifier le mod\xE8le que nous avons form\xE9 en utilisant ce code \xE0 ["),tl=l("em"),wi=n("huggingface-course/bert-finetuned-ner-accelerate"),xi=n("("),In=l("a"),Ci=n("https://huggingface.co/huggingface-course/bert-finetuned-ner-accelerate"),yi=n("). Et si vous voulez tester des modifications de la boucle d\u2019entra\xEEnement, vous pouvez les impl\xE9menter directement en modifiant le code ci-dessus !"),this.h()},l(i){d=r(i,"H3",{class:!0});var v=o(d);E=r(v,"A",{id:!0,class:!0,href:!0});var no=o(E);h=r(no,"SPAN",{});var fu=o(h);w(q.$$.fragment,fu),fu.forEach(s),no.forEach(s),z=c(v),$=r(v,"SPAN",{});var hu=o($);k=a(hu,"D\xE9finir le mod\xE8le"),hu.forEach(s),v.forEach(s),O=c(i),y=r(i,"P",{});var at=o(y);P=a(at,"Puisque nous travaillons sur un probl\xE8me de classification de "),H=r(at,"EM",{});var vu=o(H);D=a(vu,"tokens"),vu.forEach(s),L=a(at,", nous allons utiliser la classe "),R=r(at,"CODE",{});var _u=o(R);A=a(_u,"AutoModelForTokenClassification"),_u.forEach(s),N=a(at,". La principale chose \xE0 retenir lors de la d\xE9finition de ce mod\xE8le est de transmettre des informations sur le nombre de labels que nous avons. La fa\xE7on la plus simple de le faire est de passer ce nombre avec l\u2019argument "),Y=r(at,"CODE",{});var zi=o(Y);G=a(zi,"num_labels"),zi.forEach(s),X=a(at,", mais si nous voulons un joli "),J=r(at,"EM",{});var Ss=o(J);K=a(Ss,"widget"),Ss.forEach(s),Q=a(at," d\u2019inf\xE9rence fonctionnant comme celui que nous avons vu au d\xE9but de cette section, il est pr\xE9f\xE9rable de d\xE9finir les correspondances correctes des \xE9tiquettes \xE0 la place."),at.forEach(s),T=c(i),F=r(i,"P",{});var Sl=o(F);S=a(Sl,"Elles devraient \xEAtre d\xE9finies par deux dictionnaires, "),W=r(Sl,"CODE",{});var ao=o(W);ae=a(ao,"id2label"),ao.forEach(s),ve=a(Sl," et "),te=r(Sl,"CODE",{});var bu=o(te);de=a(bu,"label2id"),bu.forEach(s),he=a(Sl,", qui contiennent les correspondances entre ID et label et vice versa :"),Sl.forEach(s),_e=c(i),w(U.$$.fragment,i),B=c(i),Z=r(i,"P",{});var Ll=o(Z);we=a(Ll,"Maintenant nous pouvons simplement les passer \xE0 la m\xE9thode "),Ie=r(Ll,"CODE",{});var lo=o(Ie);xe=a(lo,"AutoModelForTokenClassification.from_pretrained()"),lo.forEach(s),ee=a(Ll,", et ils seront d\xE9finis dans la configuration du mod\xE8le et ensuite correctement sauvegard\xE9s et t\xE9l\xE9charg\xE9s vers le "),le=r(Ll,"EM",{});var $u=o(le);Ye=a($u,"Hub"),$u.forEach(s),ks=a(Ll," :"),Ll.forEach(s),Ce=c(i),w(Ee.$$.fragment,i),Rs=c(i),re=r(i,"P",{});var ha=o(re);cn=a(ha,"Comme lorsque nous avons d\xE9fini notre "),it=r(ha,"CODE",{});var ro=o(it);ja=a(ro,"AutoModelForSequenceClassification"),ro.forEach(s),dn=a(ha," au "),js=r(ha,"A",{href:!0});var gu=o(js);wa=a(gu,"Chapitre 3"),gu.forEach(s),mn=a(ha,", la cr\xE9ation du mod\xE8le \xE9met un avertissement indiquant que certains poids n\u2019ont pas \xE9t\xE9 utilis\xE9s (ceux de la t\xEAte de pr\xE9-entra\xEEnement) et que d\u2019autres poids ont \xE9t\xE9 initialis\xE9s de mani\xE8re al\xE9atoire (ceux de la t\xEAte de classification des nouveaux "),ut=r(ha,"EM",{});var Eu=o(ut);xa=a(Eu,"tokens"),Eu.forEach(s),fn=a(ha,"), et que ce mod\xE8le doit \xEAtre entra\xEEn\xE9. Nous ferons cela dans une minute, mais v\xE9rifions d\u2019abord que notre mod\xE8le a le bon nombre d\u2019\xE9tiquettes :"),ha.forEach(s),hn=c(i),w(Je.$$.fragment,i),pt=c(i),w(Qe.$$.fragment,i),vn=c(i),w(Re.$$.fragment,i),_n=c(i),ye=r(i,"H3",{class:!0});var nl=o(ye);Ae=r(nl,"A",{id:!0,class:!0,href:!0});var qu=o(Ae);es=r(qu,"SPAN",{});var ku=o(es);w(He.$$.fragment,ku),ku.forEach(s),qu.forEach(s),Fs=c(nl),ct=r(nl,"SPAN",{});var Oi=o(ct);bn=a(Oi,"*Finetuning* du mod\xE8le"),Oi.forEach(s),nl.forEach(s),$n=c(i),ze=r(i,"P",{});var rn=o(ze);Fn=a(rn,"Nous sommes maintenant pr\xEAts \xE0 entra\xEEner notre mod\xE8le ! Nous devons juste faire deux derni\xE8res choses avant de d\xE9finir notre "),be=r(rn,"CODE",{});var Pi=o(be);vl=a(Pi,"Trainer"),Pi.forEach(s),Bn=a(rn," : se connecter \xE0 Hugging Face et d\xE9finir nos arguments d\u2019entra\xEEnement. Si vous travaillez dans un "),qe=r(rn,"EM",{});var Il=o(qe);Nt=a(Il,"notebook"),Il.forEach(s),gn=a(rn,", il y a une fonction pratique pour vous aider \xE0 le faire :"),rn.forEach(s),ke=c(i),w(ss.$$.fragment,i),En=c(i),Bs=r(i,"P",{});var Or=o(Bs);dt=a(Or,"Cela affichera un "),qn=r(Or,"EM",{});var oe=o(qn);ws=a(oe,"widget"),oe.forEach(s),ds=a(Or," o\xF9 vous pourrez entrer vos identifiants de connexion \xE0 Hugging Face."),Or.forEach(s),Tt=c(i),ms=r(i,"P",{});var oo=o(ms);Ca=a(oo,"Si vous ne travaillez pas dans un "),St=r(oo,"EM",{});var io=o(St);ts=a(io,"notebook"),io.forEach(s),Hn=a(oo,", tapez simplement la ligne suivante dans votre terminal :"),oo.forEach(s),Oe=c(i),w(Hs.$$.fragment,i),Ge=c(i),Fe=r(i,"P",{});var uo=o(Fe);kn=a(uo,"Une fois ceci fait, nous pouvons d\xE9finir nos "),ns=r(uo,"CODE",{});var ju=o(ns);ya=a(ju,"TrainingArguments"),ju.forEach(s),jn=a(uo," :"),uo.forEach(s),Lt=c(i),w(Gs.$$.fragment,i),as=c(i),ie=r(i,"P",{});var Ze=o(ie);wn=a(Ze,"Vous avez d\xE9j\xE0 vu la plupart d\u2019entre eux : nous d\xE9finissons quelques hyperparam\xE8tres (comme le taux d\u2019apprentissage, le nombre d\u2019\xE9poques \xE0 entra\xEEner, et la d\xE9croissance du poids), et nous sp\xE9cifions "),xn=r(Ze,"CODE",{});var wu=o(xn);Gn=a(wu,"push_to_hub=True"),wu.forEach(s),ls=a(Ze," pour indiquer que nous voulons sauvegarder le mod\xE8le et l\u2019\xE9valuer \xE0 la fin de chaque \xE9poque, et que nous voulons t\xE9l\xE9charger nos r\xE9sultats vers le "),It=r(Ze,"EM",{});var xu=o(It);fs=a(xu,"Hub"),xu.forEach(s),Un=a(Ze,". Notez que vous pouvez sp\xE9cifier le nom du r\xE9f\xE9rentiel vers lequel vous voulez pousser avec l\u2019argument "),Ue=r(Ze,"CODE",{});var po=o(Ue);Vn=a(po,"hub_model_id"),po.forEach(s),xs=a(Ze," (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),Ne=r(Ze,"A",{href:!0,rel:!0});var Cu=o(Ne);mt=r(Cu,"CODE",{});var yu=o(mt);ft=a(yu,"huggingface-course"),yu.forEach(s),Cu.forEach(s),Wn=a(Ze,", nous avons ajout\xE9 "),je=r(Ze,"CODE",{});var co=o(je);za=a(co,'hub_model_id="huggingface-course/bert-finetuned-ner"``TrainingArguments'),co.forEach(s),Rt=a(Ze,". Par d\xE9faut, le r\xE9f\xE9rentiel utilis\xE9 sera dans votre espace de noms et nomm\xE9 d\u2019apr\xE8s le r\xE9pertoire de sortie que vous avez d\xE9fini, donc dans notre cas ce sera "),Ve=r(Ze,"CODE",{});var zu=o(Ve);Oa=a(zu,'"sgugger/bert-finetuned-ner"'),zu.forEach(s),ht=a(Ze,"."),Ze.forEach(s),Xn=c(i),w(vt.$$.fragment,i),Us=c(i),Vs=r(i,"P",{});var mo=o(Vs);Pa=a(mo,"Enfin, nous passons tout au "),_t=r(mo,"CODE",{});var fo=o(_t);rs=a(fo,"Trainer"),fo.forEach(s),Cn=a(mo," et lan\xE7ons l\u2019entra\xEEnement :"),mo.forEach(s),ue=c(i),w(bt.$$.fragment,i),Cs=c(i),Ws=r(i,"P",{});var ho=o(Ws);Da=a(ho,"Notez que pendant l\u2019entra\xEEnement, chaque fois que le mod\xE8le est sauvegard\xE9 (ici, \xE0 chaque \xE9poque), il est t\xE9l\xE9charg\xE9 sur le "),hs=r(ho,"EM",{});var Ou=o(hs);ys=a(Ou,"Hub"),Ou.forEach(s),Zn=a(ho," en arri\xE8re-plan. De cette fa\xE7on, vous serez en mesure de reprendre votre entra\xEEnement sur une autre machine si n\xE9cessaire."),ho.forEach(s),Xs=c(i),os=r(i,"P",{});var Rl=o(os);We=a(Rl,"Une fois l\u2019entra\xEEnement termin\xE9, nous utilisons la m\xE9thode "),yn=r(Rl,"CODE",{});var Pu=o(yn);$t=a(Pu,"push_to_hub()"),Pu.forEach(s),Ma=a(Rl," pour nous assurer que nous t\xE9l\xE9chargeons la version la plus r\xE9cente du mod\xE8le :"),Rl.forEach(s),Kn=c(i),w(vs.$$.fragment,i),Zs=c(i),gt=r(i,"P",{});var Du=o(gt);_s=a(Du,"Cette commande renvoie l\u2019URL du commit qu\u2019elle vient de faire, si vous voulez l\u2019inspecter :"),Du.forEach(s),Yn=c(i),w(zs.$$.fragment,i),zn=c(i),$e=r(i,"P",{});var lt=o($e);Jn=a(lt,"Le "),ge=r(lt,"CODE",{});var Mu=o(ge);Et=a(Mu,"Trainer"),Mu.forEach(s),Ft=a(lt," r\xE9dige \xE9galement une carte mod\xE8le avec tous les r\xE9sultats de l\u2019\xE9valuation et la t\xE9l\xE9charge. A ce stade, vous pouvez utiliser le "),Os=r(lt,"EM",{});var Au=o(Os);Qn=a(Au,"widget"),Au.forEach(s),Ks=a(lt," d\u2019inf\xE9rence sur le "),On=r(lt,"EM",{});var vo=o(On);ea=a(vo,"Hub"),vo.forEach(s),Ps=a(lt," pour tester votre mod\xE8le et le partager avec vos amis. Vous avez r\xE9ussi \xE0 affiner un mod\xE8le sur une t\xE2che de classification de "),Bt=r(lt,"EM",{});var Nu=o(Bt);qt=a(Nu,"tokens"),Nu.forEach(s),Ht=a(lt,". F\xE9licitations !"),lt.forEach(s),Ds=c(i),Ys=r(i,"P",{});var _o=o(Ys);Gt=a(_o,"Si vous voulez plonger un peu plus profond\xE9ment dans la boucle d\u2019entra\xEEnement, nous allons maintenant vous montrer comment faire la m\xEAme chose en utilisant \u{1F917} "),f=r(_o,"EM",{});var bo=o(f);I=a(bo,"Accelerate"),bo.forEach(s),Aa=a(_o,"."),_o.forEach(s),kt=c(i),Ms=r(i,"H2",{class:!0});var $o=o(Ms);me=r($o,"A",{id:!0,class:!0,href:!0});var Tu=o(me);Pn=r(Tu,"SPAN",{});var go=o(Pn);w(fe.$$.fragment,go),go.forEach(s),Tu.forEach(s),_l=c($o),Ut=r($o,"SPAN",{});var Su=o(Ut);Vt=a(Su,"Une boucle d'entra\xEEnement personnalis\xE9e"),Su.forEach(s),$o.forEach(s),Na=c(i),As=r(i,"P",{});var Eo=o(As);Wt=a(Eo,"Jetons maintenant un coup d\u2019\u0153il \xE0 la boucle d\u2019entra\xEEnement compl\xE8te, afin que vous puissiez facilement personnaliser les parties dont vous avez besoin. Elle ressemblera beaucoup \xE0 ce que nous avons fait dans le "),Dn=r(Eo,"A",{href:!0});var Di=o(Dn);sa=a(Di,"Chapitre 3"),Di.forEach(s),Js=a(Eo,", avec quelques changements pour l\u2019\xE9valuation."),Eo.forEach(s),Ta=c(i),bs=r(i,"H3",{class:!0});var va=o(bs);jt=r(va,"A",{id:!0,class:!0,href:!0});var Mi=o(jt);Xt=r(Mi,"SPAN",{});var Pr=o(Xt);w(Qs.$$.fragment,Pr),Pr.forEach(s),Mi.forEach(s),bl=c(va),ta=r(va,"SPAN",{});var Lu=o(ta);Mn=a(Lu,"Pr\xE9parer tout pour l'entra\xEEnement"),Lu.forEach(s),va.forEach(s),wt=c(i),Te=r(i,"P",{});var Rn=o(Te);Zt=a(Rn,"D\u2019abord nous devons construire le "),xt=r(Rn,"CODE",{});var Fl=o(xt);Ns=a(Fl,"DataLoader"),Fl.forEach(s),$s=a(Rn,"s \xE0 partir de nos jeux de donn\xE9es. Nous allons r\xE9utiliser notre "),Kt=r(Rn,"CODE",{});var Ai=o(Kt);$l=a(Ai,"data_collator"),Ai.forEach(s),gl=a(Rn," comme un "),Ct=r(Rn,"CODE",{});var Bl=o(Ct);Yt=a(Bl,"collate_fn"),Bl.forEach(s),El=a(Rn," et m\xE9langer l\u2019ensemble d\u2019entra\xEEnement, mais pas l\u2019ensemble de validation :"),Rn.forEach(s),na=c(i),w(ne.$$.fragment,i),Jt=c(i),yt=r(i,"P",{});var Ni=o(yt);ql=a(Ni,"Ensuite, nous r\xE9instantifions notre mod\xE8le, pour nous assurer que nous ne continuons pas le r\xE9glage fin d\u2019avant, mais que nous repartons du mod\xE8le pr\xE9-entra\xEEn\xE9 de BERT :"),Ni.forEach(s),is=c(i),w(Qt.$$.fragment,i),gs=c(i),us=r(i,"P",{});var Be=o(us);kl=a(Be,"Ensuite, nous aurons besoin d\u2019un optimiseur. Nous allons utiliser le classique "),aa=r(Be,"CODE",{});var Iu=o(aa);en=a(Iu,"AdamW"),Iu.forEach(s),jl=a(Be,", qui est comme "),Xe=r(Be,"CODE",{});var qo=o(Xe);la=a(qo,"Adam"),qo.forEach(s),wl=a(Be,", mais avec un correctif dans la fa\xE7on dont la d\xE9croissance du taux des poids est appliqu\xE9e :"),Be.forEach(s),Sa=c(i),w(sn.$$.fragment,i),zt=c(i),tn=r(i,"P",{});var ko=o(tn);Ro=a(ko,"Une fois que nous avons tous ces objets, nous pouvons les envoyer \xE0 la m\xE9thode "),Yl=r(ko,"CODE",{});var Ru=o(Yl);Jl=a(Ru,"accelerator.prepare()"),Ru.forEach(s),Fo=a(ko," :"),ko.forEach(s),Ir=c(i),w(An.$$.fragment,i),Rr=c(i),w(La.$$.fragment,i),Fr=c(i),Pe=r(i,"P",{});var on=o(Pe);Ql=a(on,"Maintenant que nous avons envoy\xE9 notre "),er=r(on,"CODE",{});var Fu=o(er);Bo=a(Fu,"train_dataloader"),Fu.forEach(s),sr=a(on," \xE0 "),tr=r(on,"CODE",{});var Bu=o(tr);Ho=a(Bu,"accelerator.prepare()"),Bu.forEach(s),nr=a(on,", nous pouvons utiliser sa longueur pour calculer le nombre d\u2019\xE9tapes d\u2019entra\xEEnement. Rappelez-vous que nous devrions toujours faire cela apr\xE8s avoir pr\xE9par\xE9 le "),ar=r(on,"EM",{});var jo=o(ar);Go=a(jo,"dataloader"),jo.forEach(s),Uo=a(on,", car cette m\xE9thode modifiera sa longueur. Nous utilisons un programme lin\xE9aire classique du taux d\u2019apprentissage \xE0 0 :"),on.forEach(s),Ot=c(i),w(Nn.$$.fragment,i),Br=c(i),et=r(i,"P",{});var _a=o(et);lr=a(_a,"Enfin, pour pousser notre mod\xE8le vers le Hub, nous aurons besoin de cr\xE9er un objet "),rr=r(_a,"CODE",{});var Hu=o(rr);Vo=a(Hu,"Repository"),Hu.forEach(s),or=a(_a," dans un dossier de travail. Tout d\u2019abord, connectez-vous \xE0 Hugging Face, si vous n\u2019\xEAtes pas d\xE9j\xE0 connect\xE9. Nous d\xE9terminerons le nom du d\xE9p\xF4t \xE0 partir de l\u2019ID du mod\xE8le que nous voulons donner \xE0 notre mod\xE8le (n\u2019h\xE9sitez pas \xE0 remplacer le "),ir=r(_a,"CODE",{});var wo=o(ir);Wo=a(wo,"repo_name"),wo.forEach(s),Hr=a(_a," par votre propre choix ; il doit juste contenir votre nom d\u2019utilisateur, ce que fait la fonction "),ra=r(_a,"CODE",{});var Gu=o(ra);Xo=a(Gu,"get_full_repo_name()"),Gu.forEach(s),Gr=a(_a,") :"),_a.forEach(s),oa=c(i),w(ia.$$.fragment,i),ua=c(i),w(pa.$$.fragment,i),Pt=c(i),xl=r(i,"P",{});var Uu=o(xl);ur=a(Uu,"Ensuite, nous pouvons cloner ce r\xE9f\xE9rentiel dans un dossier local. S\u2019il existe d\xE9j\xE0, ce dossier local doit \xEAtre un clone existant du r\xE9f\xE9rentiel avec lequel nous travaillons :"),Uu.forEach(s),Ur=c(i),w(Ia.$$.fragment,i),Cl=c(i),nn=r(i,"P",{});var al=o(nn);Zo=a(al,"Nous pouvons maintenant t\xE9l\xE9charger tout ce que nous sauvegardons dans "),yl=r(al,"CODE",{});var ll=o(yl);Ra=a(ll,"output_dir"),ll.forEach(s),Vr=a(al," en appelant la m\xE9thode "),ca=r(al,"CODE",{});var Ti=o(ca);Ko=a(Ti,"repo.push_to_hub()"),Ti.forEach(s),Wr=a(al,". Cela nous aidera \xE0 t\xE9l\xE9charger les mod\xE8les interm\xE9diaires \xE0 la fin de chaque \xE9poque."),al.forEach(s),Tn=c(i),an=r(i,"H3",{class:!0});var De=o(an);Es=r(De,"A",{id:!0,class:!0,href:!0});var Vu=o(Es);ln=r(Vu,"SPAN",{});var xo=o(ln);w(Sn.$$.fragment,xo),xo.forEach(s),Vu.forEach(s),Fa=c(De),pr=r(De,"SPAN",{});var Wu=o(pr);cr=a(Wu,"Boucle d'entra\xEEnement"),Wu.forEach(s),De.forEach(s),Xr=c(i),Dt=r(i,"P",{});var Hl=o(Dt);Ba=a(Hl,"Nous sommes maintenant pr\xEAts \xE0 \xE9crire la boucle d\u2019entra\xEEnement compl\xE8te. Pour simplifier sa partie \xE9valuation, nous d\xE9finissons cette fonction "),zl=r(Hl,"CODE",{});var Co=o(zl);qs=a(Co,"postprocess()"),Co.forEach(s),Yo=a(Hl," qui prend les pr\xE9dictions et les \xE9tiquettes et les convertit en listes de cha\xEEnes de caract\xE8res, comme notre objet "),Ha=r(Hl,"CODE",{});var Xu=o(Ha);Jo=a(Xu,"metric"),Xu.forEach(s),Qo=a(Hl," l\u2019attend :"),Hl.forEach(s),Ga=c(i),w(Ua.$$.fragment,i),Zr=c(i),da=r(i,"P",{});var Zu=o(da);ei=a(Zu,"Ensuite, nous pouvons \xE9crire la boucle d\u2019entra\xEEnement. Apr\xE8s avoir d\xE9fini une barre de progression pour suivre l\u2019\xE9volution de l\u2019entra\xEEnement, la boucle comporte trois parties :"),Zu.forEach(s),Kr=c(i),st=r(i,"UL",{});var ba=o(st);Va=r(ba,"LI",{});var yo=o(Va);si=a(yo,"l\u2019entra\xEEnement proprement dit, qui est l\u2019it\xE9ration classique sur le "),Ol=r(yo,"CODE",{});var Ku=o(Ol);ma=a(Ku,"train_dataloader"),Ku.forEach(s),ti=a(yo,", passage en avant du mod\xE8le, puis passage en arri\xE8re et \xE9tape d\u2019optimisation,"),yo.forEach(s),dr=c(ba),Ts=r(ba,"LI",{});var rt=o(Ts);ni=a(rt,"l\u2019\xE9valuation, dans laquelle il y a une nouveaut\xE9 apr\xE8s avoir obtenu les sorties de notre mod\xE8le sur un lot : puisque deux processus peuvent avoir padd\xE9 les entr\xE9es et les \xE9tiquettes \xE0 des formes diff\xE9rentes, nous devons utiliser "),Pl=r(rt,"CODE",{});var Yu=o(Pl);Wa=a(Yu,"accelerator.pad_across_processes()"),Yu.forEach(s),Yr=a(rt," pour rendre les pr\xE9dictions et les \xE9tiquettes de la m\xEAme forme avant d\u2019appeler la m\xE9thode "),se=r(rt,"CODE",{});var Ju=o(se);ai=a(Ju,"gather()"),Ju.forEach(s),mr=a(rt,". Si nous ne le faisons pas, l\u2019\xE9valuation va soit se tromper, soit se bloquer pour toujours. Ensuite, nous envoyons les r\xE9sultats \xE0 "),fr=r(rt,"CODE",{});var zo=o(fr);li=a(zo,"metric.add_batch()"),zo.forEach(s),hr=a(rt," et appelons "),vr=r(rt,"CODE",{});var Qu=o(vr);ri=a(Qu,"metric.compute()"),Qu.forEach(s),Xa=a(rt," une fois que la boucle d\u2019\xE9valuation est termin\xE9e,"),rt.forEach(s),oi=c(ba),Mt=r(ba,"LI",{});var $a=o(Mt);_r=a($a,"sauvegarde et t\xE9l\xE9chargement, o\xF9 nous sauvegardons d\u2019abord le mod\xE8le et le tokenizer, puis appelons "),br=r($a,"CODE",{});var Oo=o(br);ii=a(Oo,"repo.push_to_hub()"),Oo.forEach(s),$r=a($a,". Remarquez que nous utilisons l\u2019argument "),gr=r($a,"CODE",{});var ep=o(gr);ui=a(ep,"blocking=False"),ep.forEach(s),Er=a($a," pour indiquer \xE0 la biblioth\xE8que \u{1F917} "),qr=r($a,"EM",{});var sp=o(qr);pi=a(sp,"Hub"),sp.forEach(s),Za=a($a," de pousser dans un processus asynchrone. De cette fa\xE7on, l\u2019entra\xEEnement continue normalement et cette (longue) instruction est ex\xE9cut\xE9e en arri\xE8re-plan."),$a.forEach(s),ba.forEach(s),Jr=c(i),Dl=r(i,"P",{});var Si=o(Dl);kr=a(Si,"Voici le code complet de la boucle d\u2019entra\xEEnement :"),Si.forEach(s),Qr=c(i),w(Ka.$$.fragment,i),Ml=c(i),fa=r(i,"P",{});var ga=o(fa);ci=a(ga,"Au cas o\xF9 ce serait la premi\xE8re fois que vous verriez un mod\xE8le enregistr\xE9 avec \u{1F917} "),Ya=r(ga,"EM",{});var Li=o(Ya);di=a(Li,"Accelerate"),Li.forEach(s),mi=a(ga,", prenons un moment pour inspecter les trois lignes de code qui l\u2019accompagnent :"),ga.forEach(s),jr=c(i),w(At.$$.fragment,i),wr=c(i),pe=r(i,"P",{});var Me=o(pe);eo=a(Me,"La premi\xE8re ligne est explicite : elle indique \xE0 tous les processus d\u2019attendre que tout le monde soit \xE0 ce stade avant de continuer. C\u2019est pour s\u2019assurer que nous avons le m\xEAme mod\xE8le dans chaque processus avant de sauvegarder. Ensuite, nous prenons le "),tt=r(Me,"CODE",{});var tp=o(tt);fi=a(tp,"unwrapped_model"),tp.forEach(s),xr=a(Me,", qui est le mod\xE8le de base que nous avons d\xE9fini. La m\xE9thode "),Cr=r(Me,"CODE",{});var Ii=o(Cr);hi=a(Ii,"accelerator.prepare()"),Ii.forEach(s),yr=a(Me," modifie le mod\xE8le pour qu\u2019il fonctionne dans l\u2019entra\xEEnement distribu\xE9, donc il n\u2019aura plus la m\xE9thode "),zr=r(Me,"CODE",{});var Dr=o(zr);vi=a(Dr,"save_pretrained()"),Dr.forEach(s),so=a(Me," ; la m\xE9thode "),Ln=r(Me,"CODE",{});var np=o(Ln);to=a(np,"accelerator.unwrap_model()"),np.forEach(s),Ja=a(Me," annule cette \xE9tape. Enfin, nous appelons "),Al=r(Me,"CODE",{});var Ri=o(Al);ce=a(Ri,"save_pretrained()"),Ri.forEach(s),_i=a(Me," mais nous disons \xE0 cette m\xE9thode d\u2019utiliser "),Qa=r(Me,"CODE",{});var Gl=o(Qa);bi=a(Gl,"accelerator.save()"),Gl.forEach(s),$i=a(Me," au lieu de "),el=r(Me,"CODE",{});var Fi=o(el);gi=a(Fi,"torch.save()"),Fi.forEach(s),Ei=a(Me,"."),Me.forEach(s),Nl=c(i),nt=r(i,"P",{});var Ls=o(nt);qi=a(Ls,"Une fois ceci fait, vous devriez avoir un mod\xE8le qui produit des r\xE9sultats assez similaires \xE0 celui entra\xEEn\xE9 avec le "),sl=r(Ls,"CODE",{});var ap=o(sl);ki=a(ap,"Trainer"),ap.forEach(s),ji=a(Ls,". Vous pouvez v\xE9rifier le mod\xE8le que nous avons form\xE9 en utilisant ce code \xE0 ["),tl=r(Ls,"EM",{});var Mr=o(tl);wi=a(Mr,"huggingface-course/bert-finetuned-ner-accelerate"),Mr.forEach(s),xi=a(Ls,"("),In=r(Ls,"A",{href:!0,rel:!0});var lp=o(In);Ci=a(lp,"https://huggingface.co/huggingface-course/bert-finetuned-ner-accelerate"),lp.forEach(s),yi=a(Ls,"). Et si vous voulez tester des modifications de la boucle d\u2019entra\xEEnement, vous pouvez les impl\xE9menter directement en modifiant le code ci-dessus !"),Ls.forEach(s),this.h()},h(){_(E,"id","dfinir-le-modle"),_(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(E,"href","#dfinir-le-modle"),_(d,"class","relative group"),_(js,"href","/course/fr/chapter3"),_(Ae,"id","finetuning-du-modle"),_(Ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Ae,"href","#finetuning-du-modle"),_(ye,"class","relative group"),_(Ne,"href","https://huggingface.co/huggingface-course"),_(Ne,"rel","nofollow"),_(me,"id","une-boucle-dentranement-personnalise"),_(me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(me,"href","#une-boucle-dentranement-personnalise"),_(Ms,"class","relative group"),_(Dn,"href","/course/fr/chapter3/4"),_(jt,"id","prparer-tout-pour-lentranement"),_(jt,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(jt,"href","#prparer-tout-pour-lentranement"),_(bs,"class","relative group"),_(Es,"id","boucle-dentranement"),_(Es,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Es,"href","#boucle-dentranement"),_(an,"class","relative group"),_(In,"href","https://huggingface.co/huggingface-course/bert-finetuned-ner-accelerate"),_(In,"rel","nofollow")},m(i,v){u(i,d,v),e(d,E),e(E,h),x(q,h,null),e(d,z),e(d,$),e($,k),u(i,O,v),u(i,y,v),e(y,P),e(y,H),e(H,D),e(y,L),e(y,R),e(R,A),e(y,N),e(y,Y),e(Y,G),e(y,X),e(y,J),e(J,K),e(y,Q),u(i,T,v),u(i,F,v),e(F,S),e(F,W),e(W,ae),e(F,ve),e(F,te),e(te,de),e(F,he),u(i,_e,v),x(U,i,v),u(i,B,v),u(i,Z,v),e(Z,we),e(Z,Ie),e(Ie,xe),e(Z,ee),e(Z,le),e(le,Ye),e(Z,ks),u(i,Ce,v),x(Ee,i,v),u(i,Rs,v),u(i,re,v),e(re,cn),e(re,it),e(it,ja),e(re,dn),e(re,js),e(js,wa),e(re,mn),e(re,ut),e(ut,xa),e(re,fn),u(i,hn,v),x(Je,i,v),u(i,pt,v),x(Qe,i,v),u(i,vn,v),x(Re,i,v),u(i,_n,v),u(i,ye,v),e(ye,Ae),e(Ae,es),x(He,es,null),e(ye,Fs),e(ye,ct),e(ct,bn),u(i,$n,v),u(i,ze,v),e(ze,Fn),e(ze,be),e(be,vl),e(ze,Bn),e(ze,qe),e(qe,Nt),e(ze,gn),u(i,ke,v),x(ss,i,v),u(i,En,v),u(i,Bs,v),e(Bs,dt),e(Bs,qn),e(qn,ws),e(Bs,ds),u(i,Tt,v),u(i,ms,v),e(ms,Ca),e(ms,St),e(St,ts),e(ms,Hn),u(i,Oe,v),x(Hs,i,v),u(i,Ge,v),u(i,Fe,v),e(Fe,kn),e(Fe,ns),e(ns,ya),e(Fe,jn),u(i,Lt,v),x(Gs,i,v),u(i,as,v),u(i,ie,v),e(ie,wn),e(ie,xn),e(xn,Gn),e(ie,ls),e(ie,It),e(It,fs),e(ie,Un),e(ie,Ue),e(Ue,Vn),e(ie,xs),e(ie,Ne),e(Ne,mt),e(mt,ft),e(ie,Wn),e(ie,je),e(je,za),e(ie,Rt),e(ie,Ve),e(Ve,Oa),e(ie,ht),u(i,Xn,v),x(vt,i,v),u(i,Us,v),u(i,Vs,v),e(Vs,Pa),e(Vs,_t),e(_t,rs),e(Vs,Cn),u(i,ue,v),x(bt,i,v),u(i,Cs,v),u(i,Ws,v),e(Ws,Da),e(Ws,hs),e(hs,ys),e(Ws,Zn),u(i,Xs,v),u(i,os,v),e(os,We),e(os,yn),e(yn,$t),e(os,Ma),u(i,Kn,v),x(vs,i,v),u(i,Zs,v),u(i,gt,v),e(gt,_s),u(i,Yn,v),x(zs,i,v),u(i,zn,v),u(i,$e,v),e($e,Jn),e($e,ge),e(ge,Et),e($e,Ft),e($e,Os),e(Os,Qn),e($e,Ks),e($e,On),e(On,ea),e($e,Ps),e($e,Bt),e(Bt,qt),e($e,Ht),u(i,Ds,v),u(i,Ys,v),e(Ys,Gt),e(Ys,f),e(f,I),e(Ys,Aa),u(i,kt,v),u(i,Ms,v),e(Ms,me),e(me,Pn),x(fe,Pn,null),e(Ms,_l),e(Ms,Ut),e(Ut,Vt),u(i,Na,v),u(i,As,v),e(As,Wt),e(As,Dn),e(Dn,sa),e(As,Js),u(i,Ta,v),u(i,bs,v),e(bs,jt),e(jt,Xt),x(Qs,Xt,null),e(bs,bl),e(bs,ta),e(ta,Mn),u(i,wt,v),u(i,Te,v),e(Te,Zt),e(Te,xt),e(xt,Ns),e(Te,$s),e(Te,Kt),e(Kt,$l),e(Te,gl),e(Te,Ct),e(Ct,Yt),e(Te,El),u(i,na,v),x(ne,i,v),u(i,Jt,v),u(i,yt,v),e(yt,ql),u(i,is,v),x(Qt,i,v),u(i,gs,v),u(i,us,v),e(us,kl),e(us,aa),e(aa,en),e(us,jl),e(us,Xe),e(Xe,la),e(us,wl),u(i,Sa,v),x(sn,i,v),u(i,zt,v),u(i,tn,v),e(tn,Ro),e(tn,Yl),e(Yl,Jl),e(tn,Fo),u(i,Ir,v),x(An,i,v),u(i,Rr,v),x(La,i,v),u(i,Fr,v),u(i,Pe,v),e(Pe,Ql),e(Pe,er),e(er,Bo),e(Pe,sr),e(Pe,tr),e(tr,Ho),e(Pe,nr),e(Pe,ar),e(ar,Go),e(Pe,Uo),u(i,Ot,v),x(Nn,i,v),u(i,Br,v),u(i,et,v),e(et,lr),e(et,rr),e(rr,Vo),e(et,or),e(et,ir),e(ir,Wo),e(et,Hr),e(et,ra),e(ra,Xo),e(et,Gr),u(i,oa,v),x(ia,i,v),u(i,ua,v),x(pa,i,v),u(i,Pt,v),u(i,xl,v),e(xl,ur),u(i,Ur,v),x(Ia,i,v),u(i,Cl,v),u(i,nn,v),e(nn,Zo),e(nn,yl),e(yl,Ra),e(nn,Vr),e(nn,ca),e(ca,Ko),e(nn,Wr),u(i,Tn,v),u(i,an,v),e(an,Es),e(Es,ln),x(Sn,ln,null),e(an,Fa),e(an,pr),e(pr,cr),u(i,Xr,v),u(i,Dt,v),e(Dt,Ba),e(Dt,zl),e(zl,qs),e(Dt,Yo),e(Dt,Ha),e(Ha,Jo),e(Dt,Qo),u(i,Ga,v),x(Ua,i,v),u(i,Zr,v),u(i,da,v),e(da,ei),u(i,Kr,v),u(i,st,v),e(st,Va),e(Va,si),e(Va,Ol),e(Ol,ma),e(Va,ti),e(st,dr),e(st,Ts),e(Ts,ni),e(Ts,Pl),e(Pl,Wa),e(Ts,Yr),e(Ts,se),e(se,ai),e(Ts,mr),e(Ts,fr),e(fr,li),e(Ts,hr),e(Ts,vr),e(vr,ri),e(Ts,Xa),e(st,oi),e(st,Mt),e(Mt,_r),e(Mt,br),e(br,ii),e(Mt,$r),e(Mt,gr),e(gr,ui),e(Mt,Er),e(Mt,qr),e(qr,pi),e(Mt,Za),u(i,Jr,v),u(i,Dl,v),e(Dl,kr),u(i,Qr,v),x(Ka,i,v),u(i,Ml,v),u(i,fa,v),e(fa,ci),e(fa,Ya),e(Ya,di),e(fa,mi),u(i,jr,v),x(At,i,v),u(i,wr,v),u(i,pe,v),e(pe,eo),e(pe,tt),e(tt,fi),e(pe,xr),e(pe,Cr),e(Cr,hi),e(pe,yr),e(pe,zr),e(zr,vi),e(pe,so),e(pe,Ln),e(Ln,to),e(pe,Ja),e(pe,Al),e(Al,ce),e(pe,_i),e(pe,Qa),e(Qa,bi),e(pe,$i),e(pe,el),e(el,gi),e(pe,Ei),u(i,Nl,v),u(i,nt,v),e(nt,qi),e(nt,sl),e(sl,ki),e(nt,ji),e(nt,tl),e(tl,wi),e(nt,xi),e(nt,In),e(In,Ci),e(nt,yi),Tl=!0},i(i){Tl||(b(q.$$.fragment,i),b(U.$$.fragment,i),b(Ee.$$.fragment,i),b(Je.$$.fragment,i),b(Qe.$$.fragment,i),b(Re.$$.fragment,i),b(He.$$.fragment,i),b(ss.$$.fragment,i),b(Hs.$$.fragment,i),b(Gs.$$.fragment,i),b(vt.$$.fragment,i),b(bt.$$.fragment,i),b(vs.$$.fragment,i),b(zs.$$.fragment,i),b(fe.$$.fragment,i),b(Qs.$$.fragment,i),b(ne.$$.fragment,i),b(Qt.$$.fragment,i),b(sn.$$.fragment,i),b(An.$$.fragment,i),b(La.$$.fragment,i),b(Nn.$$.fragment,i),b(ia.$$.fragment,i),b(pa.$$.fragment,i),b(Ia.$$.fragment,i),b(Sn.$$.fragment,i),b(Ua.$$.fragment,i),b(Ka.$$.fragment,i),b(At.$$.fragment,i),Tl=!0)},o(i){g(q.$$.fragment,i),g(U.$$.fragment,i),g(Ee.$$.fragment,i),g(Je.$$.fragment,i),g(Qe.$$.fragment,i),g(Re.$$.fragment,i),g(He.$$.fragment,i),g(ss.$$.fragment,i),g(Hs.$$.fragment,i),g(Gs.$$.fragment,i),g(vt.$$.fragment,i),g(bt.$$.fragment,i),g(vs.$$.fragment,i),g(zs.$$.fragment,i),g(fe.$$.fragment,i),g(Qs.$$.fragment,i),g(ne.$$.fragment,i),g(Qt.$$.fragment,i),g(sn.$$.fragment,i),g(An.$$.fragment,i),g(La.$$.fragment,i),g(Nn.$$.fragment,i),g(ia.$$.fragment,i),g(pa.$$.fragment,i),g(Ia.$$.fragment,i),g(Sn.$$.fragment,i),g(Ua.$$.fragment,i),g(Ka.$$.fragment,i),g(At.$$.fragment,i),Tl=!1},d(i){i&&s(d),C(q),i&&s(O),i&&s(y),i&&s(T),i&&s(F),i&&s(_e),C(U,i),i&&s(B),i&&s(Z),i&&s(Ce),C(Ee,i),i&&s(Rs),i&&s(re),i&&s(hn),C(Je,i),i&&s(pt),C(Qe,i),i&&s(vn),C(Re,i),i&&s(_n),i&&s(ye),C(He),i&&s($n),i&&s(ze),i&&s(ke),C(ss,i),i&&s(En),i&&s(Bs),i&&s(Tt),i&&s(ms),i&&s(Oe),C(Hs,i),i&&s(Ge),i&&s(Fe),i&&s(Lt),C(Gs,i),i&&s(as),i&&s(ie),i&&s(Xn),C(vt,i),i&&s(Us),i&&s(Vs),i&&s(ue),C(bt,i),i&&s(Cs),i&&s(Ws),i&&s(Xs),i&&s(os),i&&s(Kn),C(vs,i),i&&s(Zs),i&&s(gt),i&&s(Yn),C(zs,i),i&&s(zn),i&&s($e),i&&s(Ds),i&&s(Ys),i&&s(kt),i&&s(Ms),C(fe),i&&s(Na),i&&s(As),i&&s(Ta),i&&s(bs),C(Qs),i&&s(wt),i&&s(Te),i&&s(na),C(ne,i),i&&s(Jt),i&&s(yt),i&&s(is),C(Qt,i),i&&s(gs),i&&s(us),i&&s(Sa),C(sn,i),i&&s(zt),i&&s(tn),i&&s(Ir),C(An,i),i&&s(Rr),C(La,i),i&&s(Fr),i&&s(Pe),i&&s(Ot),C(Nn,i),i&&s(Br),i&&s(et),i&&s(oa),C(ia,i),i&&s(ua),C(pa,i),i&&s(Pt),i&&s(xl),i&&s(Ur),C(Ia,i),i&&s(Cl),i&&s(nn),i&&s(Tn),i&&s(an),C(Sn),i&&s(Xr),i&&s(Dt),i&&s(Ga),C(Ua,i),i&&s(Zr),i&&s(da),i&&s(Kr),i&&s(st),i&&s(Jr),i&&s(Dl),i&&s(Qr),C(Ka,i),i&&s(Ml),i&&s(fa),i&&s(jr),C(At,i),i&&s(wr),i&&s(pe),i&&s(Nl),i&&s(nt)}}}function Ph(V){let d,E,h,q,z;return{c(){d=l("p"),E=n("\u26A0\uFE0F Si vous avez un mod\xE8le avec le mauvais nombre d\u2019\xE9tiquettes, vous obtiendrez une erreur obscure lors de l\u2019appel de la m\xE9thode "),h=l("code"),q=n("Trainer.train()"),z=n(" plus tard (quelque chose comme \u201CCUDA error : device-side assert triggered\u201D). C\u2019est la premi\xE8re cause de bogues signal\xE9s par les utilisateurs pour de telles erreurs, donc assurez-vous de faire cette v\xE9rification pour confirmer que vous avez le nombre d\u2019\xE9tiquettes attendu.")},l($){d=r($,"P",{});var k=o(d);E=a(k,"\u26A0\uFE0F Si vous avez un mod\xE8le avec le mauvais nombre d\u2019\xE9tiquettes, vous obtiendrez une erreur obscure lors de l\u2019appel de la m\xE9thode "),h=r(k,"CODE",{});var O=o(h);q=a(O,"Trainer.train()"),O.forEach(s),z=a(k," plus tard (quelque chose comme \u201CCUDA error : device-side assert triggered\u201D). C\u2019est la premi\xE8re cause de bogues signal\xE9s par les utilisateurs pour de telles erreurs, donc assurez-vous de faire cette v\xE9rification pour confirmer que vous avez le nombre d\u2019\xE9tiquettes attendu."),k.forEach(s)},m($,k){u($,d,k),e(d,E),e(d,h),e(h,q),e(d,z)},d($){$&&s(d)}}}function Dh(V){let d,E,h,q,z;return{c(){d=l("p"),E=n("\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de la d\xE9finition de votre "),h=l("code"),q=n("Trainer"),z=n(" et devrez d\xE9finir un nouveau nom.")},l($){d=r($,"P",{});var k=o(d);E=a(k,"\u{1F4A1} Si le r\xE9pertoire de sortie que vous utilisez existe d\xE9j\xE0, il doit \xEAtre un clone local du d\xE9p\xF4t vers lequel vous voulez pousser. S\u2019il ne l\u2019est pas, vous obtiendrez une erreur lors de la d\xE9finition de votre "),h=r(k,"CODE",{});var O=o(h);q=a(O,"Trainer"),O.forEach(s),z=a(k," et devrez d\xE9finir un nouveau nom."),k.forEach(s)},m($,k){u($,d,k),e(d,E),e(d,h),e(h,q),e(d,z)},d($){$&&s(d)}}}function Mh(V){let d,E,h,q,z;return{c(){d=l("p"),E=n("\u{1F6A8} Si vous vous entra\xEEnez sur un TPU, vous devrez d\xE9placer tout le code \xE0 partir de la cellule ci-dessus dans une fonction d\u2019entra\xEEnement d\xE9di\xE9e. Voir le "),h=l("a"),q=n("Chapitre 3"),z=n(" pour plus de d\xE9tails."),this.h()},l($){d=r($,"P",{});var k=o(d);E=a(k,"\u{1F6A8} Si vous vous entra\xEEnez sur un TPU, vous devrez d\xE9placer tout le code \xE0 partir de la cellule ci-dessus dans une fonction d\u2019entra\xEEnement d\xE9di\xE9e. Voir le "),h=r(k,"A",{href:!0});var O=o(h);q=a(O,"Chapitre 3"),O.forEach(s),z=a(k," pour plus de d\xE9tails."),k.forEach(s),this.h()},h(){_(h,"href","/course/fr/chapter3")},m($,k){u($,d,k),e(d,E),e(d,h),e(h,q),e(d,z)},d($){$&&s(d)}}}function Ah(V){let d,E,h,q,z,$,k,O,y,P,H,D,L,R,A,N,Y,G,X,J,K,Q,T,F,S,W,ae,ve,te,de,he,_e,U,B,Z,we,Ie,xe,ee,le,Ye,ks,Ce,Ee,Rs,re,cn,it,ja,dn,js,wa,mn,ut,xa,fn,hn,Je,pt,Qe,vn,Re,_n,ye,Ae,es,He,Fs,ct,bn,$n,ze,Fn,be,vl,Bn,qe,Nt,gn,ke,ss,En,Bs,dt,qn,ws,ds,Tt,ms,Ca,St,ts,Hn,Oe,Hs,Ge,Fe,kn,ns,ya,jn,Lt,Gs,as,ie,wn,xn,Gn,ls,It,fs,Un,Ue,Vn,xs,Ne,mt,ft,Wn,je,za,Rt,Ve,Oa,ht,Xn,vt,Us,Vs,Pa,_t,rs,Cn,ue,bt,Cs,Ws,Da,hs,ys,Zn,Xs,os,We,yn,$t,Ma,Kn,vs,Zs,gt,_s,Yn,zs,zn,$e,Jn,ge,Et,Ft,Os,Qn,Ks,On,ea,Ps,Bt,qt,Ht,Ds,Ys,Gt,f,I,Aa,kt,Ms,me,Pn,fe,_l,Ut,Vt,Na,As,Wt,Dn,sa,Js,Ta,bs,jt,Xt,Qs,bl,ta,Mn,wt,Te,Zt,xt,Ns,$s,Kt,$l,gl,Ct,Yt,El,na,ne,Jt,yt,ql,is,Qt,gs,us,kl,aa,en,jl,Xe,la,wl,Sa,sn,zt,tn,Ro,Yl,Jl,Fo,Ir,An,Rr,La,Fr,Pe,Ql,er,Bo,sr,tr,Ho,nr,ar,Go,Uo,Ot,Nn,Br,et,lr,rr,Vo,or,ir,Wo,Hr,ra,Xo,Gr,oa,ia,ua,pa,Pt,xl,ur,Ur,Ia,Cl,nn,Zo,yl,Ra,Vr,ca,Ko,Wr,Tn,an,Es,ln,Sn,Fa,pr,cr,Xr,Dt,Ba,zl,qs,Yo,Ha,Jo,Qo,Ga,Ua,Zr,da,ei,Kr,st,Va,si,Ol,ma,ti,dr,Ts,ni,Pl,Wa,Yr,se,ai,mr,fr,li,hr,vr,ri,Xa,oi,Mt,_r,br,ii,$r,gr,ui,Er,qr,pi,Za,Jr,Dl,kr,Qr,Ka,Ml,fa,ci,Ya,di,mi,jr,At,wr,pe,eo,tt,fi,xr,Cr,hi,yr,zr,vi,so,Ln,to,Ja,Al,ce,_i,Qa,bi,$i,el,gi,Ei,Nl,nt,qi,sl,ki,ji,tl,wi,xi,In,Ci,yi,Tl,i,v,no,fu,hu,at,vu,_u,zi,Ss,Sl,ao,bu,Ll,lo,$u,ha,ro,gu,Eu,nl,qu,ku,Oi,rn,Pi,Il,Or,oe,oo,io,uo,ju,Ze,wu,xu,po,Cu,yu,co,zu,mo,fo,ho,Ou,Rl,Pu,Du,lt,Mu,Au,vo,Nu,_o,bo,$o,Tu,go,Su,Eo,Di,va,Mi,Pr,Lu,Rn,Fl,Ai,Bl,Ni,Be,Iu,qo,ko,Ru,on,Fu,Bu,jo,_a,Hu,wo,Gu,Uu,al,ll,Ti,De,Vu,xo,Wu,Hl,Co,Xu,Zu,ba,yo,Ku,rt,Yu,Ju,zo,Qu,$a,Oo,ep,sp,Si,ga,Li,Me,tp,Ii,Dr,np,Ri,Gl,Fi,Ls,ap,Mr,lp,Oc,Wp,rl,ol,rp,Ar,Po,Op,Bi,Pc,Pp,Dc,Xp,un,Mc,Dp,Ac,Nc,op,Tc,Sc,Mp,Lc,Ic,Ap,Rc,Fc,Zp,Ea,Bc,Hi,Np,Hc,Gc,Tp,Uc,Vc,Sp,Wc,Xc,Kp,il,ul,ip,up,Zc,Yp,Gi,Jp,Ui,Qp,pp,Kc,ec,Vi,sc,Wi,tc,pl,cl,cp,dp,Nr,Do,Lp,Xi,Yc,Ip,Jc,nc,dl,ml,mp,Zi,ac,fp,Qc,lc,Ki,rc,Yi,oc,hp,ed,ic,Ji,uc,vp,sd,pc,Qi,cc,fl,hl,_p,bp,Tr,Mo,Rp,eu,td,Fp,nd,dc,qa,ad,Bp,ld,rd,Hp,od,id,Gp,ud,pd,mc,su,fc,tu,hc,$p,cd,vc;h=new mh({props:{fw:V[0]}}),O=new ot({});const fd=[hh,fh],nu=[];function hd(t,m){return t[0]==="pt"?0:1}L=hd(V),R=nu[L]=fd[L](V),es=new ah({props:{id:"wVHdVlPScxA"}}),ns=new ot({}),Ue=new Io({props:{$$slots:{default:[vh]},$$scope:{ctx:V}}}),ft=new ot({}),rs=new M({props:{code:`from datasets import load_dataset

raw_datasets = load_dataset("conll2003")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

raw_datasets = load_dataset(<span class="hljs-string">&quot;conll2003&quot;</span>)`}}),ys=new M({props:{code:"raw_datasets",highlighted:"raw_datasets"}}),Xs=new M({props:{code:`DatasetDict({
    train: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 14041
    })
    validation: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 3250
    })
    test: Dataset({
        features: ['chunk_tags', 'id', 'ner_tags', 'pos_tags', 'tokens'],
        num_rows: 3453
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],
        num_rows: <span class="hljs-number">14041</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],
        num_rows: <span class="hljs-number">3250</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;chunk_tags&#x27;</span>, <span class="hljs-string">&#x27;id&#x27;</span>, <span class="hljs-string">&#x27;ner_tags&#x27;</span>, <span class="hljs-string">&#x27;pos_tags&#x27;</span>, <span class="hljs-string">&#x27;tokens&#x27;</span>],
        num_rows: <span class="hljs-number">3453</span>
    })
})`}}),Et=new M({props:{code:'raw_datasets["train"][0]["tokens"]',highlighted:'raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;tokens&quot;</span>]'}}),Os=new M({props:{code:"['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']",highlighted:'[<span class="hljs-string">&#x27;EU&#x27;</span>, <span class="hljs-string">&#x27;rejects&#x27;</span>, <span class="hljs-string">&#x27;German&#x27;</span>, <span class="hljs-string">&#x27;call&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;boycott&#x27;</span>, <span class="hljs-string">&#x27;British&#x27;</span>, <span class="hljs-string">&#x27;lamb&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>]'}}),Ps=new M({props:{code:'raw_datasets["train"][0]["ner_tags"]',highlighted:'raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]'}}),qt=new M({props:{code:"[3, 0, 7, 0, 0, 0, 7, 0, 0]",highlighted:'[<span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]'}}),kt=new M({props:{code:`ner_feature = raw_datasets["train"].features["ner_tags"]
ner_feature`,highlighted:`ner_feature = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].features[<span class="hljs-string">&quot;ner_tags&quot;</span>]
ner_feature`}}),me=new M({props:{code:"Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], names_file=None, id=None), length=-1, id=None)",highlighted:'<span class="hljs-type">Sequence</span>(feature=ClassLabel(num_classes=<span class="hljs-number">9</span>, names=[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;I-PER&#x27;</span>, <span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;I-ORG&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;I-LOC&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>], names_file=<span class="hljs-literal">None</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>), length=-<span class="hljs-number">1</span>, <span class="hljs-built_in">id</span>=<span class="hljs-literal">None</span>)'}}),wt=new M({props:{code:`label_names = ner_feature.feature.names
label_names`,highlighted:`label_names = ner_feature.feature.names
label_names`}}),Zt=new M({props:{code:"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']",highlighted:'[<span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-PER&#x27;</span>, <span class="hljs-string">&#x27;I-PER&#x27;</span>, <span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;I-ORG&#x27;</span>, <span class="hljs-string">&#x27;B-LOC&#x27;</span>, <span class="hljs-string">&#x27;I-LOC&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;I-MISC&#x27;</span>]'}}),oa=new M({props:{code:`words = raw_datasets["train"][0]["tokens"]
labels = raw_datasets["train"][0]["ner_tags"]
line1 = ""
line2 = ""
for word, label in zip(words, labels):
    full_label = label_names[label]
    max_length = max(len(word), len(full_label))
    line1 += word + " " * (max_length - len(word) + 1)
    line2 += full_label + " " * (max_length - len(full_label) + 1)

print(line1)
print(line2)`,highlighted:`words = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;tokens&quot;</span>]
labels = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]
line1 = <span class="hljs-string">&quot;&quot;</span>
line2 = <span class="hljs-string">&quot;&quot;</span>
<span class="hljs-keyword">for</span> word, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(words, labels):
    full_label = label_names[label]
    max_length = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">len</span>(word), <span class="hljs-built_in">len</span>(full_label))
    line1 += word + <span class="hljs-string">&quot; &quot;</span> * (max_length - <span class="hljs-built_in">len</span>(word) + <span class="hljs-number">1</span>)
    line2 += full_label + <span class="hljs-string">&quot; &quot;</span> * (max_length - <span class="hljs-built_in">len</span>(full_label) + <span class="hljs-number">1</span>)

<span class="hljs-built_in">print</span>(line1)
<span class="hljs-built_in">print</span>(line2)`}}),ua=new M({props:{code:`'EU    rejects German call to boycott British lamb .'
'B-ORG O       B-MISC O    O  O       B-MISC  O    O'`,highlighted:`<span class="hljs-string">&#x27;EU    rejects German call to boycott British lamb .&#x27;</span>
<span class="hljs-string">&#x27;B-ORG O       B-MISC O    O  O       B-MISC  O    O&#x27;</span>`}}),Ra=new M({props:{code:`'Germany \\'s representative to the European Union \\'s veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .'
'B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O'`,highlighted:`<span class="hljs-string">&#x27;Germany \\&#x27;s representative to the European Union \\&#x27;s veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .&#x27;</span>
<span class="hljs-string">&#x27;B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O&#x27;</span>`}}),Tn=new Io({props:{$$slots:{default:[_h]},$$scope:{ctx:V}}}),Fa=new ot({}),Ba=new ah({props:{id:"iY2AZYdZAr0"}}),Wa=new M({props:{code:`from transformers import AutoTokenizer

model_checkpoint = "bert-base-cased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

model_checkpoint = <span class="hljs-string">&quot;bert-base-cased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)`}}),At=new M({props:{code:"tokenizer.is_fast",highlighted:"tokenizer.is_fast"}}),pe=new M({props:{code:"True",highlighted:'<span class="hljs-literal">True</span>'}}),Ln=new M({props:{code:`inputs = tokenizer(raw_datasets["train"][0]["tokens"], is_split_into_words=True)
inputs.tokens()`,highlighted:`inputs = tokenizer(raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;tokens&quot;</span>], is_split_into_words=<span class="hljs-literal">True</span>)
inputs.tokens()`}}),Ja=new M({props:{code:"['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]']",highlighted:'[<span class="hljs-string">&#x27;[CLS]&#x27;</span>, <span class="hljs-string">&#x27;EU&#x27;</span>, <span class="hljs-string">&#x27;rejects&#x27;</span>, <span class="hljs-string">&#x27;German&#x27;</span>, <span class="hljs-string">&#x27;call&#x27;</span>, <span class="hljs-string">&#x27;to&#x27;</span>, <span class="hljs-string">&#x27;boycott&#x27;</span>, <span class="hljs-string">&#x27;British&#x27;</span>, <span class="hljs-string">&#x27;la&#x27;</span>, <span class="hljs-string">&#x27;##mb&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>]'}}),rn=new M({props:{code:"inputs.word_ids()",highlighted:"inputs.word_ids()"}}),Il=new M({props:{code:"[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]",highlighted:'[<span class="hljs-literal">None</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-literal">None</span>]'}}),va=new M({props:{code:`def align_labels_with_tokens(labels, word_ids):
    new_labels = []
    current_word = None
    for word_id in word_ids:
        if word_id != current_word:
            # Start of a new word!
            current_word = word_id
            label = -100 if word_id is None else labels[word_id]
            new_labels.append(label)
        elif word_id is None:
            # Special token
            new_labels.append(-100)
        else:
            # Same word as previous token
            label = labels[word_id]
            # If the label is B-XXX we change it to I-XXX
            if label % 2 == 1:
                label += 1
            new_labels.append(label)

    return new_labels`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">align_labels_with_tokens</span>(<span class="hljs-params">labels, word_ids</span>):
    new_labels = []
    current_word = <span class="hljs-literal">None</span>
    <span class="hljs-keyword">for</span> word_id <span class="hljs-keyword">in</span> word_ids:
        <span class="hljs-keyword">if</span> word_id != current_word:
            <span class="hljs-comment"># Start of a new word!</span>
            current_word = word_id
            label = -<span class="hljs-number">100</span> <span class="hljs-keyword">if</span> word_id <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> labels[word_id]
            new_labels.append(label)
        <span class="hljs-keyword">elif</span> word_id <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
            <span class="hljs-comment"># Special token</span>
            new_labels.append(-<span class="hljs-number">100</span>)
        <span class="hljs-keyword">else</span>:
            <span class="hljs-comment"># Same word as previous token</span>
            label = labels[word_id]
            <span class="hljs-comment"># If the label is B-XXX we change it to I-XXX</span>
            <span class="hljs-keyword">if</span> label % <span class="hljs-number">2</span> == <span class="hljs-number">1</span>:
                label += <span class="hljs-number">1</span>
            new_labels.append(label)

    <span class="hljs-keyword">return</span> new_labels`}}),Fl=new M({props:{code:`labels = raw_datasets["train"][0]["ner_tags"]
word_ids = inputs.word_ids()
print(labels)
print(align_labels_with_tokens(labels, word_ids))`,highlighted:`labels = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]
word_ids = inputs.word_ids()
<span class="hljs-built_in">print</span>(labels)
<span class="hljs-built_in">print</span>(align_labels_with_tokens(labels, word_ids))`}}),Bl=new M({props:{code:`[3, 0, 7, 0, 0, 0, 7, 0, 0]
[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]`,highlighted:`[<span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]
[-<span class="hljs-number">100</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">100</span>]`}}),ll=new Io({props:{$$slots:{default:[bh]},$$scope:{ctx:V}}}),ga=new M({props:{code:`def tokenize_and_align_labels(examples):
    tokenized_inputs = tokenizer(
        examples["tokens"], truncation=True, is_split_into_words=True
    )
    all_labels = examples["ner_tags"]
    new_labels = []
    for i, labels in enumerate(all_labels):
        word_ids = tokenized_inputs.word_ids(i)
        new_labels.append(align_labels_with_tokens(labels, word_ids))

    tokenized_inputs["labels"] = new_labels
    return tokenized_inputs`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_and_align_labels</span>(<span class="hljs-params">examples</span>):
    tokenized_inputs = tokenizer(
        examples[<span class="hljs-string">&quot;tokens&quot;</span>], truncation=<span class="hljs-literal">True</span>, is_split_into_words=<span class="hljs-literal">True</span>
    )
    all_labels = examples[<span class="hljs-string">&quot;ner_tags&quot;</span>]
    new_labels = []
    <span class="hljs-keyword">for</span> i, labels <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(all_labels):
        word_ids = tokenized_inputs.word_ids(i)
        new_labels.append(align_labels_with_tokens(labels, word_ids))

    tokenized_inputs[<span class="hljs-string">&quot;labels&quot;</span>] = new_labels
    <span class="hljs-keyword">return</span> tokenized_inputs`}}),Gl=new M({props:{code:`tokenized_datasets = raw_datasets.map(
    tokenize_and_align_labels,
    batched=True,
    remove_columns=raw_datasets["train"].column_names,
)`,highlighted:`tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(
    tokenize_and_align_labels,
    batched=<span class="hljs-literal">True</span>,
    remove_columns=raw_datasets[<span class="hljs-string">&quot;train&quot;</span>].column_names,
)`}});const vd=[gh,$h],au=[];function _d(t,m){return t[0]==="pt"?0:1}rl=_d(V),ol=au[rl]=vd[rl](V),Bi=new ot({});const bd=[qh,Eh],lu=[];function $d(t,m){return t[0]==="pt"?0:1}il=$d(V),ul=lu[il]=bd[il](V),Gi=new M({props:{code:`batch = data_collator([tokenized_datasets["train"][i] for i in range(2)])
batch["labels"]`,highlighted:`batch = data_collator([tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>)])
batch[<span class="hljs-string">&quot;labels&quot;</span>]`}}),Ui=new M({props:{code:`tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],
        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])`,highlighted:`tensor([[-<span class="hljs-number">100</span>,    <span class="hljs-number">3</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">7</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">7</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">0</span>,    <span class="hljs-number">0</span>, -<span class="hljs-number">100</span>],
        [-<span class="hljs-number">100</span>,    <span class="hljs-number">1</span>,    <span class="hljs-number">2</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>, -<span class="hljs-number">100</span>]])`}}),Vi=new M({props:{code:`for i in range(2):
    print(tokenized_datasets["train"][i]["labels"])`,highlighted:`<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):
    <span class="hljs-built_in">print</span>(tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][i][<span class="hljs-string">&quot;labels&quot;</span>])`}}),Wi=new M({props:{code:`[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]
[-100, 1, 2, -100]`,highlighted:`[-<span class="hljs-number">100</span>, <span class="hljs-number">3</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, -<span class="hljs-number">100</span>]
[-<span class="hljs-number">100</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, -<span class="hljs-number">100</span>]`}});const gd=[jh,kh],ru=[];function Ed(t,m){return t[0]==="pt"?0:1}pl=Ed(V),cl=ru[pl]=gd[pl](V);let ps=V[0]==="tf"&&lh(V);Xi=new ot({});const qd=[yh,Ch],ou=[];function kd(t,m){return t[0]==="pt"?0:1}dl=kd(V),ml=ou[dl]=qd[dl](V),Zi=new M({props:{code:`from datasets import load_metric

metric = load_metric("seqeval")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric

metric = load_metric(<span class="hljs-string">&quot;seqeval&quot;</span>)`}}),Ki=new M({props:{code:`labels = raw_datasets["train"][0]["ner_tags"]
labels = [label_names[i] for i in labels]
labels`,highlighted:`labels = raw_datasets[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;ner_tags&quot;</span>]
labels = [label_names[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> labels]
labels`}}),Yi=new M({props:{code:"['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']",highlighted:'[<span class="hljs-string">&#x27;B-ORG&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;B-MISC&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>]'}}),Ji=new M({props:{code:`predictions = labels.copy()
predictions[2] = "O"
metric.compute(predictions=[predictions], references=[labels])`,highlighted:`predictions = labels.copy()
predictions[<span class="hljs-number">2</span>] = <span class="hljs-string">&quot;O&quot;</span>
metric.compute(predictions=[predictions], references=[labels])`}}),Qi=new M({props:{code:`{'MISC': {'precision': 1.0, 'recall': 0.5, 'f1': 0.67, 'number': 2},
 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},
 'overall_precision': 1.0,
 'overall_recall': 0.67,
 'overall_f1': 0.8,
 'overall_accuracy': 0.89}`,highlighted:`{<span class="hljs-string">&#x27;MISC&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">1.0</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">0.5</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.67</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">2</span>},
 <span class="hljs-string">&#x27;ORG&#x27;</span>: {<span class="hljs-string">&#x27;precision&#x27;</span>: <span class="hljs-number">1.0</span>, <span class="hljs-string">&#x27;recall&#x27;</span>: <span class="hljs-number">1.0</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">1.0</span>, <span class="hljs-string">&#x27;number&#x27;</span>: <span class="hljs-number">1</span>},
 <span class="hljs-string">&#x27;overall_precision&#x27;</span>: <span class="hljs-number">1.0</span>,
 <span class="hljs-string">&#x27;overall_recall&#x27;</span>: <span class="hljs-number">0.67</span>,
 <span class="hljs-string">&#x27;overall_f1&#x27;</span>: <span class="hljs-number">0.8</span>,
 <span class="hljs-string">&#x27;overall_accuracy&#x27;</span>: <span class="hljs-number">0.89</span>}`}});const jd=[Oh,zh],iu=[];function wd(t,m){return t[0]==="pt"?0:1}fl=wd(V),hl=iu[fl]=jd[fl](V);let cs=V[0]==="pt"&&rh(V);return eu=new ot({}),su=new M({props:{code:`from transformers import pipeline

# Remplacez ceci par votre propre checkpoint
model_checkpoint = "huggingface-course/bert-finetuned-ner"
token_classifier = pipeline(
    "token-classification", model=model_checkpoint, aggregation_strategy="simple"
)
token_classifier("My name is Sylvain and I work at Hugging Face in Brooklyn.")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-comment"># Remplacez ceci par votre propre checkpoint</span>
model_checkpoint = <span class="hljs-string">&quot;huggingface-course/bert-finetuned-ner&quot;</span>
token_classifier = pipeline(
    <span class="hljs-string">&quot;token-classification&quot;</span>, model=model_checkpoint, aggregation_strategy=<span class="hljs-string">&quot;simple&quot;</span>
)
token_classifier(<span class="hljs-string">&quot;My name is Sylvain and I work at Hugging Face in Brooklyn.&quot;</span>)`}}),tu=new M({props:{code:`[{'entity_group': 'PER', 'score': 0.9988506, 'word': 'Sylvain', 'start': 11, 'end': 18},
 {'entity_group': 'ORG', 'score': 0.9647625, 'word': 'Hugging Face', 'start': 33, 'end': 45},
 {'entity_group': 'LOC', 'score': 0.9986118, 'word': 'Brooklyn', 'start': 49, 'end': 57}]`,highlighted:`[{<span class="hljs-string">&#x27;entity_group&#x27;</span>: <span class="hljs-string">&#x27;PER&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9988506</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;Sylvain&#x27;</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">11</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">18</span>},
 {<span class="hljs-string">&#x27;entity_group&#x27;</span>: <span class="hljs-string">&#x27;ORG&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9647625</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;Hugging Face&#x27;</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">33</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">45</span>},
 {<span class="hljs-string">&#x27;entity_group&#x27;</span>: <span class="hljs-string">&#x27;LOC&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9986118</span>, <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;Brooklyn&#x27;</span>, <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">49</span>, <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">57</span>}]`}}),{c(){d=l("meta"),E=p(),j(h.$$.fragment),q=p(),z=l("h1"),$=l("a"),k=l("span"),j(O.$$.fragment),y=p(),P=l("span"),H=n("Classification de *tokens*"),D=p(),R.c(),A=p(),N=l("p"),Y=n("La premi\xE8re application que nous allons explorer est la classification de "),G=l("em"),X=n("tokens"),J=n(". Cette t\xE2che g\xE9n\xE9rique englobe tous les probl\xE8mes qui peuvent \xEAtre formul\xE9s comme \u201Cl\u2019attribution d\u2019une \xE9tiquette \xE0 chaque "),K=l("em"),Q=n("token"),T=n(" dans une phrase\u201D, tels que :"),F=p(),S=l("ul"),W=l("li"),ae=l("strong"),ve=n("reconnaissance d\u2019entit\xE9s nomm\xE9es (NER)"),te=n(" : trouver les entit\xE9s (telles que des personnes, des lieux ou des organisations) dans une phrase. Cela peut \xEAtre formul\xE9 comme l\u2019attribution d\u2019une \xE9tiquette \xE0 chaque "),de=l("em"),he=n("token"),_e=n(" en ayant une classe par entit\xE9 et une classe pour \u201Caucune entit\xE9\u201D."),U=p(),B=l("li"),Z=l("strong"),we=n("part-of-speech tagging (POS)"),Ie=n(" : marquer chaque mot dans une phrase comme correspondant \xE0 une partie particuli\xE8re du discours (comme un nom, un verbe, un adjectif, etc.)."),xe=p(),ee=l("li"),le=l("strong"),Ye=l("em"),ks=n("chunking"),Ce=n(" : trouver les "),Ee=l("em"),Rs=n("tokens"),re=n(" qui appartiennent \xE0 la m\xEAme entit\xE9. Cette t\xE2che (qui peut \xEAtre combin\xE9e avec le POS ou la NER) peut \xEAtre formul\xE9e comme l\u2019attribution d\u2019une \xE9tiquette (habituellement "),cn=l("code"),it=n("B-"),ja=n(") \xE0 tous les "),dn=l("em"),js=n("tokens"),wa=n(" qui sont au d\xE9but d\u2019un morceau, une autre \xE9tiquette (habituellement "),mn=l("code"),ut=n("I-"),xa=n(") aux "),fn=l("em"),hn=n("tokens"),Je=n(" qui sont \xE0 l\u2019int\xE9rieur d\u2019un morceau, et une troisi\xE8me \xE9tiquette (habituellement "),pt=l("code"),Qe=n("O"),vn=n(") aux "),Re=l("em"),_n=n("tokens"),ye=n(" qui n\u2019appartiennent \xE0 aucun morceau."),Ae=p(),j(es.$$.fragment),He=p(),Fs=l("p"),ct=n("Bien s\xFBr, il existe de nombreux autres types de probl\xE8mes de classification de "),bn=l("em"),$n=n("tokens"),ze=n(" ; ce ne sont l\xE0 que quelques exemples repr\xE9sentatifs. Dans cette section, nous allons affiner un mod\xE8le (BERT) sur une t\xE2che NER, qui sera alors capable de calculer des pr\xE9dictions comme celle-ci :"),Fn=p(),be=l("iframe"),Bn=p(),qe=l("iframe"),gn=p(),ke=l("a"),ss=l("img"),Bs=p(),dt=l("img"),ws=p(),ds=l("p"),Tt=n("Vous pouvez trouver le mod\xE8le que nous allons entra\xEEner et t\xE9l\xE9charger sur le "),ms=l("em"),Ca=n("Hub"),St=n(" et v\xE9rifier ses pr\xE9dictions "),ts=l("a"),Hn=n("ici"),Oe=n("."),Hs=p(),Ge=l("h2"),Fe=l("a"),kn=l("span"),j(ns.$$.fragment),ya=p(),jn=l("span"),Lt=n("Pr\xE9paration des donn\xE9es"),Gs=p(),as=l("p"),ie=n("Tout d\u2019abord, nous avons besoin d\u2019un jeu de donn\xE9es adapt\xE9 \xE0 la classification des "),wn=l("em"),xn=n("tokens"),Gn=n(". Dans cette section, nous utiliserons le jeu de donn\xE9es "),ls=l("a"),It=n("CoNLL-2003"),fs=n(", qui contient des articles de presse de Reuters."),Un=p(),j(Ue.$$.fragment),Vn=p(),xs=l("h3"),Ne=l("a"),mt=l("span"),j(ft.$$.fragment),Wn=p(),je=l("span"),za=n("Le jeu de donn\xE9es CoNLL-2003"),Rt=p(),Ve=l("p"),Oa=n("Pour charger le jeu de donn\xE9es CoNLL-2003, nous utilisons la m\xE9thode "),ht=l("code"),Xn=n("load_dataset()"),vt=n(" de la biblioth\xE8que \u{1F917} "),Us=l("em"),Vs=n("Datasets"),Pa=n(" :"),_t=p(),j(rs.$$.fragment),Cn=p(),ue=l("p"),bt=n("Cela va t\xE9l\xE9charger et mettre en cache le jeu de donn\xE9es, comme nous l\u2019avons vu dans "),Cs=l("a"),Ws=n("Chapitre 3"),Da=n(" pour le jeu de donn\xE9es GLUE MRPC. L\u2019inspection de cet objet nous montre les colonnes pr\xE9sentes et la r\xE9partition entre les ensembles d\u2019entra\xEEnement, de validation et de test :"),hs=p(),j(ys.$$.fragment),Zn=p(),j(Xs.$$.fragment),os=p(),We=l("p"),yn=n("En particulier, nous pouvons voir que le jeu de donn\xE9es contient des \xE9tiquettes pour les trois t\xE2ches que nous avons mentionn\xE9es pr\xE9c\xE9demment : NER, POS, et "),$t=l("em"),Ma=n("chunking"),Kn=n(". Une grande diff\xE9rence avec les autres jeux de donn\xE9es est que les textes d\u2019entr\xE9e ne sont pas pr\xE9sent\xE9s comme des phrases ou des documents, mais comme des listes de mots (la derni\xE8re colonne est appel\xE9e "),vs=l("code"),Zs=n("tokens"),gt=n(", mais elle contient des mots dans le sens o\xF9 ce sont des entr\xE9es pr\xE9-tok\xE9nis\xE9es qui doivent encore passer par le "),_s=l("em"),Yn=n("tokenizer"),zs=n(" pour la tokenisation des sous-mots)."),zn=p(),$e=l("p"),Jn=n("Regardons le premier \xE9l\xE9ment de l\u2019ensemble d\u2019entra\xEEnement :"),ge=p(),j(Et.$$.fragment),Ft=p(),j(Os.$$.fragment),Qn=p(),Ks=l("p"),On=n("Puisque nous voulons effectuer la reconnaissance des entit\xE9s nomm\xE9es, nous allons examiner les balises NER :"),ea=p(),j(Ps.$$.fragment),Bt=p(),j(qt.$$.fragment),Ht=p(),Ds=l("p"),Ys=n("Ce sont les \xE9tiquettes sous forme d\u2019entiers pr\xEAts pour l\u2019entra\xEEnement, mais ils ne sont pas n\xE9cessairement utiles lorsque nous voulons inspecter les donn\xE9es. Comme pour la classification de texte, nous pouvons acc\xE9der \xE0 la correspondance entre ces entiers et les noms des \xE9tiquettes en regardant l\u2019attribut "),Gt=l("code"),f=n("features"),I=n(" de notre jeu de donn\xE9es :"),Aa=p(),j(kt.$$.fragment),Ms=p(),j(me.$$.fragment),Pn=p(),fe=l("p"),_l=n("Cette colonne contient donc des \xE9l\xE9ments qui sont des s\xE9quences de "),Ut=l("code"),Vt=n("ClassLabel"),Na=n("s. Le type des \xE9l\xE9ments de la s\xE9quence se trouve dans l\u2019attribut "),As=l("code"),Wt=n("feature"),Dn=n(" de cette "),sa=l("code"),Js=n("ner_feature"),Ta=n(", et nous pouvons acc\xE9der \xE0 la liste des noms en regardant l\u2019attribut "),bs=l("code"),jt=n("names"),Xt=n(" de cette "),Qs=l("code"),bl=n("feature"),ta=n(" :"),Mn=p(),j(wt.$$.fragment),Te=p(),j(Zt.$$.fragment),xt=p(),Ns=l("p"),$s=n("Nous avons d\xE9j\xE0 vu ces \xE9tiquettes en creusant dans le pipeline "),Kt=l("code"),$l=n("token-classification"),gl=n(" au "),Ct=l("a"),Yt=n("Chapitre 6"),El=n(", mais pour un rapide rappel :"),na=p(),ne=l("ul"),Jt=l("li"),yt=l("code"),ql=n("O"),is=n(" signifie que le mot ne correspond \xE0 aucune entit\xE9."),Qt=p(),gs=l("li"),us=l("code"),kl=n("B-PER"),aa=n("/"),en=l("code"),jl=n("I-PER"),Xe=n(" signifie que le mot correspond au d\xE9but de/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),la=l("em"),wl=n("personne"),Sa=n("."),sn=p(),zt=l("li"),tn=l("code"),Ro=n("B-ORG"),Yl=n("/"),Jl=l("code"),Fo=n("I-ORG"),Ir=n(" signifie que le mot correspond au d\xE9but/\xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),An=l("em"),Rr=n("organisation"),La=n("."),Fr=p(),Pe=l("li"),Ql=l("code"),er=n("B-LOC"),Bo=n("/"),sr=l("code"),tr=n("I-LOC"),Ho=n(" signifie que le mot correspond au d\xE9but/\xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),nr=l("em"),ar=n("location"),Go=n("."),Uo=p(),Ot=l("li"),Nn=l("code"),Br=n("B-MISC"),et=n("/"),lr=l("code"),rr=n("I-MISC"),Vo=n(" signifie que le mot correspond au d\xE9but/\xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),or=l("em"),ir=n("divers"),Wo=n("."),Hr=p(),ra=l("p"),Xo=n("Maintenant, le d\xE9codage des \xE9tiquettes que nous avons vues pr\xE9c\xE9demment nous donne ceci :"),Gr=p(),j(oa.$$.fragment),ia=p(),j(ua.$$.fragment),pa=p(),Pt=l("p"),xl=n("Et pour un exemple m\xE9langeant les \xE9tiquettes "),ur=l("code"),Ur=n("B-"),Ia=n(" et "),Cl=l("code"),nn=n("I-"),Zo=n(", voici ce que le m\xEAme code nous donne sur l\u2019\xE9l\xE9ment de l\u2019ensemble d\u2019entra\xEEnement \xE0 l\u2019indice 4 :"),yl=p(),j(Ra.$$.fragment),Vr=p(),ca=l("p"),Ko=n("Comme on peut le voir, les entit\xE9s couvrant deux mots, comme \u201CUnion europ\xE9enne\u201D et \u201CWerner Zwingmann\u201D, se voient attribuer une \xE9tiquette \u201CB-\u201D pour le premier mot et une \xE9tiquette \u201CI-\u201D pour le second."),Wr=p(),j(Tn.$$.fragment),an=p(),Es=l("h3"),ln=l("a"),Sn=l("span"),j(Fa.$$.fragment),pr=p(),cr=l("span"),Xr=n("Traitement des donn\xE9es"),Dt=p(),j(Ba.$$.fragment),zl=p(),qs=l("p"),Yo=n("Comme d\u2019habitude, nos textes doivent \xEAtre convertis en identifiants de "),Ha=l("em"),Jo=n("tokens"),Qo=n(" avant que le mod\xE8le puisse leur donner un sens. Comme nous l\u2019avons vu dans le "),Ga=l("a"),Ua=n("Chapitre 6"),Zr=n(", une grande diff\xE9rence dans le cas des t\xE2ches de classification de "),da=l("em"),ei=n("tokens"),Kr=n(" est que nous avons des entr\xE9es pr\xE9-tok\xE9nis\xE9es. Heureusement, l\u2019API tokenizer peut g\xE9rer cela assez facilement ; nous devons juste avertir le "),st=l("code"),Va=n("tokenizer"),si=n(" avec un drapeau sp\xE9cial."),Ol=p(),ma=l("p"),ti=n("Pour commencer, nous allons cr\xE9er notre objet "),dr=l("code"),Ts=n("tokenizer"),ni=n(". Comme nous l\u2019avons dit pr\xE9c\xE9demment, nous allons utiliser un mod\xE8le pr\xE9-entra\xEEn\xE9 BERT, donc nous allons commencer par t\xE9l\xE9charger et mettre en cache le tokenizer associ\xE9 :"),Pl=p(),j(Wa.$$.fragment),Yr=p(),se=l("p"),ai=n("Vous pouvez remplacer le "),mr=l("code"),fr=n("model_checkpoint"),li=n(" par tout autre mod\xE8le que vous pr\xE9f\xE9rez \xE0 partir du ["),hr=l("em"),vr=n("Hub"),ri=n("]"),Xa=l("a"),oi=n("https://huggingface.co/models"),Mt=n("), ou par un dossier local dans lequel vous avez sauvegard\xE9 un mod\xE8le pr\xE9-entra\xEEn\xE9 et un "),_r=l("em"),br=n("tokenizer"),ii=n(". La seule contrainte est que le "),$r=l("em"),gr=n("tokenizer"),ui=n(" doit \xEAtre soutenu par la biblioth\xE8que \u{1F917} "),Er=l("em"),qr=n("Tokenizers"),pi=n(", il y a donc une version \u201Crapide\u201D disponible. Vous pouvez voir toutes les architectures qui ont une version rapide dans "),Za=l("a"),Jr=n("ce grand tableau"),Dl=n(", et pour v\xE9rifier que l\u2019objet "),kr=l("code"),Qr=n("tokenizer"),Ka=n(" que vous utilisez est bien soutenu par \u{1F917} "),Ml=l("em"),fa=n("Tokenizers"),ci=n(" vous pouvez regarder son attribut "),Ya=l("code"),di=n("is_fast"),mi=n(" :"),jr=p(),j(At.$$.fragment),wr=p(),j(pe.$$.fragment),eo=p(),tt=l("p"),fi=n("Pour tokeniser une entr\xE9e pr\xE9-tokenis\xE9e, nous pouvons utiliser notre "),xr=l("code"),Cr=n("tokenizer"),hi=n(" comme d\u2019habitude et juste ajouter "),yr=l("code"),zr=n("is_split_into_words=True"),vi=n(" :"),so=p(),j(Ln.$$.fragment),to=p(),j(Ja.$$.fragment),Al=p(),ce=l("p"),_i=n("Comme on peut le voir, le "),Qa=l("em"),bi=n("tokenizer"),$i=n(" a ajout\xE9 les "),el=l("em"),gi=n("tokens"),Ei=n(" sp\xE9ciaux utilis\xE9s par le mod\xE8le ("),Nl=l("code"),nt=n("[CLS]"),qi=n(" au d\xE9but et "),sl=l("code"),ki=n("[SEP]"),ji=n(" \xE0 la fin) et n\u2019a pas touch\xE9 \xE0 la plupart des mots. Le mot "),tl=l("code"),wi=n("lamb"),xi=n(", cependant, a \xE9t\xE9 tokenis\xE9 en deux sous-mots, "),In=l("code"),Ci=n("la"),yi=n(" et "),Tl=l("code"),i=n("##mb"),v=n(". Cela introduit un d\xE9calage entre nos entr\xE9es et les \xE9tiquettes : la liste des \xE9tiquettes n\u2019a que 9 \xE9l\xE9ments, alors que notre entr\xE9e a maintenant 12 "),no=l("em"),fu=n("tokens"),hu=n(". Il est facile de tenir compte des "),at=l("em"),vu=n("tokens"),_u=n(" sp\xE9ciaux (nous savons qu\u2019ils sont au d\xE9but et \xE0 la fin), mais nous devons \xE9galement nous assurer que nous alignons toutes les \xE9tiquettes avec les mots appropri\xE9s."),zi=p(),Ss=l("p"),Sl=n("Heureusement, comme nous utilisons un "),ao=l("em"),bu=n("tokenizer"),Ll=n(" rapide, nous avons acc\xE8s aux superpouvoirs des \u{1F917} "),lo=l("em"),$u=n("Tokenizers"),ha=n(", ce qui signifie que nous pouvons facilement faire correspondre chaque "),ro=l("em"),gu=n("token"),Eu=n(" au mot correspondant (comme on le voit au "),nl=l("a"),qu=n("Chapitre 6"),ku=n(") :"),Oi=p(),j(rn.$$.fragment),Pi=p(),j(Il.$$.fragment),Or=p(),oe=l("p"),oo=n("Avec un peu de travail, nous pouvons alors \xE9tendre notre liste d\u2019\xE9tiquettes pour qu\u2019elle corresponde aux "),io=l("em"),uo=n("tokens"),ju=n(". La premi\xE8re r\xE8gle que nous allons appliquer est que les "),Ze=l("em"),wu=n("tokens"),xu=n(" sp\xE9ciaux re\xE7oivent une \xE9tiquette de "),po=l("code"),Cu=n("-100"),yu=n(". En effet, par d\xE9faut, "),co=l("code"),zu=n("-100"),mo=n(" est un indice qui est ignor\xE9 dans la fonction de perte que nous allons utiliser (entropie crois\xE9e). Ensuite, chaque "),fo=l("em"),ho=n("token"),Ou=n(" re\xE7oit la m\xEAme \xE9tiquette que le "),Rl=l("em"),Pu=n("token"),Du=n(" qui a commenc\xE9 le mot dans lequel il se trouve, puisqu\u2019ils font partie de la m\xEAme entit\xE9. Pour les "),lt=l("em"),Mu=n("tokens"),Au=n(" \xE0 l\u2019int\xE9rieur d\u2019un mot mais pas au d\xE9but, nous rempla\xE7ons le "),vo=l("code"),Nu=n("B-"),_o=n(" par "),bo=l("code"),$o=n("I-"),Tu=n(" (puisque le "),go=l("em"),Su=n("token"),Eo=n(" ne commence pas l\u2019entit\xE9) :"),Di=p(),j(va.$$.fragment),Mi=p(),Pr=l("p"),Lu=n("Essayons-le sur notre premi\xE8re phrase :"),Rn=p(),j(Fl.$$.fragment),Ai=p(),j(Bl.$$.fragment),Ni=p(),Be=l("p"),Iu=n("Comme nous pouvons le voir, notre fonction a ajout\xE9 le "),qo=l("code"),ko=n("-100"),Ru=n(" pour les deux "),on=l("em"),Fu=n("tokens"),Bu=n(" sp\xE9ciaux au d\xE9but et \xE0 la fin, et un nouveau "),jo=l("code"),_a=n("0"),Hu=n(" pour notre mot qui a \xE9t\xE9 divis\xE9 en deux "),wo=l("em"),Gu=n("tokens"),Uu=n("."),al=p(),j(ll.$$.fragment),Ti=p(),De=l("p"),Vu=n("Pour pr\xE9traiter notre ensemble de donn\xE9es, nous devons tokeniser toutes les entr\xE9es et appliquer "),xo=l("code"),Wu=n("align_labels_with_tokens()"),Hl=n(" sur toutes les \xE9tiquettes. Pour profiter de la vitesse de notre "),Co=l("em"),Xu=n("tokenizer"),Zu=n(" rapide, il est pr\xE9f\xE9rable de tokeniser beaucoup de textes en m\xEAme temps, donc nous allons \xE9crire une fonction qui traite une liste d\u2019exemples et utiliser la m\xE9thode "),ba=l("code"),yo=n("Dataset.map()"),Ku=n(" avec l\u2019option "),rt=l("code"),Yu=n("batched=True"),Ju=n(". La seule chose qui diff\xE8re de notre exemple pr\xE9c\xE9dent est que la fonction "),zo=l("code"),Qu=n("word_ids()"),$a=n(" a besoin de r\xE9cup\xE9rer l\u2019index de l\u2019exemple dont nous voulons les IDs de mots lorsque les entr\xE9es du "),Oo=l("em"),ep=n("tokenizer"),sp=n(" sont des listes de textes (ou dans notre cas, des listes de mots), donc nous l\u2019ajoutons aussi :"),Si=p(),j(ga.$$.fragment),Li=p(),Me=l("p"),tp=n("Notez que nous n\u2019avons pas encore padd\xE9 nos entr\xE9es ; nous le ferons plus tard, lors de la cr\xE9ation des lots avec un collateur de donn\xE9es."),Ii=p(),Dr=l("p"),np=n("Nous pouvons maintenant appliquer tout ce pr\xE9traitement en une seule fois sur les autres divisions de notre jeu de donn\xE9es :"),Ri=p(),j(Gl.$$.fragment),Fi=p(),Ls=l("p"),ap=n("Nous avons fait la partie la plus difficile ! Maintenant que les donn\xE9es ont \xE9t\xE9 pr\xE9trait\xE9es, l\u2019entra\xEEnement r\xE9el ressemblera beaucoup \xE0 ce que nous avons fait dans le "),Mr=l("a"),lp=n("Chapitre 3"),Oc=n("."),Wp=p(),ol.c(),rp=p(),Ar=l("h3"),Po=l("a"),Op=l("span"),j(Bi.$$.fragment),Pc=p(),Pp=l("span"),Dc=n("Collation des donn\xE9es"),Xp=p(),un=l("p"),Mc=n("Nous ne pouvons pas simplement utiliser un "),Dp=l("code"),Ac=n("DataCollatorWithPadding"),Nc=n(" comme dans "),op=l("a"),Tc=n("Chapter 3"),Sc=n(" parce que cela ne fait que rembourrer les entr\xE9es (IDs d\u2019entr\xE9e, masque d\u2019attention, et IDs de type de "),Mp=l("em"),Lc=n("token"),Ic=n("). Ici, nos \xE9tiquettes doivent \xEAtre remplies exactement de la m\xEAme mani\xE8re que les entr\xE9es afin qu\u2019elles gardent la m\xEAme taille, en utilisant "),Ap=l("code"),Rc=n("-100"),Fc=n(" comme valeur afin que les pr\xE9dictions correspondantes soient ignor\xE9es dans le calcul de la perte."),Zp=p(),Ea=l("p"),Bc=n("Tout ceci est fait par un "),Hi=l("a"),Np=l("code"),Hc=n("DataCollatorForTokenClassification"),Gc=n(". Comme le "),Tp=l("code"),Uc=n("DataCollatorWithPadding"),Vc=n(", il prend le "),Sp=l("code"),Wc=n("tokenizer"),Xc=n(" utilis\xE9 pour pr\xE9traiter les entr\xE9es :"),Kp=p(),ul.c(),ip=p(),up=l("p"),Zc=n("Pour tester cette fonction sur quelques \xE9chantillons, nous pouvons simplement l\u2019appeler sur une liste d\u2019exemples provenant de notre jeu d\u2019entra\xEEnement tok\xE9nis\xE9 :"),Yp=p(),j(Gi.$$.fragment),Jp=p(),j(Ui.$$.fragment),Qp=p(),pp=l("p"),Kc=n("Comparons cela aux \xE9tiquettes des premier et deuxi\xE8me \xE9l\xE9ments de notre jeu de donn\xE9es :"),ec=p(),j(Vi.$$.fragment),sc=p(),j(Wi.$$.fragment),tc=p(),cl.c(),cp=p(),ps&&ps.c(),dp=p(),Nr=l("h3"),Do=l("a"),Lp=l("span"),j(Xi.$$.fragment),Yc=p(),Ip=l("span"),Jc=n("M\xE9triques"),nc=p(),ml.c(),mp=p(),j(Zi.$$.fragment),ac=p(),fp=l("p"),Qc=n("Cette m\xE9trique ne se comporte pas comme la pr\xE9cision standard : elle prend les listes d\u2019\xE9tiquettes comme des cha\xEEnes de caract\xE8res et non comme des entiers. Nous devrons donc d\xE9coder compl\xE8tement les pr\xE9dictions et les \xE9tiquettes avant de les transmettre \xE0 la m\xE9trique. Voyons comment cela fonctionne. Tout d\u2019abord, nous allons obtenir les \xE9tiquettes pour notre premier exemple d\u2019entra\xEEnement :"),lc=p(),j(Ki.$$.fragment),rc=p(),j(Yi.$$.fragment),oc=p(),hp=l("p"),ed=n("Nous pouvons alors cr\xE9er de fausses pr\xE9dictions pour celles-ci en changeant simplement la valeur de l\u2019indice 2 :"),ic=p(),j(Ji.$$.fragment),uc=p(),vp=l("p"),sd=n("Notez que la m\xE9trique prend une liste de pr\xE9dictions (pas seulement une) et une liste d\u2019\xE9tiquettes. Voici la sortie :"),pc=p(),j(Qi.$$.fragment),cc=p(),hl.c(),_p=p(),cs&&cs.c(),bp=p(),Tr=l("h3"),Mo=l("a"),Rp=l("span"),j(eu.$$.fragment),td=p(),Fp=l("span"),nd=n("Utilisation du mod\xE8le *finetun\xE9*"),dc=p(),qa=l("p"),ad=n("Nous vous avons d\xE9j\xE0 montr\xE9 comment vous pouvez utiliser le mod\xE8le que nous avons affin\xE9 sur le "),Bp=l("em"),ld=n("Hub"),rd=n(" avec le "),Hp=l("em"),od=n("widget"),id=n(" d\u2019inf\xE9rence. Pour l\u2019utiliser localement dans un "),Gp=l("code"),ud=n("pipeline"),pd=n(", vous devez juste sp\xE9cifier l\u2019identifiant de mod\xE8le appropri\xE9 :"),mc=p(),j(su.$$.fragment),fc=p(),j(tu.$$.fragment),hc=p(),$p=l("p"),cd=n("Super ! Notre mod\xE8le fonctionne aussi bien que le mod\xE8le par d\xE9faut pour ce pipeline !"),this.h()},l(t){const m=ch('[data-svelte="svelte-1phssyn"]',document.head);d=r(m,"META",{name:!0,content:!0}),m.forEach(s),E=c(t),w(h.$$.fragment,t),q=c(t),z=r(t,"H1",{class:!0});var uu=o(z);$=r(uu,"A",{id:!0,class:!0,href:!0});var gp=o($);k=r(gp,"SPAN",{});var Up=o(k);w(O.$$.fragment,Up),Up.forEach(s),gp.forEach(s),y=c(uu),P=r(uu,"SPAN",{});var Vp=o(P);H=a(Vp,"Classification de *tokens*"),Vp.forEach(s),uu.forEach(s),D=c(t),R.l(t),A=c(t),N=r(t,"P",{});var Sr=o(N);Y=a(Sr,"La premi\xE8re application que nous allons explorer est la classification de "),G=r(Sr,"EM",{});var Ep=o(G);X=a(Ep,"tokens"),Ep.forEach(s),J=a(Sr,". Cette t\xE2che g\xE9n\xE9rique englobe tous les probl\xE8mes qui peuvent \xEAtre formul\xE9s comme \u201Cl\u2019attribution d\u2019une \xE9tiquette \xE0 chaque "),K=r(Sr,"EM",{});var qp=o(K);Q=a(qp,"token"),qp.forEach(s),T=a(Sr," dans une phrase\u201D, tels que :"),Sr.forEach(s),F=c(t),S=r(t,"UL",{});var Ul=o(S);W=r(Ul,"LI",{});var Lr=o(W);ae=r(Lr,"STRONG",{});var kp=o(ae);ve=a(kp,"reconnaissance d\u2019entit\xE9s nomm\xE9es (NER)"),kp.forEach(s),te=a(Lr," : trouver les entit\xE9s (telles que des personnes, des lieux ou des organisations) dans une phrase. Cela peut \xEAtre formul\xE9 comme l\u2019attribution d\u2019une \xE9tiquette \xE0 chaque "),de=r(Lr,"EM",{});var xd=o(de);he=a(xd,"token"),xd.forEach(s),_e=a(Lr," en ayant une classe par entit\xE9 et une classe pour \u201Caucune entit\xE9\u201D."),Lr.forEach(s),U=c(Ul),B=r(Ul,"LI",{});var dd=o(B);Z=r(dd,"STRONG",{});var Cd=o(Z);we=a(Cd,"part-of-speech tagging (POS)"),Cd.forEach(s),Ie=a(dd," : marquer chaque mot dans une phrase comme correspondant \xE0 une partie particuli\xE8re du discours (comme un nom, un verbe, un adjectif, etc.)."),dd.forEach(s),xe=c(Ul),ee=r(Ul,"LI",{});var Is=o(ee);le=r(Is,"STRONG",{});var yd=o(le);Ye=r(yd,"EM",{});var zd=o(Ye);ks=a(zd,"chunking"),zd.forEach(s),yd.forEach(s),Ce=a(Is," : trouver les "),Ee=r(Is,"EM",{});var Od=o(Ee);Rs=a(Od,"tokens"),Od.forEach(s),re=a(Is," qui appartiennent \xE0 la m\xEAme entit\xE9. Cette t\xE2che (qui peut \xEAtre combin\xE9e avec le POS ou la NER) peut \xEAtre formul\xE9e comme l\u2019attribution d\u2019une \xE9tiquette (habituellement "),cn=r(Is,"CODE",{});var Pd=o(cn);it=a(Pd,"B-"),Pd.forEach(s),ja=a(Is,") \xE0 tous les "),dn=r(Is,"EM",{});var Dd=o(dn);js=a(Dd,"tokens"),Dd.forEach(s),wa=a(Is," qui sont au d\xE9but d\u2019un morceau, une autre \xE9tiquette (habituellement "),mn=r(Is,"CODE",{});var Md=o(mn);ut=a(Md,"I-"),Md.forEach(s),xa=a(Is,") aux "),fn=r(Is,"EM",{});var Ad=o(fn);hn=a(Ad,"tokens"),Ad.forEach(s),Je=a(Is," qui sont \xE0 l\u2019int\xE9rieur d\u2019un morceau, et une troisi\xE8me \xE9tiquette (habituellement "),pt=r(Is,"CODE",{});var Nd=o(pt);Qe=a(Nd,"O"),Nd.forEach(s),vn=a(Is,") aux "),Re=r(Is,"EM",{});var Td=o(Re);_n=a(Td,"tokens"),Td.forEach(s),ye=a(Is," qui n\u2019appartiennent \xE0 aucun morceau."),Is.forEach(s),Ul.forEach(s),Ae=c(t),w(es.$$.fragment,t),He=c(t),Fs=r(t,"P",{});var _c=o(Fs);ct=a(_c,"Bien s\xFBr, il existe de nombreux autres types de probl\xE8mes de classification de "),bn=r(_c,"EM",{});var Sd=o(bn);$n=a(Sd,"tokens"),Sd.forEach(s),ze=a(_c," ; ce ne sont l\xE0 que quelques exemples repr\xE9sentatifs. Dans cette section, nous allons affiner un mod\xE8le (BERT) sur une t\xE2che NER, qui sera alors capable de calculer des pr\xE9dictions comme celle-ci :"),_c.forEach(s),Fn=c(t),be=r(t,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),o(be).forEach(s),Bn=c(t),qe=r(t,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),o(qe).forEach(s),gn=c(t),ke=r(t,"A",{class:!0,href:!0});var bc=o(ke);ss=r(bc,"IMG",{class:!0,src:!0,alt:!0}),Bs=c(bc),dt=r(bc,"IMG",{class:!0,src:!0,alt:!0}),bc.forEach(s),ws=c(t),ds=r(t,"P",{});var jp=o(ds);Tt=a(jp,"Vous pouvez trouver le mod\xE8le que nous allons entra\xEEner et t\xE9l\xE9charger sur le "),ms=r(jp,"EM",{});var Ld=o(ms);Ca=a(Ld,"Hub"),Ld.forEach(s),St=a(jp," et v\xE9rifier ses pr\xE9dictions "),ts=r(jp,"A",{href:!0,rel:!0});var Id=o(ts);Hn=a(Id,"ici"),Id.forEach(s),Oe=a(jp,"."),jp.forEach(s),Hs=c(t),Ge=r(t,"H2",{class:!0});var $c=o(Ge);Fe=r($c,"A",{id:!0,class:!0,href:!0});var Rd=o(Fe);kn=r(Rd,"SPAN",{});var Fd=o(kn);w(ns.$$.fragment,Fd),Fd.forEach(s),Rd.forEach(s),ya=c($c),jn=r($c,"SPAN",{});var Bd=o(jn);Lt=a(Bd,"Pr\xE9paration des donn\xE9es"),Bd.forEach(s),$c.forEach(s),Gs=c(t),as=r(t,"P",{});var wp=o(as);ie=a(wp,"Tout d\u2019abord, nous avons besoin d\u2019un jeu de donn\xE9es adapt\xE9 \xE0 la classification des "),wn=r(wp,"EM",{});var Hd=o(wn);xn=a(Hd,"tokens"),Hd.forEach(s),Gn=a(wp,". Dans cette section, nous utiliserons le jeu de donn\xE9es "),ls=r(wp,"A",{href:!0,rel:!0});var Gd=o(ls);It=a(Gd,"CoNLL-2003"),Gd.forEach(s),fs=a(wp,", qui contient des articles de presse de Reuters."),wp.forEach(s),Un=c(t),w(Ue.$$.fragment,t),Vn=c(t),xs=r(t,"H3",{class:!0});var gc=o(xs);Ne=r(gc,"A",{id:!0,class:!0,href:!0});var Ud=o(Ne);mt=r(Ud,"SPAN",{});var Vd=o(mt);w(ft.$$.fragment,Vd),Vd.forEach(s),Ud.forEach(s),Wn=c(gc),je=r(gc,"SPAN",{});var Wd=o(je);za=a(Wd,"Le jeu de donn\xE9es CoNLL-2003"),Wd.forEach(s),gc.forEach(s),Rt=c(t),Ve=r(t,"P",{});var xp=o(Ve);Oa=a(xp,"Pour charger le jeu de donn\xE9es CoNLL-2003, nous utilisons la m\xE9thode "),ht=r(xp,"CODE",{});var Xd=o(ht);Xn=a(Xd,"load_dataset()"),Xd.forEach(s),vt=a(xp," de la biblioth\xE8que \u{1F917} "),Us=r(xp,"EM",{});var Zd=o(Us);Vs=a(Zd,"Datasets"),Zd.forEach(s),Pa=a(xp," :"),xp.forEach(s),_t=c(t),w(rs.$$.fragment,t),Cn=c(t),ue=r(t,"P",{});var Ec=o(ue);bt=a(Ec,"Cela va t\xE9l\xE9charger et mettre en cache le jeu de donn\xE9es, comme nous l\u2019avons vu dans "),Cs=r(Ec,"A",{href:!0});var Kd=o(Cs);Ws=a(Kd,"Chapitre 3"),Kd.forEach(s),Da=a(Ec," pour le jeu de donn\xE9es GLUE MRPC. L\u2019inspection de cet objet nous montre les colonnes pr\xE9sentes et la r\xE9partition entre les ensembles d\u2019entra\xEEnement, de validation et de test :"),Ec.forEach(s),hs=c(t),w(ys.$$.fragment,t),Zn=c(t),w(Xs.$$.fragment,t),os=c(t),We=r(t,"P",{});var Ao=o(We);yn=a(Ao,"En particulier, nous pouvons voir que le jeu de donn\xE9es contient des \xE9tiquettes pour les trois t\xE2ches que nous avons mentionn\xE9es pr\xE9c\xE9demment : NER, POS, et "),$t=r(Ao,"EM",{});var Yd=o($t);Ma=a(Yd,"chunking"),Yd.forEach(s),Kn=a(Ao,". Une grande diff\xE9rence avec les autres jeux de donn\xE9es est que les textes d\u2019entr\xE9e ne sont pas pr\xE9sent\xE9s comme des phrases ou des documents, mais comme des listes de mots (la derni\xE8re colonne est appel\xE9e "),vs=r(Ao,"CODE",{});var Jd=o(vs);Zs=a(Jd,"tokens"),Jd.forEach(s),gt=a(Ao,", mais elle contient des mots dans le sens o\xF9 ce sont des entr\xE9es pr\xE9-tok\xE9nis\xE9es qui doivent encore passer par le "),_s=r(Ao,"EM",{});var Qd=o(_s);Yn=a(Qd,"tokenizer"),Qd.forEach(s),zs=a(Ao," pour la tokenisation des sous-mots)."),Ao.forEach(s),zn=c(t),$e=r(t,"P",{});var em=o($e);Jn=a(em,"Regardons le premier \xE9l\xE9ment de l\u2019ensemble d\u2019entra\xEEnement :"),em.forEach(s),ge=c(t),w(Et.$$.fragment,t),Ft=c(t),w(Os.$$.fragment,t),Qn=c(t),Ks=r(t,"P",{});var sm=o(Ks);On=a(sm,"Puisque nous voulons effectuer la reconnaissance des entit\xE9s nomm\xE9es, nous allons examiner les balises NER :"),sm.forEach(s),ea=c(t),w(Ps.$$.fragment,t),Bt=c(t),w(qt.$$.fragment,t),Ht=c(t),Ds=r(t,"P",{});var qc=o(Ds);Ys=a(qc,"Ce sont les \xE9tiquettes sous forme d\u2019entiers pr\xEAts pour l\u2019entra\xEEnement, mais ils ne sont pas n\xE9cessairement utiles lorsque nous voulons inspecter les donn\xE9es. Comme pour la classification de texte, nous pouvons acc\xE9der \xE0 la correspondance entre ces entiers et les noms des \xE9tiquettes en regardant l\u2019attribut "),Gt=r(qc,"CODE",{});var tm=o(Gt);f=a(tm,"features"),tm.forEach(s),I=a(qc," de notre jeu de donn\xE9es :"),qc.forEach(s),Aa=c(t),w(kt.$$.fragment,t),Ms=c(t),w(me.$$.fragment,t),Pn=c(t),fe=r(t,"P",{});var ka=o(fe);_l=a(ka,"Cette colonne contient donc des \xE9l\xE9ments qui sont des s\xE9quences de "),Ut=r(ka,"CODE",{});var nm=o(Ut);Vt=a(nm,"ClassLabel"),nm.forEach(s),Na=a(ka,"s. Le type des \xE9l\xE9ments de la s\xE9quence se trouve dans l\u2019attribut "),As=r(ka,"CODE",{});var am=o(As);Wt=a(am,"feature"),am.forEach(s),Dn=a(ka," de cette "),sa=r(ka,"CODE",{});var lm=o(sa);Js=a(lm,"ner_feature"),lm.forEach(s),Ta=a(ka,", et nous pouvons acc\xE9der \xE0 la liste des noms en regardant l\u2019attribut "),bs=r(ka,"CODE",{});var rm=o(bs);jt=a(rm,"names"),rm.forEach(s),Xt=a(ka," de cette "),Qs=r(ka,"CODE",{});var om=o(Qs);bl=a(om,"feature"),om.forEach(s),ta=a(ka," :"),ka.forEach(s),Mn=c(t),w(wt.$$.fragment,t),Te=c(t),w(Zt.$$.fragment,t),xt=c(t),Ns=r(t,"P",{});var Cp=o(Ns);$s=a(Cp,"Nous avons d\xE9j\xE0 vu ces \xE9tiquettes en creusant dans le pipeline "),Kt=r(Cp,"CODE",{});var im=o(Kt);$l=a(im,"token-classification"),im.forEach(s),gl=a(Cp," au "),Ct=r(Cp,"A",{href:!0});var um=o(Ct);Yt=a(um,"Chapitre 6"),um.forEach(s),El=a(Cp,", mais pour un rapide rappel :"),Cp.forEach(s),na=c(t),ne=r(t,"UL",{});var Vl=o(ne);Jt=r(Vl,"LI",{});var md=o(Jt);yt=r(md,"CODE",{});var pm=o(yt);ql=a(pm,"O"),pm.forEach(s),is=a(md," signifie que le mot ne correspond \xE0 aucune entit\xE9."),md.forEach(s),Qt=c(Vl),gs=r(Vl,"LI",{});var pu=o(gs);us=r(pu,"CODE",{});var cm=o(us);kl=a(cm,"B-PER"),cm.forEach(s),aa=a(pu,"/"),en=r(pu,"CODE",{});var dm=o(en);jl=a(dm,"I-PER"),dm.forEach(s),Xe=a(pu," signifie que le mot correspond au d\xE9but de/est \xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),la=r(pu,"EM",{});var mm=o(la);wl=a(mm,"personne"),mm.forEach(s),Sa=a(pu,"."),pu.forEach(s),sn=c(Vl),zt=r(Vl,"LI",{});var cu=o(zt);tn=r(cu,"CODE",{});var fm=o(tn);Ro=a(fm,"B-ORG"),fm.forEach(s),Yl=a(cu,"/"),Jl=r(cu,"CODE",{});var hm=o(Jl);Fo=a(hm,"I-ORG"),hm.forEach(s),Ir=a(cu," signifie que le mot correspond au d\xE9but/\xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),An=r(cu,"EM",{});var vm=o(An);Rr=a(vm,"organisation"),vm.forEach(s),La=a(cu,"."),cu.forEach(s),Fr=c(Vl),Pe=r(Vl,"LI",{});var du=o(Pe);Ql=r(du,"CODE",{});var _m=o(Ql);er=a(_m,"B-LOC"),_m.forEach(s),Bo=a(du,"/"),sr=r(du,"CODE",{});var bm=o(sr);tr=a(bm,"I-LOC"),bm.forEach(s),Ho=a(du," signifie que le mot correspond au d\xE9but/\xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),nr=r(du,"EM",{});var $m=o(nr);ar=a($m,"location"),$m.forEach(s),Go=a(du,"."),du.forEach(s),Uo=c(Vl),Ot=r(Vl,"LI",{});var mu=o(Ot);Nn=r(mu,"CODE",{});var gm=o(Nn);Br=a(gm,"B-MISC"),gm.forEach(s),et=a(mu,"/"),lr=r(mu,"CODE",{});var Em=o(lr);rr=a(Em,"I-MISC"),Em.forEach(s),Vo=a(mu," signifie que le mot correspond au d\xE9but/\xE0 l\u2019int\xE9rieur d\u2019une entit\xE9 "),or=r(mu,"EM",{});var qm=o(or);ir=a(qm,"divers"),qm.forEach(s),Wo=a(mu,"."),mu.forEach(s),Vl.forEach(s),Hr=c(t),ra=r(t,"P",{});var km=o(ra);Xo=a(km,"Maintenant, le d\xE9codage des \xE9tiquettes que nous avons vues pr\xE9c\xE9demment nous donne ceci :"),km.forEach(s),Gr=c(t),w(oa.$$.fragment,t),ia=c(t),w(ua.$$.fragment,t),pa=c(t),Pt=r(t,"P",{});var yp=o(Pt);xl=a(yp,"Et pour un exemple m\xE9langeant les \xE9tiquettes "),ur=r(yp,"CODE",{});var jm=o(ur);Ur=a(jm,"B-"),jm.forEach(s),Ia=a(yp," et "),Cl=r(yp,"CODE",{});var wm=o(Cl);nn=a(wm,"I-"),wm.forEach(s),Zo=a(yp,", voici ce que le m\xEAme code nous donne sur l\u2019\xE9l\xE9ment de l\u2019ensemble d\u2019entra\xEEnement \xE0 l\u2019indice 4 :"),yp.forEach(s),yl=c(t),w(Ra.$$.fragment,t),Vr=c(t),ca=r(t,"P",{});var xm=o(ca);Ko=a(xm,"Comme on peut le voir, les entit\xE9s couvrant deux mots, comme \u201CUnion europ\xE9enne\u201D et \u201CWerner Zwingmann\u201D, se voient attribuer une \xE9tiquette \u201CB-\u201D pour le premier mot et une \xE9tiquette \u201CI-\u201D pour le second."),xm.forEach(s),Wr=c(t),w(Tn.$$.fragment,t),an=c(t),Es=r(t,"H3",{class:!0});var kc=o(Es);ln=r(kc,"A",{id:!0,class:!0,href:!0});var Cm=o(ln);Sn=r(Cm,"SPAN",{});var ym=o(Sn);w(Fa.$$.fragment,ym),ym.forEach(s),Cm.forEach(s),pr=c(kc),cr=r(kc,"SPAN",{});var zm=o(cr);Xr=a(zm,"Traitement des donn\xE9es"),zm.forEach(s),kc.forEach(s),Dt=c(t),w(Ba.$$.fragment,t),zl=c(t),qs=r(t,"P",{});var Wl=o(qs);Yo=a(Wl,"Comme d\u2019habitude, nos textes doivent \xEAtre convertis en identifiants de "),Ha=r(Wl,"EM",{});var Om=o(Ha);Jo=a(Om,"tokens"),Om.forEach(s),Qo=a(Wl," avant que le mod\xE8le puisse leur donner un sens. Comme nous l\u2019avons vu dans le "),Ga=r(Wl,"A",{href:!0});var Pm=o(Ga);Ua=a(Pm,"Chapitre 6"),Pm.forEach(s),Zr=a(Wl,", une grande diff\xE9rence dans le cas des t\xE2ches de classification de "),da=r(Wl,"EM",{});var Dm=o(da);ei=a(Dm,"tokens"),Dm.forEach(s),Kr=a(Wl," est que nous avons des entr\xE9es pr\xE9-tok\xE9nis\xE9es. Heureusement, l\u2019API tokenizer peut g\xE9rer cela assez facilement ; nous devons juste avertir le "),st=r(Wl,"CODE",{});var Mm=o(st);Va=a(Mm,"tokenizer"),Mm.forEach(s),si=a(Wl," avec un drapeau sp\xE9cial."),Wl.forEach(s),Ol=c(t),ma=r(t,"P",{});var jc=o(ma);ti=a(jc,"Pour commencer, nous allons cr\xE9er notre objet "),dr=r(jc,"CODE",{});var Am=o(dr);Ts=a(Am,"tokenizer"),Am.forEach(s),ni=a(jc,". Comme nous l\u2019avons dit pr\xE9c\xE9demment, nous allons utiliser un mod\xE8le pr\xE9-entra\xEEn\xE9 BERT, donc nous allons commencer par t\xE9l\xE9charger et mettre en cache le tokenizer associ\xE9 :"),jc.forEach(s),Pl=c(t),w(Wa.$$.fragment,t),Yr=c(t),se=r(t,"P",{});var Se=o(se);ai=a(Se,"Vous pouvez remplacer le "),mr=r(Se,"CODE",{});var Nm=o(mr);fr=a(Nm,"model_checkpoint"),Nm.forEach(s),li=a(Se," par tout autre mod\xE8le que vous pr\xE9f\xE9rez \xE0 partir du ["),hr=r(Se,"EM",{});var Tm=o(hr);vr=a(Tm,"Hub"),Tm.forEach(s),ri=a(Se,"]"),Xa=r(Se,"A",{href:!0,rel:!0});var Sm=o(Xa);oi=a(Sm,"https://huggingface.co/models"),Sm.forEach(s),Mt=a(Se,"), ou par un dossier local dans lequel vous avez sauvegard\xE9 un mod\xE8le pr\xE9-entra\xEEn\xE9 et un "),_r=r(Se,"EM",{});var Lm=o(_r);br=a(Lm,"tokenizer"),Lm.forEach(s),ii=a(Se,". La seule contrainte est que le "),$r=r(Se,"EM",{});var Im=o($r);gr=a(Im,"tokenizer"),Im.forEach(s),ui=a(Se," doit \xEAtre soutenu par la biblioth\xE8que \u{1F917} "),Er=r(Se,"EM",{});var Rm=o(Er);qr=a(Rm,"Tokenizers"),Rm.forEach(s),pi=a(Se,", il y a donc une version \u201Crapide\u201D disponible. Vous pouvez voir toutes les architectures qui ont une version rapide dans "),Za=r(Se,"A",{href:!0,rel:!0});var Fm=o(Za);Jr=a(Fm,"ce grand tableau"),Fm.forEach(s),Dl=a(Se,", et pour v\xE9rifier que l\u2019objet "),kr=r(Se,"CODE",{});var Bm=o(kr);Qr=a(Bm,"tokenizer"),Bm.forEach(s),Ka=a(Se," que vous utilisez est bien soutenu par \u{1F917} "),Ml=r(Se,"EM",{});var Hm=o(Ml);fa=a(Hm,"Tokenizers"),Hm.forEach(s),ci=a(Se," vous pouvez regarder son attribut "),Ya=r(Se,"CODE",{});var Gm=o(Ya);di=a(Gm,"is_fast"),Gm.forEach(s),mi=a(Se," :"),Se.forEach(s),jr=c(t),w(At.$$.fragment,t),wr=c(t),w(pe.$$.fragment,t),eo=c(t),tt=r(t,"P",{});var zp=o(tt);fi=a(zp,"Pour tokeniser une entr\xE9e pr\xE9-tokenis\xE9e, nous pouvons utiliser notre "),xr=r(zp,"CODE",{});var Um=o(xr);Cr=a(Um,"tokenizer"),Um.forEach(s),hi=a(zp," comme d\u2019habitude et juste ajouter "),yr=r(zp,"CODE",{});var Vm=o(yr);zr=a(Vm,"is_split_into_words=True"),Vm.forEach(s),vi=a(zp," :"),zp.forEach(s),so=c(t),w(Ln.$$.fragment,t),to=c(t),w(Ja.$$.fragment,t),Al=c(t),ce=r(t,"P",{});var Ke=o(ce);_i=a(Ke,"Comme on peut le voir, le "),Qa=r(Ke,"EM",{});var Wm=o(Qa);bi=a(Wm,"tokenizer"),Wm.forEach(s),$i=a(Ke," a ajout\xE9 les "),el=r(Ke,"EM",{});var Xm=o(el);gi=a(Xm,"tokens"),Xm.forEach(s),Ei=a(Ke," sp\xE9ciaux utilis\xE9s par le mod\xE8le ("),Nl=r(Ke,"CODE",{});var Zm=o(Nl);nt=a(Zm,"[CLS]"),Zm.forEach(s),qi=a(Ke," au d\xE9but et "),sl=r(Ke,"CODE",{});var Km=o(sl);ki=a(Km,"[SEP]"),Km.forEach(s),ji=a(Ke," \xE0 la fin) et n\u2019a pas touch\xE9 \xE0 la plupart des mots. Le mot "),tl=r(Ke,"CODE",{});var Ym=o(tl);wi=a(Ym,"lamb"),Ym.forEach(s),xi=a(Ke,", cependant, a \xE9t\xE9 tokenis\xE9 en deux sous-mots, "),In=r(Ke,"CODE",{});var Jm=o(In);Ci=a(Jm,"la"),Jm.forEach(s),yi=a(Ke," et "),Tl=r(Ke,"CODE",{});var Qm=o(Tl);i=a(Qm,"##mb"),Qm.forEach(s),v=a(Ke,". Cela introduit un d\xE9calage entre nos entr\xE9es et les \xE9tiquettes : la liste des \xE9tiquettes n\u2019a que 9 \xE9l\xE9ments, alors que notre entr\xE9e a maintenant 12 "),no=r(Ke,"EM",{});var ef=o(no);fu=a(ef,"tokens"),ef.forEach(s),hu=a(Ke,". Il est facile de tenir compte des "),at=r(Ke,"EM",{});var sf=o(at);vu=a(sf,"tokens"),sf.forEach(s),_u=a(Ke," sp\xE9ciaux (nous savons qu\u2019ils sont au d\xE9but et \xE0 la fin), mais nous devons \xE9galement nous assurer que nous alignons toutes les \xE9tiquettes avec les mots appropri\xE9s."),Ke.forEach(s),zi=c(t),Ss=r(t,"P",{});var Xl=o(Ss);Sl=a(Xl,"Heureusement, comme nous utilisons un "),ao=r(Xl,"EM",{});var tf=o(ao);bu=a(tf,"tokenizer"),tf.forEach(s),Ll=a(Xl," rapide, nous avons acc\xE8s aux superpouvoirs des \u{1F917} "),lo=r(Xl,"EM",{});var nf=o(lo);$u=a(nf,"Tokenizers"),nf.forEach(s),ha=a(Xl,", ce qui signifie que nous pouvons facilement faire correspondre chaque "),ro=r(Xl,"EM",{});var af=o(ro);gu=a(af,"token"),af.forEach(s),Eu=a(Xl," au mot correspondant (comme on le voit au "),nl=r(Xl,"A",{href:!0});var lf=o(nl);qu=a(lf,"Chapitre 6"),lf.forEach(s),ku=a(Xl,") :"),Xl.forEach(s),Oi=c(t),w(rn.$$.fragment,t),Pi=c(t),w(Il.$$.fragment,t),Or=c(t),oe=r(t,"P",{});var Le=o(oe);oo=a(Le,"Avec un peu de travail, nous pouvons alors \xE9tendre notre liste d\u2019\xE9tiquettes pour qu\u2019elle corresponde aux "),io=r(Le,"EM",{});var rf=o(io);uo=a(rf,"tokens"),rf.forEach(s),ju=a(Le,". La premi\xE8re r\xE8gle que nous allons appliquer est que les "),Ze=r(Le,"EM",{});var of=o(Ze);wu=a(of,"tokens"),of.forEach(s),xu=a(Le," sp\xE9ciaux re\xE7oivent une \xE9tiquette de "),po=r(Le,"CODE",{});var uf=o(po);Cu=a(uf,"-100"),uf.forEach(s),yu=a(Le,". En effet, par d\xE9faut, "),co=r(Le,"CODE",{});var pf=o(co);zu=a(pf,"-100"),pf.forEach(s),mo=a(Le," est un indice qui est ignor\xE9 dans la fonction de perte que nous allons utiliser (entropie crois\xE9e). Ensuite, chaque "),fo=r(Le,"EM",{});var cf=o(fo);ho=a(cf,"token"),cf.forEach(s),Ou=a(Le," re\xE7oit la m\xEAme \xE9tiquette que le "),Rl=r(Le,"EM",{});var df=o(Rl);Pu=a(df,"token"),df.forEach(s),Du=a(Le," qui a commenc\xE9 le mot dans lequel il se trouve, puisqu\u2019ils font partie de la m\xEAme entit\xE9. Pour les "),lt=r(Le,"EM",{});var mf=o(lt);Mu=a(mf,"tokens"),mf.forEach(s),Au=a(Le," \xE0 l\u2019int\xE9rieur d\u2019un mot mais pas au d\xE9but, nous rempla\xE7ons le "),vo=r(Le,"CODE",{});var ff=o(vo);Nu=a(ff,"B-"),ff.forEach(s),_o=a(Le," par "),bo=r(Le,"CODE",{});var hf=o(bo);$o=a(hf,"I-"),hf.forEach(s),Tu=a(Le," (puisque le "),go=r(Le,"EM",{});var vf=o(go);Su=a(vf,"token"),vf.forEach(s),Eo=a(Le," ne commence pas l\u2019entit\xE9) :"),Le.forEach(s),Di=c(t),w(va.$$.fragment,t),Mi=c(t),Pr=r(t,"P",{});var _f=o(Pr);Lu=a(_f,"Essayons-le sur notre premi\xE8re phrase :"),_f.forEach(s),Rn=c(t),w(Fl.$$.fragment,t),Ai=c(t),w(Bl.$$.fragment,t),Ni=c(t),Be=r(t,"P",{});var Zl=o(Be);Iu=a(Zl,"Comme nous pouvons le voir, notre fonction a ajout\xE9 le "),qo=r(Zl,"CODE",{});var bf=o(qo);ko=a(bf,"-100"),bf.forEach(s),Ru=a(Zl," pour les deux "),on=r(Zl,"EM",{});var $f=o(on);Fu=a($f,"tokens"),$f.forEach(s),Bu=a(Zl," sp\xE9ciaux au d\xE9but et \xE0 la fin, et un nouveau "),jo=r(Zl,"CODE",{});var gf=o(jo);_a=a(gf,"0"),gf.forEach(s),Hu=a(Zl," pour notre mot qui a \xE9t\xE9 divis\xE9 en deux "),wo=r(Zl,"EM",{});var Ef=o(wo);Gu=a(Ef,"tokens"),Ef.forEach(s),Uu=a(Zl,"."),Zl.forEach(s),al=c(t),w(ll.$$.fragment,t),Ti=c(t),De=r(t,"P",{});var pn=o(De);Vu=a(pn,"Pour pr\xE9traiter notre ensemble de donn\xE9es, nous devons tokeniser toutes les entr\xE9es et appliquer "),xo=r(pn,"CODE",{});var qf=o(xo);Wu=a(qf,"align_labels_with_tokens()"),qf.forEach(s),Hl=a(pn," sur toutes les \xE9tiquettes. Pour profiter de la vitesse de notre "),Co=r(pn,"EM",{});var kf=o(Co);Xu=a(kf,"tokenizer"),kf.forEach(s),Zu=a(pn," rapide, il est pr\xE9f\xE9rable de tokeniser beaucoup de textes en m\xEAme temps, donc nous allons \xE9crire une fonction qui traite une liste d\u2019exemples et utiliser la m\xE9thode "),ba=r(pn,"CODE",{});var jf=o(ba);yo=a(jf,"Dataset.map()"),jf.forEach(s),Ku=a(pn," avec l\u2019option "),rt=r(pn,"CODE",{});var wf=o(rt);Yu=a(wf,"batched=True"),wf.forEach(s),Ju=a(pn,". La seule chose qui diff\xE8re de notre exemple pr\xE9c\xE9dent est que la fonction "),zo=r(pn,"CODE",{});var xf=o(zo);Qu=a(xf,"word_ids()"),xf.forEach(s),$a=a(pn," a besoin de r\xE9cup\xE9rer l\u2019index de l\u2019exemple dont nous voulons les IDs de mots lorsque les entr\xE9es du "),Oo=r(pn,"EM",{});var Cf=o(Oo);ep=a(Cf,"tokenizer"),Cf.forEach(s),sp=a(pn," sont des listes de textes (ou dans notre cas, des listes de mots), donc nous l\u2019ajoutons aussi :"),pn.forEach(s),Si=c(t),w(ga.$$.fragment,t),Li=c(t),Me=r(t,"P",{});var yf=o(Me);tp=a(yf,"Notez que nous n\u2019avons pas encore padd\xE9 nos entr\xE9es ; nous le ferons plus tard, lors de la cr\xE9ation des lots avec un collateur de donn\xE9es."),yf.forEach(s),Ii=c(t),Dr=r(t,"P",{});var zf=o(Dr);np=a(zf,"Nous pouvons maintenant appliquer tout ce pr\xE9traitement en une seule fois sur les autres divisions de notre jeu de donn\xE9es :"),zf.forEach(s),Ri=c(t),w(Gl.$$.fragment,t),Fi=c(t),Ls=r(t,"P",{});var wc=o(Ls);ap=a(wc,"Nous avons fait la partie la plus difficile ! Maintenant que les donn\xE9es ont \xE9t\xE9 pr\xE9trait\xE9es, l\u2019entra\xEEnement r\xE9el ressemblera beaucoup \xE0 ce que nous avons fait dans le "),Mr=r(wc,"A",{href:!0});var Of=o(Mr);lp=a(Of,"Chapitre 3"),Of.forEach(s),Oc=a(wc,"."),wc.forEach(s),Wp=c(t),ol.l(t),rp=c(t),Ar=r(t,"H3",{class:!0});var xc=o(Ar);Po=r(xc,"A",{id:!0,class:!0,href:!0});var Pf=o(Po);Op=r(Pf,"SPAN",{});var Df=o(Op);w(Bi.$$.fragment,Df),Df.forEach(s),Pf.forEach(s),Pc=c(xc),Pp=r(xc,"SPAN",{});var Mf=o(Pp);Dc=a(Mf,"Collation des donn\xE9es"),Mf.forEach(s),xc.forEach(s),Xp=c(t),un=r(t,"P",{});var Kl=o(un);Mc=a(Kl,"Nous ne pouvons pas simplement utiliser un "),Dp=r(Kl,"CODE",{});var Af=o(Dp);Ac=a(Af,"DataCollatorWithPadding"),Af.forEach(s),Nc=a(Kl," comme dans "),op=r(Kl,"A",{href:!0});var Nf=o(op);Tc=a(Nf,"Chapter 3"),Nf.forEach(s),Sc=a(Kl," parce que cela ne fait que rembourrer les entr\xE9es (IDs d\u2019entr\xE9e, masque d\u2019attention, et IDs de type de "),Mp=r(Kl,"EM",{});var Tf=o(Mp);Lc=a(Tf,"token"),Tf.forEach(s),Ic=a(Kl,"). Ici, nos \xE9tiquettes doivent \xEAtre remplies exactement de la m\xEAme mani\xE8re que les entr\xE9es afin qu\u2019elles gardent la m\xEAme taille, en utilisant "),Ap=r(Kl,"CODE",{});var Sf=o(Ap);Rc=a(Sf,"-100"),Sf.forEach(s),Fc=a(Kl," comme valeur afin que les pr\xE9dictions correspondantes soient ignor\xE9es dans le calcul de la perte."),Kl.forEach(s),Zp=c(t),Ea=r(t,"P",{});var No=o(Ea);Bc=a(No,"Tout ceci est fait par un "),Hi=r(No,"A",{href:!0,rel:!0});var Lf=o(Hi);Np=r(Lf,"CODE",{});var If=o(Np);Hc=a(If,"DataCollatorForTokenClassification"),If.forEach(s),Lf.forEach(s),Gc=a(No,". Comme le "),Tp=r(No,"CODE",{});var Rf=o(Tp);Uc=a(Rf,"DataCollatorWithPadding"),Rf.forEach(s),Vc=a(No,", il prend le "),Sp=r(No,"CODE",{});var Ff=o(Sp);Wc=a(Ff,"tokenizer"),Ff.forEach(s),Xc=a(No," utilis\xE9 pour pr\xE9traiter les entr\xE9es :"),No.forEach(s),Kp=c(t),ul.l(t),ip=c(t),up=r(t,"P",{});var Bf=o(up);Zc=a(Bf,"Pour tester cette fonction sur quelques \xE9chantillons, nous pouvons simplement l\u2019appeler sur une liste d\u2019exemples provenant de notre jeu d\u2019entra\xEEnement tok\xE9nis\xE9 :"),Bf.forEach(s),Yp=c(t),w(Gi.$$.fragment,t),Jp=c(t),w(Ui.$$.fragment,t),Qp=c(t),pp=r(t,"P",{});var Hf=o(pp);Kc=a(Hf,"Comparons cela aux \xE9tiquettes des premier et deuxi\xE8me \xE9l\xE9ments de notre jeu de donn\xE9es :"),Hf.forEach(s),ec=c(t),w(Vi.$$.fragment,t),sc=c(t),w(Wi.$$.fragment,t),tc=c(t),cl.l(t),cp=c(t),ps&&ps.l(t),dp=c(t),Nr=r(t,"H3",{class:!0});var Cc=o(Nr);Do=r(Cc,"A",{id:!0,class:!0,href:!0});var Gf=o(Do);Lp=r(Gf,"SPAN",{});var Uf=o(Lp);w(Xi.$$.fragment,Uf),Uf.forEach(s),Gf.forEach(s),Yc=c(Cc),Ip=r(Cc,"SPAN",{});var Vf=o(Ip);Jc=a(Vf,"M\xE9triques"),Vf.forEach(s),Cc.forEach(s),nc=c(t),ml.l(t),mp=c(t),w(Zi.$$.fragment,t),ac=c(t),fp=r(t,"P",{});var Wf=o(fp);Qc=a(Wf,"Cette m\xE9trique ne se comporte pas comme la pr\xE9cision standard : elle prend les listes d\u2019\xE9tiquettes comme des cha\xEEnes de caract\xE8res et non comme des entiers. Nous devrons donc d\xE9coder compl\xE8tement les pr\xE9dictions et les \xE9tiquettes avant de les transmettre \xE0 la m\xE9trique. Voyons comment cela fonctionne. Tout d\u2019abord, nous allons obtenir les \xE9tiquettes pour notre premier exemple d\u2019entra\xEEnement :"),Wf.forEach(s),lc=c(t),w(Ki.$$.fragment,t),rc=c(t),w(Yi.$$.fragment,t),oc=c(t),hp=r(t,"P",{});var Xf=o(hp);ed=a(Xf,"Nous pouvons alors cr\xE9er de fausses pr\xE9dictions pour celles-ci en changeant simplement la valeur de l\u2019indice 2 :"),Xf.forEach(s),ic=c(t),w(Ji.$$.fragment,t),uc=c(t),vp=r(t,"P",{});var Zf=o(vp);sd=a(Zf,"Notez que la m\xE9trique prend une liste de pr\xE9dictions (pas seulement une) et une liste d\u2019\xE9tiquettes. Voici la sortie :"),Zf.forEach(s),pc=c(t),w(Qi.$$.fragment,t),cc=c(t),hl.l(t),_p=c(t),cs&&cs.l(t),bp=c(t),Tr=r(t,"H3",{class:!0});var yc=o(Tr);Mo=r(yc,"A",{id:!0,class:!0,href:!0});var Kf=o(Mo);Rp=r(Kf,"SPAN",{});var Yf=o(Rp);w(eu.$$.fragment,Yf),Yf.forEach(s),Kf.forEach(s),td=c(yc),Fp=r(yc,"SPAN",{});var Jf=o(Fp);nd=a(Jf,"Utilisation du mod\xE8le *finetun\xE9*"),Jf.forEach(s),yc.forEach(s),dc=c(t),qa=r(t,"P",{});var To=o(qa);ad=a(To,"Nous vous avons d\xE9j\xE0 montr\xE9 comment vous pouvez utiliser le mod\xE8le que nous avons affin\xE9 sur le "),Bp=r(To,"EM",{});var Qf=o(Bp);ld=a(Qf,"Hub"),Qf.forEach(s),rd=a(To," avec le "),Hp=r(To,"EM",{});var eh=o(Hp);od=a(eh,"widget"),eh.forEach(s),id=a(To," d\u2019inf\xE9rence. Pour l\u2019utiliser localement dans un "),Gp=r(To,"CODE",{});var sh=o(Gp);ud=a(sh,"pipeline"),sh.forEach(s),pd=a(To,", vous devez juste sp\xE9cifier l\u2019identifiant de mod\xE8le appropri\xE9 :"),To.forEach(s),mc=c(t),w(su.$$.fragment,t),fc=c(t),w(tu.$$.fragment,t),hc=c(t),$p=r(t,"P",{});var th=o($p);cd=a(th,"Super ! Notre mod\xE8le fonctionne aussi bien que le mod\xE8le par d\xE9faut pour ce pipeline !"),th.forEach(s),this.h()},h(){_(d,"name","hf:doc:metadata"),_(d,"content",JSON.stringify(Nh)),_($,"id","classification-de-tokens"),_($,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_($,"href","#classification-de-tokens"),_(z,"class","relative group"),zc(be.src,vl="https://hf.space/gradioiframe/course-demos/bert-finetuned-ner/+")||_(be,"src",vl),_(be,"frameborder","0"),_(be,"height","350"),_(be,"title","Gradio app"),_(be,"class","block dark:hidden container p-0 flex-grow space-iframe"),_(be,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),_(be,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),zc(qe.src,Nt="https://hf.space/gradioiframe/course-demos/bert-finetuned-ner-darkmode/+")||_(qe,"src",Nt),_(qe,"frameborder","0"),_(qe,"height","350"),_(qe,"title","Gradio app"),_(qe,"class","hidden dark:block container p-0 flex-grow space-iframe"),_(qe,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),_(qe,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),_(ss,"class","block dark:hidden lg:w-3/5"),zc(ss.src,En="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/model-eval-bert-finetuned-ner.png")||_(ss,"src",En),_(ss,"alt","One-hot encoded labels for question answering."),_(dt,"class","hidden dark:block lg:w-3/5"),zc(dt.src,qn="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/model-eval-bert-finetuned-ner-dark.png")||_(dt,"src",qn),_(dt,"alt","One-hot encoded labels for question answering."),_(ke,"class","flex justify-center"),_(ke,"href","/huggingface-course/bert-finetuned-ner"),_(ts,"href","https://huggingface.co/huggingface-course/bert-finetuned-ner?text=My+nom+est+Sylvain+et+je+travaille+%C3%A0+Hugging+Face+in+Brooklyn"),_(ts,"rel","nofollow"),_(Fe,"id","prparation-des-donnes"),_(Fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Fe,"href","#prparation-des-donnes"),_(Ge,"class","relative group"),_(ls,"href","https://huggingface.co/datasets/conll2003"),_(ls,"rel","nofollow"),_(Ne,"id","le-jeu-de-donnes-conll2003"),_(Ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Ne,"href","#le-jeu-de-donnes-conll2003"),_(xs,"class","relative group"),_(Cs,"href","/course/fr/chapter3"),_(Ct,"href","/course/fr/chapter6/3"),_(ln,"id","traitement-des-donnes"),_(ln,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(ln,"href","#traitement-des-donnes"),_(Es,"class","relative group"),_(Ga,"href","/course/fr/chapter6/"),_(Xa,"href","https://huggingface.co/models"),_(Xa,"rel","nofollow"),_(Za,"href","https://huggingface.co/transformers/#supported-frameworks"),_(Za,"rel","nofollow"),_(nl,"href","/course/fr/chapter6/3"),_(Mr,"href","/course/fr/chapter3"),_(Po,"id","collation-des-donnes"),_(Po,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Po,"href","#collation-des-donnes"),_(Ar,"class","relative group"),_(op,"href","/course/fr/chapter3"),_(Hi,"href","https://huggingface.co/transformers/main_classes/data_collator.html#datacollatorfortokenclassification"),_(Hi,"rel","nofollow"),_(Do,"id","mtriques"),_(Do,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Do,"href","#mtriques"),_(Nr,"class","relative group"),_(Mo,"id","utilisation-du-modle-finetun"),_(Mo,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(Mo,"href","#utilisation-du-modle-finetun"),_(Tr,"class","relative group")},m(t,m){e(document.head,d),u(t,E,m),x(h,t,m),u(t,q,m),u(t,z,m),e(z,$),e($,k),x(O,k,null),e(z,y),e(z,P),e(P,H),u(t,D,m),nu[L].m(t,m),u(t,A,m),u(t,N,m),e(N,Y),e(N,G),e(G,X),e(N,J),e(N,K),e(K,Q),e(N,T),u(t,F,m),u(t,S,m),e(S,W),e(W,ae),e(ae,ve),e(W,te),e(W,de),e(de,he),e(W,_e),e(S,U),e(S,B),e(B,Z),e(Z,we),e(B,Ie),e(S,xe),e(S,ee),e(ee,le),e(le,Ye),e(Ye,ks),e(ee,Ce),e(ee,Ee),e(Ee,Rs),e(ee,re),e(ee,cn),e(cn,it),e(ee,ja),e(ee,dn),e(dn,js),e(ee,wa),e(ee,mn),e(mn,ut),e(ee,xa),e(ee,fn),e(fn,hn),e(ee,Je),e(ee,pt),e(pt,Qe),e(ee,vn),e(ee,Re),e(Re,_n),e(ee,ye),u(t,Ae,m),x(es,t,m),u(t,He,m),u(t,Fs,m),e(Fs,ct),e(Fs,bn),e(bn,$n),e(Fs,ze),u(t,Fn,m),u(t,be,m),u(t,Bn,m),u(t,qe,m),u(t,gn,m),u(t,ke,m),e(ke,ss),e(ke,Bs),e(ke,dt),u(t,ws,m),u(t,ds,m),e(ds,Tt),e(ds,ms),e(ms,Ca),e(ds,St),e(ds,ts),e(ts,Hn),e(ds,Oe),u(t,Hs,m),u(t,Ge,m),e(Ge,Fe),e(Fe,kn),x(ns,kn,null),e(Ge,ya),e(Ge,jn),e(jn,Lt),u(t,Gs,m),u(t,as,m),e(as,ie),e(as,wn),e(wn,xn),e(as,Gn),e(as,ls),e(ls,It),e(as,fs),u(t,Un,m),x(Ue,t,m),u(t,Vn,m),u(t,xs,m),e(xs,Ne),e(Ne,mt),x(ft,mt,null),e(xs,Wn),e(xs,je),e(je,za),u(t,Rt,m),u(t,Ve,m),e(Ve,Oa),e(Ve,ht),e(ht,Xn),e(Ve,vt),e(Ve,Us),e(Us,Vs),e(Ve,Pa),u(t,_t,m),x(rs,t,m),u(t,Cn,m),u(t,ue,m),e(ue,bt),e(ue,Cs),e(Cs,Ws),e(ue,Da),u(t,hs,m),x(ys,t,m),u(t,Zn,m),x(Xs,t,m),u(t,os,m),u(t,We,m),e(We,yn),e(We,$t),e($t,Ma),e(We,Kn),e(We,vs),e(vs,Zs),e(We,gt),e(We,_s),e(_s,Yn),e(We,zs),u(t,zn,m),u(t,$e,m),e($e,Jn),u(t,ge,m),x(Et,t,m),u(t,Ft,m),x(Os,t,m),u(t,Qn,m),u(t,Ks,m),e(Ks,On),u(t,ea,m),x(Ps,t,m),u(t,Bt,m),x(qt,t,m),u(t,Ht,m),u(t,Ds,m),e(Ds,Ys),e(Ds,Gt),e(Gt,f),e(Ds,I),u(t,Aa,m),x(kt,t,m),u(t,Ms,m),x(me,t,m),u(t,Pn,m),u(t,fe,m),e(fe,_l),e(fe,Ut),e(Ut,Vt),e(fe,Na),e(fe,As),e(As,Wt),e(fe,Dn),e(fe,sa),e(sa,Js),e(fe,Ta),e(fe,bs),e(bs,jt),e(fe,Xt),e(fe,Qs),e(Qs,bl),e(fe,ta),u(t,Mn,m),x(wt,t,m),u(t,Te,m),x(Zt,t,m),u(t,xt,m),u(t,Ns,m),e(Ns,$s),e(Ns,Kt),e(Kt,$l),e(Ns,gl),e(Ns,Ct),e(Ct,Yt),e(Ns,El),u(t,na,m),u(t,ne,m),e(ne,Jt),e(Jt,yt),e(yt,ql),e(Jt,is),e(ne,Qt),e(ne,gs),e(gs,us),e(us,kl),e(gs,aa),e(gs,en),e(en,jl),e(gs,Xe),e(gs,la),e(la,wl),e(gs,Sa),e(ne,sn),e(ne,zt),e(zt,tn),e(tn,Ro),e(zt,Yl),e(zt,Jl),e(Jl,Fo),e(zt,Ir),e(zt,An),e(An,Rr),e(zt,La),e(ne,Fr),e(ne,Pe),e(Pe,Ql),e(Ql,er),e(Pe,Bo),e(Pe,sr),e(sr,tr),e(Pe,Ho),e(Pe,nr),e(nr,ar),e(Pe,Go),e(ne,Uo),e(ne,Ot),e(Ot,Nn),e(Nn,Br),e(Ot,et),e(Ot,lr),e(lr,rr),e(Ot,Vo),e(Ot,or),e(or,ir),e(Ot,Wo),u(t,Hr,m),u(t,ra,m),e(ra,Xo),u(t,Gr,m),x(oa,t,m),u(t,ia,m),x(ua,t,m),u(t,pa,m),u(t,Pt,m),e(Pt,xl),e(Pt,ur),e(ur,Ur),e(Pt,Ia),e(Pt,Cl),e(Cl,nn),e(Pt,Zo),u(t,yl,m),x(Ra,t,m),u(t,Vr,m),u(t,ca,m),e(ca,Ko),u(t,Wr,m),x(Tn,t,m),u(t,an,m),u(t,Es,m),e(Es,ln),e(ln,Sn),x(Fa,Sn,null),e(Es,pr),e(Es,cr),e(cr,Xr),u(t,Dt,m),x(Ba,t,m),u(t,zl,m),u(t,qs,m),e(qs,Yo),e(qs,Ha),e(Ha,Jo),e(qs,Qo),e(qs,Ga),e(Ga,Ua),e(qs,Zr),e(qs,da),e(da,ei),e(qs,Kr),e(qs,st),e(st,Va),e(qs,si),u(t,Ol,m),u(t,ma,m),e(ma,ti),e(ma,dr),e(dr,Ts),e(ma,ni),u(t,Pl,m),x(Wa,t,m),u(t,Yr,m),u(t,se,m),e(se,ai),e(se,mr),e(mr,fr),e(se,li),e(se,hr),e(hr,vr),e(se,ri),e(se,Xa),e(Xa,oi),e(se,Mt),e(se,_r),e(_r,br),e(se,ii),e(se,$r),e($r,gr),e(se,ui),e(se,Er),e(Er,qr),e(se,pi),e(se,Za),e(Za,Jr),e(se,Dl),e(se,kr),e(kr,Qr),e(se,Ka),e(se,Ml),e(Ml,fa),e(se,ci),e(se,Ya),e(Ya,di),e(se,mi),u(t,jr,m),x(At,t,m),u(t,wr,m),x(pe,t,m),u(t,eo,m),u(t,tt,m),e(tt,fi),e(tt,xr),e(xr,Cr),e(tt,hi),e(tt,yr),e(yr,zr),e(tt,vi),u(t,so,m),x(Ln,t,m),u(t,to,m),x(Ja,t,m),u(t,Al,m),u(t,ce,m),e(ce,_i),e(ce,Qa),e(Qa,bi),e(ce,$i),e(ce,el),e(el,gi),e(ce,Ei),e(ce,Nl),e(Nl,nt),e(ce,qi),e(ce,sl),e(sl,ki),e(ce,ji),e(ce,tl),e(tl,wi),e(ce,xi),e(ce,In),e(In,Ci),e(ce,yi),e(ce,Tl),e(Tl,i),e(ce,v),e(ce,no),e(no,fu),e(ce,hu),e(ce,at),e(at,vu),e(ce,_u),u(t,zi,m),u(t,Ss,m),e(Ss,Sl),e(Ss,ao),e(ao,bu),e(Ss,Ll),e(Ss,lo),e(lo,$u),e(Ss,ha),e(Ss,ro),e(ro,gu),e(Ss,Eu),e(Ss,nl),e(nl,qu),e(Ss,ku),u(t,Oi,m),x(rn,t,m),u(t,Pi,m),x(Il,t,m),u(t,Or,m),u(t,oe,m),e(oe,oo),e(oe,io),e(io,uo),e(oe,ju),e(oe,Ze),e(Ze,wu),e(oe,xu),e(oe,po),e(po,Cu),e(oe,yu),e(oe,co),e(co,zu),e(oe,mo),e(oe,fo),e(fo,ho),e(oe,Ou),e(oe,Rl),e(Rl,Pu),e(oe,Du),e(oe,lt),e(lt,Mu),e(oe,Au),e(oe,vo),e(vo,Nu),e(oe,_o),e(oe,bo),e(bo,$o),e(oe,Tu),e(oe,go),e(go,Su),e(oe,Eo),u(t,Di,m),x(va,t,m),u(t,Mi,m),u(t,Pr,m),e(Pr,Lu),u(t,Rn,m),x(Fl,t,m),u(t,Ai,m),x(Bl,t,m),u(t,Ni,m),u(t,Be,m),e(Be,Iu),e(Be,qo),e(qo,ko),e(Be,Ru),e(Be,on),e(on,Fu),e(Be,Bu),e(Be,jo),e(jo,_a),e(Be,Hu),e(Be,wo),e(wo,Gu),e(Be,Uu),u(t,al,m),x(ll,t,m),u(t,Ti,m),u(t,De,m),e(De,Vu),e(De,xo),e(xo,Wu),e(De,Hl),e(De,Co),e(Co,Xu),e(De,Zu),e(De,ba),e(ba,yo),e(De,Ku),e(De,rt),e(rt,Yu),e(De,Ju),e(De,zo),e(zo,Qu),e(De,$a),e(De,Oo),e(Oo,ep),e(De,sp),u(t,Si,m),x(ga,t,m),u(t,Li,m),u(t,Me,m),e(Me,tp),u(t,Ii,m),u(t,Dr,m),e(Dr,np),u(t,Ri,m),x(Gl,t,m),u(t,Fi,m),u(t,Ls,m),e(Ls,ap),e(Ls,Mr),e(Mr,lp),e(Ls,Oc),u(t,Wp,m),au[rl].m(t,m),u(t,rp,m),u(t,Ar,m),e(Ar,Po),e(Po,Op),x(Bi,Op,null),e(Ar,Pc),e(Ar,Pp),e(Pp,Dc),u(t,Xp,m),u(t,un,m),e(un,Mc),e(un,Dp),e(Dp,Ac),e(un,Nc),e(un,op),e(op,Tc),e(un,Sc),e(un,Mp),e(Mp,Lc),e(un,Ic),e(un,Ap),e(Ap,Rc),e(un,Fc),u(t,Zp,m),u(t,Ea,m),e(Ea,Bc),e(Ea,Hi),e(Hi,Np),e(Np,Hc),e(Ea,Gc),e(Ea,Tp),e(Tp,Uc),e(Ea,Vc),e(Ea,Sp),e(Sp,Wc),e(Ea,Xc),u(t,Kp,m),lu[il].m(t,m),u(t,ip,m),u(t,up,m),e(up,Zc),u(t,Yp,m),x(Gi,t,m),u(t,Jp,m),x(Ui,t,m),u(t,Qp,m),u(t,pp,m),e(pp,Kc),u(t,ec,m),x(Vi,t,m),u(t,sc,m),x(Wi,t,m),u(t,tc,m),ru[pl].m(t,m),u(t,cp,m),ps&&ps.m(t,m),u(t,dp,m),u(t,Nr,m),e(Nr,Do),e(Do,Lp),x(Xi,Lp,null),e(Nr,Yc),e(Nr,Ip),e(Ip,Jc),u(t,nc,m),ou[dl].m(t,m),u(t,mp,m),x(Zi,t,m),u(t,ac,m),u(t,fp,m),e(fp,Qc),u(t,lc,m),x(Ki,t,m),u(t,rc,m),x(Yi,t,m),u(t,oc,m),u(t,hp,m),e(hp,ed),u(t,ic,m),x(Ji,t,m),u(t,uc,m),u(t,vp,m),e(vp,sd),u(t,pc,m),x(Qi,t,m),u(t,cc,m),iu[fl].m(t,m),u(t,_p,m),cs&&cs.m(t,m),u(t,bp,m),u(t,Tr,m),e(Tr,Mo),e(Mo,Rp),x(eu,Rp,null),e(Tr,td),e(Tr,Fp),e(Fp,nd),u(t,dc,m),u(t,qa,m),e(qa,ad),e(qa,Bp),e(Bp,ld),e(qa,rd),e(qa,Hp),e(Hp,od),e(qa,id),e(qa,Gp),e(Gp,ud),e(qa,pd),u(t,mc,m),x(su,t,m),u(t,fc,m),x(tu,t,m),u(t,hc,m),u(t,$p,m),e($p,cd),vc=!0},p(t,[m]){const uu={};m&1&&(uu.fw=t[0]),h.$set(uu);let gp=L;L=hd(t),L!==gp&&(Lo(),g(nu[gp],1,1,()=>{nu[gp]=null}),So(),R=nu[L],R||(R=nu[L]=fd[L](t),R.c()),b(R,1),R.m(A.parentNode,A));const Up={};m&2&&(Up.$$scope={dirty:m,ctx:t}),Ue.$set(Up);const Vp={};m&2&&(Vp.$$scope={dirty:m,ctx:t}),Tn.$set(Vp);const Sr={};m&2&&(Sr.$$scope={dirty:m,ctx:t}),ll.$set(Sr);let Ep=rl;rl=_d(t),rl!==Ep&&(Lo(),g(au[Ep],1,1,()=>{au[Ep]=null}),So(),ol=au[rl],ol||(ol=au[rl]=vd[rl](t),ol.c()),b(ol,1),ol.m(rp.parentNode,rp));let qp=il;il=$d(t),il!==qp&&(Lo(),g(lu[qp],1,1,()=>{lu[qp]=null}),So(),ul=lu[il],ul||(ul=lu[il]=bd[il](t),ul.c()),b(ul,1),ul.m(ip.parentNode,ip));let Ul=pl;pl=Ed(t),pl!==Ul&&(Lo(),g(ru[Ul],1,1,()=>{ru[Ul]=null}),So(),cl=ru[pl],cl||(cl=ru[pl]=gd[pl](t),cl.c()),b(cl,1),cl.m(cp.parentNode,cp)),t[0]==="tf"?ps?m&1&&b(ps,1):(ps=lh(t),ps.c(),b(ps,1),ps.m(dp.parentNode,dp)):ps&&(Lo(),g(ps,1,1,()=>{ps=null}),So());let Lr=dl;dl=kd(t),dl!==Lr&&(Lo(),g(ou[Lr],1,1,()=>{ou[Lr]=null}),So(),ml=ou[dl],ml||(ml=ou[dl]=qd[dl](t),ml.c()),b(ml,1),ml.m(mp.parentNode,mp));let kp=fl;fl=wd(t),fl!==kp&&(Lo(),g(iu[kp],1,1,()=>{iu[kp]=null}),So(),hl=iu[fl],hl||(hl=iu[fl]=jd[fl](t),hl.c()),b(hl,1),hl.m(_p.parentNode,_p)),t[0]==="pt"?cs?m&1&&b(cs,1):(cs=rh(t),cs.c(),b(cs,1),cs.m(bp.parentNode,bp)):cs&&(Lo(),g(cs,1,1,()=>{cs=null}),So())},i(t){vc||(b(h.$$.fragment,t),b(O.$$.fragment,t),b(R),b(es.$$.fragment,t),b(ns.$$.fragment,t),b(Ue.$$.fragment,t),b(ft.$$.fragment,t),b(rs.$$.fragment,t),b(ys.$$.fragment,t),b(Xs.$$.fragment,t),b(Et.$$.fragment,t),b(Os.$$.fragment,t),b(Ps.$$.fragment,t),b(qt.$$.fragment,t),b(kt.$$.fragment,t),b(me.$$.fragment,t),b(wt.$$.fragment,t),b(Zt.$$.fragment,t),b(oa.$$.fragment,t),b(ua.$$.fragment,t),b(Ra.$$.fragment,t),b(Tn.$$.fragment,t),b(Fa.$$.fragment,t),b(Ba.$$.fragment,t),b(Wa.$$.fragment,t),b(At.$$.fragment,t),b(pe.$$.fragment,t),b(Ln.$$.fragment,t),b(Ja.$$.fragment,t),b(rn.$$.fragment,t),b(Il.$$.fragment,t),b(va.$$.fragment,t),b(Fl.$$.fragment,t),b(Bl.$$.fragment,t),b(ll.$$.fragment,t),b(ga.$$.fragment,t),b(Gl.$$.fragment,t),b(ol),b(Bi.$$.fragment,t),b(ul),b(Gi.$$.fragment,t),b(Ui.$$.fragment,t),b(Vi.$$.fragment,t),b(Wi.$$.fragment,t),b(cl),b(ps),b(Xi.$$.fragment,t),b(ml),b(Zi.$$.fragment,t),b(Ki.$$.fragment,t),b(Yi.$$.fragment,t),b(Ji.$$.fragment,t),b(Qi.$$.fragment,t),b(hl),b(cs),b(eu.$$.fragment,t),b(su.$$.fragment,t),b(tu.$$.fragment,t),vc=!0)},o(t){g(h.$$.fragment,t),g(O.$$.fragment,t),g(R),g(es.$$.fragment,t),g(ns.$$.fragment,t),g(Ue.$$.fragment,t),g(ft.$$.fragment,t),g(rs.$$.fragment,t),g(ys.$$.fragment,t),g(Xs.$$.fragment,t),g(Et.$$.fragment,t),g(Os.$$.fragment,t),g(Ps.$$.fragment,t),g(qt.$$.fragment,t),g(kt.$$.fragment,t),g(me.$$.fragment,t),g(wt.$$.fragment,t),g(Zt.$$.fragment,t),g(oa.$$.fragment,t),g(ua.$$.fragment,t),g(Ra.$$.fragment,t),g(Tn.$$.fragment,t),g(Fa.$$.fragment,t),g(Ba.$$.fragment,t),g(Wa.$$.fragment,t),g(At.$$.fragment,t),g(pe.$$.fragment,t),g(Ln.$$.fragment,t),g(Ja.$$.fragment,t),g(rn.$$.fragment,t),g(Il.$$.fragment,t),g(va.$$.fragment,t),g(Fl.$$.fragment,t),g(Bl.$$.fragment,t),g(ll.$$.fragment,t),g(ga.$$.fragment,t),g(Gl.$$.fragment,t),g(ol),g(Bi.$$.fragment,t),g(ul),g(Gi.$$.fragment,t),g(Ui.$$.fragment,t),g(Vi.$$.fragment,t),g(Wi.$$.fragment,t),g(cl),g(ps),g(Xi.$$.fragment,t),g(ml),g(Zi.$$.fragment,t),g(Ki.$$.fragment,t),g(Yi.$$.fragment,t),g(Ji.$$.fragment,t),g(Qi.$$.fragment,t),g(hl),g(cs),g(eu.$$.fragment,t),g(su.$$.fragment,t),g(tu.$$.fragment,t),vc=!1},d(t){s(d),t&&s(E),C(h,t),t&&s(q),t&&s(z),C(O),t&&s(D),nu[L].d(t),t&&s(A),t&&s(N),t&&s(F),t&&s(S),t&&s(Ae),C(es,t),t&&s(He),t&&s(Fs),t&&s(Fn),t&&s(be),t&&s(Bn),t&&s(qe),t&&s(gn),t&&s(ke),t&&s(ws),t&&s(ds),t&&s(Hs),t&&s(Ge),C(ns),t&&s(Gs),t&&s(as),t&&s(Un),C(Ue,t),t&&s(Vn),t&&s(xs),C(ft),t&&s(Rt),t&&s(Ve),t&&s(_t),C(rs,t),t&&s(Cn),t&&s(ue),t&&s(hs),C(ys,t),t&&s(Zn),C(Xs,t),t&&s(os),t&&s(We),t&&s(zn),t&&s($e),t&&s(ge),C(Et,t),t&&s(Ft),C(Os,t),t&&s(Qn),t&&s(Ks),t&&s(ea),C(Ps,t),t&&s(Bt),C(qt,t),t&&s(Ht),t&&s(Ds),t&&s(Aa),C(kt,t),t&&s(Ms),C(me,t),t&&s(Pn),t&&s(fe),t&&s(Mn),C(wt,t),t&&s(Te),C(Zt,t),t&&s(xt),t&&s(Ns),t&&s(na),t&&s(ne),t&&s(Hr),t&&s(ra),t&&s(Gr),C(oa,t),t&&s(ia),C(ua,t),t&&s(pa),t&&s(Pt),t&&s(yl),C(Ra,t),t&&s(Vr),t&&s(ca),t&&s(Wr),C(Tn,t),t&&s(an),t&&s(Es),C(Fa),t&&s(Dt),C(Ba,t),t&&s(zl),t&&s(qs),t&&s(Ol),t&&s(ma),t&&s(Pl),C(Wa,t),t&&s(Yr),t&&s(se),t&&s(jr),C(At,t),t&&s(wr),C(pe,t),t&&s(eo),t&&s(tt),t&&s(so),C(Ln,t),t&&s(to),C(Ja,t),t&&s(Al),t&&s(ce),t&&s(zi),t&&s(Ss),t&&s(Oi),C(rn,t),t&&s(Pi),C(Il,t),t&&s(Or),t&&s(oe),t&&s(Di),C(va,t),t&&s(Mi),t&&s(Pr),t&&s(Rn),C(Fl,t),t&&s(Ai),C(Bl,t),t&&s(Ni),t&&s(Be),t&&s(al),C(ll,t),t&&s(Ti),t&&s(De),t&&s(Si),C(ga,t),t&&s(Li),t&&s(Me),t&&s(Ii),t&&s(Dr),t&&s(Ri),C(Gl,t),t&&s(Fi),t&&s(Ls),t&&s(Wp),au[rl].d(t),t&&s(rp),t&&s(Ar),C(Bi),t&&s(Xp),t&&s(un),t&&s(Zp),t&&s(Ea),t&&s(Kp),lu[il].d(t),t&&s(ip),t&&s(up),t&&s(Yp),C(Gi,t),t&&s(Jp),C(Ui,t),t&&s(Qp),t&&s(pp),t&&s(ec),C(Vi,t),t&&s(sc),C(Wi,t),t&&s(tc),ru[pl].d(t),t&&s(cp),ps&&ps.d(t),t&&s(dp),t&&s(Nr),C(Xi),t&&s(nc),ou[dl].d(t),t&&s(mp),C(Zi,t),t&&s(ac),t&&s(fp),t&&s(lc),C(Ki,t),t&&s(rc),C(Yi,t),t&&s(oc),t&&s(hp),t&&s(ic),C(Ji,t),t&&s(uc),t&&s(vp),t&&s(pc),C(Qi,t),t&&s(cc),iu[fl].d(t),t&&s(_p),cs&&cs.d(t),t&&s(bp),t&&s(Tr),C(eu),t&&s(dc),t&&s(qa),t&&s(mc),C(su,t),t&&s(fc),C(tu,t),t&&s(hc),t&&s($p)}}}const Nh={local:"classification-de-tokens",sections:[{local:"prparation-des-donnes",sections:[{local:"le-jeu-de-donnes-conll2003",title:"Le jeu de donn\xE9es CoNLL-2003"},{local:"traitement-des-donnes",title:"Traitement des donn\xE9es"}],title:"Pr\xE9paration des donn\xE9es"},{local:"finetuning-du-modle-avec-lapi-trainer",title:"*Finetuning* du mod\xE8le avec l'API `Trainer`."},{local:"finetuning-fin-du-modle-avec-keras",sections:[{local:"collation-des-donnes",title:"Collation des donn\xE9es"},{local:"dfinir-le-modle",title:"D\xE9finir le mod\xE8le"},{local:"finetuning-du-modle",title:"*Finetuning* du mod\xE8le"},{local:"mtriques",title:"M\xE9triques"},{local:"dfinir-le-modle",title:"D\xE9finir le mod\xE8le"},{local:"finetuning-du-modle",title:"*Finetuning* du mod\xE8le"}],title:"*Finetuning* fin du mod\xE8le avec Keras"},{local:"une-boucle-dentranement-personnalise",sections:[{local:"prparer-tout-pour-lentranement",title:"Pr\xE9parer tout pour l'entra\xEEnement"},{local:"boucle-dentranement",title:"Boucle d'entra\xEEnement"},{local:"utilisation-du-modle-finetun",title:"Utilisation du mod\xE8le *finetun\xE9*"}],title:"Une boucle d'entra\xEEnement personnalis\xE9e"}],title:"Classification de *tokens*"};function Th(V,d,E){let h="pt";return dh(()=>{const q=new URLSearchParams(window.location.search);E(0,h=q.get("fw")||"pt")}),[h]}class Gh extends ih{constructor(d){super();uh(this,d,Th,Ah,ph,{})}}export{Gh as default,Nh as metadata};
