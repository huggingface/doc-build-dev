import{S as rz,i as oz,s as lz,e as l,k as f,w as k,t as n,M as az,c as a,d as t,m as c,a as p,x as m,h as r,b as h,N as nz,G as s,g as i,y as d,q as _,o as $,B as u,v as iz}from"../../chunks/vendor-hf-doc-builder.js";import{T as pz}from"../../chunks/Tip-hf-doc-builder.js";import{Y as fz}from"../../chunks/Youtube-hf-doc-builder.js";import{I as dl}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as z}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as cz}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";function kz(_l){let E,ne,L,F,J,V,fs,Z,cs,De,S,Ce,re,ve,ye,P,Q,ks,ms,ee,ds,_s,se,$s,us,te,zs;return{c(){E=l("p"),ne=l("strong"),L=n("\u0E23\u0E32\u0E22\u0E25\u0E30\u0E40\u0E2D\u0E35\u0E22\u0E14\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E40\u0E15\u0E34\u0E21"),F=n(" \u0E16\u0E49\u0E32\u0E04\u0E38\u0E13\u0E17\u0E14\u0E25\u0E2D\u0E07\u0E43\u0E0A\u0E49\u0E07\u0E32\u0E19 normalizer \u0E17\u0E31\u0E49\u0E07\u0E2A\u0E2D\u0E07\u0E40\u0E27\u0E2D\u0E23\u0E4C\u0E0A\u0E31\u0E19\u0E01\u0E31\u0E1A\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E17\u0E35\u0E48\u0E21\u0E35\u0E15\u0E31\u0E27\u0E2D\u0E31\u0E01\u0E29\u0E23 unicode "),J=l("code"),V=n('u"\\u0085"'),fs=n(` \u0E04\u0E38\u0E13\u0E08\u0E30\u0E44\u0E14\u0E49\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E17\u0E35\u0E48\u0E41\u0E15\u0E01\u0E15\u0E48\u0E32\u0E07\u0E01\u0E31\u0E19
\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E44\u0E23\u0E01\u0E47\u0E15\u0E32\u0E21 \u0E40\u0E23\u0E32\u0E44\u0E21\u0E48\u0E2D\u0E22\u0E32\u0E01\u0E17\u0E33\u0E43\u0E2B\u0E49\u0E40\u0E27\u0E2D\u0E23\u0E4C\u0E0A\u0E31\u0E19\u0E17\u0E35\u0E48\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E08\u0E32\u0E01 `),Z=l("code"),cs=n("normalizers.Sequence"),De=n(" \u0E02\u0E2D\u0E07\u0E40\u0E23\u0E32\u0E19\u0E31\u0E49\u0E19\u0E0B\u0E31\u0E1A\u0E0B\u0E49\u0E2D\u0E19\u0E40\u0E01\u0E34\u0E19\u0E44\u0E1B \u0E40\u0E23\u0E32\u0E08\u0E36\u0E07\u0E44\u0E21\u0E48\u0E43\u0E0A\u0E49 Regex \u0E17\u0E35\u0E48 "),S=l("code"),Ce=n("BertNormalizer"),re=n(" \u0E43\u0E0A\u0E49\u0E40\u0E27\u0E25\u0E32\u0E17\u0E35\u0E48 "),ve=l("code"),ye=n("clean_text"),P=n(" \u0E16\u0E39\u0E01\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32\u0E40\u0E1B\u0E47\u0E19 "),Q=l("code"),ks=n("True"),ms=n(` \u0E0B\u0E36\u0E48\u0E07\u0E40\u0E1B\u0E47\u0E19\u0E04\u0E48\u0E32\u0E15\u0E31\u0E49\u0E07\u0E15\u0E49\u0E19
\u0E41\u0E15\u0E48\u0E04\u0E38\u0E13\u0E44\u0E21\u0E48\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E31\u0E07\u0E27\u0E25\u0E44\u0E1B \u0E40\u0E1E\u0E23\u0E32\u0E30\u0E21\u0E31\u0E19\u0E22\u0E31\u0E07\u0E21\u0E35\u0E27\u0E34\u0E18\u0E35\u0E17\u0E35\u0E48\u0E08\u0E30\u0E17\u0E33\u0E43\u0E2B\u0E49\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E2D\u0E2D\u0E01\u0E21\u0E32\u0E40\u0E1B\u0E47\u0E19\u0E40\u0E2B\u0E21\u0E37\u0E2D\u0E19\u0E01\u0E31\u0E19\u0E42\u0E14\u0E22\u0E17\u0E35\u0E48\u0E44\u0E21\u0E48\u0E15\u0E49\u0E2D\u0E07\u0E43\u0E0A\u0E49 `),ee=l("code"),ds=n("BertNormalizer"),_s=n(" \u0E19\u0E31\u0E48\u0E19\u0E04\u0E37\u0E2D\u0E42\u0E14\u0E22\u0E01\u0E32\u0E23\u0E40\u0E1E\u0E34\u0E48\u0E21 "),se=l("code"),$s=n("normalizers.Replace"),us=n(" \u0E2A\u0E2D\u0E07\u0E04\u0E23\u0E31\u0E49\u0E07 \u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E43\u0E19 "),te=l("code"),zs=n("normalizers.Sequence")},l(oe){E=a(oe,"P",{});var j=p(E);ne=a(j,"STRONG",{});var nn=p(ne);L=r(nn,"\u0E23\u0E32\u0E22\u0E25\u0E30\u0E40\u0E2D\u0E35\u0E22\u0E14\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E40\u0E15\u0E34\u0E21"),nn.forEach(t),F=r(j," \u0E16\u0E49\u0E32\u0E04\u0E38\u0E13\u0E17\u0E14\u0E25\u0E2D\u0E07\u0E43\u0E0A\u0E49\u0E07\u0E32\u0E19 normalizer \u0E17\u0E31\u0E49\u0E07\u0E2A\u0E2D\u0E07\u0E40\u0E27\u0E2D\u0E23\u0E4C\u0E0A\u0E31\u0E19\u0E01\u0E31\u0E1A\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E17\u0E35\u0E48\u0E21\u0E35\u0E15\u0E31\u0E27\u0E2D\u0E31\u0E01\u0E29\u0E23 unicode "),J=a(j,"CODE",{});var hs=p(J);V=r(hs,'u"\\u0085"'),hs.forEach(t),fs=r(j,` \u0E04\u0E38\u0E13\u0E08\u0E30\u0E44\u0E14\u0E49\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E17\u0E35\u0E48\u0E41\u0E15\u0E01\u0E15\u0E48\u0E32\u0E07\u0E01\u0E31\u0E19
\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E44\u0E23\u0E01\u0E47\u0E15\u0E32\u0E21 \u0E40\u0E23\u0E32\u0E44\u0E21\u0E48\u0E2D\u0E22\u0E32\u0E01\u0E17\u0E33\u0E43\u0E2B\u0E49\u0E40\u0E27\u0E2D\u0E23\u0E4C\u0E0A\u0E31\u0E19\u0E17\u0E35\u0E48\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E08\u0E32\u0E01 `),Z=a(j,"CODE",{});var A=p(Z);cs=r(A,"normalizers.Sequence"),A.forEach(t),De=r(j," \u0E02\u0E2D\u0E07\u0E40\u0E23\u0E32\u0E19\u0E31\u0E49\u0E19\u0E0B\u0E31\u0E1A\u0E0B\u0E49\u0E2D\u0E19\u0E40\u0E01\u0E34\u0E19\u0E44\u0E1B \u0E40\u0E23\u0E32\u0E08\u0E36\u0E07\u0E44\u0E21\u0E48\u0E43\u0E0A\u0E49 Regex \u0E17\u0E35\u0E48 "),S=a(j,"CODE",{});var le=p(S);Ce=r(le,"BertNormalizer"),le.forEach(t),re=r(j," \u0E43\u0E0A\u0E49\u0E40\u0E27\u0E25\u0E32\u0E17\u0E35\u0E48 "),ve=a(j,"CODE",{});var Hn=p(ve);ye=r(Hn,"clean_text"),Hn.forEach(t),P=r(j," \u0E16\u0E39\u0E01\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32\u0E40\u0E1B\u0E47\u0E19 "),Q=a(j,"CODE",{});var rn=p(Q);ks=r(rn,"True"),rn.forEach(t),ms=r(j,` \u0E0B\u0E36\u0E48\u0E07\u0E40\u0E1B\u0E47\u0E19\u0E04\u0E48\u0E32\u0E15\u0E31\u0E49\u0E07\u0E15\u0E49\u0E19
\u0E41\u0E15\u0E48\u0E04\u0E38\u0E13\u0E44\u0E21\u0E48\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E31\u0E07\u0E27\u0E25\u0E44\u0E1B \u0E40\u0E1E\u0E23\u0E32\u0E30\u0E21\u0E31\u0E19\u0E22\u0E31\u0E07\u0E21\u0E35\u0E27\u0E34\u0E18\u0E35\u0E17\u0E35\u0E48\u0E08\u0E30\u0E17\u0E33\u0E43\u0E2B\u0E49\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E2D\u0E2D\u0E01\u0E21\u0E32\u0E40\u0E1B\u0E47\u0E19\u0E40\u0E2B\u0E21\u0E37\u0E2D\u0E19\u0E01\u0E31\u0E19\u0E42\u0E14\u0E22\u0E17\u0E35\u0E48\u0E44\u0E21\u0E48\u0E15\u0E49\u0E2D\u0E07\u0E43\u0E0A\u0E49 `),ee=a(j,"CODE",{});var ae=p(ee);ds=r(ae,"BertNormalizer"),ae.forEach(t),_s=r(j," \u0E19\u0E31\u0E48\u0E19\u0E04\u0E37\u0E2D\u0E42\u0E14\u0E22\u0E01\u0E32\u0E23\u0E40\u0E1E\u0E34\u0E48\u0E21 "),se=a(j,"CODE",{});var Yn=p(se);$s=r(Yn,"normalizers.Replace"),Yn.forEach(t),us=r(j," \u0E2A\u0E2D\u0E07\u0E04\u0E23\u0E31\u0E49\u0E07 \u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E43\u0E19 "),te=a(j,"CODE",{});var Es=p(te);zs=r(Es,"normalizers.Sequence"),Es.forEach(t),j.forEach(t)},m(oe,j){i(oe,E,j),s(E,ne),s(ne,L),s(E,F),s(E,J),s(J,V),s(E,fs),s(E,Z),s(Z,cs),s(E,De),s(E,S),s(S,Ce),s(E,re),s(E,ve),s(ve,ye),s(E,P),s(E,Q),s(Q,ks),s(E,ms),s(E,ee),s(ee,ds),s(E,_s),s(E,se),s(se,$s),s(E,us),s(E,te),s(te,zs)},d(oe){oe&&t(E)}}}function mz(_l){let E,ne,L,F,J,V,fs,Z,cs,De,S,Ce,re,ve,ye,P,Q,ks,ms,ee,ds,_s,se,$s,us,te,zs,oe,j,nn,hs,A,le,Hn,rn,ae,Yn,Es,Oe,Cp,on,yp,Op,$l,js,ul,Le,Lp,Jn,Sp,Bp,zl,w,ie,Vn,Np,Fp,Zn,Ap,Wp,vs,Up,Ip,Rp,pe,Qn,Gp,Mp,er,Xp,Kp,bs,Hp,Yp,Jp,q,sr,Vp,Zp,tr,Qp,ef,nr,sf,tf,rr,nf,rf,or,of,lf,xs,af,pf,ff,fe,lr,cf,kf,ar,mf,df,gs,_f,$f,uf,ce,ir,zf,hf,pr,Ef,jf,Ps,vf,bf,xf,ke,fr,gf,Pf,cr,wf,qf,ws,Tf,Df,hl,qs,Cf,Ts,yf,El,be,Se,kr,Ds,Of,mr,Lf,jl,xe,Sf,ln,Bf,Nf,Cs,Ff,vl,ys,bl,Os,dr,Af,Wf,xl,Ls,gl,an,Uf,Pl,ge,Be,_r,Ss,If,$r,Rf,wl,b,Gf,ur,Mf,Xf,zr,Kf,Hf,hr,Yf,Jf,Er,Vf,Zf,jr,Qf,ec,vr,sc,tc,ql,Ne,nc,br,rc,oc,Tl,Bs,Dl,W,lc,xr,ac,ic,gr,pc,fc,Pr,cc,kc,Cl,T,mc,wr,dc,_c,qr,$c,uc,Tr,zc,hc,Dr,Ec,jc,Cr,vc,bc,yl,Fe,xc,yr,gc,Pc,Ol,Ns,Ll,pn,wc,Sl,U,qc,Or,Tc,Dc,Lr,Cc,yc,Sr,Oc,Lc,Bl,Fs,Nl,me,Sc,Br,Bc,Nc,Nr,Fc,Ac,Fl,de,Wc,Fr,Uc,Ic,Ar,Rc,Gc,Al,As,Wl,Ws,Ul,Ae,Il,We,Mc,Wr,Xc,Kc,Rl,Us,Gl,fn,Hc,Ml,Is,Xl,Ue,Yc,Ur,Jc,Vc,Kl,Rs,Hl,Gs,Yl,Ie,Zc,Ir,Qc,ek,Jl,Ms,Vl,Xs,Zl,Re,sk,Rr,tk,nk,Ql,Ks,ea,Hs,sa,Ys,rk,Gr,ok,ta,cn,lk,na,Js,ra,D,ak,Mr,ik,pk,Xr,fk,ck,Kr,kk,mk,Hr,dk,_k,Yr,$k,uk,oa,kn,zk,la,Vs,aa,Ge,hk,Jr,Ek,jk,ia,Zs,pa,Me,vk,Vr,bk,xk,fa,Qs,ca,et,ka,v,Zr,gk,Pk,Qr,wk,qk,eo,Tk,Dk,so,Ck,yk,to,Ok,Lk,no,Sk,Bk,ro,Nk,Fk,oo,Ak,Wk,lo,Uk,ma,_e,Ik,ao,Rk,Gk,io,Mk,Xk,da,I,Kk,po,Hk,Yk,fo,Jk,Vk,co,Zk,Qk,_a,st,$a,tt,ua,R,em,ko,sm,tm,mo,nm,rm,_o,om,lm,za,mn,am,ha,nt,Ea,dn,im,ja,_n,pm,va,rt,ba,ot,xa,$n,fm,ga,lt,Pa,at,wa,un,cm,qa,it,Ta,Xe,km,$o,mm,dm,Da,pt,Ca,ft,ya,zn,_m,Oa,ct,La,$e,$m,uo,um,zm,zo,hm,Em,Sa,kt,Ba,ue,jm,ho,vm,bm,Eo,xm,gm,Na,C,Pm,jo,wm,qm,vo,Tm,Dm,bo,Cm,ym,xo,Om,Lm,go,Sm,Bm,Fa,mt,Aa,Ke,Nm,Po,Fm,Am,Wa,dt,Ua,Pe,Wm,wo,Um,Im,qo,Rm,Ia,hn,Gm,Ra,we,He,To,_t,Mm,Do,Xm,Ga,Ye,Km,Co,Hm,Ym,Ma,$t,Xa,G,Jm,yo,Vm,Zm,Oo,Qm,ed,Lo,sd,td,Ka,En,nd,Ha,ut,Ya,zt,So,rd,od,Ja,jn,ld,Va,ht,Za,Et,Qa,vn,ad,ei,jt,si,g,id,Bo,pd,fd,No,cd,kd,Fo,md,dd,Ao,_d,$d,Wo,ud,zd,Uo,hd,ti,bn,Ed,ni,vt,ri,xn,jd,oi,bt,li,xt,ai,gn,vd,ii,gt,pi,qe,Io,bd,xd,Ro,gd,Pd,fi,Je,wd,Go,qd,Td,ci,Pt,ki,wt,mi,Pn,Dd,di,qt,_i,wn,Cd,$i,Tt,ui,Dt,zi,ze,yd,Mo,Od,Ld,Xo,Sd,Bd,hi,Ct,Ei,qn,Nd,ji,yt,vi,Tn,Fd,bi,Te,Ve,Ko,Ot,Ad,Ho,Wd,xi,Ze,Ud,Yo,Id,Rd,gi,Lt,Pi,Dn,Gd,wi,Cn,Md,qi,St,Ti,M,Xd,Jo,Kd,Hd,Vo,Yd,Jd,Zo,Vd,Zd,Di,Qe,Qd,Qo,e_,s_,Ci,Bt,yi,yn,t_,Oi,Nt,Li,Ft,Si,On,n_,Bi,At,Ni,y,r_,el,o_,l_,sl,a_,i_,tl,p_,f_,nl,c_,k_,Fi,Ln,m_,Ai,Wt,Wi,Sn,d_,Ui,Ut,Ii,It,Ri,es,__,rl,$_,u_,Gi,he,z_,ol,h_,E_,ll,j_,v_,Mi,Rt,Xi,Gt,Ki,Bn,b_,Hi,Mt,Yi,Nn,x_,Ji,Xt,Vi,Kt,Zi,ss,g_,al,P_,w_,Qi,Ht,ep,Ee,q_,il,T_,D_,pl,C_,y_,sp,ts,O_,fl,L_,S_,tp,Yt,np,Fn,B_,rp,Jt,op,An,N_,lp;return V=new dl({}),S=new cz({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter6/section8.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter6/section8.ipynb"}]}}),js=new fz({props:{id:"MR8tZm5ViWU"}}),Ds=new dl({}),ys=new z({props:{code:`from datasets import load_dataset

dataset = load_dataset("wikitext", name="wikitext-2-raw-v1", split="train")


def get_training_corpus():
    for i in range(0, len(dataset), 1000):
        yield dataset[i : i + 1000]["text"]`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

dataset = load_dataset(<span class="hljs-string">&quot;wikitext&quot;</span>, name=<span class="hljs-string">&quot;wikitext-2-raw-v1&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">get_training_corpus</span>():
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(dataset), <span class="hljs-number">1000</span>):
        <span class="hljs-keyword">yield</span> dataset[i : i + <span class="hljs-number">1000</span>][<span class="hljs-string">&quot;text&quot;</span>]`}}),Ls=new z({props:{code:`with open("wikitext-2.txt", "w", encoding="utf-8") as f:
    for i in range(len(dataset)):
        f.write(dataset[i]["text"] + "\\n")`,highlighted:`<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;wikitext-2.txt&quot;</span>, <span class="hljs-string">&quot;w&quot;</span>, encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(dataset)):
        f.write(dataset[i][<span class="hljs-string">&quot;text&quot;</span>] + <span class="hljs-string">&quot;\\n&quot;</span>)`}}),Ss=new dl({}),Bs=new z({props:{code:`from tokenizers import (
    decoders,
    models,
    normalizers,
    pre_tokenizers,
    processors,
    trainers,
    Tokenizer,
)

tokenizer = Tokenizer(models.WordPiece(unk_token="[UNK]"))`,highlighted:`<span class="hljs-keyword">from</span> tokenizers <span class="hljs-keyword">import</span> (
    decoders,
    models,
    normalizers,
    pre_tokenizers,
    processors,
    trainers,
    Tokenizer,
)

tokenizer = Tokenizer(models.WordPiece(unk_token=<span class="hljs-string">&quot;[UNK]&quot;</span>))`}}),Ns=new z({props:{code:"tokenizer.normalizer = normalizers.BertNormalizer(lowercase=True)",highlighted:'tokenizer.normalizer = normalizers.BertNormalizer(lowercase=<span class="hljs-literal">True</span>)'}}),Fs=new z({props:{code:`tokenizer.normalizer = normalizers.Sequence(
    [normalizers.NFD(), normalizers.Lowercase(), normalizers.StripAccents()]
)`,highlighted:`tokenizer.normalizer = normalizers.<span class="hljs-type">Sequence</span>(
    [normalizers.NFD(), normalizers.Lowercase(), normalizers.StripAccents()]
)`}}),As=new z({props:{code:'print(tokenizer.normalizer.normalize_str("H\xE9ll\xF2 h\xF4w are \xFC?"))',highlighted:'<span class="hljs-built_in">print</span>(tokenizer.normalizer.normalize_str(<span class="hljs-string">&quot;H\xE9ll\xF2 h\xF4w are \xFC?&quot;</span>))'}}),Ws=new z({props:{code:"hello how are u?",highlighted:"hello how are u?"}}),Ae=new pz({props:{$$slots:{default:[kz]},$$scope:{ctx:_l}}}),Us=new z({props:{code:"tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()",highlighted:"tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()"}}),Is=new z({props:{code:"tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()",highlighted:"tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()"}}),Rs=new z({props:{code:`tokenizer.pre_tokenizer.pre_tokenize_str("Let's test my pre-tokenizer.")`,highlighted:'tokenizer.pre_tokenizer.pre_tokenize_str(<span class="hljs-string">&quot;Let&#x27;s test my pre-tokenizer.&quot;</span>)'}}),Gs=new z({props:{code:`[('Let', (0, 3)), ("'", (3, 4)), ('s', (4, 5)), ('test', (6, 10)), ('my', (11, 13)), ('pre', (14, 17)),
 ('-', (17, 18)), ('tokenizer', (18, 27)), ('.', (27, 28))]`,highlighted:`[(<span class="hljs-string">&#x27;Let&#x27;</span>, (<span class="hljs-number">0</span>, <span class="hljs-number">3</span>)), (<span class="hljs-string">&quot;&#x27;&quot;</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">4</span>)), (<span class="hljs-string">&#x27;s&#x27;</span>, (<span class="hljs-number">4</span>, <span class="hljs-number">5</span>)), (<span class="hljs-string">&#x27;test&#x27;</span>, (<span class="hljs-number">6</span>, <span class="hljs-number">10</span>)), (<span class="hljs-string">&#x27;my&#x27;</span>, (<span class="hljs-number">11</span>, <span class="hljs-number">13</span>)), (<span class="hljs-string">&#x27;pre&#x27;</span>, (<span class="hljs-number">14</span>, <span class="hljs-number">17</span>)),
 (<span class="hljs-string">&#x27;-&#x27;</span>, (<span class="hljs-number">17</span>, <span class="hljs-number">18</span>)), (<span class="hljs-string">&#x27;tokenizer&#x27;</span>, (<span class="hljs-number">18</span>, <span class="hljs-number">27</span>)), (<span class="hljs-string">&#x27;.&#x27;</span>, (<span class="hljs-number">27</span>, <span class="hljs-number">28</span>))]`}}),Ms=new z({props:{code:`pre_tokenizer = pre_tokenizers.WhitespaceSplit()
pre_tokenizer.pre_tokenize_str("Let's test my pre-tokenizer.")`,highlighted:`pre_tokenizer = pre_tokenizers.WhitespaceSplit()
pre_tokenizer.pre_tokenize_str(<span class="hljs-string">&quot;Let&#x27;s test my pre-tokenizer.&quot;</span>)`}}),Xs=new z({props:{code:`[("Let's", (0, 5)), ('test', (6, 10)), ('my', (11, 13)), ('pre-tokenizer.', (14, 28))]`,highlighted:'[(<span class="hljs-string">&quot;Let&#x27;s&quot;</span>, (<span class="hljs-number">0</span>, <span class="hljs-number">5</span>)), (<span class="hljs-string">&#x27;test&#x27;</span>, (<span class="hljs-number">6</span>, <span class="hljs-number">10</span>)), (<span class="hljs-string">&#x27;my&#x27;</span>, (<span class="hljs-number">11</span>, <span class="hljs-number">13</span>)), (<span class="hljs-string">&#x27;pre-tokenizer.&#x27;</span>, (<span class="hljs-number">14</span>, <span class="hljs-number">28</span>))]'}}),Ks=new z({props:{code:`pre_tokenizer = pre_tokenizers.Sequence(
    [pre_tokenizers.WhitespaceSplit(), pre_tokenizers.Punctuation()]
)
pre_tokenizer.pre_tokenize_str("Let's test my pre-tokenizer.")`,highlighted:`pre_tokenizer = pre_tokenizers.<span class="hljs-type">Sequence</span>(
    [pre_tokenizers.WhitespaceSplit(), pre_tokenizers.Punctuation()]
)
pre_tokenizer.pre_tokenize_str(<span class="hljs-string">&quot;Let&#x27;s test my pre-tokenizer.&quot;</span>)`}}),Hs=new z({props:{code:`[('Let', (0, 3)), ("'", (3, 4)), ('s', (4, 5)), ('test', (6, 10)), ('my', (11, 13)), ('pre', (14, 17)),
 ('-', (17, 18)), ('tokenizer', (18, 27)), ('.', (27, 28))]`,highlighted:`[(<span class="hljs-string">&#x27;Let&#x27;</span>, (<span class="hljs-number">0</span>, <span class="hljs-number">3</span>)), (<span class="hljs-string">&quot;&#x27;&quot;</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">4</span>)), (<span class="hljs-string">&#x27;s&#x27;</span>, (<span class="hljs-number">4</span>, <span class="hljs-number">5</span>)), (<span class="hljs-string">&#x27;test&#x27;</span>, (<span class="hljs-number">6</span>, <span class="hljs-number">10</span>)), (<span class="hljs-string">&#x27;my&#x27;</span>, (<span class="hljs-number">11</span>, <span class="hljs-number">13</span>)), (<span class="hljs-string">&#x27;pre&#x27;</span>, (<span class="hljs-number">14</span>, <span class="hljs-number">17</span>)),
 (<span class="hljs-string">&#x27;-&#x27;</span>, (<span class="hljs-number">17</span>, <span class="hljs-number">18</span>)), (<span class="hljs-string">&#x27;tokenizer&#x27;</span>, (<span class="hljs-number">18</span>, <span class="hljs-number">27</span>)), (<span class="hljs-string">&#x27;.&#x27;</span>, (<span class="hljs-number">27</span>, <span class="hljs-number">28</span>))]`}}),Js=new z({props:{code:`special_tokens = ["[UNK]", "[PAD]", "[CLS]", "[SEP]", "[MASK]"]
trainer = trainers.WordPieceTrainer(vocab_size=25000, special_tokens=special_tokens)`,highlighted:`special_tokens = [<span class="hljs-string">&quot;[UNK]&quot;</span>, <span class="hljs-string">&quot;[PAD]&quot;</span>, <span class="hljs-string">&quot;[CLS]&quot;</span>, <span class="hljs-string">&quot;[SEP]&quot;</span>, <span class="hljs-string">&quot;[MASK]&quot;</span>]
trainer = trainers.WordPieceTrainer(vocab_size=<span class="hljs-number">25000</span>, special_tokens=special_tokens)`}}),Vs=new z({props:{code:"tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)",highlighted:"tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)"}}),Zs=new z({props:{code:`tokenizer.model = models.WordPiece(unk_token="[UNK]")
tokenizer.train(["wikitext-2.txt"], trainer=trainer)`,highlighted:`tokenizer.model = models.WordPiece(unk_token=<span class="hljs-string">&quot;[UNK]&quot;</span>)
tokenizer.train([<span class="hljs-string">&quot;wikitext-2.txt&quot;</span>], trainer=trainer)`}}),Qs=new z({props:{code:`encoding = tokenizer.encode("Let's test this tokenizer.")
print(encoding.tokens)`,highlighted:`encoding = tokenizer.encode(<span class="hljs-string">&quot;Let&#x27;s test this tokenizer.&quot;</span>)
<span class="hljs-built_in">print</span>(encoding.tokens)`}}),et=new z({props:{code:`['let', "'", 's', 'test', 'this', 'tok', '##eni', '##zer', '.']`,highlighted:'[<span class="hljs-string">&#x27;let&#x27;</span>, <span class="hljs-string">&quot;&#x27;&quot;</span>, <span class="hljs-string">&#x27;s&#x27;</span>, <span class="hljs-string">&#x27;test&#x27;</span>, <span class="hljs-string">&#x27;this&#x27;</span>, <span class="hljs-string">&#x27;tok&#x27;</span>, <span class="hljs-string">&#x27;##eni&#x27;</span>, <span class="hljs-string">&#x27;##zer&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>]'}}),st=new z({props:{code:`cls_token_id = tokenizer.token_to_id("[CLS]")
sep_token_id = tokenizer.token_to_id("[SEP]")
print(cls_token_id, sep_token_id)`,highlighted:`cls_token_id = tokenizer.token_to_id(<span class="hljs-string">&quot;[CLS]&quot;</span>)
sep_token_id = tokenizer.token_to_id(<span class="hljs-string">&quot;[SEP]&quot;</span>)
<span class="hljs-built_in">print</span>(cls_token_id, sep_token_id)`}}),tt=new z({props:{code:"(2, 3)",highlighted:'(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)'}}),nt=new z({props:{code:`tokenizer.post_processor = processors.TemplateProcessing(
    single=f"[CLS]:0 $A:0 [SEP]:0",
    pair=f"[CLS]:0 $A:0 [SEP]:0 $B:1 [SEP]:1",
    special_tokens=[("[CLS]", cls_token_id), ("[SEP]", sep_token_id)],
)`,highlighted:`tokenizer.post_processor = processors.TemplateProcessing(
    single=<span class="hljs-string">f&quot;[CLS]:0 $A:0 [SEP]:0&quot;</span>,
    pair=<span class="hljs-string">f&quot;[CLS]:0 $A:0 [SEP]:0 $B:1 [SEP]:1&quot;</span>,
    special_tokens=[(<span class="hljs-string">&quot;[CLS]&quot;</span>, cls_token_id), (<span class="hljs-string">&quot;[SEP]&quot;</span>, sep_token_id)],
)`}}),rt=new z({props:{code:`encoding = tokenizer.encode("Let's test this tokenizer.")
print(encoding.tokens)`,highlighted:`encoding = tokenizer.encode(<span class="hljs-string">&quot;Let&#x27;s test this tokenizer.&quot;</span>)
<span class="hljs-built_in">print</span>(encoding.tokens)`}}),ot=new z({props:{code:`['[CLS]', 'let', "'", 's', 'test', 'this', 'tok', '##eni', '##zer', '.', '[SEP]']`,highlighted:'[<span class="hljs-string">&#x27;[CLS]&#x27;</span>, <span class="hljs-string">&#x27;let&#x27;</span>, <span class="hljs-string">&quot;&#x27;&quot;</span>, <span class="hljs-string">&#x27;s&#x27;</span>, <span class="hljs-string">&#x27;test&#x27;</span>, <span class="hljs-string">&#x27;this&#x27;</span>, <span class="hljs-string">&#x27;tok&#x27;</span>, <span class="hljs-string">&#x27;##eni&#x27;</span>, <span class="hljs-string">&#x27;##zer&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>]'}}),lt=new z({props:{code:`encoding = tokenizer.encode("Let's test this tokenizer...", "on a pair of sentences.")
print(encoding.tokens)
print(encoding.type_ids)`,highlighted:`encoding = tokenizer.encode(<span class="hljs-string">&quot;Let&#x27;s test this tokenizer...&quot;</span>, <span class="hljs-string">&quot;on a pair of sentences.&quot;</span>)
<span class="hljs-built_in">print</span>(encoding.tokens)
<span class="hljs-built_in">print</span>(encoding.type_ids)`}}),at=new z({props:{code:`['[CLS]', 'let', "'", 's', 'test', 'this', 'tok', '##eni', '##zer', '...', '[SEP]', 'on', 'a', 'pair', 'of', 'sentences', '.', '[SEP]']
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]`,highlighted:`[<span class="hljs-string">&#x27;[CLS]&#x27;</span>, <span class="hljs-string">&#x27;let&#x27;</span>, <span class="hljs-string">&quot;&#x27;&quot;</span>, <span class="hljs-string">&#x27;s&#x27;</span>, <span class="hljs-string">&#x27;test&#x27;</span>, <span class="hljs-string">&#x27;this&#x27;</span>, <span class="hljs-string">&#x27;tok&#x27;</span>, <span class="hljs-string">&#x27;##eni&#x27;</span>, <span class="hljs-string">&#x27;##zer&#x27;</span>, <span class="hljs-string">&#x27;...&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>, <span class="hljs-string">&#x27;on&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;pair&#x27;</span>, <span class="hljs-string">&#x27;of&#x27;</span>, <span class="hljs-string">&#x27;sentences&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>]
[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]`}}),it=new z({props:{code:'tokenizer.decoder = decoders.WordPiece(prefix="##")',highlighted:'tokenizer.decoder = decoders.WordPiece(prefix=<span class="hljs-string">&quot;##&quot;</span>)'}}),pt=new z({props:{code:"tokenizer.decode(encoding.ids)",highlighted:"tokenizer.decode(encoding.ids)"}}),ft=new z({props:{code:`"let's test this tokenizer... on a pair of sentences."`,highlighted:'<span class="hljs-string">&quot;let&#x27;s test this tokenizer... on a pair of sentences.&quot;</span>'}}),ct=new z({props:{code:'tokenizer.save("tokenizer.json")',highlighted:'tokenizer.save(<span class="hljs-string">&quot;tokenizer.json&quot;</span>)'}}),kt=new z({props:{code:'new_tokenizer = Tokenizer.from_file("tokenizer.json")',highlighted:'new_tokenizer = Tokenizer.from_file(<span class="hljs-string">&quot;tokenizer.json&quot;</span>)'}}),mt=new z({props:{code:`from transformers import PreTrainedTokenizerFast

wrapped_tokenizer = PreTrainedTokenizerFast(
    tokenizer_object=tokenizer,
    # tokenizer_file="tokenizer.json", # You can load from the tokenizer file, alternatively
    unk_token="[UNK]",
    pad_token="[PAD]",
    cls_token="[CLS]",
    sep_token="[SEP]",
    mask_token="[MASK]",
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> PreTrainedTokenizerFast

wrapped_tokenizer = PreTrainedTokenizerFast(
    tokenizer_object=tokenizer,
    <span class="hljs-comment"># tokenizer_file=&quot;tokenizer.json&quot;, # You can load from the tokenizer file, alternatively</span>
    unk_token=<span class="hljs-string">&quot;[UNK]&quot;</span>,
    pad_token=<span class="hljs-string">&quot;[PAD]&quot;</span>,
    cls_token=<span class="hljs-string">&quot;[CLS]&quot;</span>,
    sep_token=<span class="hljs-string">&quot;[SEP]&quot;</span>,
    mask_token=<span class="hljs-string">&quot;[MASK]&quot;</span>,
)`}}),dt=new z({props:{code:`from transformers import BertTokenizerFast

wrapped_tokenizer = BertTokenizerFast(tokenizer_object=tokenizer)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizerFast

wrapped_tokenizer = BertTokenizerFast(tokenizer_object=tokenizer)`}}),_t=new dl({}),$t=new z({props:{code:"tokenizer = Tokenizer(models.BPE())",highlighted:"tokenizer = Tokenizer(models.BPE())"}}),ut=new z({props:{code:"tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)",highlighted:'tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=<span class="hljs-literal">False</span>)'}}),ht=new z({props:{code:`tokenizer.pre_tokenizer.pre_tokenize_str("Let's test pre-tokenization!")`,highlighted:'tokenizer.pre_tokenizer.pre_tokenize_str(<span class="hljs-string">&quot;Let&#x27;s test pre-tokenization!&quot;</span>)'}}),Et=new z({props:{code:`[('Let', (0, 3)), ("'s", (3, 5)), ('\u0120test', (5, 10)), ('\u0120pre', (10, 14)), ('-', (14, 15)),
 ('tokenization', (15, 27)), ('!', (27, 28))]`,highlighted:`[(<span class="hljs-string">&#x27;Let&#x27;</span>, (<span class="hljs-number">0</span>, <span class="hljs-number">3</span>)), (<span class="hljs-string">&quot;&#x27;s&quot;</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)), (<span class="hljs-string">&#x27;\u0120test&#x27;</span>, (<span class="hljs-number">5</span>, <span class="hljs-number">10</span>)), (<span class="hljs-string">&#x27;\u0120pre&#x27;</span>, (<span class="hljs-number">10</span>, <span class="hljs-number">14</span>)), (<span class="hljs-string">&#x27;-&#x27;</span>, (<span class="hljs-number">14</span>, <span class="hljs-number">15</span>)),
 (<span class="hljs-string">&#x27;tokenization&#x27;</span>, (<span class="hljs-number">15</span>, <span class="hljs-number">27</span>)), (<span class="hljs-string">&#x27;!&#x27;</span>, (<span class="hljs-number">27</span>, <span class="hljs-number">28</span>))]`}}),jt=new z({props:{code:`trainer = trainers.BpeTrainer(vocab_size=25000, special_tokens=["<|endoftext|>"])
tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)`,highlighted:`trainer = trainers.BpeTrainer(vocab_size=<span class="hljs-number">25000</span>, special_tokens=[<span class="hljs-string">&quot;&lt;|endoftext|&gt;&quot;</span>])
tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)`}}),vt=new z({props:{code:`tokenizer.model = models.BPE()
tokenizer.train(["wikitext-2.txt"], trainer=trainer)`,highlighted:`tokenizer.model = models.BPE()
tokenizer.train([<span class="hljs-string">&quot;wikitext-2.txt&quot;</span>], trainer=trainer)`}}),bt=new z({props:{code:`encoding = tokenizer.encode("Let's test this tokenizer.")
print(encoding.tokens)`,highlighted:`encoding = tokenizer.encode(<span class="hljs-string">&quot;Let&#x27;s test this tokenizer.&quot;</span>)
<span class="hljs-built_in">print</span>(encoding.tokens)`}}),xt=new z({props:{code:`['L', 'et', "'", 's', '\u0120test', '\u0120this', '\u0120to', 'ken', 'izer', '.']`,highlighted:'[<span class="hljs-string">&#x27;L&#x27;</span>, <span class="hljs-string">&#x27;et&#x27;</span>, <span class="hljs-string">&quot;&#x27;&quot;</span>, <span class="hljs-string">&#x27;s&#x27;</span>, <span class="hljs-string">&#x27;\u0120test&#x27;</span>, <span class="hljs-string">&#x27;\u0120this&#x27;</span>, <span class="hljs-string">&#x27;\u0120to&#x27;</span>, <span class="hljs-string">&#x27;ken&#x27;</span>, <span class="hljs-string">&#x27;izer&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>]'}}),gt=new z({props:{code:"tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)",highlighted:'tokenizer.post_processor = processors.ByteLevel(trim_offsets=<span class="hljs-literal">False</span>)'}}),Pt=new z({props:{code:`sentence = "Let's test this tokenizer."
encoding = tokenizer.encode(sentence)
start, end = encoding.offsets[4]
sentence[start:end]`,highlighted:`sentence = <span class="hljs-string">&quot;Let&#x27;s test this tokenizer.&quot;</span>
encoding = tokenizer.encode(sentence)
start, end = encoding.offsets[<span class="hljs-number">4</span>]
sentence[start:end]`}}),wt=new z({props:{code:"' test'",highlighted:'<span class="hljs-string">&#x27; test&#x27;</span>'}}),qt=new z({props:{code:"tokenizer.decoder = decoders.ByteLevel()",highlighted:"tokenizer.decoder = decoders.ByteLevel()"}}),Tt=new z({props:{code:"tokenizer.decode(encoding.ids)",highlighted:"tokenizer.decode(encoding.ids)"}}),Dt=new z({props:{code:`"Let's test this tokenizer."`,highlighted:'<span class="hljs-string">&quot;Let&#x27;s test this tokenizer.&quot;</span>'}}),Ct=new z({props:{code:`from transformers import PreTrainedTokenizerFast

wrapped_tokenizer = PreTrainedTokenizerFast(
    tokenizer_object=tokenizer,
    bos_token="<|endoftext|>",
    eos_token="<|endoftext|>",
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> PreTrainedTokenizerFast

wrapped_tokenizer = PreTrainedTokenizerFast(
    tokenizer_object=tokenizer,
    bos_token=<span class="hljs-string">&quot;&lt;|endoftext|&gt;&quot;</span>,
    eos_token=<span class="hljs-string">&quot;&lt;|endoftext|&gt;&quot;</span>,
)`}}),yt=new z({props:{code:`from transformers import GPT2TokenizerFast

wrapped_tokenizer = GPT2TokenizerFast(tokenizer_object=tokenizer)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> GPT2TokenizerFast

wrapped_tokenizer = GPT2TokenizerFast(tokenizer_object=tokenizer)`}}),Ot=new dl({}),Lt=new z({props:{code:"tokenizer = Tokenizer(models.Unigram())",highlighted:"tokenizer = Tokenizer(models.Unigram())"}}),St=new z({props:{code:`from tokenizers import Regex

tokenizer.normalizer = normalizers.Sequence(
    [
        normalizers.Replace("\`\`", '"'),
        normalizers.Replace("''", '"'),
        normalizers.NFKD(),
        normalizers.StripAccents(),
        normalizers.Replace(Regex(" {2,}"), " "),
    ]
)`,highlighted:`<span class="hljs-keyword">from</span> tokenizers <span class="hljs-keyword">import</span> Regex

tokenizer.normalizer = normalizers.<span class="hljs-type">Sequence</span>(
    [
        normalizers.Replace(<span class="hljs-string">&quot;\`\`&quot;</span>, <span class="hljs-string">&#x27;&quot;&#x27;</span>),
        normalizers.Replace(<span class="hljs-string">&quot;&#x27;&#x27;&quot;</span>, <span class="hljs-string">&#x27;&quot;&#x27;</span>),
        normalizers.NFKD(),
        normalizers.StripAccents(),
        normalizers.Replace(Regex(<span class="hljs-string">&quot; {2,}&quot;</span>), <span class="hljs-string">&quot; &quot;</span>),
    ]
)`}}),Bt=new z({props:{code:"tokenizer.pre_tokenizer = pre_tokenizers.Metaspace()",highlighted:"tokenizer.pre_tokenizer = pre_tokenizers.Metaspace()"}}),Nt=new z({props:{code:`tokenizer.pre_tokenizer.pre_tokenize_str("Let's test the pre-tokenizer!")`,highlighted:'tokenizer.pre_tokenizer.pre_tokenize_str(<span class="hljs-string">&quot;Let&#x27;s test the pre-tokenizer!&quot;</span>)'}}),Ft=new z({props:{code:`[("\u2581Let's", (0, 5)), ('\u2581test', (5, 10)), ('\u2581the', (10, 14)), ('\u2581pre-tokenizer!', (14, 29))]`,highlighted:'[(<span class="hljs-string">&quot;\u2581Let&#x27;s&quot;</span>, (<span class="hljs-number">0</span>, <span class="hljs-number">5</span>)), (<span class="hljs-string">&#x27;\u2581test&#x27;</span>, (<span class="hljs-number">5</span>, <span class="hljs-number">10</span>)), (<span class="hljs-string">&#x27;\u2581the&#x27;</span>, (<span class="hljs-number">10</span>, <span class="hljs-number">14</span>)), (<span class="hljs-string">&#x27;\u2581pre-tokenizer!&#x27;</span>, (<span class="hljs-number">14</span>, <span class="hljs-number">29</span>))]'}}),At=new z({props:{code:`special_tokens = ["<cls>", "<sep>", "<unk>", "<pad>", "<mask>", "<s>", "</s>"]
trainer = trainers.UnigramTrainer(
    vocab_size=25000, special_tokens=special_tokens, unk_token="<unk>"
)
tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)`,highlighted:`special_tokens = [<span class="hljs-string">&quot;&lt;cls&gt;&quot;</span>, <span class="hljs-string">&quot;&lt;sep&gt;&quot;</span>, <span class="hljs-string">&quot;&lt;unk&gt;&quot;</span>, <span class="hljs-string">&quot;&lt;pad&gt;&quot;</span>, <span class="hljs-string">&quot;&lt;mask&gt;&quot;</span>, <span class="hljs-string">&quot;&lt;s&gt;&quot;</span>, <span class="hljs-string">&quot;&lt;/s&gt;&quot;</span>]
trainer = trainers.UnigramTrainer(
    vocab_size=<span class="hljs-number">25000</span>, special_tokens=special_tokens, unk_token=<span class="hljs-string">&quot;&lt;unk&gt;&quot;</span>
)
tokenizer.train_from_iterator(get_training_corpus(), trainer=trainer)`}}),Wt=new z({props:{code:`tokenizer.model = models.Unigram()
tokenizer.train(["wikitext-2.txt"], trainer=trainer)`,highlighted:`tokenizer.model = models.Unigram()
tokenizer.train([<span class="hljs-string">&quot;wikitext-2.txt&quot;</span>], trainer=trainer)`}}),Ut=new z({props:{code:`encoding = tokenizer.encode("Let's test this tokenizer.")
print(encoding.tokens)`,highlighted:`encoding = tokenizer.encode(<span class="hljs-string">&quot;Let&#x27;s test this tokenizer.&quot;</span>)
<span class="hljs-built_in">print</span>(encoding.tokens)`}}),It=new z({props:{code:`['\u2581Let', "'", 's', '\u2581test', '\u2581this', '\u2581to', 'ken', 'izer', '.']`,highlighted:'[<span class="hljs-string">&#x27;\u2581Let&#x27;</span>, <span class="hljs-string">&quot;&#x27;&quot;</span>, <span class="hljs-string">&#x27;s&#x27;</span>, <span class="hljs-string">&#x27;\u2581test&#x27;</span>, <span class="hljs-string">&#x27;\u2581this&#x27;</span>, <span class="hljs-string">&#x27;\u2581to&#x27;</span>, <span class="hljs-string">&#x27;ken&#x27;</span>, <span class="hljs-string">&#x27;izer&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>]'}}),Rt=new z({props:{code:`cls_token_id = tokenizer.token_to_id("<cls>")
sep_token_id = tokenizer.token_to_id("<sep>")
print(cls_token_id, sep_token_id)`,highlighted:`cls_token_id = tokenizer.token_to_id(<span class="hljs-string">&quot;&lt;cls&gt;&quot;</span>)
sep_token_id = tokenizer.token_to_id(<span class="hljs-string">&quot;&lt;sep&gt;&quot;</span>)
<span class="hljs-built_in">print</span>(cls_token_id, sep_token_id)`}}),Gt=new z({props:{code:"0 1",highlighted:'<span class="hljs-number">0</span> <span class="hljs-number">1</span>'}}),Mt=new z({props:{code:`tokenizer.post_processor = processors.TemplateProcessing(
    single="$A:0 <sep>:0 <cls>:2",
    pair="$A:0 <sep>:0 $B:1 <sep>:1 <cls>:2",
    special_tokens=[("<sep>", sep_token_id), ("<cls>", cls_token_id)],
)`,highlighted:`tokenizer.post_processor = processors.TemplateProcessing(
    single=<span class="hljs-string">&quot;$A:0 &lt;sep&gt;:0 &lt;cls&gt;:2&quot;</span>,
    pair=<span class="hljs-string">&quot;$A:0 &lt;sep&gt;:0 $B:1 &lt;sep&gt;:1 &lt;cls&gt;:2&quot;</span>,
    special_tokens=[(<span class="hljs-string">&quot;&lt;sep&gt;&quot;</span>, sep_token_id), (<span class="hljs-string">&quot;&lt;cls&gt;&quot;</span>, cls_token_id)],
)`}}),Xt=new z({props:{code:`encoding = tokenizer.encode("Let's test this tokenizer...", "on a pair of sentences!")
print(encoding.tokens)
print(encoding.type_ids)`,highlighted:`encoding = tokenizer.encode(<span class="hljs-string">&quot;Let&#x27;s test this tokenizer...&quot;</span>, <span class="hljs-string">&quot;on a pair of sentences!&quot;</span>)
<span class="hljs-built_in">print</span>(encoding.tokens)
<span class="hljs-built_in">print</span>(encoding.type_ids)`}}),Kt=new z({props:{code:`['\u2581Let', "'", 's', '\u2581test', '\u2581this', '\u2581to', 'ken', 'izer', '.', '.', '.', '<sep>', '\u2581', 'on', '\u2581', 'a', '\u2581pair',
  '\u2581of', '\u2581sentence', 's', '!', '<sep>', '<cls>']
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]`,highlighted:`[<span class="hljs-string">&#x27;\u2581Let&#x27;</span>, <span class="hljs-string">&quot;&#x27;&quot;</span>, <span class="hljs-string">&#x27;s&#x27;</span>, <span class="hljs-string">&#x27;\u2581test&#x27;</span>, <span class="hljs-string">&#x27;\u2581this&#x27;</span>, <span class="hljs-string">&#x27;\u2581to&#x27;</span>, <span class="hljs-string">&#x27;ken&#x27;</span>, <span class="hljs-string">&#x27;izer&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;&lt;sep&gt;&#x27;</span>, <span class="hljs-string">&#x27;\u2581&#x27;</span>, <span class="hljs-string">&#x27;on&#x27;</span>, <span class="hljs-string">&#x27;\u2581&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;\u2581pair&#x27;</span>,
  <span class="hljs-string">&#x27;\u2581of&#x27;</span>, <span class="hljs-string">&#x27;\u2581sentence&#x27;</span>, <span class="hljs-string">&#x27;s&#x27;</span>, <span class="hljs-string">&#x27;!&#x27;</span>, <span class="hljs-string">&#x27;&lt;sep&gt;&#x27;</span>, <span class="hljs-string">&#x27;&lt;cls&gt;&#x27;</span>]
[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>]`}}),Ht=new z({props:{code:"tokenizer.decoder = decoders.Metaspace()",highlighted:"tokenizer.decoder = decoders.Metaspace()"}}),Yt=new z({props:{code:`from transformers import PreTrainedTokenizerFast

wrapped_tokenizer = PreTrainedTokenizerFast(
    tokenizer_object=tokenizer,
    bos_token="<s>",
    eos_token="</s>",
    unk_token="<unk>",
    pad_token="<pad>",
    cls_token="<cls>",
    sep_token="<sep>",
    mask_token="<mask>",
    padding_side="left",
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> PreTrainedTokenizerFast

wrapped_tokenizer = PreTrainedTokenizerFast(
    tokenizer_object=tokenizer,
    bos_token=<span class="hljs-string">&quot;&lt;s&gt;&quot;</span>,
    eos_token=<span class="hljs-string">&quot;&lt;/s&gt;&quot;</span>,
    unk_token=<span class="hljs-string">&quot;&lt;unk&gt;&quot;</span>,
    pad_token=<span class="hljs-string">&quot;&lt;pad&gt;&quot;</span>,
    cls_token=<span class="hljs-string">&quot;&lt;cls&gt;&quot;</span>,
    sep_token=<span class="hljs-string">&quot;&lt;sep&gt;&quot;</span>,
    mask_token=<span class="hljs-string">&quot;&lt;mask&gt;&quot;</span>,
    padding_side=<span class="hljs-string">&quot;left&quot;</span>,
)`}}),Jt=new z({props:{code:`from transformers import XLNetTokenizerFast

wrapped_tokenizer = XLNetTokenizerFast(tokenizer_object=tokenizer)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> XLNetTokenizerFast

wrapped_tokenizer = XLNetTokenizerFast(tokenizer_object=tokenizer)`}}),{c(){E=l("meta"),ne=f(),L=l("h1"),F=l("a"),J=l("span"),k(V.$$.fragment),fs=f(),Z=l("span"),cs=n("\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 tokenizer \u0E17\u0E35\u0E25\u0E30\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19"),De=f(),k(S.$$.fragment),Ce=f(),re=l("p"),ve=n("\u0E08\u0E32\u0E01\u0E1A\u0E17\u0E01\u0E48\u0E2D\u0E19\u0E46 \u0E04\u0E38\u0E13\u0E08\u0E30\u0E40\u0E2B\u0E47\u0E19\u0E27\u0E48\u0E32 \u0E01\u0E32\u0E23\u0E15\u0E31\u0E14\u0E04\u0E33 \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22\u0E2B\u0E25\u0E32\u0E22\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19 :"),ye=f(),P=l("ul"),Q=l("li"),ks=n("Normalization (\u0E2B\u0E23\u0E37\u0E2D \u0E01\u0E32\u0E23\u0E1B\u0E23\u0E31\u0E1A\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E43\u0E2B\u0E49\u0E40\u0E1B\u0E47\u0E19\u0E21\u0E32\u0E15\u0E23\u0E10\u0E32\u0E19 \u0E2B\u0E21\u0E32\u0E22\u0E16\u0E36\u0E07\u0E01\u0E32\u0E23\u0E17\u0E33\u0E04\u0E27\u0E32\u0E21\u0E2A\u0E30\u0E2D\u0E32\u0E14\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21 \u0E40\u0E0A\u0E48\u0E19 \u0E25\u0E1A\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E2B\u0E23\u0E37\u0E2D\u0E40\u0E04\u0E23\u0E37\u0E48\u0E2D\u0E07\u0E2B\u0E21\u0E32\u0E22\u0E40\u0E19\u0E49\u0E19\u0E40\u0E2A\u0E35\u0E22\u0E07 \u0E23\u0E27\u0E21\u0E16\u0E36\u0E07\u0E01\u0E32\u0E23\u0E17\u0E33 Unicode normalization \u0E41\u0E25\u0E30\u0E2D\u0E37\u0E48\u0E19\u0E46)"),ms=f(),ee=l("li"),ds=n("Pre-tokenization (\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E01\u0E48\u0E2D\u0E19\u0E15\u0E31\u0E14\u0E04\u0E33 \u0E2B\u0E21\u0E32\u0E22\u0E16\u0E36\u0E07 \u0E01\u0E32\u0E23\u0E41\u0E22\u0E01\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E2D\u0E2D\u0E01\u0E40\u0E1B\u0E47\u0E19\u0E04\u0E33\u0E46)"),_s=f(),se=l("li"),$s=n("\u0E2A\u0E48\u0E07 input \u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E43\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25 (\u0E41\u0E22\u0E01\u0E04\u0E33\u0E17\u0E35\u0E48\u0E44\u0E14\u0E49\u0E08\u0E32\u0E01\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19 pre-tokenization \u0E2D\u0E2D\u0E01\u0E40\u0E1B\u0E47\u0E19\u0E04\u0E33\u0E22\u0E48\u0E2D\u0E22\u0E2B\u0E25\u0E32\u0E22\u0E46\u0E04\u0E33)"),us=f(),te=l("li"),zs=n("Post-processing (\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E1B\u0E23\u0E31\u0E1A\u0E41\u0E15\u0E48\u0E07\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C \u0E40\u0E0A\u0E48\u0E19 \u0E01\u0E32\u0E23\u0E43\u0E2A\u0E48 token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E02\u0E2D\u0E07 tokenizer \u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E43\u0E19\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C, \u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 attention mask \u0E41\u0E25\u0E30 token type IDs)"),oe=f(),j=l("p"),nn=n("\u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E40\u0E1B\u0E47\u0E19\u0E01\u0E32\u0E23\u0E40\u0E15\u0E37\u0E2D\u0E19\u0E04\u0E27\u0E32\u0E21\u0E08\u0E33 \u0E21\u0E32\u0E14\u0E39\u0E01\u0E23\u0E30\u0E1A\u0E27\u0E19\u0E01\u0E32\u0E23\u0E42\u0E14\u0E22\u0E23\u0E27\u0E21\u0E2D\u0E35\u0E01\u0E04\u0E23\u0E31\u0E49\u0E07 :"),hs=f(),A=l("div"),le=l("img"),rn=f(),ae=l("img"),Es=f(),Oe=l("p"),Cp=n(`\u{1F917} Tokenizers library \u0E40\u0E1B\u0E47\u0E19\u0E40\u0E04\u0E23\u0E37\u0E48\u0E2D\u0E07\u0E21\u0E37\u0E2D\u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A\u0E0A\u0E48\u0E27\u0E22\u0E14\u0E33\u0E40\u0E19\u0E34\u0E19\u0E01\u0E32\u0E23\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E1E\u0E27\u0E01\u0E19\u0E35\u0E49 \u0E42\u0E14\u0E22\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E1C\u0E2A\u0E21\u0E1C\u0E2A\u0E32\u0E19\u0E40\u0E04\u0E23\u0E37\u0E48\u0E2D\u0E07\u0E21\u0E37\u0E2D\u0E1E\u0E27\u0E01\u0E19\u0E35\u0E49\u0E15\u0E32\u0E21\u0E04\u0E27\u0E32\u0E21\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E32\u0E23\u0E44\u0E14\u0E49
\u0E43\u0E19\u0E1A\u0E17\u0E19\u0E35\u0E49\u0E40\u0E23\u0E32\u0E08\u0E30\u0E21\u0E32\u0E40\u0E23\u0E35\u0E22\u0E19\u0E27\u0E34\u0E18\u0E35\u0E2A\u0E23\u0E49\u0E32\u0E07 tokenizer \u0E02\u0E36\u0E49\u0E19\u0E21\u0E32\u0E15\u0E31\u0E49\u0E07\u0E41\u0E15\u0E48\u0E15\u0E49\u0E19 \u0E41\u0E17\u0E19\u0E17\u0E35\u0E48\u0E08\u0E30\u0E40\u0E17\u0E23\u0E19\u0E08\u0E32\u0E01\u0E15\u0E31\u0E27\u0E17\u0E35\u0E48\u0E16\u0E39\u0E01 implement \u0E41\u0E25\u0E49\u0E27\u0E14\u0E49\u0E27\u0E22\u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E43\u0E2B\u0E21\u0E48\u0E40\u0E17\u0E48\u0E32\u0E19\u0E31\u0E49\u0E19 \u0E2D\u0E22\u0E48\u0E32\u0E07\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E25\u0E2D\u0E07\u0E17\u0E33\u0E01\u0E31\u0E19\u0E43\u0E19`),on=l("a"),yp=n("\u0E1A\u0E17\u0E17\u0E35\u0E48 2"),Op=n(" \u0E40\u0E21\u0E37\u0E48\u0E2D\u0E08\u0E1A\u0E1A\u0E17\u0E19\u0E35\u0E49 \u0E04\u0E38\u0E13\u0E08\u0E30\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E2A\u0E23\u0E49\u0E32\u0E07 tokenizer \u0E41\u0E1A\u0E1A\u0E43\u0E14\u0E01\u0E47\u0E44\u0E14\u0E49\u0E15\u0E32\u0E21\u0E17\u0E35\u0E48\u0E04\u0E38\u0E13\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E32\u0E23"),$l=f(),k(js.$$.fragment),ul=f(),Le=l("p"),Lp=n("library \u0E19\u0E35\u0E49 \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E14\u0E49\u0E27\u0E22\u0E2A\u0E48\u0E27\u0E19\u0E2B\u0E25\u0E31\u0E01\u0E04\u0E37\u0E2D "),Jn=l("code"),Sp=n("Tokenizer"),Bp=n(" class \u0E17\u0E35\u0E48\u0E21\u0E35\u0E2A\u0E48\u0E27\u0E19\u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E22\u0E48\u0E2D\u0E22\u0E2A\u0E33\u0E04\u0E31\u0E0D\u0E2D\u0E37\u0E48\u0E19\u0E46 \u0E41\u0E1A\u0E48\u0E07\u0E40\u0E1B\u0E47\u0E19\u0E2B\u0E25\u0E32\u0E22 submodules"),zl=f(),w=l("ul"),ie=l("li"),Vn=l("code"),Np=n("normalizers"),Fp=n(" \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22 "),Zn=l("code"),Ap=n("Normalizer"),Wp=n(" \u0E2B\u0E25\u0E32\u0E22\u0E1B\u0E23\u0E30\u0E40\u0E20\u0E17\u0E17\u0E35\u0E48\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49\u0E44\u0E14\u0E49 (\u0E23\u0E32\u0E22\u0E0A\u0E37\u0E48\u0E2D\u0E17\u0E31\u0E49\u0E07\u0E2B\u0E21\u0E14\u0E14\u0E39\u0E44\u0E14\u0E49"),vs=l("a"),Up=n("\u0E17\u0E35\u0E48\u0E19\u0E35\u0E48"),Ip=n(")."),Rp=f(),pe=l("li"),Qn=l("code"),Gp=n("pre_tokenizers"),Mp=n(" \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22 "),er=l("code"),Xp=n("PreTokenizer"),Kp=n(" \u0E2B\u0E25\u0E32\u0E22\u0E1B\u0E23\u0E30\u0E40\u0E20\u0E17\u0E17\u0E35\u0E48\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49\u0E44\u0E14\u0E49 (\u0E23\u0E32\u0E22\u0E0A\u0E37\u0E48\u0E2D\u0E17\u0E31\u0E49\u0E07\u0E2B\u0E21\u0E14\u0E14\u0E39\u0E44\u0E14\u0E49"),bs=l("a"),Hp=n("\u0E17\u0E35\u0E48\u0E19\u0E35\u0E48"),Yp=n(")."),Jp=f(),q=l("li"),sr=l("code"),Vp=n("models"),Zp=n(" \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22 "),tr=l("code"),Qp=n("Model"),ef=n(" \u0E2B\u0E25\u0E32\u0E22\u0E1B\u0E23\u0E30\u0E40\u0E20\u0E17\u0E17\u0E35\u0E48\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49\u0E44\u0E14\u0E49 \u0E40\u0E0A\u0E48\u0E19 "),nr=l("code"),sf=n("BPE"),tf=n(", "),rr=l("code"),nf=n("WordPiece"),rf=n(", \u0E41\u0E25\u0E30 "),or=l("code"),of=n("Unigram"),lf=n(" (\u0E23\u0E32\u0E22\u0E0A\u0E37\u0E48\u0E2D\u0E17\u0E31\u0E49\u0E07\u0E2B\u0E21\u0E14\u0E14\u0E39\u0E44\u0E14\u0E49"),xs=l("a"),af=n("\u0E17\u0E35\u0E48\u0E19\u0E35\u0E48"),pf=n(")."),ff=f(),fe=l("li"),lr=l("code"),cf=n("trainers"),kf=n(" \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22 "),ar=l("code"),mf=n("Trainer"),df=n(" \u0E2B\u0E25\u0E32\u0E22\u0E1B\u0E23\u0E30\u0E40\u0E20\u0E17\u0E17\u0E35\u0E48\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49\u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E40\u0E17\u0E23\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25\u0E14\u0E49\u0E27\u0E22 corpus \u0E17\u0E35\u0E48\u0E21\u0E35\u0E44\u0E14\u0E49 (\u0E41\u0E15\u0E48\u0E25\u0E30\u0E42\u0E21\u0E40\u0E14\u0E25\u0E08\u0E30\u0E21\u0E35\u0E40\u0E17\u0E23\u0E19\u0E40\u0E19\u0E2D\u0E23\u0E4C\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E25\u0E30\u0E15\u0E31\u0E27; \u0E23\u0E32\u0E22\u0E0A\u0E37\u0E48\u0E2D\u0E17\u0E31\u0E49\u0E07\u0E2B\u0E21\u0E14\u0E14\u0E39\u0E44\u0E14\u0E49"),gs=l("a"),_f=n("\u0E17\u0E35\u0E48\u0E19\u0E35\u0E48"),$f=n(")."),uf=f(),ce=l("li"),ir=l("code"),zf=n("post_processors"),hf=n(" \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22 "),pr=l("code"),Ef=n("PostProcessor"),jf=n(" \u0E2B\u0E25\u0E32\u0E22\u0E1B\u0E23\u0E30\u0E40\u0E20\u0E17\u0E17\u0E35\u0E48\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49\u0E44\u0E14\u0E49 (\u0E23\u0E32\u0E22\u0E0A\u0E37\u0E48\u0E2D\u0E17\u0E31\u0E49\u0E07\u0E2B\u0E21\u0E14\u0E14\u0E39\u0E44\u0E14\u0E49"),Ps=l("a"),vf=n("\u0E17\u0E35\u0E48\u0E19\u0E35\u0E48"),bf=n(")"),xf=f(),ke=l("li"),fr=l("code"),gf=n("decoders"),Pf=n(" \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22 "),cr=l("code"),wf=n("Decoder"),qf=n(" \u0E2B\u0E25\u0E32\u0E22\u0E1B\u0E23\u0E30\u0E40\u0E20\u0E17\u0E17\u0E35\u0E48\u0E43\u0E0A\u0E49\u0E40\u0E1E\u0E37\u0E48\u0E2D decode \u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E08\u0E32\u0E01\u0E01\u0E32\u0E23 tokenization (\u0E23\u0E32\u0E22\u0E0A\u0E37\u0E48\u0E2D\u0E17\u0E31\u0E49\u0E07\u0E2B\u0E21\u0E14\u0E14\u0E39\u0E44\u0E14\u0E49"),ws=l("a"),Tf=n("\u0E17\u0E35\u0E48\u0E19\u0E35\u0E48"),Df=n(")"),hl=f(),qs=l("p"),Cf=n("\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E14\u0E39\u0E23\u0E32\u0E22\u0E0A\u0E37\u0E48\u0E2D\u0E02\u0E2D\u0E07\u0E2A\u0E48\u0E27\u0E19\u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E2A\u0E33\u0E04\u0E31\u0E0D\u0E46\u0E15\u0E48\u0E32\u0E07\u0E46\u0E44\u0E14\u0E49"),Ts=l("a"),yf=n("\u0E17\u0E35\u0E48\u0E19\u0E35\u0E48"),El=f(),be=l("h2"),Se=l("a"),kr=l("span"),k(Ds.$$.fragment),Of=f(),mr=l("span"),Lf=n("\u0E01\u0E32\u0E23\u0E42\u0E2B\u0E25\u0E14 corpus"),jl=f(),xe=l("p"),Sf=n(`\u0E43\u0E19\u0E01\u0E32\u0E23\u0E40\u0E17\u0E23\u0E19 tokenizer \u0E15\u0E31\u0E27\u0E43\u0E2B\u0E21\u0E48 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49 corpus \u0E40\u0E25\u0E47\u0E01\u0E46 \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E17\u0E35\u0E48\u0E01\u0E32\u0E23\u0E04\u0E33\u0E19\u0E27\u0E13\u0E08\u0E30\u0E44\u0E14\u0E49\u0E23\u0E27\u0E14\u0E40\u0E23\u0E47\u0E27
\u0E01\u0E32\u0E23\u0E40\u0E23\u0E35\u0E22\u0E01\u0E43\u0E0A\u0E49\u0E07\u0E32\u0E19 corpus \u0E08\u0E30\u0E17\u0E33\u0E04\u0E25\u0E49\u0E32\u0E22\u0E46\u0E01\u0E31\u0E1A\u0E27\u0E34\u0E18\u0E35\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E43\u0E0A\u0E49\u0E43\u0E19`),ln=l("a"),Bf=n("\u0E15\u0E2D\u0E19\u0E15\u0E49\u0E19\u0E02\u0E2D\u0E07\u0E1A\u0E17\u0E19\u0E35\u0E49"),Nf=n(" \u0E41\u0E15\u0E48\u0E04\u0E23\u0E31\u0E49\u0E07\u0E19\u0E35\u0E49\u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49\u0E0A\u0E38\u0E14\u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E0A\u0E37\u0E48\u0E2D "),Cs=l("a"),Ff=n("WikiText-2"),vl=f(),k(ys.$$.fragment),bl=f(),Os=l("p"),dr=l("code"),Af=n("get_training_corpus()"),Wf=n(` \u0E40\u0E1B\u0E47\u0E19 generator \u0E17\u0E35\u0E48\u0E08\u0E30 yield \u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E43\u0E19\u0E23\u0E39\u0E1B\u0E41\u0E1A\u0E1A batch \u0E42\u0E14\u0E22\u0E41\u0E15\u0E48\u0E25\u0E30 batch \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22 1,000 \u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21
\u{1F917} Tokenizers \u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E40\u0E17\u0E23\u0E19\u0E44\u0E14\u0E49\u0E08\u0E32\u0E01\u0E44\u0E1F\u0E25\u0E4C\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E42\u0E14\u0E22\u0E15\u0E23\u0E07 \u0E14\u0E31\u0E07\u0E19\u0E31\u0E49\u0E19\u0E40\u0E23\u0E32\u0E08\u0E30\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E44\u0E1F\u0E25\u0E4C\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21 \u0E17\u0E35\u0E48\u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22 \u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E17\u0E31\u0E49\u0E07\u0E2B\u0E21\u0E14\u0E08\u0E32\u0E01 WikiText-2`),xl=f(),k(Ls.$$.fragment),gl=f(),an=l("p"),Uf=n(`\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E40\u0E23\u0E32\u0E08\u0E30\u0E1E\u0E32\u0E04\u0E38\u0E13\u0E2A\u0E23\u0E49\u0E32\u0E07 tokenizer \u0E41\u0E1A\u0E1A BERT, GPT-2, and XLNet \u0E02\u0E2D\u0E07\u0E04\u0E38\u0E13\u0E40\u0E2D\u0E07 \u0E17\u0E35\u0E25\u0E30\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19
\u0E0B\u0E36\u0E48\u0E07\u0E04\u0E38\u0E13\u0E01\u0E47\u0E08\u0E30\u0E44\u0E14\u0E49\u0E25\u0E2D\u0E07\u0E43\u0E0A\u0E49\u0E07\u0E32\u0E19 tokenization algorithm \u0E15\u0E48\u0E32\u0E07\u0E46\u0E17\u0E35\u0E48\u0E44\u0E14\u0E49\u0E40\u0E23\u0E35\u0E22\u0E19\u0E21\u0E32\u0E41\u0E25\u0E49\u0E27 \u0E40\u0E0A\u0E48\u0E19 WordPiece, BPE, and Unigram \u0E21\u0E32\u0E40\u0E23\u0E34\u0E48\u0E21\u0E08\u0E32\u0E01 BERT \u0E01\u0E31\u0E19`),Pl=f(),ge=l("h2"),Be=l("a"),_r=l("span"),k(Ss.$$.fragment),If=f(),$r=l("span"),Rf=n("\u0E2A\u0E23\u0E49\u0E32\u0E07 WordPiece tokenizer \u0E15\u0E31\u0E49\u0E07\u0E41\u0E15\u0E48\u0E40\u0E23\u0E34\u0E48\u0E21\u0E15\u0E49\u0E19"),wl=f(),b=l("p"),Gf=n("\u0E43\u0E19\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 tokenizer \u0E42\u0E14\u0E22\u0E43\u0E0A\u0E49 \u{1F917} Tokenizers library \u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E23\u0E34\u0E48\u0E21\u0E08\u0E32\u0E01\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 "),ur=l("code"),Mf=n("Tokenizer"),Xf=n(" object \u0E08\u0E32\u0E01 "),zr=l("code"),Kf=n("model"),Hf=n(" \u0E41\u0E25\u0E30\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32 attribute \u0E15\u0E48\u0E32\u0E07\u0E46 \u0E44\u0E14\u0E49\u0E41\u0E01\u0E48 "),hr=l("code"),Yf=n("normalizer"),Jf=n(", "),Er=l("code"),Vf=n("pre_tokenizer"),Zf=n(", "),jr=l("code"),Qf=n("post_processor"),ec=n(", \u0E41\u0E25\u0E30 "),vr=l("code"),sc=n("decoder"),tc=n(" \u0E14\u0E49\u0E27\u0E22\u0E04\u0E48\u0E32\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E32\u0E23"),ql=f(),Ne=l("p"),nc=n("\u0E43\u0E19\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E19\u0E35\u0E49 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E2A\u0E23\u0E49\u0E32\u0E07 "),br=l("code"),rc=n("Tokenizer"),oc=n(" \u0E14\u0E49\u0E27\u0E22 WordPiece :"),Tl=f(),k(Bs.$$.fragment),Dl=f(),W=l("p"),lc=n("\u0E08\u0E32\u0E01\u0E19\u0E31\u0E49\u0E19\u0E40\u0E23\u0E32\u0E08\u0E30\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32 "),xr=l("code"),ac=n("unk_token"),ic=n(` \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E1A\u0E2D\u0E01\u0E42\u0E21\u0E40\u0E14\u0E25\u0E27\u0E48\u0E32\u0E43\u0E2B\u0E49\u0E21\u0E31\u0E19 return \u0E04\u0E48\u0E32\u0E2D\u0E30\u0E44\u0E23\u0E2B\u0E32\u0E01\u0E21\u0E31\u0E19\u0E40\u0E08\u0E2D\u0E15\u0E31\u0E27\u0E2D\u0E31\u0E01\u0E29\u0E23\u0E17\u0E35\u0E48\u0E21\u0E31\u0E19\u0E44\u0E21\u0E48\u0E23\u0E39\u0E49\u0E08\u0E31\u0E01
\u0E2A\u0E48\u0E27\u0E19 argument \u0E2D\u0E37\u0E48\u0E19\u0E46\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32\u0E44\u0E14\u0E49\u0E01\u0E47\u0E04\u0E37\u0E2D `),gr=l("code"),pc=n("vocab"),fc=n(" (\u0E41\u0E15\u0E48\u0E40\u0E19\u0E37\u0E48\u0E2D\u0E07\u0E08\u0E32\u0E01\u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E17\u0E23\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25 \u0E17\u0E33\u0E43\u0E2B\u0E49\u0E15\u0E2D\u0E19\u0E19\u0E35\u0E49\u0E40\u0E23\u0E32\u0E22\u0E31\u0E07\u0E44\u0E21\u0E48\u0E15\u0E49\u0E2D\u0E07\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32\u0E19\u0E35\u0E49) \u0E41\u0E25\u0E30 "),Pr=l("code"),cc=n("max_input_chars_per_word"),kc=n(" \u0E0B\u0E36\u0E48\u0E07\u0E2B\u0E21\u0E32\u0E22\u0E16\u0E36\u0E07 \u0E04\u0E27\u0E32\u0E21\u0E22\u0E32\u0E27\u0E2A\u0E39\u0E07\u0E2A\u0E38\u0E14\u0E02\u0E2D\u0E07\u0E41\u0E15\u0E48\u0E25\u0E30\u0E04\u0E33 (\u0E04\u0E33\u0E17\u0E35\u0E48\u0E22\u0E32\u0E27\u0E01\u0E27\u0E48\u0E32\u0E04\u0E48\u0E32\u0E19\u0E35\u0E49\u0E08\u0E30\u0E16\u0E39\u0E01\u0E41\u0E1A\u0E48\u0E07\u0E40\u0E1B\u0E47\u0E19\u0E2B\u0E25\u0E32\u0E22\u0E46\u0E2A\u0E48\u0E27\u0E19)"),Cl=f(),T=l("p"),mc=n("\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E41\u0E23\u0E01\u0E04\u0E37\u0E2D normalization \u0E40\u0E19\u0E37\u0E48\u0E2D\u0E07\u0E08\u0E32\u0E01 BERT \u0E40\u0E1B\u0E47\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25\u0E17\u0E35\u0E48\u0E44\u0E14\u0E49\u0E23\u0E31\u0E1A\u0E04\u0E27\u0E32\u0E21\u0E19\u0E34\u0E22\u0E21\u0E21\u0E32\u0E01 \u0E40\u0E23\u0E32\u0E08\u0E36\u0E07\u0E21\u0E35 "),wr=l("code"),dc=n("BertNormalizer"),_c=n(" \u0E40\u0E09\u0E1E\u0E32\u0E30 \u0E0B\u0E36\u0E48\u0E07\u0E21\u0E35 option \u0E15\u0E48\u0E32\u0E07\u0E46\u0E14\u0E31\u0E07\u0E19\u0E35\u0E49: "),qr=l("code"),$c=n("lowercase"),uc=n(", "),Tr=l("code"),zc=n("strip_accents"),hc=n(", "),Dr=l("code"),Ec=n("clean_text"),jc=n(" (\u0E25\u0E1A control characters \u0E41\u0E25\u0E30\u0E41\u0E17\u0E19\u0E17\u0E35\u0E48\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E17\u0E35\u0E48\u0E2D\u0E22\u0E39\u0E48\u0E15\u0E48\u0E2D\u0E01\u0E31\u0E19\u0E2B\u0E25\u0E32\u0E22\u0E46\u0E2D\u0E31\u0E19\u0E14\u0E49\u0E27\u0E22\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E40\u0E14\u0E35\u0E22\u0E27), \u0E41\u0E25\u0E30 "),Cr=l("code"),vc=n("handle_chinese_chars"),bc=n(" (\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E43\u0E19\u0E15\u0E31\u0E27\u0E2D\u0E31\u0E01\u0E29\u0E23\u0E08\u0E35\u0E19)"),yl=f(),Fe=l("p"),xc=n("\u0E40\u0E23\u0E32\u0E08\u0E30\u0E21\u0E32\u0E40\u0E25\u0E35\u0E22\u0E19\u0E41\u0E1A\u0E1A "),yr=l("code"),gc=n("bert-base-uncased"),Pc=n(" tokenizer \u0E42\u0E14\u0E22\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32 normalizer \u0E14\u0E31\u0E07\u0E19\u0E35\u0E49 :"),Ol=f(),k(Ns.$$.fragment),Ll=f(),pn=l("p"),wc=n("\u0E41\u0E15\u0E48\u0E1B\u0E01\u0E15\u0E34\u0E41\u0E25\u0E49\u0E27 \u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A tokenizer \u0E43\u0E2B\u0E21\u0E48 \u0E04\u0E38\u0E13\u0E2D\u0E32\u0E08\u0E08\u0E30\u0E44\u0E21\u0E48\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49 normalizer \u0E17\u0E35\u0E48\u0E08\u0E32\u0E01 \u{1F917} Tokenizers library \u0E44\u0E14\u0E49 \u0E14\u0E31\u0E07\u0E19\u0E31\u0E49\u0E19\u0E40\u0E23\u0E32\u0E08\u0E30\u0E21\u0E32\u0E40\u0E23\u0E35\u0E22\u0E19\u0E27\u0E34\u0E18\u0E35\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 BERT normalizer \u0E40\u0E2D\u0E07\u0E01\u0E31\u0E19"),Sl=f(),U=l("p"),qc=n("library \u0E19\u0E35\u0E49 \u0E21\u0E35 normalizer \u0E40\u0E1E\u0E37\u0E48\u0E2D "),Or=l("code"),Tc=n("Lowercase"),Dc=n(" \u0E41\u0E25\u0E30\u0E40\u0E1E\u0E37\u0E48\u0E2D "),Lr=l("code"),Cc=n("StripAccents"),yc=n(" \u0E0B\u0E36\u0E48\u0E07\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E23\u0E27\u0E21\u0E17\u0E31\u0E49\u0E07\u0E2A\u0E2D\u0E07\u0E15\u0E31\u0E27\u0E44\u0E14\u0E49\u0E42\u0E14\u0E22\u0E43\u0E0A\u0E49 "),Sr=l("code"),Oc=n("Sequence"),Lc=n(" :"),Bl=f(),k(Fs.$$.fragment),Nl=f(),me=l("p"),Sc=n("\u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49 "),Br=l("code"),Bc=n("NFD"),Nc=n(" Unicode normalizer \u0E14\u0E49\u0E27\u0E22 \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E17\u0E35\u0E48\u0E08\u0E30\u0E43\u0E2B\u0E49 "),Nr=l("code"),Fc=n("StripAccents"),Ac=n(" \u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E2B\u0E32\u0E2A\u0E31\u0E0D\u0E25\u0E31\u0E01\u0E29\u0E13\u0E4C accents \u0E44\u0E14\u0E49 \u0E41\u0E25\u0E30\u0E08\u0E30\u0E44\u0E14\u0E49\u0E25\u0E1A\u0E1E\u0E27\u0E01\u0E21\u0E31\u0E19\u0E2D\u0E2D\u0E01"),Fl=f(),de=l("p"),Wc=n("\u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E40\u0E0A\u0E47\u0E04\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E02\u0E2D\u0E07 normalizer \u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49 "),Fr=l("code"),Uc=n("normalize_str()"),Ic=n(" method \u0E08\u0E32\u0E01 "),Ar=l("code"),Rc=n("normalizer"),Gc=n(" :"),Al=f(),k(As.$$.fragment),Wl=f(),k(Ws.$$.fragment),Ul=f(),k(Ae.$$.fragment),Il=f(),We=l("p"),Mc=n("\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E04\u0E37\u0E2D \u0E01\u0E32\u0E23 pre-tokenization \u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49 "),Wr=l("code"),Xc=n("BertPreTokenizer"),Kc=n(" \u0E17\u0E35\u0E48\u0E16\u0E39\u0E01\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E21\u0E32\u0E41\u0E25\u0E49\u0E27 :"),Rl=f(),k(Us.$$.fragment),Gl=f(),fn=l("p"),Hc=n("\u0E2B\u0E23\u0E37\u0E2D\u0E08\u0E30\u0E43\u0E0A\u0E49\u0E15\u0E31\u0E27\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E02\u0E36\u0E49\u0E19\u0E21\u0E32\u0E40\u0E2D\u0E07\u0E01\u0E47\u0E44\u0E14\u0E49 :"),Ml=f(),k(Is.$$.fragment),Xl=f(),Ue=l("p"),Yc=n("\u0E42\u0E1B\u0E23\u0E14\u0E17\u0E23\u0E32\u0E1A\u0E27\u0E48\u0E32 "),Ur=l("code"),Jc=n("Whitespace"),Vc=n(" pre-tokenizer \u0E08\u0E30\u0E15\u0E31\u0E14\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E15\u0E23\u0E07\u0E17\u0E35\u0E48\u0E21\u0E35\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07 \u0E41\u0E25\u0E30 \u0E23\u0E27\u0E21\u0E16\u0E36\u0E07\u0E15\u0E31\u0E27\u0E2A\u0E31\u0E0D\u0E25\u0E31\u0E01\u0E29\u0E13\u0E4C\u0E17\u0E35\u0E48\u0E44\u0E21\u0E48\u0E43\u0E0A\u0E49\u0E15\u0E31\u0E27\u0E2D\u0E31\u0E01\u0E29\u0E23 \u0E15\u0E31\u0E27\u0E40\u0E25\u0E02 \u0E2B\u0E23\u0E37\u0E2D underscore \u0E2B\u0E23\u0E37\u0E2D\u0E1E\u0E39\u0E14\u0E2D\u0E35\u0E01\u0E41\u0E1A\u0E1A\u0E01\u0E47\u0E04\u0E37\u0E2D \u0E21\u0E31\u0E19\u0E08\u0E30\u0E41\u0E1A\u0E48\u0E07\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E15\u0E23\u0E07\u0E17\u0E35\u0E48\u0E21\u0E35\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E41\u0E25\u0E30\u0E40\u0E04\u0E23\u0E37\u0E48\u0E2D\u0E07\u0E2B\u0E21\u0E32\u0E22\u0E27\u0E23\u0E23\u0E04\u0E15\u0E2D\u0E19 \u0E19\u0E31\u0E48\u0E19\u0E40\u0E2D\u0E07"),Kl=f(),k(Rs.$$.fragment),Hl=f(),k(Gs.$$.fragment),Yl=f(),Ie=l("p"),Zc=n("\u0E41\u0E15\u0E48\u0E16\u0E49\u0E32\u0E04\u0E38\u0E13\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E32\u0E23\u0E08\u0E30\u0E41\u0E1A\u0E48\u0E07\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E15\u0E32\u0E21\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E40\u0E17\u0E48\u0E32\u0E19\u0E31\u0E49\u0E19 \u0E43\u0E2B\u0E49\u0E43\u0E0A\u0E49 "),Ir=l("code"),Qc=n("WhitespaceSplit"),ek=n(" pre-tokenizer :"),Jl=f(),k(Ms.$$.fragment),Vl=f(),k(Xs.$$.fragment),Zl=f(),Re=l("p"),sk=n("\u0E40\u0E2B\u0E21\u0E37\u0E2D\u0E19\u0E01\u0E31\u0E1A\u0E43\u0E19 normalizer \u0E40\u0E23\u0E32\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49 "),Rr=l("code"),tk=n("Sequence"),nk=n(" \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E23\u0E27\u0E21\u0E2B\u0E25\u0E32\u0E22\u0E46 pre-tokenizers \u0E40\u0E02\u0E49\u0E32\u0E14\u0E49\u0E27\u0E22\u0E01\u0E31\u0E19 :"),Ql=f(),k(Ks.$$.fragment),ea=f(),k(Hs.$$.fragment),sa=f(),Ys=l("p"),rk=n(`\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E43\u0E19 tokenization pipeline \u0E04\u0E37\u0E2D\u0E01\u0E32\u0E23\u0E43\u0E2A\u0E48 input \u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E43\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25
\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E42\u0E21\u0E40\u0E14\u0E25\u0E02\u0E36\u0E49\u0E19\u0E21\u0E32\u0E41\u0E25\u0E49\u0E27 \u0E41\u0E15\u0E48\u0E40\u0E23\u0E32\u0E22\u0E31\u0E07\u0E04\u0E07\u0E15\u0E49\u0E2D\u0E07\u0E40\u0E17\u0E23\u0E19\u0E21\u0E31\u0E19 \u0E0B\u0E36\u0E48\u0E07\u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49 `),Gr=l("code"),ok=n("WordPieceTrainer"),ta=f(),cn=l("p"),lk=n("\u0E2A\u0E34\u0E48\u0E07\u0E2A\u0E33\u0E04\u0E31\u0E0D\u0E17\u0E35\u0E48\u0E04\u0E38\u0E13\u0E15\u0E49\u0E2D\u0E07\u0E08\u0E33\u0E04\u0E37\u0E2D \u0E40\u0E27\u0E25\u0E32\u0E2A\u0E23\u0E49\u0E32\u0E07 (instantiate) trainer \u0E43\u0E19 \u{1F917} Tokenizers \u0E04\u0E38\u0E13\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E40\u0E1E\u0E34\u0E48\u0E21 token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E15\u0E48\u0E32\u0E07\u0E46 \u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E43\u0E19\u0E40\u0E17\u0E23\u0E19\u0E40\u0E19\u0E2D\u0E23\u0E4C\u0E40\u0E2D\u0E07 \u0E44\u0E21\u0E48\u0E40\u0E0A\u0E48\u0E19\u0E19\u0E31\u0E49\u0E19 \u0E21\u0E31\u0E19\u0E08\u0E30\u0E44\u0E21\u0E48\u0E40\u0E1E\u0E34\u0E48\u0E21 token \u0E1E\u0E27\u0E01\u0E19\u0E35\u0E49\u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E43\u0E19 vocabulary \u0E40\u0E1E\u0E23\u0E32\u0E30\u0E27\u0E48\u0E32 token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E44\u0E21\u0E48\u0E44\u0E14\u0E49\u0E2D\u0E22\u0E39\u0E48\u0E43\u0E19 training corpus :"),na=f(),k(Js.$$.fragment),ra=f(),D=l("p"),ak=n("\u0E19\u0E2D\u0E01\u0E08\u0E32\u0E01\u0E40\u0E23\u0E32\u0E08\u0E30\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32 "),Mr=l("code"),ik=n("vocab_size"),pk=n(" \u0E41\u0E25\u0E30 "),Xr=l("code"),fk=n("special_tokens"),ck=n(" \u0E41\u0E25\u0E49\u0E27 \u0E40\u0E23\u0E32\u0E22\u0E31\u0E07\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32 "),Kr=l("code"),kk=n("min_frequency"),mk=n(" (\u0E04\u0E27\u0E32\u0E21\u0E16\u0E35\u0E48\u0E02\u0E31\u0E49\u0E19\u0E15\u0E48\u0E33\u0E02\u0E2D\u0E07\u0E04\u0E33\u0E17\u0E35\u0E48\u0E15\u0E49\u0E2D\u0E07\u0E21\u0E35 \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E17\u0E35\u0E48\u0E08\u0E30\u0E44\u0E14\u0E49\u0E16\u0E39\u0E01\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E25\u0E07\u0E44\u0E1B\u0E43\u0E19 vocabulary) \u0E2B\u0E23\u0E37\u0E2D "),Hr=l("code"),dk=n("continuing_subword_prefix"),_k=n(" (\u0E16\u0E49\u0E32\u0E2B\u0E32\u0E01\u0E40\u0E23\u0E32\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E32\u0E23\u0E43\u0E0A\u0E49\u0E2A\u0E31\u0E0D\u0E25\u0E31\u0E01\u0E29\u0E13\u0E4C\u0E2D\u0E37\u0E48\u0E19 \u0E17\u0E35\u0E48\u0E44\u0E21\u0E48\u0E43\u0E0A\u0E48"),Yr=l("code"),$k=n("##"),uk=n(") \u0E44\u0E14\u0E49\u0E2D\u0E35\u0E01\u0E14\u0E49\u0E27\u0E22"),oa=f(),kn=l("p"),zk=n("\u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E17\u0E23\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25\u0E42\u0E14\u0E22\u0E23\u0E31\u0E19\u0E04\u0E33\u0E2A\u0E31\u0E48\u0E07\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E19\u0E35\u0E49 :"),la=f(),k(Vs.$$.fragment),aa=f(),Ge=l("p"),hk=n("\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49\u0E44\u0E1F\u0E25\u0E4C\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E40\u0E17\u0E23\u0E19\u0E44\u0E14\u0E49\u0E14\u0E49\u0E27\u0E22 (\u0E41\u0E15\u0E48\u0E01\u0E48\u0E2D\u0E19\u0E2D\u0E37\u0E48\u0E19 \u0E04\u0E38\u0E13\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E42\u0E21\u0E40\u0E14\u0E25\u0E02\u0E36\u0E49\u0E19\u0E21\u0E32\u0E43\u0E2B\u0E21\u0E48\u0E42\u0E14\u0E22\u0E43\u0E0A\u0E49 "),Jr=l("code"),Ek=n("WordPiece"),jk=n(" \u0E17\u0E35\u0E48\u0E22\u0E31\u0E07\u0E27\u0E48\u0E32\u0E07\u0E40\u0E1B\u0E25\u0E48\u0E32\u0E2D\u0E22\u0E39\u0E48) :"),ia=f(),k(Zs.$$.fragment),pa=f(),Me=l("p"),vk=n("\u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A\u0E17\u0E31\u0E49\u0E07\u0E2A\u0E2D\u0E07\u0E01\u0E23\u0E13\u0E35 \u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E17\u0E14\u0E25\u0E2D\u0E07\u0E43\u0E0A\u0E49 tokenizer \u0E01\u0E31\u0E1A\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E44\u0E14\u0E49 \u0E42\u0E14\u0E22\u0E40\u0E23\u0E35\u0E22\u0E01\u0E43\u0E0A\u0E49 "),Vr=l("code"),bk=n("encode()"),xk=n(" method :"),fa=f(),k(Qs.$$.fragment),ca=f(),k(et.$$.fragment),ka=f(),v=l("p"),Zr=l("code"),gk=n("encoding"),Pk=n(" \u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E04\u0E37\u0E2D "),Qr=l("code"),wk=n("Encoding"),qk=n(" \u0E17\u0E35\u0E48\u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22\u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E08\u0E33\u0E40\u0E1B\u0E47\u0E19\u0E15\u0E48\u0E32\u0E07\u0E46\u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A tokenizer \u0E44\u0E14\u0E49\u0E41\u0E01\u0E48 "),eo=l("code"),Tk=n("ids"),Dk=n(", "),so=l("code"),Ck=n("type_ids"),yk=n(", "),to=l("code"),Ok=n("tokens"),Lk=n(", "),no=l("code"),Sk=n("offsets"),Bk=n(", "),ro=l("code"),Nk=n("attention_mask"),Fk=n(", "),oo=l("code"),Ak=n("special_tokens_mask"),Wk=n(", \u0E41\u0E25\u0E30 "),lo=l("code"),Uk=n("overflowing"),ma=f(),_e=l("p"),Ik=n(`\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E2A\u0E38\u0E14\u0E17\u0E49\u0E32\u0E22\u0E02\u0E2D\u0E07 pipeline \u0E04\u0E37\u0E2D post-processing
\u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E1E\u0E34\u0E48\u0E21 `),ao=l("code"),Rk=n("[CLS]"),Gk=n(" \u0E44\u0E27\u0E49\u0E17\u0E35\u0E48\u0E15\u0E2D\u0E19\u0E15\u0E49\u0E19\u0E02\u0E2D\u0E07\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E08\u0E32\u0E01\u0E01\u0E32\u0E23 tokenize \u0E41\u0E25\u0E30 "),io=l("code"),Mk=n("[SEP]"),Xk=n(" \u0E44\u0E27\u0E49\u0E17\u0E35\u0E48\u0E15\u0E2D\u0E19\u0E17\u0E49\u0E32\u0E22 \u0E2B\u0E23\u0E37\u0E2D\u0E2B\u0E25\u0E31\u0E07\u0E2A\u0E34\u0E49\u0E19\u0E2A\u0E38\u0E14\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04 \u0E16\u0E49\u0E32 input \u0E02\u0E2D\u0E07\u0E40\u0E23\u0E32\u0E21\u0E35\u0E2A\u0E2D\u0E07\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04"),da=f(),I=l("p"),Kk=n("\u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49 "),po=l("code"),Hk=n("TemplateProcessor"),Yk=n(" \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E0A\u0E48\u0E27\u0E22\u0E40\u0E23\u0E32\u0E17\u0E33 \u0E41\u0E15\u0E48\u0E01\u0E48\u0E2D\u0E19\u0E2D\u0E37\u0E48\u0E19\u0E40\u0E23\u0E32\u0E15\u0E49\u0E2D\u0E07\u0E2B\u0E32 ID \u0E02\u0E2D\u0E07 "),fo=l("code"),Jk=n("[CLS]"),Vk=n(" \u0E41\u0E25\u0E30 "),co=l("code"),Zk=n("[SEP]"),Qk=n(" \u0E01\u0E48\u0E2D\u0E19 :"),_a=f(),k(st.$$.fragment),$a=f(),k(tt.$$.fragment),ua=f(),R=l("p"),em=n("\u0E40\u0E23\u0E32\u0E08\u0E30\u0E21\u0E32\u0E2A\u0E23\u0E49\u0E32\u0E07 template \u0E43\u0E2B\u0E49\u0E01\u0E31\u0E1A "),ko=l("code"),sm=n("TemplateProcessor"),tm=n(` \u0E42\u0E14\u0E22\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E33\u0E2B\u0E19\u0E14\u0E27\u0E48\u0E32\u0E40\u0E23\u0E32\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E32\u0E23\u0E43\u0E2B\u0E49\u0E21\u0E31\u0E19\u0E1B\u0E23\u0E30\u0E21\u0E27\u0E25\u0E1C\u0E25 input \u0E17\u0E35\u0E48\u0E40\u0E1B\u0E47\u0E19 \u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E40\u0E14\u0E35\u0E48\u0E22\u0E27 \u0E41\u0E25\u0E30 input \u0E17\u0E35\u0E48\u0E21\u0E35\u0E2A\u0E2D\u0E07\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E44\u0E23
\u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A\u0E17\u0E31\u0E49\u0E07\u0E2A\u0E2D\u0E07\u0E01\u0E23\u0E13\u0E35 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E33\u0E2B\u0E19\u0E14 token \u0E1E\u0E34\u0E40\u0E28\u0E29 \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E41\u0E17\u0E19\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E02\u0E36\u0E49\u0E19\u0E21\u0E32 \u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E40\u0E14\u0E35\u0E48\u0E22\u0E27\u0E2B\u0E23\u0E37\u0E2D\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E41\u0E23\u0E01 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49 `),mo=l("code"),nm=n("$A"),rm=n(" \u0E2A\u0E48\u0E27\u0E19\u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E17\u0E35\u0E48\u0E2A\u0E2D\u0E07 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49 "),_o=l("code"),om=n("$B"),lm=n(`
\u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E1E\u0E27\u0E01\u0E19\u0E35\u0E49\u0E41\u0E25\u0E30\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E2A\u0E23\u0E49\u0E32\u0E07 token type ID \u0E02\u0E36\u0E49\u0E19\u0E21\u0E32 \u0E42\u0E14\u0E22\u0E08\u0E30\u0E40\u0E02\u0E35\u0E22\u0E19 ID \u0E19\u0E35\u0E49\u0E2B\u0E25\u0E31\u0E07\u0E40\u0E04\u0E23\u0E37\u0E48\u0E2D\u0E07\u0E2B\u0E21\u0E32\u0E22 colon`),za=f(),mn=l("p"),am=n("template \u0E02\u0E2D\u0E07 BERT \u0E21\u0E35\u0E23\u0E32\u0E22\u0E25\u0E30\u0E40\u0E2D\u0E35\u0E22\u0E14\u0E14\u0E31\u0E07\u0E19\u0E35\u0E49 :"),ha=f(),k(nt.$$.fragment),Ea=f(),dn=l("p"),im=n("\u0E2D\u0E22\u0E48\u0E32\u0E25\u0E37\u0E21\u0E27\u0E48\u0E32 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E43\u0E2B\u0E49\u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E42\u0E21\u0E40\u0E14\u0E25\u0E40\u0E01\u0E35\u0E48\u0E22\u0E27\u0E01\u0E31\u0E1A ID \u0E02\u0E2D\u0E07 token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E14\u0E49\u0E27\u0E22 \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E17\u0E35\u0E48\u0E42\u0E21\u0E40\u0E14\u0E25\u0E08\u0E30\u0E44\u0E14\u0E49\u0E41\u0E1B\u0E25\u0E07\u0E21\u0E31\u0E19\u0E44\u0E14\u0E49\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E16\u0E39\u0E01\u0E15\u0E49\u0E2D\u0E07"),ja=f(),_n=l("p"),pm=n("\u0E40\u0E23\u0E32\u0E08\u0E30\u0E01\u0E25\u0E31\u0E1A\u0E21\u0E32\u0E14\u0E39\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E01\u0E48\u0E2D\u0E19\u0E2B\u0E19\u0E49\u0E32\u0E01\u0E31\u0E19 :"),va=f(),k(rt.$$.fragment),ba=f(),k(ot.$$.fragment),xa=f(),$n=l("p"),fm=n("\u0E16\u0E49\u0E32\u0E40\u0E23\u0E32\u0E43\u0E2A\u0E48 input \u0E17\u0E35\u0E48\u0E40\u0E1B\u0E47\u0E19\u0E2A\u0E2D\u0E07\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E44\u0E14\u0E49 :"),ga=f(),k(lt.$$.fragment),Pa=f(),k(at.$$.fragment),wa=f(),un=l("p"),cm=n("\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E2A\u0E38\u0E14\u0E17\u0E49\u0E32\u0E22 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E1E\u0E34\u0E48\u0E21 decoder \u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E43\u0E19 pipeline :"),qa=f(),k(it.$$.fragment),Ta=f(),Xe=l("p"),km=n("\u0E21\u0E32\u0E14\u0E39\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E02\u0E2D\u0E07 "),$o=l("code"),mm=n("encoding"),dm=n(" \u0E01\u0E31\u0E19 :"),Da=f(),k(pt.$$.fragment),Ca=f(),k(ft.$$.fragment),ya=f(),zn=l("p"),_m=n("\u0E40\u0E22\u0E35\u0E48\u0E22\u0E21\u0E21\u0E32\u0E01! \u0E15\u0E2D\u0E19\u0E19\u0E35\u0E49\u0E40\u0E23\u0E32\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E1A\u0E31\u0E19\u0E17\u0E36\u0E01 tokenizer \u0E19\u0E35\u0E49\u0E40\u0E1B\u0E47\u0E19\u0E44\u0E1F\u0E25\u0E4C JSON \u0E44\u0E14\u0E49\u0E41\u0E25\u0E49\u0E27 \u0E14\u0E31\u0E07\u0E19\u0E35\u0E49 :"),Oa=f(),k(ct.$$.fragment),La=f(),$e=l("p"),$m=n("\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E42\u0E2B\u0E25\u0E14\u0E44\u0E1F\u0E25\u0E4C\u0E19\u0E35\u0E49\u0E43\u0E2B\u0E49\u0E40\u0E1B\u0E47\u0E19 "),uo=l("code"),um=n("Tokenizer"),zm=n(" object \u0E44\u0E14\u0E49\u0E42\u0E14\u0E22\u0E43\u0E0A\u0E49 "),zo=l("code"),hm=n("from_file()"),Em=n(" method :"),Sa=f(),k(kt.$$.fragment),Ba=f(),ue=l("p"),jm=n("\u0E01\u0E32\u0E23\u0E08\u0E30\u0E19\u0E33 tokenizer \u0E19\u0E35\u0E49\u0E21\u0E32\u0E43\u0E0A\u0E49\u0E43\u0E19 \u{1F917} Transformers \u0E40\u0E23\u0E32\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07 wrap \u0E21\u0E31\u0E19\u0E43\u0E2B\u0E49\u0E40\u0E1B\u0E47\u0E19 "),ho=l("code"),vm=n("PreTrainedTokenizerFast"),bm=n(` \u0E01\u0E48\u0E2D\u0E19
\u0E42\u0E14\u0E22\u0E40\u0E23\u0E32\u0E43\u0E0A\u0E49 class \u0E1B\u0E01\u0E15\u0E34 (\u0E16\u0E49\u0E32 tokenizer \u0E02\u0E2D\u0E07\u0E40\u0E23\u0E32\u0E21\u0E35\u0E42\u0E04\u0E23\u0E07\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E2A\u0E2D\u0E14\u0E04\u0E25\u0E49\u0E2D\u0E07\u0E01\u0E31\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25\u0E2B\u0E25\u0E31\u0E01\u0E40\u0E23\u0E32\u0E17\u0E35\u0E48\u0E08\u0E30\u0E43\u0E0A\u0E49\u0E07\u0E32\u0E19) \u0E2B\u0E23\u0E37\u0E2D class \u0E17\u0E35\u0E48\u0E16\u0E39\u0E01\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E02\u0E36\u0E49\u0E19\u0E21\u0E32\u0E41\u0E25\u0E49\u0E27 \u0E40\u0E0A\u0E48\u0E19 `),Eo=l("code"),xm=n("BertTokenizerFast"),gm=n(`
\u0E43\u0E19\u0E01\u0E23\u0E13\u0E35\u0E17\u0E35\u0E48\u0E04\u0E38\u0E13\u0E2A\u0E23\u0E49\u0E32\u0E07 tokenizer \u0E02\u0E36\u0E49\u0E19\u0E21\u0E32\u0E40\u0E2D\u0E07\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E2A\u0E2D\u0E19\u0E44\u0E27\u0E49\u0E02\u0E49\u0E32\u0E07\u0E15\u0E49\u0E19 \u0E04\u0E38\u0E13\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E43\u0E0A\u0E49\u0E15\u0E31\u0E27\u0E40\u0E25\u0E37\u0E2D\u0E01\u0E41\u0E23\u0E01`),Na=f(),C=l("p"),Pm=n("\u0E01\u0E32\u0E23\u0E08\u0E30 wrap tokenizer \u0E02\u0E2D\u0E07\u0E40\u0E23\u0E32\u0E43\u0E2B\u0E49\u0E40\u0E1B\u0E47\u0E19 "),jo=l("code"),wm=n("PreTrainedTokenizerFast"),qm=n(" \u0E40\u0E23\u0E32\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E2A\u0E48\u0E07\u0E1C\u0E48\u0E32\u0E19 tokenizer \u0E02\u0E2D\u0E07\u0E40\u0E23\u0E32\u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E40\u0E1B\u0E47\u0E19 "),vo=l("code"),Tm=n("tokenizer_object"),Dm=n(" \u0E2B\u0E23\u0E37\u0E2D \u0E2A\u0E48\u0E07\u0E1C\u0E48\u0E32\u0E19\u0E44\u0E1F\u0E25\u0E4C\u0E02\u0E2D\u0E07 tokenizer \u0E40\u0E1B\u0E47\u0E19 "),bo=l("code"),Cm=n("tokenizer_file"),ym=n(`
\u0E2A\u0E34\u0E48\u0E07\u0E2A\u0E33\u0E04\u0E31\u0E0D\u0E2D\u0E35\u0E01\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E04\u0E37\u0E2D \u0E04\u0E38\u0E13\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E2A\u0E48\u0E07\u0E1C\u0E48\u0E32\u0E19\u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E40\u0E01\u0E35\u0E48\u0E22\u0E27\u0E01\u0E31\u0E1A token \u0E1E\u0E34\u0E40\u0E28\u0E29 \u0E15\u0E48\u0E32\u0E07\u0E46\u0E43\u0E2B\u0E49\u0E42\u0E21\u0E40\u0E14\u0E25\u0E40\u0E2D\u0E07 \u0E40\u0E1E\u0E23\u0E32\u0E30\u0E27\u0E48\u0E32 class \u0E19\u0E35\u0E49\u0E08\u0E30\u0E44\u0E21\u0E48\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16 infer \u0E08\u0E32\u0E01 `),xo=l("code"),Om=n("tokenizer"),Lm=n(" object \u0E44\u0E14\u0E49\u0E40\u0E2D\u0E07 \u0E27\u0E48\u0E32 token \u0E15\u0E31\u0E27\u0E44\u0E2B\u0E19\u0E40\u0E1B\u0E47\u0E19 mask token \u0E40\u0E0A\u0E48\u0E19 "),go=l("code"),Sm=n("[CLS]"),Bm=n(" :"),Fa=f(),k(mt.$$.fragment),Aa=f(),Ke=l("p"),Nm=n("\u0E16\u0E49\u0E32\u0E04\u0E38\u0E13\u0E43\u0E0A\u0E49 class \u0E17\u0E35\u0E48\u0E40\u0E09\u0E1E\u0E32\u0E30\u0E40\u0E08\u0E32\u0E30\u0E08\u0E07 \u0E40\u0E0A\u0E48\u0E19 "),Po=l("code"),Fm=n("BertTokenizerFast"),Am=n(" \u0E04\u0E38\u0E13\u0E40\u0E1E\u0E35\u0E22\u0E07\u0E41\u0E04\u0E48\u0E15\u0E49\u0E2D\u0E07\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E40\u0E01\u0E35\u0E48\u0E22\u0E27\u0E01\u0E31\u0E1A token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E17\u0E35\u0E48\u0E15\u0E48\u0E32\u0E07\u0E08\u0E32\u0E01\u0E15\u0E31\u0E27\u0E17\u0E35\u0E48\u0E42\u0E21\u0E40\u0E14\u0E25\u0E43\u0E0A\u0E49\u0E2D\u0E22\u0E39\u0E48\u0E41\u0E25\u0E49\u0E27 \u0E43\u0E19\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E02\u0E2D\u0E07\u0E40\u0E23\u0E32 \u0E40\u0E23\u0E32\u0E44\u0E21\u0E48\u0E44\u0E14\u0E49\u0E43\u0E0A\u0E49 token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E2D\u0E37\u0E48\u0E19 \u0E08\u0E36\u0E07\u0E44\u0E21\u0E48\u0E15\u0E49\u0E2D\u0E07\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E2D\u0E30\u0E44\u0E23 :"),Wa=f(),k(dt.$$.fragment),Ua=f(),Pe=l("p"),Wm=n("\u0E15\u0E2D\u0E19\u0E19\u0E35\u0E49\u0E40\u0E23\u0E32\u0E01\u0E47\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49 tokenizer \u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E02\u0E36\u0E49\u0E19\u0E21\u0E32\u0E40\u0E2D\u0E07 \u0E40\u0E2B\u0E21\u0E37\u0E2D\u0E19\u0E01\u0E31\u0E1A tokenizer \u0E15\u0E31\u0E27\u0E2D\u0E37\u0E48\u0E19\u0E46\u0E08\u0E32\u0E01 \u{1F917} Transformers \u0E44\u0E14\u0E49\u0E41\u0E25\u0E49\u0E27 \u0E19\u0E2D\u0E01\u0E08\u0E32\u0E01\u0E19\u0E31\u0E49\u0E19\u0E04\u0E38\u0E13\u0E22\u0E31\u0E07\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E40\u0E0B\u0E1F\u0E21\u0E31\u0E19\u0E44\u0E14\u0E49 \u0E42\u0E14\u0E22\u0E43\u0E0A\u0E49 "),wo=l("code"),Um=n("save_pretrained()"),Im=n(" \u0E2B\u0E23\u0E37\u0E2D\u0E2D\u0E31\u0E1E\u0E42\u0E2B\u0E25\u0E14\u0E21\u0E31\u0E19\u0E44\u0E1B\u0E17\u0E35\u0E48 Hub \u0E42\u0E14\u0E22\u0E43\u0E0A\u0E49 "),qo=l("code"),Rm=n("push_to_hub()"),Ia=f(),hn=l("p"),Gm=n("\u0E2B\u0E25\u0E31\u0E07\u0E08\u0E32\u0E01\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E14\u0E39\u0E01\u0E31\u0E19\u0E41\u0E25\u0E49\u0E27\u0E27\u0E48\u0E32\u0E08\u0E30\u0E2A\u0E23\u0E49\u0E32\u0E07 WordPiece tokenizer \u0E2D\u0E22\u0E48\u0E32\u0E07\u0E44\u0E23 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E21\u0E32\u0E14\u0E39\u0E01\u0E31\u0E19\u0E27\u0E48\u0E32 \u0E08\u0E30\u0E17\u0E33\u0E41\u0E1A\u0E1A\u0E40\u0E14\u0E35\u0E22\u0E27\u0E01\u0E31\u0E19\u0E01\u0E31\u0E1A BPE tokenizer \u0E44\u0E14\u0E49\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E44\u0E23 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E2D\u0E18\u0E34\u0E1A\u0E32\u0E22\u0E04\u0E23\u0E48\u0E32\u0E27\u0E46\u0E40\u0E17\u0E48\u0E32\u0E19\u0E31\u0E49\u0E19 \u0E40\u0E1E\u0E23\u0E32\u0E30\u0E04\u0E38\u0E13\u0E44\u0E14\u0E49\u0E40\u0E23\u0E35\u0E22\u0E19\u0E23\u0E32\u0E22\u0E25\u0E30\u0E40\u0E2D\u0E35\u0E22\u0E14\u0E21\u0E32\u0E41\u0E25\u0E49\u0E27 \u0E41\u0E25\u0E30\u0E08\u0E30\u0E1E\u0E39\u0E14\u0E16\u0E36\u0E07\u0E41\u0E04\u0E48\u0E02\u0E49\u0E2D\u0E41\u0E15\u0E01\u0E15\u0E48\u0E32\u0E07\u0E40\u0E17\u0E48\u0E32\u0E19\u0E31\u0E49\u0E19"),Ra=f(),we=l("h2"),He=l("a"),To=l("span"),k(_t.$$.fragment),Mm=f(),Do=l("span"),Xm=n("\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 BPE tokenizer \u0E15\u0E31\u0E49\u0E07\u0E41\u0E15\u0E48\u0E40\u0E23\u0E34\u0E48\u0E21\u0E15\u0E49\u0E19"),Ga=f(),Ye=l("p"),Km=n("\u0E40\u0E23\u0E32\u0E08\u0E30\u0E21\u0E32\u0E2A\u0E23\u0E49\u0E32\u0E07 GPT-2 tokenizer \u0E01\u0E31\u0E19 \u0E40\u0E0A\u0E48\u0E19\u0E40\u0E14\u0E35\u0E22\u0E27\u0E01\u0E31\u0E1A\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E02\u0E2D\u0E07 BERT tokenizer \u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E23\u0E34\u0E48\u0E21\u0E14\u0E49\u0E27\u0E22\u0E01\u0E31\u0E19 initialize "),Co=l("code"),Hm=n("Tokenizer"),Ym=n(" \u0E14\u0E49\u0E27\u0E22\u0E42\u0E21\u0E40\u0E14\u0E25 BPE :"),Ma=f(),k($t.$$.fragment),Xa=f(),G=l("p"),Jm=n("\u0E40\u0E23\u0E32\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E42\u0E21\u0E40\u0E14\u0E25\u0E19\u0E35\u0E49\u0E14\u0E49\u0E27\u0E22 vocabulary \u0E17\u0E35\u0E48\u0E21\u0E35\u0E2D\u0E22\u0E39\u0E48\u0E44\u0E14\u0E49 \u0E42\u0E14\u0E22\u0E2A\u0E48\u0E07\u0E1C\u0E48\u0E32\u0E19 "),yo=l("code"),Vm=n("vocab"),Zm=n(" \u0E41\u0E25\u0E30 "),Oo=l("code"),Qm=n("merges"),ed=n(` \u0E41\u0E15\u0E48\u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E17\u0E23\u0E19\u0E15\u0E31\u0E49\u0E07\u0E41\u0E15\u0E48\u0E15\u0E49\u0E19 \u0E41\u0E1B\u0E25\u0E27\u0E48\u0E32\u0E40\u0E23\u0E32\u0E44\u0E21\u0E48\u0E08\u0E33\u0E40\u0E1B\u0E47\u0E19\u0E15\u0E49\u0E2D\u0E07\u0E17\u0E33\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E19\u0E35\u0E49
\u0E40\u0E23\u0E32\u0E44\u0E21\u0E48\u0E08\u0E33\u0E40\u0E1B\u0E47\u0E19\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E33\u0E2B\u0E19\u0E14 `),Lo=l("code"),sd=n("unk_token"),td=n(" \u0E40\u0E1E\u0E23\u0E32\u0E30 GPT-2 \u0E43\u0E0A\u0E49 byte-level BPE"),Ka=f(),En=l("p"),nd=n("\u0E19\u0E2D\u0E01\u0E08\u0E32\u0E01\u0E19\u0E31\u0E49\u0E19 GPT-2 \u0E22\u0E31\u0E07\u0E44\u0E21\u0E48\u0E43\u0E0A\u0E49 normalizer \u0E2D\u0E35\u0E01\u0E14\u0E49\u0E27\u0E22 \u0E40\u0E23\u0E32\u0E08\u0E36\u0E07\u0E08\u0E30\u0E02\u0E49\u0E32\u0E21\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E19\u0E35\u0E49\u0E44\u0E1B\u0E17\u0E33 pre-tokenization \u0E40\u0E25\u0E22 :"),Ha=f(),k(ut.$$.fragment),Ya=f(),zt=l("p"),So=l("code"),rd=n("add_prefix_space=False"),od=n(" \u0E2B\u0E21\u0E32\u0E22\u0E16\u0E36\u0E07\u0E40\u0E23\u0E32\u0E08\u0E30\u0E44\u0E21\u0E48\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E15\u0E23\u0E07\u0E15\u0E49\u0E19\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04 (\u0E04\u0E48\u0E32 default \u0E08\u0E30\u0E21\u0E35\u0E01\u0E32\u0E23\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E19\u0E35\u0E49)"),Ja=f(),jn=l("p"),ld=n("\u0E21\u0E32\u0E14\u0E39\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E02\u0E2D\u0E07\u0E01\u0E32\u0E23 pre-tokenization \u0E01\u0E31\u0E19 :"),Va=f(),k(ht.$$.fragment),Za=f(),k(Et.$$.fragment),Qa=f(),vn=l("p"),ad=n("\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E04\u0E37\u0E2D\u0E01\u0E32\u0E23\u0E40\u0E17\u0E23\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25  \u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A GPT-2 \u0E21\u0E31\u0E19\u0E08\u0E30\u0E21\u0E35 token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E15\u0E31\u0E27\u0E40\u0E14\u0E35\u0E22\u0E27\u0E04\u0E37\u0E2D end-of-text token (\u0E2D\u0E22\u0E39\u0E48\u0E15\u0E23\u0E07\u0E17\u0E49\u0E32\u0E22\u0E02\u0E2D\u0E07\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21) :"),ei=f(),k(jt.$$.fragment),si=f(),g=l("p"),id=n("\u0E40\u0E0A\u0E48\u0E19\u0E40\u0E14\u0E35\u0E22\u0E27\u0E01\u0E31\u0E19\u0E01\u0E31\u0E1A "),Bo=l("code"),pd=n("WordPieceTrainer"),fd=n(" \u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E01\u0E33\u0E2B\u0E19\u0E14 "),No=l("code"),cd=n("vocab_size"),kd=n(", "),Fo=l("code"),md=n("special_tokens"),dd=n(", "),Ao=l("code"),_d=n("min_frequency"),$d=n(" \u0E44\u0E14\u0E49 \u0E16\u0E49\u0E32\u0E2B\u0E32\u0E01\u0E04\u0E38\u0E13\u0E43\u0E0A\u0E49 end-of-word suffix (\u0E40\u0E0A\u0E48\u0E19 "),Wo=l("code"),ud=n("</w>"),zd=n(") \u0E04\u0E38\u0E13\u0E01\u0E47\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32\u0E21\u0E31\u0E19\u0E44\u0E14\u0E49\u0E14\u0E49\u0E27\u0E22 "),Uo=l("code"),hd=n("end_of_word_suffix"),ti=f(),bn=l("p"),Ed=n("\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E40\u0E17\u0E23\u0E19\u0E14\u0E49\u0E27\u0E22\u0E44\u0E1F\u0E25\u0E4C\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E44\u0E14\u0E49\u0E14\u0E49\u0E27\u0E22 :"),ni=f(),k(vt.$$.fragment),ri=f(),xn=l("p"),jd=n("\u0E21\u0E32\u0E14\u0E39\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E02\u0E2D\u0E07\u0E01\u0E32\u0E23 tokenize \u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E01\u0E31\u0E19 :"),oi=f(),k(bt.$$.fragment),li=f(),k(xt.$$.fragment),ai=f(),gn=l("p"),vd=n("\u0E40\u0E23\u0E32\u0E08\u0E30\u0E17\u0E33\u0E01\u0E32\u0E23 post-processing \u0E41\u0E1A\u0E1A byte-level \u0E43\u0E2B\u0E49\u0E01\u0E31\u0E1A GPT-2 tokenizer \u0E14\u0E31\u0E07\u0E19\u0E35\u0E49 :"),ii=f(),k(gt.$$.fragment),pi=f(),qe=l("p"),Io=l("code"),bd=n("trim_offsets = False"),xd=n(" \u0E41\u0E1B\u0E25\u0E27\u0E48\u0E32\u0E40\u0E23\u0E32\u0E08\u0E30\u0E44\u0E21\u0E48\u0E40\u0E1B\u0E25\u0E35\u0E48\u0E22\u0E19\u0E41\u0E1B\u0E25\u0E07\u0E04\u0E48\u0E32 offset \u0E02\u0E2D\u0E07 token \u0E17\u0E35\u0E48\u0E02\u0E36\u0E49\u0E19\u0E15\u0E49\u0E19\u0E14\u0E49\u0E27\u0E22 "),Ro=l("code"),gd=n("\u0120"),Pd=n(" \u0E0B\u0E36\u0E48\u0E07\u0E41\u0E1B\u0E25\u0E27\u0E48\u0E32\u0E15\u0E33\u0E41\u0E2B\u0E19\u0E48\u0E07\u0E40\u0E23\u0E34\u0E48\u0E21\u0E15\u0E49\u0E19\u0E02\u0E2D\u0E07 offset \u0E08\u0E30\u0E2B\u0E21\u0E32\u0E22\u0E16\u0E36\u0E07 \u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07 \u0E41\u0E25\u0E30\u0E44\u0E21\u0E48\u0E43\u0E0A\u0E48\u0E15\u0E31\u0E27\u0E2D\u0E31\u0E01\u0E29\u0E23\u0E41\u0E23\u0E01\u0E02\u0E2D\u0E07 token \u0E19\u0E31\u0E49\u0E19"),fi=f(),Je=l("p"),wd=n("\u0E21\u0E32\u0E14\u0E39\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E02\u0E2D\u0E07\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E40\u0E1E\u0E34\u0E48\u0E07\u0E08\u0E30 encode \u0E01\u0E31\u0E19\u0E44\u0E1B \u0E43\u0E19\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E19\u0E35\u0E49 token \u0E43\u0E19\u0E15\u0E33\u0E41\u0E2B\u0E19\u0E48\u0E07\u0E17\u0E35\u0E48 4 \u0E04\u0E37\u0E2D "),Go=l("code"),qd=n("'\u0120test'"),Td=n(" :"),ci=f(),k(Pt.$$.fragment),ki=f(),k(wt.$$.fragment),mi=f(),Pn=l("p"),Dd=n("\u0E2A\u0E38\u0E14\u0E17\u0E49\u0E32\u0E22\u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E2A\u0E48\u0E27\u0E19\u0E17\u0E35\u0E48\u0E40\u0E1B\u0E47\u0E19 byte-level decoder :"),di=f(),k(qt.$$.fragment),_i=f(),wn=l("p"),Cd=n("\u0E40\u0E0A\u0E47\u0E04\u0E14\u0E39\u0E2D\u0E35\u0E01\u0E17\u0E35\u0E27\u0E48\u0E32\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E16\u0E39\u0E01\u0E15\u0E49\u0E2D\u0E07\u0E2B\u0E23\u0E37\u0E2D\u0E44\u0E21\u0E48 :"),$i=f(),k(Tt.$$.fragment),ui=f(),k(Dt.$$.fragment),zi=f(),ze=l("p"),yd=n("\u0E40\u0E22\u0E35\u0E48\u0E22\u0E21\u0E21\u0E32\u0E01! \u0E15\u0E2D\u0E19\u0E19\u0E35\u0E49\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E40\u0E0B\u0E1F\u0E42\u0E21\u0E40\u0E14\u0E25\u0E44\u0E14\u0E49 \u0E2A\u0E48\u0E27\u0E19\u0E02\u0E31\u0E49\u0E19\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E04\u0E37\u0E2D \u0E40\u0E23\u0E32\u0E08\u0E30 wrap tokenizer \u0E02\u0E2D\u0E07\u0E40\u0E23\u0E32\u0E43\u0E2B\u0E49\u0E40\u0E1B\u0E47\u0E19 "),Mo=l("code"),Od=n("PreTrainedTokenizerFast"),Ld=n(" \u0E2B\u0E23\u0E37\u0E2D "),Xo=l("code"),Sd=n("GPT2TokenizerFast"),Bd=n(" \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E08\u0E30\u0E44\u0E14\u0E49\u0E40\u0E23\u0E35\u0E22\u0E01\u0E43\u0E0A\u0E49\u0E21\u0E31\u0E19\u0E44\u0E14\u0E49\u0E43\u0E19 \u{1F917} Transformers"),hi=f(),k(Ct.$$.fragment),Ei=f(),qn=l("p"),Nd=n("\u0E2B\u0E23\u0E37\u0E2D :"),ji=f(),k(yt.$$.fragment),vi=f(),Tn=l("p"),Fd=n("\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E40\u0E23\u0E32\u0E08\u0E30\u0E2A\u0E2D\u0E19\u0E27\u0E34\u0E18\u0E35\u0E2A\u0E23\u0E49\u0E32\u0E07 Unigram tokenizer \u0E1A\u0E49\u0E32\u0E07"),bi=f(),Te=l("h2"),Ve=l("a"),Ko=l("span"),k(Ot.$$.fragment),Ad=f(),Ho=l("span"),Wd=n("\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 Unigram tokenizer \u0E15\u0E31\u0E49\u0E07\u0E41\u0E15\u0E48\u0E40\u0E23\u0E34\u0E48\u0E21\u0E15\u0E49\u0E19"),xi=f(),Ze=l("p"),Ud=n("\u0E40\u0E23\u0E32\u0E08\u0E30\u0E2A\u0E23\u0E49\u0E32\u0E07 XLNet tokenizer \u0E42\u0E14\u0E22\u0E40\u0E23\u0E34\u0E48\u0E21\u0E08\u0E32\u0E01 initialize "),Yo=l("code"),Id=n("Tokenizer"),Rd=n(" \u0E14\u0E49\u0E27\u0E22 Unigram model !"),gi=f(),k(Lt.$$.fragment),Pi=f(),Dn=l("p"),Gd=n("\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16 initialize \u0E21\u0E31\u0E19\u0E42\u0E14\u0E22\u0E2A\u0E48\u0E07\u0E1C\u0E48\u0E32\u0E19 vocabulary \u0E17\u0E35\u0E48\u0E21\u0E35\u0E2D\u0E22\u0E39\u0E48\u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22"),wi=f(),Cn=l("p"),Md=n("\u0E43\u0E19\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19 normalization \u0E42\u0E21\u0E40\u0E14\u0E25 XLNet \u0E08\u0E30\u0E21\u0E35\u0E01\u0E32\u0E23\u0E41\u0E17\u0E19\u0E17\u0E35\u0E48\u0E15\u0E31\u0E27\u0E2D\u0E31\u0E01\u0E29\u0E23\u0E15\u0E48\u0E32\u0E07\u0E46 :"),qi=f(),k(St.$$.fragment),Ti=f(),M=l("p"),Xd=n("\u0E42\u0E04\u0E49\u0E14\u0E02\u0E49\u0E32\u0E07\u0E1A\u0E19\u0E19\u0E35\u0E49\u0E08\u0E30\u0E41\u0E17\u0E19\u0E17\u0E35\u0E48 "),Jo=l("code"),Kd=n("\u201C"),Hd=n(" \u0E41\u0E25\u0E30 "),Vo=l("code"),Yd=n("\u201D"),Jd=n(" \u0E14\u0E49\u0E27\u0E22 "),Zo=l("code"),Vd=n("\u201D"),Zd=n(`
\u0E41\u0E25\u0E30\u0E16\u0E49\u0E32\u0E21\u0E35\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E17\u0E35\u0E48\u0E2D\u0E22\u0E39\u0E48\u0E15\u0E48\u0E2D\u0E46\u0E01\u0E31\u0E19 \u0E21\u0E31\u0E19\u0E08\u0E30\u0E16\u0E39\u0E01\u0E41\u0E1B\u0E25\u0E07\u0E43\u0E2B\u0E49\u0E40\u0E1B\u0E47\u0E19\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E40\u0E14\u0E35\u0E22\u0E27 \u0E41\u0E25\u0E30\u0E2A\u0E38\u0E14\u0E17\u0E49\u0E32\u0E22\u0E21\u0E31\u0E19\u0E08\u0E30\u0E25\u0E1A\u0E2A\u0E31\u0E0D\u0E25\u0E31\u0E01\u0E29\u0E13\u0E4C accent \u0E2D\u0E2D\u0E01\u0E14\u0E49\u0E27\u0E22`),Di=f(),Qe=l("p"),Qd=n("pre-tokenizer \u0E17\u0E35\u0E48\u0E43\u0E0A\u0E49\u0E43\u0E19 SentencePiece tokenizer \u0E04\u0E37\u0E2D "),Qo=l("code"),e_=n("Metaspace"),s_=n("  :"),Ci=f(),k(Bt.$$.fragment),yi=f(),yn=l("p"),t_=n("\u0E21\u0E32\u0E14\u0E39\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E02\u0E2D\u0E07\u0E01\u0E32\u0E23 pre-tokenization \u0E01\u0E31\u0E1A\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E01\u0E31\u0E19  :"),Oi=f(),k(Nt.$$.fragment),Li=f(),k(Ft.$$.fragment),Si=f(),On=l("p"),n_=n("\u0E02\u0E31\u0E49\u0E19\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E04\u0E37\u0E2D\u0E01\u0E32\u0E23\u0E40\u0E17\u0E23\u0E19  XLNet \u0E21\u0E35\u0E01\u0E32\u0E23\u0E43\u0E0A\u0E49 token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E2D\u0E22\u0E39\u0E48\u0E08\u0E33\u0E19\u0E27\u0E19\u0E2B\u0E19\u0E36\u0E48\u0E07 :"),Bi=f(),k(At.$$.fragment),Ni=f(),y=l("p"),r_=n("\u0E2A\u0E34\u0E48\u0E07\u0E2A\u0E33\u0E04\u0E31\u0E0D\u0E40\u0E27\u0E25\u0E32\u0E43\u0E0A\u0E49 "),el=l("code"),o_=n("UnigramTrainer"),l_=n(" \u0E04\u0E37\u0E2D \u0E2D\u0E22\u0E48\u0E32\u0E25\u0E37\u0E21\u0E01\u0E33\u0E2B\u0E19\u0E14 argument "),sl=l("code"),a_=n("unk_token"),i_=n(`
\u0E19\u0E2D\u0E01\u0E08\u0E32\u0E01\u0E19\u0E31\u0E49\u0E19\u0E04\u0E38\u0E13\u0E22\u0E31\u0E07\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32 argument \u0E2D\u0E37\u0E48\u0E19\u0E46\u0E17\u0E35\u0E48\u0E15\u0E49\u0E2D\u0E07\u0E43\u0E0A\u0E49\u0E01\u0E31\u0E1A Unigram algorithm \u0E44\u0E14\u0E49\u0E14\u0E49\u0E27\u0E22 \u0E40\u0E0A\u0E48\u0E19 `),tl=l("code"),p_=n("shrinking_factor"),f_=n(" (\u0E04\u0E48\u0E32\u0E40\u0E23\u0E34\u0E48\u0E21\u0E15\u0E49\u0E19\u0E04\u0E37\u0E2D  0.75) \u0E2B\u0E23\u0E37\u0E2D "),nl=l("code"),c_=n("max_piece_length"),k_=n(" (\u0E04\u0E48\u0E32\u0E40\u0E23\u0E34\u0E48\u0E21\u0E15\u0E49\u0E19\u0E04\u0E37\u0E2D 16)"),Fi=f(),Ln=l("p"),m_=n("\u0E40\u0E23\u0E32\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E40\u0E17\u0E23\u0E19\u0E08\u0E32\u0E01\u0E44\u0E1F\u0E25\u0E4C\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E44\u0E14\u0E49\u0E14\u0E49\u0E27\u0E22  :"),Ai=f(),k(Wt.$$.fragment),Wi=f(),Sn=l("p"),d_=n("\u0E25\u0E2D\u0E07 tokenize \u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E07\u0E48\u0E32\u0E22\u0E46\u0E14\u0E39  :"),Ui=f(),k(Ut.$$.fragment),Ii=f(),k(It.$$.fragment),Ri=f(),es=l("p"),__=n("XLNet \u0E08\u0E30\u0E40\u0E1E\u0E34\u0E48\u0E21 token \u0E1E\u0E34\u0E40\u0E28\u0E29 "),rl=l("code"),$_=n("<cls>"),u_=n(` \u0E43\u0E2A\u0E48\u0E43\u0E19\u0E15\u0E2D\u0E19\u0E17\u0E49\u0E32\u0E22\u0E02\u0E2D\u0E07\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04 \u0E41\u0E25\u0E30\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32 type ID \u0E21\u0E31\u0E19\u0E40\u0E1B\u0E47\u0E19 2 \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E43\u0E2B\u0E49\u0E21\u0E31\u0E19\u0E41\u0E15\u0E01\u0E15\u0E48\u0E32\u0E07\u0E08\u0E32\u0E01 token \u0E2D\u0E37\u0E48\u0E19
\u0E01\u0E32\u0E23\u0E17\u0E33\u0E41\u0E1A\u0E1A\u0E19\u0E35\u0E49\u0E16\u0E37\u0E2D\u0E27\u0E48\u0E32\u0E40\u0E1B\u0E47\u0E19\u0E01\u0E32\u0E23 padding \u0E17\u0E32\u0E07\u0E14\u0E49\u0E32\u0E22\u0E0B\u0E49\u0E32\u0E22`),Gi=f(),he=l("p"),z_=n("\u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E08\u0E31\u0E14\u0E01\u0E32\u0E23\u0E01\u0E31\u0E1A token \u0E1E\u0E34\u0E40\u0E28\u0E29 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E2A\u0E23\u0E49\u0E32\u0E07 template \u0E02\u0E36\u0E49\u0E19\u0E21\u0E32 \u0E01\u0E48\u0E2D\u0E19\u0E2D\u0E37\u0E48\u0E19\u0E40\u0E23\u0E32\u0E15\u0E49\u0E2D\u0E07\u0E14\u0E39\u0E27\u0E48\u0E32 ID \u0E02\u0E2D\u0E07 "),ol=l("code"),h_=n("<cls>"),E_=n(" \u0E41\u0E25\u0E30 "),ll=l("code"),j_=n("<sep>"),v_=n(" \u0E04\u0E37\u0E2D\u0E2D\u0E30\u0E44\u0E23 :"),Mi=f(),k(Rt.$$.fragment),Xi=f(),k(Gt.$$.fragment),Ki=f(),Bn=l("p"),b_=n("\u0E19\u0E35\u0E48\u0E04\u0E37\u0E2D\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 template :"),Hi=f(),k(Mt.$$.fragment),Yi=f(),Nn=l("p"),x_=n("\u0E40\u0E23\u0E32\u0E08\u0E30\u0E17\u0E14\u0E25\u0E2D\u0E07\u0E43\u0E0A\u0E49\u0E07\u0E32\u0E19\u0E21\u0E31\u0E19\u0E42\u0E14\u0E22\u0E01\u0E32\u0E23 encode \u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04 input \u0E2A\u0E2D\u0E07\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04 :"),Ji=f(),k(Xt.$$.fragment),Vi=f(),k(Kt.$$.fragment),Zi=f(),ss=l("p"),g_=n("\u0E08\u0E32\u0E01\u0E19\u0E31\u0E49\u0E19\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32 decoder \u0E40\u0E1B\u0E47\u0E19 "),al=l("code"),P_=n("Metaspace"),w_=n(" :"),Qi=f(),k(Ht.$$.fragment),ep=f(),Ee=l("p"),q_=n("\u0E15\u0E2D\u0E19\u0E19\u0E35\u0E49\u0E40\u0E23\u0E32\u0E01\u0E47\u0E40\u0E2A\u0E23\u0E47\u0E08\u0E41\u0E25\u0E49\u0E27 \u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E40\u0E0B\u0E1F tokenizer \u0E41\u0E25\u0E30 wrap \u0E21\u0E31\u0E19\u0E43\u0E2B\u0E49\u0E40\u0E1B\u0E47\u0E19 "),il=l("code"),T_=n("PreTrainedTokenizerFast"),D_=n(" \u0E2B\u0E23\u0E37\u0E2D "),pl=l("code"),C_=n("XLNetTokenizerFast"),y_=n(" \u0E01\u0E47\u0E44\u0E14\u0E49 \u0E16\u0E49\u0E32\u0E04\u0E38\u0E13\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E32\u0E23\u0E43\u0E0A\u0E49\u0E21\u0E31\u0E19\u0E43\u0E19 \u{1F917} Transformers"),sp=f(),ts=l("p"),O_=n("\u0E2A\u0E34\u0E48\u0E07\u0E2A\u0E33\u0E04\u0E31\u0E0D\u0E2D\u0E35\u0E01\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E40\u0E27\u0E25\u0E32\u0E43\u0E0A\u0E49 "),fl=l("code"),L_=n("PreTrainedTokenizerFast"),S_=n(" \u0E01\u0E47\u0E04\u0E37\u0E2D\u0E40\u0E23\u0E32\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E1A\u0E2D\u0E01 \u{1F917} Transformers library \u0E27\u0E48\u0E32\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E17\u0E33\u0E01\u0E32\u0E23 padding \u0E17\u0E32\u0E07\u0E0B\u0E49\u0E32\u0E22 :"),tp=f(),k(Yt.$$.fragment),np=f(),Fn=l("p"),B_=n("\u0E2D\u0E35\u0E01\u0E27\u0E34\u0E18\u0E35\u0E01\u0E47\u0E04\u0E37\u0E2D :"),rp=f(),k(Jt.$$.fragment),op=f(),An=l("p"),N_=n("\u0E15\u0E2D\u0E19\u0E19\u0E35\u0E49 \u0E04\u0E38\u0E13\u0E01\u0E47\u0E44\u0E14\u0E49\u0E40\u0E23\u0E35\u0E22\u0E19\u0E23\u0E39\u0E49\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E43\u0E19\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 tokenizer \u0E02\u0E36\u0E49\u0E19\u0E21\u0E32\u0E40\u0E2D\u0E07\u0E41\u0E25\u0E49\u0E27 \u0E42\u0E14\u0E22\u0E01\u0E32\u0E23\u0E43\u0E0A\u0E49\u0E40\u0E04\u0E23\u0E37\u0E48\u0E2D\u0E07\u0E21\u0E37\u0E2D\u0E08\u0E32\u0E01 \u{1F917} Tokenizers library \u0E41\u0E25\u0E30\u0E44\u0E14\u0E49\u0E40\u0E23\u0E35\u0E22\u0E19\u0E27\u0E34\u0E18\u0E35\u0E01\u0E32\u0E23\u0E19\u0E33 tokenizer \u0E02\u0E2D\u0E07\u0E04\u0E38\u0E13\u0E44\u0E1B\u0E43\u0E0A\u0E49\u0E43\u0E19 \u{1F917} Transformers \u0E2D\u0E35\u0E01\u0E14\u0E49\u0E27\u0E22"),this.h()},l(e){const o=az('[data-svelte="svelte-1phssyn"]',document.head);E=a(o,"META",{name:!0,content:!0}),o.forEach(t),ne=c(e),L=a(e,"H1",{class:!0});var Vt=p(L);F=a(Vt,"A",{id:!0,class:!0,href:!0});var I_=p(F);J=a(I_,"SPAN",{});var R_=p(J);m(V.$$.fragment,R_),R_.forEach(t),I_.forEach(t),fs=c(Vt),Z=a(Vt,"SPAN",{});var G_=p(Z);cs=r(G_,"\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 tokenizer \u0E17\u0E35\u0E25\u0E30\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19"),G_.forEach(t),Vt.forEach(t),De=c(e),m(S.$$.fragment,e),Ce=c(e),re=a(e,"P",{});var M_=p(re);ve=r(M_,"\u0E08\u0E32\u0E01\u0E1A\u0E17\u0E01\u0E48\u0E2D\u0E19\u0E46 \u0E04\u0E38\u0E13\u0E08\u0E30\u0E40\u0E2B\u0E47\u0E19\u0E27\u0E48\u0E32 \u0E01\u0E32\u0E23\u0E15\u0E31\u0E14\u0E04\u0E33 \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22\u0E2B\u0E25\u0E32\u0E22\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19 :"),M_.forEach(t),ye=c(e),P=a(e,"UL",{});var ns=p(P);Q=a(ns,"LI",{});var X_=p(Q);ks=r(X_,"Normalization (\u0E2B\u0E23\u0E37\u0E2D \u0E01\u0E32\u0E23\u0E1B\u0E23\u0E31\u0E1A\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E43\u0E2B\u0E49\u0E40\u0E1B\u0E47\u0E19\u0E21\u0E32\u0E15\u0E23\u0E10\u0E32\u0E19 \u0E2B\u0E21\u0E32\u0E22\u0E16\u0E36\u0E07\u0E01\u0E32\u0E23\u0E17\u0E33\u0E04\u0E27\u0E32\u0E21\u0E2A\u0E30\u0E2D\u0E32\u0E14\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21 \u0E40\u0E0A\u0E48\u0E19 \u0E25\u0E1A\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E2B\u0E23\u0E37\u0E2D\u0E40\u0E04\u0E23\u0E37\u0E48\u0E2D\u0E07\u0E2B\u0E21\u0E32\u0E22\u0E40\u0E19\u0E49\u0E19\u0E40\u0E2A\u0E35\u0E22\u0E07 \u0E23\u0E27\u0E21\u0E16\u0E36\u0E07\u0E01\u0E32\u0E23\u0E17\u0E33 Unicode normalization \u0E41\u0E25\u0E30\u0E2D\u0E37\u0E48\u0E19\u0E46)"),X_.forEach(t),ms=c(ns),ee=a(ns,"LI",{});var K_=p(ee);ds=r(K_,"Pre-tokenization (\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E01\u0E48\u0E2D\u0E19\u0E15\u0E31\u0E14\u0E04\u0E33 \u0E2B\u0E21\u0E32\u0E22\u0E16\u0E36\u0E07 \u0E01\u0E32\u0E23\u0E41\u0E22\u0E01\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E2D\u0E2D\u0E01\u0E40\u0E1B\u0E47\u0E19\u0E04\u0E33\u0E46)"),K_.forEach(t),_s=c(ns),se=a(ns,"LI",{});var H_=p(se);$s=r(H_,"\u0E2A\u0E48\u0E07 input \u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E43\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25 (\u0E41\u0E22\u0E01\u0E04\u0E33\u0E17\u0E35\u0E48\u0E44\u0E14\u0E49\u0E08\u0E32\u0E01\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19 pre-tokenization \u0E2D\u0E2D\u0E01\u0E40\u0E1B\u0E47\u0E19\u0E04\u0E33\u0E22\u0E48\u0E2D\u0E22\u0E2B\u0E25\u0E32\u0E22\u0E46\u0E04\u0E33)"),H_.forEach(t),us=c(ns),te=a(ns,"LI",{});var Y_=p(te);zs=r(Y_,"Post-processing (\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E1B\u0E23\u0E31\u0E1A\u0E41\u0E15\u0E48\u0E07\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C \u0E40\u0E0A\u0E48\u0E19 \u0E01\u0E32\u0E23\u0E43\u0E2A\u0E48 token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E02\u0E2D\u0E07 tokenizer \u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E43\u0E19\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C, \u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 attention mask \u0E41\u0E25\u0E30 token type IDs)"),Y_.forEach(t),ns.forEach(t),oe=c(e),j=a(e,"P",{});var J_=p(j);nn=r(J_,"\u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E40\u0E1B\u0E47\u0E19\u0E01\u0E32\u0E23\u0E40\u0E15\u0E37\u0E2D\u0E19\u0E04\u0E27\u0E32\u0E21\u0E08\u0E33 \u0E21\u0E32\u0E14\u0E39\u0E01\u0E23\u0E30\u0E1A\u0E27\u0E19\u0E01\u0E32\u0E23\u0E42\u0E14\u0E22\u0E23\u0E27\u0E21\u0E2D\u0E35\u0E01\u0E04\u0E23\u0E31\u0E49\u0E07 :"),J_.forEach(t),hs=c(e),A=a(e,"DIV",{class:!0});var ap=p(A);le=a(ap,"IMG",{class:!0,src:!0,alt:!0}),rn=c(ap),ae=a(ap,"IMG",{class:!0,src:!0,alt:!0}),ap.forEach(t),Es=c(e),Oe=a(e,"P",{});var ip=p(Oe);Cp=r(ip,`\u{1F917} Tokenizers library \u0E40\u0E1B\u0E47\u0E19\u0E40\u0E04\u0E23\u0E37\u0E48\u0E2D\u0E07\u0E21\u0E37\u0E2D\u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A\u0E0A\u0E48\u0E27\u0E22\u0E14\u0E33\u0E40\u0E19\u0E34\u0E19\u0E01\u0E32\u0E23\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E1E\u0E27\u0E01\u0E19\u0E35\u0E49 \u0E42\u0E14\u0E22\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E1C\u0E2A\u0E21\u0E1C\u0E2A\u0E32\u0E19\u0E40\u0E04\u0E23\u0E37\u0E48\u0E2D\u0E07\u0E21\u0E37\u0E2D\u0E1E\u0E27\u0E01\u0E19\u0E35\u0E49\u0E15\u0E32\u0E21\u0E04\u0E27\u0E32\u0E21\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E32\u0E23\u0E44\u0E14\u0E49
\u0E43\u0E19\u0E1A\u0E17\u0E19\u0E35\u0E49\u0E40\u0E23\u0E32\u0E08\u0E30\u0E21\u0E32\u0E40\u0E23\u0E35\u0E22\u0E19\u0E27\u0E34\u0E18\u0E35\u0E2A\u0E23\u0E49\u0E32\u0E07 tokenizer \u0E02\u0E36\u0E49\u0E19\u0E21\u0E32\u0E15\u0E31\u0E49\u0E07\u0E41\u0E15\u0E48\u0E15\u0E49\u0E19 \u0E41\u0E17\u0E19\u0E17\u0E35\u0E48\u0E08\u0E30\u0E40\u0E17\u0E23\u0E19\u0E08\u0E32\u0E01\u0E15\u0E31\u0E27\u0E17\u0E35\u0E48\u0E16\u0E39\u0E01 implement \u0E41\u0E25\u0E49\u0E27\u0E14\u0E49\u0E27\u0E22\u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E43\u0E2B\u0E21\u0E48\u0E40\u0E17\u0E48\u0E32\u0E19\u0E31\u0E49\u0E19 \u0E2D\u0E22\u0E48\u0E32\u0E07\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E25\u0E2D\u0E07\u0E17\u0E33\u0E01\u0E31\u0E19\u0E43\u0E19`),on=a(ip,"A",{href:!0});var V_=p(on);yp=r(V_,"\u0E1A\u0E17\u0E17\u0E35\u0E48 2"),V_.forEach(t),Op=r(ip," \u0E40\u0E21\u0E37\u0E48\u0E2D\u0E08\u0E1A\u0E1A\u0E17\u0E19\u0E35\u0E49 \u0E04\u0E38\u0E13\u0E08\u0E30\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E2A\u0E23\u0E49\u0E32\u0E07 tokenizer \u0E41\u0E1A\u0E1A\u0E43\u0E14\u0E01\u0E47\u0E44\u0E14\u0E49\u0E15\u0E32\u0E21\u0E17\u0E35\u0E48\u0E04\u0E38\u0E13\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E32\u0E23"),ip.forEach(t),$l=c(e),m(js.$$.fragment,e),ul=c(e),Le=a(e,"P",{});var pp=p(Le);Lp=r(pp,"library \u0E19\u0E35\u0E49 \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E14\u0E49\u0E27\u0E22\u0E2A\u0E48\u0E27\u0E19\u0E2B\u0E25\u0E31\u0E01\u0E04\u0E37\u0E2D "),Jn=a(pp,"CODE",{});var Z_=p(Jn);Sp=r(Z_,"Tokenizer"),Z_.forEach(t),Bp=r(pp," class \u0E17\u0E35\u0E48\u0E21\u0E35\u0E2A\u0E48\u0E27\u0E19\u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E22\u0E48\u0E2D\u0E22\u0E2A\u0E33\u0E04\u0E31\u0E0D\u0E2D\u0E37\u0E48\u0E19\u0E46 \u0E41\u0E1A\u0E48\u0E07\u0E40\u0E1B\u0E47\u0E19\u0E2B\u0E25\u0E32\u0E22 submodules"),pp.forEach(t),zl=c(e),w=a(e,"UL",{});var X=p(w);ie=a(X,"LI",{});var Zt=p(ie);Vn=a(Zt,"CODE",{});var Q_=p(Vn);Np=r(Q_,"normalizers"),Q_.forEach(t),Fp=r(Zt," \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22 "),Zn=a(Zt,"CODE",{});var e2=p(Zn);Ap=r(e2,"Normalizer"),e2.forEach(t),Wp=r(Zt," \u0E2B\u0E25\u0E32\u0E22\u0E1B\u0E23\u0E30\u0E40\u0E20\u0E17\u0E17\u0E35\u0E48\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49\u0E44\u0E14\u0E49 (\u0E23\u0E32\u0E22\u0E0A\u0E37\u0E48\u0E2D\u0E17\u0E31\u0E49\u0E07\u0E2B\u0E21\u0E14\u0E14\u0E39\u0E44\u0E14\u0E49"),vs=a(Zt,"A",{href:!0,rel:!0});var s2=p(vs);Up=r(s2,"\u0E17\u0E35\u0E48\u0E19\u0E35\u0E48"),s2.forEach(t),Ip=r(Zt,")."),Zt.forEach(t),Rp=c(X),pe=a(X,"LI",{});var Qt=p(pe);Qn=a(Qt,"CODE",{});var t2=p(Qn);Gp=r(t2,"pre_tokenizers"),t2.forEach(t),Mp=r(Qt," \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22 "),er=a(Qt,"CODE",{});var n2=p(er);Xp=r(n2,"PreTokenizer"),n2.forEach(t),Kp=r(Qt," \u0E2B\u0E25\u0E32\u0E22\u0E1B\u0E23\u0E30\u0E40\u0E20\u0E17\u0E17\u0E35\u0E48\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49\u0E44\u0E14\u0E49 (\u0E23\u0E32\u0E22\u0E0A\u0E37\u0E48\u0E2D\u0E17\u0E31\u0E49\u0E07\u0E2B\u0E21\u0E14\u0E14\u0E39\u0E44\u0E14\u0E49"),bs=a(Qt,"A",{href:!0,rel:!0});var r2=p(bs);Hp=r(r2,"\u0E17\u0E35\u0E48\u0E19\u0E35\u0E48"),r2.forEach(t),Yp=r(Qt,")."),Qt.forEach(t),Jp=c(X),q=a(X,"LI",{});var B=p(q);sr=a(B,"CODE",{});var o2=p(sr);Vp=r(o2,"models"),o2.forEach(t),Zp=r(B," \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22 "),tr=a(B,"CODE",{});var l2=p(tr);Qp=r(l2,"Model"),l2.forEach(t),ef=r(B," \u0E2B\u0E25\u0E32\u0E22\u0E1B\u0E23\u0E30\u0E40\u0E20\u0E17\u0E17\u0E35\u0E48\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49\u0E44\u0E14\u0E49 \u0E40\u0E0A\u0E48\u0E19 "),nr=a(B,"CODE",{});var a2=p(nr);sf=r(a2,"BPE"),a2.forEach(t),tf=r(B,", "),rr=a(B,"CODE",{});var i2=p(rr);nf=r(i2,"WordPiece"),i2.forEach(t),rf=r(B,", \u0E41\u0E25\u0E30 "),or=a(B,"CODE",{});var p2=p(or);of=r(p2,"Unigram"),p2.forEach(t),lf=r(B," (\u0E23\u0E32\u0E22\u0E0A\u0E37\u0E48\u0E2D\u0E17\u0E31\u0E49\u0E07\u0E2B\u0E21\u0E14\u0E14\u0E39\u0E44\u0E14\u0E49"),xs=a(B,"A",{href:!0,rel:!0});var f2=p(xs);af=r(f2,"\u0E17\u0E35\u0E48\u0E19\u0E35\u0E48"),f2.forEach(t),pf=r(B,")."),B.forEach(t),ff=c(X),fe=a(X,"LI",{});var en=p(fe);lr=a(en,"CODE",{});var c2=p(lr);cf=r(c2,"trainers"),c2.forEach(t),kf=r(en," \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22 "),ar=a(en,"CODE",{});var k2=p(ar);mf=r(k2,"Trainer"),k2.forEach(t),df=r(en," \u0E2B\u0E25\u0E32\u0E22\u0E1B\u0E23\u0E30\u0E40\u0E20\u0E17\u0E17\u0E35\u0E48\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49\u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E40\u0E17\u0E23\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25\u0E14\u0E49\u0E27\u0E22 corpus \u0E17\u0E35\u0E48\u0E21\u0E35\u0E44\u0E14\u0E49 (\u0E41\u0E15\u0E48\u0E25\u0E30\u0E42\u0E21\u0E40\u0E14\u0E25\u0E08\u0E30\u0E21\u0E35\u0E40\u0E17\u0E23\u0E19\u0E40\u0E19\u0E2D\u0E23\u0E4C\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E25\u0E30\u0E15\u0E31\u0E27; \u0E23\u0E32\u0E22\u0E0A\u0E37\u0E48\u0E2D\u0E17\u0E31\u0E49\u0E07\u0E2B\u0E21\u0E14\u0E14\u0E39\u0E44\u0E14\u0E49"),gs=a(en,"A",{href:!0,rel:!0});var m2=p(gs);_f=r(m2,"\u0E17\u0E35\u0E48\u0E19\u0E35\u0E48"),m2.forEach(t),$f=r(en,")."),en.forEach(t),uf=c(X),ce=a(X,"LI",{});var sn=p(ce);ir=a(sn,"CODE",{});var d2=p(ir);zf=r(d2,"post_processors"),d2.forEach(t),hf=r(sn," \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22 "),pr=a(sn,"CODE",{});var _2=p(pr);Ef=r(_2,"PostProcessor"),_2.forEach(t),jf=r(sn," \u0E2B\u0E25\u0E32\u0E22\u0E1B\u0E23\u0E30\u0E40\u0E20\u0E17\u0E17\u0E35\u0E48\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49\u0E44\u0E14\u0E49 (\u0E23\u0E32\u0E22\u0E0A\u0E37\u0E48\u0E2D\u0E17\u0E31\u0E49\u0E07\u0E2B\u0E21\u0E14\u0E14\u0E39\u0E44\u0E14\u0E49"),Ps=a(sn,"A",{href:!0,rel:!0});var $2=p(Ps);vf=r($2,"\u0E17\u0E35\u0E48\u0E19\u0E35\u0E48"),$2.forEach(t),bf=r(sn,")"),sn.forEach(t),xf=c(X),ke=a(X,"LI",{});var tn=p(ke);fr=a(tn,"CODE",{});var u2=p(fr);gf=r(u2,"decoders"),u2.forEach(t),Pf=r(tn," \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22 "),cr=a(tn,"CODE",{});var z2=p(cr);wf=r(z2,"Decoder"),z2.forEach(t),qf=r(tn," \u0E2B\u0E25\u0E32\u0E22\u0E1B\u0E23\u0E30\u0E40\u0E20\u0E17\u0E17\u0E35\u0E48\u0E43\u0E0A\u0E49\u0E40\u0E1E\u0E37\u0E48\u0E2D decode \u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E08\u0E32\u0E01\u0E01\u0E32\u0E23 tokenization (\u0E23\u0E32\u0E22\u0E0A\u0E37\u0E48\u0E2D\u0E17\u0E31\u0E49\u0E07\u0E2B\u0E21\u0E14\u0E14\u0E39\u0E44\u0E14\u0E49"),ws=a(tn,"A",{href:!0,rel:!0});var h2=p(ws);Tf=r(h2,"\u0E17\u0E35\u0E48\u0E19\u0E35\u0E48"),h2.forEach(t),Df=r(tn,")"),tn.forEach(t),X.forEach(t),hl=c(e),qs=a(e,"P",{});var F_=p(qs);Cf=r(F_,"\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E14\u0E39\u0E23\u0E32\u0E22\u0E0A\u0E37\u0E48\u0E2D\u0E02\u0E2D\u0E07\u0E2A\u0E48\u0E27\u0E19\u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E2A\u0E33\u0E04\u0E31\u0E0D\u0E46\u0E15\u0E48\u0E32\u0E07\u0E46\u0E44\u0E14\u0E49"),Ts=a(F_,"A",{href:!0,rel:!0});var E2=p(Ts);yf=r(E2,"\u0E17\u0E35\u0E48\u0E19\u0E35\u0E48"),E2.forEach(t),F_.forEach(t),El=c(e),be=a(e,"H2",{class:!0});var fp=p(be);Se=a(fp,"A",{id:!0,class:!0,href:!0});var j2=p(Se);kr=a(j2,"SPAN",{});var v2=p(kr);m(Ds.$$.fragment,v2),v2.forEach(t),j2.forEach(t),Of=c(fp),mr=a(fp,"SPAN",{});var b2=p(mr);Lf=r(b2,"\u0E01\u0E32\u0E23\u0E42\u0E2B\u0E25\u0E14 corpus"),b2.forEach(t),fp.forEach(t),jl=c(e),xe=a(e,"P",{});var cl=p(xe);Sf=r(cl,`\u0E43\u0E19\u0E01\u0E32\u0E23\u0E40\u0E17\u0E23\u0E19 tokenizer \u0E15\u0E31\u0E27\u0E43\u0E2B\u0E21\u0E48 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49 corpus \u0E40\u0E25\u0E47\u0E01\u0E46 \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E17\u0E35\u0E48\u0E01\u0E32\u0E23\u0E04\u0E33\u0E19\u0E27\u0E13\u0E08\u0E30\u0E44\u0E14\u0E49\u0E23\u0E27\u0E14\u0E40\u0E23\u0E47\u0E27
\u0E01\u0E32\u0E23\u0E40\u0E23\u0E35\u0E22\u0E01\u0E43\u0E0A\u0E49\u0E07\u0E32\u0E19 corpus \u0E08\u0E30\u0E17\u0E33\u0E04\u0E25\u0E49\u0E32\u0E22\u0E46\u0E01\u0E31\u0E1A\u0E27\u0E34\u0E18\u0E35\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E43\u0E0A\u0E49\u0E43\u0E19`),ln=a(cl,"A",{href:!0});var x2=p(ln);Bf=r(x2,"\u0E15\u0E2D\u0E19\u0E15\u0E49\u0E19\u0E02\u0E2D\u0E07\u0E1A\u0E17\u0E19\u0E35\u0E49"),x2.forEach(t),Nf=r(cl," \u0E41\u0E15\u0E48\u0E04\u0E23\u0E31\u0E49\u0E07\u0E19\u0E35\u0E49\u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49\u0E0A\u0E38\u0E14\u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E0A\u0E37\u0E48\u0E2D "),Cs=a(cl,"A",{href:!0,rel:!0});var g2=p(Cs);Ff=r(g2,"WikiText-2"),g2.forEach(t),cl.forEach(t),vl=c(e),m(ys.$$.fragment,e),bl=c(e),Os=a(e,"P",{});var A_=p(Os);dr=a(A_,"CODE",{});var P2=p(dr);Af=r(P2,"get_training_corpus()"),P2.forEach(t),Wf=r(A_,` \u0E40\u0E1B\u0E47\u0E19 generator \u0E17\u0E35\u0E48\u0E08\u0E30 yield \u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E43\u0E19\u0E23\u0E39\u0E1B\u0E41\u0E1A\u0E1A batch \u0E42\u0E14\u0E22\u0E41\u0E15\u0E48\u0E25\u0E30 batch \u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22 1,000 \u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21
\u{1F917} Tokenizers \u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E40\u0E17\u0E23\u0E19\u0E44\u0E14\u0E49\u0E08\u0E32\u0E01\u0E44\u0E1F\u0E25\u0E4C\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E42\u0E14\u0E22\u0E15\u0E23\u0E07 \u0E14\u0E31\u0E07\u0E19\u0E31\u0E49\u0E19\u0E40\u0E23\u0E32\u0E08\u0E30\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E44\u0E1F\u0E25\u0E4C\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21 \u0E17\u0E35\u0E48\u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22 \u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E17\u0E31\u0E49\u0E07\u0E2B\u0E21\u0E14\u0E08\u0E32\u0E01 WikiText-2`),A_.forEach(t),xl=c(e),m(Ls.$$.fragment,e),gl=c(e),an=a(e,"P",{});var w2=p(an);Uf=r(w2,`\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E40\u0E23\u0E32\u0E08\u0E30\u0E1E\u0E32\u0E04\u0E38\u0E13\u0E2A\u0E23\u0E49\u0E32\u0E07 tokenizer \u0E41\u0E1A\u0E1A BERT, GPT-2, and XLNet \u0E02\u0E2D\u0E07\u0E04\u0E38\u0E13\u0E40\u0E2D\u0E07 \u0E17\u0E35\u0E25\u0E30\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19
\u0E0B\u0E36\u0E48\u0E07\u0E04\u0E38\u0E13\u0E01\u0E47\u0E08\u0E30\u0E44\u0E14\u0E49\u0E25\u0E2D\u0E07\u0E43\u0E0A\u0E49\u0E07\u0E32\u0E19 tokenization algorithm \u0E15\u0E48\u0E32\u0E07\u0E46\u0E17\u0E35\u0E48\u0E44\u0E14\u0E49\u0E40\u0E23\u0E35\u0E22\u0E19\u0E21\u0E32\u0E41\u0E25\u0E49\u0E27 \u0E40\u0E0A\u0E48\u0E19 WordPiece, BPE, and Unigram \u0E21\u0E32\u0E40\u0E23\u0E34\u0E48\u0E21\u0E08\u0E32\u0E01 BERT \u0E01\u0E31\u0E19`),w2.forEach(t),Pl=c(e),ge=a(e,"H2",{class:!0});var cp=p(ge);Be=a(cp,"A",{id:!0,class:!0,href:!0});var q2=p(Be);_r=a(q2,"SPAN",{});var T2=p(_r);m(Ss.$$.fragment,T2),T2.forEach(t),q2.forEach(t),If=c(cp),$r=a(cp,"SPAN",{});var D2=p($r);Rf=r(D2,"\u0E2A\u0E23\u0E49\u0E32\u0E07 WordPiece tokenizer \u0E15\u0E31\u0E49\u0E07\u0E41\u0E15\u0E48\u0E40\u0E23\u0E34\u0E48\u0E21\u0E15\u0E49\u0E19"),D2.forEach(t),cp.forEach(t),wl=c(e),b=a(e,"P",{});var O=p(b);Gf=r(O,"\u0E43\u0E19\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 tokenizer \u0E42\u0E14\u0E22\u0E43\u0E0A\u0E49 \u{1F917} Tokenizers library \u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E23\u0E34\u0E48\u0E21\u0E08\u0E32\u0E01\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 "),ur=a(O,"CODE",{});var C2=p(ur);Mf=r(C2,"Tokenizer"),C2.forEach(t),Xf=r(O," object \u0E08\u0E32\u0E01 "),zr=a(O,"CODE",{});var y2=p(zr);Kf=r(y2,"model"),y2.forEach(t),Hf=r(O," \u0E41\u0E25\u0E30\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32 attribute \u0E15\u0E48\u0E32\u0E07\u0E46 \u0E44\u0E14\u0E49\u0E41\u0E01\u0E48 "),hr=a(O,"CODE",{});var O2=p(hr);Yf=r(O2,"normalizer"),O2.forEach(t),Jf=r(O,", "),Er=a(O,"CODE",{});var L2=p(Er);Vf=r(L2,"pre_tokenizer"),L2.forEach(t),Zf=r(O,", "),jr=a(O,"CODE",{});var S2=p(jr);Qf=r(S2,"post_processor"),S2.forEach(t),ec=r(O,", \u0E41\u0E25\u0E30 "),vr=a(O,"CODE",{});var B2=p(vr);sc=r(B2,"decoder"),B2.forEach(t),tc=r(O," \u0E14\u0E49\u0E27\u0E22\u0E04\u0E48\u0E32\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E32\u0E23"),O.forEach(t),ql=c(e),Ne=a(e,"P",{});var kp=p(Ne);nc=r(kp,"\u0E43\u0E19\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E19\u0E35\u0E49 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E2A\u0E23\u0E49\u0E32\u0E07 "),br=a(kp,"CODE",{});var N2=p(br);rc=r(N2,"Tokenizer"),N2.forEach(t),oc=r(kp," \u0E14\u0E49\u0E27\u0E22 WordPiece :"),kp.forEach(t),Tl=c(e),m(Bs.$$.fragment,e),Dl=c(e),W=a(e,"P",{});var rs=p(W);lc=r(rs,"\u0E08\u0E32\u0E01\u0E19\u0E31\u0E49\u0E19\u0E40\u0E23\u0E32\u0E08\u0E30\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32 "),xr=a(rs,"CODE",{});var F2=p(xr);ac=r(F2,"unk_token"),F2.forEach(t),ic=r(rs,` \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E1A\u0E2D\u0E01\u0E42\u0E21\u0E40\u0E14\u0E25\u0E27\u0E48\u0E32\u0E43\u0E2B\u0E49\u0E21\u0E31\u0E19 return \u0E04\u0E48\u0E32\u0E2D\u0E30\u0E44\u0E23\u0E2B\u0E32\u0E01\u0E21\u0E31\u0E19\u0E40\u0E08\u0E2D\u0E15\u0E31\u0E27\u0E2D\u0E31\u0E01\u0E29\u0E23\u0E17\u0E35\u0E48\u0E21\u0E31\u0E19\u0E44\u0E21\u0E48\u0E23\u0E39\u0E49\u0E08\u0E31\u0E01
\u0E2A\u0E48\u0E27\u0E19 argument \u0E2D\u0E37\u0E48\u0E19\u0E46\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32\u0E44\u0E14\u0E49\u0E01\u0E47\u0E04\u0E37\u0E2D `),gr=a(rs,"CODE",{});var A2=p(gr);pc=r(A2,"vocab"),A2.forEach(t),fc=r(rs," (\u0E41\u0E15\u0E48\u0E40\u0E19\u0E37\u0E48\u0E2D\u0E07\u0E08\u0E32\u0E01\u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E17\u0E23\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25 \u0E17\u0E33\u0E43\u0E2B\u0E49\u0E15\u0E2D\u0E19\u0E19\u0E35\u0E49\u0E40\u0E23\u0E32\u0E22\u0E31\u0E07\u0E44\u0E21\u0E48\u0E15\u0E49\u0E2D\u0E07\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32\u0E19\u0E35\u0E49) \u0E41\u0E25\u0E30 "),Pr=a(rs,"CODE",{});var W2=p(Pr);cc=r(W2,"max_input_chars_per_word"),W2.forEach(t),kc=r(rs," \u0E0B\u0E36\u0E48\u0E07\u0E2B\u0E21\u0E32\u0E22\u0E16\u0E36\u0E07 \u0E04\u0E27\u0E32\u0E21\u0E22\u0E32\u0E27\u0E2A\u0E39\u0E07\u0E2A\u0E38\u0E14\u0E02\u0E2D\u0E07\u0E41\u0E15\u0E48\u0E25\u0E30\u0E04\u0E33 (\u0E04\u0E33\u0E17\u0E35\u0E48\u0E22\u0E32\u0E27\u0E01\u0E27\u0E48\u0E32\u0E04\u0E48\u0E32\u0E19\u0E35\u0E49\u0E08\u0E30\u0E16\u0E39\u0E01\u0E41\u0E1A\u0E48\u0E07\u0E40\u0E1B\u0E47\u0E19\u0E2B\u0E25\u0E32\u0E22\u0E46\u0E2A\u0E48\u0E27\u0E19)"),rs.forEach(t),Cl=c(e),T=a(e,"P",{});var K=p(T);mc=r(K,"\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E41\u0E23\u0E01\u0E04\u0E37\u0E2D normalization \u0E40\u0E19\u0E37\u0E48\u0E2D\u0E07\u0E08\u0E32\u0E01 BERT \u0E40\u0E1B\u0E47\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25\u0E17\u0E35\u0E48\u0E44\u0E14\u0E49\u0E23\u0E31\u0E1A\u0E04\u0E27\u0E32\u0E21\u0E19\u0E34\u0E22\u0E21\u0E21\u0E32\u0E01 \u0E40\u0E23\u0E32\u0E08\u0E36\u0E07\u0E21\u0E35 "),wr=a(K,"CODE",{});var U2=p(wr);dc=r(U2,"BertNormalizer"),U2.forEach(t),_c=r(K," \u0E40\u0E09\u0E1E\u0E32\u0E30 \u0E0B\u0E36\u0E48\u0E07\u0E21\u0E35 option \u0E15\u0E48\u0E32\u0E07\u0E46\u0E14\u0E31\u0E07\u0E19\u0E35\u0E49: "),qr=a(K,"CODE",{});var I2=p(qr);$c=r(I2,"lowercase"),I2.forEach(t),uc=r(K,", "),Tr=a(K,"CODE",{});var R2=p(Tr);zc=r(R2,"strip_accents"),R2.forEach(t),hc=r(K,", "),Dr=a(K,"CODE",{});var G2=p(Dr);Ec=r(G2,"clean_text"),G2.forEach(t),jc=r(K," (\u0E25\u0E1A control characters \u0E41\u0E25\u0E30\u0E41\u0E17\u0E19\u0E17\u0E35\u0E48\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E17\u0E35\u0E48\u0E2D\u0E22\u0E39\u0E48\u0E15\u0E48\u0E2D\u0E01\u0E31\u0E19\u0E2B\u0E25\u0E32\u0E22\u0E46\u0E2D\u0E31\u0E19\u0E14\u0E49\u0E27\u0E22\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E40\u0E14\u0E35\u0E22\u0E27), \u0E41\u0E25\u0E30 "),Cr=a(K,"CODE",{});var M2=p(Cr);vc=r(M2,"handle_chinese_chars"),M2.forEach(t),bc=r(K," (\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E43\u0E19\u0E15\u0E31\u0E27\u0E2D\u0E31\u0E01\u0E29\u0E23\u0E08\u0E35\u0E19)"),K.forEach(t),yl=c(e),Fe=a(e,"P",{});var mp=p(Fe);xc=r(mp,"\u0E40\u0E23\u0E32\u0E08\u0E30\u0E21\u0E32\u0E40\u0E25\u0E35\u0E22\u0E19\u0E41\u0E1A\u0E1A "),yr=a(mp,"CODE",{});var X2=p(yr);gc=r(X2,"bert-base-uncased"),X2.forEach(t),Pc=r(mp," tokenizer \u0E42\u0E14\u0E22\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32 normalizer \u0E14\u0E31\u0E07\u0E19\u0E35\u0E49 :"),mp.forEach(t),Ol=c(e),m(Ns.$$.fragment,e),Ll=c(e),pn=a(e,"P",{});var K2=p(pn);wc=r(K2,"\u0E41\u0E15\u0E48\u0E1B\u0E01\u0E15\u0E34\u0E41\u0E25\u0E49\u0E27 \u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A tokenizer \u0E43\u0E2B\u0E21\u0E48 \u0E04\u0E38\u0E13\u0E2D\u0E32\u0E08\u0E08\u0E30\u0E44\u0E21\u0E48\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49 normalizer \u0E17\u0E35\u0E48\u0E08\u0E32\u0E01 \u{1F917} Tokenizers library \u0E44\u0E14\u0E49 \u0E14\u0E31\u0E07\u0E19\u0E31\u0E49\u0E19\u0E40\u0E23\u0E32\u0E08\u0E30\u0E21\u0E32\u0E40\u0E23\u0E35\u0E22\u0E19\u0E27\u0E34\u0E18\u0E35\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 BERT normalizer \u0E40\u0E2D\u0E07\u0E01\u0E31\u0E19"),K2.forEach(t),Sl=c(e),U=a(e,"P",{});var os=p(U);qc=r(os,"library \u0E19\u0E35\u0E49 \u0E21\u0E35 normalizer \u0E40\u0E1E\u0E37\u0E48\u0E2D "),Or=a(os,"CODE",{});var H2=p(Or);Tc=r(H2,"Lowercase"),H2.forEach(t),Dc=r(os," \u0E41\u0E25\u0E30\u0E40\u0E1E\u0E37\u0E48\u0E2D "),Lr=a(os,"CODE",{});var Y2=p(Lr);Cc=r(Y2,"StripAccents"),Y2.forEach(t),yc=r(os," \u0E0B\u0E36\u0E48\u0E07\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E23\u0E27\u0E21\u0E17\u0E31\u0E49\u0E07\u0E2A\u0E2D\u0E07\u0E15\u0E31\u0E27\u0E44\u0E14\u0E49\u0E42\u0E14\u0E22\u0E43\u0E0A\u0E49 "),Sr=a(os,"CODE",{});var J2=p(Sr);Oc=r(J2,"Sequence"),J2.forEach(t),Lc=r(os," :"),os.forEach(t),Bl=c(e),m(Fs.$$.fragment,e),Nl=c(e),me=a(e,"P",{});var Wn=p(me);Sc=r(Wn,"\u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49 "),Br=a(Wn,"CODE",{});var V2=p(Br);Bc=r(V2,"NFD"),V2.forEach(t),Nc=r(Wn," Unicode normalizer \u0E14\u0E49\u0E27\u0E22 \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E17\u0E35\u0E48\u0E08\u0E30\u0E43\u0E2B\u0E49 "),Nr=a(Wn,"CODE",{});var Z2=p(Nr);Fc=r(Z2,"StripAccents"),Z2.forEach(t),Ac=r(Wn," \u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E2B\u0E32\u0E2A\u0E31\u0E0D\u0E25\u0E31\u0E01\u0E29\u0E13\u0E4C accents \u0E44\u0E14\u0E49 \u0E41\u0E25\u0E30\u0E08\u0E30\u0E44\u0E14\u0E49\u0E25\u0E1A\u0E1E\u0E27\u0E01\u0E21\u0E31\u0E19\u0E2D\u0E2D\u0E01"),Wn.forEach(t),Fl=c(e),de=a(e,"P",{});var Un=p(de);Wc=r(Un,"\u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E40\u0E0A\u0E47\u0E04\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E02\u0E2D\u0E07 normalizer \u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49 "),Fr=a(Un,"CODE",{});var Q2=p(Fr);Uc=r(Q2,"normalize_str()"),Q2.forEach(t),Ic=r(Un," method \u0E08\u0E32\u0E01 "),Ar=a(Un,"CODE",{});var e$=p(Ar);Rc=r(e$,"normalizer"),e$.forEach(t),Gc=r(Un," :"),Un.forEach(t),Al=c(e),m(As.$$.fragment,e),Wl=c(e),m(Ws.$$.fragment,e),Ul=c(e),m(Ae.$$.fragment,e),Il=c(e),We=a(e,"P",{});var dp=p(We);Mc=r(dp,"\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E04\u0E37\u0E2D \u0E01\u0E32\u0E23 pre-tokenization \u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49 "),Wr=a(dp,"CODE",{});var s$=p(Wr);Xc=r(s$,"BertPreTokenizer"),s$.forEach(t),Kc=r(dp," \u0E17\u0E35\u0E48\u0E16\u0E39\u0E01\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E21\u0E32\u0E41\u0E25\u0E49\u0E27 :"),dp.forEach(t),Rl=c(e),m(Us.$$.fragment,e),Gl=c(e),fn=a(e,"P",{});var t$=p(fn);Hc=r(t$,"\u0E2B\u0E23\u0E37\u0E2D\u0E08\u0E30\u0E43\u0E0A\u0E49\u0E15\u0E31\u0E27\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E02\u0E36\u0E49\u0E19\u0E21\u0E32\u0E40\u0E2D\u0E07\u0E01\u0E47\u0E44\u0E14\u0E49 :"),t$.forEach(t),Ml=c(e),m(Is.$$.fragment,e),Xl=c(e),Ue=a(e,"P",{});var _p=p(Ue);Yc=r(_p,"\u0E42\u0E1B\u0E23\u0E14\u0E17\u0E23\u0E32\u0E1A\u0E27\u0E48\u0E32 "),Ur=a(_p,"CODE",{});var n$=p(Ur);Jc=r(n$,"Whitespace"),n$.forEach(t),Vc=r(_p," pre-tokenizer \u0E08\u0E30\u0E15\u0E31\u0E14\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E15\u0E23\u0E07\u0E17\u0E35\u0E48\u0E21\u0E35\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07 \u0E41\u0E25\u0E30 \u0E23\u0E27\u0E21\u0E16\u0E36\u0E07\u0E15\u0E31\u0E27\u0E2A\u0E31\u0E0D\u0E25\u0E31\u0E01\u0E29\u0E13\u0E4C\u0E17\u0E35\u0E48\u0E44\u0E21\u0E48\u0E43\u0E0A\u0E49\u0E15\u0E31\u0E27\u0E2D\u0E31\u0E01\u0E29\u0E23 \u0E15\u0E31\u0E27\u0E40\u0E25\u0E02 \u0E2B\u0E23\u0E37\u0E2D underscore \u0E2B\u0E23\u0E37\u0E2D\u0E1E\u0E39\u0E14\u0E2D\u0E35\u0E01\u0E41\u0E1A\u0E1A\u0E01\u0E47\u0E04\u0E37\u0E2D \u0E21\u0E31\u0E19\u0E08\u0E30\u0E41\u0E1A\u0E48\u0E07\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E15\u0E23\u0E07\u0E17\u0E35\u0E48\u0E21\u0E35\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E41\u0E25\u0E30\u0E40\u0E04\u0E23\u0E37\u0E48\u0E2D\u0E07\u0E2B\u0E21\u0E32\u0E22\u0E27\u0E23\u0E23\u0E04\u0E15\u0E2D\u0E19 \u0E19\u0E31\u0E48\u0E19\u0E40\u0E2D\u0E07"),_p.forEach(t),Kl=c(e),m(Rs.$$.fragment,e),Hl=c(e),m(Gs.$$.fragment,e),Yl=c(e),Ie=a(e,"P",{});var $p=p(Ie);Zc=r($p,"\u0E41\u0E15\u0E48\u0E16\u0E49\u0E32\u0E04\u0E38\u0E13\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E32\u0E23\u0E08\u0E30\u0E41\u0E1A\u0E48\u0E07\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E15\u0E32\u0E21\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E40\u0E17\u0E48\u0E32\u0E19\u0E31\u0E49\u0E19 \u0E43\u0E2B\u0E49\u0E43\u0E0A\u0E49 "),Ir=a($p,"CODE",{});var r$=p(Ir);Qc=r(r$,"WhitespaceSplit"),r$.forEach(t),ek=r($p," pre-tokenizer :"),$p.forEach(t),Jl=c(e),m(Ms.$$.fragment,e),Vl=c(e),m(Xs.$$.fragment,e),Zl=c(e),Re=a(e,"P",{});var up=p(Re);sk=r(up,"\u0E40\u0E2B\u0E21\u0E37\u0E2D\u0E19\u0E01\u0E31\u0E1A\u0E43\u0E19 normalizer \u0E40\u0E23\u0E32\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49 "),Rr=a(up,"CODE",{});var o$=p(Rr);tk=r(o$,"Sequence"),o$.forEach(t),nk=r(up," \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E23\u0E27\u0E21\u0E2B\u0E25\u0E32\u0E22\u0E46 pre-tokenizers \u0E40\u0E02\u0E49\u0E32\u0E14\u0E49\u0E27\u0E22\u0E01\u0E31\u0E19 :"),up.forEach(t),Ql=c(e),m(Ks.$$.fragment,e),ea=c(e),m(Hs.$$.fragment,e),sa=c(e),Ys=a(e,"P",{});var W_=p(Ys);rk=r(W_,`\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E43\u0E19 tokenization pipeline \u0E04\u0E37\u0E2D\u0E01\u0E32\u0E23\u0E43\u0E2A\u0E48 input \u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E43\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25
\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E42\u0E21\u0E40\u0E14\u0E25\u0E02\u0E36\u0E49\u0E19\u0E21\u0E32\u0E41\u0E25\u0E49\u0E27 \u0E41\u0E15\u0E48\u0E40\u0E23\u0E32\u0E22\u0E31\u0E07\u0E04\u0E07\u0E15\u0E49\u0E2D\u0E07\u0E40\u0E17\u0E23\u0E19\u0E21\u0E31\u0E19 \u0E0B\u0E36\u0E48\u0E07\u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49 `),Gr=a(W_,"CODE",{});var l$=p(Gr);ok=r(l$,"WordPieceTrainer"),l$.forEach(t),W_.forEach(t),ta=c(e),cn=a(e,"P",{});var a$=p(cn);lk=r(a$,"\u0E2A\u0E34\u0E48\u0E07\u0E2A\u0E33\u0E04\u0E31\u0E0D\u0E17\u0E35\u0E48\u0E04\u0E38\u0E13\u0E15\u0E49\u0E2D\u0E07\u0E08\u0E33\u0E04\u0E37\u0E2D \u0E40\u0E27\u0E25\u0E32\u0E2A\u0E23\u0E49\u0E32\u0E07 (instantiate) trainer \u0E43\u0E19 \u{1F917} Tokenizers \u0E04\u0E38\u0E13\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E40\u0E1E\u0E34\u0E48\u0E21 token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E15\u0E48\u0E32\u0E07\u0E46 \u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E43\u0E19\u0E40\u0E17\u0E23\u0E19\u0E40\u0E19\u0E2D\u0E23\u0E4C\u0E40\u0E2D\u0E07 \u0E44\u0E21\u0E48\u0E40\u0E0A\u0E48\u0E19\u0E19\u0E31\u0E49\u0E19 \u0E21\u0E31\u0E19\u0E08\u0E30\u0E44\u0E21\u0E48\u0E40\u0E1E\u0E34\u0E48\u0E21 token \u0E1E\u0E27\u0E01\u0E19\u0E35\u0E49\u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E43\u0E19 vocabulary \u0E40\u0E1E\u0E23\u0E32\u0E30\u0E27\u0E48\u0E32 token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E44\u0E21\u0E48\u0E44\u0E14\u0E49\u0E2D\u0E22\u0E39\u0E48\u0E43\u0E19 training corpus :"),a$.forEach(t),na=c(e),m(Js.$$.fragment,e),ra=c(e),D=a(e,"P",{});var H=p(D);ak=r(H,"\u0E19\u0E2D\u0E01\u0E08\u0E32\u0E01\u0E40\u0E23\u0E32\u0E08\u0E30\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32 "),Mr=a(H,"CODE",{});var i$=p(Mr);ik=r(i$,"vocab_size"),i$.forEach(t),pk=r(H," \u0E41\u0E25\u0E30 "),Xr=a(H,"CODE",{});var p$=p(Xr);fk=r(p$,"special_tokens"),p$.forEach(t),ck=r(H," \u0E41\u0E25\u0E49\u0E27 \u0E40\u0E23\u0E32\u0E22\u0E31\u0E07\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32 "),Kr=a(H,"CODE",{});var f$=p(Kr);kk=r(f$,"min_frequency"),f$.forEach(t),mk=r(H," (\u0E04\u0E27\u0E32\u0E21\u0E16\u0E35\u0E48\u0E02\u0E31\u0E49\u0E19\u0E15\u0E48\u0E33\u0E02\u0E2D\u0E07\u0E04\u0E33\u0E17\u0E35\u0E48\u0E15\u0E49\u0E2D\u0E07\u0E21\u0E35 \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E17\u0E35\u0E48\u0E08\u0E30\u0E44\u0E14\u0E49\u0E16\u0E39\u0E01\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E25\u0E07\u0E44\u0E1B\u0E43\u0E19 vocabulary) \u0E2B\u0E23\u0E37\u0E2D "),Hr=a(H,"CODE",{});var c$=p(Hr);dk=r(c$,"continuing_subword_prefix"),c$.forEach(t),_k=r(H," (\u0E16\u0E49\u0E32\u0E2B\u0E32\u0E01\u0E40\u0E23\u0E32\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E32\u0E23\u0E43\u0E0A\u0E49\u0E2A\u0E31\u0E0D\u0E25\u0E31\u0E01\u0E29\u0E13\u0E4C\u0E2D\u0E37\u0E48\u0E19 \u0E17\u0E35\u0E48\u0E44\u0E21\u0E48\u0E43\u0E0A\u0E48"),Yr=a(H,"CODE",{});var k$=p(Yr);$k=r(k$,"##"),k$.forEach(t),uk=r(H,") \u0E44\u0E14\u0E49\u0E2D\u0E35\u0E01\u0E14\u0E49\u0E27\u0E22"),H.forEach(t),oa=c(e),kn=a(e,"P",{});var m$=p(kn);zk=r(m$,"\u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E17\u0E23\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25\u0E42\u0E14\u0E22\u0E23\u0E31\u0E19\u0E04\u0E33\u0E2A\u0E31\u0E48\u0E07\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E19\u0E35\u0E49 :"),m$.forEach(t),la=c(e),m(Vs.$$.fragment,e),aa=c(e),Ge=a(e,"P",{});var zp=p(Ge);hk=r(zp,"\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49\u0E44\u0E1F\u0E25\u0E4C\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E40\u0E17\u0E23\u0E19\u0E44\u0E14\u0E49\u0E14\u0E49\u0E27\u0E22 (\u0E41\u0E15\u0E48\u0E01\u0E48\u0E2D\u0E19\u0E2D\u0E37\u0E48\u0E19 \u0E04\u0E38\u0E13\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E42\u0E21\u0E40\u0E14\u0E25\u0E02\u0E36\u0E49\u0E19\u0E21\u0E32\u0E43\u0E2B\u0E21\u0E48\u0E42\u0E14\u0E22\u0E43\u0E0A\u0E49 "),Jr=a(zp,"CODE",{});var d$=p(Jr);Ek=r(d$,"WordPiece"),d$.forEach(t),jk=r(zp," \u0E17\u0E35\u0E48\u0E22\u0E31\u0E07\u0E27\u0E48\u0E32\u0E07\u0E40\u0E1B\u0E25\u0E48\u0E32\u0E2D\u0E22\u0E39\u0E48) :"),zp.forEach(t),ia=c(e),m(Zs.$$.fragment,e),pa=c(e),Me=a(e,"P",{});var hp=p(Me);vk=r(hp,"\u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A\u0E17\u0E31\u0E49\u0E07\u0E2A\u0E2D\u0E07\u0E01\u0E23\u0E13\u0E35 \u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E17\u0E14\u0E25\u0E2D\u0E07\u0E43\u0E0A\u0E49 tokenizer \u0E01\u0E31\u0E1A\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E44\u0E14\u0E49 \u0E42\u0E14\u0E22\u0E40\u0E23\u0E35\u0E22\u0E01\u0E43\u0E0A\u0E49 "),Vr=a(hp,"CODE",{});var _$=p(Vr);bk=r(_$,"encode()"),_$.forEach(t),xk=r(hp," method :"),hp.forEach(t),fa=c(e),m(Qs.$$.fragment,e),ca=c(e),m(et.$$.fragment,e),ka=c(e),v=a(e,"P",{});var x=p(v);Zr=a(x,"CODE",{});var $$=p(Zr);gk=r($$,"encoding"),$$.forEach(t),Pk=r(x," \u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E04\u0E37\u0E2D "),Qr=a(x,"CODE",{});var u$=p(Qr);wk=r(u$,"Encoding"),u$.forEach(t),qk=r(x," \u0E17\u0E35\u0E48\u0E1B\u0E23\u0E30\u0E01\u0E2D\u0E1A\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22\u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E08\u0E33\u0E40\u0E1B\u0E47\u0E19\u0E15\u0E48\u0E32\u0E07\u0E46\u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A tokenizer \u0E44\u0E14\u0E49\u0E41\u0E01\u0E48 "),eo=a(x,"CODE",{});var z$=p(eo);Tk=r(z$,"ids"),z$.forEach(t),Dk=r(x,", "),so=a(x,"CODE",{});var h$=p(so);Ck=r(h$,"type_ids"),h$.forEach(t),yk=r(x,", "),to=a(x,"CODE",{});var E$=p(to);Ok=r(E$,"tokens"),E$.forEach(t),Lk=r(x,", "),no=a(x,"CODE",{});var j$=p(no);Sk=r(j$,"offsets"),j$.forEach(t),Bk=r(x,", "),ro=a(x,"CODE",{});var v$=p(ro);Nk=r(v$,"attention_mask"),v$.forEach(t),Fk=r(x,", "),oo=a(x,"CODE",{});var b$=p(oo);Ak=r(b$,"special_tokens_mask"),b$.forEach(t),Wk=r(x,", \u0E41\u0E25\u0E30 "),lo=a(x,"CODE",{});var x$=p(lo);Uk=r(x$,"overflowing"),x$.forEach(t),x.forEach(t),ma=c(e),_e=a(e,"P",{});var In=p(_e);Ik=r(In,`\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E2A\u0E38\u0E14\u0E17\u0E49\u0E32\u0E22\u0E02\u0E2D\u0E07 pipeline \u0E04\u0E37\u0E2D post-processing
\u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E1E\u0E34\u0E48\u0E21 `),ao=a(In,"CODE",{});var g$=p(ao);Rk=r(g$,"[CLS]"),g$.forEach(t),Gk=r(In," \u0E44\u0E27\u0E49\u0E17\u0E35\u0E48\u0E15\u0E2D\u0E19\u0E15\u0E49\u0E19\u0E02\u0E2D\u0E07\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E08\u0E32\u0E01\u0E01\u0E32\u0E23 tokenize \u0E41\u0E25\u0E30 "),io=a(In,"CODE",{});var P$=p(io);Mk=r(P$,"[SEP]"),P$.forEach(t),Xk=r(In," \u0E44\u0E27\u0E49\u0E17\u0E35\u0E48\u0E15\u0E2D\u0E19\u0E17\u0E49\u0E32\u0E22 \u0E2B\u0E23\u0E37\u0E2D\u0E2B\u0E25\u0E31\u0E07\u0E2A\u0E34\u0E49\u0E19\u0E2A\u0E38\u0E14\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04 \u0E16\u0E49\u0E32 input \u0E02\u0E2D\u0E07\u0E40\u0E23\u0E32\u0E21\u0E35\u0E2A\u0E2D\u0E07\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04"),In.forEach(t),da=c(e),I=a(e,"P",{});var ls=p(I);Kk=r(ls,"\u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49 "),po=a(ls,"CODE",{});var w$=p(po);Hk=r(w$,"TemplateProcessor"),w$.forEach(t),Yk=r(ls," \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E0A\u0E48\u0E27\u0E22\u0E40\u0E23\u0E32\u0E17\u0E33 \u0E41\u0E15\u0E48\u0E01\u0E48\u0E2D\u0E19\u0E2D\u0E37\u0E48\u0E19\u0E40\u0E23\u0E32\u0E15\u0E49\u0E2D\u0E07\u0E2B\u0E32 ID \u0E02\u0E2D\u0E07 "),fo=a(ls,"CODE",{});var q$=p(fo);Jk=r(q$,"[CLS]"),q$.forEach(t),Vk=r(ls," \u0E41\u0E25\u0E30 "),co=a(ls,"CODE",{});var T$=p(co);Zk=r(T$,"[SEP]"),T$.forEach(t),Qk=r(ls," \u0E01\u0E48\u0E2D\u0E19 :"),ls.forEach(t),_a=c(e),m(st.$$.fragment,e),$a=c(e),m(tt.$$.fragment,e),ua=c(e),R=a(e,"P",{});var as=p(R);em=r(as,"\u0E40\u0E23\u0E32\u0E08\u0E30\u0E21\u0E32\u0E2A\u0E23\u0E49\u0E32\u0E07 template \u0E43\u0E2B\u0E49\u0E01\u0E31\u0E1A "),ko=a(as,"CODE",{});var D$=p(ko);sm=r(D$,"TemplateProcessor"),D$.forEach(t),tm=r(as,` \u0E42\u0E14\u0E22\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E33\u0E2B\u0E19\u0E14\u0E27\u0E48\u0E32\u0E40\u0E23\u0E32\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E32\u0E23\u0E43\u0E2B\u0E49\u0E21\u0E31\u0E19\u0E1B\u0E23\u0E30\u0E21\u0E27\u0E25\u0E1C\u0E25 input \u0E17\u0E35\u0E48\u0E40\u0E1B\u0E47\u0E19 \u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E40\u0E14\u0E35\u0E48\u0E22\u0E27 \u0E41\u0E25\u0E30 input \u0E17\u0E35\u0E48\u0E21\u0E35\u0E2A\u0E2D\u0E07\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E44\u0E23
\u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A\u0E17\u0E31\u0E49\u0E07\u0E2A\u0E2D\u0E07\u0E01\u0E23\u0E13\u0E35 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E33\u0E2B\u0E19\u0E14 token \u0E1E\u0E34\u0E40\u0E28\u0E29 \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E41\u0E17\u0E19\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E02\u0E36\u0E49\u0E19\u0E21\u0E32 \u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E40\u0E14\u0E35\u0E48\u0E22\u0E27\u0E2B\u0E23\u0E37\u0E2D\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E41\u0E23\u0E01 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49 `),mo=a(as,"CODE",{});var C$=p(mo);nm=r(C$,"$A"),C$.forEach(t),rm=r(as," \u0E2A\u0E48\u0E27\u0E19\u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04\u0E17\u0E35\u0E48\u0E2A\u0E2D\u0E07 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E43\u0E0A\u0E49 "),_o=a(as,"CODE",{});var y$=p(_o);om=r(y$,"$B"),y$.forEach(t),lm=r(as,`
\u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E1E\u0E27\u0E01\u0E19\u0E35\u0E49\u0E41\u0E25\u0E30\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E2A\u0E23\u0E49\u0E32\u0E07 token type ID \u0E02\u0E36\u0E49\u0E19\u0E21\u0E32 \u0E42\u0E14\u0E22\u0E08\u0E30\u0E40\u0E02\u0E35\u0E22\u0E19 ID \u0E19\u0E35\u0E49\u0E2B\u0E25\u0E31\u0E07\u0E40\u0E04\u0E23\u0E37\u0E48\u0E2D\u0E07\u0E2B\u0E21\u0E32\u0E22 colon`),as.forEach(t),za=c(e),mn=a(e,"P",{});var O$=p(mn);am=r(O$,"template \u0E02\u0E2D\u0E07 BERT \u0E21\u0E35\u0E23\u0E32\u0E22\u0E25\u0E30\u0E40\u0E2D\u0E35\u0E22\u0E14\u0E14\u0E31\u0E07\u0E19\u0E35\u0E49 :"),O$.forEach(t),ha=c(e),m(nt.$$.fragment,e),Ea=c(e),dn=a(e,"P",{});var L$=p(dn);im=r(L$,"\u0E2D\u0E22\u0E48\u0E32\u0E25\u0E37\u0E21\u0E27\u0E48\u0E32 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E43\u0E2B\u0E49\u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E42\u0E21\u0E40\u0E14\u0E25\u0E40\u0E01\u0E35\u0E48\u0E22\u0E27\u0E01\u0E31\u0E1A ID \u0E02\u0E2D\u0E07 token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E14\u0E49\u0E27\u0E22 \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E17\u0E35\u0E48\u0E42\u0E21\u0E40\u0E14\u0E25\u0E08\u0E30\u0E44\u0E14\u0E49\u0E41\u0E1B\u0E25\u0E07\u0E21\u0E31\u0E19\u0E44\u0E14\u0E49\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E16\u0E39\u0E01\u0E15\u0E49\u0E2D\u0E07"),L$.forEach(t),ja=c(e),_n=a(e,"P",{});var S$=p(_n);pm=r(S$,"\u0E40\u0E23\u0E32\u0E08\u0E30\u0E01\u0E25\u0E31\u0E1A\u0E21\u0E32\u0E14\u0E39\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E01\u0E48\u0E2D\u0E19\u0E2B\u0E19\u0E49\u0E32\u0E01\u0E31\u0E19 :"),S$.forEach(t),va=c(e),m(rt.$$.fragment,e),ba=c(e),m(ot.$$.fragment,e),xa=c(e),$n=a(e,"P",{});var B$=p($n);fm=r(B$,"\u0E16\u0E49\u0E32\u0E40\u0E23\u0E32\u0E43\u0E2A\u0E48 input \u0E17\u0E35\u0E48\u0E40\u0E1B\u0E47\u0E19\u0E2A\u0E2D\u0E07\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E44\u0E14\u0E49 :"),B$.forEach(t),ga=c(e),m(lt.$$.fragment,e),Pa=c(e),m(at.$$.fragment,e),wa=c(e),un=a(e,"P",{});var N$=p(un);cm=r(N$,"\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E2A\u0E38\u0E14\u0E17\u0E49\u0E32\u0E22 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E1E\u0E34\u0E48\u0E21 decoder \u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E43\u0E19 pipeline :"),N$.forEach(t),qa=c(e),m(it.$$.fragment,e),Ta=c(e),Xe=a(e,"P",{});var Ep=p(Xe);km=r(Ep,"\u0E21\u0E32\u0E14\u0E39\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E02\u0E2D\u0E07 "),$o=a(Ep,"CODE",{});var F$=p($o);mm=r(F$,"encoding"),F$.forEach(t),dm=r(Ep," \u0E01\u0E31\u0E19 :"),Ep.forEach(t),Da=c(e),m(pt.$$.fragment,e),Ca=c(e),m(ft.$$.fragment,e),ya=c(e),zn=a(e,"P",{});var A$=p(zn);_m=r(A$,"\u0E40\u0E22\u0E35\u0E48\u0E22\u0E21\u0E21\u0E32\u0E01! \u0E15\u0E2D\u0E19\u0E19\u0E35\u0E49\u0E40\u0E23\u0E32\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E1A\u0E31\u0E19\u0E17\u0E36\u0E01 tokenizer \u0E19\u0E35\u0E49\u0E40\u0E1B\u0E47\u0E19\u0E44\u0E1F\u0E25\u0E4C JSON \u0E44\u0E14\u0E49\u0E41\u0E25\u0E49\u0E27 \u0E14\u0E31\u0E07\u0E19\u0E35\u0E49 :"),A$.forEach(t),Oa=c(e),m(ct.$$.fragment,e),La=c(e),$e=a(e,"P",{});var Rn=p($e);$m=r(Rn,"\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E42\u0E2B\u0E25\u0E14\u0E44\u0E1F\u0E25\u0E4C\u0E19\u0E35\u0E49\u0E43\u0E2B\u0E49\u0E40\u0E1B\u0E47\u0E19 "),uo=a(Rn,"CODE",{});var W$=p(uo);um=r(W$,"Tokenizer"),W$.forEach(t),zm=r(Rn," object \u0E44\u0E14\u0E49\u0E42\u0E14\u0E22\u0E43\u0E0A\u0E49 "),zo=a(Rn,"CODE",{});var U$=p(zo);hm=r(U$,"from_file()"),U$.forEach(t),Em=r(Rn," method :"),Rn.forEach(t),Sa=c(e),m(kt.$$.fragment,e),Ba=c(e),ue=a(e,"P",{});var Gn=p(ue);jm=r(Gn,"\u0E01\u0E32\u0E23\u0E08\u0E30\u0E19\u0E33 tokenizer \u0E19\u0E35\u0E49\u0E21\u0E32\u0E43\u0E0A\u0E49\u0E43\u0E19 \u{1F917} Transformers \u0E40\u0E23\u0E32\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07 wrap \u0E21\u0E31\u0E19\u0E43\u0E2B\u0E49\u0E40\u0E1B\u0E47\u0E19 "),ho=a(Gn,"CODE",{});var I$=p(ho);vm=r(I$,"PreTrainedTokenizerFast"),I$.forEach(t),bm=r(Gn,` \u0E01\u0E48\u0E2D\u0E19
\u0E42\u0E14\u0E22\u0E40\u0E23\u0E32\u0E43\u0E0A\u0E49 class \u0E1B\u0E01\u0E15\u0E34 (\u0E16\u0E49\u0E32 tokenizer \u0E02\u0E2D\u0E07\u0E40\u0E23\u0E32\u0E21\u0E35\u0E42\u0E04\u0E23\u0E07\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E2A\u0E2D\u0E14\u0E04\u0E25\u0E49\u0E2D\u0E07\u0E01\u0E31\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25\u0E2B\u0E25\u0E31\u0E01\u0E40\u0E23\u0E32\u0E17\u0E35\u0E48\u0E08\u0E30\u0E43\u0E0A\u0E49\u0E07\u0E32\u0E19) \u0E2B\u0E23\u0E37\u0E2D class \u0E17\u0E35\u0E48\u0E16\u0E39\u0E01\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E02\u0E36\u0E49\u0E19\u0E21\u0E32\u0E41\u0E25\u0E49\u0E27 \u0E40\u0E0A\u0E48\u0E19 `),Eo=a(Gn,"CODE",{});var R$=p(Eo);xm=r(R$,"BertTokenizerFast"),R$.forEach(t),gm=r(Gn,`
\u0E43\u0E19\u0E01\u0E23\u0E13\u0E35\u0E17\u0E35\u0E48\u0E04\u0E38\u0E13\u0E2A\u0E23\u0E49\u0E32\u0E07 tokenizer \u0E02\u0E36\u0E49\u0E19\u0E21\u0E32\u0E40\u0E2D\u0E07\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E2A\u0E2D\u0E19\u0E44\u0E27\u0E49\u0E02\u0E49\u0E32\u0E07\u0E15\u0E49\u0E19 \u0E04\u0E38\u0E13\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E43\u0E0A\u0E49\u0E15\u0E31\u0E27\u0E40\u0E25\u0E37\u0E2D\u0E01\u0E41\u0E23\u0E01`),Gn.forEach(t),Na=c(e),C=a(e,"P",{});var Y=p(C);Pm=r(Y,"\u0E01\u0E32\u0E23\u0E08\u0E30 wrap tokenizer \u0E02\u0E2D\u0E07\u0E40\u0E23\u0E32\u0E43\u0E2B\u0E49\u0E40\u0E1B\u0E47\u0E19 "),jo=a(Y,"CODE",{});var G$=p(jo);wm=r(G$,"PreTrainedTokenizerFast"),G$.forEach(t),qm=r(Y," \u0E40\u0E23\u0E32\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E2A\u0E48\u0E07\u0E1C\u0E48\u0E32\u0E19 tokenizer \u0E02\u0E2D\u0E07\u0E40\u0E23\u0E32\u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E40\u0E1B\u0E47\u0E19 "),vo=a(Y,"CODE",{});var M$=p(vo);Tm=r(M$,"tokenizer_object"),M$.forEach(t),Dm=r(Y," \u0E2B\u0E23\u0E37\u0E2D \u0E2A\u0E48\u0E07\u0E1C\u0E48\u0E32\u0E19\u0E44\u0E1F\u0E25\u0E4C\u0E02\u0E2D\u0E07 tokenizer \u0E40\u0E1B\u0E47\u0E19 "),bo=a(Y,"CODE",{});var X$=p(bo);Cm=r(X$,"tokenizer_file"),X$.forEach(t),ym=r(Y,`
\u0E2A\u0E34\u0E48\u0E07\u0E2A\u0E33\u0E04\u0E31\u0E0D\u0E2D\u0E35\u0E01\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E04\u0E37\u0E2D \u0E04\u0E38\u0E13\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E2A\u0E48\u0E07\u0E1C\u0E48\u0E32\u0E19\u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E40\u0E01\u0E35\u0E48\u0E22\u0E27\u0E01\u0E31\u0E1A token \u0E1E\u0E34\u0E40\u0E28\u0E29 \u0E15\u0E48\u0E32\u0E07\u0E46\u0E43\u0E2B\u0E49\u0E42\u0E21\u0E40\u0E14\u0E25\u0E40\u0E2D\u0E07 \u0E40\u0E1E\u0E23\u0E32\u0E30\u0E27\u0E48\u0E32 class \u0E19\u0E35\u0E49\u0E08\u0E30\u0E44\u0E21\u0E48\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16 infer \u0E08\u0E32\u0E01 `),xo=a(Y,"CODE",{});var K$=p(xo);Om=r(K$,"tokenizer"),K$.forEach(t),Lm=r(Y," object \u0E44\u0E14\u0E49\u0E40\u0E2D\u0E07 \u0E27\u0E48\u0E32 token \u0E15\u0E31\u0E27\u0E44\u0E2B\u0E19\u0E40\u0E1B\u0E47\u0E19 mask token \u0E40\u0E0A\u0E48\u0E19 "),go=a(Y,"CODE",{});var H$=p(go);Sm=r(H$,"[CLS]"),H$.forEach(t),Bm=r(Y," :"),Y.forEach(t),Fa=c(e),m(mt.$$.fragment,e),Aa=c(e),Ke=a(e,"P",{});var jp=p(Ke);Nm=r(jp,"\u0E16\u0E49\u0E32\u0E04\u0E38\u0E13\u0E43\u0E0A\u0E49 class \u0E17\u0E35\u0E48\u0E40\u0E09\u0E1E\u0E32\u0E30\u0E40\u0E08\u0E32\u0E30\u0E08\u0E07 \u0E40\u0E0A\u0E48\u0E19 "),Po=a(jp,"CODE",{});var Y$=p(Po);Fm=r(Y$,"BertTokenizerFast"),Y$.forEach(t),Am=r(jp," \u0E04\u0E38\u0E13\u0E40\u0E1E\u0E35\u0E22\u0E07\u0E41\u0E04\u0E48\u0E15\u0E49\u0E2D\u0E07\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E02\u0E49\u0E2D\u0E21\u0E39\u0E25\u0E40\u0E01\u0E35\u0E48\u0E22\u0E27\u0E01\u0E31\u0E1A token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E17\u0E35\u0E48\u0E15\u0E48\u0E32\u0E07\u0E08\u0E32\u0E01\u0E15\u0E31\u0E27\u0E17\u0E35\u0E48\u0E42\u0E21\u0E40\u0E14\u0E25\u0E43\u0E0A\u0E49\u0E2D\u0E22\u0E39\u0E48\u0E41\u0E25\u0E49\u0E27 \u0E43\u0E19\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E02\u0E2D\u0E07\u0E40\u0E23\u0E32 \u0E40\u0E23\u0E32\u0E44\u0E21\u0E48\u0E44\u0E14\u0E49\u0E43\u0E0A\u0E49 token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E2D\u0E37\u0E48\u0E19 \u0E08\u0E36\u0E07\u0E44\u0E21\u0E48\u0E15\u0E49\u0E2D\u0E07\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E2D\u0E30\u0E44\u0E23 :"),jp.forEach(t),Wa=c(e),m(dt.$$.fragment,e),Ua=c(e),Pe=a(e,"P",{});var kl=p(Pe);Wm=r(kl,"\u0E15\u0E2D\u0E19\u0E19\u0E35\u0E49\u0E40\u0E23\u0E32\u0E01\u0E47\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E43\u0E0A\u0E49 tokenizer \u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E02\u0E36\u0E49\u0E19\u0E21\u0E32\u0E40\u0E2D\u0E07 \u0E40\u0E2B\u0E21\u0E37\u0E2D\u0E19\u0E01\u0E31\u0E1A tokenizer \u0E15\u0E31\u0E27\u0E2D\u0E37\u0E48\u0E19\u0E46\u0E08\u0E32\u0E01 \u{1F917} Transformers \u0E44\u0E14\u0E49\u0E41\u0E25\u0E49\u0E27 \u0E19\u0E2D\u0E01\u0E08\u0E32\u0E01\u0E19\u0E31\u0E49\u0E19\u0E04\u0E38\u0E13\u0E22\u0E31\u0E07\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E40\u0E0B\u0E1F\u0E21\u0E31\u0E19\u0E44\u0E14\u0E49 \u0E42\u0E14\u0E22\u0E43\u0E0A\u0E49 "),wo=a(kl,"CODE",{});var J$=p(wo);Um=r(J$,"save_pretrained()"),J$.forEach(t),Im=r(kl," \u0E2B\u0E23\u0E37\u0E2D\u0E2D\u0E31\u0E1E\u0E42\u0E2B\u0E25\u0E14\u0E21\u0E31\u0E19\u0E44\u0E1B\u0E17\u0E35\u0E48 Hub \u0E42\u0E14\u0E22\u0E43\u0E0A\u0E49 "),qo=a(kl,"CODE",{});var V$=p(qo);Rm=r(V$,"push_to_hub()"),V$.forEach(t),kl.forEach(t),Ia=c(e),hn=a(e,"P",{});var Z$=p(hn);Gm=r(Z$,"\u0E2B\u0E25\u0E31\u0E07\u0E08\u0E32\u0E01\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E14\u0E39\u0E01\u0E31\u0E19\u0E41\u0E25\u0E49\u0E27\u0E27\u0E48\u0E32\u0E08\u0E30\u0E2A\u0E23\u0E49\u0E32\u0E07 WordPiece tokenizer \u0E2D\u0E22\u0E48\u0E32\u0E07\u0E44\u0E23 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E21\u0E32\u0E14\u0E39\u0E01\u0E31\u0E19\u0E27\u0E48\u0E32 \u0E08\u0E30\u0E17\u0E33\u0E41\u0E1A\u0E1A\u0E40\u0E14\u0E35\u0E22\u0E27\u0E01\u0E31\u0E19\u0E01\u0E31\u0E1A BPE tokenizer \u0E44\u0E14\u0E49\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E44\u0E23 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E2D\u0E18\u0E34\u0E1A\u0E32\u0E22\u0E04\u0E23\u0E48\u0E32\u0E27\u0E46\u0E40\u0E17\u0E48\u0E32\u0E19\u0E31\u0E49\u0E19 \u0E40\u0E1E\u0E23\u0E32\u0E30\u0E04\u0E38\u0E13\u0E44\u0E14\u0E49\u0E40\u0E23\u0E35\u0E22\u0E19\u0E23\u0E32\u0E22\u0E25\u0E30\u0E40\u0E2D\u0E35\u0E22\u0E14\u0E21\u0E32\u0E41\u0E25\u0E49\u0E27 \u0E41\u0E25\u0E30\u0E08\u0E30\u0E1E\u0E39\u0E14\u0E16\u0E36\u0E07\u0E41\u0E04\u0E48\u0E02\u0E49\u0E2D\u0E41\u0E15\u0E01\u0E15\u0E48\u0E32\u0E07\u0E40\u0E17\u0E48\u0E32\u0E19\u0E31\u0E49\u0E19"),Z$.forEach(t),Ra=c(e),we=a(e,"H2",{class:!0});var vp=p(we);He=a(vp,"A",{id:!0,class:!0,href:!0});var Q$=p(He);To=a(Q$,"SPAN",{});var eu=p(To);m(_t.$$.fragment,eu),eu.forEach(t),Q$.forEach(t),Mm=c(vp),Do=a(vp,"SPAN",{});var su=p(Do);Xm=r(su,"\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 BPE tokenizer \u0E15\u0E31\u0E49\u0E07\u0E41\u0E15\u0E48\u0E40\u0E23\u0E34\u0E48\u0E21\u0E15\u0E49\u0E19"),su.forEach(t),vp.forEach(t),Ga=c(e),Ye=a(e,"P",{});var bp=p(Ye);Km=r(bp,"\u0E40\u0E23\u0E32\u0E08\u0E30\u0E21\u0E32\u0E2A\u0E23\u0E49\u0E32\u0E07 GPT-2 tokenizer \u0E01\u0E31\u0E19 \u0E40\u0E0A\u0E48\u0E19\u0E40\u0E14\u0E35\u0E22\u0E27\u0E01\u0E31\u0E1A\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E02\u0E2D\u0E07 BERT tokenizer \u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E23\u0E34\u0E48\u0E21\u0E14\u0E49\u0E27\u0E22\u0E01\u0E31\u0E19 initialize "),Co=a(bp,"CODE",{});var tu=p(Co);Hm=r(tu,"Tokenizer"),tu.forEach(t),Ym=r(bp," \u0E14\u0E49\u0E27\u0E22\u0E42\u0E21\u0E40\u0E14\u0E25 BPE :"),bp.forEach(t),Ma=c(e),m($t.$$.fragment,e),Xa=c(e),G=a(e,"P",{});var is=p(G);Jm=r(is,"\u0E40\u0E23\u0E32\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E2A\u0E23\u0E49\u0E32\u0E07\u0E42\u0E21\u0E40\u0E14\u0E25\u0E19\u0E35\u0E49\u0E14\u0E49\u0E27\u0E22 vocabulary \u0E17\u0E35\u0E48\u0E21\u0E35\u0E2D\u0E22\u0E39\u0E48\u0E44\u0E14\u0E49 \u0E42\u0E14\u0E22\u0E2A\u0E48\u0E07\u0E1C\u0E48\u0E32\u0E19 "),yo=a(is,"CODE",{});var nu=p(yo);Vm=r(nu,"vocab"),nu.forEach(t),Zm=r(is," \u0E41\u0E25\u0E30 "),Oo=a(is,"CODE",{});var ru=p(Oo);Qm=r(ru,"merges"),ru.forEach(t),ed=r(is,` \u0E41\u0E15\u0E48\u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E17\u0E23\u0E19\u0E15\u0E31\u0E49\u0E07\u0E41\u0E15\u0E48\u0E15\u0E49\u0E19 \u0E41\u0E1B\u0E25\u0E27\u0E48\u0E32\u0E40\u0E23\u0E32\u0E44\u0E21\u0E48\u0E08\u0E33\u0E40\u0E1B\u0E47\u0E19\u0E15\u0E49\u0E2D\u0E07\u0E17\u0E33\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E19\u0E35\u0E49
\u0E40\u0E23\u0E32\u0E44\u0E21\u0E48\u0E08\u0E33\u0E40\u0E1B\u0E47\u0E19\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E33\u0E2B\u0E19\u0E14 `),Lo=a(is,"CODE",{});var ou=p(Lo);sd=r(ou,"unk_token"),ou.forEach(t),td=r(is," \u0E40\u0E1E\u0E23\u0E32\u0E30 GPT-2 \u0E43\u0E0A\u0E49 byte-level BPE"),is.forEach(t),Ka=c(e),En=a(e,"P",{});var lu=p(En);nd=r(lu,"\u0E19\u0E2D\u0E01\u0E08\u0E32\u0E01\u0E19\u0E31\u0E49\u0E19 GPT-2 \u0E22\u0E31\u0E07\u0E44\u0E21\u0E48\u0E43\u0E0A\u0E49 normalizer \u0E2D\u0E35\u0E01\u0E14\u0E49\u0E27\u0E22 \u0E40\u0E23\u0E32\u0E08\u0E36\u0E07\u0E08\u0E30\u0E02\u0E49\u0E32\u0E21\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E19\u0E35\u0E49\u0E44\u0E1B\u0E17\u0E33 pre-tokenization \u0E40\u0E25\u0E22 :"),lu.forEach(t),Ha=c(e),m(ut.$$.fragment,e),Ya=c(e),zt=a(e,"P",{});var U_=p(zt);So=a(U_,"CODE",{});var au=p(So);rd=r(au,"add_prefix_space=False"),au.forEach(t),od=r(U_," \u0E2B\u0E21\u0E32\u0E22\u0E16\u0E36\u0E07\u0E40\u0E23\u0E32\u0E08\u0E30\u0E44\u0E21\u0E48\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E15\u0E23\u0E07\u0E15\u0E49\u0E19\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04 (\u0E04\u0E48\u0E32 default \u0E08\u0E30\u0E21\u0E35\u0E01\u0E32\u0E23\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E19\u0E35\u0E49)"),U_.forEach(t),Ja=c(e),jn=a(e,"P",{});var iu=p(jn);ld=r(iu,"\u0E21\u0E32\u0E14\u0E39\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E02\u0E2D\u0E07\u0E01\u0E32\u0E23 pre-tokenization \u0E01\u0E31\u0E19 :"),iu.forEach(t),Va=c(e),m(ht.$$.fragment,e),Za=c(e),m(Et.$$.fragment,e),Qa=c(e),vn=a(e,"P",{});var pu=p(vn);ad=r(pu,"\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E04\u0E37\u0E2D\u0E01\u0E32\u0E23\u0E40\u0E17\u0E23\u0E19\u0E42\u0E21\u0E40\u0E14\u0E25  \u0E2A\u0E33\u0E2B\u0E23\u0E31\u0E1A GPT-2 \u0E21\u0E31\u0E19\u0E08\u0E30\u0E21\u0E35 token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E15\u0E31\u0E27\u0E40\u0E14\u0E35\u0E22\u0E27\u0E04\u0E37\u0E2D end-of-text token (\u0E2D\u0E22\u0E39\u0E48\u0E15\u0E23\u0E07\u0E17\u0E49\u0E32\u0E22\u0E02\u0E2D\u0E07\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21) :"),pu.forEach(t),ei=c(e),m(jt.$$.fragment,e),si=c(e),g=a(e,"P",{});var N=p(g);id=r(N,"\u0E40\u0E0A\u0E48\u0E19\u0E40\u0E14\u0E35\u0E22\u0E27\u0E01\u0E31\u0E19\u0E01\u0E31\u0E1A "),Bo=a(N,"CODE",{});var fu=p(Bo);pd=r(fu,"WordPieceTrainer"),fu.forEach(t),fd=r(N," \u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E01\u0E33\u0E2B\u0E19\u0E14 "),No=a(N,"CODE",{});var cu=p(No);cd=r(cu,"vocab_size"),cu.forEach(t),kd=r(N,", "),Fo=a(N,"CODE",{});var ku=p(Fo);md=r(ku,"special_tokens"),ku.forEach(t),dd=r(N,", "),Ao=a(N,"CODE",{});var mu=p(Ao);_d=r(mu,"min_frequency"),mu.forEach(t),$d=r(N," \u0E44\u0E14\u0E49 \u0E16\u0E49\u0E32\u0E2B\u0E32\u0E01\u0E04\u0E38\u0E13\u0E43\u0E0A\u0E49 end-of-word suffix (\u0E40\u0E0A\u0E48\u0E19 "),Wo=a(N,"CODE",{});var du=p(Wo);ud=r(du,"</w>"),du.forEach(t),zd=r(N,") \u0E04\u0E38\u0E13\u0E01\u0E47\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32\u0E21\u0E31\u0E19\u0E44\u0E14\u0E49\u0E14\u0E49\u0E27\u0E22 "),Uo=a(N,"CODE",{});var _u=p(Uo);hd=r(_u,"end_of_word_suffix"),_u.forEach(t),N.forEach(t),ti=c(e),bn=a(e,"P",{});var $u=p(bn);Ed=r($u,"\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E40\u0E17\u0E23\u0E19\u0E14\u0E49\u0E27\u0E22\u0E44\u0E1F\u0E25\u0E4C\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E44\u0E14\u0E49\u0E14\u0E49\u0E27\u0E22 :"),$u.forEach(t),ni=c(e),m(vt.$$.fragment,e),ri=c(e),xn=a(e,"P",{});var uu=p(xn);jd=r(uu,"\u0E21\u0E32\u0E14\u0E39\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E02\u0E2D\u0E07\u0E01\u0E32\u0E23 tokenize \u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E01\u0E31\u0E19 :"),uu.forEach(t),oi=c(e),m(bt.$$.fragment,e),li=c(e),m(xt.$$.fragment,e),ai=c(e),gn=a(e,"P",{});var zu=p(gn);vd=r(zu,"\u0E40\u0E23\u0E32\u0E08\u0E30\u0E17\u0E33\u0E01\u0E32\u0E23 post-processing \u0E41\u0E1A\u0E1A byte-level \u0E43\u0E2B\u0E49\u0E01\u0E31\u0E1A GPT-2 tokenizer \u0E14\u0E31\u0E07\u0E19\u0E35\u0E49 :"),zu.forEach(t),ii=c(e),m(gt.$$.fragment,e),pi=c(e),qe=a(e,"P",{});var ml=p(qe);Io=a(ml,"CODE",{});var hu=p(Io);bd=r(hu,"trim_offsets = False"),hu.forEach(t),xd=r(ml," \u0E41\u0E1B\u0E25\u0E27\u0E48\u0E32\u0E40\u0E23\u0E32\u0E08\u0E30\u0E44\u0E21\u0E48\u0E40\u0E1B\u0E25\u0E35\u0E48\u0E22\u0E19\u0E41\u0E1B\u0E25\u0E07\u0E04\u0E48\u0E32 offset \u0E02\u0E2D\u0E07 token \u0E17\u0E35\u0E48\u0E02\u0E36\u0E49\u0E19\u0E15\u0E49\u0E19\u0E14\u0E49\u0E27\u0E22 "),Ro=a(ml,"CODE",{});var Eu=p(Ro);gd=r(Eu,"\u0120"),Eu.forEach(t),Pd=r(ml," \u0E0B\u0E36\u0E48\u0E07\u0E41\u0E1B\u0E25\u0E27\u0E48\u0E32\u0E15\u0E33\u0E41\u0E2B\u0E19\u0E48\u0E07\u0E40\u0E23\u0E34\u0E48\u0E21\u0E15\u0E49\u0E19\u0E02\u0E2D\u0E07 offset \u0E08\u0E30\u0E2B\u0E21\u0E32\u0E22\u0E16\u0E36\u0E07 \u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07 \u0E41\u0E25\u0E30\u0E44\u0E21\u0E48\u0E43\u0E0A\u0E48\u0E15\u0E31\u0E27\u0E2D\u0E31\u0E01\u0E29\u0E23\u0E41\u0E23\u0E01\u0E02\u0E2D\u0E07 token \u0E19\u0E31\u0E49\u0E19"),ml.forEach(t),fi=c(e),Je=a(e,"P",{});var xp=p(Je);wd=r(xp,"\u0E21\u0E32\u0E14\u0E39\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E02\u0E2D\u0E07\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E17\u0E35\u0E48\u0E40\u0E23\u0E32\u0E40\u0E1E\u0E34\u0E48\u0E07\u0E08\u0E30 encode \u0E01\u0E31\u0E19\u0E44\u0E1B \u0E43\u0E19\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E19\u0E35\u0E49 token \u0E43\u0E19\u0E15\u0E33\u0E41\u0E2B\u0E19\u0E48\u0E07\u0E17\u0E35\u0E48 4 \u0E04\u0E37\u0E2D "),Go=a(xp,"CODE",{});var ju=p(Go);qd=r(ju,"'\u0120test'"),ju.forEach(t),Td=r(xp," :"),xp.forEach(t),ci=c(e),m(Pt.$$.fragment,e),ki=c(e),m(wt.$$.fragment,e),mi=c(e),Pn=a(e,"P",{});var vu=p(Pn);Dd=r(vu,"\u0E2A\u0E38\u0E14\u0E17\u0E49\u0E32\u0E22\u0E40\u0E23\u0E32\u0E08\u0E30\u0E40\u0E1E\u0E34\u0E48\u0E21\u0E2A\u0E48\u0E27\u0E19\u0E17\u0E35\u0E48\u0E40\u0E1B\u0E47\u0E19 byte-level decoder :"),vu.forEach(t),di=c(e),m(qt.$$.fragment,e),_i=c(e),wn=a(e,"P",{});var bu=p(wn);Cd=r(bu,"\u0E40\u0E0A\u0E47\u0E04\u0E14\u0E39\u0E2D\u0E35\u0E01\u0E17\u0E35\u0E27\u0E48\u0E32\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E16\u0E39\u0E01\u0E15\u0E49\u0E2D\u0E07\u0E2B\u0E23\u0E37\u0E2D\u0E44\u0E21\u0E48 :"),bu.forEach(t),$i=c(e),m(Tt.$$.fragment,e),ui=c(e),m(Dt.$$.fragment,e),zi=c(e),ze=a(e,"P",{});var Mn=p(ze);yd=r(Mn,"\u0E40\u0E22\u0E35\u0E48\u0E22\u0E21\u0E21\u0E32\u0E01! \u0E15\u0E2D\u0E19\u0E19\u0E35\u0E49\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E40\u0E0B\u0E1F\u0E42\u0E21\u0E40\u0E14\u0E25\u0E44\u0E14\u0E49 \u0E2A\u0E48\u0E27\u0E19\u0E02\u0E31\u0E49\u0E19\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E04\u0E37\u0E2D \u0E40\u0E23\u0E32\u0E08\u0E30 wrap tokenizer \u0E02\u0E2D\u0E07\u0E40\u0E23\u0E32\u0E43\u0E2B\u0E49\u0E40\u0E1B\u0E47\u0E19 "),Mo=a(Mn,"CODE",{});var xu=p(Mo);Od=r(xu,"PreTrainedTokenizerFast"),xu.forEach(t),Ld=r(Mn," \u0E2B\u0E23\u0E37\u0E2D "),Xo=a(Mn,"CODE",{});var gu=p(Xo);Sd=r(gu,"GPT2TokenizerFast"),gu.forEach(t),Bd=r(Mn," \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E08\u0E30\u0E44\u0E14\u0E49\u0E40\u0E23\u0E35\u0E22\u0E01\u0E43\u0E0A\u0E49\u0E21\u0E31\u0E19\u0E44\u0E14\u0E49\u0E43\u0E19 \u{1F917} Transformers"),Mn.forEach(t),hi=c(e),m(Ct.$$.fragment,e),Ei=c(e),qn=a(e,"P",{});var Pu=p(qn);Nd=r(Pu,"\u0E2B\u0E23\u0E37\u0E2D :"),Pu.forEach(t),ji=c(e),m(yt.$$.fragment,e),vi=c(e),Tn=a(e,"P",{});var wu=p(Tn);Fd=r(wu,"\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E40\u0E23\u0E32\u0E08\u0E30\u0E2A\u0E2D\u0E19\u0E27\u0E34\u0E18\u0E35\u0E2A\u0E23\u0E49\u0E32\u0E07 Unigram tokenizer \u0E1A\u0E49\u0E32\u0E07"),wu.forEach(t),bi=c(e),Te=a(e,"H2",{class:!0});var gp=p(Te);Ve=a(gp,"A",{id:!0,class:!0,href:!0});var qu=p(Ve);Ko=a(qu,"SPAN",{});var Tu=p(Ko);m(Ot.$$.fragment,Tu),Tu.forEach(t),qu.forEach(t),Ad=c(gp),Ho=a(gp,"SPAN",{});var Du=p(Ho);Wd=r(Du,"\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 Unigram tokenizer \u0E15\u0E31\u0E49\u0E07\u0E41\u0E15\u0E48\u0E40\u0E23\u0E34\u0E48\u0E21\u0E15\u0E49\u0E19"),Du.forEach(t),gp.forEach(t),xi=c(e),Ze=a(e,"P",{});var Pp=p(Ze);Ud=r(Pp,"\u0E40\u0E23\u0E32\u0E08\u0E30\u0E2A\u0E23\u0E49\u0E32\u0E07 XLNet tokenizer \u0E42\u0E14\u0E22\u0E40\u0E23\u0E34\u0E48\u0E21\u0E08\u0E32\u0E01 initialize "),Yo=a(Pp,"CODE",{});var Cu=p(Yo);Id=r(Cu,"Tokenizer"),Cu.forEach(t),Rd=r(Pp," \u0E14\u0E49\u0E27\u0E22 Unigram model !"),Pp.forEach(t),gi=c(e),m(Lt.$$.fragment,e),Pi=c(e),Dn=a(e,"P",{});var yu=p(Dn);Gd=r(yu,"\u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16 initialize \u0E21\u0E31\u0E19\u0E42\u0E14\u0E22\u0E2A\u0E48\u0E07\u0E1C\u0E48\u0E32\u0E19 vocabulary \u0E17\u0E35\u0E48\u0E21\u0E35\u0E2D\u0E22\u0E39\u0E48\u0E40\u0E02\u0E49\u0E32\u0E44\u0E1B\u0E14\u0E49\u0E27\u0E22"),yu.forEach(t),wi=c(e),Cn=a(e,"P",{});var Ou=p(Cn);Md=r(Ou,"\u0E43\u0E19\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19 normalization \u0E42\u0E21\u0E40\u0E14\u0E25 XLNet \u0E08\u0E30\u0E21\u0E35\u0E01\u0E32\u0E23\u0E41\u0E17\u0E19\u0E17\u0E35\u0E48\u0E15\u0E31\u0E27\u0E2D\u0E31\u0E01\u0E29\u0E23\u0E15\u0E48\u0E32\u0E07\u0E46 :"),Ou.forEach(t),qi=c(e),m(St.$$.fragment,e),Ti=c(e),M=a(e,"P",{});var ps=p(M);Xd=r(ps,"\u0E42\u0E04\u0E49\u0E14\u0E02\u0E49\u0E32\u0E07\u0E1A\u0E19\u0E19\u0E35\u0E49\u0E08\u0E30\u0E41\u0E17\u0E19\u0E17\u0E35\u0E48 "),Jo=a(ps,"CODE",{});var Lu=p(Jo);Kd=r(Lu,"\u201C"),Lu.forEach(t),Hd=r(ps," \u0E41\u0E25\u0E30 "),Vo=a(ps,"CODE",{});var Su=p(Vo);Yd=r(Su,"\u201D"),Su.forEach(t),Jd=r(ps," \u0E14\u0E49\u0E27\u0E22 "),Zo=a(ps,"CODE",{});var Bu=p(Zo);Vd=r(Bu,"\u201D"),Bu.forEach(t),Zd=r(ps,`
\u0E41\u0E25\u0E30\u0E16\u0E49\u0E32\u0E21\u0E35\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E17\u0E35\u0E48\u0E2D\u0E22\u0E39\u0E48\u0E15\u0E48\u0E2D\u0E46\u0E01\u0E31\u0E19 \u0E21\u0E31\u0E19\u0E08\u0E30\u0E16\u0E39\u0E01\u0E41\u0E1B\u0E25\u0E07\u0E43\u0E2B\u0E49\u0E40\u0E1B\u0E47\u0E19\u0E0A\u0E48\u0E2D\u0E07\u0E27\u0E48\u0E32\u0E07\u0E40\u0E14\u0E35\u0E22\u0E27 \u0E41\u0E25\u0E30\u0E2A\u0E38\u0E14\u0E17\u0E49\u0E32\u0E22\u0E21\u0E31\u0E19\u0E08\u0E30\u0E25\u0E1A\u0E2A\u0E31\u0E0D\u0E25\u0E31\u0E01\u0E29\u0E13\u0E4C accent \u0E2D\u0E2D\u0E01\u0E14\u0E49\u0E27\u0E22`),ps.forEach(t),Di=c(e),Qe=a(e,"P",{});var wp=p(Qe);Qd=r(wp,"pre-tokenizer \u0E17\u0E35\u0E48\u0E43\u0E0A\u0E49\u0E43\u0E19 SentencePiece tokenizer \u0E04\u0E37\u0E2D "),Qo=a(wp,"CODE",{});var Nu=p(Qo);e_=r(Nu,"Metaspace"),Nu.forEach(t),s_=r(wp,"  :"),wp.forEach(t),Ci=c(e),m(Bt.$$.fragment,e),yi=c(e),yn=a(e,"P",{});var Fu=p(yn);t_=r(Fu,"\u0E21\u0E32\u0E14\u0E39\u0E1C\u0E25\u0E25\u0E31\u0E1E\u0E18\u0E4C\u0E02\u0E2D\u0E07\u0E01\u0E32\u0E23 pre-tokenization \u0E01\u0E31\u0E1A\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E01\u0E31\u0E19  :"),Fu.forEach(t),Oi=c(e),m(Nt.$$.fragment,e),Li=c(e),m(Ft.$$.fragment,e),Si=c(e),On=a(e,"P",{});var Au=p(On);n_=r(Au,"\u0E02\u0E31\u0E49\u0E19\u0E15\u0E48\u0E2D\u0E44\u0E1B\u0E04\u0E37\u0E2D\u0E01\u0E32\u0E23\u0E40\u0E17\u0E23\u0E19  XLNet \u0E21\u0E35\u0E01\u0E32\u0E23\u0E43\u0E0A\u0E49 token \u0E1E\u0E34\u0E40\u0E28\u0E29\u0E2D\u0E22\u0E39\u0E48\u0E08\u0E33\u0E19\u0E27\u0E19\u0E2B\u0E19\u0E36\u0E48\u0E07 :"),Au.forEach(t),Bi=c(e),m(At.$$.fragment,e),Ni=c(e),y=a(e,"P",{});var je=p(y);r_=r(je,"\u0E2A\u0E34\u0E48\u0E07\u0E2A\u0E33\u0E04\u0E31\u0E0D\u0E40\u0E27\u0E25\u0E32\u0E43\u0E0A\u0E49 "),el=a(je,"CODE",{});var Wu=p(el);o_=r(Wu,"UnigramTrainer"),Wu.forEach(t),l_=r(je," \u0E04\u0E37\u0E2D \u0E2D\u0E22\u0E48\u0E32\u0E25\u0E37\u0E21\u0E01\u0E33\u0E2B\u0E19\u0E14 argument "),sl=a(je,"CODE",{});var Uu=p(sl);a_=r(Uu,"unk_token"),Uu.forEach(t),i_=r(je,`
\u0E19\u0E2D\u0E01\u0E08\u0E32\u0E01\u0E19\u0E31\u0E49\u0E19\u0E04\u0E38\u0E13\u0E22\u0E31\u0E07\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32 argument \u0E2D\u0E37\u0E48\u0E19\u0E46\u0E17\u0E35\u0E48\u0E15\u0E49\u0E2D\u0E07\u0E43\u0E0A\u0E49\u0E01\u0E31\u0E1A Unigram algorithm \u0E44\u0E14\u0E49\u0E14\u0E49\u0E27\u0E22 \u0E40\u0E0A\u0E48\u0E19 `),tl=a(je,"CODE",{});var Iu=p(tl);p_=r(Iu,"shrinking_factor"),Iu.forEach(t),f_=r(je," (\u0E04\u0E48\u0E32\u0E40\u0E23\u0E34\u0E48\u0E21\u0E15\u0E49\u0E19\u0E04\u0E37\u0E2D  0.75) \u0E2B\u0E23\u0E37\u0E2D "),nl=a(je,"CODE",{});var Ru=p(nl);c_=r(Ru,"max_piece_length"),Ru.forEach(t),k_=r(je," (\u0E04\u0E48\u0E32\u0E40\u0E23\u0E34\u0E48\u0E21\u0E15\u0E49\u0E19\u0E04\u0E37\u0E2D 16)"),je.forEach(t),Fi=c(e),Ln=a(e,"P",{});var Gu=p(Ln);m_=r(Gu,"\u0E40\u0E23\u0E32\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E40\u0E17\u0E23\u0E19\u0E08\u0E32\u0E01\u0E44\u0E1F\u0E25\u0E4C\u0E02\u0E49\u0E2D\u0E04\u0E27\u0E32\u0E21\u0E44\u0E14\u0E49\u0E14\u0E49\u0E27\u0E22  :"),Gu.forEach(t),Ai=c(e),m(Wt.$$.fragment,e),Wi=c(e),Sn=a(e,"P",{});var Mu=p(Sn);d_=r(Mu,"\u0E25\u0E2D\u0E07 tokenize \u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E07\u0E48\u0E32\u0E22\u0E46\u0E14\u0E39  :"),Mu.forEach(t),Ui=c(e),m(Ut.$$.fragment,e),Ii=c(e),m(It.$$.fragment,e),Ri=c(e),es=a(e,"P",{});var qp=p(es);__=r(qp,"XLNet \u0E08\u0E30\u0E40\u0E1E\u0E34\u0E48\u0E21 token \u0E1E\u0E34\u0E40\u0E28\u0E29 "),rl=a(qp,"CODE",{});var Xu=p(rl);$_=r(Xu,"<cls>"),Xu.forEach(t),u_=r(qp,` \u0E43\u0E2A\u0E48\u0E43\u0E19\u0E15\u0E2D\u0E19\u0E17\u0E49\u0E32\u0E22\u0E02\u0E2D\u0E07\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04 \u0E41\u0E25\u0E30\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32 type ID \u0E21\u0E31\u0E19\u0E40\u0E1B\u0E47\u0E19 2 \u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E43\u0E2B\u0E49\u0E21\u0E31\u0E19\u0E41\u0E15\u0E01\u0E15\u0E48\u0E32\u0E07\u0E08\u0E32\u0E01 token \u0E2D\u0E37\u0E48\u0E19
\u0E01\u0E32\u0E23\u0E17\u0E33\u0E41\u0E1A\u0E1A\u0E19\u0E35\u0E49\u0E16\u0E37\u0E2D\u0E27\u0E48\u0E32\u0E40\u0E1B\u0E47\u0E19\u0E01\u0E32\u0E23 padding \u0E17\u0E32\u0E07\u0E14\u0E49\u0E32\u0E22\u0E0B\u0E49\u0E32\u0E22`),qp.forEach(t),Gi=c(e),he=a(e,"P",{});var Xn=p(he);z_=r(Xn,"\u0E40\u0E1E\u0E37\u0E48\u0E2D\u0E08\u0E31\u0E14\u0E01\u0E32\u0E23\u0E01\u0E31\u0E1A token \u0E1E\u0E34\u0E40\u0E28\u0E29 \u0E40\u0E23\u0E32\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E2A\u0E23\u0E49\u0E32\u0E07 template \u0E02\u0E36\u0E49\u0E19\u0E21\u0E32 \u0E01\u0E48\u0E2D\u0E19\u0E2D\u0E37\u0E48\u0E19\u0E40\u0E23\u0E32\u0E15\u0E49\u0E2D\u0E07\u0E14\u0E39\u0E27\u0E48\u0E32 ID \u0E02\u0E2D\u0E07 "),ol=a(Xn,"CODE",{});var Ku=p(ol);h_=r(Ku,"<cls>"),Ku.forEach(t),E_=r(Xn," \u0E41\u0E25\u0E30 "),ll=a(Xn,"CODE",{});var Hu=p(ll);j_=r(Hu,"<sep>"),Hu.forEach(t),v_=r(Xn," \u0E04\u0E37\u0E2D\u0E2D\u0E30\u0E44\u0E23 :"),Xn.forEach(t),Mi=c(e),m(Rt.$$.fragment,e),Xi=c(e),m(Gt.$$.fragment,e),Ki=c(e),Bn=a(e,"P",{});var Yu=p(Bn);b_=r(Yu,"\u0E19\u0E35\u0E48\u0E04\u0E37\u0E2D\u0E15\u0E31\u0E27\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 template :"),Yu.forEach(t),Hi=c(e),m(Mt.$$.fragment,e),Yi=c(e),Nn=a(e,"P",{});var Ju=p(Nn);x_=r(Ju,"\u0E40\u0E23\u0E32\u0E08\u0E30\u0E17\u0E14\u0E25\u0E2D\u0E07\u0E43\u0E0A\u0E49\u0E07\u0E32\u0E19\u0E21\u0E31\u0E19\u0E42\u0E14\u0E22\u0E01\u0E32\u0E23 encode \u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04 input \u0E2A\u0E2D\u0E07\u0E1B\u0E23\u0E30\u0E42\u0E22\u0E04 :"),Ju.forEach(t),Ji=c(e),m(Xt.$$.fragment,e),Vi=c(e),m(Kt.$$.fragment,e),Zi=c(e),ss=a(e,"P",{});var Tp=p(ss);g_=r(Tp,"\u0E08\u0E32\u0E01\u0E19\u0E31\u0E49\u0E19\u0E15\u0E31\u0E49\u0E07\u0E04\u0E48\u0E32 decoder \u0E40\u0E1B\u0E47\u0E19 "),al=a(Tp,"CODE",{});var Vu=p(al);P_=r(Vu,"Metaspace"),Vu.forEach(t),w_=r(Tp," :"),Tp.forEach(t),Qi=c(e),m(Ht.$$.fragment,e),ep=c(e),Ee=a(e,"P",{});var Kn=p(Ee);q_=r(Kn,"\u0E15\u0E2D\u0E19\u0E19\u0E35\u0E49\u0E40\u0E23\u0E32\u0E01\u0E47\u0E40\u0E2A\u0E23\u0E47\u0E08\u0E41\u0E25\u0E49\u0E27 \u0E04\u0E38\u0E13\u0E2A\u0E32\u0E21\u0E32\u0E23\u0E16\u0E40\u0E0B\u0E1F tokenizer \u0E41\u0E25\u0E30 wrap \u0E21\u0E31\u0E19\u0E43\u0E2B\u0E49\u0E40\u0E1B\u0E47\u0E19 "),il=a(Kn,"CODE",{});var Zu=p(il);T_=r(Zu,"PreTrainedTokenizerFast"),Zu.forEach(t),D_=r(Kn," \u0E2B\u0E23\u0E37\u0E2D "),pl=a(Kn,"CODE",{});var Qu=p(pl);C_=r(Qu,"XLNetTokenizerFast"),Qu.forEach(t),y_=r(Kn," \u0E01\u0E47\u0E44\u0E14\u0E49 \u0E16\u0E49\u0E32\u0E04\u0E38\u0E13\u0E15\u0E49\u0E2D\u0E07\u0E01\u0E32\u0E23\u0E43\u0E0A\u0E49\u0E21\u0E31\u0E19\u0E43\u0E19 \u{1F917} Transformers"),Kn.forEach(t),sp=c(e),ts=a(e,"P",{});var Dp=p(ts);O_=r(Dp,"\u0E2A\u0E34\u0E48\u0E07\u0E2A\u0E33\u0E04\u0E31\u0E0D\u0E2D\u0E35\u0E01\u0E2D\u0E22\u0E48\u0E32\u0E07\u0E40\u0E27\u0E25\u0E32\u0E43\u0E0A\u0E49 "),fl=a(Dp,"CODE",{});var ez=p(fl);L_=r(ez,"PreTrainedTokenizerFast"),ez.forEach(t),S_=r(Dp," \u0E01\u0E47\u0E04\u0E37\u0E2D\u0E40\u0E23\u0E32\u0E08\u0E30\u0E15\u0E49\u0E2D\u0E07\u0E1A\u0E2D\u0E01 \u{1F917} Transformers library \u0E27\u0E48\u0E32\u0E40\u0E23\u0E32\u0E44\u0E14\u0E49\u0E17\u0E33\u0E01\u0E32\u0E23 padding \u0E17\u0E32\u0E07\u0E0B\u0E49\u0E32\u0E22 :"),Dp.forEach(t),tp=c(e),m(Yt.$$.fragment,e),np=c(e),Fn=a(e,"P",{});var sz=p(Fn);B_=r(sz,"\u0E2D\u0E35\u0E01\u0E27\u0E34\u0E18\u0E35\u0E01\u0E47\u0E04\u0E37\u0E2D :"),sz.forEach(t),rp=c(e),m(Jt.$$.fragment,e),op=c(e),An=a(e,"P",{});var tz=p(An);N_=r(tz,"\u0E15\u0E2D\u0E19\u0E19\u0E35\u0E49 \u0E04\u0E38\u0E13\u0E01\u0E47\u0E44\u0E14\u0E49\u0E40\u0E23\u0E35\u0E22\u0E19\u0E23\u0E39\u0E49\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19\u0E43\u0E19\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 tokenizer \u0E02\u0E36\u0E49\u0E19\u0E21\u0E32\u0E40\u0E2D\u0E07\u0E41\u0E25\u0E49\u0E27 \u0E42\u0E14\u0E22\u0E01\u0E32\u0E23\u0E43\u0E0A\u0E49\u0E40\u0E04\u0E23\u0E37\u0E48\u0E2D\u0E07\u0E21\u0E37\u0E2D\u0E08\u0E32\u0E01 \u{1F917} Tokenizers library \u0E41\u0E25\u0E30\u0E44\u0E14\u0E49\u0E40\u0E23\u0E35\u0E22\u0E19\u0E27\u0E34\u0E18\u0E35\u0E01\u0E32\u0E23\u0E19\u0E33 tokenizer \u0E02\u0E2D\u0E07\u0E04\u0E38\u0E13\u0E44\u0E1B\u0E43\u0E0A\u0E49\u0E43\u0E19 \u{1F917} Transformers \u0E2D\u0E35\u0E01\u0E14\u0E49\u0E27\u0E22"),tz.forEach(t),this.h()},h(){h(E,"name","hf:doc:metadata"),h(E,"content",JSON.stringify(dz)),h(F,"id","tokenizer"),h(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(F,"href","#tokenizer"),h(L,"class","relative group"),h(le,"class","block dark:hidden"),nz(le.src,Hn="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter6/tokenization_pipeline.svg")||h(le,"src",Hn),h(le,"alt","The tokenization pipeline."),h(ae,"class","hidden dark:block"),nz(ae.src,Yn="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter6/tokenization_pipeline-dark.svg")||h(ae,"src",Yn),h(ae,"alt","The tokenization pipeline."),h(A,"class","flex justify-center"),h(on,"href","/course/chapter6/2"),h(vs,"href","https://huggingface.co/docs/tokenizers/python/latest/api/reference.html#module-tokenizers.normalizers"),h(vs,"rel","nofollow"),h(bs,"href","https://huggingface.co/docs/tokenizers/python/latest/api/reference.html#module-tokenizers.pre_tokenizers"),h(bs,"rel","nofollow"),h(xs,"href","https://huggingface.co/docs/tokenizers/python/latest/api/reference.html#module-tokenizers.models"),h(xs,"rel","nofollow"),h(gs,"href","https://huggingface.co/docs/tokenizers/python/latest/api/reference.html#module-tokenizers.trainers"),h(gs,"rel","nofollow"),h(Ps,"href","https://huggingface.co/docs/tokenizers/python/latest/api/reference.html#module-tokenizers.processors"),h(Ps,"rel","nofollow"),h(ws,"href","https://huggingface.co/docs/tokenizers/python/latest/components.html#decoders"),h(ws,"rel","nofollow"),h(Ts,"href","https://huggingface.co/docs/tokenizers/python/latest/components.html"),h(Ts,"rel","nofollow"),h(Se,"id","corpus"),h(Se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Se,"href","#corpus"),h(be,"class","relative group"),h(ln,"href","/course/chapter6/2"),h(Cs,"href","https://huggingface.co/datasets/wikitext"),h(Cs,"rel","nofollow"),h(Be,"id","wordpiece-tokenizer"),h(Be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Be,"href","#wordpiece-tokenizer"),h(ge,"class","relative group"),h(He,"id","bpe-tokenizer"),h(He,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(He,"href","#bpe-tokenizer"),h(we,"class","relative group"),h(Ve,"id","unigram-tokenizer"),h(Ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Ve,"href","#unigram-tokenizer"),h(Te,"class","relative group")},m(e,o){s(document.head,E),i(e,ne,o),i(e,L,o),s(L,F),s(F,J),d(V,J,null),s(L,fs),s(L,Z),s(Z,cs),i(e,De,o),d(S,e,o),i(e,Ce,o),i(e,re,o),s(re,ve),i(e,ye,o),i(e,P,o),s(P,Q),s(Q,ks),s(P,ms),s(P,ee),s(ee,ds),s(P,_s),s(P,se),s(se,$s),s(P,us),s(P,te),s(te,zs),i(e,oe,o),i(e,j,o),s(j,nn),i(e,hs,o),i(e,A,o),s(A,le),s(A,rn),s(A,ae),i(e,Es,o),i(e,Oe,o),s(Oe,Cp),s(Oe,on),s(on,yp),s(Oe,Op),i(e,$l,o),d(js,e,o),i(e,ul,o),i(e,Le,o),s(Le,Lp),s(Le,Jn),s(Jn,Sp),s(Le,Bp),i(e,zl,o),i(e,w,o),s(w,ie),s(ie,Vn),s(Vn,Np),s(ie,Fp),s(ie,Zn),s(Zn,Ap),s(ie,Wp),s(ie,vs),s(vs,Up),s(ie,Ip),s(w,Rp),s(w,pe),s(pe,Qn),s(Qn,Gp),s(pe,Mp),s(pe,er),s(er,Xp),s(pe,Kp),s(pe,bs),s(bs,Hp),s(pe,Yp),s(w,Jp),s(w,q),s(q,sr),s(sr,Vp),s(q,Zp),s(q,tr),s(tr,Qp),s(q,ef),s(q,nr),s(nr,sf),s(q,tf),s(q,rr),s(rr,nf),s(q,rf),s(q,or),s(or,of),s(q,lf),s(q,xs),s(xs,af),s(q,pf),s(w,ff),s(w,fe),s(fe,lr),s(lr,cf),s(fe,kf),s(fe,ar),s(ar,mf),s(fe,df),s(fe,gs),s(gs,_f),s(fe,$f),s(w,uf),s(w,ce),s(ce,ir),s(ir,zf),s(ce,hf),s(ce,pr),s(pr,Ef),s(ce,jf),s(ce,Ps),s(Ps,vf),s(ce,bf),s(w,xf),s(w,ke),s(ke,fr),s(fr,gf),s(ke,Pf),s(ke,cr),s(cr,wf),s(ke,qf),s(ke,ws),s(ws,Tf),s(ke,Df),i(e,hl,o),i(e,qs,o),s(qs,Cf),s(qs,Ts),s(Ts,yf),i(e,El,o),i(e,be,o),s(be,Se),s(Se,kr),d(Ds,kr,null),s(be,Of),s(be,mr),s(mr,Lf),i(e,jl,o),i(e,xe,o),s(xe,Sf),s(xe,ln),s(ln,Bf),s(xe,Nf),s(xe,Cs),s(Cs,Ff),i(e,vl,o),d(ys,e,o),i(e,bl,o),i(e,Os,o),s(Os,dr),s(dr,Af),s(Os,Wf),i(e,xl,o),d(Ls,e,o),i(e,gl,o),i(e,an,o),s(an,Uf),i(e,Pl,o),i(e,ge,o),s(ge,Be),s(Be,_r),d(Ss,_r,null),s(ge,If),s(ge,$r),s($r,Rf),i(e,wl,o),i(e,b,o),s(b,Gf),s(b,ur),s(ur,Mf),s(b,Xf),s(b,zr),s(zr,Kf),s(b,Hf),s(b,hr),s(hr,Yf),s(b,Jf),s(b,Er),s(Er,Vf),s(b,Zf),s(b,jr),s(jr,Qf),s(b,ec),s(b,vr),s(vr,sc),s(b,tc),i(e,ql,o),i(e,Ne,o),s(Ne,nc),s(Ne,br),s(br,rc),s(Ne,oc),i(e,Tl,o),d(Bs,e,o),i(e,Dl,o),i(e,W,o),s(W,lc),s(W,xr),s(xr,ac),s(W,ic),s(W,gr),s(gr,pc),s(W,fc),s(W,Pr),s(Pr,cc),s(W,kc),i(e,Cl,o),i(e,T,o),s(T,mc),s(T,wr),s(wr,dc),s(T,_c),s(T,qr),s(qr,$c),s(T,uc),s(T,Tr),s(Tr,zc),s(T,hc),s(T,Dr),s(Dr,Ec),s(T,jc),s(T,Cr),s(Cr,vc),s(T,bc),i(e,yl,o),i(e,Fe,o),s(Fe,xc),s(Fe,yr),s(yr,gc),s(Fe,Pc),i(e,Ol,o),d(Ns,e,o),i(e,Ll,o),i(e,pn,o),s(pn,wc),i(e,Sl,o),i(e,U,o),s(U,qc),s(U,Or),s(Or,Tc),s(U,Dc),s(U,Lr),s(Lr,Cc),s(U,yc),s(U,Sr),s(Sr,Oc),s(U,Lc),i(e,Bl,o),d(Fs,e,o),i(e,Nl,o),i(e,me,o),s(me,Sc),s(me,Br),s(Br,Bc),s(me,Nc),s(me,Nr),s(Nr,Fc),s(me,Ac),i(e,Fl,o),i(e,de,o),s(de,Wc),s(de,Fr),s(Fr,Uc),s(de,Ic),s(de,Ar),s(Ar,Rc),s(de,Gc),i(e,Al,o),d(As,e,o),i(e,Wl,o),d(Ws,e,o),i(e,Ul,o),d(Ae,e,o),i(e,Il,o),i(e,We,o),s(We,Mc),s(We,Wr),s(Wr,Xc),s(We,Kc),i(e,Rl,o),d(Us,e,o),i(e,Gl,o),i(e,fn,o),s(fn,Hc),i(e,Ml,o),d(Is,e,o),i(e,Xl,o),i(e,Ue,o),s(Ue,Yc),s(Ue,Ur),s(Ur,Jc),s(Ue,Vc),i(e,Kl,o),d(Rs,e,o),i(e,Hl,o),d(Gs,e,o),i(e,Yl,o),i(e,Ie,o),s(Ie,Zc),s(Ie,Ir),s(Ir,Qc),s(Ie,ek),i(e,Jl,o),d(Ms,e,o),i(e,Vl,o),d(Xs,e,o),i(e,Zl,o),i(e,Re,o),s(Re,sk),s(Re,Rr),s(Rr,tk),s(Re,nk),i(e,Ql,o),d(Ks,e,o),i(e,ea,o),d(Hs,e,o),i(e,sa,o),i(e,Ys,o),s(Ys,rk),s(Ys,Gr),s(Gr,ok),i(e,ta,o),i(e,cn,o),s(cn,lk),i(e,na,o),d(Js,e,o),i(e,ra,o),i(e,D,o),s(D,ak),s(D,Mr),s(Mr,ik),s(D,pk),s(D,Xr),s(Xr,fk),s(D,ck),s(D,Kr),s(Kr,kk),s(D,mk),s(D,Hr),s(Hr,dk),s(D,_k),s(D,Yr),s(Yr,$k),s(D,uk),i(e,oa,o),i(e,kn,o),s(kn,zk),i(e,la,o),d(Vs,e,o),i(e,aa,o),i(e,Ge,o),s(Ge,hk),s(Ge,Jr),s(Jr,Ek),s(Ge,jk),i(e,ia,o),d(Zs,e,o),i(e,pa,o),i(e,Me,o),s(Me,vk),s(Me,Vr),s(Vr,bk),s(Me,xk),i(e,fa,o),d(Qs,e,o),i(e,ca,o),d(et,e,o),i(e,ka,o),i(e,v,o),s(v,Zr),s(Zr,gk),s(v,Pk),s(v,Qr),s(Qr,wk),s(v,qk),s(v,eo),s(eo,Tk),s(v,Dk),s(v,so),s(so,Ck),s(v,yk),s(v,to),s(to,Ok),s(v,Lk),s(v,no),s(no,Sk),s(v,Bk),s(v,ro),s(ro,Nk),s(v,Fk),s(v,oo),s(oo,Ak),s(v,Wk),s(v,lo),s(lo,Uk),i(e,ma,o),i(e,_e,o),s(_e,Ik),s(_e,ao),s(ao,Rk),s(_e,Gk),s(_e,io),s(io,Mk),s(_e,Xk),i(e,da,o),i(e,I,o),s(I,Kk),s(I,po),s(po,Hk),s(I,Yk),s(I,fo),s(fo,Jk),s(I,Vk),s(I,co),s(co,Zk),s(I,Qk),i(e,_a,o),d(st,e,o),i(e,$a,o),d(tt,e,o),i(e,ua,o),i(e,R,o),s(R,em),s(R,ko),s(ko,sm),s(R,tm),s(R,mo),s(mo,nm),s(R,rm),s(R,_o),s(_o,om),s(R,lm),i(e,za,o),i(e,mn,o),s(mn,am),i(e,ha,o),d(nt,e,o),i(e,Ea,o),i(e,dn,o),s(dn,im),i(e,ja,o),i(e,_n,o),s(_n,pm),i(e,va,o),d(rt,e,o),i(e,ba,o),d(ot,e,o),i(e,xa,o),i(e,$n,o),s($n,fm),i(e,ga,o),d(lt,e,o),i(e,Pa,o),d(at,e,o),i(e,wa,o),i(e,un,o),s(un,cm),i(e,qa,o),d(it,e,o),i(e,Ta,o),i(e,Xe,o),s(Xe,km),s(Xe,$o),s($o,mm),s(Xe,dm),i(e,Da,o),d(pt,e,o),i(e,Ca,o),d(ft,e,o),i(e,ya,o),i(e,zn,o),s(zn,_m),i(e,Oa,o),d(ct,e,o),i(e,La,o),i(e,$e,o),s($e,$m),s($e,uo),s(uo,um),s($e,zm),s($e,zo),s(zo,hm),s($e,Em),i(e,Sa,o),d(kt,e,o),i(e,Ba,o),i(e,ue,o),s(ue,jm),s(ue,ho),s(ho,vm),s(ue,bm),s(ue,Eo),s(Eo,xm),s(ue,gm),i(e,Na,o),i(e,C,o),s(C,Pm),s(C,jo),s(jo,wm),s(C,qm),s(C,vo),s(vo,Tm),s(C,Dm),s(C,bo),s(bo,Cm),s(C,ym),s(C,xo),s(xo,Om),s(C,Lm),s(C,go),s(go,Sm),s(C,Bm),i(e,Fa,o),d(mt,e,o),i(e,Aa,o),i(e,Ke,o),s(Ke,Nm),s(Ke,Po),s(Po,Fm),s(Ke,Am),i(e,Wa,o),d(dt,e,o),i(e,Ua,o),i(e,Pe,o),s(Pe,Wm),s(Pe,wo),s(wo,Um),s(Pe,Im),s(Pe,qo),s(qo,Rm),i(e,Ia,o),i(e,hn,o),s(hn,Gm),i(e,Ra,o),i(e,we,o),s(we,He),s(He,To),d(_t,To,null),s(we,Mm),s(we,Do),s(Do,Xm),i(e,Ga,o),i(e,Ye,o),s(Ye,Km),s(Ye,Co),s(Co,Hm),s(Ye,Ym),i(e,Ma,o),d($t,e,o),i(e,Xa,o),i(e,G,o),s(G,Jm),s(G,yo),s(yo,Vm),s(G,Zm),s(G,Oo),s(Oo,Qm),s(G,ed),s(G,Lo),s(Lo,sd),s(G,td),i(e,Ka,o),i(e,En,o),s(En,nd),i(e,Ha,o),d(ut,e,o),i(e,Ya,o),i(e,zt,o),s(zt,So),s(So,rd),s(zt,od),i(e,Ja,o),i(e,jn,o),s(jn,ld),i(e,Va,o),d(ht,e,o),i(e,Za,o),d(Et,e,o),i(e,Qa,o),i(e,vn,o),s(vn,ad),i(e,ei,o),d(jt,e,o),i(e,si,o),i(e,g,o),s(g,id),s(g,Bo),s(Bo,pd),s(g,fd),s(g,No),s(No,cd),s(g,kd),s(g,Fo),s(Fo,md),s(g,dd),s(g,Ao),s(Ao,_d),s(g,$d),s(g,Wo),s(Wo,ud),s(g,zd),s(g,Uo),s(Uo,hd),i(e,ti,o),i(e,bn,o),s(bn,Ed),i(e,ni,o),d(vt,e,o),i(e,ri,o),i(e,xn,o),s(xn,jd),i(e,oi,o),d(bt,e,o),i(e,li,o),d(xt,e,o),i(e,ai,o),i(e,gn,o),s(gn,vd),i(e,ii,o),d(gt,e,o),i(e,pi,o),i(e,qe,o),s(qe,Io),s(Io,bd),s(qe,xd),s(qe,Ro),s(Ro,gd),s(qe,Pd),i(e,fi,o),i(e,Je,o),s(Je,wd),s(Je,Go),s(Go,qd),s(Je,Td),i(e,ci,o),d(Pt,e,o),i(e,ki,o),d(wt,e,o),i(e,mi,o),i(e,Pn,o),s(Pn,Dd),i(e,di,o),d(qt,e,o),i(e,_i,o),i(e,wn,o),s(wn,Cd),i(e,$i,o),d(Tt,e,o),i(e,ui,o),d(Dt,e,o),i(e,zi,o),i(e,ze,o),s(ze,yd),s(ze,Mo),s(Mo,Od),s(ze,Ld),s(ze,Xo),s(Xo,Sd),s(ze,Bd),i(e,hi,o),d(Ct,e,o),i(e,Ei,o),i(e,qn,o),s(qn,Nd),i(e,ji,o),d(yt,e,o),i(e,vi,o),i(e,Tn,o),s(Tn,Fd),i(e,bi,o),i(e,Te,o),s(Te,Ve),s(Ve,Ko),d(Ot,Ko,null),s(Te,Ad),s(Te,Ho),s(Ho,Wd),i(e,xi,o),i(e,Ze,o),s(Ze,Ud),s(Ze,Yo),s(Yo,Id),s(Ze,Rd),i(e,gi,o),d(Lt,e,o),i(e,Pi,o),i(e,Dn,o),s(Dn,Gd),i(e,wi,o),i(e,Cn,o),s(Cn,Md),i(e,qi,o),d(St,e,o),i(e,Ti,o),i(e,M,o),s(M,Xd),s(M,Jo),s(Jo,Kd),s(M,Hd),s(M,Vo),s(Vo,Yd),s(M,Jd),s(M,Zo),s(Zo,Vd),s(M,Zd),i(e,Di,o),i(e,Qe,o),s(Qe,Qd),s(Qe,Qo),s(Qo,e_),s(Qe,s_),i(e,Ci,o),d(Bt,e,o),i(e,yi,o),i(e,yn,o),s(yn,t_),i(e,Oi,o),d(Nt,e,o),i(e,Li,o),d(Ft,e,o),i(e,Si,o),i(e,On,o),s(On,n_),i(e,Bi,o),d(At,e,o),i(e,Ni,o),i(e,y,o),s(y,r_),s(y,el),s(el,o_),s(y,l_),s(y,sl),s(sl,a_),s(y,i_),s(y,tl),s(tl,p_),s(y,f_),s(y,nl),s(nl,c_),s(y,k_),i(e,Fi,o),i(e,Ln,o),s(Ln,m_),i(e,Ai,o),d(Wt,e,o),i(e,Wi,o),i(e,Sn,o),s(Sn,d_),i(e,Ui,o),d(Ut,e,o),i(e,Ii,o),d(It,e,o),i(e,Ri,o),i(e,es,o),s(es,__),s(es,rl),s(rl,$_),s(es,u_),i(e,Gi,o),i(e,he,o),s(he,z_),s(he,ol),s(ol,h_),s(he,E_),s(he,ll),s(ll,j_),s(he,v_),i(e,Mi,o),d(Rt,e,o),i(e,Xi,o),d(Gt,e,o),i(e,Ki,o),i(e,Bn,o),s(Bn,b_),i(e,Hi,o),d(Mt,e,o),i(e,Yi,o),i(e,Nn,o),s(Nn,x_),i(e,Ji,o),d(Xt,e,o),i(e,Vi,o),d(Kt,e,o),i(e,Zi,o),i(e,ss,o),s(ss,g_),s(ss,al),s(al,P_),s(ss,w_),i(e,Qi,o),d(Ht,e,o),i(e,ep,o),i(e,Ee,o),s(Ee,q_),s(Ee,il),s(il,T_),s(Ee,D_),s(Ee,pl),s(pl,C_),s(Ee,y_),i(e,sp,o),i(e,ts,o),s(ts,O_),s(ts,fl),s(fl,L_),s(ts,S_),i(e,tp,o),d(Yt,e,o),i(e,np,o),i(e,Fn,o),s(Fn,B_),i(e,rp,o),d(Jt,e,o),i(e,op,o),i(e,An,o),s(An,N_),lp=!0},p(e,[o]){const Vt={};o&2&&(Vt.$$scope={dirty:o,ctx:e}),Ae.$set(Vt)},i(e){lp||(_(V.$$.fragment,e),_(S.$$.fragment,e),_(js.$$.fragment,e),_(Ds.$$.fragment,e),_(ys.$$.fragment,e),_(Ls.$$.fragment,e),_(Ss.$$.fragment,e),_(Bs.$$.fragment,e),_(Ns.$$.fragment,e),_(Fs.$$.fragment,e),_(As.$$.fragment,e),_(Ws.$$.fragment,e),_(Ae.$$.fragment,e),_(Us.$$.fragment,e),_(Is.$$.fragment,e),_(Rs.$$.fragment,e),_(Gs.$$.fragment,e),_(Ms.$$.fragment,e),_(Xs.$$.fragment,e),_(Ks.$$.fragment,e),_(Hs.$$.fragment,e),_(Js.$$.fragment,e),_(Vs.$$.fragment,e),_(Zs.$$.fragment,e),_(Qs.$$.fragment,e),_(et.$$.fragment,e),_(st.$$.fragment,e),_(tt.$$.fragment,e),_(nt.$$.fragment,e),_(rt.$$.fragment,e),_(ot.$$.fragment,e),_(lt.$$.fragment,e),_(at.$$.fragment,e),_(it.$$.fragment,e),_(pt.$$.fragment,e),_(ft.$$.fragment,e),_(ct.$$.fragment,e),_(kt.$$.fragment,e),_(mt.$$.fragment,e),_(dt.$$.fragment,e),_(_t.$$.fragment,e),_($t.$$.fragment,e),_(ut.$$.fragment,e),_(ht.$$.fragment,e),_(Et.$$.fragment,e),_(jt.$$.fragment,e),_(vt.$$.fragment,e),_(bt.$$.fragment,e),_(xt.$$.fragment,e),_(gt.$$.fragment,e),_(Pt.$$.fragment,e),_(wt.$$.fragment,e),_(qt.$$.fragment,e),_(Tt.$$.fragment,e),_(Dt.$$.fragment,e),_(Ct.$$.fragment,e),_(yt.$$.fragment,e),_(Ot.$$.fragment,e),_(Lt.$$.fragment,e),_(St.$$.fragment,e),_(Bt.$$.fragment,e),_(Nt.$$.fragment,e),_(Ft.$$.fragment,e),_(At.$$.fragment,e),_(Wt.$$.fragment,e),_(Ut.$$.fragment,e),_(It.$$.fragment,e),_(Rt.$$.fragment,e),_(Gt.$$.fragment,e),_(Mt.$$.fragment,e),_(Xt.$$.fragment,e),_(Kt.$$.fragment,e),_(Ht.$$.fragment,e),_(Yt.$$.fragment,e),_(Jt.$$.fragment,e),lp=!0)},o(e){$(V.$$.fragment,e),$(S.$$.fragment,e),$(js.$$.fragment,e),$(Ds.$$.fragment,e),$(ys.$$.fragment,e),$(Ls.$$.fragment,e),$(Ss.$$.fragment,e),$(Bs.$$.fragment,e),$(Ns.$$.fragment,e),$(Fs.$$.fragment,e),$(As.$$.fragment,e),$(Ws.$$.fragment,e),$(Ae.$$.fragment,e),$(Us.$$.fragment,e),$(Is.$$.fragment,e),$(Rs.$$.fragment,e),$(Gs.$$.fragment,e),$(Ms.$$.fragment,e),$(Xs.$$.fragment,e),$(Ks.$$.fragment,e),$(Hs.$$.fragment,e),$(Js.$$.fragment,e),$(Vs.$$.fragment,e),$(Zs.$$.fragment,e),$(Qs.$$.fragment,e),$(et.$$.fragment,e),$(st.$$.fragment,e),$(tt.$$.fragment,e),$(nt.$$.fragment,e),$(rt.$$.fragment,e),$(ot.$$.fragment,e),$(lt.$$.fragment,e),$(at.$$.fragment,e),$(it.$$.fragment,e),$(pt.$$.fragment,e),$(ft.$$.fragment,e),$(ct.$$.fragment,e),$(kt.$$.fragment,e),$(mt.$$.fragment,e),$(dt.$$.fragment,e),$(_t.$$.fragment,e),$($t.$$.fragment,e),$(ut.$$.fragment,e),$(ht.$$.fragment,e),$(Et.$$.fragment,e),$(jt.$$.fragment,e),$(vt.$$.fragment,e),$(bt.$$.fragment,e),$(xt.$$.fragment,e),$(gt.$$.fragment,e),$(Pt.$$.fragment,e),$(wt.$$.fragment,e),$(qt.$$.fragment,e),$(Tt.$$.fragment,e),$(Dt.$$.fragment,e),$(Ct.$$.fragment,e),$(yt.$$.fragment,e),$(Ot.$$.fragment,e),$(Lt.$$.fragment,e),$(St.$$.fragment,e),$(Bt.$$.fragment,e),$(Nt.$$.fragment,e),$(Ft.$$.fragment,e),$(At.$$.fragment,e),$(Wt.$$.fragment,e),$(Ut.$$.fragment,e),$(It.$$.fragment,e),$(Rt.$$.fragment,e),$(Gt.$$.fragment,e),$(Mt.$$.fragment,e),$(Xt.$$.fragment,e),$(Kt.$$.fragment,e),$(Ht.$$.fragment,e),$(Yt.$$.fragment,e),$(Jt.$$.fragment,e),lp=!1},d(e){t(E),e&&t(ne),e&&t(L),u(V),e&&t(De),u(S,e),e&&t(Ce),e&&t(re),e&&t(ye),e&&t(P),e&&t(oe),e&&t(j),e&&t(hs),e&&t(A),e&&t(Es),e&&t(Oe),e&&t($l),u(js,e),e&&t(ul),e&&t(Le),e&&t(zl),e&&t(w),e&&t(hl),e&&t(qs),e&&t(El),e&&t(be),u(Ds),e&&t(jl),e&&t(xe),e&&t(vl),u(ys,e),e&&t(bl),e&&t(Os),e&&t(xl),u(Ls,e),e&&t(gl),e&&t(an),e&&t(Pl),e&&t(ge),u(Ss),e&&t(wl),e&&t(b),e&&t(ql),e&&t(Ne),e&&t(Tl),u(Bs,e),e&&t(Dl),e&&t(W),e&&t(Cl),e&&t(T),e&&t(yl),e&&t(Fe),e&&t(Ol),u(Ns,e),e&&t(Ll),e&&t(pn),e&&t(Sl),e&&t(U),e&&t(Bl),u(Fs,e),e&&t(Nl),e&&t(me),e&&t(Fl),e&&t(de),e&&t(Al),u(As,e),e&&t(Wl),u(Ws,e),e&&t(Ul),u(Ae,e),e&&t(Il),e&&t(We),e&&t(Rl),u(Us,e),e&&t(Gl),e&&t(fn),e&&t(Ml),u(Is,e),e&&t(Xl),e&&t(Ue),e&&t(Kl),u(Rs,e),e&&t(Hl),u(Gs,e),e&&t(Yl),e&&t(Ie),e&&t(Jl),u(Ms,e),e&&t(Vl),u(Xs,e),e&&t(Zl),e&&t(Re),e&&t(Ql),u(Ks,e),e&&t(ea),u(Hs,e),e&&t(sa),e&&t(Ys),e&&t(ta),e&&t(cn),e&&t(na),u(Js,e),e&&t(ra),e&&t(D),e&&t(oa),e&&t(kn),e&&t(la),u(Vs,e),e&&t(aa),e&&t(Ge),e&&t(ia),u(Zs,e),e&&t(pa),e&&t(Me),e&&t(fa),u(Qs,e),e&&t(ca),u(et,e),e&&t(ka),e&&t(v),e&&t(ma),e&&t(_e),e&&t(da),e&&t(I),e&&t(_a),u(st,e),e&&t($a),u(tt,e),e&&t(ua),e&&t(R),e&&t(za),e&&t(mn),e&&t(ha),u(nt,e),e&&t(Ea),e&&t(dn),e&&t(ja),e&&t(_n),e&&t(va),u(rt,e),e&&t(ba),u(ot,e),e&&t(xa),e&&t($n),e&&t(ga),u(lt,e),e&&t(Pa),u(at,e),e&&t(wa),e&&t(un),e&&t(qa),u(it,e),e&&t(Ta),e&&t(Xe),e&&t(Da),u(pt,e),e&&t(Ca),u(ft,e),e&&t(ya),e&&t(zn),e&&t(Oa),u(ct,e),e&&t(La),e&&t($e),e&&t(Sa),u(kt,e),e&&t(Ba),e&&t(ue),e&&t(Na),e&&t(C),e&&t(Fa),u(mt,e),e&&t(Aa),e&&t(Ke),e&&t(Wa),u(dt,e),e&&t(Ua),e&&t(Pe),e&&t(Ia),e&&t(hn),e&&t(Ra),e&&t(we),u(_t),e&&t(Ga),e&&t(Ye),e&&t(Ma),u($t,e),e&&t(Xa),e&&t(G),e&&t(Ka),e&&t(En),e&&t(Ha),u(ut,e),e&&t(Ya),e&&t(zt),e&&t(Ja),e&&t(jn),e&&t(Va),u(ht,e),e&&t(Za),u(Et,e),e&&t(Qa),e&&t(vn),e&&t(ei),u(jt,e),e&&t(si),e&&t(g),e&&t(ti),e&&t(bn),e&&t(ni),u(vt,e),e&&t(ri),e&&t(xn),e&&t(oi),u(bt,e),e&&t(li),u(xt,e),e&&t(ai),e&&t(gn),e&&t(ii),u(gt,e),e&&t(pi),e&&t(qe),e&&t(fi),e&&t(Je),e&&t(ci),u(Pt,e),e&&t(ki),u(wt,e),e&&t(mi),e&&t(Pn),e&&t(di),u(qt,e),e&&t(_i),e&&t(wn),e&&t($i),u(Tt,e),e&&t(ui),u(Dt,e),e&&t(zi),e&&t(ze),e&&t(hi),u(Ct,e),e&&t(Ei),e&&t(qn),e&&t(ji),u(yt,e),e&&t(vi),e&&t(Tn),e&&t(bi),e&&t(Te),u(Ot),e&&t(xi),e&&t(Ze),e&&t(gi),u(Lt,e),e&&t(Pi),e&&t(Dn),e&&t(wi),e&&t(Cn),e&&t(qi),u(St,e),e&&t(Ti),e&&t(M),e&&t(Di),e&&t(Qe),e&&t(Ci),u(Bt,e),e&&t(yi),e&&t(yn),e&&t(Oi),u(Nt,e),e&&t(Li),u(Ft,e),e&&t(Si),e&&t(On),e&&t(Bi),u(At,e),e&&t(Ni),e&&t(y),e&&t(Fi),e&&t(Ln),e&&t(Ai),u(Wt,e),e&&t(Wi),e&&t(Sn),e&&t(Ui),u(Ut,e),e&&t(Ii),u(It,e),e&&t(Ri),e&&t(es),e&&t(Gi),e&&t(he),e&&t(Mi),u(Rt,e),e&&t(Xi),u(Gt,e),e&&t(Ki),e&&t(Bn),e&&t(Hi),u(Mt,e),e&&t(Yi),e&&t(Nn),e&&t(Ji),u(Xt,e),e&&t(Vi),u(Kt,e),e&&t(Zi),e&&t(ss),e&&t(Qi),u(Ht,e),e&&t(ep),e&&t(Ee),e&&t(sp),e&&t(ts),e&&t(tp),u(Yt,e),e&&t(np),e&&t(Fn),e&&t(rp),u(Jt,e),e&&t(op),e&&t(An)}}}const dz={local:"tokenizer",sections:[{local:"corpus",title:"\u0E01\u0E32\u0E23\u0E42\u0E2B\u0E25\u0E14 corpus"},{local:"wordpiece-tokenizer",title:"\u0E2A\u0E23\u0E49\u0E32\u0E07 WordPiece tokenizer \u0E15\u0E31\u0E49\u0E07\u0E41\u0E15\u0E48\u0E40\u0E23\u0E34\u0E48\u0E21\u0E15\u0E49\u0E19"},{local:"bpe-tokenizer",title:"\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 BPE tokenizer \u0E15\u0E31\u0E49\u0E07\u0E41\u0E15\u0E48\u0E40\u0E23\u0E34\u0E48\u0E21\u0E15\u0E49\u0E19"},{local:"unigram-tokenizer",title:"\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 Unigram tokenizer \u0E15\u0E31\u0E49\u0E07\u0E41\u0E15\u0E48\u0E40\u0E23\u0E34\u0E48\u0E21\u0E15\u0E49\u0E19"}],title:"\u0E01\u0E32\u0E23\u0E2A\u0E23\u0E49\u0E32\u0E07 tokenizer \u0E17\u0E35\u0E25\u0E30\u0E02\u0E31\u0E49\u0E19\u0E15\u0E2D\u0E19"};function _z(_l){return iz(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class vz extends rz{constructor(E){super();oz(this,E,_z,mz,lz,{})}}export{vz as default,dz as metadata};
