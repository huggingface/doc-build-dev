import{S as Ns,i as Hs,s as Rs,e as a,k as u,w as g,t as r,M as Zs,c as s,d as t,m as c,x as w,a as l,h as i,b as p,G as n,g as o,y as v,q as b,o as _,B as k,v as Js}from"../../chunks/vendor-hf-doc-builder.js";import{D as Ys,Y as Xs,T as Ls}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{I as Aa}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as S}from"../../chunks/CodeBlock-hf-doc-builder.js";import{F as Qs}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function el(ge){let f,j,m,P,D,E,T,F,I,Q,we;return{c(){f=a("p"),j=r("\u{1F4A1} Wenn du dein Modell w\xE4hrend des Trainings automatisch in das Hub hochladen m\xF6chtest, kann in "),m=a("code"),P=r("TrainingArguments"),D=r(" das Argument "),E=a("code"),T=r("push_to_hub=True"),F=r(" angegeben werden. Dar\xFCber erfahren wir in "),I=a("a"),Q=r("Kapitel 4"),we=r(" mehr."),this.h()},l(L){f=s(L,"P",{});var $=l(f);j=i($,"\u{1F4A1} Wenn du dein Modell w\xE4hrend des Trainings automatisch in das Hub hochladen m\xF6chtest, kann in "),m=s($,"CODE",{});var ve=l(m);P=i(ve,"TrainingArguments"),ve.forEach(t),D=i($," das Argument "),E=s($,"CODE",{});var N=l(E);T=i(N,"push_to_hub=True"),N.forEach(t),F=i($," angegeben werden. Dar\xFCber erfahren wir in "),I=s($,"A",{href:!0});var be=l(I);Q=i(be,"Kapitel 4"),be.forEach(t),we=i($," mehr."),$.forEach(t),this.h()},h(){p(I,"href","/course/chapter4/3")},m(L,$){o(L,f,$),n(f,j),n(f,m),n(m,P),n(f,D),n(f,E),n(E,T),n(f,F),n(f,I),n(I,Q),n(f,we)},d(L){L&&t(f)}}}function nl(ge){let f,j,m,P,D;return{c(){f=a("p"),j=r("\u270F\uFE0F "),m=a("strong"),P=r("Probier es aus!"),D=r(" Fein-tune ein Modell mit dem GLUE SST-2 Datensatz, indem du die Datenverarbeitung aus Abschnitt 2 verwendest.")},l(E){f=s(E,"P",{});var T=l(f);j=i(T,"\u270F\uFE0F "),m=s(T,"STRONG",{});var F=l(m);P=i(F,"Probier es aus!"),F.forEach(t),D=i(T," Fein-tune ein Modell mit dem GLUE SST-2 Datensatz, indem du die Datenverarbeitung aus Abschnitt 2 verwendest."),T.forEach(t)},m(E,T){o(E,f,T),n(f,j),n(f,m),n(m,P),n(f,D)},d(E){E&&t(f)}}}function tl(ge){let f,j,m,P,D,E,T,F,I,Q,we,L,$,ve,N,be,O,Nt,Ze,Ht,Rt,Je,Zt,Jt,Ye,Yt,Xt,_e,Qt,er,nt,Ue,nr,tt,ke,rt,ee,re,Xe,Ee,tr,Qe,rr,it,H,ir,en,ar,sr,nn,lr,dr,at,$e,st,ie,lt,R,or,xe,ur,cr,tn,fr,pr,dt,ze,ot,ae,mr,Be,hr,gr,ut,M,wr,rn,vr,br,an,_r,kr,sn,Er,$r,ln,zr,Dr,dn,Tr,Mr,ct,De,ft,C,Cr,on,Ar,jr,un,Pr,Fr,cn,Or,yr,fn,qr,Sr,pn,Gr,Kr,pt,Z,Ur,mn,xr,Br,hn,Vr,Wr,mt,Te,ht,Ve,Ir,gt,se,A,Lr,gn,Nr,Hr,wn,Rr,Zr,vn,Jr,Yr,bn,Xr,Qr,_n,ei,ni,ti,ne,ri,kn,ii,ai,En,si,li,wt,te,le,$n,Me,di,zn,oi,vt,y,ui,Dn,ci,fi,Tn,pi,mi,Mn,hi,gi,Cn,wi,vi,bt,Ce,_t,Ae,kt,h,bi,An,_i,ki,jn,Ei,$i,Pn,zi,Di,Fn,Ti,Mi,On,Ci,Ai,yn,ji,Pi,qn,Fi,Oi,Sn,yi,qi,Et,G,Si,Gn,Gi,Ki,Kn,Ui,xi,We,Bi,Vi,$t,je,zt,q,Wi,Un,Ii,Li,Pe,Ni,Hi,xn,Ri,Zi,Bn,Ji,Yi,Dt,Fe,Tt,Oe,Mt,K,Xi,ye,Qi,ea,Vn,na,ta,Wn,ra,ia,Ct,de,aa,In,sa,la,At,qe,jt,oe,da,Ln,oa,ua,Pt,Se,Ft,U,ca,Nn,fa,pa,Hn,ma,ha,Rn,ga,wa,Ot,Ge,yt,Ie,va,qt,x,ba,Zn,_a,ka,Jn,Ea,$a,Yn,za,Da,St,ue,Ta,Xn,Ma,Ca,Gt,ce,Kt;return m=new Qs({props:{fw:ge[0]}}),F=new Aa({}),$=new Ys({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter3/section3.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter3/section3.ipynb"}]}}),N=new Xs({props:{id:"nvBXf7s7vTI"}}),ke=new S({props:{code:`from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>)
checkpoint = <span class="hljs-string">&quot;bert-base-uncased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">example</span>):
    <span class="hljs-keyword">return</span> tokenizer(example[<span class="hljs-string">&quot;sentence1&quot;</span>], example[<span class="hljs-string">&quot;sentence2&quot;</span>], truncation=<span class="hljs-literal">True</span>)


tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)`}}),Ee=new Aa({}),$e=new S({props:{code:`from transformers import TrainingArguments

training_args = TrainingArguments("test-trainer")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

training_args = TrainingArguments(<span class="hljs-string">&quot;test-trainer&quot;</span>)`}}),ie=new Ls({props:{$$slots:{default:[el]},$$scope:{ctx:ge}}}),ze=new S({props:{code:`from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">2</span>)`}}),De=new S({props:{code:`from transformers import Trainer

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],
    data_collator=data_collator,
    tokenizer=tokenizer,
)`}}),Te=new S({props:{code:"trainer.train()",highlighted:"trainer.train()"}}),Me=new Aa({}),Ce=new S({props:{code:`predictions = trainer.predict(tokenized_datasets["validation"])
print(predictions.predictions.shape, predictions.label_ids.shape)`,highlighted:`predictions = trainer.predict(tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>])
<span class="hljs-built_in">print</span>(predictions.predictions.shape, predictions.label_ids.shape)`}}),Ae=new S({props:{code:"(408, 2) (408,)",highlighted:'(<span class="hljs-number">408</span>, <span class="hljs-number">2</span>) (<span class="hljs-number">408</span>,)'}}),je=new S({props:{code:`import numpy as np

preds = np.argmax(predictions.predictions, axis=-1)`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

preds = np.argmax(predictions.predictions, axis=-<span class="hljs-number">1</span>)`}}),Fe=new S({props:{code:`import evaluate

metric = evaluate.load("glue", "mrpc")
metric.compute(predictions=preds, references=predictions.label_ids)`,highlighted:`<span class="hljs-keyword">import</span> evaluate

metric = evaluate.load(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>)
metric.compute(predictions=preds, references=predictions.label_ids)`}}),Oe=new S({props:{code:"{'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}",highlighted:'{<span class="hljs-string">&#x27;accuracy&#x27;</span>: <span class="hljs-number">0.8578431372549019</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.8996539792387542</span>}'}}),qe=new S({props:{code:`def compute_metrics(eval_preds):
    metric = evaluate.load("glue", "mrpc")
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_preds</span>):
    metric = evaluate.load(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>)
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)
    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)`}}),Se=new S({props:{code:`training_args = TrainingArguments("test-trainer", evaluation_strategy="epoch")
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)`,highlighted:`training_args = TrainingArguments(<span class="hljs-string">&quot;test-trainer&quot;</span>, evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">2</span>)

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)`}}),Ge=new S({props:{code:"trainer.train()",highlighted:'trainer.trai<span class="hljs-meta">n</span>()'}}),ce=new Ls({props:{$$slots:{default:[nl]},$$scope:{ctx:ge}}}),{c(){f=a("meta"),j=u(),g(m.$$.fragment),P=u(),D=a("h1"),E=a("a"),T=a("span"),g(F.$$.fragment),I=u(),Q=a("span"),we=r("Fine-tuning eine Modells mit der Trainer API"),L=u(),g($.$$.fragment),ve=u(),g(N.$$.fragment),be=u(),O=a("p"),Nt=r("\u{1F917} Transformers stellt eine "),Ze=a("code"),Ht=r("Trainer"),Rt=r("-Klasse bereit, mit der du Modelle auf deinen Datens\xE4tzen fein-tunen kannst. Nachdem die Datenverarbeitung im letzten Abschnitt abgeschlossen ist, bleiben nur noch wenige Schritte, um den "),Je=a("code"),Zt=r("Trainer"),Jt=r(" zu definieren. Der schwierigste Teil ist die Vorbereitung der Umgebung um "),Ye=a("code"),Yt=r("Trainer.train()"),Xt=r(" auszuf\xFChren, da dies auf einer CPU sehr langsam l\xE4uft. Wenn keine GPU verf\xFCgbar ist, kannst du bei [Google Colab] ("),_e=a("a"),Qt=r("https://colab.research.google.com/"),er=r(") auf kostenlose GPUs oder TPUs zugreifen."),nt=u(),Ue=a("p"),nr=r("In den folgenden Code-Beispielen wird davon ausgegangen, dass du die Beispiele aus dem vorherigen Abschnitt bereits ausgef\xFChrt hast. Hier ist eine kurze Zusammenfassung, die dir zeigt, was erwartet wird:"),tt=u(),g(ke.$$.fragment),rt=u(),ee=a("h3"),re=a("a"),Xe=a("span"),g(Ee.$$.fragment),tr=u(),Qe=a("span"),rr=r("Training"),it=u(),H=a("p"),ir=r("Als erstes m\xFCssen wir eine Klasse "),en=a("code"),ar=r("TrainingArguments"),sr=r(" definieren, die alle Hyperparameter enth\xE4lt, die der "),nn=a("code"),lr=r("Trainer"),dr=r(" f\xFCr das Training und die Evaluation verwendet. Das einzige Argument das hier angegeben werden muss, ist ein Verzeichnis in dem das trainierte Modell sowie die Checkpoints gespeichert werden. F\xFCr alles andere k\xF6nnen die Standardeinstellungen verwendet werden. Diese sollten f\xFCr ein grundlegendes Fein-tunen ausreichen."),at=u(),g($e.$$.fragment),st=u(),g(ie.$$.fragment),lt=u(),R=a("p"),or=r("Der zweite Schritt ist die Definition unseres Modells. Wie im "),xe=a("a"),ur=r("vorherigen Kapitel"),cr=r(" verwenden wir die Klasse "),tn=a("code"),fr=r("AutoModelForSequenceClassification"),pr=r(" mit zwei Labels:"),dt=u(),g(ze.$$.fragment),ot=u(),ae=a("p"),mr=r("Du wirst feststellen, dass du im Gegensatz zu "),Be=a("a"),hr=r("Kapitel 2"),gr=r(" eine Warnung erh\xE4ltst, nachdem du dieses vortrainierte Modell instanziiert hast. Der Grund daf\xFCr ist, dass BERT nicht auf die Klassifizierung von Satzpaaren vortrainiert wurde. Deshalb wurde der Kopf des vortrainierten Modells verworfen und stattdessen ein neuer Kopf hinzugef\xFCgt, der f\xFCr die Klassifizierung von Sequenzen geeignet ist. Diese Warnungen weisen darauf hin, dass Teile der Gewichtung nicht verwendet wurden (die Gewichte f\xFCr den verworfenen Kopf) und dass einige andere zuf\xE4llig initialisiert wurden (die Gewichte f\xFCr den neuen Kopf). Abschlie\xDFend werden wir aufgefordert, das Modell zu trainieren, und genau das werden wir jetzt tun."),ut=u(),M=a("p"),wr=r("Sobald wir unser Modell haben, k\xF6nnen wir einen "),rn=a("code"),vr=r("Trainer"),br=r(" definieren, indem wir alle bisher erstellten Objekte \xFCbergeben - das "),an=a("code"),_r=r("Modell"),kr=r(", die "),sn=a("code"),Er=r("training_args"),$r=r(", die Trainings- und Validierungsdaten, unseren "),ln=a("code"),zr=r("data_collator"),Dr=r(" und unseren "),dn=a("code"),Tr=r("tokenizer"),Mr=r(":"),ct=u(),g(De.$$.fragment),ft=u(),C=a("p"),Cr=r("Merke: Wenn der "),on=a("code"),Ar=r("tokenizer"),jr=r(" \xFCbergeben wird, wie wir es hier getan haben, wird der vom "),un=a("code"),Pr=r("Trainer"),Fr=r(" verwendete "),cn=a("code"),Or=r("data_collator"),yr=r(" standardm\xE4\xDFig ein "),fn=a("code"),qr=r("DataCollatorWithPadding"),Sr=r(" sein, wie er zuvor definiert wurde. Deshalb kannst du die Zeile "),pn=a("code"),Gr=r("data_collator=data_collator"),Kr=r(" in diesem Aufruf weglassen. Unabh\xE4ngig davon war es trotzdem wichtig, diesen Teil der Verarbeitung in Abschnitt 2 zu zeigen!"),pt=u(),Z=a("p"),Ur=r("Um das Modell auf unserem Datensatz fein-tunen zu k\xF6nnen, m\xFCssen wir nur die Methode "),mn=a("code"),xr=r("train()"),Br=r(" unseres "),hn=a("code"),Vr=r("Trainers"),Wr=r(" aufrufen:"),mt=u(),g(Te.$$.fragment),ht=u(),Ve=a("p"),Ir=r("Dadurch wird das Fein-tunen gestartet (was auf einer GPU ein paar Minuten dauern sollte) und der Trainingsverlust wird alle 500 Schritte gemeldet. Es wird jedoch nicht zur\xFCckgegeben, wie gut (oder schlecht) das Modell funktioniert. Dies liegt an folgenden Punkten:"),gt=u(),se=a("ol"),A=a("li"),Lr=r("Wir haben dem "),gn=a("code"),Nr=r("Trainer"),Hr=r(" nicht mitgeteilt die Performance in der Trainingsschleife auszuwerten, indem wir "),wn=a("code"),Rr=r("evaluation_strategy"),Zr=r(" entweder auf "),vn=a("code"),Jr=r('"steps"'),Yr=r(" (alle "),bn=a("code"),Xr=r("eval_steps"),Qr=r(" auswerten) oder "),_n=a("code"),ei=r('"epoch"'),ni=r(" (am Ende jeder Epoche evaluieren) gesetzt haben."),ti=u(),ne=a("li"),ri=r("Wir haben dem "),kn=a("code"),ii=r("Trainer"),ai=r(" keine Funktion "),En=a("code"),si=r("compute_metrics()"),li=r(" zur Verf\xFCgung gestellt, um w\xE4hrend der Evaluation eine Metrik zu berechnen (sonst h\xE4tte die Evaluation nur den Verlust ausgegeben, was keine sehr intuitive Zahl ist)."),wt=u(),te=a("h3"),le=a("a"),$n=a("span"),g(Me.$$.fragment),di=u(),zn=a("span"),oi=r("Evaluation"),vt=u(),y=a("p"),ui=r("Im Folgenden wird gezeigt, wie wir eine "),Dn=a("code"),ci=r("compute_metrics()"),fi=r("-Funktion erstellen und sie beim n\xE4chsten Training verwenden k\xF6nnen. Die Funktion muss ein "),Tn=a("code"),pi=r("EvalPrediction"),mi=r("-Objekt (ein bennantes Tupel mit einem "),Mn=a("code"),hi=r("predictions"),gi=r("-Feld und einem "),Cn=a("code"),wi=r("label_ids"),vi=r("-Feld) annehmen und ein Dictionary zur\xFCckgeben, das Strings auf Floats abbildet (die Strings sind die Namen der zur\xFCckgegebenen Metriken und die Floats ihre zugeh\xF6rigen Werte). Um Vorhersagen von unserem Modell zu erhalten, k\xF6nnen wir den Befehl \u201CTrainer.predict()\u201D verwenden:"),bt=u(),g(Ce.$$.fragment),_t=u(),g(Ae.$$.fragment),kt=u(),h=a("p"),bi=r("Die Ausgabe der "),An=a("code"),_i=r("predict()"),ki=r("-Methode ist ein weiteres benanntes Tupel mit drei Feldern: "),jn=a("code"),Ei=r("predictions"),$i=r(", "),Pn=a("code"),zi=r("label_ids"),Di=r(" und "),Fn=a("code"),Ti=r("metrics"),Mi=r(". Das Feld "),On=a("code"),Ci=r("metrics"),Ai=r(" enth\xE4lt den Verlust des \xFCbergebenen Datensatzes sowie Zeitangaben dazu, wie lange die Vorhersage insgesamt und im Durchschnitt gedauert hat. Sobald wir unsere Funktion "),yn=a("code"),ji=r("compute_metrics()"),Pi=r(" fertiggestellt haben und sie an den "),qn=a("code"),Fi=r("Trainer"),Oi=r(" \xFCbergeben, enth\xE4lt dieses Feld auch die von der "),Sn=a("code"),yi=r("compute_metrics()"),qi=r("-Funktion zur\xFCckgegebenen Metriken."),Et=u(),G=a("p"),Si=r("Die Vorhersagen in "),Gn=a("code"),Gi=r("predictions"),Ki=r(" sind ein zweidimensionales Array mit der Form 408 x 2 (408 ist die Anzahl der Elemente unseres Datensatzes). Das sind die Logits f\xFCr jedes Element des Datensatzes, das wir an "),Kn=a("code"),Ui=r("predict()"),xi=r(" \xFCbergeben haben (siehe "),We=a("a"),Bi=r("vorheriges Kapitel"),Vi=r(" dass alle Transformer Modelle Logits zur\xFCckgeben). Um diese in Vorhersagen umzuwandeln, die wir mit den Labels vergleichen k\xF6nnen, m\xFCssen wir den Index mit dem h\xF6chsten Wert auf der zweiten Achse nehmen:"),$t=u(),g(je.$$.fragment),zt=u(),q=a("p"),Wi=r("Jetzt k\xF6nnen wir diese Vorhersagen in "),Un=a("code"),Ii=r("preds"),Li=r(" mit den Labels vergleichen. Wir greifen auf die Metriken aus der \u{1F917} Bibliothek "),Pe=a("a"),Ni=r("Evaluate"),Hi=r(" zur\xFCck, um unsere Funktion "),xn=a("code"),Ri=r("compute_metric()"),Zi=r(" zu erstellen. Die mit dem MRPC-Datensatz verbundenen Metriken k\xF6nnen genauso einfach geladen werden, wie wir den Datensatz geladen haben, diesmal mit der Funktion "),Bn=a("code"),Ji=r("evaluate.load()"),Yi=r(". Das zur\xFCckgegebene Objekt verf\xFCgt \xFCber eine Berechnungsmethode, mit der wir die Metrik auswerten k\xF6nnen:"),Dt=u(),g(Fe.$$.fragment),Tt=u(),g(Oe.$$.fragment),Mt=u(),K=a("p"),Xi=r("Die genauen Ergebnisse k\xF6nnen variieren, da die zuf\xE4llige Initialisierung des Modellkopfes den Optimierungsverlauf und damit die Metriken ver\xE4ndern kann. Hier hat das Modell eine Genauigkeit von 85,78 % \xFCber die Validierungsdaten und eine F1-Ma\xDF von 89,97 erreicht hat. Dies sind die beiden Kennzahlen, die zur Bewertung der Ergebnisse des MRPC-Datensatzes f\xFCr den GLUE-Benchmark verwendet werden. In der Tabelle im [BERT-Paper] ("),ye=a("a"),Qi=r("https://arxiv.org/pdf/1810.04805.pdf"),ea=r(") wird f\xFCr das Basismodell ein F1-Ma\xDF von 88,9 angegeben. Das Paper hat das "),Vn=a("code"),na=r("uncased"),ta=r(" Modell verwendet, w\xE4hrend wir derzeit das "),Wn=a("code"),ra=r("cased"),ia=r(" Modell verwenden, was das bessere Ergebnis erkl\xE4rt."),Ct=u(),de=a("p"),aa=r("Zusammenfassend ergibt das unsere Funktion "),In=a("code"),sa=r("compute_metrics()"),la=r(":"),At=u(),g(qe.$$.fragment),jt=u(),oe=a("p"),da=r("Um diese Funktion in Aktion zu sehen, definieren wir einen neuen "),Ln=a("code"),oa=r("Trainer"),ua=r(" mit der Funktion \u201Ccompute_metrics()\u201D, um am Ende jeder Epoche Metriken zu melden:"),Pt=u(),g(Se.$$.fragment),Ft=u(),U=a("p"),ca=r("Hier ein Hinweis, dass wir ein neues "),Nn=a("code"),fa=r("TrainingArguments"),pa=r(" errstellen, dessen "),Hn=a("code"),ma=r("evaluation_strategy"),ha=r(" auf "),Rn=a("code"),ga=r('"epoch"'),wa=r(" gesetzt ist, und ein neues Modell definieren - andernfalls w\xFCrden wir nur das Training des momentanen Modells fortf\xFChren, das wir bereits trainiert haben. Um einen neuen Trainingslauf zu starten, f\xFChren wir folgendes aus:"),Ot=u(),g(Ge.$$.fragment),yt=u(),Ie=a("p"),va=r("Nun werden am Ende jeder Epoche zus\xE4tzlich zu den Trainingsverlusten auch die Validierungsverluste und -metriken gemeldet. Auch hier kann die Genauigkeit/F1-Ma\xDF aufgrund der zuf\xE4lligen Initialisierung des Modells zu unserem Beispiel variieren, aber sie sollte in etwa gleich sein."),qt=u(),x=a("p"),ba=r("Der "),Zn=a("code"),_a=r("Trainer"),ka=r(" funktioniert sofort auf mehreren GPUs oder TPUs und bietet zahlreiche Optionen, wie z. B. Training mit gemischter Genauigkeit (verwende "),Jn=a("code"),Ea=r("fp16 = True"),$a=r(" in deinen Trainingsargumenten). In Kapitel 10 gehen wir auf alle Funktionen ein, die die "),Yn=a("code"),za=r("Trainer"),Da=r("-Klasse bereitstellt."),St=u(),ue=a("p"),Ta=r("Damit ist die Einf\xFChrung in das Fein-tunen mit der "),Xn=a("code"),Ma=r("Trainer"),Ca=r(" API abgeschlossen. Beispiele f\xFCr die g\xE4ngigsten CL-Aufgaben werden in Kapitel 7 gegeben, aber jetzt schauen wir uns erst einmal an, wie man das Gleiche in PyTorch bewerkstelligen kann."),Gt=u(),g(ce.$$.fragment),this.h()},l(e){const d=Zs('[data-svelte="svelte-1phssyn"]',document.head);f=s(d,"META",{name:!0,content:!0}),d.forEach(t),j=c(e),w(m.$$.fragment,e),P=c(e),D=s(e,"H1",{class:!0});var Ke=l(D);E=s(Ke,"A",{id:!0,class:!0,href:!0});var Qn=l(E);T=s(Qn,"SPAN",{});var et=l(T);w(F.$$.fragment,et),et.forEach(t),Qn.forEach(t),I=c(Ke),Q=s(Ke,"SPAN",{});var ja=l(Q);we=i(ja,"Fine-tuning eine Modells mit der Trainer API"),ja.forEach(t),Ke.forEach(t),L=c(e),w($.$$.fragment,e),ve=c(e),w(N.$$.fragment,e),be=c(e),O=s(e,"P",{});var J=l(O);Nt=i(J,"\u{1F917} Transformers stellt eine "),Ze=s(J,"CODE",{});var Pa=l(Ze);Ht=i(Pa,"Trainer"),Pa.forEach(t),Rt=i(J,"-Klasse bereit, mit der du Modelle auf deinen Datens\xE4tzen fein-tunen kannst. Nachdem die Datenverarbeitung im letzten Abschnitt abgeschlossen ist, bleiben nur noch wenige Schritte, um den "),Je=s(J,"CODE",{});var Fa=l(Je);Zt=i(Fa,"Trainer"),Fa.forEach(t),Jt=i(J," zu definieren. Der schwierigste Teil ist die Vorbereitung der Umgebung um "),Ye=s(J,"CODE",{});var Oa=l(Ye);Yt=i(Oa,"Trainer.train()"),Oa.forEach(t),Xt=i(J," auszuf\xFChren, da dies auf einer CPU sehr langsam l\xE4uft. Wenn keine GPU verf\xFCgbar ist, kannst du bei [Google Colab] ("),_e=s(J,"A",{href:!0,rel:!0});var ya=l(_e);Qt=i(ya,"https://colab.research.google.com/"),ya.forEach(t),er=i(J,") auf kostenlose GPUs oder TPUs zugreifen."),J.forEach(t),nt=c(e),Ue=s(e,"P",{});var qa=l(Ue);nr=i(qa,"In den folgenden Code-Beispielen wird davon ausgegangen, dass du die Beispiele aus dem vorherigen Abschnitt bereits ausgef\xFChrt hast. Hier ist eine kurze Zusammenfassung, die dir zeigt, was erwartet wird:"),qa.forEach(t),tt=c(e),w(ke.$$.fragment,e),rt=c(e),ee=s(e,"H3",{class:!0});var Ut=l(ee);re=s(Ut,"A",{id:!0,class:!0,href:!0});var Sa=l(re);Xe=s(Sa,"SPAN",{});var Ga=l(Xe);w(Ee.$$.fragment,Ga),Ga.forEach(t),Sa.forEach(t),tr=c(Ut),Qe=s(Ut,"SPAN",{});var Ka=l(Qe);rr=i(Ka,"Training"),Ka.forEach(t),Ut.forEach(t),it=c(e),H=s(e,"P",{});var Le=l(H);ir=i(Le,"Als erstes m\xFCssen wir eine Klasse "),en=s(Le,"CODE",{});var Ua=l(en);ar=i(Ua,"TrainingArguments"),Ua.forEach(t),sr=i(Le," definieren, die alle Hyperparameter enth\xE4lt, die der "),nn=s(Le,"CODE",{});var xa=l(nn);lr=i(xa,"Trainer"),xa.forEach(t),dr=i(Le," f\xFCr das Training und die Evaluation verwendet. Das einzige Argument das hier angegeben werden muss, ist ein Verzeichnis in dem das trainierte Modell sowie die Checkpoints gespeichert werden. F\xFCr alles andere k\xF6nnen die Standardeinstellungen verwendet werden. Diese sollten f\xFCr ein grundlegendes Fein-tunen ausreichen."),Le.forEach(t),at=c(e),w($e.$$.fragment,e),st=c(e),w(ie.$$.fragment,e),lt=c(e),R=s(e,"P",{});var Ne=l(R);or=i(Ne,"Der zweite Schritt ist die Definition unseres Modells. Wie im "),xe=s(Ne,"A",{href:!0});var Ba=l(xe);ur=i(Ba,"vorherigen Kapitel"),Ba.forEach(t),cr=i(Ne," verwenden wir die Klasse "),tn=s(Ne,"CODE",{});var Va=l(tn);fr=i(Va,"AutoModelForSequenceClassification"),Va.forEach(t),pr=i(Ne," mit zwei Labels:"),Ne.forEach(t),dt=c(e),w(ze.$$.fragment,e),ot=c(e),ae=s(e,"P",{});var xt=l(ae);mr=i(xt,"Du wirst feststellen, dass du im Gegensatz zu "),Be=s(xt,"A",{href:!0});var Wa=l(Be);hr=i(Wa,"Kapitel 2"),Wa.forEach(t),gr=i(xt," eine Warnung erh\xE4ltst, nachdem du dieses vortrainierte Modell instanziiert hast. Der Grund daf\xFCr ist, dass BERT nicht auf die Klassifizierung von Satzpaaren vortrainiert wurde. Deshalb wurde der Kopf des vortrainierten Modells verworfen und stattdessen ein neuer Kopf hinzugef\xFCgt, der f\xFCr die Klassifizierung von Sequenzen geeignet ist. Diese Warnungen weisen darauf hin, dass Teile der Gewichtung nicht verwendet wurden (die Gewichte f\xFCr den verworfenen Kopf) und dass einige andere zuf\xE4llig initialisiert wurden (die Gewichte f\xFCr den neuen Kopf). Abschlie\xDFend werden wir aufgefordert, das Modell zu trainieren, und genau das werden wir jetzt tun."),xt.forEach(t),ut=c(e),M=s(e,"P",{});var B=l(M);wr=i(B,"Sobald wir unser Modell haben, k\xF6nnen wir einen "),rn=s(B,"CODE",{});var Ia=l(rn);vr=i(Ia,"Trainer"),Ia.forEach(t),br=i(B," definieren, indem wir alle bisher erstellten Objekte \xFCbergeben - das "),an=s(B,"CODE",{});var La=l(an);_r=i(La,"Modell"),La.forEach(t),kr=i(B,", die "),sn=s(B,"CODE",{});var Na=l(sn);Er=i(Na,"training_args"),Na.forEach(t),$r=i(B,", die Trainings- und Validierungsdaten, unseren "),ln=s(B,"CODE",{});var Ha=l(ln);zr=i(Ha,"data_collator"),Ha.forEach(t),Dr=i(B," und unseren "),dn=s(B,"CODE",{});var Ra=l(dn);Tr=i(Ra,"tokenizer"),Ra.forEach(t),Mr=i(B,":"),B.forEach(t),ct=c(e),w(De.$$.fragment,e),ft=c(e),C=s(e,"P",{});var V=l(C);Cr=i(V,"Merke: Wenn der "),on=s(V,"CODE",{});var Za=l(on);Ar=i(Za,"tokenizer"),Za.forEach(t),jr=i(V," \xFCbergeben wird, wie wir es hier getan haben, wird der vom "),un=s(V,"CODE",{});var Ja=l(un);Pr=i(Ja,"Trainer"),Ja.forEach(t),Fr=i(V," verwendete "),cn=s(V,"CODE",{});var Ya=l(cn);Or=i(Ya,"data_collator"),Ya.forEach(t),yr=i(V," standardm\xE4\xDFig ein "),fn=s(V,"CODE",{});var Xa=l(fn);qr=i(Xa,"DataCollatorWithPadding"),Xa.forEach(t),Sr=i(V," sein, wie er zuvor definiert wurde. Deshalb kannst du die Zeile "),pn=s(V,"CODE",{});var Qa=l(pn);Gr=i(Qa,"data_collator=data_collator"),Qa.forEach(t),Kr=i(V," in diesem Aufruf weglassen. Unabh\xE4ngig davon war es trotzdem wichtig, diesen Teil der Verarbeitung in Abschnitt 2 zu zeigen!"),V.forEach(t),pt=c(e),Z=s(e,"P",{});var He=l(Z);Ur=i(He,"Um das Modell auf unserem Datensatz fein-tunen zu k\xF6nnen, m\xFCssen wir nur die Methode "),mn=s(He,"CODE",{});var es=l(mn);xr=i(es,"train()"),es.forEach(t),Br=i(He," unseres "),hn=s(He,"CODE",{});var ns=l(hn);Vr=i(ns,"Trainers"),ns.forEach(t),Wr=i(He," aufrufen:"),He.forEach(t),mt=c(e),w(Te.$$.fragment,e),ht=c(e),Ve=s(e,"P",{});var ts=l(Ve);Ir=i(ts,"Dadurch wird das Fein-tunen gestartet (was auf einer GPU ein paar Minuten dauern sollte) und der Trainingsverlust wird alle 500 Schritte gemeldet. Es wird jedoch nicht zur\xFCckgegeben, wie gut (oder schlecht) das Modell funktioniert. Dies liegt an folgenden Punkten:"),ts.forEach(t),gt=c(e),se=s(e,"OL",{});var Bt=l(se);A=s(Bt,"LI",{});var W=l(A);Lr=i(W,"Wir haben dem "),gn=s(W,"CODE",{});var rs=l(gn);Nr=i(rs,"Trainer"),rs.forEach(t),Hr=i(W," nicht mitgeteilt die Performance in der Trainingsschleife auszuwerten, indem wir "),wn=s(W,"CODE",{});var is=l(wn);Rr=i(is,"evaluation_strategy"),is.forEach(t),Zr=i(W," entweder auf "),vn=s(W,"CODE",{});var as=l(vn);Jr=i(as,'"steps"'),as.forEach(t),Yr=i(W," (alle "),bn=s(W,"CODE",{});var ss=l(bn);Xr=i(ss,"eval_steps"),ss.forEach(t),Qr=i(W," auswerten) oder "),_n=s(W,"CODE",{});var ls=l(_n);ei=i(ls,'"epoch"'),ls.forEach(t),ni=i(W," (am Ende jeder Epoche evaluieren) gesetzt haben."),W.forEach(t),ti=c(Bt),ne=s(Bt,"LI",{});var Re=l(ne);ri=i(Re,"Wir haben dem "),kn=s(Re,"CODE",{});var ds=l(kn);ii=i(ds,"Trainer"),ds.forEach(t),ai=i(Re," keine Funktion "),En=s(Re,"CODE",{});var os=l(En);si=i(os,"compute_metrics()"),os.forEach(t),li=i(Re," zur Verf\xFCgung gestellt, um w\xE4hrend der Evaluation eine Metrik zu berechnen (sonst h\xE4tte die Evaluation nur den Verlust ausgegeben, was keine sehr intuitive Zahl ist)."),Re.forEach(t),Bt.forEach(t),wt=c(e),te=s(e,"H3",{class:!0});var Vt=l(te);le=s(Vt,"A",{id:!0,class:!0,href:!0});var us=l(le);$n=s(us,"SPAN",{});var cs=l($n);w(Me.$$.fragment,cs),cs.forEach(t),us.forEach(t),di=c(Vt),zn=s(Vt,"SPAN",{});var fs=l(zn);oi=i(fs,"Evaluation"),fs.forEach(t),Vt.forEach(t),vt=c(e),y=s(e,"P",{});var Y=l(y);ui=i(Y,"Im Folgenden wird gezeigt, wie wir eine "),Dn=s(Y,"CODE",{});var ps=l(Dn);ci=i(ps,"compute_metrics()"),ps.forEach(t),fi=i(Y,"-Funktion erstellen und sie beim n\xE4chsten Training verwenden k\xF6nnen. Die Funktion muss ein "),Tn=s(Y,"CODE",{});var ms=l(Tn);pi=i(ms,"EvalPrediction"),ms.forEach(t),mi=i(Y,"-Objekt (ein bennantes Tupel mit einem "),Mn=s(Y,"CODE",{});var hs=l(Mn);hi=i(hs,"predictions"),hs.forEach(t),gi=i(Y,"-Feld und einem "),Cn=s(Y,"CODE",{});var gs=l(Cn);wi=i(gs,"label_ids"),gs.forEach(t),vi=i(Y,"-Feld) annehmen und ein Dictionary zur\xFCckgeben, das Strings auf Floats abbildet (die Strings sind die Namen der zur\xFCckgegebenen Metriken und die Floats ihre zugeh\xF6rigen Werte). Um Vorhersagen von unserem Modell zu erhalten, k\xF6nnen wir den Befehl \u201CTrainer.predict()\u201D verwenden:"),Y.forEach(t),bt=c(e),w(Ce.$$.fragment,e),_t=c(e),w(Ae.$$.fragment,e),kt=c(e),h=s(e,"P",{});var z=l(h);bi=i(z,"Die Ausgabe der "),An=s(z,"CODE",{});var ws=l(An);_i=i(ws,"predict()"),ws.forEach(t),ki=i(z,"-Methode ist ein weiteres benanntes Tupel mit drei Feldern: "),jn=s(z,"CODE",{});var vs=l(jn);Ei=i(vs,"predictions"),vs.forEach(t),$i=i(z,", "),Pn=s(z,"CODE",{});var bs=l(Pn);zi=i(bs,"label_ids"),bs.forEach(t),Di=i(z," und "),Fn=s(z,"CODE",{});var _s=l(Fn);Ti=i(_s,"metrics"),_s.forEach(t),Mi=i(z,". Das Feld "),On=s(z,"CODE",{});var ks=l(On);Ci=i(ks,"metrics"),ks.forEach(t),Ai=i(z," enth\xE4lt den Verlust des \xFCbergebenen Datensatzes sowie Zeitangaben dazu, wie lange die Vorhersage insgesamt und im Durchschnitt gedauert hat. Sobald wir unsere Funktion "),yn=s(z,"CODE",{});var Es=l(yn);ji=i(Es,"compute_metrics()"),Es.forEach(t),Pi=i(z," fertiggestellt haben und sie an den "),qn=s(z,"CODE",{});var $s=l(qn);Fi=i($s,"Trainer"),$s.forEach(t),Oi=i(z," \xFCbergeben, enth\xE4lt dieses Feld auch die von der "),Sn=s(z,"CODE",{});var zs=l(Sn);yi=i(zs,"compute_metrics()"),zs.forEach(t),qi=i(z,"-Funktion zur\xFCckgegebenen Metriken."),z.forEach(t),Et=c(e),G=s(e,"P",{});var fe=l(G);Si=i(fe,"Die Vorhersagen in "),Gn=s(fe,"CODE",{});var Ds=l(Gn);Gi=i(Ds,"predictions"),Ds.forEach(t),Ki=i(fe," sind ein zweidimensionales Array mit der Form 408 x 2 (408 ist die Anzahl der Elemente unseres Datensatzes). Das sind die Logits f\xFCr jedes Element des Datensatzes, das wir an "),Kn=s(fe,"CODE",{});var Ts=l(Kn);Ui=i(Ts,"predict()"),Ts.forEach(t),xi=i(fe," \xFCbergeben haben (siehe "),We=s(fe,"A",{href:!0});var Ms=l(We);Bi=i(Ms,"vorheriges Kapitel"),Ms.forEach(t),Vi=i(fe," dass alle Transformer Modelle Logits zur\xFCckgeben). Um diese in Vorhersagen umzuwandeln, die wir mit den Labels vergleichen k\xF6nnen, m\xFCssen wir den Index mit dem h\xF6chsten Wert auf der zweiten Achse nehmen:"),fe.forEach(t),$t=c(e),w(je.$$.fragment,e),zt=c(e),q=s(e,"P",{});var X=l(q);Wi=i(X,"Jetzt k\xF6nnen wir diese Vorhersagen in "),Un=s(X,"CODE",{});var Cs=l(Un);Ii=i(Cs,"preds"),Cs.forEach(t),Li=i(X," mit den Labels vergleichen. Wir greifen auf die Metriken aus der \u{1F917} Bibliothek "),Pe=s(X,"A",{href:!0,rel:!0});var As=l(Pe);Ni=i(As,"Evaluate"),As.forEach(t),Hi=i(X," zur\xFCck, um unsere Funktion "),xn=s(X,"CODE",{});var js=l(xn);Ri=i(js,"compute_metric()"),js.forEach(t),Zi=i(X," zu erstellen. Die mit dem MRPC-Datensatz verbundenen Metriken k\xF6nnen genauso einfach geladen werden, wie wir den Datensatz geladen haben, diesmal mit der Funktion "),Bn=s(X,"CODE",{});var Ps=l(Bn);Ji=i(Ps,"evaluate.load()"),Ps.forEach(t),Yi=i(X,". Das zur\xFCckgegebene Objekt verf\xFCgt \xFCber eine Berechnungsmethode, mit der wir die Metrik auswerten k\xF6nnen:"),X.forEach(t),Dt=c(e),w(Fe.$$.fragment,e),Tt=c(e),w(Oe.$$.fragment,e),Mt=c(e),K=s(e,"P",{});var pe=l(K);Xi=i(pe,"Die genauen Ergebnisse k\xF6nnen variieren, da die zuf\xE4llige Initialisierung des Modellkopfes den Optimierungsverlauf und damit die Metriken ver\xE4ndern kann. Hier hat das Modell eine Genauigkeit von 85,78 % \xFCber die Validierungsdaten und eine F1-Ma\xDF von 89,97 erreicht hat. Dies sind die beiden Kennzahlen, die zur Bewertung der Ergebnisse des MRPC-Datensatzes f\xFCr den GLUE-Benchmark verwendet werden. In der Tabelle im [BERT-Paper] ("),ye=s(pe,"A",{href:!0,rel:!0});var Fs=l(ye);Qi=i(Fs,"https://arxiv.org/pdf/1810.04805.pdf"),Fs.forEach(t),ea=i(pe,") wird f\xFCr das Basismodell ein F1-Ma\xDF von 88,9 angegeben. Das Paper hat das "),Vn=s(pe,"CODE",{});var Os=l(Vn);na=i(Os,"uncased"),Os.forEach(t),ta=i(pe," Modell verwendet, w\xE4hrend wir derzeit das "),Wn=s(pe,"CODE",{});var ys=l(Wn);ra=i(ys,"cased"),ys.forEach(t),ia=i(pe," Modell verwenden, was das bessere Ergebnis erkl\xE4rt."),pe.forEach(t),Ct=c(e),de=s(e,"P",{});var Wt=l(de);aa=i(Wt,"Zusammenfassend ergibt das unsere Funktion "),In=s(Wt,"CODE",{});var qs=l(In);sa=i(qs,"compute_metrics()"),qs.forEach(t),la=i(Wt,":"),Wt.forEach(t),At=c(e),w(qe.$$.fragment,e),jt=c(e),oe=s(e,"P",{});var It=l(oe);da=i(It,"Um diese Funktion in Aktion zu sehen, definieren wir einen neuen "),Ln=s(It,"CODE",{});var Ss=l(Ln);oa=i(Ss,"Trainer"),Ss.forEach(t),ua=i(It," mit der Funktion \u201Ccompute_metrics()\u201D, um am Ende jeder Epoche Metriken zu melden:"),It.forEach(t),Pt=c(e),w(Se.$$.fragment,e),Ft=c(e),U=s(e,"P",{});var me=l(U);ca=i(me,"Hier ein Hinweis, dass wir ein neues "),Nn=s(me,"CODE",{});var Gs=l(Nn);fa=i(Gs,"TrainingArguments"),Gs.forEach(t),pa=i(me," errstellen, dessen "),Hn=s(me,"CODE",{});var Ks=l(Hn);ma=i(Ks,"evaluation_strategy"),Ks.forEach(t),ha=i(me," auf "),Rn=s(me,"CODE",{});var Us=l(Rn);ga=i(Us,'"epoch"'),Us.forEach(t),wa=i(me," gesetzt ist, und ein neues Modell definieren - andernfalls w\xFCrden wir nur das Training des momentanen Modells fortf\xFChren, das wir bereits trainiert haben. Um einen neuen Trainingslauf zu starten, f\xFChren wir folgendes aus:"),me.forEach(t),Ot=c(e),w(Ge.$$.fragment,e),yt=c(e),Ie=s(e,"P",{});var xs=l(Ie);va=i(xs,"Nun werden am Ende jeder Epoche zus\xE4tzlich zu den Trainingsverlusten auch die Validierungsverluste und -metriken gemeldet. Auch hier kann die Genauigkeit/F1-Ma\xDF aufgrund der zuf\xE4lligen Initialisierung des Modells zu unserem Beispiel variieren, aber sie sollte in etwa gleich sein."),xs.forEach(t),qt=c(e),x=s(e,"P",{});var he=l(x);ba=i(he,"Der "),Zn=s(he,"CODE",{});var Bs=l(Zn);_a=i(Bs,"Trainer"),Bs.forEach(t),ka=i(he," funktioniert sofort auf mehreren GPUs oder TPUs und bietet zahlreiche Optionen, wie z. B. Training mit gemischter Genauigkeit (verwende "),Jn=s(he,"CODE",{});var Vs=l(Jn);Ea=i(Vs,"fp16 = True"),Vs.forEach(t),$a=i(he," in deinen Trainingsargumenten). In Kapitel 10 gehen wir auf alle Funktionen ein, die die "),Yn=s(he,"CODE",{});var Ws=l(Yn);za=i(Ws,"Trainer"),Ws.forEach(t),Da=i(he,"-Klasse bereitstellt."),he.forEach(t),St=c(e),ue=s(e,"P",{});var Lt=l(ue);Ta=i(Lt,"Damit ist die Einf\xFChrung in das Fein-tunen mit der "),Xn=s(Lt,"CODE",{});var Is=l(Xn);Ma=i(Is,"Trainer"),Is.forEach(t),Ca=i(Lt," API abgeschlossen. Beispiele f\xFCr die g\xE4ngigsten CL-Aufgaben werden in Kapitel 7 gegeben, aber jetzt schauen wir uns erst einmal an, wie man das Gleiche in PyTorch bewerkstelligen kann."),Lt.forEach(t),Gt=c(e),w(ce.$$.fragment,e),this.h()},h(){p(f,"name","hf:doc:metadata"),p(f,"content",JSON.stringify(rl)),p(E,"id","finetuning-eine-modells-mit-der-trainer-api"),p(E,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(E,"href","#finetuning-eine-modells-mit-der-trainer-api"),p(D,"class","relative group"),p(_e,"href","https://colab.research.google.com/"),p(_e,"rel","nofollow"),p(re,"id","training"),p(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(re,"href","#training"),p(ee,"class","relative group"),p(xe,"href","/course/chapter2"),p(Be,"href","/course/chapter2"),p(le,"id","evaluation"),p(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(le,"href","#evaluation"),p(te,"class","relative group"),p(We,"href","/course/chapter2"),p(Pe,"href","https://github.com/huggingface/evaluate/"),p(Pe,"rel","nofollow"),p(ye,"href","https://arxiv.org/pdf/1810.04805.pdf"),p(ye,"rel","nofollow")},m(e,d){n(document.head,f),o(e,j,d),v(m,e,d),o(e,P,d),o(e,D,d),n(D,E),n(E,T),v(F,T,null),n(D,I),n(D,Q),n(Q,we),o(e,L,d),v($,e,d),o(e,ve,d),v(N,e,d),o(e,be,d),o(e,O,d),n(O,Nt),n(O,Ze),n(Ze,Ht),n(O,Rt),n(O,Je),n(Je,Zt),n(O,Jt),n(O,Ye),n(Ye,Yt),n(O,Xt),n(O,_e),n(_e,Qt),n(O,er),o(e,nt,d),o(e,Ue,d),n(Ue,nr),o(e,tt,d),v(ke,e,d),o(e,rt,d),o(e,ee,d),n(ee,re),n(re,Xe),v(Ee,Xe,null),n(ee,tr),n(ee,Qe),n(Qe,rr),o(e,it,d),o(e,H,d),n(H,ir),n(H,en),n(en,ar),n(H,sr),n(H,nn),n(nn,lr),n(H,dr),o(e,at,d),v($e,e,d),o(e,st,d),v(ie,e,d),o(e,lt,d),o(e,R,d),n(R,or),n(R,xe),n(xe,ur),n(R,cr),n(R,tn),n(tn,fr),n(R,pr),o(e,dt,d),v(ze,e,d),o(e,ot,d),o(e,ae,d),n(ae,mr),n(ae,Be),n(Be,hr),n(ae,gr),o(e,ut,d),o(e,M,d),n(M,wr),n(M,rn),n(rn,vr),n(M,br),n(M,an),n(an,_r),n(M,kr),n(M,sn),n(sn,Er),n(M,$r),n(M,ln),n(ln,zr),n(M,Dr),n(M,dn),n(dn,Tr),n(M,Mr),o(e,ct,d),v(De,e,d),o(e,ft,d),o(e,C,d),n(C,Cr),n(C,on),n(on,Ar),n(C,jr),n(C,un),n(un,Pr),n(C,Fr),n(C,cn),n(cn,Or),n(C,yr),n(C,fn),n(fn,qr),n(C,Sr),n(C,pn),n(pn,Gr),n(C,Kr),o(e,pt,d),o(e,Z,d),n(Z,Ur),n(Z,mn),n(mn,xr),n(Z,Br),n(Z,hn),n(hn,Vr),n(Z,Wr),o(e,mt,d),v(Te,e,d),o(e,ht,d),o(e,Ve,d),n(Ve,Ir),o(e,gt,d),o(e,se,d),n(se,A),n(A,Lr),n(A,gn),n(gn,Nr),n(A,Hr),n(A,wn),n(wn,Rr),n(A,Zr),n(A,vn),n(vn,Jr),n(A,Yr),n(A,bn),n(bn,Xr),n(A,Qr),n(A,_n),n(_n,ei),n(A,ni),n(se,ti),n(se,ne),n(ne,ri),n(ne,kn),n(kn,ii),n(ne,ai),n(ne,En),n(En,si),n(ne,li),o(e,wt,d),o(e,te,d),n(te,le),n(le,$n),v(Me,$n,null),n(te,di),n(te,zn),n(zn,oi),o(e,vt,d),o(e,y,d),n(y,ui),n(y,Dn),n(Dn,ci),n(y,fi),n(y,Tn),n(Tn,pi),n(y,mi),n(y,Mn),n(Mn,hi),n(y,gi),n(y,Cn),n(Cn,wi),n(y,vi),o(e,bt,d),v(Ce,e,d),o(e,_t,d),v(Ae,e,d),o(e,kt,d),o(e,h,d),n(h,bi),n(h,An),n(An,_i),n(h,ki),n(h,jn),n(jn,Ei),n(h,$i),n(h,Pn),n(Pn,zi),n(h,Di),n(h,Fn),n(Fn,Ti),n(h,Mi),n(h,On),n(On,Ci),n(h,Ai),n(h,yn),n(yn,ji),n(h,Pi),n(h,qn),n(qn,Fi),n(h,Oi),n(h,Sn),n(Sn,yi),n(h,qi),o(e,Et,d),o(e,G,d),n(G,Si),n(G,Gn),n(Gn,Gi),n(G,Ki),n(G,Kn),n(Kn,Ui),n(G,xi),n(G,We),n(We,Bi),n(G,Vi),o(e,$t,d),v(je,e,d),o(e,zt,d),o(e,q,d),n(q,Wi),n(q,Un),n(Un,Ii),n(q,Li),n(q,Pe),n(Pe,Ni),n(q,Hi),n(q,xn),n(xn,Ri),n(q,Zi),n(q,Bn),n(Bn,Ji),n(q,Yi),o(e,Dt,d),v(Fe,e,d),o(e,Tt,d),v(Oe,e,d),o(e,Mt,d),o(e,K,d),n(K,Xi),n(K,ye),n(ye,Qi),n(K,ea),n(K,Vn),n(Vn,na),n(K,ta),n(K,Wn),n(Wn,ra),n(K,ia),o(e,Ct,d),o(e,de,d),n(de,aa),n(de,In),n(In,sa),n(de,la),o(e,At,d),v(qe,e,d),o(e,jt,d),o(e,oe,d),n(oe,da),n(oe,Ln),n(Ln,oa),n(oe,ua),o(e,Pt,d),v(Se,e,d),o(e,Ft,d),o(e,U,d),n(U,ca),n(U,Nn),n(Nn,fa),n(U,pa),n(U,Hn),n(Hn,ma),n(U,ha),n(U,Rn),n(Rn,ga),n(U,wa),o(e,Ot,d),v(Ge,e,d),o(e,yt,d),o(e,Ie,d),n(Ie,va),o(e,qt,d),o(e,x,d),n(x,ba),n(x,Zn),n(Zn,_a),n(x,ka),n(x,Jn),n(Jn,Ea),n(x,$a),n(x,Yn),n(Yn,za),n(x,Da),o(e,St,d),o(e,ue,d),n(ue,Ta),n(ue,Xn),n(Xn,Ma),n(ue,Ca),o(e,Gt,d),v(ce,e,d),Kt=!0},p(e,[d]){const Ke={};d&1&&(Ke.fw=e[0]),m.$set(Ke);const Qn={};d&2&&(Qn.$$scope={dirty:d,ctx:e}),ie.$set(Qn);const et={};d&2&&(et.$$scope={dirty:d,ctx:e}),ce.$set(et)},i(e){Kt||(b(m.$$.fragment,e),b(F.$$.fragment,e),b($.$$.fragment,e),b(N.$$.fragment,e),b(ke.$$.fragment,e),b(Ee.$$.fragment,e),b($e.$$.fragment,e),b(ie.$$.fragment,e),b(ze.$$.fragment,e),b(De.$$.fragment,e),b(Te.$$.fragment,e),b(Me.$$.fragment,e),b(Ce.$$.fragment,e),b(Ae.$$.fragment,e),b(je.$$.fragment,e),b(Fe.$$.fragment,e),b(Oe.$$.fragment,e),b(qe.$$.fragment,e),b(Se.$$.fragment,e),b(Ge.$$.fragment,e),b(ce.$$.fragment,e),Kt=!0)},o(e){_(m.$$.fragment,e),_(F.$$.fragment,e),_($.$$.fragment,e),_(N.$$.fragment,e),_(ke.$$.fragment,e),_(Ee.$$.fragment,e),_($e.$$.fragment,e),_(ie.$$.fragment,e),_(ze.$$.fragment,e),_(De.$$.fragment,e),_(Te.$$.fragment,e),_(Me.$$.fragment,e),_(Ce.$$.fragment,e),_(Ae.$$.fragment,e),_(je.$$.fragment,e),_(Fe.$$.fragment,e),_(Oe.$$.fragment,e),_(qe.$$.fragment,e),_(Se.$$.fragment,e),_(Ge.$$.fragment,e),_(ce.$$.fragment,e),Kt=!1},d(e){t(f),e&&t(j),k(m,e),e&&t(P),e&&t(D),k(F),e&&t(L),k($,e),e&&t(ve),k(N,e),e&&t(be),e&&t(O),e&&t(nt),e&&t(Ue),e&&t(tt),k(ke,e),e&&t(rt),e&&t(ee),k(Ee),e&&t(it),e&&t(H),e&&t(at),k($e,e),e&&t(st),k(ie,e),e&&t(lt),e&&t(R),e&&t(dt),k(ze,e),e&&t(ot),e&&t(ae),e&&t(ut),e&&t(M),e&&t(ct),k(De,e),e&&t(ft),e&&t(C),e&&t(pt),e&&t(Z),e&&t(mt),k(Te,e),e&&t(ht),e&&t(Ve),e&&t(gt),e&&t(se),e&&t(wt),e&&t(te),k(Me),e&&t(vt),e&&t(y),e&&t(bt),k(Ce,e),e&&t(_t),k(Ae,e),e&&t(kt),e&&t(h),e&&t(Et),e&&t(G),e&&t($t),k(je,e),e&&t(zt),e&&t(q),e&&t(Dt),k(Fe,e),e&&t(Tt),k(Oe,e),e&&t(Mt),e&&t(K),e&&t(Ct),e&&t(de),e&&t(At),k(qe,e),e&&t(jt),e&&t(oe),e&&t(Pt),k(Se,e),e&&t(Ft),e&&t(U),e&&t(Ot),k(Ge,e),e&&t(yt),e&&t(Ie),e&&t(qt),e&&t(x),e&&t(St),e&&t(ue),e&&t(Gt),k(ce,e)}}}const rl={local:"finetuning-eine-modells-mit-der-trainer-api",sections:[{local:"training",title:"Training"},{local:"evaluation",title:"Evaluation"}],title:"Fine-tuning eine Modells mit der Trainer API"};function il(ge,f,j){let m="pt";return Js(()=>{const P=new URLSearchParams(window.location.search);j(0,m=P.get("fw")||"pt")}),[m]}class ul extends Ns{constructor(f){super();Hs(this,f,il,tl,Rs,{})}}export{ul as default,rl as metadata};
