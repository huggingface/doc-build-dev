import{S as xe,i as Me,s as be,e as a,k as f,w as ye,t as c,M as qe,c as l,d as t,m,a as r,x as Pe,h as p,b as i,G as o,g as n,y as Ae,L as ze,q as Le,o as Te,B as Ie,v as Se}from"../../chunks/vendor-hf-doc-builder.js";import{Y as ke}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Ce}from"../../chunks/IconCopyLink-hf-doc-builder.js";function Ge(se){let u,C,h,_,x,g,J,M,O,G,$,Q,v,j,b,D,F,N,L,K,R,T,V,U,I,W,X,d,q,w,Z,ee,z,y,te,oe,S,P,ae,le,k,A,re,Y;return g=new Ce({}),$=new ke({props:{id:"d_ixlCubqQw"}}),{c(){u=a("meta"),C=f(),h=a("h1"),_=a("a"),x=a("span"),ye(g.$$.fragment),J=f(),M=a("span"),O=c("Modelli decoder"),G=f(),ye($.$$.fragment),Q=f(),v=a("p"),j=c("I modelli decoder utilizzano solo il decoder di un modello Transformer. Ad ogni passaggio e per una data parola, gli attention layer hanno accesso solo alle parole che la precedono nella frase. Questi modelli sono spesso detti "),b=a("em"),D=c("auto-regressive models"),F=c("."),N=f(),L=a("p"),K=c("Il pre-addestramento dei modelli decoder ha spesso a che fare con la previsione della parola successiva in un contesto frasale."),R=f(),T=a("p"),V=c("Questi modelli sono particolarmente adatti a compiti di generazione testuale."),U=f(),I=a("p"),W=c("Alcuni rappresentanti di questa famiglia includono:"),X=f(),d=a("ul"),q=a("li"),w=a("a"),Z=c("CTRL"),ee=f(),z=a("li"),y=a("a"),te=c("GPT"),oe=f(),S=a("li"),P=a("a"),ae=c("GPT-2"),le=f(),k=a("li"),A=a("a"),re=c("Transformer XL"),this.h()},l(e){const s=qe('[data-svelte="svelte-1phssyn"]',document.head);u=l(s,"META",{name:!0,content:!0}),s.forEach(t),C=m(e),h=l(e,"H1",{class:!0});var B=r(h);_=l(B,"A",{id:!0,class:!0,href:!0});var ie=r(_);x=l(ie,"SPAN",{});var ne=r(x);Pe(g.$$.fragment,ne),ne.forEach(t),ie.forEach(t),J=m(B),M=l(B,"SPAN",{});var de=r(M);O=p(de,"Modelli decoder"),de.forEach(t),B.forEach(t),G=m(e),Pe($.$$.fragment,e),Q=m(e),v=l(e,"P",{});var H=r(v);j=p(H,"I modelli decoder utilizzano solo il decoder di un modello Transformer. Ad ogni passaggio e per una data parola, gli attention layer hanno accesso solo alle parole che la precedono nella frase. Questi modelli sono spesso detti "),b=l(H,"EM",{});var fe=r(b);D=p(fe,"auto-regressive models"),fe.forEach(t),F=p(H,"."),H.forEach(t),N=m(e),L=l(e,"P",{});var ce=r(L);K=p(ce,"Il pre-addestramento dei modelli decoder ha spesso a che fare con la previsione della parola successiva in un contesto frasale."),ce.forEach(t),R=m(e),T=l(e,"P",{});var me=r(T);V=p(me,"Questi modelli sono particolarmente adatti a compiti di generazione testuale."),me.forEach(t),U=m(e),I=l(e,"P",{});var pe=r(I);W=p(pe,"Alcuni rappresentanti di questa famiglia includono:"),pe.forEach(t),X=m(e),d=l(e,"UL",{});var E=r(d);q=l(E,"LI",{});var ue=r(q);w=l(ue,"A",{href:!0,rel:!0});var he=r(w);Z=p(he,"CTRL"),he.forEach(t),ue.forEach(t),ee=m(E),z=l(E,"LI",{});var _e=r(z);y=l(_e,"A",{href:!0,rel:!0});var ve=r(y);te=p(ve,"GPT"),ve.forEach(t),_e.forEach(t),oe=m(E),S=l(E,"LI",{});var Ee=r(S);P=l(Ee,"A",{href:!0,rel:!0});var ge=r(P);ae=p(ge,"GPT-2"),ge.forEach(t),Ee.forEach(t),le=m(E),k=l(E,"LI",{});var $e=r(k);A=l($e,"A",{href:!0,rel:!0});var we=r(A);re=p(we,"Transformer XL"),we.forEach(t),$e.forEach(t),E.forEach(t),this.h()},h(){i(u,"name","hf:doc:metadata"),i(u,"content",JSON.stringify(Qe)),i(_,"id","modelli-decoder"),i(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(_,"href","#modelli-decoder"),i(h,"class","relative group"),i(w,"href","https://huggingface.co/transformers/model_doc/ctrl.html"),i(w,"rel","nofollow"),i(y,"href","https://huggingface.co/transformers/model_doc/gpt.html"),i(y,"rel","nofollow"),i(P,"href","https://huggingface.co/transformers/model_doc/gpt2.html"),i(P,"rel","nofollow"),i(A,"href","https://huggingface.co/transformers/model_doc/transfo-xl.html"),i(A,"rel","nofollow")},m(e,s){o(document.head,u),n(e,C,s),n(e,h,s),o(h,_),o(_,x),Ae(g,x,null),o(h,J),o(h,M),o(M,O),n(e,G,s),Ae($,e,s),n(e,Q,s),n(e,v,s),o(v,j),o(v,b),o(b,D),o(v,F),n(e,N,s),n(e,L,s),o(L,K),n(e,R,s),n(e,T,s),o(T,V),n(e,U,s),n(e,I,s),o(I,W),n(e,X,s),n(e,d,s),o(d,q),o(q,w),o(w,Z),o(d,ee),o(d,z),o(z,y),o(y,te),o(d,oe),o(d,S),o(S,P),o(P,ae),o(d,le),o(d,k),o(k,A),o(A,re),Y=!0},p:ze,i(e){Y||(Le(g.$$.fragment,e),Le($.$$.fragment,e),Y=!0)},o(e){Te(g.$$.fragment,e),Te($.$$.fragment,e),Y=!1},d(e){t(u),e&&t(C),e&&t(h),Ie(g),e&&t(G),Ie($,e),e&&t(Q),e&&t(v),e&&t(N),e&&t(L),e&&t(R),e&&t(T),e&&t(U),e&&t(I),e&&t(X),e&&t(d)}}}const Qe={local:"modelli-decoder",title:"Modelli decoder"};function Ne(se){return Se(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ye extends xe{constructor(u){super();Me(this,u,Ne,Ge,be,{})}}export{Ye as default,Qe as metadata};
