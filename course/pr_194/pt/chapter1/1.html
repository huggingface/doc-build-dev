<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;introduo&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;bemvindoa-ao-curso&quot;,&quot;title&quot;:&quot;Bem-vindo(a) ao Curso ğŸ¤—!&quot;},{&quot;local&quot;:&quot;o-que-esperar&quot;,&quot;title&quot;:&quot;O que esperar?&quot;},{&quot;local&quot;:&quot;quem-ns-somos&quot;,&quot;title&quot;:&quot;Quem nÃ³s somos?&quot;}],&quot;title&quot;:&quot;IntroduÃ§Ã£o&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/course/pr_194/pt/_app/assets/pages/__layout.svelte-048423b6.css">
	<link rel="modulepreload" href="/docs/course/pr_194/pt/_app/start-3fb4d890.js">
	<link rel="modulepreload" href="/docs/course/pr_194/pt/_app/chunks/vendor-e6c5d93e.js">
	<link rel="modulepreload" href="/docs/course/pr_194/pt/_app/chunks/paths-4b3c6e7e.js">
	<link rel="modulepreload" href="/docs/course/pr_194/pt/_app/pages/__layout.svelte-20ef27ff.js">
	<link rel="modulepreload" href="/docs/course/pr_194/pt/_app/pages/chapter1/1.mdx-1daae04a.js">
	<link rel="modulepreload" href="/docs/course/pr_194/pt/_app/chunks/Youtube-58bb6821.js">
	<link rel="modulepreload" href="/docs/course/pr_194/pt/_app/chunks/IconCopyLink-7b8d27fe.js"> 





<h1 class="relative group"><a id="introduo" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#introduo"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>IntroduÃ§Ã£o
	</span></h1>

<h2 class="relative group"><a id="bemvindoa-ao-curso" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#bemvindoa-ao-curso"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Bem-vindo(a) ao Curso ğŸ¤—!
	</span></h2>

<iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/00GKzGyWFEs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p>Esse curso te ensinarÃ¡ sobre processamento de linguagem natural (PLN, ou NLP em inglÃªs) usando as bibliotecas do ecossistema <a href="https://huggingface.co/" rel="nofollow">Hugging Face</a> â€” <a href="https://github.com/huggingface/transformers" rel="nofollow">ğŸ¤— Transformers</a>, <a href="https://github.com/huggingface/datasets" rel="nofollow">ğŸ¤— Datasets</a>, <a href="https://github.com/huggingface/tokenizers" rel="nofollow">ğŸ¤— Tokenizers</a> e <a href="https://github.com/huggingface/accelerate" rel="nofollow">ğŸ¤— Accelerate</a> â€” assim como a <a href="https://huggingface.co/models" rel="nofollow">Hugging Face Hub</a>. Ã‰ completamente gratuito e sem anÃºncios!</p>
<h2 class="relative group"><a id="o-que-esperar" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#o-que-esperar"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>O que esperar?
	</span></h2>

<p>Aqui uma visÃ£o geral do curso:</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg" alt="Brief overview of the chapters of the course.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg" alt="Brief overview of the chapters of the course."></div>
<ul><li>CapÃ­tulos 1 ao 4 dÃ¡ uma introduÃ§Ã£o para os principais conceitos da biblioteca Transformers ğŸ¤—. No final dessa parte do curso, vocÃª se tornarÃ¡ familiar sobre como os modelos Transformers funcionam, saberÃ¡ como usar o modelo da <a href="https://huggingface.co/models" rel="nofollow">Hugging Face Hub</a>, fazer um ajuste fino em um dataset e compartilhar os resultados no Hub!</li>
<li>CapÃ­tulo 5 ao 8 ensina o bÃ¡sico dos ğŸ¤— Datasets e ğŸ¤— Tokenizadores antes de mergulhar nas tarefas clÃ¡ssicas de NLP. Ao final dessa parte, vocÃª serÃ¡ capaz de resolver por conta prÃ³pria os problemas mais comuns de NLP. Ao longo do caminho, vocÃª aprenderÃ¡ como construir e compartilhar demonstraÃ§Ãµes de seus modelos e otimiza-los para ambientes de produÃ§Ã£o. No final dessa parte, vocÃª serÃ¡ capaz de aplicar a ğŸ¤— Transformers para (quase) qualquer problema de aprendizagem de mÃ¡quina!</li></ul>
<p>Esse curso:</p>
<ul><li>Requer um bom conhecimento de Python</li>
<li>Ã‰ melhor aproveitado depois de um curso de introduÃ§Ã£o ao deep learning (aprendizagem profunda), como o da <a href="https://www.fast.ai/" rel="nofollow">fast.ai</a> <a href="https://course.fast.ai/" rel="nofollow">Practical Deep Learning for Coders</a>  ou um dos programas desenvolvidos pela <a href="https://www.deeplearning.ai/" rel="nofollow">DeepLearning.AI</a></li>
<li>NÃ£o se espera nenhum conhecimento prÃ©vio em <a href="https://pytorch.org/" rel="nofollow">PyTorch</a>  ou em <a href="https://www.tensorflow.org/" rel="nofollow">TensorFlow</a> , ainda que certa familiaridade com ambas as ferramentas seja proveitoso</li></ul>
<p>Depois de vocÃª ter completado esse curso, nÃ³s recomendamos dar uma olhada na especializaÃ§Ã£o da DeepLearning.AI de <a href="https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh" rel="nofollow">Processamento de Linguagem Natural</a>, que cobre uma grande gama de modelos de NLP como naive Bayes e LSTMs que valem bastante a pena ter conhecimento!</p>
<h2 class="relative group"><a id="quem-ns-somos" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#quem-ns-somos"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Quem nÃ³s somos?
	</span></h2>

<p>Sobre os autores:</p>
<p><strong>Matthew Carrigan</strong> Ã© Engenheiro de Machine Learning na Hugging Face. Ele mora em Dublin na Irlanda e anteriormente trabalhou como Engenheiro de ML na Parse.ly e antes disso como pesquisador pÃ³s-doc na Trinity College Dublin. Ele nÃ£o acredita que chegaremos a um rendimento anual bruto corrigido escalando as arquiteturas existentes, mas de qualquer forma ele tem grandes esperanÃ§as na imortalidade das mÃ¡quinas.</p>
<p><strong>Lysandre Debut</strong> Ã© um Engenheiro de Machine Learning na Hugging Face e tem trabalhado para a biblioteca ğŸ¤— Transformers desde seus estÃ¡gios iniciais de desenvolvimento. Seu objetivo Ã© fazer com que a Ã¡rea de NLP se torne acessÃ­vel para qualquer pessoa atravÃ©s do desenvolvimento de ferramentas com uma API simples.</p>
<p><strong>Sylvain Gugger</strong> Ã© um Engenheiro Pesquisador na Hugging Face e um dos principais mantenedores da biblioteca ğŸ¤— Transformers. Anteriormente ele foi Cientista Pesquisador na fast.ai, e co-escreveu <em><a href="https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/" rel="nofollow">Deep Learning for Coders with fastai and PyTorch</a></em> com Jeremy Howard. O principal foco de sua pesquisa estÃ¡ em fazer o deep learning mais acessÃ­vel, atravÃ©s de desenhos e tÃ©cnicas de aprimoramento que permitam que modelos sejam treinados mais rÃ¡pidos e com recursos limitados.</p>
<p><strong>Merve Noyan</strong> Ã© um desenvolvedor e evangelista na Hugging Face, trabalhando no desenvolvimento e construÃ§Ã£o de conteÃºdos envolta da temÃ¡tica de democratizaÃ§Ã£o do Machine Learning para todas as pessoas.</p>
<p><strong>Lucile Saulnier</strong> Ã© uma Engenheira de Machine Learning na Hugging Face, desenvolvendo e apoiando o uso de ferramentas de cÃ³digo aberto. Ela tambÃ©m Ã© ativamente envolvida em muitos projetos de pesquisa no campo do Processamento de Linguagem natural assim como em treinamentos colaborativos e BigScience.</p>
<p><strong>Lewis Tunstall</strong>  Ã© um Engenheiro de Machine Learning na Hugging Face, focado no desenvolvimento de ferramentas open-source e em fazÃª-las amplamente acessÃ­veis pela comunidade. Ele tambÃ©m Ã© co-autor do livro que estÃ¡ pra lanÃ§ar <a href="https://www.oreilly.com/library/view/natural-language-processing/9781098103231/" rel="nofollow">Oâ€™Reilly book on Transformers</a>.</p>
<p><strong>Leandro von Werra</strong>  Ã© um Engenheiro de Machine Learning no time de open-source na Hugging Face e tambÃ©m co-autor do livro <a href="https://www.oreilly.com/library/view/natural-language-processing/9781098103231/" rel="nofollow">Oâ€™Reilly book on Transformers</a>. Ele tem muitos anos de experiÃªncia na indÃºstria trazendo projetos de NLP para produÃ§Ã£o trabalhando com vÃ¡rias stacks de Machine Learning.</p>
<p>EstÃ¡ pronto para seguir? Nesse capÃ­tulo, vocÃª aprenderÃ¡:</p>
<ul><li>Como usar a funÃ§Ã£o <code>pipeline()</code>  para solucionar tarefas de NLP tais como geraÃ§Ã£o de texto e classificaÃ§Ã£o</li>
<li>Sobre a arquitetura Transformer</li>
<li>Como distinguir entre as arquiteturas encoder, decoder, encoder-decoder e seus casos de uso</li></ul>


		<script type="module" data-hydrate="5x6z0b">
		import { start } from "/docs/course/pr_194/pt/_app/start-3fb4d890.js";
		start({
			target: document.querySelector('[data-hydrate="5x6z0b"]').parentNode,
			paths: {"base":"/docs/course/pr_194/pt","assets":"/docs/course/pr_194/pt"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/course/pr_194/pt/_app/pages/__layout.svelte-20ef27ff.js"),
						import("/docs/course/pr_194/pt/_app/pages/chapter1/1.mdx-1daae04a.js")
				],
				params: {}
			}
		});
	</script>
