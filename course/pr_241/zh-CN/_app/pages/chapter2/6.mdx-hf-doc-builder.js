import{S as Js,i as Us,s as Ks,e as m,k as r,w as _,t as p,l as Ws,M as Qs,c as f,d as s,m as i,x as k,a as h,h as u,b as A,G as a,g as o,y as b,o as d,p as Os,q as g,B as $,v as Vs,n as Ls}from"../../chunks/vendor-hf-doc-builder.js";import{I as Xs}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as j}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as Gs}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as Ys}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function Zs(v){let l,c;return l=new Gs({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter2/section6_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter2/section6_tf.ipynb"}]}}),{c(){_(l.$$.fragment)},l(n){k(l.$$.fragment,n)},m(n,q){b(l,n,q),c=!0},i(n){c||(g(l.$$.fragment,n),c=!0)},o(n){d(l.$$.fragment,n),c=!1},d(n){$(l,n)}}}function et(v){let l,c;return l=new Gs({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter2/section6_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter2/section6_pt.ipynb"}]}}),{c(){_(l.$$.fragment)},l(n){k(l.$$.fragment,n)},m(n,q){b(l,n,q),c=!0},i(n){c||(g(l.$$.fragment,n),c=!0)},o(n){d(l.$$.fragment,n),c=!1},d(n){$(l,n)}}}function st(v){let l,c;return l=new j({props:{code:`import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)
sequences = ["I've been waiting for a HuggingFace course my whole life.", "So have I!"]

tokens = tokenizer(sequences, padding=True, truncation=True, return_tensors="tf")
output = model(**tokens)`,highlighted:`<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)
sequences = [<span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>, <span class="hljs-string">&quot;So have I!&quot;</span>]

tokens = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)
output = model(**tokens)`}}),{c(){_(l.$$.fragment)},l(n){k(l.$$.fragment,n)},m(n,q){b(l,n,q),c=!0},i(n){c||(g(l.$$.fragment,n),c=!0)},o(n){d(l.$$.fragment,n),c=!1},d(n){$(l,n)}}}function tt(v){let l,c;return l=new j({props:{code:`import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
sequences = ["I've been waiting for a HuggingFace course my whole life.", "So have I!"]

tokens = tokenizer(sequences, padding=True, truncation=True, return_tensors="pt")
output = model(**tokens)`,highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
model = AutoModelForSequenceClassification.from_pretrained(checkpoint)
sequences = [<span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>, <span class="hljs-string">&quot;So have I!&quot;</span>]

tokens = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
output = model(**tokens)`}}),{c(){_(l.$$.fragment)},l(n){k(l.$$.fragment,n)},m(n,q){b(l,n,q),c=!0},i(n){c||(g(l.$$.fragment,n),c=!0)},o(n){d(l.$$.fragment,n),c=!1},d(n){$(l,n)}}}function nt(v){let l,c,n,q,D,Ue,be,y,z,V,X,Ke,$e,Y,Qe,qe,C,we,x,Ve,ue,Xe,Ye,je,Z,Ze,ve,H,ye,ee,es,ze,R,Te,se,ss,Ee,B,Ie,te,ts,Se,N,xe,w,ns,ce,os,ls,me,as,rs,fe,is,ps,Fe,M,Pe,S,F,he,W,us,de,cs,Ae,ne,ms,De,O,Ce,L,He,oe,fs,Re,G,Be,J,Ne,I,hs,ge,ds,gs,_e,_s,ks,Me,U,bs,We,le,$s,Oe,T,E,ae,Le;n=new Ys({props:{fw:v[0]}});const qs=[et,Zs],K=[];function ws(e,t){return e[0]==="pt"?0:1}y=ws(v),z=K[y]=qs[y](v),C=new j({props:{code:`from transformers import AutoTokenizer

checkpoint = "distilbert-base-uncased-finetuned-sst-2-english"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

sequence = "I've been waiting for a HuggingFace course my whole life."

model_inputs = tokenizer(sequence)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

sequence = <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>

model_inputs = tokenizer(sequence)`}}),H=new j({props:{code:`sequence = "I've been waiting for a HuggingFace course my whole life."

model_inputs = tokenizer(sequence)`,highlighted:`sequence = <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>

model_inputs = tokenizer(sequence)`}}),R=new j({props:{code:`sequences = ["I've been waiting for a HuggingFace course my whole life.", "So have I!"]

model_inputs = tokenizer(sequences)`,highlighted:`sequences = [<span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>, <span class="hljs-string">&quot;So have I!&quot;</span>]

model_inputs = tokenizer(sequences)`}}),B=new j({props:{code:`# Will pad the sequences up to the maximum sequence length
model_inputs = tokenizer(sequences, padding="longest")

# Will pad the sequences up to the model max length
# (512 for BERT or DistilBERT)
model_inputs = tokenizer(sequences, padding="max_length")

# Will pad the sequences up to the specified max length
model_inputs = tokenizer(sequences, padding="max_length", max_length=8)`,highlighted:`<span class="hljs-comment"># Will pad the sequences up to the maximum sequence length</span>
model_inputs = tokenizer(sequences, padding=<span class="hljs-string">&quot;longest&quot;</span>)

<span class="hljs-comment"># Will pad the sequences up to the model max length</span>
<span class="hljs-comment"># (512 for BERT or DistilBERT)</span>
model_inputs = tokenizer(sequences, padding=<span class="hljs-string">&quot;max_length&quot;</span>)

<span class="hljs-comment"># Will pad the sequences up to the specified max length</span>
model_inputs = tokenizer(sequences, padding=<span class="hljs-string">&quot;max_length&quot;</span>, max_length=<span class="hljs-number">8</span>)`}}),N=new j({props:{code:`sequences = ["I've been waiting for a HuggingFace course my whole life.", "So have I!"]

# Will truncate the sequences that are longer than the model max length
# (512 for BERT or DistilBERT)
model_inputs = tokenizer(sequences, truncation=True)

# Will truncate the sequences that are longer than the specified max length
model_inputs = tokenizer(sequences, max_length=8, truncation=True)`,highlighted:`sequences = [<span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>, <span class="hljs-string">&quot;So have I!&quot;</span>]

<span class="hljs-comment"># Will truncate the sequences that are longer than the model max length</span>
<span class="hljs-comment"># (512 for BERT or DistilBERT)</span>
model_inputs = tokenizer(sequences, truncation=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># Will truncate the sequences that are longer than the specified max length</span>
model_inputs = tokenizer(sequences, max_length=<span class="hljs-number">8</span>, truncation=<span class="hljs-literal">True</span>)`}}),M=new j({props:{code:`sequences = ["I've been waiting for a HuggingFace course my whole life.", "So have I!"]

# Returns PyTorch tensors
model_inputs = tokenizer(sequences, padding=True, return_tensors="pt")

# Returns TensorFlow tensors
model_inputs = tokenizer(sequences, padding=True, return_tensors="tf")

# Returns NumPy arrays
model_inputs = tokenizer(sequences, padding=True, return_tensors="np")`,highlighted:`sequences = [<span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>, <span class="hljs-string">&quot;So have I!&quot;</span>]

<span class="hljs-comment"># Returns PyTorch tensors</span>
model_inputs = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)

<span class="hljs-comment"># Returns TensorFlow tensors</span>
model_inputs = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)

<span class="hljs-comment"># Returns NumPy arrays</span>
model_inputs = tokenizer(sequences, padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;np&quot;</span>)`}}),W=new Xs({}),O=new j({props:{code:`sequence = "I've been waiting for a HuggingFace course my whole life."

model_inputs = tokenizer(sequence)
print(model_inputs["input_ids"])

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)
print(ids)`,highlighted:`sequence = <span class="hljs-string">&quot;I&#x27;ve been waiting for a HuggingFace course my whole life.&quot;</span>

model_inputs = tokenizer(sequence)
<span class="hljs-built_in">print</span>(model_inputs[<span class="hljs-string">&quot;input_ids&quot;</span>])

tokens = tokenizer.tokenize(sequence)
ids = tokenizer.convert_tokens_to_ids(tokens)
<span class="hljs-built_in">print</span>(ids)`}}),L=new j({props:{code:`[101, 1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012, 102]
[1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012]`,highlighted:`[<span class="hljs-number">101</span>, <span class="hljs-number">1045</span>, <span class="hljs-number">1005</span>, <span class="hljs-number">2310</span>, <span class="hljs-number">2042</span>, <span class="hljs-number">3403</span>, <span class="hljs-number">2005</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">17662</span>, <span class="hljs-number">12172</span>, <span class="hljs-number">2607</span>, <span class="hljs-number">2026</span>, <span class="hljs-number">2878</span>, <span class="hljs-number">2166</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>]
[<span class="hljs-number">1045</span>, <span class="hljs-number">1005</span>, <span class="hljs-number">2310</span>, <span class="hljs-number">2042</span>, <span class="hljs-number">3403</span>, <span class="hljs-number">2005</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">17662</span>, <span class="hljs-number">12172</span>, <span class="hljs-number">2607</span>, <span class="hljs-number">2026</span>, <span class="hljs-number">2878</span>, <span class="hljs-number">2166</span>, <span class="hljs-number">1012</span>]`}}),G=new j({props:{code:`print(tokenizer.decode(model_inputs["input_ids"]))
print(tokenizer.decode(ids))`,highlighted:`<span class="hljs-built_in">print</span>(tokenizer.decode(model_inputs[<span class="hljs-string">&quot;input_ids&quot;</span>]))
<span class="hljs-built_in">print</span>(tokenizer.decode(ids))`}}),J=new j({props:{code:`"[CLS] i've been waiting for a huggingface course my whole life. [SEP]"
"i've been waiting for a huggingface course my whole life."`,highlighted:`<span class="hljs-string">&quot;[CLS] i&#x27;ve been waiting for a huggingface course my whole life. [SEP]&quot;</span>
<span class="hljs-string">&quot;i&#x27;ve been waiting for a huggingface course my whole life.&quot;</span>`}});const js=[tt,st],Q=[];function vs(e,t){return e[0]==="pt"?0:1}return T=vs(v),E=Q[T]=js[T](v),{c(){l=m("meta"),c=r(),_(n.$$.fragment),q=r(),D=m("h1"),Ue=p("\u628A\u5B83\u4EEC\u653E\u5728\u4E00\u8D77"),be=r(),z.c(),V=r(),X=m("p"),Ke=p("\u5728\u6700\u540E\u51E0\u8282\u4E2D\uFF0C\u6211\u4EEC\u4E00\u76F4\u5728\u5C3D\u6700\u5927\u52AA\u529B\u624B\u5DE5\u5B8C\u6210\u5927\u90E8\u5206\u5DE5\u4F5C\u3002\u6211\u4EEC\u63A2\u8BA8\u4E86\u6807\u8BB0\u5316\u5668\u7684\u5DE5\u4F5C\u539F\u7406\uFF0C\u5E76\u7814\u7A76\u4E86\u6807\u8BB0\u5316\u3001\u5230\u8F93\u5165ID\u7684\u8F6C\u6362\u3001\u586B\u5145\u3001\u622A\u65AD\u548C\u6CE8\u610F\u63A9\u7801\u3002"),$e=r(),Y=m("p"),Qe=p("\u7136\u800C\uFF0C\u6B63\u5982\u6211\u4EEC\u5728\u7B2C2\u8282\u4E2D\u6240\u770B\u5230\u7684\uFF0C\u{1F917} Transformers API\u53EF\u4EE5\u901A\u8FC7\u4E00\u4E2A\u9AD8\u7EA7\u51FD\u6570\u4E3A\u6211\u4EEC\u5904\u7406\u6240\u6709\u8FD9\u4E9B\uFF0C\u6211\u4EEC\u5C06\u5728\u8FD9\u91CC\u6DF1\u5165\u8BA8\u8BBA\u3002\u5F53\u4F60\u76F4\u63A5\u5728\u53E5\u5B50\u4E0A\u8C03\u7528\u6807\u8BB0\u5668\u65F6\uFF0C\u4F60\u4F1A\u5F97\u5230\u51C6\u5907\u901A\u8FC7\u6A21\u578B\u4F20\u9012\u7684\u8F93\u5165"),qe=r(),_(C.$$.fragment),we=r(),x=m("p"),Ve=p("\u8FD9\u91CC\uFF0C"),ue=m("code"),Xe=p("model_inputs"),Ye=p(`
\u53D8\u91CF\u5305\u542B\u6A21\u578B\u826F\u597D\u8FD0\u884C\u6240\u9700\u7684\u4E00\u5207\u3002\u5BF9\u4E8EDistilBERT\uFF0C\u5B83\u5305\u62EC\u8F93\u5165 ID\u548C\u6CE8\u610F\u529B\u63A9\u7801(attention mask)\u3002\u5176\u4ED6\u63A5\u53D7\u989D\u5916\u8F93\u5165\u7684\u6A21\u578B\u4E5F\u4F1A\u6709\u6807\u8BB0\u5668\u5BF9\u8C61\u7684\u8F93\u51FA\u3002`),je=r(),Z=m("p"),Ze=p("\u6B63\u5982\u6211\u4EEC\u5C06\u5728\u4E0B\u9762\u7684\u4E00\u4E9B\u793A\u4F8B\u4E2D\u770B\u5230\u7684\uFF0C\u8FD9\u79CD\u65B9\u6CD5\u975E\u5E38\u5F3A\u5927\u3002\u9996\u5148\uFF0C\u5B83\u53EF\u4EE5\u6807\u8BB0\u5355\u4E2A\u5E8F\u5217\uFF1A"),ve=r(),_(H.$$.fragment),ye=r(),ee=m("p"),es=p("\u5B83\u8FD8\u4E00\u6B21\u5904\u7406\u591A\u4E2A\u5E8F\u5217\uFF0C\u5E76\u4E14API\u6CA1\u6709\u4EFB\u4F55\u53D8\u5316\uFF1A"),ze=r(),_(R.$$.fragment),Te=r(),se=m("p"),ss=p("\u5B83\u53EF\u4EE5\u6839\u636E\u51E0\u4E2A\u76EE\u6807\u8FDB\u884C\u586B\u5145\uFF1A"),Ee=r(),_(B.$$.fragment),Ie=r(),te=m("p"),ts=p("\u5B83\u8FD8\u53EF\u4EE5\u622A\u65AD\u5E8F\u5217:"),Se=r(),_(N.$$.fragment),xe=r(),w=m("p"),ns=p("\u6807\u8BB0\u5668\u5BF9\u8C61\u53EF\u4EE5\u5904\u7406\u5230\u7279\u5B9A\u6846\u67B6\u5F20\u91CF\u7684\u8F6C\u6362\uFF0C\u7136\u540E\u53EF\u4EE5\u76F4\u63A5\u53D1\u9001\u5230\u6A21\u578B\u3002\u4F8B\u5982\uFF0C\u5728\u4E0B\u9762\u7684\u4EE3\u7801\u793A\u4F8B\u4E2D\uFF0C\u6211\u4EEC\u63D0\u793A\u6807\u8BB0\u5668\u4ECE\u4E0D\u540C\u7684\u6846\u67B6\u8FD4\u56DE\u5F20\u91CF\u2014\u2014"),ce=m("code"),os=p('"pt"'),ls=p("\u8FD4\u56DEPy Torch\u5F20\u91CF\uFF0C"),me=m("code"),as=p('"tf"'),rs=p("\u8FD4\u56DETensorFlow\u5F20\u91CF\uFF0C"),fe=m("code"),is=p('"np"'),ps=p("\u8FD4\u56DENumPy\u6570\u7EC4\uFF1A"),Fe=r(),_(M.$$.fragment),Pe=r(),S=m("h2"),F=m("a"),he=m("span"),_(W.$$.fragment),us=r(),de=m("span"),cs=p("\u7279\u6B8A\u8BCD\u7B26(token)"),Ae=r(),ne=m("p"),ms=p("\u5982\u679C\u6211\u4EEC\u770B\u4E00\u4E0B\u6807\u8BB0\u5668\u8FD4\u56DE\u7684\u8F93\u5165 ID\uFF0C\u6211\u4EEC\u4F1A\u53D1\u73B0\u5B83\u4EEC\u4E0E\u4E4B\u524D\u7684\u7565\u6709\u4E0D\u540C\uFF1A"),De=r(),_(O.$$.fragment),Ce=r(),_(L.$$.fragment),He=r(),oe=m("p"),fs=p("\u4E00\u4E2A\u5728\u5F00\u59CB\u65F6\u6DFB\u52A0\u4E86\u4E00\u4E2A\u6807\u8BB0(token) ID\uFF0C\u4E00\u4E2A\u5728\u7ED3\u675F\u65F6\u6DFB\u52A0\u4E86\u4E00\u4E2A\u6807\u8BB0(token) ID\u3002\u8BA9\u6211\u4EEC\u89E3\u7801\u4E0A\u9762\u7684\u4E24\u4E2AID\u5E8F\u5217\uFF0C\u770B\u770B\u8FD9\u662F\u600E\u4E48\u56DE\u4E8B\uFF1A"),Re=r(),_(G.$$.fragment),Be=r(),_(J.$$.fragment),Ne=r(),I=m("p"),hs=p("\u6807\u8BB0\u5668\u5728\u5F00\u5934\u6DFB\u52A0\u4E86\u7279\u6B8A\u5355\u8BCD"),ge=m("code"),ds=p("[CLS]"),gs=p("\uFF0C\u5728\u7ED3\u5C3E\u6DFB\u52A0\u4E86\u7279\u6B8A\u5355\u8BCD"),_e=m("code"),_s=p("[SEP]"),ks=p("\u3002\u8FD9\u662F\u56E0\u4E3A\u6A21\u578B\u662F\u7528\u8FD9\u4E9B\u6570\u636E\u9884\u8BAD\u7EC3\u7684\uFF0C\u6240\u4EE5\u4E3A\u4E86\u5F97\u5230\u76F8\u540C\u7684\u63A8\u7406\u7ED3\u679C\uFF0C\u6211\u4EEC\u8FD8\u9700\u8981\u6DFB\u52A0\u5B83\u4EEC\u3002\u8BF7\u6CE8\u610F\uFF0C\u6709\u4E9B\u6A21\u578B\u4E0D\u6DFB\u52A0\u7279\u6B8A\u5355\u8BCD\uFF0C\u6216\u8005\u6DFB\u52A0\u4E0D\u540C\u7684\u5355\u8BCD\uFF1B\u6A21\u578B\u4E5F\u53EF\u80FD\u53EA\u5728\u5F00\u5934\u6216\u7ED3\u5C3E\u6DFB\u52A0\u8FD9\u4E9B\u7279\u6B8A\u5355\u8BCD\u3002\u5728\u4EFB\u4F55\u60C5\u51B5\u4E0B\uFF0C\u6807\u8BB0\u5668\u90FD\u77E5\u9053\u9700\u8981\u54EA\u4E9B\u8BCD\u7B26\uFF0C\u5E76\u5C06\u4E3A\u60A8\u5904\u7406\u8FD9\u4E9B\u8BCD\u7B26\u3002"),Me=r(),U=m("h2"),bs=p("\u7ED3\u675F\uFF1A\u4ECE\u6807\u8BB0\u5668\u5230\u6A21\u578B"),We=r(),le=m("p"),$s=p("\u73B0\u5728\u6211\u4EEC\u5DF2\u7ECF\u770B\u5230\u4E86\u6807\u8BB0\u5668\u5BF9\u8C61\u5728\u5E94\u7528\u4E8E\u6587\u672C\u65F6\u4F7F\u7528\u7684\u6240\u6709\u5355\u72EC\u6B65\u9AA4\uFF0C\u8BA9\u6211\u4EEC\u6700\u540E\u4E00\u6B21\u770B\u770B\u5B83\u5982\u4F55\u5904\u7406\u591A\u4E2A\u5E8F\u5217\uFF08\u586B\u5145\uFF01\uFF09\uFF0C\u975E\u5E38\u957F\u7684\u5E8F\u5217\uFF08\u622A\u65AD\uFF01\uFF09\uFF0C\u4EE5\u53CA\u591A\u79CD\u7C7B\u578B\u7684\u5F20\u91CF\u53CA\u5176\u4E3B\u8981API\uFF1A"),Oe=r(),E.c(),ae=Ws(),this.h()},l(e){const t=Qs('[data-svelte="svelte-1phssyn"]',document.head);l=f(t,"META",{name:!0,content:!0}),t.forEach(s),c=i(e),k(n.$$.fragment,e),q=i(e),D=f(e,"H1",{id:!0});var ke=h(D);Ue=u(ke,"\u628A\u5B83\u4EEC\u653E\u5728\u4E00\u8D77"),ke.forEach(s),be=i(e),z.l(e),V=i(e),X=f(e,"P",{});var re=h(X);Ke=u(re,"\u5728\u6700\u540E\u51E0\u8282\u4E2D\uFF0C\u6211\u4EEC\u4E00\u76F4\u5728\u5C3D\u6700\u5927\u52AA\u529B\u624B\u5DE5\u5B8C\u6210\u5927\u90E8\u5206\u5DE5\u4F5C\u3002\u6211\u4EEC\u63A2\u8BA8\u4E86\u6807\u8BB0\u5316\u5668\u7684\u5DE5\u4F5C\u539F\u7406\uFF0C\u5E76\u7814\u7A76\u4E86\u6807\u8BB0\u5316\u3001\u5230\u8F93\u5165ID\u7684\u8F6C\u6362\u3001\u586B\u5145\u3001\u622A\u65AD\u548C\u6CE8\u610F\u63A9\u7801\u3002"),re.forEach(s),$e=i(e),Y=f(e,"P",{});var ie=h(Y);Qe=u(ie,"\u7136\u800C\uFF0C\u6B63\u5982\u6211\u4EEC\u5728\u7B2C2\u8282\u4E2D\u6240\u770B\u5230\u7684\uFF0C\u{1F917} Transformers API\u53EF\u4EE5\u901A\u8FC7\u4E00\u4E2A\u9AD8\u7EA7\u51FD\u6570\u4E3A\u6211\u4EEC\u5904\u7406\u6240\u6709\u8FD9\u4E9B\uFF0C\u6211\u4EEC\u5C06\u5728\u8FD9\u91CC\u6DF1\u5165\u8BA8\u8BBA\u3002\u5F53\u4F60\u76F4\u63A5\u5728\u53E5\u5B50\u4E0A\u8C03\u7528\u6807\u8BB0\u5668\u65F6\uFF0C\u4F60\u4F1A\u5F97\u5230\u51C6\u5907\u901A\u8FC7\u6A21\u578B\u4F20\u9012\u7684\u8F93\u5165"),ie.forEach(s),qe=i(e),k(C.$$.fragment,e),we=i(e),x=f(e,"P",{});var Ge=h(x);Ve=u(Ge,"\u8FD9\u91CC\uFF0C"),ue=f(Ge,"CODE",{});var ys=h(ue);Xe=u(ys,"model_inputs"),ys.forEach(s),Ye=u(Ge,`
\u53D8\u91CF\u5305\u542B\u6A21\u578B\u826F\u597D\u8FD0\u884C\u6240\u9700\u7684\u4E00\u5207\u3002\u5BF9\u4E8EDistilBERT\uFF0C\u5B83\u5305\u62EC\u8F93\u5165 ID\u548C\u6CE8\u610F\u529B\u63A9\u7801(attention mask)\u3002\u5176\u4ED6\u63A5\u53D7\u989D\u5916\u8F93\u5165\u7684\u6A21\u578B\u4E5F\u4F1A\u6709\u6807\u8BB0\u5668\u5BF9\u8C61\u7684\u8F93\u51FA\u3002`),Ge.forEach(s),je=i(e),Z=f(e,"P",{});var zs=h(Z);Ze=u(zs,"\u6B63\u5982\u6211\u4EEC\u5C06\u5728\u4E0B\u9762\u7684\u4E00\u4E9B\u793A\u4F8B\u4E2D\u770B\u5230\u7684\uFF0C\u8FD9\u79CD\u65B9\u6CD5\u975E\u5E38\u5F3A\u5927\u3002\u9996\u5148\uFF0C\u5B83\u53EF\u4EE5\u6807\u8BB0\u5355\u4E2A\u5E8F\u5217\uFF1A"),zs.forEach(s),ve=i(e),k(H.$$.fragment,e),ye=i(e),ee=f(e,"P",{});var Ts=h(ee);es=u(Ts,"\u5B83\u8FD8\u4E00\u6B21\u5904\u7406\u591A\u4E2A\u5E8F\u5217\uFF0C\u5E76\u4E14API\u6CA1\u6709\u4EFB\u4F55\u53D8\u5316\uFF1A"),Ts.forEach(s),ze=i(e),k(R.$$.fragment,e),Te=i(e),se=f(e,"P",{});var Es=h(se);ss=u(Es,"\u5B83\u53EF\u4EE5\u6839\u636E\u51E0\u4E2A\u76EE\u6807\u8FDB\u884C\u586B\u5145\uFF1A"),Es.forEach(s),Ee=i(e),k(B.$$.fragment,e),Ie=i(e),te=f(e,"P",{});var Is=h(te);ts=u(Is,"\u5B83\u8FD8\u53EF\u4EE5\u622A\u65AD\u5E8F\u5217:"),Is.forEach(s),Se=i(e),k(N.$$.fragment,e),xe=i(e),w=f(e,"P",{});var P=h(w);ns=u(P,"\u6807\u8BB0\u5668\u5BF9\u8C61\u53EF\u4EE5\u5904\u7406\u5230\u7279\u5B9A\u6846\u67B6\u5F20\u91CF\u7684\u8F6C\u6362\uFF0C\u7136\u540E\u53EF\u4EE5\u76F4\u63A5\u53D1\u9001\u5230\u6A21\u578B\u3002\u4F8B\u5982\uFF0C\u5728\u4E0B\u9762\u7684\u4EE3\u7801\u793A\u4F8B\u4E2D\uFF0C\u6211\u4EEC\u63D0\u793A\u6807\u8BB0\u5668\u4ECE\u4E0D\u540C\u7684\u6846\u67B6\u8FD4\u56DE\u5F20\u91CF\u2014\u2014"),ce=f(P,"CODE",{});var Ss=h(ce);os=u(Ss,'"pt"'),Ss.forEach(s),ls=u(P,"\u8FD4\u56DEPy Torch\u5F20\u91CF\uFF0C"),me=f(P,"CODE",{});var xs=h(me);as=u(xs,'"tf"'),xs.forEach(s),rs=u(P,"\u8FD4\u56DETensorFlow\u5F20\u91CF\uFF0C"),fe=f(P,"CODE",{});var Fs=h(fe);is=u(Fs,'"np"'),Fs.forEach(s),ps=u(P,"\u8FD4\u56DENumPy\u6570\u7EC4\uFF1A"),P.forEach(s),Fe=i(e),k(M.$$.fragment,e),Pe=i(e),S=f(e,"H2",{class:!0});var Je=h(S);F=f(Je,"A",{id:!0,class:!0,href:!0});var Ps=h(F);he=f(Ps,"SPAN",{});var As=h(he);k(W.$$.fragment,As),As.forEach(s),Ps.forEach(s),us=i(Je),de=f(Je,"SPAN",{});var Ds=h(de);cs=u(Ds,"\u7279\u6B8A\u8BCD\u7B26(token)"),Ds.forEach(s),Je.forEach(s),Ae=i(e),ne=f(e,"P",{});var Cs=h(ne);ms=u(Cs,"\u5982\u679C\u6211\u4EEC\u770B\u4E00\u4E0B\u6807\u8BB0\u5668\u8FD4\u56DE\u7684\u8F93\u5165 ID\uFF0C\u6211\u4EEC\u4F1A\u53D1\u73B0\u5B83\u4EEC\u4E0E\u4E4B\u524D\u7684\u7565\u6709\u4E0D\u540C\uFF1A"),Cs.forEach(s),De=i(e),k(O.$$.fragment,e),Ce=i(e),k(L.$$.fragment,e),He=i(e),oe=f(e,"P",{});var Hs=h(oe);fs=u(Hs,"\u4E00\u4E2A\u5728\u5F00\u59CB\u65F6\u6DFB\u52A0\u4E86\u4E00\u4E2A\u6807\u8BB0(token) ID\uFF0C\u4E00\u4E2A\u5728\u7ED3\u675F\u65F6\u6DFB\u52A0\u4E86\u4E00\u4E2A\u6807\u8BB0(token) ID\u3002\u8BA9\u6211\u4EEC\u89E3\u7801\u4E0A\u9762\u7684\u4E24\u4E2AID\u5E8F\u5217\uFF0C\u770B\u770B\u8FD9\u662F\u600E\u4E48\u56DE\u4E8B\uFF1A"),Hs.forEach(s),Re=i(e),k(G.$$.fragment,e),Be=i(e),k(J.$$.fragment,e),Ne=i(e),I=f(e,"P",{});var pe=h(I);hs=u(pe,"\u6807\u8BB0\u5668\u5728\u5F00\u5934\u6DFB\u52A0\u4E86\u7279\u6B8A\u5355\u8BCD"),ge=f(pe,"CODE",{});var Rs=h(ge);ds=u(Rs,"[CLS]"),Rs.forEach(s),gs=u(pe,"\uFF0C\u5728\u7ED3\u5C3E\u6DFB\u52A0\u4E86\u7279\u6B8A\u5355\u8BCD"),_e=f(pe,"CODE",{});var Bs=h(_e);_s=u(Bs,"[SEP]"),Bs.forEach(s),ks=u(pe,"\u3002\u8FD9\u662F\u56E0\u4E3A\u6A21\u578B\u662F\u7528\u8FD9\u4E9B\u6570\u636E\u9884\u8BAD\u7EC3\u7684\uFF0C\u6240\u4EE5\u4E3A\u4E86\u5F97\u5230\u76F8\u540C\u7684\u63A8\u7406\u7ED3\u679C\uFF0C\u6211\u4EEC\u8FD8\u9700\u8981\u6DFB\u52A0\u5B83\u4EEC\u3002\u8BF7\u6CE8\u610F\uFF0C\u6709\u4E9B\u6A21\u578B\u4E0D\u6DFB\u52A0\u7279\u6B8A\u5355\u8BCD\uFF0C\u6216\u8005\u6DFB\u52A0\u4E0D\u540C\u7684\u5355\u8BCD\uFF1B\u6A21\u578B\u4E5F\u53EF\u80FD\u53EA\u5728\u5F00\u5934\u6216\u7ED3\u5C3E\u6DFB\u52A0\u8FD9\u4E9B\u7279\u6B8A\u5355\u8BCD\u3002\u5728\u4EFB\u4F55\u60C5\u51B5\u4E0B\uFF0C\u6807\u8BB0\u5668\u90FD\u77E5\u9053\u9700\u8981\u54EA\u4E9B\u8BCD\u7B26\uFF0C\u5E76\u5C06\u4E3A\u60A8\u5904\u7406\u8FD9\u4E9B\u8BCD\u7B26\u3002"),pe.forEach(s),Me=i(e),U=f(e,"H2",{id:!0});var Ns=h(U);bs=u(Ns,"\u7ED3\u675F\uFF1A\u4ECE\u6807\u8BB0\u5668\u5230\u6A21\u578B"),Ns.forEach(s),We=i(e),le=f(e,"P",{});var Ms=h(le);$s=u(Ms,"\u73B0\u5728\u6211\u4EEC\u5DF2\u7ECF\u770B\u5230\u4E86\u6807\u8BB0\u5668\u5BF9\u8C61\u5728\u5E94\u7528\u4E8E\u6587\u672C\u65F6\u4F7F\u7528\u7684\u6240\u6709\u5355\u72EC\u6B65\u9AA4\uFF0C\u8BA9\u6211\u4EEC\u6700\u540E\u4E00\u6B21\u770B\u770B\u5B83\u5982\u4F55\u5904\u7406\u591A\u4E2A\u5E8F\u5217\uFF08\u586B\u5145\uFF01\uFF09\uFF0C\u975E\u5E38\u957F\u7684\u5E8F\u5217\uFF08\u622A\u65AD\uFF01\uFF09\uFF0C\u4EE5\u53CA\u591A\u79CD\u7C7B\u578B\u7684\u5F20\u91CF\u53CA\u5176\u4E3B\u8981API\uFF1A"),Ms.forEach(s),Oe=i(e),E.l(e),ae=Ws(),this.h()},h(){A(l,"name","hf:doc:metadata"),A(l,"content",JSON.stringify(ot)),A(D,"id",""),A(F,"id","token"),A(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),A(F,"href","#token"),A(S,"class","relative group"),A(U,"id","")},m(e,t){a(document.head,l),o(e,c,t),b(n,e,t),o(e,q,t),o(e,D,t),a(D,Ue),o(e,be,t),K[y].m(e,t),o(e,V,t),o(e,X,t),a(X,Ke),o(e,$e,t),o(e,Y,t),a(Y,Qe),o(e,qe,t),b(C,e,t),o(e,we,t),o(e,x,t),a(x,Ve),a(x,ue),a(ue,Xe),a(x,Ye),o(e,je,t),o(e,Z,t),a(Z,Ze),o(e,ve,t),b(H,e,t),o(e,ye,t),o(e,ee,t),a(ee,es),o(e,ze,t),b(R,e,t),o(e,Te,t),o(e,se,t),a(se,ss),o(e,Ee,t),b(B,e,t),o(e,Ie,t),o(e,te,t),a(te,ts),o(e,Se,t),b(N,e,t),o(e,xe,t),o(e,w,t),a(w,ns),a(w,ce),a(ce,os),a(w,ls),a(w,me),a(me,as),a(w,rs),a(w,fe),a(fe,is),a(w,ps),o(e,Fe,t),b(M,e,t),o(e,Pe,t),o(e,S,t),a(S,F),a(F,he),b(W,he,null),a(S,us),a(S,de),a(de,cs),o(e,Ae,t),o(e,ne,t),a(ne,ms),o(e,De,t),b(O,e,t),o(e,Ce,t),b(L,e,t),o(e,He,t),o(e,oe,t),a(oe,fs),o(e,Re,t),b(G,e,t),o(e,Be,t),b(J,e,t),o(e,Ne,t),o(e,I,t),a(I,hs),a(I,ge),a(ge,ds),a(I,gs),a(I,_e),a(_e,_s),a(I,ks),o(e,Me,t),o(e,U,t),a(U,bs),o(e,We,t),o(e,le,t),a(le,$s),o(e,Oe,t),Q[T].m(e,t),o(e,ae,t),Le=!0},p(e,[t]){const ke={};t&1&&(ke.fw=e[0]),n.$set(ke);let re=y;y=ws(e),y!==re&&(Ls(),d(K[re],1,1,()=>{K[re]=null}),Os(),z=K[y],z||(z=K[y]=qs[y](e),z.c()),g(z,1),z.m(V.parentNode,V));let ie=T;T=vs(e),T!==ie&&(Ls(),d(Q[ie],1,1,()=>{Q[ie]=null}),Os(),E=Q[T],E||(E=Q[T]=js[T](e),E.c()),g(E,1),E.m(ae.parentNode,ae))},i(e){Le||(g(n.$$.fragment,e),g(z),g(C.$$.fragment,e),g(H.$$.fragment,e),g(R.$$.fragment,e),g(B.$$.fragment,e),g(N.$$.fragment,e),g(M.$$.fragment,e),g(W.$$.fragment,e),g(O.$$.fragment,e),g(L.$$.fragment,e),g(G.$$.fragment,e),g(J.$$.fragment,e),g(E),Le=!0)},o(e){d(n.$$.fragment,e),d(z),d(C.$$.fragment,e),d(H.$$.fragment,e),d(R.$$.fragment,e),d(B.$$.fragment,e),d(N.$$.fragment,e),d(M.$$.fragment,e),d(W.$$.fragment,e),d(O.$$.fragment,e),d(L.$$.fragment,e),d(G.$$.fragment,e),d(J.$$.fragment,e),d(E),Le=!1},d(e){s(l),e&&s(c),$(n,e),e&&s(q),e&&s(D),e&&s(be),K[y].d(e),e&&s(V),e&&s(X),e&&s($e),e&&s(Y),e&&s(qe),$(C,e),e&&s(we),e&&s(x),e&&s(je),e&&s(Z),e&&s(ve),$(H,e),e&&s(ye),e&&s(ee),e&&s(ze),$(R,e),e&&s(Te),e&&s(se),e&&s(Ee),$(B,e),e&&s(Ie),e&&s(te),e&&s(Se),$(N,e),e&&s(xe),e&&s(w),e&&s(Fe),$(M,e),e&&s(Pe),e&&s(S),$(W),e&&s(Ae),e&&s(ne),e&&s(De),$(O,e),e&&s(Ce),$(L,e),e&&s(He),e&&s(oe),e&&s(Re),$(G,e),e&&s(Be),$(J,e),e&&s(Ne),e&&s(I),e&&s(Me),e&&s(U),e&&s(We),e&&s(le),e&&s(Oe),Q[T].d(e),e&&s(ae)}}}const ot={local:"",sections:[{local:"token",title:"\u7279\u6B8A\u8BCD\u7B26(token)"},{local:"",title:"\u7ED3\u675F\uFF1A\u4ECE\u6807\u8BB0\u5668\u5230\u6A21\u578B"}],title:"\u628A\u5B83\u4EEC\u653E\u5728\u4E00\u8D77"};function lt(v,l,c){let n="pt";return Vs(()=>{const q=new URLSearchParams(window.location.search);c(0,n=q.get("fw")||"pt")}),[n]}class ct extends Js{constructor(l){super();Us(this,l,lt,nt,Ks,{})}}export{ct as default,ot as metadata};
