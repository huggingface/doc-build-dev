import{S as $e,i as Ge,s as Be,e as r,k as u,w as Me,t as o,M as Ne,c as s,d as a,m,a as n,x as qe,h as i,b as g,G as t,g as c,y as De,L as Oe,q as Ue,o as He,B as Je,v as Re}from"../../chunks/vendor-hf-doc-builder.js";import{I as je}from"../../chunks/IconCopyLink-hf-doc-builder.js";function ze(ve){let v,q,y,_,L,b,z,A,F,D,d,K,I,Q,V,S,W,X,O,x,Y,U,f,$,Z,ee,G,te,ae,B,oe,ie,M,re,H,h,se,N,ne,le,E,he,fe,k,ce,de,T,pe,ue,J,C,me,R;return b=new je({}),{c(){v=r("meta"),q=u(),y=r("h1"),_=r("a"),L=r("span"),Me(b.$$.fragment),z=u(),A=r("span"),F=o("Going beyond text"),D=u(),d=r("p"),K=o("So far in this course, we\u2019ve seen that Transformers are exceptionally good at tackling a wide variety of tasks in NLP. But did you know that Transformers can also be applied to entirely different "),I=r("em"),Q=o("modalities"),V=o(" like audio and images? In this chapter, we will explore how Transformers can process "),S=r("em"),W=o("audio waveforms"),X=o(" to produce novel applications like speech recognition."),O=u(),x=r("p"),Y=o("After explaining why Transformers might be suitable for audio, each of the sections in this chapter will dive into some of the most common tasks in this fast-moving field:"),U=u(),f=r("ul"),$=r("li"),Z=o("Classifying audio signals into a set of categories."),ee=u(),G=r("li"),te=o("Transcribing speech to text"),ae=u(),B=r("li"),oe=o("Converting text to speech"),ie=u(),M=r("li"),re=o("Bypassing text altogether and converting audio to audio"),H=u(),h=r("p"),se=o("To do this, you\u2019ll need to leverage everything you learned about the "),N=r("code"),ne=o("Trainer"),le=o(" API library in "),E=r("a"),he=o("Chapter 3"),fe=o(", the \u{1F917} Datasets library in "),k=r("a"),ce=o("Chapter 5"),de=o(", and the Gradio library in "),T=r("a"),pe=o("Chapter 9"),ue=o(". So go read those chapters first if you haven\u2019t done so already."),J=u(),C=r("p"),me=o("Let\u2019s now dive into the fascinating world of audio!"),this.h()},l(e){const l=Ne('[data-svelte="svelte-1phssyn"]',document.head);v=s(l,"META",{name:!0,content:!0}),l.forEach(a),q=m(e),y=s(e,"H1",{class:!0});var j=n(y);_=s(j,"A",{id:!0,class:!0,href:!0});var ye=n(_);L=s(ye,"SPAN",{});var ge=n(L);qe(b.$$.fragment,ge),ge.forEach(a),ye.forEach(a),z=m(j),A=s(j,"SPAN",{});var _e=n(A);F=i(_e,"Going beyond text"),_e.forEach(a),j.forEach(a),D=m(e),d=s(e,"P",{});var P=n(d);K=i(P,"So far in this course, we\u2019ve seen that Transformers are exceptionally good at tackling a wide variety of tasks in NLP. But did you know that Transformers can also be applied to entirely different "),I=s(P,"EM",{});var we=n(I);Q=i(we,"modalities"),we.forEach(a),V=i(P," like audio and images? In this chapter, we will explore how Transformers can process "),S=s(P,"EM",{});var be=n(S);W=i(be,"audio waveforms"),be.forEach(a),X=i(P," to produce novel applications like speech recognition."),P.forEach(a),O=m(e),x=s(e,"P",{});var xe=n(x);Y=i(xe,"After explaining why Transformers might be suitable for audio, each of the sections in this chapter will dive into some of the most common tasks in this fast-moving field:"),xe.forEach(a),U=m(e),f=s(e,"UL",{});var w=n(f);$=s(w,"LI",{});var Ee=n($);Z=i(Ee,"Classifying audio signals into a set of categories."),Ee.forEach(a),ee=m(w),G=s(w,"LI",{});var ke=n(G);te=i(ke,"Transcribing speech to text"),ke.forEach(a),ae=m(w),B=s(w,"LI",{});var Te=n(B);oe=i(Te,"Converting text to speech"),Te.forEach(a),ie=m(w),M=s(w,"LI",{});var Ce=n(M);re=i(Ce,"Bypassing text altogether and converting audio to audio"),Ce.forEach(a),w.forEach(a),H=m(e),h=s(e,"P",{});var p=n(h);se=i(p,"To do this, you\u2019ll need to leverage everything you learned about the "),N=s(p,"CODE",{});var Pe=n(N);ne=i(Pe,"Trainer"),Pe.forEach(a),le=i(p," API library in "),E=s(p,"A",{href:!0});var Le=n(E);he=i(Le,"Chapter 3"),Le.forEach(a),fe=i(p,", the \u{1F917} Datasets library in "),k=s(p,"A",{href:!0});var Ae=n(k);ce=i(Ae,"Chapter 5"),Ae.forEach(a),de=i(p,", and the Gradio library in "),T=s(p,"A",{href:!0});var Ie=n(T);pe=i(Ie,"Chapter 9"),Ie.forEach(a),ue=i(p,". So go read those chapters first if you haven\u2019t done so already."),p.forEach(a),J=m(e),C=s(e,"P",{});var Se=n(C);me=i(Se,"Let\u2019s now dive into the fascinating world of audio!"),Se.forEach(a),this.h()},h(){g(v,"name","hf:doc:metadata"),g(v,"content",JSON.stringify(Fe)),g(_,"id","going-beyond-text"),g(_,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),g(_,"href","#going-beyond-text"),g(y,"class","relative group"),g(E,"href","/course/chapter3"),g(k,"href","/course/chapter5"),g(T,"href","/course/chapter9")},m(e,l){t(document.head,v),c(e,q,l),c(e,y,l),t(y,_),t(_,L),De(b,L,null),t(y,z),t(y,A),t(A,F),c(e,D,l),c(e,d,l),t(d,K),t(d,I),t(I,Q),t(d,V),t(d,S),t(S,W),t(d,X),c(e,O,l),c(e,x,l),t(x,Y),c(e,U,l),c(e,f,l),t(f,$),t($,Z),t(f,ee),t(f,G),t(G,te),t(f,ae),t(f,B),t(B,oe),t(f,ie),t(f,M),t(M,re),c(e,H,l),c(e,h,l),t(h,se),t(h,N),t(N,ne),t(h,le),t(h,E),t(E,he),t(h,fe),t(h,k),t(k,ce),t(h,de),t(h,T),t(T,pe),t(h,ue),c(e,J,l),c(e,C,l),t(C,me),R=!0},p:Oe,i(e){R||(Ue(b.$$.fragment,e),R=!0)},o(e){He(b.$$.fragment,e),R=!1},d(e){a(v),e&&a(q),e&&a(y),Je(b),e&&a(D),e&&a(d),e&&a(O),e&&a(x),e&&a(U),e&&a(f),e&&a(H),e&&a(h),e&&a(J),e&&a(C)}}}const Fe={local:"going-beyond-text",title:"Going beyond text"};function Ke(ve){return Re(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class We extends $e{constructor(v){super();Ge(this,v,Ke,ze,Be,{})}}export{We as default,Fe as metadata};
