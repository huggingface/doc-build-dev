import{S as ri,i as ai,s as oi,e as i,k as u,w as m,t as d,M as li,c as s,d as t,m as p,a as r,x as f,h as c,b as o,F as n,g as l,y as h,L as ui,q as v,o as $,B as g,v as pi}from"../../chunks/vendor-1e8b365d.js";import{I as x}from"../../chunks/IconCopyLink-483c28ba.js";import{Q as q}from"../../chunks/Question-31426fe2.js";function di(wn){let k,Ve,z,Q,ze,V,It,we,Qt,Re,qe,Lt,Fe,w,L,_e,R,Ut,F,Ht,Ee,Bt,Wt,Ge,G,Je,_,U,ye,J,jt,K,Dt,be,Ot,Tt,Ke,X,Xe,E,H,Pe,Y,Mt,Z,Vt,Ce,Rt,Ft,Ye,ee,Ze,y,B,Ae,te,Gt,b,Jt,Se,Kt,Xt,Ne,Yt,Zt,et,ne,tt,P,W,Ie,ie,en,se,tn,Qe,nn,sn,nt,re,it,C,j,Le,ae,rn,Ue,an,st,oe,rt,A,D,He,le,on,ue,ln,Be,un,pn,at,pe,ot,S,O,We,de,dn,ce,cn,je,mn,fn,lt,me,ut,N,T,De,fe,hn,he,vn,Oe,$n,gn,pt,ve,dt,I,M,Te,$e,xn,ge,qn,Me,kn,zn,ct,xe,mt;return V=new x({}),R=new x({}),G=new q({props:{choices:[{text:"Lorsque votre jeu de donn\xE9es est similaire \xE0 celui utilis\xE9 par un mod\xE8le pr\xE9-entra\xEEn\xE9 existant et que vous voulez pr\xE9-entra\xEEner un nouveau mod\xE8le",explain:"Dans ce cas, pour \xE9conomiser du temps et des ressources de calcul, il est pr\xE9f\xE9rable d'utiliser le m\xEAme <i>tokenizer</i> que le mod\xE8le pr\xE9-entra\xEEn\xE9 et de <i>finetuner</i> ce mod\xE8le \xE0 la place."},{text:"Lorsque votre jeu de donn\xE9es est similaire \xE0 celui utilis\xE9 par un mod\xE8le pr\xE9-entra\xEEn\xE9 existant et que vous souhaitez <i>finetuner</i> un nouveau mod\xE8le en utilisant ce mod\xE8le pr\xE9-entra\xEEn\xE9.",explain:"Pour <i>finetuner</i> un mod\xE8le \xE0 partir d'un mod\xE8le pr\xE9-entra\xEEn\xE9, vous devez toujours utiliser le m\xEAme <i>tokenizer</i>."},{text:"Lorsque votre jeu de donn\xE9es est diff\xE9rent de celui utilis\xE9 par un mod\xE8le pr\xE9-entra\xEEn\xE9 existant et que vous souhaitez pr\xE9-entra\xEEner un nouveau mod\xE8le.",explain:"Dans ce cas, il n'y a aucun avantage \xE0 utiliser le m\xEAme <i>tokenizer</i>.",correct:!0},{text:"Lorsque votre jeu de donn\xE9es est diff\xE9rent de celui utilis\xE9 par un mod\xE8le pr\xE9-entra\xEEn\xE9 existant mais que vous souhaitez <i>finetuner</i> un nouveau mod\xE8le en utilisant ce mod\xE8le pr\xE9-entra\xEEn\xE9.",explain:"Pour <i>finetuner</i> un mod\xE8le \xE0 partir d'un mod\xE8le pr\xE9-entra\xEEn\xE9, vous devez toujours utiliser le m\xEAme <i>tokenizer</i>."}]}}),J=new x({}),X=new q({props:{choices:[{text:"C'est le seul type que la m\xE9thode <code>train_new_from_iterator()</code> accepte.",explain:"Une liste de listes de textes est un type particulier de g\xE9n\xE9rateur de listes de textes, la m\xE9thode l'acceptera donc aussi. Essayez \xE0 nouveau !"},{text:"Vous \xE9viterez de charger l'ensemble des donn\xE9es en m\xE9moire en une seule fois.",explain:"Chaque batch de textes sera lib\xE9r\xE9 de la m\xE9moire lorsque vous it\xE9rerez et le gain sera particuli\xE8rement visible si vous utilisez des \u{1F917} <i>Datasets</i> pour stocker vos textes.",correct:!0},{text:"Cela permettra \xE0 la biblioth\xE8que \u{1F917} <i>Tokenizers</i> d'utiliser le multitraitement.",explain:"Il utilisera le multiprocesseur dans tous les cas."},{text:"Le <i>tokenizer</i> que vous entra\xEEnez g\xE9n\xE9rera de meilleurs textes.",explain:"Le <i>tokenizer</i> ne g\xE9n\xE8re pas de texte. Vous le confondez avec un mod\xE8le de langage ?"}]}}),Y=new x({}),ee=new q({props:{choices:[{text:"Il peut traiter les entr\xE9es plus rapidement qu'un <i>tokenizer</i> lent lorsque vous faites des batchs d'entr\xE9es.",explain:"Gr\xE2ce au parall\xE9lisme impl\xE9ment\xE9 dans Rust, il sera plus rapide sur les batchs d'entr\xE9es. Quel autre avantage pouvez-vous imaginer ?",correct:!0},{text:"Les *tokenizers* rapides sont toujours plus rapides que leurs homologues lents.",explain:"Un <i>tokenizer</i> rapide peut en fait \xEAtre plus lent si vous ne lui donnez qu'un seul ou tr\xE8s peu de textes, car il ne peut pas utiliser le parall\xE9lisme."},{text:"Il peut appliquer le <i>padding</i> et la troncature.",explain:"C'est vrai, mais les <i>tokenizers</i> lents le font aussi."},{text:"Il poss\xE8de des fonctionnalit\xE9s suppl\xE9mentaires qui vous permettent d'associer les <i>tokens</i> \xE0 l'extrait de texte qui les a cr\xE9\xE9s.",explain:"En effet, c'est ce qu'on appelle des correspondances d'<i>offset</i>. Ce n'est pas le seul avantage, cependant.",correct:!0}]}}),te=new x({}),ne=new q({props:{choices:[{text:"Les entit\xE9s ayant la m\xEAme \xE9tiquette sont fusionn\xE9es en une seule entit\xE9.",explain:"C'est un peu trop simplifier les choses. Essayez encore !"},{text:"Il existe une \xE9tiquette pour le d\xE9but d'une entit\xE9 et une \xE9tiquette pour la suite d'une entit\xE9.",explain:" ",correct:!0},{text:"Dans un mot donn\xE9, tant que le premier <i>token</i> porte l'\xE9tiquette de l'entit\xE9, le mot entier est consid\xE9r\xE9 comme \xE9tiquet\xE9 avec cette entit\xE9.",explain:"C'est une strat\xE9gie pour g\xE9rer les entit\xE9s. Quelles autres r\xE9ponses s'appliquent ici ?",correct:!0},{text:"Lorsqu'un <i>token</i> a l'\xE9tiquette d'une entit\xE9 donn\xE9e, tout autre <i>token</i> suivant ayant la m\xEAme \xE9tiquette est consid\xE9r\xE9 comme faisant partie de la m\xEAme entit\xE9, \xE0 moins qu'il ne soit \xE9tiquet\xE9 comme le d\xE9but d'une nouvelle entit\xE9.",explain:"C'est la fa\xE7on la plus courante de regrouper des entit\xE9s, mais ce n'est pas la seule bonne r\xE9ponse.",correct:!0}]}}),ie=new x({}),re=new q({props:{choices:[{text:"Ce n'est pas vraiment le cas car il tronque le long contexte \xE0 la longueur maximale accept\xE9e par le mod\xE8le.",explain:"Il existe une astuce que vous pouvez utiliser pour g\xE9rer les longs contextes. Vous en souvenez-vous ?"},{text:"Il divise le contexte en plusieurs parties et fait la moyenne des r\xE9sultats obtenus.",explain:"Cela n'aurait pas de sens de faire la moyenne des r\xE9sultats car certaines parties du contexte n'incluront pas la r\xE9ponse."},{text:"Il divise le contexte en plusieurs parties (avec chevauchement) et trouve le score maximum pour une r\xE9ponse dans chaque partie.",explain:"C'est la bonne r\xE9ponse !",correct:!0},{text:"Il divise le contexte en plusieurs parties (sans chevauchemen par souci d'efficacit\xE9) et trouve le score maximum pour une r\xE9ponse dans chaque partie.",explain:"Il comprend un certain chevauchement entre les parties pour \xE9viter une situation o\xF9 la r\xE9ponse serait divis\xE9e en deux parties."}]}}),ae=new x({}),oe=new q({props:{choices:[{text:"C'est le nettoyage que le <i>tokenizer</i> effectue sur les textes lors des \xE9tapes initiales.",explain:"Par exemple, il peut s'agir de supprimer les accents ou les espaces, ou de mettre les entr\xE9es en minuscules.",correct:!0},{text:"Il s'agit d'une technique d'augmentation de donn\xE9es qui consiste \xE0 rendre le texte plus normal en supprimant les mots rares.",explain:"Essayez encore."},{text:"C'est l'\xE9tape finale du post-traitement o\xF9 le <i>tokenizer</i> ajoute les <i>tokens</i> sp\xE9ciaux.",explain:"Cette \xE9tape est simplement appel\xE9e post-traitement."},{text:"C'est lorsque les ench\xE2ssements sont faits avec une moyenne nulle et un \xE9cart-type de 1, en soustrayant la moyenne et en divisant par l'\xE9cart-type.",explain:"Ce processus est commun\xE9ment appel\xE9 normalisation lorsqu'il est appliqu\xE9 aux valeurs des pixels en vision par ordinateur, mais ce n'est pas ce que signifie la normalisation en NLP."}]}}),le=new x({}),pe=new q({props:{choices:[{text:"C'est l'\xE9tape qui pr\xE9c\xE8de la tok\xE9nisation, o\xF9 l'augmentation des donn\xE9es (comme le masquage al\xE9atoire) est appliqu\xE9e.",explain:"Cette \xE9tape fait partie du pr\xE9traitement."},{text:"C'est l'\xE9tape avant la tok\xE9nisation, o\xF9 les op\xE9rations de nettoyage souhait\xE9es sont appliqu\xE9es au texte.",explain:"C'est l'\xE9tape de normalisation."},{text:"C'est l'\xE9tape qui pr\xE9c\xE8de l'application du mod\xE8le *tokenizer*, pour diviser l'entr\xE9e en mots.",explain:"C'est la bonne r\xE9ponse !",correct:!0},{text:"Il s'agit de l'\xE9tape pr\xE9c\xE9dant l'application du mod\xE8le <i>tokenizer</i>, qui divise l'entr\xE9e en <i>tokens</i>.",explain:"La division en <i>tokens</i> est le travail du mod\xE8le <i>tokenizer</i>."}]}}),de=new x({}),me=new q({props:{choices:[{text:"BPE est un algorithme de tok\xE9nisation en sous-mots qui part d'un petit vocabulaire et apprend des r\xE8gles de fusion.",explain:"C'est le cas en effet !",correct:!0},{text:"BPE est un algorithme de tok\xE9nisation en sous-mots qui part d'un grand vocabulaire et en retire progressivement les <i>tokens</i>.",explain:"C'est l'approche adopt\xE9e par un algorithme de tok\xE9nisation diff\xE9rent."},{text:"Un <i>tokenizer</i> BPE apprend les r\xE8gles de fusion en fusionnant la paire de <i>tokens</i> la plus fr\xE9quente.",explain:"C'est exact !",correct:!0},{text:"Un <i>tokenizer</i> BPE apprend une r\xE8gle de fusion en fusionnant la paire de <i>tokens</i> qui maximise un score qui privil\xE9gie les paires fr\xE9quentes avec des parties individuelles moins fr\xE9quentes.",explain:"C'est la strat\xE9gie appliqu\xE9e par un autre algorithme de tokenization."},{text:"BPE tokenise les mots en sous-mots en les divisant en caract\xE8res, puis en appliquant les r\xE8gles de fusion.",explain:" ",correct:!0},{text:"BPE tokenise les mots en sous-mots en trouvant le plus long sous-mot du vocabulaire en commen\xE7ant par le d\xE9but, puis en r\xE9p\xE9tant le processus pour le reste du texte.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."}]}}),fe=new x({}),ve=new q({props:{choices:[{text:"WordPiece est un algorithme de tok\xE9nisation en sous-mots qui part d'un petit vocabulaire et apprend des r\xE8gles de fusion.",explain:"C'est le cas en effet !",correct:!0},{text:"WordPiece est un algorithme de tok\xE9nisation en sous-mots qui part d'un grand vocabulaire et en retire progressivement les <i>tokens</i>.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."},{text:"WordPiece Les <i>tokenizer</i> apprennent les r\xE8gles de fusion en fusionnant la paire de <i>tokens</i> la plus fr\xE9quente.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."},{text:"Un <i>tokenizer</i> WordPiece apprend une r\xE8gle de fusion en fusionnant la paire de <i>tokens</i> qui maximise un score qui privil\xE9gie les paires fr\xE9quentes avec des parties individuelles moins fr\xE9quentes.",explain:" ",correct:!0},{text:"WordPiece tokenise les mots en sous-mots en trouvant la segmentation en <i>tokens</i> la plus probable, selon le mod\xE8le.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."},{text:"WordPiece tokenise les mots en sous-mots en trouvant le plus long sous-mot du vocabulaire en commen\xE7ant par le d\xE9but, puis en r\xE9p\xE9tant le processus pour le reste du texte.",explain:"C'est ainsi que WordPiece proc\xE8de pour l'encodage.",correct:!0}]}}),$e=new x({}),xe=new q({props:{choices:[{text:"Unigram est un algorithme de tok\xE9nisation en sous-mots qui part d'un petit vocabulaire et apprend des r\xE8gles de fusion.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."},{text:"Unigram est un algorithme de tok\xE9nisation en sous-mots qui part d'un grand vocabulaire et en retire progressivement les <i>tokens</i>.",explain:" ",correct:!0},{text:"Unigram adapte son vocabulaire en minimisant une perte calcul\xE9e sur l'ensemble du corpus.",explain:" ",correct:!0},{text:"Unigram adapte son vocabulaire en conservant les sous-mots les plus fr\xE9quents.",explain:" "},{text:"Unigram segmente les mots en sous-mots en trouvant la segmentation la plus probable en <i>tokens</i>, selon le mod\xE8le.",explain:" ",correct:!0},{text:"Unigram d\xE9compose les mots en sous-mots en les divisant en caract\xE8res puis en appliquant les r\xE8gles de fusion.",explain:"C'est la fa\xE7on de faire d'un autre algorithme de tokenization."}]}}),{c(){k=i("meta"),Ve=u(),z=i("h1"),Q=i("a"),ze=i("span"),m(V.$$.fragment),It=u(),we=i("span"),Qt=d("Quiz de fin de chapitre"),Re=u(),qe=i("p"),Lt=d("Testons ce que vous avez appris dans ce chapitre !"),Fe=u(),w=i("h3"),L=i("a"),_e=i("span"),m(R.$$.fragment),Ut=u(),F=i("span"),Ht=d("1. Quand devez-vous entra\xEEner un nouveau "),Ee=i("i"),Bt=d("tokenizer"),Wt=d(" ?"),Ge=u(),m(G.$$.fragment),Je=u(),_=i("h3"),U=i("a"),ye=i("span"),m(J.$$.fragment),jt=u(),K=i("span"),Dt=d("2. Quel est l\u2019avantage d\u2019utiliser un g\xE9n\xE9rateur de listes par rapport \xE0 une liste de listes lors de l\u2019utilisation de "),be=i("code"),Ot=d("train_new_from_iterator()"),Tt=d(" ?"),Ke=u(),m(X.$$.fragment),Xe=u(),E=i("h3"),H=i("a"),Pe=i("span"),m(Y.$$.fragment),Mt=u(),Z=i("span"),Vt=d("3. Quels sont les avantages d\u2019utiliser un "),Ce=i("i"),Rt=d("tokenizer"),Ft=d(" \xAB rapide \xBB ?"),Ye=u(),m(ee.$$.fragment),Ze=u(),y=i("h3"),B=i("a"),Ae=i("span"),m(te.$$.fragment),Gt=u(),b=i("span"),Jt=d("4. Comment le pipeline "),Se=i("code"),Kt=d("token-classification"),Xt=d(" g\xE8re-t-il les entit\xE9s qui s\u2019\xE9tendent sur plusieurs "),Ne=i("i"),Yt=d("tokens"),Zt=d(" ?"),et=u(),m(ne.$$.fragment),tt=u(),P=i("h3"),W=i("a"),Ie=i("span"),m(ie.$$.fragment),en=u(),se=i("span"),tn=d("5. Comment le pipeline "),Qe=i("code"),nn=d("question-answering"),sn=d(" g\xE8re-t-il les contextes longs ?"),nt=u(),m(re.$$.fragment),it=u(),C=i("h3"),j=i("a"),Le=i("span"),m(ae.$$.fragment),rn=u(),Ue=i("span"),an=d("6. Qu\u2019est-ce que la normalisation ?"),st=u(),m(oe.$$.fragment),rt=u(),A=i("h3"),D=i("a"),He=i("span"),m(le.$$.fragment),on=u(),ue=i("span"),ln=d("7. Qu\u2019est-ce que la pr\xE9-tok\xE9nisation pour un "),Be=i("i"),un=d("tokenizer"),pn=d(" en sous-mots ?"),at=u(),m(pe.$$.fragment),ot=u(),S=i("h3"),O=i("a"),We=i("span"),m(de.$$.fragment),dn=u(),ce=i("span"),cn=d("8. S\xE9lectionnez les phrases qui s\u2019appliquent au "),je=i("i"),mn=d("tokenizer"),fn=d(" BPE."),lt=u(),m(me.$$.fragment),ut=u(),N=i("h3"),T=i("a"),De=i("span"),m(fe.$$.fragment),hn=u(),he=i("span"),vn=d("9. S\xE9lectionnez les phrases qui s\u2019appliquent au "),Oe=i("i"),$n=d("tokenizer"),gn=d(" WordPiece."),pt=u(),m(ve.$$.fragment),dt=u(),I=i("h3"),M=i("a"),Te=i("span"),m($e.$$.fragment),xn=u(),ge=i("span"),qn=d("10. S\xE9lectionnez les phrases qui s\u2019appliquent au "),Me=i("i"),kn=d("tokenizer"),zn=d(" Unigram."),ct=u(),m(xe.$$.fragment),this.h()},l(e){const a=li('[data-svelte="svelte-1phssyn"]',document.head);k=s(a,"META",{name:!0,content:!0}),a.forEach(t),Ve=p(e),z=s(e,"H1",{class:!0});var ft=r(z);Q=s(ft,"A",{id:!0,class:!0,href:!0});var _n=r(Q);ze=s(_n,"SPAN",{});var En=r(ze);f(V.$$.fragment,En),En.forEach(t),_n.forEach(t),It=p(ft),we=s(ft,"SPAN",{});var yn=r(we);Qt=c(yn,"Quiz de fin de chapitre"),yn.forEach(t),ft.forEach(t),Re=p(e),qe=s(e,"P",{});var bn=r(qe);Lt=c(bn,"Testons ce que vous avez appris dans ce chapitre !"),bn.forEach(t),Fe=p(e),w=s(e,"H3",{class:!0});var ht=r(w);L=s(ht,"A",{id:!0,class:!0,href:!0});var Pn=r(L);_e=s(Pn,"SPAN",{});var Cn=r(_e);f(R.$$.fragment,Cn),Cn.forEach(t),Pn.forEach(t),Ut=p(ht),F=s(ht,"SPAN",{});var vt=r(F);Ht=c(vt,"1. Quand devez-vous entra\xEEner un nouveau "),Ee=s(vt,"I",{});var An=r(Ee);Bt=c(An,"tokenizer"),An.forEach(t),Wt=c(vt," ?"),vt.forEach(t),ht.forEach(t),Ge=p(e),f(G.$$.fragment,e),Je=p(e),_=s(e,"H3",{class:!0});var $t=r(_);U=s($t,"A",{id:!0,class:!0,href:!0});var Sn=r(U);ye=s(Sn,"SPAN",{});var Nn=r(ye);f(J.$$.fragment,Nn),Nn.forEach(t),Sn.forEach(t),jt=p($t),K=s($t,"SPAN",{});var gt=r(K);Dt=c(gt,"2. Quel est l\u2019avantage d\u2019utiliser un g\xE9n\xE9rateur de listes par rapport \xE0 une liste de listes lors de l\u2019utilisation de "),be=s(gt,"CODE",{});var In=r(be);Ot=c(In,"train_new_from_iterator()"),In.forEach(t),Tt=c(gt," ?"),gt.forEach(t),$t.forEach(t),Ke=p(e),f(X.$$.fragment,e),Xe=p(e),E=s(e,"H3",{class:!0});var xt=r(E);H=s(xt,"A",{id:!0,class:!0,href:!0});var Qn=r(H);Pe=s(Qn,"SPAN",{});var Ln=r(Pe);f(Y.$$.fragment,Ln),Ln.forEach(t),Qn.forEach(t),Mt=p(xt),Z=s(xt,"SPAN",{});var qt=r(Z);Vt=c(qt,"3. Quels sont les avantages d\u2019utiliser un "),Ce=s(qt,"I",{});var Un=r(Ce);Rt=c(Un,"tokenizer"),Un.forEach(t),Ft=c(qt," \xAB rapide \xBB ?"),qt.forEach(t),xt.forEach(t),Ye=p(e),f(ee.$$.fragment,e),Ze=p(e),y=s(e,"H3",{class:!0});var kt=r(y);B=s(kt,"A",{id:!0,class:!0,href:!0});var Hn=r(B);Ae=s(Hn,"SPAN",{});var Bn=r(Ae);f(te.$$.fragment,Bn),Bn.forEach(t),Hn.forEach(t),Gt=p(kt),b=s(kt,"SPAN",{});var ke=r(b);Jt=c(ke,"4. Comment le pipeline "),Se=s(ke,"CODE",{});var Wn=r(Se);Kt=c(Wn,"token-classification"),Wn.forEach(t),Xt=c(ke," g\xE8re-t-il les entit\xE9s qui s\u2019\xE9tendent sur plusieurs "),Ne=s(ke,"I",{});var jn=r(Ne);Yt=c(jn,"tokens"),jn.forEach(t),Zt=c(ke," ?"),ke.forEach(t),kt.forEach(t),et=p(e),f(ne.$$.fragment,e),tt=p(e),P=s(e,"H3",{class:!0});var zt=r(P);W=s(zt,"A",{id:!0,class:!0,href:!0});var Dn=r(W);Ie=s(Dn,"SPAN",{});var On=r(Ie);f(ie.$$.fragment,On),On.forEach(t),Dn.forEach(t),en=p(zt),se=s(zt,"SPAN",{});var wt=r(se);tn=c(wt,"5. Comment le pipeline "),Qe=s(wt,"CODE",{});var Tn=r(Qe);nn=c(Tn,"question-answering"),Tn.forEach(t),sn=c(wt," g\xE8re-t-il les contextes longs ?"),wt.forEach(t),zt.forEach(t),nt=p(e),f(re.$$.fragment,e),it=p(e),C=s(e,"H3",{class:!0});var _t=r(C);j=s(_t,"A",{id:!0,class:!0,href:!0});var Mn=r(j);Le=s(Mn,"SPAN",{});var Vn=r(Le);f(ae.$$.fragment,Vn),Vn.forEach(t),Mn.forEach(t),rn=p(_t),Ue=s(_t,"SPAN",{});var Rn=r(Ue);an=c(Rn,"6. Qu\u2019est-ce que la normalisation ?"),Rn.forEach(t),_t.forEach(t),st=p(e),f(oe.$$.fragment,e),rt=p(e),A=s(e,"H3",{class:!0});var Et=r(A);D=s(Et,"A",{id:!0,class:!0,href:!0});var Fn=r(D);He=s(Fn,"SPAN",{});var Gn=r(He);f(le.$$.fragment,Gn),Gn.forEach(t),Fn.forEach(t),on=p(Et),ue=s(Et,"SPAN",{});var yt=r(ue);ln=c(yt,"7. Qu\u2019est-ce que la pr\xE9-tok\xE9nisation pour un "),Be=s(yt,"I",{});var Jn=r(Be);un=c(Jn,"tokenizer"),Jn.forEach(t),pn=c(yt," en sous-mots ?"),yt.forEach(t),Et.forEach(t),at=p(e),f(pe.$$.fragment,e),ot=p(e),S=s(e,"H3",{class:!0});var bt=r(S);O=s(bt,"A",{id:!0,class:!0,href:!0});var Kn=r(O);We=s(Kn,"SPAN",{});var Xn=r(We);f(de.$$.fragment,Xn),Xn.forEach(t),Kn.forEach(t),dn=p(bt),ce=s(bt,"SPAN",{});var Pt=r(ce);cn=c(Pt,"8. S\xE9lectionnez les phrases qui s\u2019appliquent au "),je=s(Pt,"I",{});var Yn=r(je);mn=c(Yn,"tokenizer"),Yn.forEach(t),fn=c(Pt," BPE."),Pt.forEach(t),bt.forEach(t),lt=p(e),f(me.$$.fragment,e),ut=p(e),N=s(e,"H3",{class:!0});var Ct=r(N);T=s(Ct,"A",{id:!0,class:!0,href:!0});var Zn=r(T);De=s(Zn,"SPAN",{});var ei=r(De);f(fe.$$.fragment,ei),ei.forEach(t),Zn.forEach(t),hn=p(Ct),he=s(Ct,"SPAN",{});var At=r(he);vn=c(At,"9. S\xE9lectionnez les phrases qui s\u2019appliquent au "),Oe=s(At,"I",{});var ti=r(Oe);$n=c(ti,"tokenizer"),ti.forEach(t),gn=c(At," WordPiece."),At.forEach(t),Ct.forEach(t),pt=p(e),f(ve.$$.fragment,e),dt=p(e),I=s(e,"H3",{class:!0});var St=r(I);M=s(St,"A",{id:!0,class:!0,href:!0});var ni=r(M);Te=s(ni,"SPAN",{});var ii=r(Te);f($e.$$.fragment,ii),ii.forEach(t),ni.forEach(t),xn=p(St),ge=s(St,"SPAN",{});var Nt=r(ge);qn=c(Nt,"10. S\xE9lectionnez les phrases qui s\u2019appliquent au "),Me=s(Nt,"I",{});var si=r(Me);kn=c(si,"tokenizer"),si.forEach(t),zn=c(Nt," Unigram."),Nt.forEach(t),St.forEach(t),ct=p(e),f(xe.$$.fragment,e),this.h()},h(){o(k,"name","hf:doc:metadata"),o(k,"content",JSON.stringify(ci)),o(Q,"id","quiz-de-fin-de-chapitre"),o(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(Q,"href","#quiz-de-fin-de-chapitre"),o(z,"class","relative group"),o(L,"id","1.-quand-devez-vous-entra\xEEner-un-nouveau-<i>tokenizer</i>-?"),o(L,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(L,"href","#1.-quand-devez-vous-entra\xEEner-un-nouveau-<i>tokenizer</i>-?"),o(w,"class","relative group"),o(U,"id","2.-quel-est-l\u2019avantage-d\u2019utiliser-un-g\xE9n\xE9rateur-de-listes-par-rapport-\xE0-une-liste-de-listes-lors-de-l\u2019utilisation-de-<code>train_new_from_iterator()</code>-?"),o(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(U,"href","#2.-quel-est-l\u2019avantage-d\u2019utiliser-un-g\xE9n\xE9rateur-de-listes-par-rapport-\xE0-une-liste-de-listes-lors-de-l\u2019utilisation-de-<code>train_new_from_iterator()</code>-?"),o(_,"class","relative group"),o(H,"id","3.-quels-sont-les-avantages-d\u2019utiliser-un-<i>tokenizer</i>-\xAB-rapide-\xBB-?"),o(H,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(H,"href","#3.-quels-sont-les-avantages-d\u2019utiliser-un-<i>tokenizer</i>-\xAB-rapide-\xBB-?"),o(E,"class","relative group"),o(B,"id","4.-comment-le-pipeline-<code>token-classification</code>-g\xE8re-t-il-les-entit\xE9s-qui-s\u2019\xE9tendent-sur-plusieurs-<i>tokens</i>-?"),o(B,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(B,"href","#4.-comment-le-pipeline-<code>token-classification</code>-g\xE8re-t-il-les-entit\xE9s-qui-s\u2019\xE9tendent-sur-plusieurs-<i>tokens</i>-?"),o(y,"class","relative group"),o(W,"id","5.-comment-le-pipeline-<code>question-answering</code>-g\xE8re-t-il-les-contextes-longs-?"),o(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(W,"href","#5.-comment-le-pipeline-<code>question-answering</code>-g\xE8re-t-il-les-contextes-longs-?"),o(P,"class","relative group"),o(j,"id","6.-qu\u2019est-ce-que-la-normalisation-?"),o(j,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(j,"href","#6.-qu\u2019est-ce-que-la-normalisation-?"),o(C,"class","relative group"),o(D,"id","7.-qu\u2019est-ce-que-la-pr\xE9-tok\xE9nisation-pour-un-<i>tokenizer</i>-en-sous-mots-?"),o(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(D,"href","#7.-qu\u2019est-ce-que-la-pr\xE9-tok\xE9nisation-pour-un-<i>tokenizer</i>-en-sous-mots-?"),o(A,"class","relative group"),o(O,"id","8.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-bpe."),o(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(O,"href","#8.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-bpe."),o(S,"class","relative group"),o(T,"id","9.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-wordpiece."),o(T,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(T,"href","#9.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-wordpiece."),o(N,"class","relative group"),o(M,"id","10.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-unigram."),o(M,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),o(M,"href","#10.-s\xE9lectionnez-les-phrases-qui-s\u2019appliquent-au-<i>tokenizer</i>-unigram."),o(I,"class","relative group")},m(e,a){n(document.head,k),l(e,Ve,a),l(e,z,a),n(z,Q),n(Q,ze),h(V,ze,null),n(z,It),n(z,we),n(we,Qt),l(e,Re,a),l(e,qe,a),n(qe,Lt),l(e,Fe,a),l(e,w,a),n(w,L),n(L,_e),h(R,_e,null),n(w,Ut),n(w,F),n(F,Ht),n(F,Ee),n(Ee,Bt),n(F,Wt),l(e,Ge,a),h(G,e,a),l(e,Je,a),l(e,_,a),n(_,U),n(U,ye),h(J,ye,null),n(_,jt),n(_,K),n(K,Dt),n(K,be),n(be,Ot),n(K,Tt),l(e,Ke,a),h(X,e,a),l(e,Xe,a),l(e,E,a),n(E,H),n(H,Pe),h(Y,Pe,null),n(E,Mt),n(E,Z),n(Z,Vt),n(Z,Ce),n(Ce,Rt),n(Z,Ft),l(e,Ye,a),h(ee,e,a),l(e,Ze,a),l(e,y,a),n(y,B),n(B,Ae),h(te,Ae,null),n(y,Gt),n(y,b),n(b,Jt),n(b,Se),n(Se,Kt),n(b,Xt),n(b,Ne),n(Ne,Yt),n(b,Zt),l(e,et,a),h(ne,e,a),l(e,tt,a),l(e,P,a),n(P,W),n(W,Ie),h(ie,Ie,null),n(P,en),n(P,se),n(se,tn),n(se,Qe),n(Qe,nn),n(se,sn),l(e,nt,a),h(re,e,a),l(e,it,a),l(e,C,a),n(C,j),n(j,Le),h(ae,Le,null),n(C,rn),n(C,Ue),n(Ue,an),l(e,st,a),h(oe,e,a),l(e,rt,a),l(e,A,a),n(A,D),n(D,He),h(le,He,null),n(A,on),n(A,ue),n(ue,ln),n(ue,Be),n(Be,un),n(ue,pn),l(e,at,a),h(pe,e,a),l(e,ot,a),l(e,S,a),n(S,O),n(O,We),h(de,We,null),n(S,dn),n(S,ce),n(ce,cn),n(ce,je),n(je,mn),n(ce,fn),l(e,lt,a),h(me,e,a),l(e,ut,a),l(e,N,a),n(N,T),n(T,De),h(fe,De,null),n(N,hn),n(N,he),n(he,vn),n(he,Oe),n(Oe,$n),n(he,gn),l(e,pt,a),h(ve,e,a),l(e,dt,a),l(e,I,a),n(I,M),n(M,Te),h($e,Te,null),n(I,xn),n(I,ge),n(ge,qn),n(ge,Me),n(Me,kn),n(ge,zn),l(e,ct,a),h(xe,e,a),mt=!0},p:ui,i(e){mt||(v(V.$$.fragment,e),v(R.$$.fragment,e),v(G.$$.fragment,e),v(J.$$.fragment,e),v(X.$$.fragment,e),v(Y.$$.fragment,e),v(ee.$$.fragment,e),v(te.$$.fragment,e),v(ne.$$.fragment,e),v(ie.$$.fragment,e),v(re.$$.fragment,e),v(ae.$$.fragment,e),v(oe.$$.fragment,e),v(le.$$.fragment,e),v(pe.$$.fragment,e),v(de.$$.fragment,e),v(me.$$.fragment,e),v(fe.$$.fragment,e),v(ve.$$.fragment,e),v($e.$$.fragment,e),v(xe.$$.fragment,e),mt=!0)},o(e){$(V.$$.fragment,e),$(R.$$.fragment,e),$(G.$$.fragment,e),$(J.$$.fragment,e),$(X.$$.fragment,e),$(Y.$$.fragment,e),$(ee.$$.fragment,e),$(te.$$.fragment,e),$(ne.$$.fragment,e),$(ie.$$.fragment,e),$(re.$$.fragment,e),$(ae.$$.fragment,e),$(oe.$$.fragment,e),$(le.$$.fragment,e),$(pe.$$.fragment,e),$(de.$$.fragment,e),$(me.$$.fragment,e),$(fe.$$.fragment,e),$(ve.$$.fragment,e),$($e.$$.fragment,e),$(xe.$$.fragment,e),mt=!1},d(e){t(k),e&&t(Ve),e&&t(z),g(V),e&&t(Re),e&&t(qe),e&&t(Fe),e&&t(w),g(R),e&&t(Ge),g(G,e),e&&t(Je),e&&t(_),g(J),e&&t(Ke),g(X,e),e&&t(Xe),e&&t(E),g(Y),e&&t(Ye),g(ee,e),e&&t(Ze),e&&t(y),g(te),e&&t(et),g(ne,e),e&&t(tt),e&&t(P),g(ie),e&&t(nt),g(re,e),e&&t(it),e&&t(C),g(ae),e&&t(st),g(oe,e),e&&t(rt),e&&t(A),g(le),e&&t(at),g(pe,e),e&&t(ot),e&&t(S),g(de),e&&t(lt),g(me,e),e&&t(ut),e&&t(N),g(fe),e&&t(pt),g(ve,e),e&&t(dt),e&&t(I),g($e),e&&t(ct),g(xe,e)}}}const ci={local:"quiz-de-fin-de-chapitre",title:"Quiz de fin de chapitre"};function mi(wn){return pi(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class $i extends ri{constructor(k){super();ai(this,k,mi,di,oi,{})}}export{$i as default,ci as metadata};
