import{S as Oe,i as Be,s as Ne,e as r,k as d,w as Re,t as o,M as qe,c as s,d as a,m as p,a as n,x as He,h as i,b as _,G as t,g as h,y as Ue,L as Je,q as je,o as ze,B as Fe,v as Ke}from"../../chunks/vendor-hf-doc-builder.js";import{I as Qe}from"../../chunks/IconCopyLink-hf-doc-builder.js";function Ve(ge){let v,N,y,g,I,E,K,L,Q,R,u,V,D,W,X,S,Y,Z,q,b,ee,H,x,te,U,c,$,ae,oe,G,ie,re,M,se,ne,O,le,J,f,fe,B,he,ce,k,de,pe,A,ue,me,T,ve,ye,j,P,_e,z;return E=new Qe({}),{c(){v=r("meta"),N=d(),y=r("h1"),g=r("a"),I=r("span"),Re(E.$$.fragment),K=d(),L=r("span"),Q=o("Going beyond text"),R=d(),u=r("p"),V=o("So far in this course, we\u2019ve seen that Transformers are exceptionally good at tackling a wide variety of tasks in NLP. But did you know that Transformers can also be applied to entirely different "),D=r("em"),W=o("modalities"),X=o(" like audio and images? In this chapter, we will explore how Transformers can process "),S=r("em"),Y=o("audio waveforms"),Z=o(" to produce novel applications like speech recognition."),q=d(),b=r("p"),ee=o("ADD GRADIO DEMO HERE"),H=d(),x=r("p"),te=o("After explaining why Transformers might be suitable for audio, each of the sections in this chapter will dive into some of the most common tasks in this fast-moving field:"),U=d(),c=r("ul"),$=r("li"),ae=o("Classifying audio signals into a set of categories."),oe=d(),G=r("li"),ie=o("Transcribing speech to text"),re=d(),M=r("li"),se=o("Converting text to speech"),ne=d(),O=r("li"),le=o("Bypassing text altogether and converting audio to audio"),J=d(),f=r("p"),fe=o("To do this, you\u2019ll need to leverage everything you learned about the "),B=r("code"),he=o("Trainer"),ce=o(" API library in "),k=r("a"),de=o("Chapter 3"),pe=o(", the \u{1F917} Datasets library in "),A=r("a"),ue=o("Chapter 5"),me=o(", and the Gradio library in "),T=r("a"),ve=o("Chapter 9"),ye=o(". So go read those chapters first if you haven\u2019t done so already."),j=d(),P=r("p"),_e=o("Let\u2019s now dive into the fascinating world of audio!"),this.h()},l(e){const l=qe('[data-svelte="svelte-1phssyn"]',document.head);v=s(l,"META",{name:!0,content:!0}),l.forEach(a),N=p(e),y=s(e,"H1",{class:!0});var F=n(y);g=s(F,"A",{id:!0,class:!0,href:!0});var we=n(g);I=s(we,"SPAN",{});var Ee=n(I);He(E.$$.fragment,Ee),Ee.forEach(a),we.forEach(a),K=p(F),L=s(F,"SPAN",{});var be=n(L);Q=i(be,"Going beyond text"),be.forEach(a),F.forEach(a),R=p(e),u=s(e,"P",{});var C=n(u);V=i(C,"So far in this course, we\u2019ve seen that Transformers are exceptionally good at tackling a wide variety of tasks in NLP. But did you know that Transformers can also be applied to entirely different "),D=s(C,"EM",{});var xe=n(D);W=i(xe,"modalities"),xe.forEach(a),X=i(C," like audio and images? In this chapter, we will explore how Transformers can process "),S=s(C,"EM",{});var ke=n(S);Y=i(ke,"audio waveforms"),ke.forEach(a),Z=i(C," to produce novel applications like speech recognition."),C.forEach(a),q=p(e),b=s(e,"P",{});var Ae=n(b);ee=i(Ae,"ADD GRADIO DEMO HERE"),Ae.forEach(a),H=p(e),x=s(e,"P",{});var Te=n(x);te=i(Te,"After explaining why Transformers might be suitable for audio, each of the sections in this chapter will dive into some of the most common tasks in this fast-moving field:"),Te.forEach(a),U=p(e),c=s(e,"UL",{});var w=n(c);$=s(w,"LI",{});var Pe=n($);ae=i(Pe,"Classifying audio signals into a set of categories."),Pe.forEach(a),oe=p(w),G=s(w,"LI",{});var Ce=n(G);ie=i(Ce,"Transcribing speech to text"),Ce.forEach(a),re=p(w),M=s(w,"LI",{});var Ie=n(M);se=i(Ie,"Converting text to speech"),Ie.forEach(a),ne=p(w),O=s(w,"LI",{});var Le=n(O);le=i(Le,"Bypassing text altogether and converting audio to audio"),Le.forEach(a),w.forEach(a),J=p(e),f=s(e,"P",{});var m=n(f);fe=i(m,"To do this, you\u2019ll need to leverage everything you learned about the "),B=s(m,"CODE",{});var De=n(B);he=i(De,"Trainer"),De.forEach(a),ce=i(m," API library in "),k=s(m,"A",{href:!0});var Se=n(k);de=i(Se,"Chapter 3"),Se.forEach(a),pe=i(m,", the \u{1F917} Datasets library in "),A=s(m,"A",{href:!0});var $e=n(A);ue=i($e,"Chapter 5"),$e.forEach(a),me=i(m,", and the Gradio library in "),T=s(m,"A",{href:!0});var Ge=n(T);ve=i(Ge,"Chapter 9"),Ge.forEach(a),ye=i(m,". So go read those chapters first if you haven\u2019t done so already."),m.forEach(a),j=p(e),P=s(e,"P",{});var Me=n(P);_e=i(Me,"Let\u2019s now dive into the fascinating world of audio!"),Me.forEach(a),this.h()},h(){_(v,"name","hf:doc:metadata"),_(v,"content",JSON.stringify(We)),_(g,"id","going-beyond-text"),_(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),_(g,"href","#going-beyond-text"),_(y,"class","relative group"),_(k,"href","/course/chapter3"),_(A,"href","/course/chapter5"),_(T,"href","/course/chapter9")},m(e,l){t(document.head,v),h(e,N,l),h(e,y,l),t(y,g),t(g,I),Ue(E,I,null),t(y,K),t(y,L),t(L,Q),h(e,R,l),h(e,u,l),t(u,V),t(u,D),t(D,W),t(u,X),t(u,S),t(S,Y),t(u,Z),h(e,q,l),h(e,b,l),t(b,ee),h(e,H,l),h(e,x,l),t(x,te),h(e,U,l),h(e,c,l),t(c,$),t($,ae),t(c,oe),t(c,G),t(G,ie),t(c,re),t(c,M),t(M,se),t(c,ne),t(c,O),t(O,le),h(e,J,l),h(e,f,l),t(f,fe),t(f,B),t(B,he),t(f,ce),t(f,k),t(k,de),t(f,pe),t(f,A),t(A,ue),t(f,me),t(f,T),t(T,ve),t(f,ye),h(e,j,l),h(e,P,l),t(P,_e),z=!0},p:Je,i(e){z||(je(E.$$.fragment,e),z=!0)},o(e){ze(E.$$.fragment,e),z=!1},d(e){a(v),e&&a(N),e&&a(y),Fe(E),e&&a(R),e&&a(u),e&&a(q),e&&a(b),e&&a(H),e&&a(x),e&&a(U),e&&a(c),e&&a(J),e&&a(f),e&&a(j),e&&a(P)}}}const We={local:"going-beyond-text",title:"Going beyond text"};function Xe(ge){return Ke(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class et extends Oe{constructor(v){super();Be(this,v,Xe,Ve,Ne,{})}}export{et as default,We as metadata};
