import{S as ya,i as xa,s as ja,e as n,k as c,w as A,t as u,M as Ta,c as r,d as e,m as f,a as o,x as N,h as m,b as i,G as t,g as l,y as P,L as ka,q as z,o as S,B as q,v as Ea}from"../../chunks/vendor-hf-doc-builder.js";import{I as _a}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as Y}from"../../chunks/CodeBlock-hf-doc-builder.js";function Aa(pa){let p,Z,h,g,H,v,aa,I,ea,D,E,sa,L,d,b,C,_,ta,G,na,M,w,ra,y,la,oa,B,x,F,j,O,$,ia,W,ca,fa,J,T,R,k,U;return v=new _a({}),_=new _a({}),x=new Y({props:{code:`from datasets import load_dataset

gtzan = load_dataset("marsyas/gtzan", split="train")
gtzan`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

gtzan = load_dataset(<span class="hljs-string">&quot;marsyas/gtzan&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
gtzan`}}),j=new Y({props:{code:`Dataset({
    features: ['file', 'audio', 'genre'],
    num_rows: 999
})`,highlighted:`Dataset({
    features: [<span class="hljs-string">&#x27;file&#x27;</span>, <span class="hljs-string">&#x27;audio&#x27;</span>, <span class="hljs-string">&#x27;genre&#x27;</span>],
    num_rows: <span class="hljs-number">999</span>
})`}}),T=new Y({props:{code:"gtzan[0]",highlighted:'gtzan[<span class="hljs-number">0</span>]'}}),k=new Y({props:{code:`{'file': '~/.cache/huggingface/datasets/downloads/extracted/7b31326ffc96eb5c1ad6dcbfc8187a6c4cc6efdfa3c7e42788fc7be8bba7a0a4/genres/blues/blues.00000.wav', 'audio': {'path': '~/.cache/huggingface/datasets/downloads/extracted/7b31326ffc96eb5c1ad6dcbfc8187a6c4cc6efdfa3c7e42788fc7be8bba7a0a4/genres/blues/blues.00000.wav', 'array': array([ 0.00732422,  0.01660156,  0.00762939, ..., -0.05560303,
       -0.06106567, -0.06417847], dtype=float32), 'sampling_rate': 22050}, 'genre': 0}`,highlighted:`{<span class="hljs-string">&#x27;file&#x27;</span>: <span class="hljs-string">&#x27;~/.cache/huggingface/datasets/downloads/extracted/7b31326ffc96eb5c1ad6dcbfc8187a6c4cc6efdfa3c7e42788fc7be8bba7a0a4/genres/blues/blues.00000.wav&#x27;</span>, <span class="hljs-string">&#x27;audio&#x27;</span>: {<span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;~/.cache/huggingface/datasets/downloads/extracted/7b31326ffc96eb5c1ad6dcbfc8187a6c4cc6efdfa3c7e42788fc7be8bba7a0a4/genres/blues/blues.00000.wav&#x27;</span>, <span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">0.00732422</span>,  <span class="hljs-number">0.01660156</span>,  <span class="hljs-number">0.00762939</span>, ..., -<span class="hljs-number">0.05560303</span>,
       -<span class="hljs-number">0.06106567</span>, -<span class="hljs-number">0.06417847</span>], dtype=float32), <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">22050</span>}, <span class="hljs-string">&#x27;genre&#x27;</span>: <span class="hljs-number">0</span>}`}}),{c(){p=n("meta"),Z=c(),h=n("h1"),g=n("a"),H=n("span"),A(v.$$.fragment),aa=c(),I=n("span"),ea=u("Training your first audio Transformer"),D=c(),E=n("p"),sa=u("Intro about music classification."),L=c(),d=n("h2"),b=n("a"),C=n("span"),A(_.$$.fragment),ta=c(),G=n("span"),na=u("The dataset"),M=c(),w=n("p"),ra=u("To train a Transformer to tell what type of music is playing, we\u2019ll need some song samples and their musical genres. We\u2019ll use the famous "),y=n("a"),la=u("GTZAN dataset"),oa=u(", which consists of 999 song samples across 10 different genres. The dataset is available on the Hugging Face Hub, so let\u2019s download it to get a sense for it contains:"),B=c(),A(x.$$.fragment),F=c(),A(j.$$.fragment),O=c(),$=n("p"),ia=u("Notice that we specified a single split to download; that\u2019s because GTZAN doesn\u2019t have a predefined training and test split. We\u2019ll create our own splits for training and evaluation shortly. If we take a look at one of the examples, we can see that we\u2019re provided with a file path, an "),W=n("code"),ca=u("audio"),fa=u(" object, and the music genre:"),J=c(),A(T.$$.fragment),R=c(),A(k.$$.fragment),this.h()},l(a){const s=Ta('[data-svelte="svelte-1phssyn"]',document.head);p=r(s,"META",{name:!0,content:!0}),s.forEach(e),Z=f(a),h=r(a,"H1",{class:!0});var K=o(h);g=r(K,"A",{id:!0,class:!0,href:!0});var ha=o(g);H=r(ha,"SPAN",{});var da=o(H);N(v.$$.fragment,da),da.forEach(e),ha.forEach(e),aa=f(K),I=r(K,"SPAN",{});var ua=o(I);ea=m(ua,"Training your first audio Transformer"),ua.forEach(e),K.forEach(e),D=f(a),E=r(a,"P",{});var ma=o(E);sa=m(ma,"Intro about music classification."),ma.forEach(e),L=f(a),d=r(a,"H2",{class:!0});var Q=o(d);b=r(Q,"A",{id:!0,class:!0,href:!0});var ga=o(b);C=r(ga,"SPAN",{});var ba=o(C);N(_.$$.fragment,ba),ba.forEach(e),ga.forEach(e),ta=f(Q),G=r(Q,"SPAN",{});var wa=o(G);na=m(wa,"The dataset"),wa.forEach(e),Q.forEach(e),M=f(a),w=r(a,"P",{});var V=o(w);ra=m(V,"To train a Transformer to tell what type of music is playing, we\u2019ll need some song samples and their musical genres. We\u2019ll use the famous "),y=r(V,"A",{href:!0,rel:!0});var $a=o(y);la=m($a,"GTZAN dataset"),$a.forEach(e),oa=m(V,", which consists of 999 song samples across 10 different genres. The dataset is available on the Hugging Face Hub, so let\u2019s download it to get a sense for it contains:"),V.forEach(e),B=f(a),N(x.$$.fragment,a),F=f(a),N(j.$$.fragment,a),O=f(a),$=r(a,"P",{});var X=o($);ia=m(X,"Notice that we specified a single split to download; that\u2019s because GTZAN doesn\u2019t have a predefined training and test split. We\u2019ll create our own splits for training and evaluation shortly. If we take a look at one of the examples, we can see that we\u2019re provided with a file path, an "),W=r(X,"CODE",{});var va=o(W);ca=m(va,"audio"),va.forEach(e),fa=m(X," object, and the music genre:"),X.forEach(e),J=f(a),N(T.$$.fragment,a),R=f(a),N(k.$$.fragment,a),this.h()},h(){i(p,"name","hf:doc:metadata"),i(p,"content",JSON.stringify(Na)),i(g,"id","training-your-first-audio-transformer"),i(g,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(g,"href","#training-your-first-audio-transformer"),i(h,"class","relative group"),i(b,"id","the-dataset"),i(b,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(b,"href","#the-dataset"),i(d,"class","relative group"),i(y,"href","https://huggingface.co/datasets/marsyas/gtzan"),i(y,"rel","nofollow")},m(a,s){t(document.head,p),l(a,Z,s),l(a,h,s),t(h,g),t(g,H),P(v,H,null),t(h,aa),t(h,I),t(I,ea),l(a,D,s),l(a,E,s),t(E,sa),l(a,L,s),l(a,d,s),t(d,b),t(b,C),P(_,C,null),t(d,ta),t(d,G),t(G,na),l(a,M,s),l(a,w,s),t(w,ra),t(w,y),t(y,la),t(w,oa),l(a,B,s),P(x,a,s),l(a,F,s),P(j,a,s),l(a,O,s),l(a,$,s),t($,ia),t($,W),t(W,ca),t($,fa),l(a,J,s),P(T,a,s),l(a,R,s),P(k,a,s),U=!0},p:ka,i(a){U||(z(v.$$.fragment,a),z(_.$$.fragment,a),z(x.$$.fragment,a),z(j.$$.fragment,a),z(T.$$.fragment,a),z(k.$$.fragment,a),U=!0)},o(a){S(v.$$.fragment,a),S(_.$$.fragment,a),S(x.$$.fragment,a),S(j.$$.fragment,a),S(T.$$.fragment,a),S(k.$$.fragment,a),U=!1},d(a){e(p),a&&e(Z),a&&e(h),q(v),a&&e(D),a&&e(E),a&&e(L),a&&e(d),q(_),a&&e(M),a&&e(w),a&&e(B),q(x,a),a&&e(F),q(j,a),a&&e(O),a&&e($),a&&e(J),q(T,a),a&&e(R),q(k,a)}}}const Na={local:"training-your-first-audio-transformer",sections:[{local:"the-dataset",title:"The dataset"}],title:"Training your first audio Transformer"};function Pa(pa){return Ea(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ha extends ya{constructor(p){super();xa(this,p,Pa,Aa,ja,{})}}export{Ha as default,Na as metadata};
