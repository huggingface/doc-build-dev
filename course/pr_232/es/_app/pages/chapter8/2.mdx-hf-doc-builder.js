import{S as ui,i as pi,s as di,e as n,k as p,w as f,t,M as ci,c as l,d as s,m as d,a as u,x as _,h as r,b as c,N as et,G as a,g as i,y as h,q as b,o as g,B as v,v as mi}from"../../chunks/vendor-hf-doc-builder.js";import{T as Hn}from"../../chunks/Tip-hf-doc-builder.js";import{Y as Mn}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Qn}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as w}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as fi}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";function _i(Y){let m,y;return{c(){m=n("p"),y=t("\u{1F6A8} \xBFVes el cuadro azul alrededor de \u201C6 frames\u201D en el traceback de Google Colab? Es una caracter\xEDstica especial de Colab, que comprime el traceback en \u201Cframes\u201D. Si no puedes encontrar el origen de un error, aseg\xFArate de ampliar el traceback completo haciendo clic en esas dos flechitas.")},l(q){m=l(q,"P",{});var $=u(m);y=r($,"\u{1F6A8} \xBFVes el cuadro azul alrededor de \u201C6 frames\u201D en el traceback de Google Colab? Es una caracter\xEDstica especial de Colab, que comprime el traceback en \u201Cframes\u201D. Si no puedes encontrar el origen de un error, aseg\xFArate de ampliar el traceback completo haciendo clic en esas dos flechitas."),$.forEach(s)},m(q,$){i(q,m,$),a(m,y)},d(q){q&&s(m)}}}function hi(Y){let m,y,q,$,D,k,A,S;return{c(){m=n("p"),y=t("\u{1F4A1} Si te encuentras con un mensaje de error dif\xEDcil de entender, simplemente copia y pega el mensaje en la barra de b\xFAsqueda de Google o de "),q=n("a"),$=t("Stack Overflow"),D=t(" (\xA1s\xED, en serio!). Es muy posible que no seas la primera persona en encontrar el error, y esta es una buena forma de hallar soluciones que otros miembros de la comunidad han publicado. Por ejemplo, al buscar "),k=n("code"),A=t("OSError: Can't load config for"),S=t(" en Stack Overflow se obtienen varios resultados que pueden ser utilizados como punto de partida para resolver el problema."),this.h()},l(U){m=l(U,"P",{});var O=u(m);y=r(O,"\u{1F4A1} Si te encuentras con un mensaje de error dif\xEDcil de entender, simplemente copia y pega el mensaje en la barra de b\xFAsqueda de Google o de "),q=l(O,"A",{href:!0,rel:!0});var N=u(q);$=r(N,"Stack Overflow"),N.forEach(s),D=r(O," (\xA1s\xED, en serio!). Es muy posible que no seas la primera persona en encontrar el error, y esta es una buena forma de hallar soluciones que otros miembros de la comunidad han publicado. Por ejemplo, al buscar "),k=l(O,"CODE",{});var fe=u(k);A=r(fe,"OSError: Can't load config for"),fe.forEach(s),S=r(O," en Stack Overflow se obtienen varios resultados que pueden ser utilizados como punto de partida para resolver el problema."),O.forEach(s),this.h()},h(){c(q,"href","https://stackoverflow.com/"),c(q,"rel","nofollow")},m(U,O){i(U,m,O),a(m,y),a(m,q),a(q,$),a(m,D),a(m,k),a(k,A),a(m,S)},d(U){U&&s(m)}}}function bi(Y){let m,y,q,$,D;return{c(){m=n("p"),y=t("\u{1F6A8} El enfoque que tomamos aqu\xED no es infalible, ya que nuestro compa\xF1ero puede haber cambiado la configuraci\xF3n de "),q=n("code"),$=t("distilbert-base-uncased"),D=t(" antes de ajustar (fine-tuning) el modelo. En la vida real, nos gustar\xEDa consultar con \xE9l primero, pero para los fines de esta secci\xF3n asumiremos que us\xF3 la configuraci\xF3n predeterminada.")},l(k){m=l(k,"P",{});var A=u(m);y=r(A,"\u{1F6A8} El enfoque que tomamos aqu\xED no es infalible, ya que nuestro compa\xF1ero puede haber cambiado la configuraci\xF3n de "),q=l(A,"CODE",{});var S=u(q);$=r(S,"distilbert-base-uncased"),S.forEach(s),D=r(A," antes de ajustar (fine-tuning) el modelo. En la vida real, nos gustar\xEDa consultar con \xE9l primero, pero para los fines de esta secci\xF3n asumiremos que us\xF3 la configuraci\xF3n predeterminada."),A.forEach(s)},m(k,A){i(k,m,A),a(m,y),a(m,q),a(q,$),a(m,D)},d(k){k&&s(m)}}}function gi(Y){let m,y,q,$,D,k,A,S,U,O,N,fe,W,at,ia,st,ot,ks,_e,Es,L,tt,he,rt,nt,be,lt,it,js,ge,ys,ua,ut,xs,ve,As,X,pt,Pa,dt,ct,Ps,qe,Cs,K,mt,Ca,ft,_t,zs,B,Z,za,we,ht,Da,bt,Ds,pa,gt,Os,da,$e,vt,ca,qt,wt,Ss,ee,$t,Oa,kt,Et,Ts,ke,Hs,Ee,Ms,T,jt,Sa,yt,xt,Ta,At,Pt,Ha,Ct,zt,Qs,je,ye,Nn,Ns,E,Dt,Ma,Ot,St,Qa,Tt,Ht,Na,Mt,Qt,La,Nt,Lt,ma,It,Vt,Ia,Ft,Rt,Ls,ae,Is,I,Gt,Va,Ut,Bt,Fa,Jt,Yt,Vs,xe,Fs,se,Rs,fa,Wt,Gs,Ae,Pe,Ln,Us,_a,Xt,Bs,Ce,ze,In,Js,ha,Kt,Ys,De,Ws,Oe,Xs,V,Zt,Ra,er,ar,Ga,sr,or,Ks,Se,Zs,Te,eo,x,tr,Ua,rr,nr,Ba,lr,ir,He,Ja,ur,pr,ba,dr,cr,Ya,mr,fr,ao,Me,so,oe,oo,te,_r,Wa,hr,br,to,Qe,ro,re,gr,Xa,vr,qr,no,Ne,lo,Le,io,ga,wr,uo,H,Ie,$r,Ka,kr,Er,jr,Za,yr,xr,es,Ar,Pr,Ve,Cr,as,zr,Dr,po,va,Or,co,J,ne,ss,Fe,Sr,os,Tr,mo,M,Hr,ts,Mr,Qr,rs,Nr,Lr,ns,Ir,Vr,fo,Re,_o,qa,Fr,ho,Ge,bo,F,Rr,wa,Gr,Ur,ls,Br,Jr,go,Ue,vo,Be,qo,le,Yr,is,Wr,Xr,wo,Je,$o,$a,Kr,ko,Ye,Eo,j,Zr,us,en,an,ps,sn,on,ds,tn,rn,cs,nn,ln,ms,un,pn,fs,dn,cn,jo,We,yo,Xe,xo,ie,mn,_s,fn,_n,Ao,Ke,Po,Ze,Co,P,hn,ka,bn,gn,hs,vn,qn,bs,wn,$n,gs,kn,En,zo,ea,Do,R,jn,vs,yn,xn,aa,An,Pn,Oo,sa,oa,Vn,So,ue,Cn,qs,zn,Dn,To,ta,Ho,ra,Mo,pe,On,na,Sn,Tn,Qo;return k=new Qn({}),N=new fi({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter8/section2.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter8/section2.ipynb"}]}}),_e=new Mn({props:{id:"DQ-CpJn6Rc4"}}),ge=new w({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`}}),ve=new w({props:{code:"huggingface-cli login",highlighted:"huggingface-cli login"}}),qe=new w({props:{code:`from distutils.dir_util import copy_tree
from huggingface_hub import Repository, snapshot_download, create_repo, get_full_repo_name


def copy_repository_template():
    # Clona el repo y extrae la ruta local
    template_repo_id = "lewtun/distilbert-base-uncased-finetuned-squad-d5716d28"
    commit_hash = "be3eaffc28669d7932492681cd5f3e8905e358b4"
    template_repo_dir = snapshot_download(template_repo_id, revision=commit_hash)
    # Crea un repo vac\xEDo en el Hub
    model_name = template_repo_id.split("/")[1]
    create_repo(model_name, exist_ok=True)
    # Clona el repo vac\xEDo
    new_repo_id = get_full_repo_name(model_name)
    new_repo_dir = model_name
    repo = Repository(local_dir=new_repo_dir, clone_from=new_repo_id)
    # Copia los archivos
    copy_tree(template_repo_dir, new_repo_dir)
    # Envia (push) al Hub
    repo.push_to_hub()`,highlighted:`<span class="hljs-keyword">from</span> distutils.dir_util <span class="hljs-keyword">import</span> copy_tree
<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> Repository, snapshot_download, create_repo, get_full_repo_name


<span class="hljs-keyword">def</span> <span class="hljs-title function_">copy_repository_template</span>():
    <span class="hljs-comment"># Clona el repo y extrae la ruta local</span>
    template_repo_id = <span class="hljs-string">&quot;lewtun/distilbert-base-uncased-finetuned-squad-d5716d28&quot;</span>
    commit_hash = <span class="hljs-string">&quot;be3eaffc28669d7932492681cd5f3e8905e358b4&quot;</span>
    template_repo_dir = snapshot_download(template_repo_id, revision=commit_hash)
    <span class="hljs-comment"># Crea un repo vac\xEDo en el Hub</span>
    model_name = template_repo_id.split(<span class="hljs-string">&quot;/&quot;</span>)[<span class="hljs-number">1</span>]
    create_repo(model_name, exist_ok=<span class="hljs-literal">True</span>)
    <span class="hljs-comment"># Clona el repo vac\xEDo</span>
    new_repo_id = get_full_repo_name(model_name)
    new_repo_dir = model_name
    repo = Repository(local_dir=new_repo_dir, clone_from=new_repo_id)
    <span class="hljs-comment"># Copia los archivos</span>
    copy_tree(template_repo_dir, new_repo_dir)
    <span class="hljs-comment"># Envia (push) al Hub</span>
    repo.push_to_hub()`}}),we=new Qn({}),ke=new w({props:{code:`from transformers import pipeline

model_checkpoint = get_full_repo_name("distillbert-base-uncased-finetuned-squad-d5716d28")
reader = pipeline("question-answering", model=model_checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

model_checkpoint = get_full_repo_name(<span class="hljs-string">&quot;distillbert-base-uncased-finetuned-squad-d5716d28&quot;</span>)
reader = pipeline(<span class="hljs-string">&quot;question-answering&quot;</span>, model=model_checkpoint)`}}),Ee=new w({props:{code:`"""
OSError: Can't load config for 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28'. Make sure that:

- 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""`,highlighted:`<span class="hljs-string">&quot;&quot;&quot;
OSError: Can&#x27;t load config for &#x27;lewtun/distillbert-base-uncased-finetuned-squad-d5716d28&#x27;. Make sure that:

- &#x27;lewtun/distillbert-base-uncased-finetuned-squad-d5716d28&#x27; is a correct model identifier listed on &#x27;https://huggingface.co/models&#x27;

- or &#x27;lewtun/distillbert-base-uncased-finetuned-squad-d5716d28&#x27; is the correct path to a directory containing a config.json file
&quot;&quot;&quot;</span>`}}),ae=new Hn({props:{$$slots:{default:[_i]},$$scope:{ctx:Y}}}),xe=new w({props:{code:`"""
Make sure that:

- 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distillbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""`,highlighted:`<span class="hljs-string">&quot;&quot;&quot;
Make sure that:

- &#x27;lewtun/distillbert-base-uncased-finetuned-squad-d5716d28&#x27; is a correct model identifier listed on &#x27;https://huggingface.co/models&#x27;

- or &#x27;lewtun/distillbert-base-uncased-finetuned-squad-d5716d28&#x27; is the correct path to a directory containing a config.json file
&quot;&quot;&quot;</span>`}}),se=new Hn({props:{$$slots:{default:[hi]},$$scope:{ctx:Y}}}),De=new w({props:{code:`model_checkpoint = get_full_repo_name("distilbert-base-uncased-finetuned-squad-d5716d28")
reader = pipeline("question-answering", model=model_checkpoint)`,highlighted:`model_checkpoint = get_full_repo_name(<span class="hljs-string">&quot;distilbert-base-uncased-finetuned-squad-d5716d28&quot;</span>)
reader = pipeline(<span class="hljs-string">&quot;question-answering&quot;</span>, model=model_checkpoint)`}}),Oe=new w({props:{code:`"""
OSError: Can't load config for 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28'. Make sure that:

- 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28' is a correct model identifier listed on 'https://huggingface.co/models'

- or 'lewtun/distilbert-base-uncased-finetuned-squad-d5716d28' is the correct path to a directory containing a config.json file
"""`,highlighted:`<span class="hljs-string">&quot;&quot;&quot;
OSError: Can&#x27;t load config for &#x27;lewtun/distilbert-base-uncased-finetuned-squad-d5716d28&#x27;. Make sure that:

- &#x27;lewtun/distilbert-base-uncased-finetuned-squad-d5716d28&#x27; is a correct model identifier listed on &#x27;https://huggingface.co/models&#x27;

- or &#x27;lewtun/distilbert-base-uncased-finetuned-squad-d5716d28&#x27; is the correct path to a directory containing a config.json file
&quot;&quot;&quot;</span>`}}),Se=new w({props:{code:`from huggingface_hub import list_repo_files

list_repo_files(repo_id=model_checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> list_repo_files

list_repo_files(repo_id=model_checkpoint)`}}),Te=new w({props:{code:"['.gitattributes', 'README.md', 'pytorch_model.bin', 'special_tokens_map.json', 'tokenizer_config.json', 'training_args.bin', 'vocab.txt']",highlighted:'[<span class="hljs-string">&#x27;.gitattributes&#x27;</span>, <span class="hljs-string">&#x27;README.md&#x27;</span>, <span class="hljs-string">&#x27;pytorch_model.bin&#x27;</span>, <span class="hljs-string">&#x27;special_tokens_map.json&#x27;</span>, <span class="hljs-string">&#x27;tokenizer_config.json&#x27;</span>, <span class="hljs-string">&#x27;training_args.bin&#x27;</span>, <span class="hljs-string">&#x27;vocab.txt&#x27;</span>]'}}),Me=new w({props:{code:`from transformers import AutoConfig

pretrained_checkpoint = "distilbert-base-uncased"
config = AutoConfig.from_pretrained(pretrained_checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

pretrained_checkpoint = <span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>
config = AutoConfig.from_pretrained(pretrained_checkpoint)`}}),oe=new Hn({props:{warning:!0,$$slots:{default:[bi]},$$scope:{ctx:Y}}}),Qe=new w({props:{code:'config.push_to_hub(model_checkpoint, commit_message="Add config.json")',highlighted:'config.push_to_hub(model_checkpoint, commit_message=<span class="hljs-string">&quot;Add config.json&quot;</span>)'}}),Ne=new w({props:{code:`reader = pipeline("question-answering", model=model_checkpoint, revision="main")

context = r"""
Extractive Question Answering is the task of extracting an answer from a text
given a question. An example of a question answering dataset is the SQuAD
dataset, which is entirely based on that task. If you would like to fine-tune a
model on a SQuAD task, you may leverage the
examples/pytorch/question-answering/run_squad.py script.

\u{1F917} Transformers is interoperable with the PyTorch, TensorFlow, and JAX
frameworks, so you can use your favourite tools for a wide variety of tasks!
"""

context_es = r"""
La respuesta a preguntas es la extracci\xF3n de una respuesta textual a partir de 
una pregunta. Un ejemplo de conjunto de datos de respuesta a preguntas es el 
dataset SQuAD, que se basa por completo en esta tarea. Si deseas afinar un modelo 
en una tarea SQuAD, puedes aprovechar el script
 examples/pytorch/question-answering/run_squad.py

\u{1F917} Transformers es interoperable con los frameworks PyTorch, TensorFlow y JAX, 
as\xED que \xA1puedes utilizar tus herramientas favoritas para una gran variedad de tareas!
"""

question = "What is extractive question answering?"
# \xBFQu\xE9 es la respuesta extractiva a preguntas?
reader(question=question, context=context)`,highlighted:`reader = pipeline(<span class="hljs-string">&quot;question-answering&quot;</span>, model=model_checkpoint, revision=<span class="hljs-string">&quot;main&quot;</span>)

context = <span class="hljs-string">r&quot;&quot;&quot;
Extractive Question Answering is the task of extracting an answer from a text
given a question. An example of a question answering dataset is the SQuAD
dataset, which is entirely based on that task. If you would like to fine-tune a
model on a SQuAD task, you may leverage the
examples/pytorch/question-answering/run_squad.py script.

\u{1F917} Transformers is interoperable with the PyTorch, TensorFlow, and JAX
frameworks, so you can use your favourite tools for a wide variety of tasks!
&quot;&quot;&quot;</span>

context_es = <span class="hljs-string">r&quot;&quot;&quot;
La respuesta a preguntas es la extracci\xF3n de una respuesta textual a partir de 
una pregunta. Un ejemplo de conjunto de datos de respuesta a preguntas es el 
dataset SQuAD, que se basa por completo en esta tarea. Si deseas afinar un modelo 
en una tarea SQuAD, puedes aprovechar el script
 examples/pytorch/question-answering/run_squad.py

\u{1F917} Transformers es interoperable con los frameworks PyTorch, TensorFlow y JAX, 
as\xED que \xA1puedes utilizar tus herramientas favoritas para una gran variedad de tareas!
&quot;&quot;&quot;</span>

question = <span class="hljs-string">&quot;What is extractive question answering?&quot;</span>
<span class="hljs-comment"># \xBFQu\xE9 es la respuesta extractiva a preguntas?</span>
reader(question=question, context=context)`}}),Le=new w({props:{code:`{'score': 0.38669535517692566,
 'start': 34,
 'end': 95,
 'answer': 'the task of extracting an answer from a text given a question'}
 # la tarea de extraer una respuesta de un texto a una pregunta dada`,highlighted:`{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.38669535517692566</span>,
 <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">34</span>,
 <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">95</span>,
 <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;the task of extracting an answer from a text given a question&#x27;</span>}
 <span class="hljs-comment"># la tarea de extraer una respuesta de un texto a una pregunta dada</span>`}}),Fe=new Qn({}),Re=new w({props:{code:`tokenizer = reader.tokenizer
model = reader.model`,highlighted:`tokenizer = reader.tokenizer
model = reader.model`}}),Ge=new w({props:{code:'question = "Which frameworks can I use?"  # \xBFQu\xE9 frameworks puedo usar?',highlighted:'question = <span class="hljs-string">&quot;Which frameworks can I use?&quot;</span>  <span class="hljs-comment"># \xBFQu\xE9 frameworks puedo usar?</span>'}}),Ue=new w({props:{code:`import torch

inputs = tokenizer(question, context, add_special_tokens=True)
input_ids = inputs["input_ids"][0]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
# Obtiene el comienzo m\xE1s probable de la respuesta con el argmax de la puntuaci\xF3n
answer_start = torch.argmax(answer_start_scores)
# Obtiene el final m\xE1s probable de la respuesta con el argmax de la puntuaci\xF3n
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
print(f"Question: {question}")
print(f"Answer: {answer}")`,highlighted:`<span class="hljs-keyword">import</span> torch

inputs = tokenizer(question, context, add_special_tokens=<span class="hljs-literal">True</span>)
input_ids = inputs[<span class="hljs-string">&quot;input_ids&quot;</span>][<span class="hljs-number">0</span>]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
<span class="hljs-comment"># Obtiene el comienzo m\xE1s probable de la respuesta con el argmax de la puntuaci\xF3n</span>
answer_start = torch.argmax(answer_start_scores)
<span class="hljs-comment"># Obtiene el final m\xE1s probable de la respuesta con el argmax de la puntuaci\xF3n</span>
answer_end = torch.argmax(answer_end_scores) + <span class="hljs-number">1</span>
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Question: <span class="hljs-subst">{question}</span>&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Answer: <span class="hljs-subst">{answer}</span>&quot;</span>)`}}),Be=new w({props:{code:`"""
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
/var/folders/28/k4cy5q7s2hs92xq7_h89_vgm0000gn/T/ipykernel_75743/2725838073.py in <module>
      1 inputs = tokenizer(question, text, add_special_tokens=True)
      2 input_ids = inputs["input_ids"]
----> 3 outputs = model(**inputs)
      4 answer_start_scores = outputs.start_logits
      5 answer_end_scores = outputs.end_logits

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)
    723         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
    724
--> 725         distilbert_output = self.distilbert(
    726             input_ids=input_ids,
    727             attention_mask=attention_mask,

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError("You cannot specify both input_ids and inputs_embeds at the same time")
    472         elif input_ids is not None:
--> 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: 'list' object has no attribute 'size'
"""`,highlighted:`<span class="hljs-string">&quot;&quot;&quot;
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
/var/folders/28/k4cy5q7s2hs92xq7_h89_vgm0000gn/T/ipykernel_75743/2725838073.py in &lt;module&gt;
      1 inputs = tokenizer(question, text, add_special_tokens=True)
      2 input_ids = inputs[&quot;input_ids&quot;]
----&gt; 3 outputs = model(**inputs)
      4 answer_start_scores = outputs.start_logits
      5 answer_end_scores = outputs.end_logits

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-&gt; 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)
    723         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
    724
--&gt; 725         distilbert_output = self.distilbert(
    726             input_ids=input_ids,
    727             attention_mask=attention_mask,

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
   1049         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
   1050                 or _global_forward_hooks or _global_forward_pre_hooks):
-&gt; 1051             return forward_call(*input, **kwargs)
   1052         # Do not call functions when jit is used
   1053         full_backward_hooks, non_full_backward_hooks = [], []

~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError(&quot;You cannot specify both input_ids and inputs_embeds at the same time&quot;)
    472         elif input_ids is not None:
--&gt; 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: &#x27;list&#x27; object has no attribute &#x27;size&#x27;
&quot;&quot;&quot;</span>`}}),Je=new Mn({props:{id:"rSPyvPw0p9k"}}),Ye=new Mn({props:{id:"5PkZ4rbHL6c"}}),We=new w({props:{code:'inputs["input_ids"][:5]',highlighted:'inputs[<span class="hljs-string">&quot;input_ids&quot;</span>][:<span class="hljs-number">5</span>]'}}),Xe=new w({props:{code:"[101, 2029, 7705, 2015, 2064]",highlighted:'[<span class="hljs-number">101</span>, <span class="hljs-number">2029</span>, <span class="hljs-number">7705</span>, <span class="hljs-number">2015</span>, <span class="hljs-number">2064</span>]'}}),Ke=new w({props:{code:'type(inputs["input_ids"])',highlighted:'<span class="hljs-built_in">type</span>(inputs[<span class="hljs-string">&quot;input_ids&quot;</span>])'}}),Ze=new w({props:{code:"list",highlighted:'<span class="hljs-built_in">list</span>'}}),ea=new w({props:{code:`~/miniconda3/envs/huggingface/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    471             raise ValueError("You cannot specify both input_ids and inputs_embeds at the same time")
    472         elif input_ids is not None:
--> 473             input_shape = input_ids.size()
    474         elif inputs_embeds is not None:
    475             input_shape = inputs_embeds.size()[:-1]

AttributeError: 'list' object has no attribute 'size'`,highlighted:`~<span class="hljs-regexp">/miniconda3/</span>envs<span class="hljs-regexp">/huggingface/</span>lib<span class="hljs-regexp">/python3.8/</span>site-packages<span class="hljs-regexp">/transformers/m</span>odels<span class="hljs-regexp">/distilbert/m</span>odeling_distilbert.py in forward(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)
    <span class="hljs-number">471</span>             raise ValueError(<span class="hljs-string">&quot;You cannot specify both input_ids and inputs_embeds at the same time&quot;</span>)
    <span class="hljs-number">472</span>         elif input_ids is not None:
--&gt; <span class="hljs-number">473</span>             input_shape = input_ids.<span class="hljs-keyword">size</span>()
    <span class="hljs-number">474</span>         elif inputs_embeds is not None:
    <span class="hljs-number">475</span>             input_shape = inputs_embeds.<span class="hljs-keyword">size</span>()[:-<span class="hljs-number">1</span>]

AttributeError: <span class="hljs-string">&#x27;list&#x27;</span> object has no attribute <span class="hljs-string">&#x27;size&#x27;</span>`}}),ta=new w({props:{code:`inputs = tokenizer(question, context, add_special_tokens=True, return_tensors="pt")
input_ids = inputs["input_ids"][0]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
# Obtiene el comienzo m\xE1s probable de la respuesta con el argmax de la puntuaci\xF3n
answer_start = torch.argmax(answer_start_scores)
# Obtiene el final m\xE1s probable de la respuesta con el argmax de la puntuaci\xF3n
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
print(f"Question: {question}")
print(f"Answer: {answer}")`,highlighted:`inputs = tokenizer(question, context, add_special_tokens=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
input_ids = inputs[<span class="hljs-string">&quot;input_ids&quot;</span>][<span class="hljs-number">0</span>]
outputs = model(**inputs)
answer_start_scores = outputs.start_logits
answer_end_scores = outputs.end_logits
<span class="hljs-comment"># Obtiene el comienzo m\xE1s probable de la respuesta con el argmax de la puntuaci\xF3n</span>
answer_start = torch.argmax(answer_start_scores)
<span class="hljs-comment"># Obtiene el final m\xE1s probable de la respuesta con el argmax de la puntuaci\xF3n</span>
answer_end = torch.argmax(answer_end_scores) + <span class="hljs-number">1</span>
answer = tokenizer.convert_tokens_to_string(
    tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end])
)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Question: <span class="hljs-subst">{question}</span>&quot;</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Answer: <span class="hljs-subst">{answer}</span>&quot;</span>)`}}),ra=new w({props:{code:`"""
Question: Which frameworks can I use? # \xBFQu\xE9 frameworks puedo usar?
Answer: pytorch, tensorflow, and jax
"""`,highlighted:`<span class="hljs-string">&quot;&quot;&quot;
Question: Which frameworks can I use? # \xBFQu\xE9 frameworks puedo usar?
Answer: pytorch, tensorflow, and jax
&quot;&quot;&quot;</span>`}}),{c(){m=n("meta"),y=p(),q=n("h1"),$=n("a"),D=n("span"),f(k.$$.fragment),A=p(),S=n("span"),U=t("\xBFQu\xE9 hacer cuando se produce un error?"),O=p(),f(N.$$.fragment),fe=p(),W=n("p"),at=t("En esta secci\xF3n veremos algunos errores comunes que pueden ocurrir cuando intentas generar predicciones a partir de tu modelo Transformer reci\xE9n afinado. Esto te preparar\xE1 para la "),ia=n("a"),st=t("secci\xF3n 4"),ot=t(", en la que exploraremos c\xF3mo depurar (debug) la fase de entrenamiento."),ks=p(),f(_e.$$.fragment),Es=p(),L=n("p"),tt=t("Hemos preparado un "),he=n("a"),rt=t("repositorio de un modelo de ejemplo"),nt=t(" para esta secci\xF3n, por lo que si deseas ejecutar el c\xF3digo en este cap\xEDtulo, primero necesitar\xE1s copiar el modelo a tu cuenta en el "),be=n("a"),lt=t("Hub de Hugging Face"),it=t(". Para ello, primero inicia sesi\xF3n (log in) ejecutando lo siguiente en una Jupyter notebook:"),js=p(),f(ge.$$.fragment),ys=p(),ua=n("p"),ut=t("o puedes ejecutar lo siguiente en tu terminal favorita:"),xs=p(),f(ve.$$.fragment),As=p(),X=n("p"),pt=t("Esto te pedir\xE1 que introduzcas tu nombre de usuario y contrase\xF1a, y guardar\xE1 un token en "),Pa=n("em"),dt=t("~/.cache/huggingface/"),ct=t(". Una vez que hayas iniciado sesi\xF3n, puedes copiar el repositorio de ejemplo con la siguiente funci\xF3n:"),Ps=p(),f(qe.$$.fragment),Cs=p(),K=n("p"),mt=t("Ahora cuando llames a la funci\xF3n "),Ca=n("code"),ft=t("copy_repository_template()"),_t=t(", esta crear\xE1 una copia del repositorio de ejemplo en tu cuenta."),zs=p(),B=n("h2"),Z=n("a"),za=n("span"),f(we.$$.fragment),ht=p(),Da=n("span"),bt=t("Depurando el pipeline de \u{1F917} Transformers"),Ds=p(),pa=n("p"),gt=t("Para iniciar nuestro viaje hacia el maravilloso mundo de la depuraci\xF3n de modelos de Transformers, imagina lo siguiente: est\xE1s trabajando con un compa\xF1ero en un proyecto de respuesta a preguntas (question answering) para ayudar a los clientes de un sitio web de comercio electr\xF3nico a encontrar respuestas sobre productos de consumo. Tu compa\xF1ero te env\xEDa el siguiente mensaje:"),Os=p(),da=n("blockquote"),$e=n("p"),vt=t("\xA1Buen d\xEDa! Acabo de lanzar un experimento usando las t\xE9cnicas del "),ca=n("a"),qt=t("Capitulo 7"),wt=t(" del curso de Hugging Face y \xA1obtuvo unos buenos resultados con el conjunto de datos SQuAD! Creo que podemos usar este modelo como punto de partida para nuestro proyecto. El identificador del modelo en el Hub es \u201Clewtun/distillbert-base-uncased-finetuned-squad-d5716d28\u201D. No dudes en probarlo :)"),Ss=p(),ee=n("p"),$t=t("y en lo primero que piensas es en cargar el modelo usando el "),Oa=n("code"),kt=t("pipeline"),Et=t(" de la librer\xEDa \u{1F917} Transformers:"),Ts=p(),f(ke.$$.fragment),Hs=p(),f(Ee.$$.fragment),Ms=p(),T=n("p"),jt=t("\xA1Oh no, algo parece estar mal! Si eres nuevo en programaci\xF3n, este tipo de errores pueden parecer un poco cr\xEDpticos al inicio (\xBFqu\xE9 es un "),Sa=n("code"),yt=t("OSError"),xt=t("?). El error mostrado aqu\xED es solo la \xFAltima parte de un reporte de errores mucho m\xE1s largo llamado "),Ta=n("em"),At=t("Python traceback"),Pt=t(" (o "),Ha=n("em"),Ct=t("stack trace"),zt=t("). Por ejemplo, si est\xE1s ejecutando este c\xF3digo en Google Colab, podr\xEDas ver algo parecido como la siguiente captura:"),Qs=p(),je=n("div"),ye=n("img"),Ns=p(),E=n("p"),Dt=t("Hay mucha informaci\xF3n contenida en estos reportes, as\xED que vamos a repasar juntos las partes clave. La primera cosa que notamos es que el "),Ma=n("em"),Ot=t("traceback"),St=t(" deber\xEDa ser le\xEDdo de "),Qa=n("em"),Tt=t("abajo hacia arriba"),Ht=t(". Esto puede sonar extra\xF1o si est\xE1s acostumbrado a leer en espa\xF1ol de arriba hacia abajo, pero refleja el hecho de que el "),Na=n("em"),Mt=t("traceback"),Qt=t(" muestra la secuencia de funciones llamadas que el "),La=n("code"),Nt=t("pipeline"),Lt=t(" realiza al descargar el modelo y el tokenizador. (Ve al "),ma=n("a"),It=t("Cap\xEDtulo 2"),Vt=t(" para m\xE1s detalles sobre c\xF3mo funciona el "),Ia=n("code"),Ft=t("pipeline"),Rt=t(" bajo el cap\xF3)"),Ls=p(),f(ae.$$.fragment),Is=p(),I=n("p"),Gt=t("Esto significa que la \xFAltima l\xEDnea del traceback indica el \xFAltimo mensaje de error y nos da el nombre de la excepci\xF3n (exception) que se ha generado. En este caso, el tipo de excepci\xF3n es "),Va=n("code"),Ut=t("OSError"),Bt=t(", lo que indica un error relacionado con el sistema. Si leemos el mensaje de error que lo acompa\xF1a, podemos ver que parece haber un problema con el archivo "),Fa=n("em"),Jt=t("config.json"),Yt=t(" del modelo, y nos da dos sugerencias para solucionarlo:"),Vs=p(),f(xe.$$.fragment),Fs=p(),f(se.$$.fragment),Rs=p(),fa=n("p"),Wt=t("La primera sugerencia nos pide que comprobemos si el identificador del modelo es realmente correcto, as\xED que lo primero es copiar el identificador y pegarlo en la barra de b\xFAsqueda del Hub:"),Gs=p(),Ae=n("div"),Pe=n("img"),Us=p(),_a=n("p"),Xt=t("Hmm, efectivamente parece que el modelo de nuestro compa\xF1ero no est\xE1 en el Hub\u2026 \xA1pero hay una errata en el nombre del modelo! DistilBERT solo tiene una \u201Cl\u201D en el nombre, as\xED que vamos a corregirlo y a buscar \u201Clewtun/distilbert-base-uncased-finetuned-squad-d5716d28\u201D en su lugar:"),Bs=p(),Ce=n("div"),ze=n("img"),Js=p(),ha=n("p"),Kt=t("Bien, esto dio resultado. Ahora vamos a intentar descargar el modelo de nuevo con el identificador correcto:"),Ys=p(),f(De.$$.fragment),Ws=p(),f(Oe.$$.fragment),Xs=p(),V=n("p"),Zt=t("Argh, fall\xF3 de nuevo, \xA1bienvenido al d\xEDa a d\xEDa de un ingeniero de machine learning! Dado que arreglamos el identificador del modelo, el problema debe estar en el repositorio. Una manera r\xE1pida de acceder a los contenidos de un repositorio en el \u{1F917} Hub es por medio de la funci\xF3n "),Ra=n("code"),er=t("list_repo_files()"),ar=t(" de la librer\xEDa de "),Ga=n("code"),sr=t("huggingface_hub"),or=t(":"),Ks=p(),f(Se.$$.fragment),Zs=p(),f(Te.$$.fragment),eo=p(),x=n("p"),tr=t("Interesante. \xA1No parece haber un archivo "),Ua=n("em"),rr=t("config.json"),nr=t(" en el repositorio! No es de extra\xF1ar que nuestro "),Ba=n("code"),lr=t("pipeline"),ir=t(" no pudiera cargar el modelo; nuestro compa\xF1ero debe haberse olvidado de enviar este archivo al Hub despu\xE9s de ajustarlo (fine-tuned). En este caso, el problema parece bastante simple de resolver: podemos pedirle a nuestro compa\xF1ero que a\xF1ada el archivo, o, ya que podemos ver en el identificador del modelo que el modelo preentrenado fue "),He=n("a"),Ja=n("code"),ur=t("distilbert-base-uncased"),pr=t(", podemos descargar la configuraci\xF3n para este modelo y enviarla a nuestro repositorio para ver si eso resuelve el problema. Intentemos esto. Usando las t\xE9cnicas que aprendimos en el "),ba=n("a"),dr=t("Cap\xEDtulo 2"),cr=t(", podemos descargar la configuraci\xF3n del modelo con la clase "),Ya=n("code"),mr=t("AutoConfig"),fr=t(":"),ao=p(),f(Me.$$.fragment),so=p(),f(oe.$$.fragment),oo=p(),te=n("p"),_r=t("Luego podemos enviar esto a nuestro repositorio del modelo con la funci\xF3n de configuraci\xF3n "),Wa=n("code"),hr=t("push_to_hub()"),br=t(":"),to=p(),f(Qe.$$.fragment),ro=p(),re=n("p"),gr=t("Ahora podemos probar si esto funciona cargando el modelo desde el \xFAltimo commit de la rama "),Xa=n("code"),vr=t("main"),qr=t(":"),no=p(),f(Ne.$$.fragment),lo=p(),f(Le.$$.fragment),io=p(),ga=n("p"),wr=t("\xA1Yuju, funcion\xF3! Recapitulemos lo que acabas de aprender:"),uo=p(),H=n("ul"),Ie=n("li"),$r=t("Los mensajes de error en Python son conocidos como "),Ka=n("em"),kr=t("tracebacks"),Er=t(" y se leen de abajo hacia arriba. La \xFAltima l\xEDnea del mensaje de error generalmente contiene la informaci\xF3n que necesitas para ubicar la fuente del problema."),jr=p(),Za=n("li"),yr=t("Si la \xFAltima l\xEDnea no contiene suficiente informaci\xF3n, sigue el traceback y mira si puedes identificar en qu\xE9 parte del c\xF3digo fuente se produce el error."),xr=p(),es=n("li"),Ar=t("Si ninguno de los mensajes de error te ayuda a depurar el problema, trata de buscar en internet una soluci\xF3n a un problema similar."),Pr=p(),Ve=n("li"),Cr=t("El \u{1F917} "),as=n("code"),zr=t("huggingface_hub"),Dr=t(" de la librer\xEDa proporciona un conjunto de herramientas que puedes utilizar para interactuar y depurar los repositorios en el Hub."),po=p(),va=n("p"),Or=t("Ahora que sabes c\xF3mo depurar un pipeline, vamos a ver un ejemplo m\xE1s complicado en la pasada hacia delante (forward pass) del propio modelo."),co=p(),J=n("h2"),ne=n("a"),ss=n("span"),f(Fe.$$.fragment),Sr=p(),os=n("span"),Tr=t("Depurando la pasada hacia delante (forward pass) de tu modelo"),mo=p(),M=n("p"),Hr=t("Aunque el "),ts=n("code"),Mr=t("pipeline"),Qr=t(" es estupendo para la mayor\xEDa de las aplicaciones en las que necesitas generar predicciones r\xE1pidamente, a veces necesitar\xE1s acceder a los "),rs=n("em"),Nr=t("logits"),Lr=t(" del modelo (por ejemplo, si tienes alg\xFAn postprocesamiento personalizado que te gustar\xEDa aplicar). Para ver lo que puede salir mal en este caso, vamos a coger primero el modelo y el tokenizador de nuestro "),ns=n("code"),Ir=t("pipeline"),Vr=t(":"),fo=p(),f(Re.$$.fragment),_o=p(),qa=n("p"),Fr=t("A continuaci\xF3n, necesitamos una pregunta, as\xED que veamos si nuestros frameworks son compatibles:"),ho=p(),f(Ge.$$.fragment),bo=p(),F=n("p"),Rr=t("Como vimos en el "),wa=n("a"),Gr=t("Cap\xEDtulo 7"),Ur=t(", los pasos habituales que debemos seguir son tokenizar los inputs, extraer los "),ls=n("em"),Br=t("logits"),Jr=t(" de los tokens de inicio y fin y luego decodificar el intervalo de la respuesta:"),go=p(),f(Ue.$$.fragment),vo=p(),f(Be.$$.fragment),qo=p(),le=n("p"),Yr=t("Vaya, parece que tenemos un "),is=n("em"),Wr=t("bug"),Xr=t(" en nuestro c\xF3digo. Pero no nos asusta un poco de depuraci\xF3n. Puedes usar el depurador de Python en una notebook:"),wo=p(),f(Je.$$.fragment),$o=p(),$a=n("p"),Kr=t("o en una terminal:"),ko=p(),f(Ye.$$.fragment),Eo=p(),j=n("p"),Zr=t("Aqu\xED la lectura del mensaje de error nos dice que el objeto "),us=n("code"),en=t("'list'"),an=t(" no tiene atributo "),ps=n("code"),sn=t("'size'"),on=t(", y podemos ver una flecha "),ds=n("code"),tn=t("-->"),rn=t(" apuntando a la l\xEDnea donde el problema se origin\xF3 en "),cs=n("code"),nn=t("model(**inputs)"),ln=t(". Puedes depurar esto interactivamente usando el "),ms=n("em"),un=t("debugger"),pn=t(" de Python, pero por ahora simplemente imprimiremos un fragmento de "),fs=n("code"),dn=t("inputs"),cn=t(" para ver qu\xE9 obtenemos:"),jo=p(),f(We.$$.fragment),yo=p(),f(Xe.$$.fragment),xo=p(),ie=n("p"),mn=t("Esto sin duda parece una "),_s=n("code"),fn=t("lista"),_n=t(" ordinaria de Python, pero vamos a comprobar el tipo:"),Ao=p(),f(Ke.$$.fragment),Po=p(),f(Ze.$$.fragment),Co=p(),P=n("p"),hn=t("S\xED, es una lista de Python. Entonces, \xBFqu\xE9 sali\xF3 mal? Recordemos del "),ka=n("a"),bn=t("Cap\xEDtulo 2"),gn=t(" que las clases "),hs=n("code"),vn=t("AutoModelForXxx"),qn=t(" en \u{1F917} Transformers operan con "),bs=n("em"),wn=t("tensores"),$n=t(" (tanto en PyTorch como en TensorFlow), y una operaci\xF3n com\xFAn es extraer las dimensiones de un tensor usando "),gs=n("code"),kn=t("Tensor.size()"),En=t(" en, por ejemplo, PyTorch. Volvamos a echar un vistazo al traceback, para ver qu\xE9 l\xEDnea desencaden\xF3 la excepci\xF3n:"),zo=p(),f(ea.$$.fragment),Do=p(),R=n("p"),jn=t("Parece que nuestro c\xF3digo trata de llamar a la funci\xF3n "),vs=n("code"),yn=t("input_ids.size()"),xn=t(", pero esta claramente no funcionar\xE1 con una lista de Python, la cual solo es un contenedor. \xBFC\xF3mo podemos resolver este problema? La b\xFAsqueda del mensaje de error en Stack Overflow da bastantes "),aa=n("a"),An=t("resultados"),Pn=t(" relevantes. Al hacer clic en el primero, aparece una pregunta similar a la nuestra, con la respuesta que se muestra en la siguiente captura de pantalla:"),Oo=p(),sa=n("div"),oa=n("img"),So=p(),ue=n("p"),Cn=t("La respuesta recomienda que adicionemos "),qs=n("code"),zn=t("return_tensors='pt'"),Dn=t(" al tokenizador, as\xED que veamos si esto nos funciona:"),To=p(),f(ta.$$.fragment),Ho=p(),f(ra.$$.fragment),Mo=p(),pe=n("p"),On=t("\xA1Excelente, funcion\xF3! Este en un gran ejemplo de lo \xFAtil que puede ser Stack Overflow: al identificar un problema similar, fuimos capaces de beneficiarnos de la experiencia de otros en la comunidad. Sin embargo, una b\xFAsqueda como esta no siempre dar\xE1 una respuesta relevante, as\xED que \xBFqu\xE9 podemos hacer en esos casos? Afortunadamente hay una comunidad acogedora de desarrolladores en los "),na=n("a"),Sn=t("foros de Hugging Face"),Tn=t(" que pueden ayudarte. En la siguiente secci\xF3n, veremos c\xF3mo elaborar buenas preguntas en el foro que tengan posibilidades de ser respondidas."),this.h()},l(e){const o=ci('[data-svelte="svelte-1phssyn"]',document.head);m=l(o,"META",{name:!0,content:!0}),o.forEach(s),y=d(e),q=l(e,"H1",{class:!0});var la=u(q);$=l(la,"A",{id:!0,class:!0,href:!0});var ws=u($);D=l(ws,"SPAN",{});var $s=u(D);_(k.$$.fragment,$s),$s.forEach(s),ws.forEach(s),A=d(la),S=l(la,"SPAN",{});var Fn=u(S);U=r(Fn,"\xBFQu\xE9 hacer cuando se produce un error?"),Fn.forEach(s),la.forEach(s),O=d(e),_(N.$$.fragment,e),fe=d(e),W=l(e,"P",{});var No=u(W);at=r(No,"En esta secci\xF3n veremos algunos errores comunes que pueden ocurrir cuando intentas generar predicciones a partir de tu modelo Transformer reci\xE9n afinado. Esto te preparar\xE1 para la "),ia=l(No,"A",{href:!0});var Rn=u(ia);st=r(Rn,"secci\xF3n 4"),Rn.forEach(s),ot=r(No,", en la que exploraremos c\xF3mo depurar (debug) la fase de entrenamiento."),No.forEach(s),ks=d(e),_(_e.$$.fragment,e),Es=d(e),L=l(e,"P",{});var Ea=u(L);tt=r(Ea,"Hemos preparado un "),he=l(Ea,"A",{href:!0,rel:!0});var Gn=u(he);rt=r(Gn,"repositorio de un modelo de ejemplo"),Gn.forEach(s),nt=r(Ea," para esta secci\xF3n, por lo que si deseas ejecutar el c\xF3digo en este cap\xEDtulo, primero necesitar\xE1s copiar el modelo a tu cuenta en el "),be=l(Ea,"A",{href:!0,rel:!0});var Un=u(be);lt=r(Un,"Hub de Hugging Face"),Un.forEach(s),it=r(Ea,". Para ello, primero inicia sesi\xF3n (log in) ejecutando lo siguiente en una Jupyter notebook:"),Ea.forEach(s),js=d(e),_(ge.$$.fragment,e),ys=d(e),ua=l(e,"P",{});var Bn=u(ua);ut=r(Bn,"o puedes ejecutar lo siguiente en tu terminal favorita:"),Bn.forEach(s),xs=d(e),_(ve.$$.fragment,e),As=d(e),X=l(e,"P",{});var Lo=u(X);pt=r(Lo,"Esto te pedir\xE1 que introduzcas tu nombre de usuario y contrase\xF1a, y guardar\xE1 un token en "),Pa=l(Lo,"EM",{});var Jn=u(Pa);dt=r(Jn,"~/.cache/huggingface/"),Jn.forEach(s),ct=r(Lo,". Una vez que hayas iniciado sesi\xF3n, puedes copiar el repositorio de ejemplo con la siguiente funci\xF3n:"),Lo.forEach(s),Ps=d(e),_(qe.$$.fragment,e),Cs=d(e),K=l(e,"P",{});var Io=u(K);mt=r(Io,"Ahora cuando llames a la funci\xF3n "),Ca=l(Io,"CODE",{});var Yn=u(Ca);ft=r(Yn,"copy_repository_template()"),Yn.forEach(s),_t=r(Io,", esta crear\xE1 una copia del repositorio de ejemplo en tu cuenta."),Io.forEach(s),zs=d(e),B=l(e,"H2",{class:!0});var Vo=u(B);Z=l(Vo,"A",{id:!0,class:!0,href:!0});var Wn=u(Z);za=l(Wn,"SPAN",{});var Xn=u(za);_(we.$$.fragment,Xn),Xn.forEach(s),Wn.forEach(s),ht=d(Vo),Da=l(Vo,"SPAN",{});var Kn=u(Da);bt=r(Kn,"Depurando el pipeline de \u{1F917} Transformers"),Kn.forEach(s),Vo.forEach(s),Ds=d(e),pa=l(e,"P",{});var Zn=u(pa);gt=r(Zn,"Para iniciar nuestro viaje hacia el maravilloso mundo de la depuraci\xF3n de modelos de Transformers, imagina lo siguiente: est\xE1s trabajando con un compa\xF1ero en un proyecto de respuesta a preguntas (question answering) para ayudar a los clientes de un sitio web de comercio electr\xF3nico a encontrar respuestas sobre productos de consumo. Tu compa\xF1ero te env\xEDa el siguiente mensaje:"),Zn.forEach(s),Os=d(e),da=l(e,"BLOCKQUOTE",{});var el=u(da);$e=l(el,"P",{});var Fo=u($e);vt=r(Fo,"\xA1Buen d\xEDa! Acabo de lanzar un experimento usando las t\xE9cnicas del "),ca=l(Fo,"A",{href:!0});var al=u(ca);qt=r(al,"Capitulo 7"),al.forEach(s),wt=r(Fo," del curso de Hugging Face y \xA1obtuvo unos buenos resultados con el conjunto de datos SQuAD! Creo que podemos usar este modelo como punto de partida para nuestro proyecto. El identificador del modelo en el Hub es \u201Clewtun/distillbert-base-uncased-finetuned-squad-d5716d28\u201D. No dudes en probarlo :)"),Fo.forEach(s),el.forEach(s),Ss=d(e),ee=l(e,"P",{});var Ro=u(ee);$t=r(Ro,"y en lo primero que piensas es en cargar el modelo usando el "),Oa=l(Ro,"CODE",{});var sl=u(Oa);kt=r(sl,"pipeline"),sl.forEach(s),Et=r(Ro," de la librer\xEDa \u{1F917} Transformers:"),Ro.forEach(s),Ts=d(e),_(ke.$$.fragment,e),Hs=d(e),_(Ee.$$.fragment,e),Ms=d(e),T=l(e,"P",{});var de=u(T);jt=r(de,"\xA1Oh no, algo parece estar mal! Si eres nuevo en programaci\xF3n, este tipo de errores pueden parecer un poco cr\xEDpticos al inicio (\xBFqu\xE9 es un "),Sa=l(de,"CODE",{});var ol=u(Sa);yt=r(ol,"OSError"),ol.forEach(s),xt=r(de,"?). El error mostrado aqu\xED es solo la \xFAltima parte de un reporte de errores mucho m\xE1s largo llamado "),Ta=l(de,"EM",{});var tl=u(Ta);At=r(tl,"Python traceback"),tl.forEach(s),Pt=r(de," (o "),Ha=l(de,"EM",{});var rl=u(Ha);Ct=r(rl,"stack trace"),rl.forEach(s),zt=r(de,"). Por ejemplo, si est\xE1s ejecutando este c\xF3digo en Google Colab, podr\xEDas ver algo parecido como la siguiente captura:"),de.forEach(s),Qs=d(e),je=l(e,"DIV",{class:!0});var nl=u(je);ye=l(nl,"IMG",{src:!0,alt:!0,width:!0}),nl.forEach(s),Ns=d(e),E=l(e,"P",{});var C=u(E);Dt=r(C,"Hay mucha informaci\xF3n contenida en estos reportes, as\xED que vamos a repasar juntos las partes clave. La primera cosa que notamos es que el "),Ma=l(C,"EM",{});var ll=u(Ma);Ot=r(ll,"traceback"),ll.forEach(s),St=r(C," deber\xEDa ser le\xEDdo de "),Qa=l(C,"EM",{});var il=u(Qa);Tt=r(il,"abajo hacia arriba"),il.forEach(s),Ht=r(C,". Esto puede sonar extra\xF1o si est\xE1s acostumbrado a leer en espa\xF1ol de arriba hacia abajo, pero refleja el hecho de que el "),Na=l(C,"EM",{});var ul=u(Na);Mt=r(ul,"traceback"),ul.forEach(s),Qt=r(C," muestra la secuencia de funciones llamadas que el "),La=l(C,"CODE",{});var pl=u(La);Nt=r(pl,"pipeline"),pl.forEach(s),Lt=r(C," realiza al descargar el modelo y el tokenizador. (Ve al "),ma=l(C,"A",{href:!0});var dl=u(ma);It=r(dl,"Cap\xEDtulo 2"),dl.forEach(s),Vt=r(C," para m\xE1s detalles sobre c\xF3mo funciona el "),Ia=l(C,"CODE",{});var cl=u(Ia);Ft=r(cl,"pipeline"),cl.forEach(s),Rt=r(C," bajo el cap\xF3)"),C.forEach(s),Ls=d(e),_(ae.$$.fragment,e),Is=d(e),I=l(e,"P",{});var ja=u(I);Gt=r(ja,"Esto significa que la \xFAltima l\xEDnea del traceback indica el \xFAltimo mensaje de error y nos da el nombre de la excepci\xF3n (exception) que se ha generado. En este caso, el tipo de excepci\xF3n es "),Va=l(ja,"CODE",{});var ml=u(Va);Ut=r(ml,"OSError"),ml.forEach(s),Bt=r(ja,", lo que indica un error relacionado con el sistema. Si leemos el mensaje de error que lo acompa\xF1a, podemos ver que parece haber un problema con el archivo "),Fa=l(ja,"EM",{});var fl=u(Fa);Jt=r(fl,"config.json"),fl.forEach(s),Yt=r(ja," del modelo, y nos da dos sugerencias para solucionarlo:"),ja.forEach(s),Vs=d(e),_(xe.$$.fragment,e),Fs=d(e),_(se.$$.fragment,e),Rs=d(e),fa=l(e,"P",{});var _l=u(fa);Wt=r(_l,"La primera sugerencia nos pide que comprobemos si el identificador del modelo es realmente correcto, as\xED que lo primero es copiar el identificador y pegarlo en la barra de b\xFAsqueda del Hub:"),_l.forEach(s),Gs=d(e),Ae=l(e,"DIV",{class:!0});var hl=u(Ae);Pe=l(hl,"IMG",{src:!0,alt:!0,width:!0}),hl.forEach(s),Us=d(e),_a=l(e,"P",{});var bl=u(_a);Xt=r(bl,"Hmm, efectivamente parece que el modelo de nuestro compa\xF1ero no est\xE1 en el Hub\u2026 \xA1pero hay una errata en el nombre del modelo! DistilBERT solo tiene una \u201Cl\u201D en el nombre, as\xED que vamos a corregirlo y a buscar \u201Clewtun/distilbert-base-uncased-finetuned-squad-d5716d28\u201D en su lugar:"),bl.forEach(s),Bs=d(e),Ce=l(e,"DIV",{class:!0});var gl=u(Ce);ze=l(gl,"IMG",{src:!0,alt:!0,width:!0}),gl.forEach(s),Js=d(e),ha=l(e,"P",{});var vl=u(ha);Kt=r(vl,"Bien, esto dio resultado. Ahora vamos a intentar descargar el modelo de nuevo con el identificador correcto:"),vl.forEach(s),Ys=d(e),_(De.$$.fragment,e),Ws=d(e),_(Oe.$$.fragment,e),Xs=d(e),V=l(e,"P",{});var ya=u(V);Zt=r(ya,"Argh, fall\xF3 de nuevo, \xA1bienvenido al d\xEDa a d\xEDa de un ingeniero de machine learning! Dado que arreglamos el identificador del modelo, el problema debe estar en el repositorio. Una manera r\xE1pida de acceder a los contenidos de un repositorio en el \u{1F917} Hub es por medio de la funci\xF3n "),Ra=l(ya,"CODE",{});var ql=u(Ra);er=r(ql,"list_repo_files()"),ql.forEach(s),ar=r(ya," de la librer\xEDa de "),Ga=l(ya,"CODE",{});var wl=u(Ga);sr=r(wl,"huggingface_hub"),wl.forEach(s),or=r(ya,":"),ya.forEach(s),Ks=d(e),_(Se.$$.fragment,e),Zs=d(e),_(Te.$$.fragment,e),eo=d(e),x=l(e,"P",{});var Q=u(x);tr=r(Q,"Interesante. \xA1No parece haber un archivo "),Ua=l(Q,"EM",{});var $l=u(Ua);rr=r($l,"config.json"),$l.forEach(s),nr=r(Q," en el repositorio! No es de extra\xF1ar que nuestro "),Ba=l(Q,"CODE",{});var kl=u(Ba);lr=r(kl,"pipeline"),kl.forEach(s),ir=r(Q," no pudiera cargar el modelo; nuestro compa\xF1ero debe haberse olvidado de enviar este archivo al Hub despu\xE9s de ajustarlo (fine-tuned). En este caso, el problema parece bastante simple de resolver: podemos pedirle a nuestro compa\xF1ero que a\xF1ada el archivo, o, ya que podemos ver en el identificador del modelo que el modelo preentrenado fue "),He=l(Q,"A",{href:!0,rel:!0});var El=u(He);Ja=l(El,"CODE",{});var jl=u(Ja);ur=r(jl,"distilbert-base-uncased"),jl.forEach(s),El.forEach(s),pr=r(Q,", podemos descargar la configuraci\xF3n para este modelo y enviarla a nuestro repositorio para ver si eso resuelve el problema. Intentemos esto. Usando las t\xE9cnicas que aprendimos en el "),ba=l(Q,"A",{href:!0});var yl=u(ba);dr=r(yl,"Cap\xEDtulo 2"),yl.forEach(s),cr=r(Q,", podemos descargar la configuraci\xF3n del modelo con la clase "),Ya=l(Q,"CODE",{});var xl=u(Ya);mr=r(xl,"AutoConfig"),xl.forEach(s),fr=r(Q,":"),Q.forEach(s),ao=d(e),_(Me.$$.fragment,e),so=d(e),_(oe.$$.fragment,e),oo=d(e),te=l(e,"P",{});var Go=u(te);_r=r(Go,"Luego podemos enviar esto a nuestro repositorio del modelo con la funci\xF3n de configuraci\xF3n "),Wa=l(Go,"CODE",{});var Al=u(Wa);hr=r(Al,"push_to_hub()"),Al.forEach(s),br=r(Go,":"),Go.forEach(s),to=d(e),_(Qe.$$.fragment,e),ro=d(e),re=l(e,"P",{});var Uo=u(re);gr=r(Uo,"Ahora podemos probar si esto funciona cargando el modelo desde el \xFAltimo commit de la rama "),Xa=l(Uo,"CODE",{});var Pl=u(Xa);vr=r(Pl,"main"),Pl.forEach(s),qr=r(Uo,":"),Uo.forEach(s),no=d(e),_(Ne.$$.fragment,e),lo=d(e),_(Le.$$.fragment,e),io=d(e),ga=l(e,"P",{});var Cl=u(ga);wr=r(Cl,"\xA1Yuju, funcion\xF3! Recapitulemos lo que acabas de aprender:"),Cl.forEach(s),uo=d(e),H=l(e,"UL",{});var ce=u(H);Ie=l(ce,"LI",{});var Bo=u(Ie);$r=r(Bo,"Los mensajes de error en Python son conocidos como "),Ka=l(Bo,"EM",{});var zl=u(Ka);kr=r(zl,"tracebacks"),zl.forEach(s),Er=r(Bo," y se leen de abajo hacia arriba. La \xFAltima l\xEDnea del mensaje de error generalmente contiene la informaci\xF3n que necesitas para ubicar la fuente del problema."),Bo.forEach(s),jr=d(ce),Za=l(ce,"LI",{});var Dl=u(Za);yr=r(Dl,"Si la \xFAltima l\xEDnea no contiene suficiente informaci\xF3n, sigue el traceback y mira si puedes identificar en qu\xE9 parte del c\xF3digo fuente se produce el error."),Dl.forEach(s),xr=d(ce),es=l(ce,"LI",{});var Ol=u(es);Ar=r(Ol,"Si ninguno de los mensajes de error te ayuda a depurar el problema, trata de buscar en internet una soluci\xF3n a un problema similar."),Ol.forEach(s),Pr=d(ce),Ve=l(ce,"LI",{});var Jo=u(Ve);Cr=r(Jo,"El \u{1F917} "),as=l(Jo,"CODE",{});var Sl=u(as);zr=r(Sl,"huggingface_hub"),Sl.forEach(s),Dr=r(Jo," de la librer\xEDa proporciona un conjunto de herramientas que puedes utilizar para interactuar y depurar los repositorios en el Hub."),Jo.forEach(s),ce.forEach(s),po=d(e),va=l(e,"P",{});var Tl=u(va);Or=r(Tl,"Ahora que sabes c\xF3mo depurar un pipeline, vamos a ver un ejemplo m\xE1s complicado en la pasada hacia delante (forward pass) del propio modelo."),Tl.forEach(s),co=d(e),J=l(e,"H2",{class:!0});var Yo=u(J);ne=l(Yo,"A",{id:!0,class:!0,href:!0});var Hl=u(ne);ss=l(Hl,"SPAN",{});var Ml=u(ss);_(Fe.$$.fragment,Ml),Ml.forEach(s),Hl.forEach(s),Sr=d(Yo),os=l(Yo,"SPAN",{});var Ql=u(os);Tr=r(Ql,"Depurando la pasada hacia delante (forward pass) de tu modelo"),Ql.forEach(s),Yo.forEach(s),mo=d(e),M=l(e,"P",{});var me=u(M);Hr=r(me,"Aunque el "),ts=l(me,"CODE",{});var Nl=u(ts);Mr=r(Nl,"pipeline"),Nl.forEach(s),Qr=r(me," es estupendo para la mayor\xEDa de las aplicaciones en las que necesitas generar predicciones r\xE1pidamente, a veces necesitar\xE1s acceder a los "),rs=l(me,"EM",{});var Ll=u(rs);Nr=r(Ll,"logits"),Ll.forEach(s),Lr=r(me," del modelo (por ejemplo, si tienes alg\xFAn postprocesamiento personalizado que te gustar\xEDa aplicar). Para ver lo que puede salir mal en este caso, vamos a coger primero el modelo y el tokenizador de nuestro "),ns=l(me,"CODE",{});var Il=u(ns);Ir=r(Il,"pipeline"),Il.forEach(s),Vr=r(me,":"),me.forEach(s),fo=d(e),_(Re.$$.fragment,e),_o=d(e),qa=l(e,"P",{});var Vl=u(qa);Fr=r(Vl,"A continuaci\xF3n, necesitamos una pregunta, as\xED que veamos si nuestros frameworks son compatibles:"),Vl.forEach(s),ho=d(e),_(Ge.$$.fragment,e),bo=d(e),F=l(e,"P",{});var xa=u(F);Rr=r(xa,"Como vimos en el "),wa=l(xa,"A",{href:!0});var Fl=u(wa);Gr=r(Fl,"Cap\xEDtulo 7"),Fl.forEach(s),Ur=r(xa,", los pasos habituales que debemos seguir son tokenizar los inputs, extraer los "),ls=l(xa,"EM",{});var Rl=u(ls);Br=r(Rl,"logits"),Rl.forEach(s),Jr=r(xa," de los tokens de inicio y fin y luego decodificar el intervalo de la respuesta:"),xa.forEach(s),go=d(e),_(Ue.$$.fragment,e),vo=d(e),_(Be.$$.fragment,e),qo=d(e),le=l(e,"P",{});var Wo=u(le);Yr=r(Wo,"Vaya, parece que tenemos un "),is=l(Wo,"EM",{});var Gl=u(is);Wr=r(Gl,"bug"),Gl.forEach(s),Xr=r(Wo," en nuestro c\xF3digo. Pero no nos asusta un poco de depuraci\xF3n. Puedes usar el depurador de Python en una notebook:"),Wo.forEach(s),wo=d(e),_(Je.$$.fragment,e),$o=d(e),$a=l(e,"P",{});var Ul=u($a);Kr=r(Ul,"o en una terminal:"),Ul.forEach(s),ko=d(e),_(Ye.$$.fragment,e),Eo=d(e),j=l(e,"P",{});var z=u(j);Zr=r(z,"Aqu\xED la lectura del mensaje de error nos dice que el objeto "),us=l(z,"CODE",{});var Bl=u(us);en=r(Bl,"'list'"),Bl.forEach(s),an=r(z," no tiene atributo "),ps=l(z,"CODE",{});var Jl=u(ps);sn=r(Jl,"'size'"),Jl.forEach(s),on=r(z,", y podemos ver una flecha "),ds=l(z,"CODE",{});var Yl=u(ds);tn=r(Yl,"-->"),Yl.forEach(s),rn=r(z," apuntando a la l\xEDnea donde el problema se origin\xF3 en "),cs=l(z,"CODE",{});var Wl=u(cs);nn=r(Wl,"model(**inputs)"),Wl.forEach(s),ln=r(z,". Puedes depurar esto interactivamente usando el "),ms=l(z,"EM",{});var Xl=u(ms);un=r(Xl,"debugger"),Xl.forEach(s),pn=r(z," de Python, pero por ahora simplemente imprimiremos un fragmento de "),fs=l(z,"CODE",{});var Kl=u(fs);dn=r(Kl,"inputs"),Kl.forEach(s),cn=r(z," para ver qu\xE9 obtenemos:"),z.forEach(s),jo=d(e),_(We.$$.fragment,e),yo=d(e),_(Xe.$$.fragment,e),xo=d(e),ie=l(e,"P",{});var Xo=u(ie);mn=r(Xo,"Esto sin duda parece una "),_s=l(Xo,"CODE",{});var Zl=u(_s);fn=r(Zl,"lista"),Zl.forEach(s),_n=r(Xo," ordinaria de Python, pero vamos a comprobar el tipo:"),Xo.forEach(s),Ao=d(e),_(Ke.$$.fragment,e),Po=d(e),_(Ze.$$.fragment,e),Co=d(e),P=l(e,"P",{});var G=u(P);hn=r(G,"S\xED, es una lista de Python. Entonces, \xBFqu\xE9 sali\xF3 mal? Recordemos del "),ka=l(G,"A",{href:!0});var ei=u(ka);bn=r(ei,"Cap\xEDtulo 2"),ei.forEach(s),gn=r(G," que las clases "),hs=l(G,"CODE",{});var ai=u(hs);vn=r(ai,"AutoModelForXxx"),ai.forEach(s),qn=r(G," en \u{1F917} Transformers operan con "),bs=l(G,"EM",{});var si=u(bs);wn=r(si,"tensores"),si.forEach(s),$n=r(G," (tanto en PyTorch como en TensorFlow), y una operaci\xF3n com\xFAn es extraer las dimensiones de un tensor usando "),gs=l(G,"CODE",{});var oi=u(gs);kn=r(oi,"Tensor.size()"),oi.forEach(s),En=r(G," en, por ejemplo, PyTorch. Volvamos a echar un vistazo al traceback, para ver qu\xE9 l\xEDnea desencaden\xF3 la excepci\xF3n:"),G.forEach(s),zo=d(e),_(ea.$$.fragment,e),Do=d(e),R=l(e,"P",{});var Aa=u(R);jn=r(Aa,"Parece que nuestro c\xF3digo trata de llamar a la funci\xF3n "),vs=l(Aa,"CODE",{});var ti=u(vs);yn=r(ti,"input_ids.size()"),ti.forEach(s),xn=r(Aa,", pero esta claramente no funcionar\xE1 con una lista de Python, la cual solo es un contenedor. \xBFC\xF3mo podemos resolver este problema? La b\xFAsqueda del mensaje de error en Stack Overflow da bastantes "),aa=l(Aa,"A",{href:!0,rel:!0});var ri=u(aa);An=r(ri,"resultados"),ri.forEach(s),Pn=r(Aa," relevantes. Al hacer clic en el primero, aparece una pregunta similar a la nuestra, con la respuesta que se muestra en la siguiente captura de pantalla:"),Aa.forEach(s),Oo=d(e),sa=l(e,"DIV",{class:!0});var ni=u(sa);oa=l(ni,"IMG",{src:!0,alt:!0,width:!0}),ni.forEach(s),So=d(e),ue=l(e,"P",{});var Ko=u(ue);Cn=r(Ko,"La respuesta recomienda que adicionemos "),qs=l(Ko,"CODE",{});var li=u(qs);zn=r(li,"return_tensors='pt'"),li.forEach(s),Dn=r(Ko," al tokenizador, as\xED que veamos si esto nos funciona:"),Ko.forEach(s),To=d(e),_(ta.$$.fragment,e),Ho=d(e),_(ra.$$.fragment,e),Mo=d(e),pe=l(e,"P",{});var Zo=u(pe);On=r(Zo,"\xA1Excelente, funcion\xF3! Este en un gran ejemplo de lo \xFAtil que puede ser Stack Overflow: al identificar un problema similar, fuimos capaces de beneficiarnos de la experiencia de otros en la comunidad. Sin embargo, una b\xFAsqueda como esta no siempre dar\xE1 una respuesta relevante, as\xED que \xBFqu\xE9 podemos hacer en esos casos? Afortunadamente hay una comunidad acogedora de desarrolladores en los "),na=l(Zo,"A",{href:!0,rel:!0});var ii=u(na);Sn=r(ii,"foros de Hugging Face"),ii.forEach(s),Tn=r(Zo," que pueden ayudarte. En la siguiente secci\xF3n, veremos c\xF3mo elaborar buenas preguntas en el foro que tengan posibilidades de ser respondidas."),Zo.forEach(s),this.h()},h(){c(m,"name","hf:doc:metadata"),c(m,"content",JSON.stringify(vi)),c($,"id","qu-hacer-cuando-se-produce-un-error"),c($,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($,"href","#qu-hacer-cuando-se-produce-un-error"),c(q,"class","relative group"),c(ia,"href","/course/chapter8/section4"),c(he,"href","https://huggingface.co/lewtun/distilbert-base-uncased-finetuned-squad-d5716d28"),c(he,"rel","nofollow"),c(be,"href","https://huggingface.co"),c(be,"rel","nofollow"),c(Z,"id","depurando-el-pipeline-de-transformers"),c(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Z,"href","#depurando-el-pipeline-de-transformers"),c(B,"class","relative group"),c(ca,"href","/course/chapter7/7"),et(ye.src,Nn="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/traceback.png")||c(ye,"src",Nn),c(ye,"alt","A Python traceback."),c(ye,"width","100%"),c(je,"class","flex justify-center"),c(ma,"href","/course/chapter2"),et(Pe.src,Ln="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/wrong-model-id.png")||c(Pe,"src",Ln),c(Pe,"alt","The wrong model name."),c(Pe,"width","100%"),c(Ae,"class","flex justify-center"),et(ze.src,In="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/true-model-id.png")||c(ze,"src",In),c(ze,"alt","The right model name."),c(ze,"width","100%"),c(Ce,"class","flex justify-center"),c(He,"href","https://huggingface.co/distilbert-base-uncased"),c(He,"rel","nofollow"),c(ba,"href","/course/chapter2"),c(ne,"id","depurando-la-pasada-hacia-delante-forward-pass-de-tu-modelo"),c(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ne,"href","#depurando-la-pasada-hacia-delante-forward-pass-de-tu-modelo"),c(J,"class","relative group"),c(wa,"href","/course/chapter7"),c(ka,"href","/course/chapter2"),c(aa,"href","https://stackoverflow.com/search?q=AttributeError%3A+%27list%27+object+has+no+attribute+%27size%27&s=c15ec54c-63cb-481d-a749-408920073e8f"),c(aa,"rel","nofollow"),et(oa.src,Vn="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter8/stack-overflow.png")||c(oa,"src",Vn),c(oa,"alt","An answer from Stack Overflow."),c(oa,"width","100%"),c(sa,"class","flex justify-center"),c(na,"href","https://discuss.huggingface.co/"),c(na,"rel","nofollow")},m(e,o){a(document.head,m),i(e,y,o),i(e,q,o),a(q,$),a($,D),h(k,D,null),a(q,A),a(q,S),a(S,U),i(e,O,o),h(N,e,o),i(e,fe,o),i(e,W,o),a(W,at),a(W,ia),a(ia,st),a(W,ot),i(e,ks,o),h(_e,e,o),i(e,Es,o),i(e,L,o),a(L,tt),a(L,he),a(he,rt),a(L,nt),a(L,be),a(be,lt),a(L,it),i(e,js,o),h(ge,e,o),i(e,ys,o),i(e,ua,o),a(ua,ut),i(e,xs,o),h(ve,e,o),i(e,As,o),i(e,X,o),a(X,pt),a(X,Pa),a(Pa,dt),a(X,ct),i(e,Ps,o),h(qe,e,o),i(e,Cs,o),i(e,K,o),a(K,mt),a(K,Ca),a(Ca,ft),a(K,_t),i(e,zs,o),i(e,B,o),a(B,Z),a(Z,za),h(we,za,null),a(B,ht),a(B,Da),a(Da,bt),i(e,Ds,o),i(e,pa,o),a(pa,gt),i(e,Os,o),i(e,da,o),a(da,$e),a($e,vt),a($e,ca),a(ca,qt),a($e,wt),i(e,Ss,o),i(e,ee,o),a(ee,$t),a(ee,Oa),a(Oa,kt),a(ee,Et),i(e,Ts,o),h(ke,e,o),i(e,Hs,o),h(Ee,e,o),i(e,Ms,o),i(e,T,o),a(T,jt),a(T,Sa),a(Sa,yt),a(T,xt),a(T,Ta),a(Ta,At),a(T,Pt),a(T,Ha),a(Ha,Ct),a(T,zt),i(e,Qs,o),i(e,je,o),a(je,ye),i(e,Ns,o),i(e,E,o),a(E,Dt),a(E,Ma),a(Ma,Ot),a(E,St),a(E,Qa),a(Qa,Tt),a(E,Ht),a(E,Na),a(Na,Mt),a(E,Qt),a(E,La),a(La,Nt),a(E,Lt),a(E,ma),a(ma,It),a(E,Vt),a(E,Ia),a(Ia,Ft),a(E,Rt),i(e,Ls,o),h(ae,e,o),i(e,Is,o),i(e,I,o),a(I,Gt),a(I,Va),a(Va,Ut),a(I,Bt),a(I,Fa),a(Fa,Jt),a(I,Yt),i(e,Vs,o),h(xe,e,o),i(e,Fs,o),h(se,e,o),i(e,Rs,o),i(e,fa,o),a(fa,Wt),i(e,Gs,o),i(e,Ae,o),a(Ae,Pe),i(e,Us,o),i(e,_a,o),a(_a,Xt),i(e,Bs,o),i(e,Ce,o),a(Ce,ze),i(e,Js,o),i(e,ha,o),a(ha,Kt),i(e,Ys,o),h(De,e,o),i(e,Ws,o),h(Oe,e,o),i(e,Xs,o),i(e,V,o),a(V,Zt),a(V,Ra),a(Ra,er),a(V,ar),a(V,Ga),a(Ga,sr),a(V,or),i(e,Ks,o),h(Se,e,o),i(e,Zs,o),h(Te,e,o),i(e,eo,o),i(e,x,o),a(x,tr),a(x,Ua),a(Ua,rr),a(x,nr),a(x,Ba),a(Ba,lr),a(x,ir),a(x,He),a(He,Ja),a(Ja,ur),a(x,pr),a(x,ba),a(ba,dr),a(x,cr),a(x,Ya),a(Ya,mr),a(x,fr),i(e,ao,o),h(Me,e,o),i(e,so,o),h(oe,e,o),i(e,oo,o),i(e,te,o),a(te,_r),a(te,Wa),a(Wa,hr),a(te,br),i(e,to,o),h(Qe,e,o),i(e,ro,o),i(e,re,o),a(re,gr),a(re,Xa),a(Xa,vr),a(re,qr),i(e,no,o),h(Ne,e,o),i(e,lo,o),h(Le,e,o),i(e,io,o),i(e,ga,o),a(ga,wr),i(e,uo,o),i(e,H,o),a(H,Ie),a(Ie,$r),a(Ie,Ka),a(Ka,kr),a(Ie,Er),a(H,jr),a(H,Za),a(Za,yr),a(H,xr),a(H,es),a(es,Ar),a(H,Pr),a(H,Ve),a(Ve,Cr),a(Ve,as),a(as,zr),a(Ve,Dr),i(e,po,o),i(e,va,o),a(va,Or),i(e,co,o),i(e,J,o),a(J,ne),a(ne,ss),h(Fe,ss,null),a(J,Sr),a(J,os),a(os,Tr),i(e,mo,o),i(e,M,o),a(M,Hr),a(M,ts),a(ts,Mr),a(M,Qr),a(M,rs),a(rs,Nr),a(M,Lr),a(M,ns),a(ns,Ir),a(M,Vr),i(e,fo,o),h(Re,e,o),i(e,_o,o),i(e,qa,o),a(qa,Fr),i(e,ho,o),h(Ge,e,o),i(e,bo,o),i(e,F,o),a(F,Rr),a(F,wa),a(wa,Gr),a(F,Ur),a(F,ls),a(ls,Br),a(F,Jr),i(e,go,o),h(Ue,e,o),i(e,vo,o),h(Be,e,o),i(e,qo,o),i(e,le,o),a(le,Yr),a(le,is),a(is,Wr),a(le,Xr),i(e,wo,o),h(Je,e,o),i(e,$o,o),i(e,$a,o),a($a,Kr),i(e,ko,o),h(Ye,e,o),i(e,Eo,o),i(e,j,o),a(j,Zr),a(j,us),a(us,en),a(j,an),a(j,ps),a(ps,sn),a(j,on),a(j,ds),a(ds,tn),a(j,rn),a(j,cs),a(cs,nn),a(j,ln),a(j,ms),a(ms,un),a(j,pn),a(j,fs),a(fs,dn),a(j,cn),i(e,jo,o),h(We,e,o),i(e,yo,o),h(Xe,e,o),i(e,xo,o),i(e,ie,o),a(ie,mn),a(ie,_s),a(_s,fn),a(ie,_n),i(e,Ao,o),h(Ke,e,o),i(e,Po,o),h(Ze,e,o),i(e,Co,o),i(e,P,o),a(P,hn),a(P,ka),a(ka,bn),a(P,gn),a(P,hs),a(hs,vn),a(P,qn),a(P,bs),a(bs,wn),a(P,$n),a(P,gs),a(gs,kn),a(P,En),i(e,zo,o),h(ea,e,o),i(e,Do,o),i(e,R,o),a(R,jn),a(R,vs),a(vs,yn),a(R,xn),a(R,aa),a(aa,An),a(R,Pn),i(e,Oo,o),i(e,sa,o),a(sa,oa),i(e,So,o),i(e,ue,o),a(ue,Cn),a(ue,qs),a(qs,zn),a(ue,Dn),i(e,To,o),h(ta,e,o),i(e,Ho,o),h(ra,e,o),i(e,Mo,o),i(e,pe,o),a(pe,On),a(pe,na),a(na,Sn),a(pe,Tn),Qo=!0},p(e,[o]){const la={};o&2&&(la.$$scope={dirty:o,ctx:e}),ae.$set(la);const ws={};o&2&&(ws.$$scope={dirty:o,ctx:e}),se.$set(ws);const $s={};o&2&&($s.$$scope={dirty:o,ctx:e}),oe.$set($s)},i(e){Qo||(b(k.$$.fragment,e),b(N.$$.fragment,e),b(_e.$$.fragment,e),b(ge.$$.fragment,e),b(ve.$$.fragment,e),b(qe.$$.fragment,e),b(we.$$.fragment,e),b(ke.$$.fragment,e),b(Ee.$$.fragment,e),b(ae.$$.fragment,e),b(xe.$$.fragment,e),b(se.$$.fragment,e),b(De.$$.fragment,e),b(Oe.$$.fragment,e),b(Se.$$.fragment,e),b(Te.$$.fragment,e),b(Me.$$.fragment,e),b(oe.$$.fragment,e),b(Qe.$$.fragment,e),b(Ne.$$.fragment,e),b(Le.$$.fragment,e),b(Fe.$$.fragment,e),b(Re.$$.fragment,e),b(Ge.$$.fragment,e),b(Ue.$$.fragment,e),b(Be.$$.fragment,e),b(Je.$$.fragment,e),b(Ye.$$.fragment,e),b(We.$$.fragment,e),b(Xe.$$.fragment,e),b(Ke.$$.fragment,e),b(Ze.$$.fragment,e),b(ea.$$.fragment,e),b(ta.$$.fragment,e),b(ra.$$.fragment,e),Qo=!0)},o(e){g(k.$$.fragment,e),g(N.$$.fragment,e),g(_e.$$.fragment,e),g(ge.$$.fragment,e),g(ve.$$.fragment,e),g(qe.$$.fragment,e),g(we.$$.fragment,e),g(ke.$$.fragment,e),g(Ee.$$.fragment,e),g(ae.$$.fragment,e),g(xe.$$.fragment,e),g(se.$$.fragment,e),g(De.$$.fragment,e),g(Oe.$$.fragment,e),g(Se.$$.fragment,e),g(Te.$$.fragment,e),g(Me.$$.fragment,e),g(oe.$$.fragment,e),g(Qe.$$.fragment,e),g(Ne.$$.fragment,e),g(Le.$$.fragment,e),g(Fe.$$.fragment,e),g(Re.$$.fragment,e),g(Ge.$$.fragment,e),g(Ue.$$.fragment,e),g(Be.$$.fragment,e),g(Je.$$.fragment,e),g(Ye.$$.fragment,e),g(We.$$.fragment,e),g(Xe.$$.fragment,e),g(Ke.$$.fragment,e),g(Ze.$$.fragment,e),g(ea.$$.fragment,e),g(ta.$$.fragment,e),g(ra.$$.fragment,e),Qo=!1},d(e){s(m),e&&s(y),e&&s(q),v(k),e&&s(O),v(N,e),e&&s(fe),e&&s(W),e&&s(ks),v(_e,e),e&&s(Es),e&&s(L),e&&s(js),v(ge,e),e&&s(ys),e&&s(ua),e&&s(xs),v(ve,e),e&&s(As),e&&s(X),e&&s(Ps),v(qe,e),e&&s(Cs),e&&s(K),e&&s(zs),e&&s(B),v(we),e&&s(Ds),e&&s(pa),e&&s(Os),e&&s(da),e&&s(Ss),e&&s(ee),e&&s(Ts),v(ke,e),e&&s(Hs),v(Ee,e),e&&s(Ms),e&&s(T),e&&s(Qs),e&&s(je),e&&s(Ns),e&&s(E),e&&s(Ls),v(ae,e),e&&s(Is),e&&s(I),e&&s(Vs),v(xe,e),e&&s(Fs),v(se,e),e&&s(Rs),e&&s(fa),e&&s(Gs),e&&s(Ae),e&&s(Us),e&&s(_a),e&&s(Bs),e&&s(Ce),e&&s(Js),e&&s(ha),e&&s(Ys),v(De,e),e&&s(Ws),v(Oe,e),e&&s(Xs),e&&s(V),e&&s(Ks),v(Se,e),e&&s(Zs),v(Te,e),e&&s(eo),e&&s(x),e&&s(ao),v(Me,e),e&&s(so),v(oe,e),e&&s(oo),e&&s(te),e&&s(to),v(Qe,e),e&&s(ro),e&&s(re),e&&s(no),v(Ne,e),e&&s(lo),v(Le,e),e&&s(io),e&&s(ga),e&&s(uo),e&&s(H),e&&s(po),e&&s(va),e&&s(co),e&&s(J),v(Fe),e&&s(mo),e&&s(M),e&&s(fo),v(Re,e),e&&s(_o),e&&s(qa),e&&s(ho),v(Ge,e),e&&s(bo),e&&s(F),e&&s(go),v(Ue,e),e&&s(vo),v(Be,e),e&&s(qo),e&&s(le),e&&s(wo),v(Je,e),e&&s($o),e&&s($a),e&&s(ko),v(Ye,e),e&&s(Eo),e&&s(j),e&&s(jo),v(We,e),e&&s(yo),v(Xe,e),e&&s(xo),e&&s(ie),e&&s(Ao),v(Ke,e),e&&s(Po),v(Ze,e),e&&s(Co),e&&s(P),e&&s(zo),v(ea,e),e&&s(Do),e&&s(R),e&&s(Oo),e&&s(sa),e&&s(So),e&&s(ue),e&&s(To),v(ta,e),e&&s(Ho),v(ra,e),e&&s(Mo),e&&s(pe)}}}const vi={local:"qu-hacer-cuando-se-produce-un-error",sections:[{local:"depurando-el-pipeline-de-transformers",title:"Depurando el pipeline de \u{1F917} Transformers"},{local:"depurando-la-pasada-hacia-delante-forward-pass-de-tu-modelo",title:"Depurando la pasada hacia delante (forward pass) de tu modelo"}],title:"\xBFQu\xE9 hacer cuando se produce un error?"};function qi(Y){return mi(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class xi extends ui{constructor(m){super();pi(this,m,qi,gi,di,{})}}export{xi as default,vi as metadata};
