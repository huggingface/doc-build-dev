import{S as Rx,i as Ux,s as Vx,e as r,k as m,w as f,t,M as Fx,c as n,d as s,m as p,a as l,x as v,h as o,b as u,f as Mx,G as a,g as i,y as h,q as _,o as g,B as $,v as Lx}from"../../chunks/vendor-hf-doc-builder.js";import{T as us}from"../../chunks/Tip-hf-doc-builder.js";import{Y as Z$}from"../../chunks/Youtube-hf-doc-builder.js";import{I as Jt}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as j}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as Bx}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";function Jx(R){let c,y,E,q,k,b,D,T;return{c(){c=r("p"),y=t("\u270F\uFE0F "),E=r("strong"),q=t("Experimente!"),k=t(" Use a fun\xE7\xE3o "),b=r("code"),D=t("Dataset.unique()"),T=t(" para encontrar o n\xFAmero de medicamentos e condi\xE7\xF5es exclusivos nos conjuntos de treinamento e teste.")},l(x){c=n(x,"P",{});var w=l(c);y=o(w,"\u270F\uFE0F "),E=n(w,"STRONG",{});var P=l(E);q=o(P,"Experimente!"),P.forEach(s),k=o(w," Use a fun\xE7\xE3o "),b=n(w,"CODE",{});var C=l(b);D=o(C,"Dataset.unique()"),C.forEach(s),T=o(w," para encontrar o n\xFAmero de medicamentos e condi\xE7\xF5es exclusivos nos conjuntos de treinamento e teste."),w.forEach(s)},m(x,w){i(x,c,w),a(c,y),a(c,E),a(E,q),a(c,k),a(c,b),a(b,D),a(c,T)},d(x){x&&s(c)}}}function Gx(R){let c,y,E,q,k,b,D,T;return{c(){c=r("p"),y=t("\u{1F64B} Uma forma alternativa de adicionar novas colunas a um conjunto de dados \xE9 com a fun\xE7\xE3o "),E=r("code"),q=t("Dataset.add_column()"),k=t(". Isso permite que voc\xEA forne\xE7a a coluna como uma lista Python ou array NumPy e pode ser \xFAtil em situa\xE7\xF5es em que "),b=r("code"),D=t("Dataset.map()"),T=t(" n\xE3o \xE9 adequado para sua an\xE1lise.")},l(x){c=n(x,"P",{});var w=l(c);y=o(w,"\u{1F64B} Uma forma alternativa de adicionar novas colunas a um conjunto de dados \xE9 com a fun\xE7\xE3o "),E=n(w,"CODE",{});var P=l(E);q=o(P,"Dataset.add_column()"),P.forEach(s),k=o(w,". Isso permite que voc\xEA forne\xE7a a coluna como uma lista Python ou array NumPy e pode ser \xFAtil em situa\xE7\xF5es em que "),b=n(w,"CODE",{});var C=l(b);D=o(C,"Dataset.map()"),C.forEach(s),T=o(w," n\xE3o \xE9 adequado para sua an\xE1lise."),w.forEach(s)},m(x,w){i(x,c,w),a(c,y),a(c,E),a(E,q),a(c,k),a(c,b),a(b,D),a(c,T)},d(x){x&&s(c)}}}function Yx(R){let c,y,E,q,k,b,D,T,x,w,P;return{c(){c=r("p"),y=t("\u270F\uFE0F "),E=r("strong"),q=t("Experimente!"),k=t(" Use a fun\xE7\xE3o "),b=r("code"),D=t("Dataset.sort()"),T=t(" para inspecionar as resenhas com o maior n\xFAmero de palavras. Consulte a "),x=r("a"),w=t("documenta\xE7\xE3o"),P=t(" para ver qual argumento voc\xEA precisa usar para classificar as avalia\xE7\xF5es por tamanho em ordem decrescente."),this.h()},l(C){c=n(C,"P",{});var z=l(c);y=o(z,"\u270F\uFE0F "),E=n(z,"STRONG",{});var G=l(E);q=o(G,"Experimente!"),G.forEach(s),k=o(z," Use a fun\xE7\xE3o "),b=n(z,"CODE",{});var N=l(b);D=o(N,"Dataset.sort()"),N.forEach(s),T=o(z," para inspecionar as resenhas com o maior n\xFAmero de palavras. Consulte a "),x=n(z,"A",{href:!0,rel:!0});var O=l(x);w=o(O,"documenta\xE7\xE3o"),O.forEach(s),P=o(z," para ver qual argumento voc\xEA precisa usar para classificar as avalia\xE7\xF5es por tamanho em ordem decrescente."),z.forEach(s),this.h()},h(){u(x,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.sort"),u(x,"rel","nofollow")},m(C,z){i(C,c,z),a(c,y),a(c,E),a(E,q),a(c,k),a(c,b),a(b,D),a(c,T),a(c,x),a(x,w),a(c,P)},d(C){C&&s(c)}}}function Qx(R){let c,y,E,q,k,b,D,T,x,w,P,C,z,G;return{c(){c=r("p"),y=t("\u270F\uFE0F "),E=r("strong"),q=t("Experimente!"),k=t(" Execute a mesma instru\xE7\xE3o com e sem "),b=r("code"),D=t("batched=True"),T=t(", ent\xE3o tente com um tokenizer lento (adicione "),x=r("code"),w=t("use_fast=False"),P=t(" no m\xE9todo "),C=r("code"),z=t("AutoTokenizer.from_pretrained()"),G=t(") para que voc\xEA possa veja quais n\xFAmeros voc\xEA obt\xE9m em seu hardware.")},l(N){c=n(N,"P",{});var O=l(c);y=o(O,"\u270F\uFE0F "),E=n(O,"STRONG",{});var _e=l(E);q=o(_e,"Experimente!"),_e.forEach(s),k=o(O," Execute a mesma instru\xE7\xE3o com e sem "),b=n(O,"CODE",{});var U=l(b);D=o(U,"batched=True"),U.forEach(s),T=o(O,", ent\xE3o tente com um tokenizer lento (adicione "),x=n(O,"CODE",{});var W=l(x);w=o(W,"use_fast=False"),W.forEach(s),P=o(O," no m\xE9todo "),C=n(O,"CODE",{});var oe=l(C);z=o(oe,"AutoTokenizer.from_pretrained()"),oe.forEach(s),G=o(O,") para que voc\xEA possa veja quais n\xFAmeros voc\xEA obt\xE9m em seu hardware."),O.forEach(s)},m(N,O){i(N,c,O),a(c,y),a(c,E),a(E,q),a(c,k),a(c,b),a(b,D),a(c,T),a(c,x),a(x,w),a(c,P),a(c,C),a(C,z),a(c,G)},d(N){N&&s(c)}}}function Wx(R){let c,y,E,q,k;return{c(){c=r("p"),y=t("Usar "),E=r("code"),q=t("num_proc"),k=t(" para acelerar seu processamento geralmente \xE9 uma \xF3tima id\xE9ia, desde que a fun\xE7\xE3o que voc\xEA est\xE1 usando n\xE3o esteja fazendo algum tipo de multiprocessamento pr\xF3prio.")},l(b){c=n(b,"P",{});var D=l(c);y=o(D,"Usar "),E=n(D,"CODE",{});var T=l(E);q=o(T,"num_proc"),T.forEach(s),k=o(D," para acelerar seu processamento geralmente \xE9 uma \xF3tima id\xE9ia, desde que a fun\xE7\xE3o que voc\xEA est\xE1 usando n\xE3o esteja fazendo algum tipo de multiprocessamento pr\xF3prio."),D.forEach(s)},m(b,D){i(b,c,D),a(c,y),a(c,E),a(E,q),a(c,k)},d(b){b&&s(c)}}}function Xx(R){let c,y,E,q,k,b,D,T,x,w,P;return{c(){c=r("p"),y=t("\u{1F4A1} No aprendizado de m\xE1quina, um "),E=r("em"),q=t("exemplo"),k=t(" geralmente \xE9 definido como o conjunto de "),b=r("em"),D=t("recursos"),T=t(" que alimentamos o modelo. Em alguns contextos, esses recursos ser\xE3o o conjunto de colunas em um "),x=r("code"),w=t("Dataset"),P=t(", mas em outros (como aqui e para resposta a perguntas), v\xE1rios recursos podem ser extra\xEDdos de um \xFAnico exemplo e pertencer a uma \xFAnica coluna.")},l(C){c=n(C,"P",{});var z=l(c);y=o(z,"\u{1F4A1} No aprendizado de m\xE1quina, um "),E=n(z,"EM",{});var G=l(E);q=o(G,"exemplo"),G.forEach(s),k=o(z," geralmente \xE9 definido como o conjunto de "),b=n(z,"EM",{});var N=l(b);D=o(N,"recursos"),N.forEach(s),T=o(z," que alimentamos o modelo. Em alguns contextos, esses recursos ser\xE3o o conjunto de colunas em um "),x=n(z,"CODE",{});var O=l(x);w=o(O,"Dataset"),O.forEach(s),P=o(z,", mas em outros (como aqui e para resposta a perguntas), v\xE1rios recursos podem ser extra\xEDdos de um \xFAnico exemplo e pertencer a uma \xFAnica coluna."),z.forEach(s)},m(C,z){i(C,c,z),a(c,y),a(c,E),a(E,q),a(c,k),a(c,b),a(b,D),a(c,T),a(c,x),a(x,w),a(c,P)},d(C){C&&s(c)}}}function Kx(R){let c,y,E,q,k,b,D,T,x,w,P,C,z,G,N,O,_e,U,W,oe,se,fs,Ge,Ye,$a,V;return{c(){c=r("p"),y=t("\u{1F6A8} "),E=r("code"),q=t("Dataset.set_format()"),k=t(" altera o formato de retorno para o m\xE9todo dunder "),b=r("code"),D=t("__getitem__()"),T=t(" do conjunto de dados. Isso significa que quando queremos criar um novo objeto como "),x=r("code"),w=t("train_df"),P=t(" a partir de um "),C=r("code"),z=t("Dataset"),G=t(" no formato "),N=r("code"),O=t('"pandas"'),_e=t(", precisamos dividir todo o conjunto de dados para obter um "),U=r("code"),W=t("pandas.DataFrame"),oe=t(". Voc\xEA pode verificar por si mesmo que o tipo de "),se=r("code"),fs=t('drug_dataset["train"]'),Ge=t(" \xE9 "),Ye=r("code"),$a=t("Dataset"),V=t(", independentemente do formato de sa\xEDda.")},l(Qe){c=n(Qe,"P",{});var A=l(c);y=o(A,"\u{1F6A8} "),E=n(A,"CODE",{});var Gt=l(E);q=o(Gt,"Dataset.set_format()"),Gt.forEach(s),k=o(A," altera o formato de retorno para o m\xE9todo dunder "),b=n(A,"CODE",{});var Yt=l(b);D=o(Yt,"__getitem__()"),Yt.forEach(s),T=o(A," do conjunto de dados. Isso significa que quando queremos criar um novo objeto como "),x=n(A,"CODE",{});var ja=l(x);w=o(ja,"train_df"),ja.forEach(s),P=o(A," a partir de um "),C=n(A,"CODE",{});var Qt=l(C);z=o(Qt,"Dataset"),Qt.forEach(s),G=o(A," no formato "),N=n(A,"CODE",{});var Wt=l(N);O=o(Wt,'"pandas"'),Wt.forEach(s),_e=o(A,", precisamos dividir todo o conjunto de dados para obter um "),U=n(A,"CODE",{});var Ea=l(U);W=o(Ea,"pandas.DataFrame"),Ea.forEach(s),oe=o(A,". Voc\xEA pode verificar por si mesmo que o tipo de "),se=n(A,"CODE",{});var Xt=l(se);fs=o(Xt,'drug_dataset["train"]'),Xt.forEach(s),Ge=o(A," \xE9 "),Ye=n(A,"CODE",{});var Kt=l(Ye);$a=o(Kt,"Dataset"),Kt.forEach(s),V=o(A,", independentemente do formato de sa\xEDda."),A.forEach(s)},m(Qe,A){i(Qe,c,A),a(c,y),a(c,E),a(E,q),a(c,k),a(c,b),a(b,D),a(c,T),a(c,x),a(x,w),a(c,P),a(c,C),a(C,z),a(c,G),a(c,N),a(N,O),a(c,_e),a(c,U),a(U,W),a(c,oe),a(c,se),a(se,fs),a(c,Ge),a(c,Ye),a(Ye,$a),a(c,V)},d(Qe){Qe&&s(c)}}}function Zx(R){let c,y,E,q,k,b,D,T;return{c(){c=r("p"),y=t("\u270F\uFE0F "),E=r("strong"),q=t("Experimente!"),k=t(" Calcule a classifica\xE7\xE3o m\xE9dia por medicamento e armazene o resultado em um novo "),b=r("code"),D=t("Dataset"),T=t(".")},l(x){c=n(x,"P",{});var w=l(c);y=o(w,"\u270F\uFE0F "),E=n(w,"STRONG",{});var P=l(E);q=o(P,"Experimente!"),P.forEach(s),k=o(w," Calcule a classifica\xE7\xE3o m\xE9dia por medicamento e armazene o resultado em um novo "),b=n(w,"CODE",{});var C=l(b);D=o(C,"Dataset"),C.forEach(s),T=o(w,"."),w.forEach(s)},m(x,w){i(x,c,w),a(c,y),a(c,E),a(E,q),a(c,k),a(c,b),a(b,D),a(c,T)},d(x){x&&s(c)}}}function e0(R){let c,y,E,q,k,b,D,T,x,w,P,C,z,G,N,O,_e,U,W,oe,se,fs,Ge,Ye,$a,V,Qe,A,Gt,Yt,ja,Qt,Wt,Ea,Xt,Kt,Zt,Vc,Fc,fi,je,Lc,vs,Bc,Jc,hs,Gc,Yc,vi,Ee,Qc,Ur,Wc,Xc,Vr,Kc,Zc,hi,_s,_i,re,eu,Fr,au,su,Lr,tu,ou,Br,ru,nu,gi,gs,$i,be,lu,Jr,du,iu,Gr,mu,pu,ji,$s,Ei,js,bi,ne,cu,Yr,uu,fu,Qr,vu,hu,Wr,_u,gu,xi,xe,Es,$u,Xr,ju,Eu,bu,bs,xu,Kr,wu,qu,Du,We,ku,Zr,Cu,yu,en,Tu,zu,wi,we,Pu,an,Ou,Au,sn,Nu,Iu,qi,xs,Di,qe,Hu,tn,Su,Mu,on,Ru,Uu,ki,ws,Ci,qs,yi,ba,Ti,X,Vu,rn,Fu,Lu,nn,Bu,Ju,eo,Gu,Yu,ln,Qu,Wu,zi,Ds,Pi,ks,Oi,K,Xu,dn,Ku,Zu,mn,ef,af,pn,sf,tf,cn,of,rf,Ai,Cs,Ni,De,nf,un,lf,df,fn,mf,pf,Ii,ys,Hi,Z,cf,vn,uf,ff,Ts,vf,hf,hn,_f,gf,_n,$f,jf,Si,zs,Mi,ao,Ef,Ri,Ps,Ui,Os,Vi,so,bf,Fi,As,Li,Ns,Bi,ke,xf,Is,wf,qf,gn,Df,kf,Ji,Hs,Gi,Ce,Cf,$n,yf,Tf,jn,zf,Pf,Yi,Ss,Qi,Ms,Wi,to,Of,Xi,Xe,xa,En,Rs,Af,bn,Nf,Ki,oo,If,Zi,ro,Hf,em,Us,am,Y,Sf,xn,Mf,Rf,wn,Uf,Vf,qn,Ff,Lf,Dn,Bf,Jf,kn,Gf,Yf,sm,Vs,tm,Fs,om,ye,Qf,Cn,Wf,Xf,yn,Kf,Zf,rm,Ls,nm,Bs,lm,no,ev,dm,wa,im,qa,av,Tn,sv,tv,mm,Js,pm,Gs,cm,lo,ov,um,Da,fm,ka,rv,zn,nv,lv,vm,Ys,hm,Qs,_m,Ca,dv,Pn,iv,mv,gm,Ws,$m,ya,pv,On,cv,uv,jm,Ke,Ta,An,Xs,fv,io,vv,Nn,hv,Em,le,_v,In,gv,$v,Hn,jv,Ev,Sn,bv,xv,bm,ee,wv,Mn,qv,Dv,Rn,kv,Cv,Un,yv,Tv,Vn,zv,Pv,xm,Ks,wm,Te,Ov,Fn,Av,Nv,Ln,Iv,Hv,qm,de,Sv,Bn,Mv,Rv,Jn,Uv,Vv,mo,Fv,Lv,Dm,Zs,km,ie,Bv,po,Jv,Gv,Gn,Yv,Qv,Yn,Wv,Xv,Cm,et,ym,za,Kv,Qn,Zv,eh,Tm,Pa,zm,co,ah,Pm,Oa,Wn,Ze,uo,sh,th,fo,oh,rh,vo,nh,lh,at,ea,ho,Xn,dh,ih,_o,mh,ph,go,ch,uh,aa,$o,Kn,fh,vh,jo,hh,_h,Eo,gh,Om,ze,$h,Zn,jh,Eh,el,bh,xh,Am,bo,wh,Nm,ge,al,qh,Dh,sl,kh,Ch,tl,yh,Th,Im,st,Hm,xo,zh,Sm,Aa,ol,sa,wo,Ph,Oh,qo,Ah,Nh,Do,Ih,Hh,$e,ta,ko,rl,Sh,Mh,Co,Rh,Uh,yo,Vh,Fh,oa,To,nl,Lh,Bh,zo,Jh,Gh,Po,Yh,Qh,ra,Na,ll,Wh,Xh,dl,Kh,Zh,Oo,e_,a_,Ao,s_,t_,na,Ia,il,o_,r_,ml,n_,l_,No,d_,i_,Io,m_,Mm,me,p_,pl,c_,u_,cl,f_,v_,ul,h_,__,Rm,Ha,Um,pe,g_,fl,$_,j_,vl,E_,b_,Ho,x_,w_,Vm,Sa,Fm,Pe,q_,hl,D_,k_,_l,C_,y_,Lm,tt,Bm,Ma,T_,gl,z_,P_,Jm,ot,Gm,rt,Ym,So,O_,Qm,nt,Wm,lt,Xm,Oe,A_,$l,N_,I_,dt,H_,S_,Km,ae,M_,jl,R_,U_,El,V_,F_,bl,L_,B_,xl,J_,G_,Zm,it,ep,Mo,Y_,ap,mt,sp,pt,tp,Ae,Q_,wl,W_,X_,ql,K_,Z_,op,ct,rp,Ra,e2,Dl,a2,s2,np,ut,lp,ft,dp,Ro,t2,ip,Ua,o2,kl,r2,n2,mp,la,Va,Cl,vt,l2,da,d2,yl,i2,m2,Tl,p2,c2,pp,ht,cp,ce,u2,zl,f2,v2,Pl,h2,_2,Ol,g2,$2,up,_t,fp,Fa,j2,Al,E2,b2,vp,gt,hp,Ne,Nl,I,_p,x2,Il,w2,q2,Hl,D2,k2,Sl,C2,y2,Ml,T2,z2,Rl,P2,O2,Ul,A2,N2,Vl,I2,H2,Fl,S2,M2,ia,H,Ll,R2,U2,Bl,V2,F2,Jl,L2,B2,Gl,J2,G2,Yl,Y2,Q2,Ql,W2,X2,Wl,K2,Z2,Xl,eg,ag,Kl,sg,tg,S,Zl,og,rg,ed,ng,lg,ad,dg,ig,sd,mg,pg,td,cg,ug,od,fg,vg,rd,hg,_g,nd,gg,$g,ld,jg,Eg,M,dd,bg,xg,id,wg,qg,md,Dg,kg,pd,Cg,yg,cd,Tg,zg,ud,Pg,Og,fd,Ag,Ng,vd,Ig,Hg,hd,Sg,gp,Ie,Mg,_d,Rg,Ug,gd,Vg,Fg,$p,$t,jp,La,Ep,Ba,Lg,$d,Bg,Jg,bp,jt,xp,He,jd,Se,wp,Gg,Ed,Yg,Qg,bd,Wg,Xg,te,ma,xd,Kg,Zg,wd,e1,a1,qd,s1,t1,pa,Dd,o1,r1,kd,n1,l1,Cd,d1,i1,ca,yd,m1,p1,Td,c1,u1,zd,f1,v1,ua,Pd,h1,_1,Od,g1,$1,Ad,j1,E1,fa,Nd,b1,x1,Id,w1,q1,Hd,D1,qp,Me,k1,Sd,C1,y1,Md,T1,z1,Dp,Et,kp,bt,Cp,Ja,yp,ue,P1,Rd,O1,A1,Ud,N1,I1,Vd,H1,S1,Tp,xt,zp,va,Ga,Fd,wt,M1,Ld,R1,Pp,Uo,U1,Op,Q,V1,Bd,F1,L1,Jd,B1,J1,Gd,G1,Y1,Yd,Q1,W1,Qd,X1,K1,Ap,qt,Np,Dt,Ip,Ya,Z1,Vo,e$,a$,Hp,ha,Qa,Wd,kt,s$,Xd,t$,Sp,Ct,Mp,Fo,o$,Rp,Wa,Kd,yt,Lo,r$,n$,Bo,l$,d$,_a,Tt,Jo,i$,m$,Go,Zd,p$,c$,zt,Yo,u$,f$,Qo,ei,v$,h$,Pt,Wo,_$,g$,Xo,ai,$$,Up,Ko,j$,Vp,Ot,Fp,Zo,E$,Lp,At,Bp,fe,b$,si,x$,w$,ti,q$,D$,oi,k$,C$,Jp,Xa,y$,ri,T$,z$,Gp,Nt,Yp,It,Qp,Ka,P$,ni,O$,A$,Wp,Ht,Xp,Za,N$,St,I$,H$,Kp,Mt,Zp,Rt,ec,es,S$,er,M$,R$,ac,Ut,sc,ar,U$,tc,as,Vt,V$,sr,F$,L$,B$,ga,J$,li,G$,Y$,tr,Q$,W$,oc,or,X$,rc;return b=new Jt({}),P=new Bx({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter5/section3.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter5/section3.ipynb"}]}}),O=new Z$({props:{id:"tqfSFcPMgOI"}}),se=new Jt({}),_s=new j({props:{code:`!wget "https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip"
!unzip drugsCom_raw.zip`,highlighted:`!wget <span class="hljs-string">&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip&quot;</span>
!unzip drugsCom_raw.<span class="hljs-built_in">zip</span>`}}),gs=new j({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

data_files = {<span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;drugsComTrain_raw.tsv&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;drugsComTest_raw.tsv&quot;</span>}
<span class="hljs-comment"># \\t is the tab character in Python</span>
drug_dataset = load_dataset(<span class="hljs-string">&quot;csv&quot;</span>, data_files=data_files, delimiter=<span class="hljs-string">&quot;\\t&quot;</span>)`}}),$s=new j({props:{code:`drug_sample = drug_dataset["train"].shuffle(seed=42).select(range(1000))
# Peek at the first few examples
drug_sample[:3]`,highlighted:`drug_sample = drug_dataset[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))
<span class="hljs-comment"># Peek at the first few examples</span>
drug_sample[:<span class="hljs-number">3</span>]`}}),js=new j({props:{code:`{'Unnamed: 0': [87571, 178045, 80482],
 'drugName': ['Naproxen', 'Duloxetine', 'Mobic'],
 'condition': ['Gout, Acute', 'ibromyalgia', 'Inflammatory Conditions'],
 'review': ['"like the previous person mention, I&#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!"',
  '"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\\r\\nas a pain reducer and an anti-depressant, however, the side effects outweighed \\r\\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\\r\\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\\r\\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\\r\\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects."',
  '"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days."'],
 'rating': [9.0, 3.0, 10.0],
 'date': ['September 2, 2015', 'November 7, 2011', 'June 5, 2013'],
 'usefulCount': [36, 13, 128]}`,highlighted:`{<span class="hljs-string">&#x27;Unnamed: 0&#x27;</span>: [<span class="hljs-number">87571</span>, <span class="hljs-number">178045</span>, <span class="hljs-number">80482</span>],
 <span class="hljs-string">&#x27;drugName&#x27;</span>: [<span class="hljs-string">&#x27;Naproxen&#x27;</span>, <span class="hljs-string">&#x27;Duloxetine&#x27;</span>, <span class="hljs-string">&#x27;Mobic&#x27;</span>],
 <span class="hljs-string">&#x27;condition&#x27;</span>: [<span class="hljs-string">&#x27;Gout, Acute&#x27;</span>, <span class="hljs-string">&#x27;ibromyalgia&#x27;</span>, <span class="hljs-string">&#x27;Inflammatory Conditions&#x27;</span>],
 <span class="hljs-string">&#x27;review&#x27;</span>: [<span class="hljs-string">&#x27;&quot;like the previous person mention, I&amp;#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!&quot;&#x27;</span>,
  <span class="hljs-string">&#x27;&quot;I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\\r\\nas a pain reducer and an anti-depressant, however, the side effects outweighed \\r\\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\\r\\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\\r\\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\\r\\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects.&quot;&#x27;</span>,
  <span class="hljs-string">&#x27;&quot;I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days.&quot;&#x27;</span>],
 <span class="hljs-string">&#x27;rating&#x27;</span>: [<span class="hljs-number">9.0</span>, <span class="hljs-number">3.0</span>, <span class="hljs-number">10.0</span>],
 <span class="hljs-string">&#x27;date&#x27;</span>: [<span class="hljs-string">&#x27;September 2, 2015&#x27;</span>, <span class="hljs-string">&#x27;November 7, 2011&#x27;</span>, <span class="hljs-string">&#x27;June 5, 2013&#x27;</span>],
 <span class="hljs-string">&#x27;usefulCount&#x27;</span>: [<span class="hljs-number">36</span>, <span class="hljs-number">13</span>, <span class="hljs-number">128</span>]}`}}),xs=new j({props:{code:`for split in drug_dataset.keys():
    assert len(drug_dataset[split]) == len(drug_dataset[split].unique("Unnamed: 0"))`,highlighted:`<span class="hljs-keyword">for</span> split <span class="hljs-keyword">in</span> drug_dataset.keys():
    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(drug_dataset[split]) == <span class="hljs-built_in">len</span>(drug_dataset[split].unique(<span class="hljs-string">&quot;Unnamed: 0&quot;</span>))`}}),ws=new j({props:{code:`drug_dataset = drug_dataset.rename_column(
    original_column_name="Unnamed: 0", new_column_name="patient_id"
)
drug_dataset`,highlighted:`drug_dataset = drug_dataset.rename_column(
    original_column_name=<span class="hljs-string">&quot;Unnamed: 0&quot;</span>, new_column_name=<span class="hljs-string">&quot;patient_id&quot;</span>
)
drug_dataset`}}),qs=new j({props:{code:`DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 161297
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],
        num_rows: 53766
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>],
        num_rows: <span class="hljs-number">161297</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>],
        num_rows: <span class="hljs-number">53766</span>
    })
})`}}),ba=new us({props:{$$slots:{default:[Jx]},$$scope:{ctx:R}}}),Ds=new j({props:{code:`
`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">lowercase_condition</span>(<span class="hljs-params">example</span>):
    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;condition&quot;</span>: example[<span class="hljs-string">&quot;condition&quot;</span>].lower()}


drug_dataset.<span class="hljs-built_in">map</span>(lowercase_condition)`}}),ks=new j({props:{code:"AttributeError: 'NoneType' object has no attribute 'lower'",highlighted:'AttributeError: <span class="hljs-string">&#x27;NoneType&#x27;</span> <span class="hljs-built_in">object</span> has no attribute <span class="hljs-string">&#x27;lower&#x27;</span>'}}),Cs=new j({props:{code:`def filter_nones(x):
    return x["condition"] is not None`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">filter_nones</span>(<span class="hljs-params">x</span>):
    <span class="hljs-keyword">return</span> x[<span class="hljs-string">&quot;condition&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>`}}),ys=new j({props:{code:"lambda <arguments> : <expression>",highlighted:'lambda <span class="hljs-tag">&lt;<span class="hljs-name">arguments</span>&gt;</span> : <span class="hljs-tag">&lt;<span class="hljs-name">expression</span>&gt;</span>'}}),zs=new j({props:{code:"lambda x : x * x",highlighted:'lambda <span class="hljs-keyword">x</span> : <span class="hljs-keyword">x</span> * <span class="hljs-keyword">x</span>'}}),Ps=new j({props:{code:"(lambda x: x * x)(3)",highlighted:'(<span class="hljs-keyword">lambda</span> x: x * x)(<span class="hljs-number">3</span>)'}}),Os=new j({props:{code:"9",highlighted:'<span class="hljs-number">9</span>'}}),As=new j({props:{code:"(lambda base, height: 0.5 * base * height)(4, 8)",highlighted:'(<span class="hljs-keyword">lambda</span> base, height: <span class="hljs-number">0.5</span> * base * height)(<span class="hljs-number">4</span>, <span class="hljs-number">8</span>)'}}),Ns=new j({props:{code:"16.0",highlighted:'<span class="hljs-number">16.0</span>'}}),Hs=new j({props:{code:'drug_dataset = drug_dataset.filter(lambda x: x["condition"] is not None)',highlighted:'drug_dataset = drug_dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&quot;condition&quot;</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>)'}}),Ss=new j({props:{code:`drug_dataset = drug_dataset.map(lowercase_condition)
# Check that lowercasing worked
drug_dataset["train"]["condition"][:3]`,highlighted:`drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(lowercase_condition)
<span class="hljs-comment"># Check that lowercasing worked</span>
drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-string">&quot;condition&quot;</span>][:<span class="hljs-number">3</span>]`}}),Ms=new j({props:{code:"['left ventricular dysfunction', 'adhd', 'birth control']",highlighted:'[<span class="hljs-string">&#x27;left ventricular dysfunction&#x27;</span>, <span class="hljs-string">&#x27;adhd&#x27;</span>, <span class="hljs-string">&#x27;birth control&#x27;</span>]'}}),Rs=new Jt({}),Us=new j({props:{code:`def compute_review_length(example):
    return {"review_length": len(example["review"].split())}`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_review_length</span>(<span class="hljs-params">example</span>):
    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;review_length&quot;</span>: <span class="hljs-built_in">len</span>(example[<span class="hljs-string">&quot;review&quot;</span>].split())}`}}),Vs=new j({props:{code:`drug_dataset = drug_dataset.map(compute_review_length)
# Inspect the first training example
drug_dataset["train"][0]`,highlighted:`drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(compute_review_length)
<span class="hljs-comment"># Inspect the first training example</span>
drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]`}}),Fs=new j({props:{code:`{'patient_id': 206461,
 'drugName': 'Valsartan',
 'condition': 'left ventricular dysfunction',
 'review': '"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil"',
 'rating': 9.0,
 'date': 'May 20, 2012',
 'usefulCount': 27,
 'review_length': 17}`,highlighted:`{<span class="hljs-string">&#x27;patient_id&#x27;</span>: <span class="hljs-number">206461</span>,
 <span class="hljs-string">&#x27;drugName&#x27;</span>: <span class="hljs-string">&#x27;Valsartan&#x27;</span>,
 <span class="hljs-string">&#x27;condition&#x27;</span>: <span class="hljs-string">&#x27;left ventricular dysfunction&#x27;</span>,
 <span class="hljs-string">&#x27;review&#x27;</span>: <span class="hljs-string">&#x27;&quot;It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil&quot;&#x27;</span>,
 <span class="hljs-string">&#x27;rating&#x27;</span>: <span class="hljs-number">9.0</span>,
 <span class="hljs-string">&#x27;date&#x27;</span>: <span class="hljs-string">&#x27;May 20, 2012&#x27;</span>,
 <span class="hljs-string">&#x27;usefulCount&#x27;</span>: <span class="hljs-number">27</span>,
 <span class="hljs-string">&#x27;review_length&#x27;</span>: <span class="hljs-number">17</span>}`}}),Ls=new j({props:{code:'drug_dataset["train"].sort("review_length")[:3]',highlighted:'drug_dataset[<span class="hljs-string">&quot;train&quot;</span>].sort(<span class="hljs-string">&quot;review_length&quot;</span>)[:<span class="hljs-number">3</span>]'}}),Bs=new j({props:{code:`{'patient_id': [103488, 23627, 20558],
 'drugName': ['Loestrin 21 1 / 20', 'Chlorzoxazone', 'Nucynta'],
 'condition': ['birth control', 'muscle spasm', 'pain'],
 'review': ['"Excellent."', '"useless"', '"ok"'],
 'rating': [10.0, 1.0, 6.0],
 'date': ['November 4, 2008', 'March 24, 2017', 'August 20, 2016'],
 'usefulCount': [5, 2, 10],
 'review_length': [1, 1, 1]}`,highlighted:`{<span class="hljs-string">&#x27;patient_id&#x27;</span>: [<span class="hljs-number">103488</span>, <span class="hljs-number">23627</span>, <span class="hljs-number">20558</span>],
 <span class="hljs-string">&#x27;drugName&#x27;</span>: [<span class="hljs-string">&#x27;Loestrin 21 1 / 20&#x27;</span>, <span class="hljs-string">&#x27;Chlorzoxazone&#x27;</span>, <span class="hljs-string">&#x27;Nucynta&#x27;</span>],
 <span class="hljs-string">&#x27;condition&#x27;</span>: [<span class="hljs-string">&#x27;birth control&#x27;</span>, <span class="hljs-string">&#x27;muscle spasm&#x27;</span>, <span class="hljs-string">&#x27;pain&#x27;</span>],
 <span class="hljs-string">&#x27;review&#x27;</span>: [<span class="hljs-string">&#x27;&quot;Excellent.&quot;&#x27;</span>, <span class="hljs-string">&#x27;&quot;useless&quot;&#x27;</span>, <span class="hljs-string">&#x27;&quot;ok&quot;&#x27;</span>],
 <span class="hljs-string">&#x27;rating&#x27;</span>: [<span class="hljs-number">10.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">6.0</span>],
 <span class="hljs-string">&#x27;date&#x27;</span>: [<span class="hljs-string">&#x27;November 4, 2008&#x27;</span>, <span class="hljs-string">&#x27;March 24, 2017&#x27;</span>, <span class="hljs-string">&#x27;August 20, 2016&#x27;</span>],
 <span class="hljs-string">&#x27;usefulCount&#x27;</span>: [<span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">10</span>],
 <span class="hljs-string">&#x27;review_length&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`}}),wa=new us({props:{$$slots:{default:[Gx]},$$scope:{ctx:R}}}),Js=new j({props:{code:`drug_dataset = drug_dataset.filter(lambda x: x["review_length"] > 30)
print(drug_dataset.num_rows)`,highlighted:`drug_dataset = drug_dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: x[<span class="hljs-string">&quot;review_length&quot;</span>] &gt; <span class="hljs-number">30</span>)
<span class="hljs-built_in">print</span>(drug_dataset.num_rows)`}}),Gs=new j({props:{code:"{'train': 138514, 'test': 46108}",highlighted:'{<span class="hljs-string">&#x27;train&#x27;</span>: <span class="hljs-number">138514</span>, <span class="hljs-string">&#x27;test&#x27;</span>: <span class="hljs-number">46108</span>}'}}),Da=new us({props:{$$slots:{default:[Yx]},$$scope:{ctx:R}}}),Ys=new j({props:{code:"",highlighted:`<span class="hljs-keyword">import</span> html

text = <span class="hljs-string">&quot;I&amp;#039;m a transformer called BERT&quot;</span>
html.unescape(text)`}}),Qs=new j({props:{code:`"I'm a transformer called BERT"`,highlighted:'<span class="hljs-string">&quot;I&#x27;m a transformer called BERT&quot;</span>'}}),Ws=new j({props:{code:'drug_dataset = drug_dataset.map(lambda x: {"review": html.unescape(x["review"])})',highlighted:'drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: {<span class="hljs-string">&quot;review&quot;</span>: html.unescape(x[<span class="hljs-string">&quot;review&quot;</span>])})'}}),Xs=new Jt({}),Ks=new j({props:{code:`new_drug_dataset = drug_dataset.map(
    lambda x: {"review": [html.unescape(o) for o in x["review"]]}, batched=True
)`,highlighted:`new_drug_dataset = drug_dataset.<span class="hljs-built_in">map</span>(
    <span class="hljs-keyword">lambda</span> x: {<span class="hljs-string">&quot;review&quot;</span>: [html.unescape(o) <span class="hljs-keyword">for</span> o <span class="hljs-keyword">in</span> x[<span class="hljs-string">&quot;review&quot;</span>]]}, batched=<span class="hljs-literal">True</span>
)`}}),Zs=new j({props:{code:`

`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;review&quot;</span>], truncation=<span class="hljs-literal">True</span>)`}}),et=new j({props:{code:"%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)",highlighted:'%time tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)'}}),Pa=new us({props:{$$slots:{default:[Qx]},$$scope:{ctx:R}}}),st=new j({props:{code:`


`,highlighted:`slow_tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>, use_fast=<span class="hljs-literal">False</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">slow_tokenize_function</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> slow_tokenizer(examples[<span class="hljs-string">&quot;review&quot;</span>], truncation=<span class="hljs-literal">True</span>)


tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(slow_tokenize_function, batched=<span class="hljs-literal">True</span>, num_proc=<span class="hljs-number">8</span>)`}}),Ha=new us({props:{$$slots:{default:[Wx]},$$scope:{ctx:R}}}),Sa=new us({props:{$$slots:{default:[Xx]},$$scope:{ctx:R}}}),tt=new j({props:{code:`def tokenize_and_split(examples):
    return tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_and_split</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> tokenizer(
        examples[<span class="hljs-string">&quot;review&quot;</span>],
        truncation=<span class="hljs-literal">True</span>,
        max_length=<span class="hljs-number">128</span>,
        return_overflowing_tokens=<span class="hljs-literal">True</span>,
    )`}}),ot=new j({props:{code:`result = tokenize_and_split(drug_dataset["train"][0])
[len(inp) for inp in result["input_ids"]]`,highlighted:`result = tokenize_and_split(drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>])
[<span class="hljs-built_in">len</span>(inp) <span class="hljs-keyword">for</span> inp <span class="hljs-keyword">in</span> result[<span class="hljs-string">&quot;input_ids&quot;</span>]]`}}),rt=new j({props:{code:"[128, 49]",highlighted:'[<span class="hljs-number">128</span>, <span class="hljs-number">49</span>]'}}),nt=new j({props:{code:"tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)",highlighted:'tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(tokenize_and_split, batched=<span class="hljs-literal">True</span>)'}}),lt=new j({props:{code:"ArrowInvalid: Column 1 named condition expected length 1463 but got length 1000",highlighted:'ArrowInvalid: Column <span class="hljs-number">1</span> named condition expected length <span class="hljs-number">1463</span> but got length <span class="hljs-number">1000</span>'}}),it=new j({props:{code:`tokenized_dataset = drug_dataset.map(
    tokenize_and_split, batched=True, remove_columns=drug_dataset["train"].column_names
)`,highlighted:`tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(
    tokenize_and_split, batched=<span class="hljs-literal">True</span>, remove_columns=drug_dataset[<span class="hljs-string">&quot;train&quot;</span>].column_names
)`}}),mt=new j({props:{code:'len(tokenized_dataset["train"]), len(drug_dataset["train"])',highlighted:'<span class="hljs-built_in">len</span>(tokenized_dataset[<span class="hljs-string">&quot;train&quot;</span>]), <span class="hljs-built_in">len</span>(drug_dataset[<span class="hljs-string">&quot;train&quot;</span>])'}}),pt=new j({props:{code:"(206772, 138514)",highlighted:'(<span class="hljs-number">206772</span>, <span class="hljs-number">138514</span>)'}}),ct=new j({props:{code:`def tokenize_and_split(examples):
    result = tokenizer(
        examples["review"],
        truncation=True,
        max_length=128,
        return_overflowing_tokens=True,
    )
    # Extract mapping between new and old indices
    sample_map = result.pop("overflow_to_sample_mapping")
    for key, values in examples.items():
        result[key] = [values[i] for i in sample_map]
    return result`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_and_split</span>(<span class="hljs-params">examples</span>):
    result = tokenizer(
        examples[<span class="hljs-string">&quot;review&quot;</span>],
        truncation=<span class="hljs-literal">True</span>,
        max_length=<span class="hljs-number">128</span>,
        return_overflowing_tokens=<span class="hljs-literal">True</span>,
    )
    <span class="hljs-comment"># Extract mapping between new and old indices</span>
    sample_map = result.pop(<span class="hljs-string">&quot;overflow_to_sample_mapping&quot;</span>)
    <span class="hljs-keyword">for</span> key, values <span class="hljs-keyword">in</span> examples.items():
        result[key] = [values[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sample_map]
    <span class="hljs-keyword">return</span> result`}}),ut=new j({props:{code:`tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)
tokenized_dataset`,highlighted:`tokenized_dataset = drug_dataset.<span class="hljs-built_in">map</span>(tokenize_and_split, batched=<span class="hljs-literal">True</span>)
tokenized_dataset`}}),ft=new j({props:{code:`DatasetDict({
    train: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 206772
    })
    test: Dataset({
        features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'],
        num_rows: 68876
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>],
        num_rows: <span class="hljs-number">206772</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;attention_mask&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;input_ids&#x27;</span>, <span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;token_type_ids&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>],
        num_rows: <span class="hljs-number">68876</span>
    })
})`}}),vt=new Jt({}),ht=new Z$({props:{id:"tfcY1067A5Q"}}),_t=new j({props:{code:'drug_dataset.set_format("pandas")',highlighted:'drug_dataset.set_format(<span class="hljs-string">&quot;pandas&quot;</span>)'}}),gt=new j({props:{code:'drug_dataset["train"][:3]',highlighted:'drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][:<span class="hljs-number">3</span>]'}}),$t=new j({props:{code:'train_df = drug_dataset["train"][:]',highlighted:'train_df = drug_dataset[<span class="hljs-string">&quot;train&quot;</span>][:]'}}),La=new us({props:{$$slots:{default:[Kx]},$$scope:{ctx:R}}}),jt=new j({props:{code:`frequencies = (
    train_df["condition"]
    .value_counts()
    .to_frame()
    .reset_index()
    .rename(columns={"index": "condition", "condition": "frequency"})
)
frequencies.head()`,highlighted:`frequencies = (
    train_df[<span class="hljs-string">&quot;condition&quot;</span>]
    .value_counts()
    .to_frame()
    .reset_index()
    .rename(columns={<span class="hljs-string">&quot;index&quot;</span>: <span class="hljs-string">&quot;condition&quot;</span>, <span class="hljs-string">&quot;condition&quot;</span>: <span class="hljs-string">&quot;frequency&quot;</span>})
)
frequencies.head()`}}),Et=new j({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> Dataset

freq_dataset = Dataset.from_pandas(frequencies)
freq_dataset`}}),bt=new j({props:{code:`Dataset({
    features: ['condition', 'frequency'],
    num_rows: 819
})`,highlighted:`Dataset({
    features: [<span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;frequency&#x27;</span>],
    num_rows: <span class="hljs-number">819</span>
})`}}),Ja=new us({props:{$$slots:{default:[Zx]},$$scope:{ctx:R}}}),xt=new j({props:{code:"drug_dataset.reset_format()",highlighted:"drug_dataset.reset_format()"}}),wt=new Jt({}),qt=new j({props:{code:`drug_dataset_clean = drug_dataset["train"].train_test_split(train_size=0.8, seed=42)
# Rename the default "test" split to "validation"
drug_dataset_clean["validation"] = drug_dataset_clean.pop("test")
# Add the "test" set to our \`DatasetDict\`
drug_dataset_clean["test"] = drug_dataset["test"]
drug_dataset_clean`,highlighted:`drug_dataset_clean = drug_dataset[<span class="hljs-string">&quot;train&quot;</span>].train_test_split(train_size=<span class="hljs-number">0.8</span>, seed=<span class="hljs-number">42</span>)
<span class="hljs-comment"># Rename the default &quot;test&quot; split to &quot;validation&quot;</span>
drug_dataset_clean[<span class="hljs-string">&quot;validation&quot;</span>] = drug_dataset_clean.pop(<span class="hljs-string">&quot;test&quot;</span>)
<span class="hljs-comment"># Add the &quot;test&quot; set to our \`DatasetDict\`</span>
drug_dataset_clean[<span class="hljs-string">&quot;test&quot;</span>] = drug_dataset[<span class="hljs-string">&quot;test&quot;</span>]
drug_dataset_clean`}}),Dt=new j({props:{code:`DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'review_clean'],
        num_rows: 46108
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;review_clean&#x27;</span>],
        num_rows: <span class="hljs-number">110811</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;review_clean&#x27;</span>],
        num_rows: <span class="hljs-number">27703</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>, <span class="hljs-string">&#x27;review_clean&#x27;</span>],
        num_rows: <span class="hljs-number">46108</span>
    })
})`}}),kt=new Jt({}),Ct=new Z$({props:{id:"blF9uxYcKHo"}}),Ot=new j({props:{code:'drug_dataset_clean.save_to_disk("drug-reviews")',highlighted:'drug_dataset_clean.save_to_disk(<span class="hljs-string">&quot;drug-reviews&quot;</span>)'}}),At=new j({props:{code:`drug-reviews/
\u251C\u2500\u2500 dataset_dict.json
\u251C\u2500\u2500 test
\u2502   \u251C\u2500\u2500 dataset.arrow
\u2502   \u251C\u2500\u2500 dataset_info.json
\u2502   \u2514\u2500\u2500 state.json
\u251C\u2500\u2500 train
\u2502   \u251C\u2500\u2500 dataset.arrow
\u2502   \u251C\u2500\u2500 dataset_info.json
\u2502   \u251C\u2500\u2500 indices.arrow
\u2502   \u2514\u2500\u2500 state.json
\u2514\u2500\u2500 validation
    \u251C\u2500\u2500 dataset.arrow
    \u251C\u2500\u2500 dataset_info.json
    \u251C\u2500\u2500 indices.arrow
    \u2514\u2500\u2500 state.json`,highlighted:`drug-reviews/
\u251C\u2500\u2500 dataset_dict.json
\u251C\u2500\u2500 test
\u2502   \u251C\u2500\u2500 dataset.arrow
\u2502   \u251C\u2500\u2500 dataset_info.json
\u2502   \u2514\u2500\u2500 <span class="hljs-keyword">state</span>.json
\u251C\u2500\u2500 train
\u2502   \u251C\u2500\u2500 dataset.arrow
\u2502   \u251C\u2500\u2500 dataset_info.json
\u2502   \u251C\u2500\u2500 indices.arrow
\u2502   \u2514\u2500\u2500 <span class="hljs-keyword">state</span>.json
\u2514\u2500\u2500 validation
    \u251C\u2500\u2500 dataset.arrow
    \u251C\u2500\u2500 dataset_info.json
    \u251C\u2500\u2500 indices.arrow
    \u2514\u2500\u2500 <span class="hljs-keyword">state</span>.json`}}),Nt=new j({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_from_disk

drug_dataset_reloaded = load_from_disk(<span class="hljs-string">&quot;drug-reviews&quot;</span>)
drug_dataset_reloaded`}}),It=new j({props:{code:`DatasetDict({
    train: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 110811
    })
    validation: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 27703
    })
    test: Dataset({
        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],
        num_rows: 46108
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>],
        num_rows: <span class="hljs-number">110811</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>],
        num_rows: <span class="hljs-number">27703</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;patient_id&#x27;</span>, <span class="hljs-string">&#x27;drugName&#x27;</span>, <span class="hljs-string">&#x27;condition&#x27;</span>, <span class="hljs-string">&#x27;review&#x27;</span>, <span class="hljs-string">&#x27;rating&#x27;</span>, <span class="hljs-string">&#x27;date&#x27;</span>, <span class="hljs-string">&#x27;usefulCount&#x27;</span>, <span class="hljs-string">&#x27;review_length&#x27;</span>],
        num_rows: <span class="hljs-number">46108</span>
    })
})`}}),Ht=new j({props:{code:`for split, dataset in drug_dataset_clean.items():
    dataset.to_json(f"drug-reviews-{split}.jsonl")`,highlighted:`<span class="hljs-keyword">for</span> split, dataset <span class="hljs-keyword">in</span> drug_dataset_clean.items():
    dataset.to_json(<span class="hljs-string">f&quot;drug-reviews-<span class="hljs-subst">{split}</span>.jsonl&quot;</span>)`}}),Mt=new j({props:{code:"!head -n 1 drug-reviews-train.jsonl",highlighted:'!head -n <span class="hljs-number">1</span> drug-reviews-train.jsonl'}}),Rt=new j({props:{code:`{"patient_id":141780,"drugName":"Escitalopram","condition":"depression","review":"\\"I seemed to experience the regular side effects of LEXAPRO, insomnia, low sex drive, sleepiness during the day. I am taking it at night because my doctor said if it made me tired to take it at night. I assumed it would and started out taking it at night. Strange dreams, some pleasant. I was diagnosed with fibromyalgia. Seems to be helping with the pain. Have had anxiety and depression in my family, and have tried quite a few other medications that haven't worked. Only have been on it for two weeks but feel more positive in my mind, want to accomplish more in my life. Hopefully the side effects will dwindle away, worth it to stick with it from hearing others responses. Great medication.\\"","rating":9.0,"date":"May 29, 2011","usefulCount":10,"review_length":125}`,highlighted:'{<span class="hljs-string">&quot;patient_id&quot;</span>:<span class="hljs-number">141780</span>,<span class="hljs-string">&quot;drugName&quot;</span>:<span class="hljs-string">&quot;Escitalopram&quot;</span>,<span class="hljs-string">&quot;condition&quot;</span>:<span class="hljs-string">&quot;depression&quot;</span>,<span class="hljs-string">&quot;review&quot;</span>:<span class="hljs-string">&quot;\\&quot;I seemed to experience the regular side effects of LEXAPRO, insomnia, low sex drive, sleepiness during the day. I am taking it at night because my doctor said if it made me tired to take it at night. I assumed it would and started out taking it at night. Strange dreams, some pleasant. I was diagnosed with fibromyalgia. Seems to be helping with the pain. Have had anxiety and depression in my family, and have tried quite a few other medications that haven&#x27;t worked. Only have been on it for two weeks but feel more positive in my mind, want to accomplish more in my life. Hopefully the side effects will dwindle away, worth it to stick with it from hearing others responses. Great medication.\\&quot;&quot;</span>,<span class="hljs-string">&quot;rating&quot;</span>:<span class="hljs-number">9.0</span>,<span class="hljs-string">&quot;date&quot;</span>:<span class="hljs-string">&quot;May 29, 2011&quot;</span>,<span class="hljs-string">&quot;usefulCount&quot;</span>:<span class="hljs-number">10</span>,<span class="hljs-string">&quot;review_length&quot;</span>:<span class="hljs-number">125</span>}'}}),Ut=new j({props:{code:`data_files = {
    "train": "drug-reviews-train.jsonl",
    "validation": "drug-reviews-validation.jsonl",
    "test": "drug-reviews-test.jsonl",
}
drug_dataset_reloaded = load_dataset("json", data_files=data_files)`,highlighted:`data_files = {
    <span class="hljs-string">&quot;train&quot;</span>: <span class="hljs-string">&quot;drug-reviews-train.jsonl&quot;</span>,
    <span class="hljs-string">&quot;validation&quot;</span>: <span class="hljs-string">&quot;drug-reviews-validation.jsonl&quot;</span>,
    <span class="hljs-string">&quot;test&quot;</span>: <span class="hljs-string">&quot;drug-reviews-test.jsonl&quot;</span>,
}
drug_dataset_reloaded = load_dataset(<span class="hljs-string">&quot;json&quot;</span>, data_files=data_files)`}}),{c(){c=r("meta"),y=m(),E=r("h1"),q=r("a"),k=r("span"),f(b.$$.fragment),D=m(),T=r("span"),x=t("Hora de fatiar e dividir os dados"),w=m(),f(P.$$.fragment),C=m(),z=r("p"),G=t("Na maioria das vezes, os dados com os quais voc\xEA trabalha n\xE3o estar\xE3o perfeitamente preparados para treinamento de modelos. Nesta se\xE7\xE3o vamos explorar as v\xE1rias caracter\xEDsticas que o \u{1F917} Datasets fornece para limpar seus conjuntos de dados."),N=m(),f(O.$$.fragment),_e=m(),U=r("h2"),W=r("a"),oe=r("span"),f(se.$$.fragment),fs=m(),Ge=r("span"),Ye=t("Slicing and dicing our data"),$a=m(),V=r("p"),Qe=t("Semelhante ao Pandas, \u{1F917} Datasets fornece v\xE1rias fun\xE7\xF5es para manipular o conte\xFAdo dos objetos "),A=r("code"),Gt=t("Dataset"),Yt=t(" e "),ja=r("code"),Qt=t("DatasetDict"),Wt=t(". J\xE1 encontramos o m\xE9todo "),Ea=r("code"),Xt=t("Dataset.map()"),Kt=t(" no "),Zt=r("a"),Vc=t("Cap\xEDtulo 3"),Fc=t(", e nesta se\xE7\xE3o vamos explorar algumas das outras fun\xE7\xF5es \xE0 nossa disposi\xE7\xE3o."),fi=m(),je=r("p"),Lc=t("Para este exemplo, usaremos o "),vs=r("a"),Bc=t("Drug Review Dataset"),Jc=t(" que est\xE1 hospedado na "),hs=r("a"),Gc=t("UC Irvine Machine Learning Repository"),Yc=t(", que cont\xE9m avalia\xE7\xF5es de pacientes sobre v\xE1rios medicamentos, juntamente com a condi\xE7\xE3o a ser tratada e uma classifica\xE7\xE3o de 10 estrelas da satisfa\xE7\xE3o do paciente."),vi=m(),Ee=r("p"),Qc=t("Primeiro precisamos baixar e extrair os dados, o que pode ser feito com os comandos "),Ur=r("code"),Wc=t("wget"),Xc=t(" e "),Vr=r("code"),Kc=t("unzip"),Zc=t(":"),hi=m(),f(_s.$$.fragment),_i=m(),re=r("p"),eu=t("Como o TSV \xE9 apenas uma variante do CSV que usa tabula\xE7\xF5es em vez de v\xEDrgulas como separador, podemos carregar esses arquivos usando o script de carregamento "),Fr=r("code"),au=t("csv"),su=t(" e especificando o argumento "),Lr=r("code"),tu=t("delimiter"),ou=t(" na fun\xE7\xE3o "),Br=r("code"),ru=t("load_dataset()"),nu=t(" da seguinte forma:"),gi=m(),f(gs.$$.fragment),$i=m(),be=r("p"),lu=t("Uma boa pr\xE1tica ao fazer qualquer tipo de an\xE1lise de dados \xE9 pegar uma pequena amostra aleat\xF3ria para ter uma ideia r\xE1pida do tipo de dados com os quais voc\xEA est\xE1 trabalhando. Em \u{1F917} Datasets, podemos criar uma amostra aleat\xF3ria encadeando as fun\xE7\xF5es "),Jr=r("code"),du=t("Dataset.shuffle()"),iu=t(" e "),Gr=r("code"),mu=t("Dataset.select()"),pu=t(" juntas:"),ji=m(),f($s.$$.fragment),Ei=m(),f(js.$$.fragment),bi=m(),ne=r("p"),cu=t("Observe que corrigimos a seed em "),Yr=r("code"),uu=t("Dataset.shuffle()"),fu=t(" para fins de reprodutibilidade. "),Qr=r("code"),vu=t("Dataset.select()"),hu=t(" espera um iter\xE1vel de \xEDndices, ent\xE3o passamos "),Wr=r("code"),_u=t("range(1000)"),gu=t(" para pegar os primeiros 1.000 exemplos do conjunto de dados embaralhado. A partir desta amostra j\xE1 podemos ver algumas peculiaridades em nosso conjunto de dados:"),xi=m(),xe=r("ul"),Es=r("li"),$u=t("A coluna  "),Xr=r("code"),ju=t("Unnamed: 0"),Eu=t(" se parece com um ID an\xF4nimo para cada paciente."),bu=m(),bs=r("li"),xu=t("A coluna "),Kr=r("code"),wu=t("condition"),qu=t(" inclui uma combina\xE7\xE3o de r\xF3tulos em mai\xFAsculas e min\xFAsculas."),Du=m(),We=r("li"),ku=t("As revis\xF5es s\xE3o de tamanho vari\xE1vel e cont\xEAm uma mistura de separadores de linha Python ("),Zr=r("code"),Cu=t("\\r\\n"),yu=t("), bem como c\xF3digos de caracteres HTML como "),en=r("code"),Tu=t("&\\#039;"),zu=t("."),wi=m(),we=r("p"),Pu=t("Vamos ver como podemos usar \u{1F917} Datasets para lidar com cada um desses problemas. Para testar a hip\xF3tese de ID do paciente para a coluna "),an=r("code"),Ou=t("Unnamed: 0"),Au=t(", podemos usar a fun\xE7\xE3o "),sn=r("code"),Nu=t("Dataset.unique()"),Iu=t(" para verificar se o n\xFAmero de IDs corresponde ao n\xFAmero de linhas em cada divis\xE3o:"),qi=m(),f(xs.$$.fragment),Di=m(),qe=r("p"),Hu=t("Isso parece confirmar nossa hip\xF3tese, ent\xE3o vamos limpar um pouco o conjunto de dados renomeando a coluna "),tn=r("code"),Su=t("Unnamed: 0"),Mu=t(" para algo um pouco mais interpret\xE1vel. Podemos usar a fun\xE7\xE3o "),on=r("code"),Ru=t("DatasetDict.rename_column()"),Uu=t(" para renomear a coluna em ambas as divis\xF5es de uma s\xF3 vez:"),ki=m(),f(ws.$$.fragment),Ci=m(),f(qs.$$.fragment),yi=m(),f(ba.$$.fragment),Ti=m(),X=r("p"),Vu=t("Em seguida, vamos normalizar todos os r\xF3tulos "),rn=r("code"),Fu=t("condition"),Lu=t(" usando "),nn=r("code"),Bu=t("Dataset.map()"),Ju=t(". Como fizemos com a tokeniza\xE7\xE3o no "),eo=r("a"),Gu=t("Cap\xEDtulo 3"),Yu=t(", podemos definir uma fun\xE7\xE3o simples que pode ser aplicada em todas as linhas de cada divis\xE3o em "),ln=r("code"),Qu=t("drug_dataset"),Wu=t(":"),zi=m(),f(Ds.$$.fragment),Pi=m(),f(ks.$$.fragment),Oi=m(),K=r("p"),Xu=t("Oh n\xE3o, tivemos um problema com nossa fun\xE7\xE3o de mapa! A partir do erro, podemos inferir que algumas das entradas na coluna "),dn=r("code"),Ku=t("condition"),Zu=t(" s\xE3o "),mn=r("code"),ef=t("None"),af=t(", que n\xE3o podem ser min\xFAsculas, pois n\xE3o s\xE3o strings. Vamos eliminar essas linhas usando "),pn=r("code"),sf=t("Dataset.filter()"),tf=t(", que funciona de maneira semelhante a "),cn=r("code"),of=t("Dataset.map()"),rf=t(" e espera uma fun\xE7\xE3o que receba um \xFAnico exemplo do conjunto de dados. Em vez de escrever uma fun\xE7\xE3o expl\xEDcita como:"),Ai=m(),f(Cs.$$.fragment),Ni=m(),De=r("p"),nf=t("e ent\xE3o executando "),un=r("code"),lf=t("drug_dataset.filter(filter_nones)"),df=t(", podemos fazer isso em uma linha usando uma "),fn=r("em"),mf=t("fun\xE7\xE3o lambda"),pf=t(". Em Python, fun\xE7\xF5es lambda s\xE3o pequenas fun\xE7\xF5es que voc\xEA pode definir sem nome\xE1-las explicitamente. Eles assumem a forma geral:"),Ii=m(),f(ys.$$.fragment),Hi=m(),Z=r("p"),cf=t("onde "),vn=r("code"),uf=t("lambda"),ff=t(" \xE9 uma das [palavras-chave] especiais do Python ("),Ts=r("a"),vf=t("https://docs.python.org/3/reference/lexical_analysis.html#keywords"),hf=t("), "),hn=r("code"),_f=t("<arguments>"),gf=t(" \xE9 uma lista/conjunto de valores separados por v\xEDrgula que defina as entradas para a fun\xE7\xE3o, e "),_n=r("code"),$f=t("<express\xE3o>"),jf=t(" representa as opera\xE7\xF5es que voc\xEA deseja executar. Por exemplo, podemos definir uma fun\xE7\xE3o lambda simples que eleva um n\xFAmero ao quadrado da seguinte forma:"),Si=m(),f(zs.$$.fragment),Mi=m(),ao=r("p"),Ef=t("Para aplicar esta fun\xE7\xE3o a uma entrada, precisamos envolv\xEA-la e a entrada entre par\xEAnteses:"),Ri=m(),f(Ps.$$.fragment),Ui=m(),f(Os.$$.fragment),Vi=m(),so=r("p"),bf=t("Da mesma forma, podemos definir fun\xE7\xF5es lambda com v\xE1rios argumentos, separando-os com v\xEDrgulas. Por exemplo, podemos calcular a \xE1rea de um tri\xE2ngulo da seguinte forma:"),Fi=m(),f(As.$$.fragment),Li=m(),f(Ns.$$.fragment),Bi=m(),ke=r("p"),xf=t("As fun\xE7\xF5es lambda s\xE3o \xFAteis quando voc\xEA deseja definir fun\xE7\xF5es pequenas e de uso \xFAnico (para obter mais informa\xE7\xF5es sobre elas, recomendamos a leitura do excelente "),Is=r("a"),wf=t("tutorial do Real Python"),qf=t(" de Andre Burgaud). No contexto \u{1F917} Datasets, podemos usar fun\xE7\xF5es lambda para definir opera\xE7\xF5es simples de mapa e filtro, ent\xE3o vamos usar este truque para eliminar as entradas "),gn=r("code"),Df=t("None"),kf=t(" em nosso conjunto de dados:"),Ji=m(),f(Hs.$$.fragment),Gi=m(),Ce=r("p"),Cf=t("Com as entradas "),$n=r("code"),yf=t("None"),Tf=t(" removidas, podemos normalizar nossa coluna "),jn=r("code"),zf=t("condition"),Pf=t(":"),Yi=m(),f(Ss.$$.fragment),Qi=m(),f(Ms.$$.fragment),Wi=m(),to=r("p"),Of=t("Funciona! Agora que limpamos os r\xF3tulos, vamos dar uma olhada na limpeza dos pr\xF3prios coment\xE1rios."),Xi=m(),Xe=r("h2"),xa=r("a"),En=r("span"),f(Rs.$$.fragment),Af=m(),bn=r("span"),Nf=t("Criando novas colunas"),Ki=m(),oo=r("p"),If=t("Sempre que estiver lidando com avalia\xE7\xF5es de clientes, uma boa pr\xE1tica \xE9 verificar o n\xFAmero de palavras em cada avalia\xE7\xE3o. Uma avalia\xE7\xE3o pode ser apenas uma \xFAnica palavra como \u201C\xD3timo!\u201D ou um ensaio completo com milhares de palavras e, dependendo do caso de uso, voc\xEA precisar\xE1 lidar com esses extremos de maneira diferente. Para calcular o n\xFAmero de palavras em cada revis\xE3o, usaremos uma heur\xEDstica aproximada baseada na divis\xE3o de cada texto por espa\xE7os em branco."),Zi=m(),ro=r("p"),Hf=t("Vamos definir uma fun\xE7\xE3o simples que conta o n\xFAmero de palavras em cada revis\xE3o:"),em=m(),f(Us.$$.fragment),am=m(),Y=r("p"),Sf=t("Ao contr\xE1rio de nossa fun\xE7\xE3o "),xn=r("code"),Mf=t("lowercase_condition()"),Rf=t(", "),wn=r("code"),Uf=t("compute_review_length()"),Vf=t(" retorna um dicion\xE1rio cuja chave n\xE3o corresponde a um dos nomes de coluna no conjunto de dados. Nesse caso, quando "),qn=r("code"),Ff=t("compute_review_length()"),Lf=t(" for passado para "),Dn=r("code"),Bf=t("Dataset.map()"),Jf=t(", ele ser\xE1 aplicado a todas as linhas do conjunto de dados para criar uma nova coluna "),kn=r("code"),Gf=t("review_length"),Yf=t(":"),sm=m(),f(Vs.$$.fragment),tm=m(),f(Fs.$$.fragment),om=m(),ye=r("p"),Qf=t("Como esperado, podemos ver que uma coluna "),Cn=r("code"),Wf=t("review_length"),Xf=t(" foi adicionada ao nosso conjunto de treinamento. Podemos classificar essa nova coluna com "),yn=r("code"),Kf=t("Dataset.sort()"),Zf=t(" para ver como s\xE3o os valores extremos:"),rm=m(),f(Ls.$$.fragment),nm=m(),f(Bs.$$.fragment),lm=m(),no=r("p"),ev=t("Como suspeit\xE1vamos, algumas revis\xF5es cont\xEAm apenas uma \xFAnica palavra, que, embora possa ser boa para an\xE1lise de sentimentos, n\xE3o seria informativa se quisermos prever a condi\xE7\xE3o."),dm=m(),f(wa.$$.fragment),im=m(),qa=r("p"),av=t("Vamos usar a fun\xE7\xE3o "),Tn=r("code"),sv=t("Dataset.filter()"),tv=t(" para remover coment\xE1rios que contenham menos de 30 palavras. Da mesma forma que fizemos com a coluna \u201Ccondi\xE7\xE3o\u201D, podemos filtrar as reviews muito curtas exigindo que as reviews tenham um comprimento acima desse limite."),mm=m(),f(Js.$$.fragment),pm=m(),f(Gs.$$.fragment),cm=m(),lo=r("p"),ov=t("Como voc\xEA pode ver, isso removeu cerca de 15% das avalia\xE7\xF5es de nossos conjuntos de treinamento e teste originais."),um=m(),f(Da.$$.fragment),fm=m(),ka=r("p"),rv=t("A \xFAltima coisa com a qual precisamos lidar \xE9 a presen\xE7a de c\xF3digos de caracteres HTML em nossas an\xE1lises. Podemos usar o m\xF3dulo "),zn=r("code"),nv=t("html"),lv=t(" do Python para liberar esses caracteres, assim:"),vm=m(),f(Ys.$$.fragment),hm=m(),f(Qs.$$.fragment),_m=m(),Ca=r("p"),dv=t("Usaremos "),Pn=r("code"),iv=t("Dataset.map()"),mv=t(" para liberar todos os caracteres HTML em nosso corpus:"),gm=m(),f(Ws.$$.fragment),$m=m(),ya=r("p"),pv=t("Como voc\xEA pode ver, o m\xE9todo "),On=r("code"),cv=t("Dataset.map()"),uv=t(" \xE9 bastante \xFAtil para o processamento de dados \u2014 e ainda nem arranhamos a superf\xEDcie de tudo o que ele pode fazer!"),jm=m(),Ke=r("h2"),Ta=r("a"),An=r("span"),f(Xs.$$.fragment),fv=m(),io=r("span"),vv=t("Os superpoderes do m\xE9todo "),Nn=r("code"),hv=t("map()"),Em=m(),le=r("p"),_v=t("O m\xE9todo "),In=r("code"),gv=t("Dataset.map()"),$v=t(" recebe um argumento "),Hn=r("code"),jv=t("batched"),Ev=t(" que, se definido como "),Sn=r("code"),bv=t("True"),xv=t(", faz com que ele envie um batch de exemplos para a fun\xE7\xE3o map de uma s\xF3 vez (o tamanho do batch \xE9 configur\xE1vel, mas o padr\xE3o \xE9 1.000). Por exemplo, a fun\xE7\xE3o map anterior que n\xE3o escapou de todo o HTML demorou um pouco para ser executada (voc\xEA pode ler o tempo gasto nas barras de progresso). Podemos acelerar isso processando v\xE1rios elementos ao mesmo tempo usando uma compreens\xE3o de lista."),bm=m(),ee=r("p"),wv=t("Quando voc\xEA especifica "),Mn=r("code"),qv=t("batched=True"),Dv=t(" a fun\xE7\xE3o recebe um dicion\xE1rio com os campos do conjunto de dados, mas cada valor agora \xE9 uma "),Rn=r("em"),kv=t("lista de valores"),Cv=t(", e n\xE3o apenas um valor \xFAnico. O valor de retorno de "),Un=r("code"),yv=t("Dataset.map()"),Tv=t(" deve ser o mesmo: um dicion\xE1rio com os campos que queremos atualizar ou adicionar ao nosso conjunto de dados e uma lista de valores. Por exemplo, aqui est\xE1 outra maneira de fazer o scape de todos os caracteres HTML, mas usando "),Vn=r("code"),zv=t("batched=True"),Pv=t(":"),xm=m(),f(Ks.$$.fragment),wm=m(),Te=r("p"),Ov=t("Se voc\xEA estiver executando esse c\xF3digo em um jupyter notebook, ver\xE1 que esse comando \xE9 executado muito mais r\xE1pido que o anterior. E n\xE3o \xE9 porque nossas revis\xF5es j\xE1 foram sem escape em HTML \u2014 se voc\xEA reexecutar a instru\xE7\xE3o da se\xE7\xE3o anterior (sem "),Fn=r("code"),Av=t("batched=True"),Nv=t("), levar\xE1 o mesmo tempo que antes. Isso ocorre porque as compreens\xF5es de lista geralmente s\xE3o mais r\xE1pidas do que executar o mesmo c\xF3digo em um loop "),Ln=r("code"),Iv=t("for"),Hv=t(", e tamb\xE9m ganhamos algum desempenho acessando muitos elementos ao mesmo tempo em vez de um por um."),qm=m(),de=r("p"),Sv=t("Usar "),Bn=r("code"),Mv=t("Dataset.map()"),Rv=t(" com "),Jn=r("code"),Uv=t("batched=True"),Vv=t(" ser\xE1 essencial para desbloquear a velocidade dos tokenizers \u201Cr\xE1pidos\u201D que encontraremos no "),mo=r("a"),Fv=t("Cap\xEDtulo 6"),Lv=t(", que podem rapidamente tokenizar grandes listas de textos. Por exemplo, para tokenizar todas as an\xE1lises de medicamentos com um tokenizer r\xE1pido, poder\xEDamos usar uma fun\xE7\xE3o como esta:"),Dm=m(),f(Zs.$$.fragment),km=m(),ie=r("p"),Bv=t("Como voc\xEA viu no "),po=r("a"),Jv=t("Cap\xEDtulo 3"),Gv=t(", podemos passar um ou v\xE1rios exemplos para o tokenizer, ent\xE3o podemos usar esta fun\xE7\xE3o com ou sem "),Gn=r("code"),Yv=t("batched=True"),Qv=t(". Vamos aproveitar esta oportunidade para comparar o desempenho das diferentes op\xE7\xF5es. Em um notebook, voc\xEA pode cronometrar uma instru\xE7\xE3o de uma linha adicionando "),Yn=r("code"),Wv=t("%time"),Xv=t(" antes da linha de c\xF3digo que deseja medir:"),Cm=m(),f(et.$$.fragment),ym=m(),za=r("p"),Kv=t("Voc\xEA tamb\xE9m pode cronometrar uma c\xE9lula inteira colocando "),Qn=r("code"),Zv=t("%%time"),eh=t(" no in\xEDcio da c\xE9lula. No hardware em que executamos isso, ele mostrava 10,8s para esta instru\xE7\xE3o (\xE9 o n\xFAmero escrito depois de \u201CWall time\u201D)."),Tm=m(),f(Pa.$$.fragment),zm=m(),co=r("p"),ah=t("Aqui est\xE3o os resultados que obtivemos com e sem batching, com um tokenizer r\xE1pido e lento:"),Pm=m(),Oa=r("table"),Wn=r("thead"),Ze=r("tr"),uo=r("th"),sh=t("Op\xE7\xF5es"),th=m(),fo=r("th"),oh=t("Tokenizador r\xE1pido"),rh=m(),vo=r("th"),nh=t("Tokenizador lento"),lh=m(),at=r("tbody"),ea=r("tr"),ho=r("td"),Xn=r("code"),dh=t("batched=True"),ih=m(),_o=r("td"),mh=t("10.8s"),ph=m(),go=r("td"),ch=t("4min41s"),uh=m(),aa=r("tr"),$o=r("td"),Kn=r("code"),fh=t("batched=False"),vh=m(),jo=r("td"),hh=t("59.2s"),_h=m(),Eo=r("td"),gh=t("5min3s"),Om=m(),ze=r("p"),$h=t("Isso significa que usar um tokenizer r\xE1pido com a op\xE7\xE3o "),Zn=r("code"),jh=t("batched=True"),Eh=t(" \xE9 30 vezes mais r\xE1pido do que seu equivalente lento sem batching \u2014 isso \xE9 realmente incr\xEDvel! Essa \xE9 a principal raz\xE3o pela qual os tokenizers r\xE1pidos s\xE3o o padr\xE3o ao usar o "),el=r("code"),bh=t("AutoTokenizer"),xh=t(" (e porque eles s\xE3o chamados de \u201Cr\xE1pidos\u201D). Eles s\xE3o capazes de alcan\xE7ar essa acelera\xE7\xE3o porque nos bastidores o c\xF3digo de tokeniza\xE7\xE3o \xE9 executado em Rust, que \xE9 uma linguagem que facilita a execu\xE7\xE3o de c\xF3digo paralelizado."),Am=m(),bo=r("p"),wh=t("A paraleliza\xE7\xE3o tamb\xE9m \xE9 a raz\xE3o para a acelera\xE7\xE3o de quase 6x que o tokenizer r\xE1pido alcan\xE7a com o batching: voc\xEA n\xE3o pode paralelizar uma \xFAnica opera\xE7\xE3o de tokeniza\xE7\xE3o, mas quando voc\xEA deseja tokenizar muitos textos ao mesmo tempo, voc\xEA pode simplesmente dividir a execu\xE7\xE3o em v\xE1rios processos, cada um respons\xE1vel por seus pr\xF3prios textos."),Nm=m(),ge=r("p"),al=r("code"),qh=t("Dataset.map()"),Dh=t(" tamb\xE9m possui alguns recursos de paraleliza\xE7\xE3o pr\xF3prios. Como eles n\xE3o s\xE3o suportados pelo Rust, eles n\xE3o permitem que um tokenizer lento alcance um r\xE1pido, mas ainda podem ser \xFAteis (especialmente se voc\xEA estiver usando um tokenizer que n\xE3o possui uma vers\xE3o r\xE1pida). Para ativar o multiprocessamento, use o argumento "),sl=r("code"),kh=t("num_proc"),Ch=t(" e especifique o n\xFAmero de processos a serem usados \u200B\u200Bem sua chamada para "),tl=r("code"),yh=t("Dataset.map()"),Th=t(":"),Im=m(),f(st.$$.fragment),Hm=m(),xo=r("p"),zh=t("Voc\xEA pode experimentar um pouco o tempo para determinar o n\xFAmero ideal de processos a serem usados; no nosso caso, 8 pareceu produzir o melhor ganho de velocidade. Aqui est\xE3o os n\xFAmeros que obtivemos com e sem multiprocessamento:"),Sm=m(),Aa=r("table"),ol=r("thead"),sa=r("tr"),wo=r("th"),Ph=t("Op\xE7\xF5es"),Oh=m(),qo=r("th"),Ah=t("Tokenizador r\xE1pido"),Nh=m(),Do=r("th"),Ih=t("Tokenizador lento"),Hh=m(),$e=r("tbody"),ta=r("tr"),ko=r("td"),rl=r("code"),Sh=t("batched=True"),Mh=m(),Co=r("td"),Rh=t("10.8s"),Uh=m(),yo=r("td"),Vh=t("4min41s"),Fh=m(),oa=r("tr"),To=r("td"),nl=r("code"),Lh=t("batched=False"),Bh=m(),zo=r("td"),Jh=t("59.2s"),Gh=m(),Po=r("td"),Yh=t("5min3s"),Qh=m(),ra=r("tr"),Na=r("td"),ll=r("code"),Wh=t("batched=True"),Xh=t(", "),dl=r("code"),Kh=t("num_proc=8"),Zh=m(),Oo=r("td"),e_=t("6.52s"),a_=m(),Ao=r("td"),s_=t("41.3s"),t_=m(),na=r("tr"),Ia=r("td"),il=r("code"),o_=t("batched=False"),r_=t(", "),ml=r("code"),n_=t("num_proc=8"),l_=m(),No=r("td"),d_=t("9.49s"),i_=m(),Io=r("td"),m_=t("45.2s"),Mm=m(),me=r("p"),p_=t("Esses s\xE3o resultados muito mais razo\xE1veis \u200B\u200Bpara o tokenizer lento, mas o desempenho do tokenizer r\xE1pido tamb\xE9m foi substancialmente melhorado. Observe, no entanto, que nem sempre ser\xE1 o caso \u2014 para valores de "),pl=r("code"),c_=t("num_proc"),u_=t(" diferentes de 8, nossos testes mostraram que era mais r\xE1pido usar "),cl=r("code"),f_=t("batched=True"),v_=t(" sem essa op\xE7\xE3o. Em geral, n\xE3o recomendamos o uso de multiprocessamento Python para tokenizers r\xE1pidos com "),ul=r("code"),h_=t("batched=True"),__=t("."),Rm=m(),f(Ha.$$.fragment),Um=m(),pe=r("p"),g_=t("Toda essa funcionalidade condensada em um \xFAnico m\xE9todo j\xE1 \xE9 incr\xEDvel, mas tem mais! Com "),fl=r("code"),$_=t("Dataset.map()"),j_=t(" e "),vl=r("code"),E_=t("batched=True"),b_=t(" voc\xEA pode alterar o n\xFAmero de elementos em seu conjunto de dados. Isso \xE9 super \xFAtil em muitas situa\xE7\xF5es em que voc\xEA deseja criar v\xE1rios recursos de treinamento a partir de um exemplo, e precisaremos fazer isso como parte do pr\xE9-processamento de v\xE1rias das tarefas de PNL que realizaremos no "),Ho=r("a"),x_=t("Cap\xEDtulo 7"),w_=t("."),Vm=m(),f(Sa.$$.fragment),Fm=m(),Pe=r("p"),q_=t("Vamos dar uma olhada em como funciona! Aqui vamos tokenizar nossos exemplos e trunc\xE1-los para um comprimento m\xE1ximo de 128, mas pediremos ao tokenizer para retornar "),hl=r("em"),D_=t("todos"),k_=t(" os peda\xE7os dos textos em vez de apenas o primeiro. Isso pode ser feito com "),_l=r("code"),C_=t("return_overflowing_tokens=True"),y_=t(":"),Lm=m(),f(tt.$$.fragment),Bm=m(),Ma=r("p"),T_=t("Vamos testar isso em um exemplo antes de usar "),gl=r("code"),z_=t("Dataset.map()"),P_=t(" em todo o conjunto de dados:"),Jm=m(),f(ot.$$.fragment),Gm=m(),f(rt.$$.fragment),Ym=m(),So=r("p"),O_=t("Assim, nosso primeiro exemplo no conjunto de treinamento se tornou dois recursos porque foi tokenizado para mais do que o n\xFAmero m\xE1ximo de tokens que especificamos: o primeiro de comprimento 128 e o segundo de comprimento 49. Agora vamos fazer isso para todos os elementos do conjunto de dados!"),Qm=m(),f(nt.$$.fragment),Wm=m(),f(lt.$$.fragment),Xm=m(),Oe=r("p"),A_=t("Oh n\xE3o! Isso n\xE3o funcionou! Por que n\xE3o? Observar a mensagem de erro nos dar\xE1 uma pista: h\xE1 uma incompatibilidade nos comprimentos de uma das colunas, sendo uma de comprimento 1.463 e a outra de comprimento 1.000. Se voc\xEA consultou a [documenta\xE7\xE3o] do "),$l=r("code"),N_=t("Dataset.map()"),I_=t(" ("),dt=r("a"),H_=t("https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map"),S_=t("), voc\xEA deve se lembrar de que \xE9 o n\xFAmero de amostras passadas para a fun\xE7\xE3o que estamos mapeando; aqui, esses 1.000 exemplos forneceram 1.463 novos recursos, resultando em um erro de forma."),Km=m(),ae=r("p"),M_=t("O problema \xE9 que estamos tentando misturar dois conjuntos de dados diferentes de tamanhos diferentes: as colunas "),jl=r("code"),R_=t("drug_dataset"),U_=t(" ter\xE3o um certo n\xFAmero de exemplos (os 1.000 em nosso erro), mas o "),El=r("code"),V_=t("tokenized_dataset"),F_=t(" que estamos construindo ter\xE1 mais (o 1.463 na mensagem de erro). Isso n\xE3o funciona para um "),bl=r("code"),L_=t("Dataset"),B_=t(", portanto, precisamos remover as colunas do conjunto de dados antigo ou torn\xE1-las do mesmo tamanho do novo conjunto de dados. Podemos fazer o primeiro com o argumento "),xl=r("code"),J_=t("remove_columns"),G_=t(":"),Zm=m(),f(it.$$.fragment),ep=m(),Mo=r("p"),Y_=t("Agora isso funciona sem erro. Podemos verificar que nosso novo conjunto de dados tem muito mais elementos do que o conjunto de dados original comparando os comprimentos:"),ap=m(),f(mt.$$.fragment),sp=m(),f(pt.$$.fragment),tp=m(),Ae=r("p"),Q_=t("Mencionamos que tamb\xE9m podemos lidar com o problema de comprimento incompat\xEDvel tornando as colunas antigas do mesmo tamanho das novas. Para fazer isso, precisaremos do campo "),wl=r("code"),W_=t("overflow_to_sample_mapping"),X_=t(" que o tokenizer retorna quando configuramos "),ql=r("code"),K_=t("return_overflowing_tokens=True"),Z_=t(". Ele nos fornece um mapeamento de um novo \xEDndice de recurso para o \xEDndice da amostra da qual ele se originou. Usando isso, podemos associar cada chave presente em nosso conjunto de dados original a uma lista de valores do tamanho certo, repetindo os valores de cada exemplo quantas vezes ele gerar novos recursos:"),op=m(),f(ct.$$.fragment),rp=m(),Ra=r("p"),e2=t("Podemos ver que funciona com "),Dl=r("code"),a2=t("Dataset.map()"),s2=t(" sem precisarmos remover as colunas antigas:"),np=m(),f(ut.$$.fragment),lp=m(),f(ft.$$.fragment),dp=m(),Ro=r("p"),t2=t("Obtemos o mesmo n\xFAmero de recursos de treinamento de antes, mas aqui mantivemos todos os campos antigos. Se voc\xEA precisar deles para algum p\xF3s-processamento ap\xF3s aplicar seu modelo, conv\xE9m usar essa abordagem."),ip=m(),Ua=r("p"),o2=t("Agora voc\xEA viu como \u{1F917} Datasets podem ser usados \u200B\u200Bpara pr\xE9-processar um conjunto de dados de v\xE1rias maneiras. Embora as fun\xE7\xF5es de processamento de \u{1F917} Datasets cubram a maioria das suas necessidades de treinamento de modelo, pode haver momentos em que voc\xEA precisar\xE1 mudar para o Pandas para acessar recursos mais poderosos, como "),kl=r("code"),r2=t("DataFrame.groupby()"),n2=t(" ou APIs de alto n\xEDvel para visualiza\xE7\xE3o. Felizmente, \u{1F917} Datasets foi projetado para ser interoper\xE1vel com bibliotecas como Pandas, NumPy, PyTorch, TensorFlow e JAX. Vamos dar uma olhada em como isso funciona."),mp=m(),la=r("h2"),Va=r("a"),Cl=r("span"),f(vt.$$.fragment),l2=m(),da=r("span"),d2=t("De "),yl=r("code"),i2=t("Dataset"),m2=t("s para "),Tl=r("code"),p2=t("DataFrame"),c2=t("s e vice-versa"),pp=m(),f(ht.$$.fragment),cp=m(),ce=r("p"),u2=t("Para habilitar a convers\xE3o entre v\xE1rias bibliotecas de terceiros, \u{1F917} Datasets fornece uma fun\xE7\xE3o "),zl=r("code"),f2=t("Dataset.set_format()"),v2=t(". Essa fun\xE7\xE3o altera apenas o "),Pl=r("em"),h2=t("formato de sa\xEDda"),_2=t(" do conjunto de dados, para que voc\xEA possa alternar facilmente para outro formato sem afetar o "),Ol=r("em"),g2=t("formato de dados"),$2=t(" subjacente, que \xE9 o Apache Arrow. A formata\xE7\xE3o \xE9 feita no local. Para demonstrar, vamos converter nosso conjunto de dados para Pandas:"),up=m(),f(_t.$$.fragment),fp=m(),Fa=r("p"),j2=t("Agora, quando acessamos os elementos do dataset, obtemos um "),Al=r("code"),E2=t("pandas.DataFrame"),b2=t(" em vez de um dicion\xE1rio:"),vp=m(),f(gt.$$.fragment),hp=m(),Ne=r("table"),Nl=r("thead"),I=r("tr"),_p=r("th"),x2=m(),Il=r("th"),w2=t("patient_id"),q2=m(),Hl=r("th"),D2=t("drugName"),k2=m(),Sl=r("th"),C2=t("condition"),y2=m(),Ml=r("th"),T2=t("review"),z2=m(),Rl=r("th"),P2=t("rating"),O2=m(),Ul=r("th"),A2=t("date"),N2=m(),Vl=r("th"),I2=t("usefulCount"),H2=m(),Fl=r("th"),S2=t("review_length"),M2=m(),ia=r("tbody"),H=r("tr"),Ll=r("th"),R2=t("0"),U2=m(),Bl=r("td"),V2=t("95260"),F2=m(),Jl=r("td"),L2=t("Guanfacine"),B2=m(),Gl=r("td"),J2=t("adhd"),G2=m(),Yl=r("td"),Y2=t('"My son is halfway through his fourth week of Intuniv..."'),Q2=m(),Ql=r("td"),W2=t("8.0"),X2=m(),Wl=r("td"),K2=t("April 27, 2010"),Z2=m(),Xl=r("td"),eg=t("192"),ag=m(),Kl=r("td"),sg=t("141"),tg=m(),S=r("tr"),Zl=r("th"),og=t("1"),rg=m(),ed=r("td"),ng=t("92703"),lg=m(),ad=r("td"),dg=t("Lybrel"),ig=m(),sd=r("td"),mg=t("birth control"),pg=m(),td=r("td"),cg=t('"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects..."'),ug=m(),od=r("td"),fg=t("5.0"),vg=m(),rd=r("td"),hg=t("December 14, 2009"),_g=m(),nd=r("td"),gg=t("17"),$g=m(),ld=r("td"),jg=t("134"),Eg=m(),M=r("tr"),dd=r("th"),bg=t("2"),xg=m(),id=r("td"),wg=t("138000"),qg=m(),md=r("td"),Dg=t("Ortho Evra"),kg=m(),pd=r("td"),Cg=t("birth control"),yg=m(),cd=r("td"),Tg=t('"This is my first time using any form of birth control..."'),zg=m(),ud=r("td"),Pg=t("8.0"),Og=m(),fd=r("td"),Ag=t("November 3, 2015"),Ng=m(),vd=r("td"),Ig=t("10"),Hg=m(),hd=r("td"),Sg=t("89"),gp=m(),Ie=r("p"),Mg=t("Vamos criar um "),_d=r("code"),Rg=t("pandas.DataFrame"),Ug=t(" para todo o conjunto de treinamento selecionando todos os elementos de "),gd=r("code"),Vg=t('drug_dataset["train"]'),Fg=t(":"),$p=m(),f($t.$$.fragment),jp=m(),f(La.$$.fragment),Ep=m(),Ba=r("p"),Lg=t("A partir daqui, podemos usar todas as funcionalidades do Pandas que queremos. Por exemplo, podemos fazer um encadeamento sofisticado para calcular a distribui\xE7\xE3o de classes entre as entradas "),$d=r("code"),Bg=t("condition"),Jg=t(":"),bp=m(),f(jt.$$.fragment),xp=m(),He=r("table"),jd=r("thead"),Se=r("tr"),wp=r("th"),Gg=m(),Ed=r("th"),Yg=t("condition"),Qg=m(),bd=r("th"),Wg=t("frequency"),Xg=m(),te=r("tbody"),ma=r("tr"),xd=r("th"),Kg=t("0"),Zg=m(),wd=r("td"),e1=t("birth control"),a1=m(),qd=r("td"),s1=t("27655"),t1=m(),pa=r("tr"),Dd=r("th"),o1=t("1"),r1=m(),kd=r("td"),n1=t("depression"),l1=m(),Cd=r("td"),d1=t("8023"),i1=m(),ca=r("tr"),yd=r("th"),m1=t("2"),p1=m(),Td=r("td"),c1=t("acne"),u1=m(),zd=r("td"),f1=t("5209"),v1=m(),ua=r("tr"),Pd=r("th"),h1=t("3"),_1=m(),Od=r("td"),g1=t("anxiety"),$1=m(),Ad=r("td"),j1=t("4991"),E1=m(),fa=r("tr"),Nd=r("th"),b1=t("4"),x1=m(),Id=r("td"),w1=t("pain"),q1=m(),Hd=r("td"),D1=t("4744"),qp=m(),Me=r("p"),k1=t("E uma vez que terminamos nossa an\xE1lise de Pandas, sempre podemos criar um novo objeto "),Sd=r("code"),C1=t("Dataset"),y1=t(" usando a fun\xE7\xE3o "),Md=r("code"),T1=t("Dataset.from_pandas()"),z1=t(" da seguinte forma:"),Dp=m(),f(Et.$$.fragment),kp=m(),f(bt.$$.fragment),Cp=m(),f(Ja.$$.fragment),yp=m(),ue=r("p"),P1=t("Isso encerra nosso tour pelas v\xE1rias t\xE9cnicas de pr\xE9-processamento dispon\xEDveis em \u{1F917} Datasets. Para completar a se\xE7\xE3o, vamos criar um conjunto de valida\xE7\xE3o para preparar o conjunto de dados para treinar um classificador. Antes de fazer isso, vamos redefinir o formato de sa\xEDda de "),Rd=r("code"),O1=t("drug_dataset"),A1=t(" de "),Ud=r("code"),N1=t('"pandas"'),I1=t(" para "),Vd=r("code"),H1=t('"arrow"'),S1=t(":"),Tp=m(),f(xt.$$.fragment),zp=m(),va=r("h2"),Ga=r("a"),Fd=r("span"),f(wt.$$.fragment),M1=m(),Ld=r("span"),R1=t("Criando um conjunto de valida\xE7\xE3o"),Pp=m(),Uo=r("p"),U1=t("Embora tenhamos um conjunto de teste que poder\xEDamos usar para avalia\xE7\xE3o, \xE9 uma boa pr\xE1tica deixar o conjunto de teste intocado e criar um conjunto de valida\xE7\xE3o separado durante o desenvolvimento. Quando estiver satisfeito com o desempenho de seus modelos no conjunto de valida\xE7\xE3o, voc\xEA poder\xE1 fazer uma verifica\xE7\xE3o final de sanidade no conjunto de teste. Esse processo ajuda a mitigar o risco de voc\xEA se ajustar demais ao conjunto de teste e implantar um modelo que falha em dados do mundo real."),Op=m(),Q=r("p"),V1=t("\u{1F917} Datasets fornece uma fun\xE7\xE3o "),Bd=r("code"),F1=t("Dataset.train_test_split()"),L1=t(" que \xE9 baseada na famosa funcionalidade do "),Jd=r("code"),B1=t("scikit-learn"),J1=t(". Vamos us\xE1-lo para dividir nosso conjunto de treinamento em divis\xF5es "),Gd=r("code"),G1=t("train"),Y1=t(" e "),Yd=r("code"),Q1=t("validation"),W1=t(" (definimos o argumento "),Qd=r("code"),X1=t("seed"),K1=t(" para reprodutibilidade):"),Ap=m(),f(qt.$$.fragment),Np=m(),f(Dt.$$.fragment),Ip=m(),Ya=r("p"),Z1=t("\xD3timo, agora preparamos um conjunto de dados pronto para treinar alguns modelos! Na "),Vo=r("a"),e$=t("se\xE7\xE3o 5"),a$=t(", mostraremos como fazer upload de conjuntos de dados para o Hugging Face Hub, mas, por enquanto, vamos encerrar nossa an\xE1lise analisando algumas maneiras de salvar conjuntos de dados em sua m\xE1quina local ."),Hp=m(),ha=r("h2"),Qa=r("a"),Wd=r("span"),f(kt.$$.fragment),s$=m(),Xd=r("span"),t$=t("Salvando um conjunto de dados"),Sp=m(),f(Ct.$$.fragment),Mp=m(),Fo=r("p"),o$=t("Embora \u{1F917} Datasets armazene em cache todos os conjuntos de dados baixados e as opera\xE7\xF5es realizadas nele, h\xE1 momentos em que voc\xEA deseja salvar um conjunto de dados em disco (por exemplo, caso o cache seja exclu\xEDdo). Conforme mostrado na tabela abaixo, \u{1F917} Datasets fornece tr\xEAs fun\xE7\xF5es principais para salvar seu conjunto de dados em diferentes formatos:"),Rp=m(),Wa=r("table"),Kd=r("thead"),yt=r("tr"),Lo=r("th"),r$=t("Formato dos dados"),n$=m(),Bo=r("th"),l$=t("Fun\xE7\xE3o"),d$=m(),_a=r("tbody"),Tt=r("tr"),Jo=r("td"),i$=t("Arrow"),m$=m(),Go=r("td"),Zd=r("code"),p$=t("Dataset.save_to_disk()"),c$=m(),zt=r("tr"),Yo=r("td"),u$=t("CSV"),f$=m(),Qo=r("td"),ei=r("code"),v$=t("Dataset.to_csv()"),h$=m(),Pt=r("tr"),Wo=r("td"),_$=t("JSON"),g$=m(),Xo=r("td"),ai=r("code"),$$=t("Dataset.to_json()"),Up=m(),Ko=r("p"),j$=t("Por exemplo, vamos salvar nosso conjunto de dados limpo no formato Arrow:"),Vp=m(),f(Ot.$$.fragment),Fp=m(),Zo=r("p"),E$=t("Isso criar\xE1 um diret\xF3rio com a seguinte estrutura:"),Lp=m(),f(At.$$.fragment),Bp=m(),fe=r("p"),b$=t("onde podemos ver que cada divis\xE3o est\xE1 associada a sua pr\xF3pria tabela "),si=r("em"),x$=t("dataset.arrow"),w$=t(" e alguns metadados em "),ti=r("em"),q$=t("dataset_info.json"),D$=t(" e "),oi=r("em"),k$=t("state.json"),C$=t(". Voc\xEA pode pensar no formato Arrow como uma tabela sofisticada de colunas e linhas otimizada para criar aplicativos de alto desempenho que processam e transportam grandes conjuntos de dados."),Jp=m(),Xa=r("p"),y$=t("Uma vez que o conjunto de dados \xE9 salvo, podemos carreg\xE1-lo usando a fun\xE7\xE3o "),ri=r("code"),T$=t("load_from_disk()"),z$=t(" da seguinte forma:"),Gp=m(),f(Nt.$$.fragment),Yp=m(),f(It.$$.fragment),Qp=m(),Ka=r("p"),P$=t("Para os formatos CSV e JSON, temos que armazenar cada divis\xE3o como um arquivo separado. Uma maneira de fazer isso \xE9 iterando as chaves e os valores no objeto "),ni=r("code"),O$=t("DatasetDict"),A$=t(":"),Wp=m(),f(Ht.$$.fragment),Xp=m(),Za=r("p"),N$=t("Isso salva cada divis\xE3o em "),St=r("a"),I$=t("formato de linhas JSON"),H$=t(", em que cada linha no conjunto de dados \xE9 armazenada como uma \xFAnica linha de JSON. Veja como \xE9 o primeiro exemplo:"),Kp=m(),f(Mt.$$.fragment),Zp=m(),f(Rt.$$.fragment),ec=m(),es=r("p"),S$=t("Podemos ent\xE3o usar as t\xE9cnicas da "),er=r("a"),M$=t("se\xE7\xE3o 2"),R$=t(" para carregar os arquivos JSON da seguinte forma:"),ac=m(),f(Ut.$$.fragment),sc=m(),ar=r("p"),U$=t("E \xE9 isso para nossa excurs\xE3o em dados com \u{1F917} Datasets! Agora que temos um conjunto de dados limpo para treinar um modelo, aqui est\xE3o algumas ideias que voc\xEA pode experimentar:"),tc=m(),as=r("ol"),Vt=r("li"),V$=t("Use as t\xE9cnicas do "),sr=r("a"),F$=t("Cap\xEDtulo 3"),L$=t(" para treinar um classificador que possa prever a condi\xE7\xE3o do paciente com base na revis\xE3o do medicamento."),B$=m(),ga=r("li"),J$=t("Use o pipeline "),li=r("code"),G$=t("summarization"),Y$=t(" do "),tr=r("a"),Q$=t("Cap\xEDtulo 1"),W$=t(" para gerar resumos das revis\xF5es."),oc=m(),or=r("p"),X$=t("A seguir, veremos como \u{1F917} Datasets pode permitir que voc\xEA trabalhe com grandes conjuntos de dados sem explodir seu laptop!"),this.h()},l(e){const d=Fx('[data-svelte="svelte-1phssyn"]',document.head);c=n(d,"META",{name:!0,content:!0}),d.forEach(s),y=p(e),E=n(e,"H1",{class:!0});var Ft=l(E);q=n(Ft,"A",{id:!0,class:!0,href:!0});var di=l(q);k=n(di,"SPAN",{});var ii=l(k);v(b.$$.fragment,ii),ii.forEach(s),di.forEach(s),D=p(Ft),T=n(Ft,"SPAN",{});var mi=l(T);x=o(mi,"Hora de fatiar e dividir os dados"),mi.forEach(s),Ft.forEach(s),w=p(e),v(P.$$.fragment,e),C=p(e),z=n(e,"P",{});var pi=l(z);G=o(pi,"Na maioria das vezes, os dados com os quais voc\xEA trabalha n\xE3o estar\xE3o perfeitamente preparados para treinamento de modelos. Nesta se\xE7\xE3o vamos explorar as v\xE1rias caracter\xEDsticas que o \u{1F917} Datasets fornece para limpar seus conjuntos de dados."),pi.forEach(s),N=p(e),v(O.$$.fragment,e),_e=p(e),U=n(e,"H2",{class:!0});var Lt=l(U);W=n(Lt,"A",{id:!0,class:!0,href:!0});var ci=l(W);oe=n(ci,"SPAN",{});var ui=l(oe);v(se.$$.fragment,ui),ui.forEach(s),ci.forEach(s),fs=p(Lt),Ge=n(Lt,"SPAN",{});var ej=l(Ge);Ye=o(ej,"Slicing and dicing our data"),ej.forEach(s),Lt.forEach(s),$a=p(e),V=n(e,"P",{});var Re=l(V);Qe=o(Re,"Semelhante ao Pandas, \u{1F917} Datasets fornece v\xE1rias fun\xE7\xF5es para manipular o conte\xFAdo dos objetos "),A=n(Re,"CODE",{});var aj=l(A);Gt=o(aj,"Dataset"),aj.forEach(s),Yt=o(Re," e "),ja=n(Re,"CODE",{});var sj=l(ja);Qt=o(sj,"DatasetDict"),sj.forEach(s),Wt=o(Re,". J\xE1 encontramos o m\xE9todo "),Ea=n(Re,"CODE",{});var tj=l(Ea);Xt=o(tj,"Dataset.map()"),tj.forEach(s),Kt=o(Re," no "),Zt=n(Re,"A",{href:!0});var oj=l(Zt);Vc=o(oj,"Cap\xEDtulo 3"),oj.forEach(s),Fc=o(Re,", e nesta se\xE7\xE3o vamos explorar algumas das outras fun\xE7\xF5es \xE0 nossa disposi\xE7\xE3o."),Re.forEach(s),fi=p(e),je=n(e,"P",{});var rr=l(je);Lc=o(rr,"Para este exemplo, usaremos o "),vs=n(rr,"A",{href:!0,rel:!0});var rj=l(vs);Bc=o(rj,"Drug Review Dataset"),rj.forEach(s),Jc=o(rr," que est\xE1 hospedado na "),hs=n(rr,"A",{href:!0,rel:!0});var nj=l(hs);Gc=o(nj,"UC Irvine Machine Learning Repository"),nj.forEach(s),Yc=o(rr,", que cont\xE9m avalia\xE7\xF5es de pacientes sobre v\xE1rios medicamentos, juntamente com a condi\xE7\xE3o a ser tratada e uma classifica\xE7\xE3o de 10 estrelas da satisfa\xE7\xE3o do paciente."),rr.forEach(s),vi=p(e),Ee=n(e,"P",{});var nr=l(Ee);Qc=o(nr,"Primeiro precisamos baixar e extrair os dados, o que pode ser feito com os comandos "),Ur=n(nr,"CODE",{});var lj=l(Ur);Wc=o(lj,"wget"),lj.forEach(s),Xc=o(nr," e "),Vr=n(nr,"CODE",{});var dj=l(Vr);Kc=o(dj,"unzip"),dj.forEach(s),Zc=o(nr,":"),nr.forEach(s),hi=p(e),v(_s.$$.fragment,e),_i=p(e),re=n(e,"P",{});var ss=l(re);eu=o(ss,"Como o TSV \xE9 apenas uma variante do CSV que usa tabula\xE7\xF5es em vez de v\xEDrgulas como separador, podemos carregar esses arquivos usando o script de carregamento "),Fr=n(ss,"CODE",{});var ij=l(Fr);au=o(ij,"csv"),ij.forEach(s),su=o(ss," e especificando o argumento "),Lr=n(ss,"CODE",{});var mj=l(Lr);tu=o(mj,"delimiter"),mj.forEach(s),ou=o(ss," na fun\xE7\xE3o "),Br=n(ss,"CODE",{});var pj=l(Br);ru=o(pj,"load_dataset()"),pj.forEach(s),nu=o(ss," da seguinte forma:"),ss.forEach(s),gi=p(e),v(gs.$$.fragment,e),$i=p(e),be=n(e,"P",{});var lr=l(be);lu=o(lr,"Uma boa pr\xE1tica ao fazer qualquer tipo de an\xE1lise de dados \xE9 pegar uma pequena amostra aleat\xF3ria para ter uma ideia r\xE1pida do tipo de dados com os quais voc\xEA est\xE1 trabalhando. Em \u{1F917} Datasets, podemos criar uma amostra aleat\xF3ria encadeando as fun\xE7\xF5es "),Jr=n(lr,"CODE",{});var cj=l(Jr);du=o(cj,"Dataset.shuffle()"),cj.forEach(s),iu=o(lr," e "),Gr=n(lr,"CODE",{});var uj=l(Gr);mu=o(uj,"Dataset.select()"),uj.forEach(s),pu=o(lr," juntas:"),lr.forEach(s),ji=p(e),v($s.$$.fragment,e),Ei=p(e),v(js.$$.fragment,e),bi=p(e),ne=n(e,"P",{});var ts=l(ne);cu=o(ts,"Observe que corrigimos a seed em "),Yr=n(ts,"CODE",{});var fj=l(Yr);uu=o(fj,"Dataset.shuffle()"),fj.forEach(s),fu=o(ts," para fins de reprodutibilidade. "),Qr=n(ts,"CODE",{});var vj=l(Qr);vu=o(vj,"Dataset.select()"),vj.forEach(s),hu=o(ts," espera um iter\xE1vel de \xEDndices, ent\xE3o passamos "),Wr=n(ts,"CODE",{});var hj=l(Wr);_u=o(hj,"range(1000)"),hj.forEach(s),gu=o(ts," para pegar os primeiros 1.000 exemplos do conjunto de dados embaralhado. A partir desta amostra j\xE1 podemos ver algumas peculiaridades em nosso conjunto de dados:"),ts.forEach(s),xi=p(e),xe=n(e,"UL",{});var dr=l(xe);Es=n(dr,"LI",{});var nc=l(Es);$u=o(nc,"A coluna  "),Xr=n(nc,"CODE",{});var _j=l(Xr);ju=o(_j,"Unnamed: 0"),_j.forEach(s),Eu=o(nc," se parece com um ID an\xF4nimo para cada paciente."),nc.forEach(s),bu=p(dr),bs=n(dr,"LI",{});var lc=l(bs);xu=o(lc,"A coluna "),Kr=n(lc,"CODE",{});var gj=l(Kr);wu=o(gj,"condition"),gj.forEach(s),qu=o(lc," inclui uma combina\xE7\xE3o de r\xF3tulos em mai\xFAsculas e min\xFAsculas."),lc.forEach(s),Du=p(dr),We=n(dr,"LI",{});var ir=l(We);ku=o(ir,"As revis\xF5es s\xE3o de tamanho vari\xE1vel e cont\xEAm uma mistura de separadores de linha Python ("),Zr=n(ir,"CODE",{});var $j=l(Zr);Cu=o($j,"\\r\\n"),$j.forEach(s),yu=o(ir,"), bem como c\xF3digos de caracteres HTML como "),en=n(ir,"CODE",{});var jj=l(en);Tu=o(jj,"&\\#039;"),jj.forEach(s),zu=o(ir,"."),ir.forEach(s),dr.forEach(s),wi=p(e),we=n(e,"P",{});var mr=l(we);Pu=o(mr,"Vamos ver como podemos usar \u{1F917} Datasets para lidar com cada um desses problemas. Para testar a hip\xF3tese de ID do paciente para a coluna "),an=n(mr,"CODE",{});var Ej=l(an);Ou=o(Ej,"Unnamed: 0"),Ej.forEach(s),Au=o(mr,", podemos usar a fun\xE7\xE3o "),sn=n(mr,"CODE",{});var bj=l(sn);Nu=o(bj,"Dataset.unique()"),bj.forEach(s),Iu=o(mr," para verificar se o n\xFAmero de IDs corresponde ao n\xFAmero de linhas em cada divis\xE3o:"),mr.forEach(s),qi=p(e),v(xs.$$.fragment,e),Di=p(e),qe=n(e,"P",{});var pr=l(qe);Hu=o(pr,"Isso parece confirmar nossa hip\xF3tese, ent\xE3o vamos limpar um pouco o conjunto de dados renomeando a coluna "),tn=n(pr,"CODE",{});var xj=l(tn);Su=o(xj,"Unnamed: 0"),xj.forEach(s),Mu=o(pr," para algo um pouco mais interpret\xE1vel. Podemos usar a fun\xE7\xE3o "),on=n(pr,"CODE",{});var wj=l(on);Ru=o(wj,"DatasetDict.rename_column()"),wj.forEach(s),Uu=o(pr," para renomear a coluna em ambas as divis\xF5es de uma s\xF3 vez:"),pr.forEach(s),ki=p(e),v(ws.$$.fragment,e),Ci=p(e),v(qs.$$.fragment,e),yi=p(e),v(ba.$$.fragment,e),Ti=p(e),X=n(e,"P",{});var Ue=l(X);Vu=o(Ue,"Em seguida, vamos normalizar todos os r\xF3tulos "),rn=n(Ue,"CODE",{});var qj=l(rn);Fu=o(qj,"condition"),qj.forEach(s),Lu=o(Ue," usando "),nn=n(Ue,"CODE",{});var Dj=l(nn);Bu=o(Dj,"Dataset.map()"),Dj.forEach(s),Ju=o(Ue,". Como fizemos com a tokeniza\xE7\xE3o no "),eo=n(Ue,"A",{href:!0});var kj=l(eo);Gu=o(kj,"Cap\xEDtulo 3"),kj.forEach(s),Yu=o(Ue,", podemos definir uma fun\xE7\xE3o simples que pode ser aplicada em todas as linhas de cada divis\xE3o em "),ln=n(Ue,"CODE",{});var Cj=l(ln);Qu=o(Cj,"drug_dataset"),Cj.forEach(s),Wu=o(Ue,":"),Ue.forEach(s),zi=p(e),v(Ds.$$.fragment,e),Pi=p(e),v(ks.$$.fragment,e),Oi=p(e),K=n(e,"P",{});var Ve=l(K);Xu=o(Ve,"Oh n\xE3o, tivemos um problema com nossa fun\xE7\xE3o de mapa! A partir do erro, podemos inferir que algumas das entradas na coluna "),dn=n(Ve,"CODE",{});var yj=l(dn);Ku=o(yj,"condition"),yj.forEach(s),Zu=o(Ve," s\xE3o "),mn=n(Ve,"CODE",{});var Tj=l(mn);ef=o(Tj,"None"),Tj.forEach(s),af=o(Ve,", que n\xE3o podem ser min\xFAsculas, pois n\xE3o s\xE3o strings. Vamos eliminar essas linhas usando "),pn=n(Ve,"CODE",{});var zj=l(pn);sf=o(zj,"Dataset.filter()"),zj.forEach(s),tf=o(Ve,", que funciona de maneira semelhante a "),cn=n(Ve,"CODE",{});var Pj=l(cn);of=o(Pj,"Dataset.map()"),Pj.forEach(s),rf=o(Ve," e espera uma fun\xE7\xE3o que receba um \xFAnico exemplo do conjunto de dados. Em vez de escrever uma fun\xE7\xE3o expl\xEDcita como:"),Ve.forEach(s),Ai=p(e),v(Cs.$$.fragment,e),Ni=p(e),De=n(e,"P",{});var cr=l(De);nf=o(cr,"e ent\xE3o executando "),un=n(cr,"CODE",{});var Oj=l(un);lf=o(Oj,"drug_dataset.filter(filter_nones)"),Oj.forEach(s),df=o(cr,", podemos fazer isso em uma linha usando uma "),fn=n(cr,"EM",{});var Aj=l(fn);mf=o(Aj,"fun\xE7\xE3o lambda"),Aj.forEach(s),pf=o(cr,". Em Python, fun\xE7\xF5es lambda s\xE3o pequenas fun\xE7\xF5es que voc\xEA pode definir sem nome\xE1-las explicitamente. Eles assumem a forma geral:"),cr.forEach(s),Ii=p(e),v(ys.$$.fragment,e),Hi=p(e),Z=n(e,"P",{});var Fe=l(Z);cf=o(Fe,"onde "),vn=n(Fe,"CODE",{});var Nj=l(vn);uf=o(Nj,"lambda"),Nj.forEach(s),ff=o(Fe," \xE9 uma das [palavras-chave] especiais do Python ("),Ts=n(Fe,"A",{href:!0,rel:!0});var Ij=l(Ts);vf=o(Ij,"https://docs.python.org/3/reference/lexical_analysis.html#keywords"),Ij.forEach(s),hf=o(Fe,"), "),hn=n(Fe,"CODE",{});var Hj=l(hn);_f=o(Hj,"<arguments>"),Hj.forEach(s),gf=o(Fe," \xE9 uma lista/conjunto de valores separados por v\xEDrgula que defina as entradas para a fun\xE7\xE3o, e "),_n=n(Fe,"CODE",{});var Sj=l(_n);$f=o(Sj,"<express\xE3o>"),Sj.forEach(s),jf=o(Fe," representa as opera\xE7\xF5es que voc\xEA deseja executar. Por exemplo, podemos definir uma fun\xE7\xE3o lambda simples que eleva um n\xFAmero ao quadrado da seguinte forma:"),Fe.forEach(s),Si=p(e),v(zs.$$.fragment,e),Mi=p(e),ao=n(e,"P",{});var Mj=l(ao);Ef=o(Mj,"Para aplicar esta fun\xE7\xE3o a uma entrada, precisamos envolv\xEA-la e a entrada entre par\xEAnteses:"),Mj.forEach(s),Ri=p(e),v(Ps.$$.fragment,e),Ui=p(e),v(Os.$$.fragment,e),Vi=p(e),so=n(e,"P",{});var Rj=l(so);bf=o(Rj,"Da mesma forma, podemos definir fun\xE7\xF5es lambda com v\xE1rios argumentos, separando-os com v\xEDrgulas. Por exemplo, podemos calcular a \xE1rea de um tri\xE2ngulo da seguinte forma:"),Rj.forEach(s),Fi=p(e),v(As.$$.fragment,e),Li=p(e),v(Ns.$$.fragment,e),Bi=p(e),ke=n(e,"P",{});var ur=l(ke);xf=o(ur,"As fun\xE7\xF5es lambda s\xE3o \xFAteis quando voc\xEA deseja definir fun\xE7\xF5es pequenas e de uso \xFAnico (para obter mais informa\xE7\xF5es sobre elas, recomendamos a leitura do excelente "),Is=n(ur,"A",{href:!0,rel:!0});var Uj=l(Is);wf=o(Uj,"tutorial do Real Python"),Uj.forEach(s),qf=o(ur," de Andre Burgaud). No contexto \u{1F917} Datasets, podemos usar fun\xE7\xF5es lambda para definir opera\xE7\xF5es simples de mapa e filtro, ent\xE3o vamos usar este truque para eliminar as entradas "),gn=n(ur,"CODE",{});var Vj=l(gn);Df=o(Vj,"None"),Vj.forEach(s),kf=o(ur," em nosso conjunto de dados:"),ur.forEach(s),Ji=p(e),v(Hs.$$.fragment,e),Gi=p(e),Ce=n(e,"P",{});var fr=l(Ce);Cf=o(fr,"Com as entradas "),$n=n(fr,"CODE",{});var Fj=l($n);yf=o(Fj,"None"),Fj.forEach(s),Tf=o(fr," removidas, podemos normalizar nossa coluna "),jn=n(fr,"CODE",{});var Lj=l(jn);zf=o(Lj,"condition"),Lj.forEach(s),Pf=o(fr,":"),fr.forEach(s),Yi=p(e),v(Ss.$$.fragment,e),Qi=p(e),v(Ms.$$.fragment,e),Wi=p(e),to=n(e,"P",{});var Bj=l(to);Of=o(Bj,"Funciona! Agora que limpamos os r\xF3tulos, vamos dar uma olhada na limpeza dos pr\xF3prios coment\xE1rios."),Bj.forEach(s),Xi=p(e),Xe=n(e,"H2",{class:!0});var dc=l(Xe);xa=n(dc,"A",{id:!0,class:!0,href:!0});var Jj=l(xa);En=n(Jj,"SPAN",{});var Gj=l(En);v(Rs.$$.fragment,Gj),Gj.forEach(s),Jj.forEach(s),Af=p(dc),bn=n(dc,"SPAN",{});var Yj=l(bn);Nf=o(Yj,"Criando novas colunas"),Yj.forEach(s),dc.forEach(s),Ki=p(e),oo=n(e,"P",{});var Qj=l(oo);If=o(Qj,"Sempre que estiver lidando com avalia\xE7\xF5es de clientes, uma boa pr\xE1tica \xE9 verificar o n\xFAmero de palavras em cada avalia\xE7\xE3o. Uma avalia\xE7\xE3o pode ser apenas uma \xFAnica palavra como \u201C\xD3timo!\u201D ou um ensaio completo com milhares de palavras e, dependendo do caso de uso, voc\xEA precisar\xE1 lidar com esses extremos de maneira diferente. Para calcular o n\xFAmero de palavras em cada revis\xE3o, usaremos uma heur\xEDstica aproximada baseada na divis\xE3o de cada texto por espa\xE7os em branco."),Qj.forEach(s),Zi=p(e),ro=n(e,"P",{});var Wj=l(ro);Hf=o(Wj,"Vamos definir uma fun\xE7\xE3o simples que conta o n\xFAmero de palavras em cada revis\xE3o:"),Wj.forEach(s),em=p(e),v(Us.$$.fragment,e),am=p(e),Y=n(e,"P",{});var ve=l(Y);Sf=o(ve,"Ao contr\xE1rio de nossa fun\xE7\xE3o "),xn=n(ve,"CODE",{});var Xj=l(xn);Mf=o(Xj,"lowercase_condition()"),Xj.forEach(s),Rf=o(ve,", "),wn=n(ve,"CODE",{});var Kj=l(wn);Uf=o(Kj,"compute_review_length()"),Kj.forEach(s),Vf=o(ve," retorna um dicion\xE1rio cuja chave n\xE3o corresponde a um dos nomes de coluna no conjunto de dados. Nesse caso, quando "),qn=n(ve,"CODE",{});var Zj=l(qn);Ff=o(Zj,"compute_review_length()"),Zj.forEach(s),Lf=o(ve," for passado para "),Dn=n(ve,"CODE",{});var eE=l(Dn);Bf=o(eE,"Dataset.map()"),eE.forEach(s),Jf=o(ve,", ele ser\xE1 aplicado a todas as linhas do conjunto de dados para criar uma nova coluna "),kn=n(ve,"CODE",{});var aE=l(kn);Gf=o(aE,"review_length"),aE.forEach(s),Yf=o(ve,":"),ve.forEach(s),sm=p(e),v(Vs.$$.fragment,e),tm=p(e),v(Fs.$$.fragment,e),om=p(e),ye=n(e,"P",{});var vr=l(ye);Qf=o(vr,"Como esperado, podemos ver que uma coluna "),Cn=n(vr,"CODE",{});var sE=l(Cn);Wf=o(sE,"review_length"),sE.forEach(s),Xf=o(vr," foi adicionada ao nosso conjunto de treinamento. Podemos classificar essa nova coluna com "),yn=n(vr,"CODE",{});var tE=l(yn);Kf=o(tE,"Dataset.sort()"),tE.forEach(s),Zf=o(vr," para ver como s\xE3o os valores extremos:"),vr.forEach(s),rm=p(e),v(Ls.$$.fragment,e),nm=p(e),v(Bs.$$.fragment,e),lm=p(e),no=n(e,"P",{});var oE=l(no);ev=o(oE,"Como suspeit\xE1vamos, algumas revis\xF5es cont\xEAm apenas uma \xFAnica palavra, que, embora possa ser boa para an\xE1lise de sentimentos, n\xE3o seria informativa se quisermos prever a condi\xE7\xE3o."),oE.forEach(s),dm=p(e),v(wa.$$.fragment,e),im=p(e),qa=n(e,"P",{});var ic=l(qa);av=o(ic,"Vamos usar a fun\xE7\xE3o "),Tn=n(ic,"CODE",{});var rE=l(Tn);sv=o(rE,"Dataset.filter()"),rE.forEach(s),tv=o(ic," para remover coment\xE1rios que contenham menos de 30 palavras. Da mesma forma que fizemos com a coluna \u201Ccondi\xE7\xE3o\u201D, podemos filtrar as reviews muito curtas exigindo que as reviews tenham um comprimento acima desse limite."),ic.forEach(s),mm=p(e),v(Js.$$.fragment,e),pm=p(e),v(Gs.$$.fragment,e),cm=p(e),lo=n(e,"P",{});var nE=l(lo);ov=o(nE,"Como voc\xEA pode ver, isso removeu cerca de 15% das avalia\xE7\xF5es de nossos conjuntos de treinamento e teste originais."),nE.forEach(s),um=p(e),v(Da.$$.fragment,e),fm=p(e),ka=n(e,"P",{});var mc=l(ka);rv=o(mc,"A \xFAltima coisa com a qual precisamos lidar \xE9 a presen\xE7a de c\xF3digos de caracteres HTML em nossas an\xE1lises. Podemos usar o m\xF3dulo "),zn=n(mc,"CODE",{});var lE=l(zn);nv=o(lE,"html"),lE.forEach(s),lv=o(mc," do Python para liberar esses caracteres, assim:"),mc.forEach(s),vm=p(e),v(Ys.$$.fragment,e),hm=p(e),v(Qs.$$.fragment,e),_m=p(e),Ca=n(e,"P",{});var pc=l(Ca);dv=o(pc,"Usaremos "),Pn=n(pc,"CODE",{});var dE=l(Pn);iv=o(dE,"Dataset.map()"),dE.forEach(s),mv=o(pc," para liberar todos os caracteres HTML em nosso corpus:"),pc.forEach(s),gm=p(e),v(Ws.$$.fragment,e),$m=p(e),ya=n(e,"P",{});var cc=l(ya);pv=o(cc,"Como voc\xEA pode ver, o m\xE9todo "),On=n(cc,"CODE",{});var iE=l(On);cv=o(iE,"Dataset.map()"),iE.forEach(s),uv=o(cc," \xE9 bastante \xFAtil para o processamento de dados \u2014 e ainda nem arranhamos a superf\xEDcie de tudo o que ele pode fazer!"),cc.forEach(s),jm=p(e),Ke=n(e,"H2",{class:!0});var uc=l(Ke);Ta=n(uc,"A",{id:!0,class:!0,href:!0});var mE=l(Ta);An=n(mE,"SPAN",{});var pE=l(An);v(Xs.$$.fragment,pE),pE.forEach(s),mE.forEach(s),fv=p(uc),io=n(uc,"SPAN",{});var K$=l(io);vv=o(K$,"Os superpoderes do m\xE9todo "),Nn=n(K$,"CODE",{});var cE=l(Nn);hv=o(cE,"map()"),cE.forEach(s),K$.forEach(s),uc.forEach(s),Em=p(e),le=n(e,"P",{});var os=l(le);_v=o(os,"O m\xE9todo "),In=n(os,"CODE",{});var uE=l(In);gv=o(uE,"Dataset.map()"),uE.forEach(s),$v=o(os," recebe um argumento "),Hn=n(os,"CODE",{});var fE=l(Hn);jv=o(fE,"batched"),fE.forEach(s),Ev=o(os," que, se definido como "),Sn=n(os,"CODE",{});var vE=l(Sn);bv=o(vE,"True"),vE.forEach(s),xv=o(os,", faz com que ele envie um batch de exemplos para a fun\xE7\xE3o map de uma s\xF3 vez (o tamanho do batch \xE9 configur\xE1vel, mas o padr\xE3o \xE9 1.000). Por exemplo, a fun\xE7\xE3o map anterior que n\xE3o escapou de todo o HTML demorou um pouco para ser executada (voc\xEA pode ler o tempo gasto nas barras de progresso). Podemos acelerar isso processando v\xE1rios elementos ao mesmo tempo usando uma compreens\xE3o de lista."),os.forEach(s),bm=p(e),ee=n(e,"P",{});var Le=l(ee);wv=o(Le,"Quando voc\xEA especifica "),Mn=n(Le,"CODE",{});var hE=l(Mn);qv=o(hE,"batched=True"),hE.forEach(s),Dv=o(Le," a fun\xE7\xE3o recebe um dicion\xE1rio com os campos do conjunto de dados, mas cada valor agora \xE9 uma "),Rn=n(Le,"EM",{});var _E=l(Rn);kv=o(_E,"lista de valores"),_E.forEach(s),Cv=o(Le,", e n\xE3o apenas um valor \xFAnico. O valor de retorno de "),Un=n(Le,"CODE",{});var gE=l(Un);yv=o(gE,"Dataset.map()"),gE.forEach(s),Tv=o(Le," deve ser o mesmo: um dicion\xE1rio com os campos que queremos atualizar ou adicionar ao nosso conjunto de dados e uma lista de valores. Por exemplo, aqui est\xE1 outra maneira de fazer o scape de todos os caracteres HTML, mas usando "),Vn=n(Le,"CODE",{});var $E=l(Vn);zv=o($E,"batched=True"),$E.forEach(s),Pv=o(Le,":"),Le.forEach(s),xm=p(e),v(Ks.$$.fragment,e),wm=p(e),Te=n(e,"P",{});var hr=l(Te);Ov=o(hr,"Se voc\xEA estiver executando esse c\xF3digo em um jupyter notebook, ver\xE1 que esse comando \xE9 executado muito mais r\xE1pido que o anterior. E n\xE3o \xE9 porque nossas revis\xF5es j\xE1 foram sem escape em HTML \u2014 se voc\xEA reexecutar a instru\xE7\xE3o da se\xE7\xE3o anterior (sem "),Fn=n(hr,"CODE",{});var jE=l(Fn);Av=o(jE,"batched=True"),jE.forEach(s),Nv=o(hr,"), levar\xE1 o mesmo tempo que antes. Isso ocorre porque as compreens\xF5es de lista geralmente s\xE3o mais r\xE1pidas do que executar o mesmo c\xF3digo em um loop "),Ln=n(hr,"CODE",{});var EE=l(Ln);Iv=o(EE,"for"),EE.forEach(s),Hv=o(hr,", e tamb\xE9m ganhamos algum desempenho acessando muitos elementos ao mesmo tempo em vez de um por um."),hr.forEach(s),qm=p(e),de=n(e,"P",{});var rs=l(de);Sv=o(rs,"Usar "),Bn=n(rs,"CODE",{});var bE=l(Bn);Mv=o(bE,"Dataset.map()"),bE.forEach(s),Rv=o(rs," com "),Jn=n(rs,"CODE",{});var xE=l(Jn);Uv=o(xE,"batched=True"),xE.forEach(s),Vv=o(rs," ser\xE1 essencial para desbloquear a velocidade dos tokenizers \u201Cr\xE1pidos\u201D que encontraremos no "),mo=n(rs,"A",{href:!0});var wE=l(mo);Fv=o(wE,"Cap\xEDtulo 6"),wE.forEach(s),Lv=o(rs,", que podem rapidamente tokenizar grandes listas de textos. Por exemplo, para tokenizar todas as an\xE1lises de medicamentos com um tokenizer r\xE1pido, poder\xEDamos usar uma fun\xE7\xE3o como esta:"),rs.forEach(s),Dm=p(e),v(Zs.$$.fragment,e),km=p(e),ie=n(e,"P",{});var ns=l(ie);Bv=o(ns,"Como voc\xEA viu no "),po=n(ns,"A",{href:!0});var qE=l(po);Jv=o(qE,"Cap\xEDtulo 3"),qE.forEach(s),Gv=o(ns,", podemos passar um ou v\xE1rios exemplos para o tokenizer, ent\xE3o podemos usar esta fun\xE7\xE3o com ou sem "),Gn=n(ns,"CODE",{});var DE=l(Gn);Yv=o(DE,"batched=True"),DE.forEach(s),Qv=o(ns,". Vamos aproveitar esta oportunidade para comparar o desempenho das diferentes op\xE7\xF5es. Em um notebook, voc\xEA pode cronometrar uma instru\xE7\xE3o de uma linha adicionando "),Yn=n(ns,"CODE",{});var kE=l(Yn);Wv=o(kE,"%time"),kE.forEach(s),Xv=o(ns," antes da linha de c\xF3digo que deseja medir:"),ns.forEach(s),Cm=p(e),v(et.$$.fragment,e),ym=p(e),za=n(e,"P",{});var fc=l(za);Kv=o(fc,"Voc\xEA tamb\xE9m pode cronometrar uma c\xE9lula inteira colocando "),Qn=n(fc,"CODE",{});var CE=l(Qn);Zv=o(CE,"%%time"),CE.forEach(s),eh=o(fc," no in\xEDcio da c\xE9lula. No hardware em que executamos isso, ele mostrava 10,8s para esta instru\xE7\xE3o (\xE9 o n\xFAmero escrito depois de \u201CWall time\u201D)."),fc.forEach(s),Tm=p(e),v(Pa.$$.fragment,e),zm=p(e),co=n(e,"P",{});var yE=l(co);ah=o(yE,"Aqui est\xE3o os resultados que obtivemos com e sem batching, com um tokenizer r\xE1pido e lento:"),yE.forEach(s),Pm=p(e),Oa=n(e,"TABLE",{});var vc=l(Oa);Wn=n(vc,"THEAD",{});var TE=l(Wn);Ze=n(TE,"TR",{});var _r=l(Ze);uo=n(_r,"TH",{align:!0});var zE=l(uo);sh=o(zE,"Op\xE7\xF5es"),zE.forEach(s),th=p(_r),fo=n(_r,"TH",{align:!0});var PE=l(fo);oh=o(PE,"Tokenizador r\xE1pido"),PE.forEach(s),rh=p(_r),vo=n(_r,"TH",{align:!0});var OE=l(vo);nh=o(OE,"Tokenizador lento"),OE.forEach(s),_r.forEach(s),TE.forEach(s),lh=p(vc),at=n(vc,"TBODY",{});var hc=l(at);ea=n(hc,"TR",{});var gr=l(ea);ho=n(gr,"TD",{align:!0});var AE=l(ho);Xn=n(AE,"CODE",{});var NE=l(Xn);dh=o(NE,"batched=True"),NE.forEach(s),AE.forEach(s),ih=p(gr),_o=n(gr,"TD",{align:!0});var IE=l(_o);mh=o(IE,"10.8s"),IE.forEach(s),ph=p(gr),go=n(gr,"TD",{align:!0});var HE=l(go);ch=o(HE,"4min41s"),HE.forEach(s),gr.forEach(s),uh=p(hc),aa=n(hc,"TR",{});var $r=l(aa);$o=n($r,"TD",{align:!0});var SE=l($o);Kn=n(SE,"CODE",{});var ME=l(Kn);fh=o(ME,"batched=False"),ME.forEach(s),SE.forEach(s),vh=p($r),jo=n($r,"TD",{align:!0});var RE=l(jo);hh=o(RE,"59.2s"),RE.forEach(s),_h=p($r),Eo=n($r,"TD",{align:!0});var UE=l(Eo);gh=o(UE,"5min3s"),UE.forEach(s),$r.forEach(s),hc.forEach(s),vc.forEach(s),Om=p(e),ze=n(e,"P",{});var jr=l(ze);$h=o(jr,"Isso significa que usar um tokenizer r\xE1pido com a op\xE7\xE3o "),Zn=n(jr,"CODE",{});var VE=l(Zn);jh=o(VE,"batched=True"),VE.forEach(s),Eh=o(jr," \xE9 30 vezes mais r\xE1pido do que seu equivalente lento sem batching \u2014 isso \xE9 realmente incr\xEDvel! Essa \xE9 a principal raz\xE3o pela qual os tokenizers r\xE1pidos s\xE3o o padr\xE3o ao usar o "),el=n(jr,"CODE",{});var FE=l(el);bh=o(FE,"AutoTokenizer"),FE.forEach(s),xh=o(jr," (e porque eles s\xE3o chamados de \u201Cr\xE1pidos\u201D). Eles s\xE3o capazes de alcan\xE7ar essa acelera\xE7\xE3o porque nos bastidores o c\xF3digo de tokeniza\xE7\xE3o \xE9 executado em Rust, que \xE9 uma linguagem que facilita a execu\xE7\xE3o de c\xF3digo paralelizado."),jr.forEach(s),Am=p(e),bo=n(e,"P",{});var LE=l(bo);wh=o(LE,"A paraleliza\xE7\xE3o tamb\xE9m \xE9 a raz\xE3o para a acelera\xE7\xE3o de quase 6x que o tokenizer r\xE1pido alcan\xE7a com o batching: voc\xEA n\xE3o pode paralelizar uma \xFAnica opera\xE7\xE3o de tokeniza\xE7\xE3o, mas quando voc\xEA deseja tokenizar muitos textos ao mesmo tempo, voc\xEA pode simplesmente dividir a execu\xE7\xE3o em v\xE1rios processos, cada um respons\xE1vel por seus pr\xF3prios textos."),LE.forEach(s),Nm=p(e),ge=n(e,"P",{});var Bt=l(ge);al=n(Bt,"CODE",{});var BE=l(al);qh=o(BE,"Dataset.map()"),BE.forEach(s),Dh=o(Bt," tamb\xE9m possui alguns recursos de paraleliza\xE7\xE3o pr\xF3prios. Como eles n\xE3o s\xE3o suportados pelo Rust, eles n\xE3o permitem que um tokenizer lento alcance um r\xE1pido, mas ainda podem ser \xFAteis (especialmente se voc\xEA estiver usando um tokenizer que n\xE3o possui uma vers\xE3o r\xE1pida). Para ativar o multiprocessamento, use o argumento "),sl=n(Bt,"CODE",{});var JE=l(sl);kh=o(JE,"num_proc"),JE.forEach(s),Ch=o(Bt," e especifique o n\xFAmero de processos a serem usados \u200B\u200Bem sua chamada para "),tl=n(Bt,"CODE",{});var GE=l(tl);yh=o(GE,"Dataset.map()"),GE.forEach(s),Th=o(Bt,":"),Bt.forEach(s),Im=p(e),v(st.$$.fragment,e),Hm=p(e),xo=n(e,"P",{});var YE=l(xo);zh=o(YE,"Voc\xEA pode experimentar um pouco o tempo para determinar o n\xFAmero ideal de processos a serem usados; no nosso caso, 8 pareceu produzir o melhor ganho de velocidade. Aqui est\xE3o os n\xFAmeros que obtivemos com e sem multiprocessamento:"),YE.forEach(s),Sm=p(e),Aa=n(e,"TABLE",{});var _c=l(Aa);ol=n(_c,"THEAD",{});var QE=l(ol);sa=n(QE,"TR",{});var Er=l(sa);wo=n(Er,"TH",{align:!0});var WE=l(wo);Ph=o(WE,"Op\xE7\xF5es"),WE.forEach(s),Oh=p(Er),qo=n(Er,"TH",{align:!0});var XE=l(qo);Ah=o(XE,"Tokenizador r\xE1pido"),XE.forEach(s),Nh=p(Er),Do=n(Er,"TH",{align:!0});var KE=l(Do);Ih=o(KE,"Tokenizador lento"),KE.forEach(s),Er.forEach(s),QE.forEach(s),Hh=p(_c),$e=n(_c,"TBODY",{});var ls=l($e);ta=n(ls,"TR",{});var br=l(ta);ko=n(br,"TD",{align:!0});var ZE=l(ko);rl=n(ZE,"CODE",{});var e7=l(rl);Sh=o(e7,"batched=True"),e7.forEach(s),ZE.forEach(s),Mh=p(br),Co=n(br,"TD",{align:!0});var a7=l(Co);Rh=o(a7,"10.8s"),a7.forEach(s),Uh=p(br),yo=n(br,"TD",{align:!0});var s7=l(yo);Vh=o(s7,"4min41s"),s7.forEach(s),br.forEach(s),Fh=p(ls),oa=n(ls,"TR",{});var xr=l(oa);To=n(xr,"TD",{align:!0});var t7=l(To);nl=n(t7,"CODE",{});var o7=l(nl);Lh=o(o7,"batched=False"),o7.forEach(s),t7.forEach(s),Bh=p(xr),zo=n(xr,"TD",{align:!0});var r7=l(zo);Jh=o(r7,"59.2s"),r7.forEach(s),Gh=p(xr),Po=n(xr,"TD",{align:!0});var n7=l(Po);Yh=o(n7,"5min3s"),n7.forEach(s),xr.forEach(s),Qh=p(ls),ra=n(ls,"TR",{});var wr=l(ra);Na=n(wr,"TD",{align:!0});var gc=l(Na);ll=n(gc,"CODE",{});var l7=l(ll);Wh=o(l7,"batched=True"),l7.forEach(s),Xh=o(gc,", "),dl=n(gc,"CODE",{});var d7=l(dl);Kh=o(d7,"num_proc=8"),d7.forEach(s),gc.forEach(s),Zh=p(wr),Oo=n(wr,"TD",{align:!0});var i7=l(Oo);e_=o(i7,"6.52s"),i7.forEach(s),a_=p(wr),Ao=n(wr,"TD",{align:!0});var m7=l(Ao);s_=o(m7,"41.3s"),m7.forEach(s),wr.forEach(s),t_=p(ls),na=n(ls,"TR",{});var qr=l(na);Ia=n(qr,"TD",{align:!0});var $c=l(Ia);il=n($c,"CODE",{});var p7=l(il);o_=o(p7,"batched=False"),p7.forEach(s),r_=o($c,", "),ml=n($c,"CODE",{});var c7=l(ml);n_=o(c7,"num_proc=8"),c7.forEach(s),$c.forEach(s),l_=p(qr),No=n(qr,"TD",{align:!0});var u7=l(No);d_=o(u7,"9.49s"),u7.forEach(s),i_=p(qr),Io=n(qr,"TD",{align:!0});var f7=l(Io);m_=o(f7,"45.2s"),f7.forEach(s),qr.forEach(s),ls.forEach(s),_c.forEach(s),Mm=p(e),me=n(e,"P",{});var ds=l(me);p_=o(ds,"Esses s\xE3o resultados muito mais razo\xE1veis \u200B\u200Bpara o tokenizer lento, mas o desempenho do tokenizer r\xE1pido tamb\xE9m foi substancialmente melhorado. Observe, no entanto, que nem sempre ser\xE1 o caso \u2014 para valores de "),pl=n(ds,"CODE",{});var v7=l(pl);c_=o(v7,"num_proc"),v7.forEach(s),u_=o(ds," diferentes de 8, nossos testes mostraram que era mais r\xE1pido usar "),cl=n(ds,"CODE",{});var h7=l(cl);f_=o(h7,"batched=True"),h7.forEach(s),v_=o(ds," sem essa op\xE7\xE3o. Em geral, n\xE3o recomendamos o uso de multiprocessamento Python para tokenizers r\xE1pidos com "),ul=n(ds,"CODE",{});var _7=l(ul);h_=o(_7,"batched=True"),_7.forEach(s),__=o(ds,"."),ds.forEach(s),Rm=p(e),v(Ha.$$.fragment,e),Um=p(e),pe=n(e,"P",{});var is=l(pe);g_=o(is,"Toda essa funcionalidade condensada em um \xFAnico m\xE9todo j\xE1 \xE9 incr\xEDvel, mas tem mais! Com "),fl=n(is,"CODE",{});var g7=l(fl);$_=o(g7,"Dataset.map()"),g7.forEach(s),j_=o(is," e "),vl=n(is,"CODE",{});var $7=l(vl);E_=o($7,"batched=True"),$7.forEach(s),b_=o(is," voc\xEA pode alterar o n\xFAmero de elementos em seu conjunto de dados. Isso \xE9 super \xFAtil em muitas situa\xE7\xF5es em que voc\xEA deseja criar v\xE1rios recursos de treinamento a partir de um exemplo, e precisaremos fazer isso como parte do pr\xE9-processamento de v\xE1rias das tarefas de PNL que realizaremos no "),Ho=n(is,"A",{href:!0});var j7=l(Ho);x_=o(j7,"Cap\xEDtulo 7"),j7.forEach(s),w_=o(is,"."),is.forEach(s),Vm=p(e),v(Sa.$$.fragment,e),Fm=p(e),Pe=n(e,"P",{});var Dr=l(Pe);q_=o(Dr,"Vamos dar uma olhada em como funciona! Aqui vamos tokenizar nossos exemplos e trunc\xE1-los para um comprimento m\xE1ximo de 128, mas pediremos ao tokenizer para retornar "),hl=n(Dr,"EM",{});var E7=l(hl);D_=o(E7,"todos"),E7.forEach(s),k_=o(Dr," os peda\xE7os dos textos em vez de apenas o primeiro. Isso pode ser feito com "),_l=n(Dr,"CODE",{});var b7=l(_l);C_=o(b7,"return_overflowing_tokens=True"),b7.forEach(s),y_=o(Dr,":"),Dr.forEach(s),Lm=p(e),v(tt.$$.fragment,e),Bm=p(e),Ma=n(e,"P",{});var jc=l(Ma);T_=o(jc,"Vamos testar isso em um exemplo antes de usar "),gl=n(jc,"CODE",{});var x7=l(gl);z_=o(x7,"Dataset.map()"),x7.forEach(s),P_=o(jc," em todo o conjunto de dados:"),jc.forEach(s),Jm=p(e),v(ot.$$.fragment,e),Gm=p(e),v(rt.$$.fragment,e),Ym=p(e),So=n(e,"P",{});var w7=l(So);O_=o(w7,"Assim, nosso primeiro exemplo no conjunto de treinamento se tornou dois recursos porque foi tokenizado para mais do que o n\xFAmero m\xE1ximo de tokens que especificamos: o primeiro de comprimento 128 e o segundo de comprimento 49. Agora vamos fazer isso para todos os elementos do conjunto de dados!"),w7.forEach(s),Qm=p(e),v(nt.$$.fragment,e),Wm=p(e),v(lt.$$.fragment,e),Xm=p(e),Oe=n(e,"P",{});var kr=l(Oe);A_=o(kr,"Oh n\xE3o! Isso n\xE3o funcionou! Por que n\xE3o? Observar a mensagem de erro nos dar\xE1 uma pista: h\xE1 uma incompatibilidade nos comprimentos de uma das colunas, sendo uma de comprimento 1.463 e a outra de comprimento 1.000. Se voc\xEA consultou a [documenta\xE7\xE3o] do "),$l=n(kr,"CODE",{});var q7=l($l);N_=o(q7,"Dataset.map()"),q7.forEach(s),I_=o(kr," ("),dt=n(kr,"A",{href:!0,rel:!0});var D7=l(dt);H_=o(D7,"https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map"),D7.forEach(s),S_=o(kr,"), voc\xEA deve se lembrar de que \xE9 o n\xFAmero de amostras passadas para a fun\xE7\xE3o que estamos mapeando; aqui, esses 1.000 exemplos forneceram 1.463 novos recursos, resultando em um erro de forma."),kr.forEach(s),Km=p(e),ae=n(e,"P",{});var Be=l(ae);M_=o(Be,"O problema \xE9 que estamos tentando misturar dois conjuntos de dados diferentes de tamanhos diferentes: as colunas "),jl=n(Be,"CODE",{});var k7=l(jl);R_=o(k7,"drug_dataset"),k7.forEach(s),U_=o(Be," ter\xE3o um certo n\xFAmero de exemplos (os 1.000 em nosso erro), mas o "),El=n(Be,"CODE",{});var C7=l(El);V_=o(C7,"tokenized_dataset"),C7.forEach(s),F_=o(Be," que estamos construindo ter\xE1 mais (o 1.463 na mensagem de erro). Isso n\xE3o funciona para um "),bl=n(Be,"CODE",{});var y7=l(bl);L_=o(y7,"Dataset"),y7.forEach(s),B_=o(Be,", portanto, precisamos remover as colunas do conjunto de dados antigo ou torn\xE1-las do mesmo tamanho do novo conjunto de dados. Podemos fazer o primeiro com o argumento "),xl=n(Be,"CODE",{});var T7=l(xl);J_=o(T7,"remove_columns"),T7.forEach(s),G_=o(Be,":"),Be.forEach(s),Zm=p(e),v(it.$$.fragment,e),ep=p(e),Mo=n(e,"P",{});var z7=l(Mo);Y_=o(z7,"Agora isso funciona sem erro. Podemos verificar que nosso novo conjunto de dados tem muito mais elementos do que o conjunto de dados original comparando os comprimentos:"),z7.forEach(s),ap=p(e),v(mt.$$.fragment,e),sp=p(e),v(pt.$$.fragment,e),tp=p(e),Ae=n(e,"P",{});var Cr=l(Ae);Q_=o(Cr,"Mencionamos que tamb\xE9m podemos lidar com o problema de comprimento incompat\xEDvel tornando as colunas antigas do mesmo tamanho das novas. Para fazer isso, precisaremos do campo "),wl=n(Cr,"CODE",{});var P7=l(wl);W_=o(P7,"overflow_to_sample_mapping"),P7.forEach(s),X_=o(Cr," que o tokenizer retorna quando configuramos "),ql=n(Cr,"CODE",{});var O7=l(ql);K_=o(O7,"return_overflowing_tokens=True"),O7.forEach(s),Z_=o(Cr,". Ele nos fornece um mapeamento de um novo \xEDndice de recurso para o \xEDndice da amostra da qual ele se originou. Usando isso, podemos associar cada chave presente em nosso conjunto de dados original a uma lista de valores do tamanho certo, repetindo os valores de cada exemplo quantas vezes ele gerar novos recursos:"),Cr.forEach(s),op=p(e),v(ct.$$.fragment,e),rp=p(e),Ra=n(e,"P",{});var Ec=l(Ra);e2=o(Ec,"Podemos ver que funciona com "),Dl=n(Ec,"CODE",{});var A7=l(Dl);a2=o(A7,"Dataset.map()"),A7.forEach(s),s2=o(Ec," sem precisarmos remover as colunas antigas:"),Ec.forEach(s),np=p(e),v(ut.$$.fragment,e),lp=p(e),v(ft.$$.fragment,e),dp=p(e),Ro=n(e,"P",{});var N7=l(Ro);t2=o(N7,"Obtemos o mesmo n\xFAmero de recursos de treinamento de antes, mas aqui mantivemos todos os campos antigos. Se voc\xEA precisar deles para algum p\xF3s-processamento ap\xF3s aplicar seu modelo, conv\xE9m usar essa abordagem."),N7.forEach(s),ip=p(e),Ua=n(e,"P",{});var bc=l(Ua);o2=o(bc,"Agora voc\xEA viu como \u{1F917} Datasets podem ser usados \u200B\u200Bpara pr\xE9-processar um conjunto de dados de v\xE1rias maneiras. Embora as fun\xE7\xF5es de processamento de \u{1F917} Datasets cubram a maioria das suas necessidades de treinamento de modelo, pode haver momentos em que voc\xEA precisar\xE1 mudar para o Pandas para acessar recursos mais poderosos, como "),kl=n(bc,"CODE",{});var I7=l(kl);r2=o(I7,"DataFrame.groupby()"),I7.forEach(s),n2=o(bc," ou APIs de alto n\xEDvel para visualiza\xE7\xE3o. Felizmente, \u{1F917} Datasets foi projetado para ser interoper\xE1vel com bibliotecas como Pandas, NumPy, PyTorch, TensorFlow e JAX. Vamos dar uma olhada em como isso funciona."),bc.forEach(s),mp=p(e),la=n(e,"H2",{class:!0});var xc=l(la);Va=n(xc,"A",{id:!0,class:!0,href:!0});var H7=l(Va);Cl=n(H7,"SPAN",{});var S7=l(Cl);v(vt.$$.fragment,S7),S7.forEach(s),H7.forEach(s),l2=p(xc),da=n(xc,"SPAN",{});var yr=l(da);d2=o(yr,"De "),yl=n(yr,"CODE",{});var M7=l(yl);i2=o(M7,"Dataset"),M7.forEach(s),m2=o(yr,"s para "),Tl=n(yr,"CODE",{});var R7=l(Tl);p2=o(R7,"DataFrame"),R7.forEach(s),c2=o(yr,"s e vice-versa"),yr.forEach(s),xc.forEach(s),pp=p(e),v(ht.$$.fragment,e),cp=p(e),ce=n(e,"P",{});var ms=l(ce);u2=o(ms,"Para habilitar a convers\xE3o entre v\xE1rias bibliotecas de terceiros, \u{1F917} Datasets fornece uma fun\xE7\xE3o "),zl=n(ms,"CODE",{});var U7=l(zl);f2=o(U7,"Dataset.set_format()"),U7.forEach(s),v2=o(ms,". Essa fun\xE7\xE3o altera apenas o "),Pl=n(ms,"EM",{});var V7=l(Pl);h2=o(V7,"formato de sa\xEDda"),V7.forEach(s),_2=o(ms," do conjunto de dados, para que voc\xEA possa alternar facilmente para outro formato sem afetar o "),Ol=n(ms,"EM",{});var F7=l(Ol);g2=o(F7,"formato de dados"),F7.forEach(s),$2=o(ms," subjacente, que \xE9 o Apache Arrow. A formata\xE7\xE3o \xE9 feita no local. Para demonstrar, vamos converter nosso conjunto de dados para Pandas:"),ms.forEach(s),up=p(e),v(_t.$$.fragment,e),fp=p(e),Fa=n(e,"P",{});var wc=l(Fa);j2=o(wc,"Agora, quando acessamos os elementos do dataset, obtemos um "),Al=n(wc,"CODE",{});var L7=l(Al);E2=o(L7,"pandas.DataFrame"),L7.forEach(s),b2=o(wc," em vez de um dicion\xE1rio:"),wc.forEach(s),vp=p(e),v(gt.$$.fragment,e),hp=p(e),Ne=n(e,"TABLE",{border:!0,class:!0});var qc=l(Ne);Nl=n(qc,"THEAD",{});var B7=l(Nl);I=n(B7,"TR",{style:!0});var F=l(I);_p=n(F,"TH",{}),l(_p).forEach(s),x2=p(F),Il=n(F,"TH",{});var J7=l(Il);w2=o(J7,"patient_id"),J7.forEach(s),q2=p(F),Hl=n(F,"TH",{});var G7=l(Hl);D2=o(G7,"drugName"),G7.forEach(s),k2=p(F),Sl=n(F,"TH",{});var Y7=l(Sl);C2=o(Y7,"condition"),Y7.forEach(s),y2=p(F),Ml=n(F,"TH",{});var Q7=l(Ml);T2=o(Q7,"review"),Q7.forEach(s),z2=p(F),Rl=n(F,"TH",{});var W7=l(Rl);P2=o(W7,"rating"),W7.forEach(s),O2=p(F),Ul=n(F,"TH",{});var X7=l(Ul);A2=o(X7,"date"),X7.forEach(s),N2=p(F),Vl=n(F,"TH",{});var K7=l(Vl);I2=o(K7,"usefulCount"),K7.forEach(s),H2=p(F),Fl=n(F,"TH",{});var Z7=l(Fl);S2=o(Z7,"review_length"),Z7.forEach(s),F.forEach(s),B7.forEach(s),M2=p(qc),ia=n(qc,"TBODY",{});var Tr=l(ia);H=n(Tr,"TR",{});var L=l(H);Ll=n(L,"TH",{});var eb=l(Ll);R2=o(eb,"0"),eb.forEach(s),U2=p(L),Bl=n(L,"TD",{});var ab=l(Bl);V2=o(ab,"95260"),ab.forEach(s),F2=p(L),Jl=n(L,"TD",{});var sb=l(Jl);L2=o(sb,"Guanfacine"),sb.forEach(s),B2=p(L),Gl=n(L,"TD",{});var tb=l(Gl);J2=o(tb,"adhd"),tb.forEach(s),G2=p(L),Yl=n(L,"TD",{});var ob=l(Yl);Y2=o(ob,'"My son is halfway through his fourth week of Intuniv..."'),ob.forEach(s),Q2=p(L),Ql=n(L,"TD",{});var rb=l(Ql);W2=o(rb,"8.0"),rb.forEach(s),X2=p(L),Wl=n(L,"TD",{});var nb=l(Wl);K2=o(nb,"April 27, 2010"),nb.forEach(s),Z2=p(L),Xl=n(L,"TD",{});var lb=l(Xl);eg=o(lb,"192"),lb.forEach(s),ag=p(L),Kl=n(L,"TD",{});var db=l(Kl);sg=o(db,"141"),db.forEach(s),L.forEach(s),tg=p(Tr),S=n(Tr,"TR",{});var B=l(S);Zl=n(B,"TH",{});var ib=l(Zl);og=o(ib,"1"),ib.forEach(s),rg=p(B),ed=n(B,"TD",{});var mb=l(ed);ng=o(mb,"92703"),mb.forEach(s),lg=p(B),ad=n(B,"TD",{});var pb=l(ad);dg=o(pb,"Lybrel"),pb.forEach(s),ig=p(B),sd=n(B,"TD",{});var cb=l(sd);mg=o(cb,"birth control"),cb.forEach(s),pg=p(B),td=n(B,"TD",{});var ub=l(td);cg=o(ub,'"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects..."'),ub.forEach(s),ug=p(B),od=n(B,"TD",{});var fb=l(od);fg=o(fb,"5.0"),fb.forEach(s),vg=p(B),rd=n(B,"TD",{});var vb=l(rd);hg=o(vb,"December 14, 2009"),vb.forEach(s),_g=p(B),nd=n(B,"TD",{});var hb=l(nd);gg=o(hb,"17"),hb.forEach(s),$g=p(B),ld=n(B,"TD",{});var _b=l(ld);jg=o(_b,"134"),_b.forEach(s),B.forEach(s),Eg=p(Tr),M=n(Tr,"TR",{});var J=l(M);dd=n(J,"TH",{});var gb=l(dd);bg=o(gb,"2"),gb.forEach(s),xg=p(J),id=n(J,"TD",{});var $b=l(id);wg=o($b,"138000"),$b.forEach(s),qg=p(J),md=n(J,"TD",{});var jb=l(md);Dg=o(jb,"Ortho Evra"),jb.forEach(s),kg=p(J),pd=n(J,"TD",{});var Eb=l(pd);Cg=o(Eb,"birth control"),Eb.forEach(s),yg=p(J),cd=n(J,"TD",{});var bb=l(cd);Tg=o(bb,'"This is my first time using any form of birth control..."'),bb.forEach(s),zg=p(J),ud=n(J,"TD",{});var xb=l(ud);Pg=o(xb,"8.0"),xb.forEach(s),Og=p(J),fd=n(J,"TD",{});var wb=l(fd);Ag=o(wb,"November 3, 2015"),wb.forEach(s),Ng=p(J),vd=n(J,"TD",{});var qb=l(vd);Ig=o(qb,"10"),qb.forEach(s),Hg=p(J),hd=n(J,"TD",{});var Db=l(hd);Sg=o(Db,"89"),Db.forEach(s),J.forEach(s),Tr.forEach(s),qc.forEach(s),gp=p(e),Ie=n(e,"P",{});var zr=l(Ie);Mg=o(zr,"Vamos criar um "),_d=n(zr,"CODE",{});var kb=l(_d);Rg=o(kb,"pandas.DataFrame"),kb.forEach(s),Ug=o(zr," para todo o conjunto de treinamento selecionando todos os elementos de "),gd=n(zr,"CODE",{});var Cb=l(gd);Vg=o(Cb,'drug_dataset["train"]'),Cb.forEach(s),Fg=o(zr,":"),zr.forEach(s),$p=p(e),v($t.$$.fragment,e),jp=p(e),v(La.$$.fragment,e),Ep=p(e),Ba=n(e,"P",{});var Dc=l(Ba);Lg=o(Dc,"A partir daqui, podemos usar todas as funcionalidades do Pandas que queremos. Por exemplo, podemos fazer um encadeamento sofisticado para calcular a distribui\xE7\xE3o de classes entre as entradas "),$d=n(Dc,"CODE",{});var yb=l($d);Bg=o(yb,"condition"),yb.forEach(s),Jg=o(Dc,":"),Dc.forEach(s),bp=p(e),v(jt.$$.fragment,e),xp=p(e),He=n(e,"TABLE",{border:!0,class:!0});var kc=l(He);jd=n(kc,"THEAD",{});var Tb=l(jd);Se=n(Tb,"TR",{style:!0});var Pr=l(Se);wp=n(Pr,"TH",{}),l(wp).forEach(s),Gg=p(Pr),Ed=n(Pr,"TH",{});var zb=l(Ed);Yg=o(zb,"condition"),zb.forEach(s),Qg=p(Pr),bd=n(Pr,"TH",{});var Pb=l(bd);Wg=o(Pb,"frequency"),Pb.forEach(s),Pr.forEach(s),Tb.forEach(s),Xg=p(kc),te=n(kc,"TBODY",{});var Je=l(te);ma=n(Je,"TR",{});var Or=l(ma);xd=n(Or,"TH",{});var Ob=l(xd);Kg=o(Ob,"0"),Ob.forEach(s),Zg=p(Or),wd=n(Or,"TD",{});var Ab=l(wd);e1=o(Ab,"birth control"),Ab.forEach(s),a1=p(Or),qd=n(Or,"TD",{});var Nb=l(qd);s1=o(Nb,"27655"),Nb.forEach(s),Or.forEach(s),t1=p(Je),pa=n(Je,"TR",{});var Ar=l(pa);Dd=n(Ar,"TH",{});var Ib=l(Dd);o1=o(Ib,"1"),Ib.forEach(s),r1=p(Ar),kd=n(Ar,"TD",{});var Hb=l(kd);n1=o(Hb,"depression"),Hb.forEach(s),l1=p(Ar),Cd=n(Ar,"TD",{});var Sb=l(Cd);d1=o(Sb,"8023"),Sb.forEach(s),Ar.forEach(s),i1=p(Je),ca=n(Je,"TR",{});var Nr=l(ca);yd=n(Nr,"TH",{});var Mb=l(yd);m1=o(Mb,"2"),Mb.forEach(s),p1=p(Nr),Td=n(Nr,"TD",{});var Rb=l(Td);c1=o(Rb,"acne"),Rb.forEach(s),u1=p(Nr),zd=n(Nr,"TD",{});var Ub=l(zd);f1=o(Ub,"5209"),Ub.forEach(s),Nr.forEach(s),v1=p(Je),ua=n(Je,"TR",{});var Ir=l(ua);Pd=n(Ir,"TH",{});var Vb=l(Pd);h1=o(Vb,"3"),Vb.forEach(s),_1=p(Ir),Od=n(Ir,"TD",{});var Fb=l(Od);g1=o(Fb,"anxiety"),Fb.forEach(s),$1=p(Ir),Ad=n(Ir,"TD",{});var Lb=l(Ad);j1=o(Lb,"4991"),Lb.forEach(s),Ir.forEach(s),E1=p(Je),fa=n(Je,"TR",{});var Hr=l(fa);Nd=n(Hr,"TH",{});var Bb=l(Nd);b1=o(Bb,"4"),Bb.forEach(s),x1=p(Hr),Id=n(Hr,"TD",{});var Jb=l(Id);w1=o(Jb,"pain"),Jb.forEach(s),q1=p(Hr),Hd=n(Hr,"TD",{});var Gb=l(Hd);D1=o(Gb,"4744"),Gb.forEach(s),Hr.forEach(s),Je.forEach(s),kc.forEach(s),qp=p(e),Me=n(e,"P",{});var Sr=l(Me);k1=o(Sr,"E uma vez que terminamos nossa an\xE1lise de Pandas, sempre podemos criar um novo objeto "),Sd=n(Sr,"CODE",{});var Yb=l(Sd);C1=o(Yb,"Dataset"),Yb.forEach(s),y1=o(Sr," usando a fun\xE7\xE3o "),Md=n(Sr,"CODE",{});var Qb=l(Md);T1=o(Qb,"Dataset.from_pandas()"),Qb.forEach(s),z1=o(Sr," da seguinte forma:"),Sr.forEach(s),Dp=p(e),v(Et.$$.fragment,e),kp=p(e),v(bt.$$.fragment,e),Cp=p(e),v(Ja.$$.fragment,e),yp=p(e),ue=n(e,"P",{});var ps=l(ue);P1=o(ps,"Isso encerra nosso tour pelas v\xE1rias t\xE9cnicas de pr\xE9-processamento dispon\xEDveis em \u{1F917} Datasets. Para completar a se\xE7\xE3o, vamos criar um conjunto de valida\xE7\xE3o para preparar o conjunto de dados para treinar um classificador. Antes de fazer isso, vamos redefinir o formato de sa\xEDda de "),Rd=n(ps,"CODE",{});var Wb=l(Rd);O1=o(Wb,"drug_dataset"),Wb.forEach(s),A1=o(ps," de "),Ud=n(ps,"CODE",{});var Xb=l(Ud);N1=o(Xb,'"pandas"'),Xb.forEach(s),I1=o(ps," para "),Vd=n(ps,"CODE",{});var Kb=l(Vd);H1=o(Kb,'"arrow"'),Kb.forEach(s),S1=o(ps,":"),ps.forEach(s),Tp=p(e),v(xt.$$.fragment,e),zp=p(e),va=n(e,"H2",{class:!0});var Cc=l(va);Ga=n(Cc,"A",{id:!0,class:!0,href:!0});var Zb=l(Ga);Fd=n(Zb,"SPAN",{});var ex=l(Fd);v(wt.$$.fragment,ex),ex.forEach(s),Zb.forEach(s),M1=p(Cc),Ld=n(Cc,"SPAN",{});var ax=l(Ld);R1=o(ax,"Criando um conjunto de valida\xE7\xE3o"),ax.forEach(s),Cc.forEach(s),Pp=p(e),Uo=n(e,"P",{});var sx=l(Uo);U1=o(sx,"Embora tenhamos um conjunto de teste que poder\xEDamos usar para avalia\xE7\xE3o, \xE9 uma boa pr\xE1tica deixar o conjunto de teste intocado e criar um conjunto de valida\xE7\xE3o separado durante o desenvolvimento. Quando estiver satisfeito com o desempenho de seus modelos no conjunto de valida\xE7\xE3o, voc\xEA poder\xE1 fazer uma verifica\xE7\xE3o final de sanidade no conjunto de teste. Esse processo ajuda a mitigar o risco de voc\xEA se ajustar demais ao conjunto de teste e implantar um modelo que falha em dados do mundo real."),sx.forEach(s),Op=p(e),Q=n(e,"P",{});var he=l(Q);V1=o(he,"\u{1F917} Datasets fornece uma fun\xE7\xE3o "),Bd=n(he,"CODE",{});var tx=l(Bd);F1=o(tx,"Dataset.train_test_split()"),tx.forEach(s),L1=o(he," que \xE9 baseada na famosa funcionalidade do "),Jd=n(he,"CODE",{});var ox=l(Jd);B1=o(ox,"scikit-learn"),ox.forEach(s),J1=o(he,". Vamos us\xE1-lo para dividir nosso conjunto de treinamento em divis\xF5es "),Gd=n(he,"CODE",{});var rx=l(Gd);G1=o(rx,"train"),rx.forEach(s),Y1=o(he," e "),Yd=n(he,"CODE",{});var nx=l(Yd);Q1=o(nx,"validation"),nx.forEach(s),W1=o(he," (definimos o argumento "),Qd=n(he,"CODE",{});var lx=l(Qd);X1=o(lx,"seed"),lx.forEach(s),K1=o(he," para reprodutibilidade):"),he.forEach(s),Ap=p(e),v(qt.$$.fragment,e),Np=p(e),v(Dt.$$.fragment,e),Ip=p(e),Ya=n(e,"P",{});var yc=l(Ya);Z1=o(yc,"\xD3timo, agora preparamos um conjunto de dados pronto para treinar alguns modelos! Na "),Vo=n(yc,"A",{href:!0});var dx=l(Vo);e$=o(dx,"se\xE7\xE3o 5"),dx.forEach(s),a$=o(yc,", mostraremos como fazer upload de conjuntos de dados para o Hugging Face Hub, mas, por enquanto, vamos encerrar nossa an\xE1lise analisando algumas maneiras de salvar conjuntos de dados em sua m\xE1quina local ."),yc.forEach(s),Hp=p(e),ha=n(e,"H2",{class:!0});var Tc=l(ha);Qa=n(Tc,"A",{id:!0,class:!0,href:!0});var ix=l(Qa);Wd=n(ix,"SPAN",{});var mx=l(Wd);v(kt.$$.fragment,mx),mx.forEach(s),ix.forEach(s),s$=p(Tc),Xd=n(Tc,"SPAN",{});var px=l(Xd);t$=o(px,"Salvando um conjunto de dados"),px.forEach(s),Tc.forEach(s),Sp=p(e),v(Ct.$$.fragment,e),Mp=p(e),Fo=n(e,"P",{});var cx=l(Fo);o$=o(cx,"Embora \u{1F917} Datasets armazene em cache todos os conjuntos de dados baixados e as opera\xE7\xF5es realizadas nele, h\xE1 momentos em que voc\xEA deseja salvar um conjunto de dados em disco (por exemplo, caso o cache seja exclu\xEDdo). Conforme mostrado na tabela abaixo, \u{1F917} Datasets fornece tr\xEAs fun\xE7\xF5es principais para salvar seu conjunto de dados em diferentes formatos:"),cx.forEach(s),Rp=p(e),Wa=n(e,"TABLE",{});var zc=l(Wa);Kd=n(zc,"THEAD",{});var ux=l(Kd);yt=n(ux,"TR",{});var Pc=l(yt);Lo=n(Pc,"TH",{align:!0});var fx=l(Lo);r$=o(fx,"Formato dos dados"),fx.forEach(s),n$=p(Pc),Bo=n(Pc,"TH",{align:!0});var vx=l(Bo);l$=o(vx,"Fun\xE7\xE3o"),vx.forEach(s),Pc.forEach(s),ux.forEach(s),d$=p(zc),_a=n(zc,"TBODY",{});var Mr=l(_a);Tt=n(Mr,"TR",{});var Oc=l(Tt);Jo=n(Oc,"TD",{align:!0});var hx=l(Jo);i$=o(hx,"Arrow"),hx.forEach(s),m$=p(Oc),Go=n(Oc,"TD",{align:!0});var _x=l(Go);Zd=n(_x,"CODE",{});var gx=l(Zd);p$=o(gx,"Dataset.save_to_disk()"),gx.forEach(s),_x.forEach(s),Oc.forEach(s),c$=p(Mr),zt=n(Mr,"TR",{});var Ac=l(zt);Yo=n(Ac,"TD",{align:!0});var $x=l(Yo);u$=o($x,"CSV"),$x.forEach(s),f$=p(Ac),Qo=n(Ac,"TD",{align:!0});var jx=l(Qo);ei=n(jx,"CODE",{});var Ex=l(ei);v$=o(Ex,"Dataset.to_csv()"),Ex.forEach(s),jx.forEach(s),Ac.forEach(s),h$=p(Mr),Pt=n(Mr,"TR",{});var Nc=l(Pt);Wo=n(Nc,"TD",{align:!0});var bx=l(Wo);_$=o(bx,"JSON"),bx.forEach(s),g$=p(Nc),Xo=n(Nc,"TD",{align:!0});var xx=l(Xo);ai=n(xx,"CODE",{});var wx=l(ai);$$=o(wx,"Dataset.to_json()"),wx.forEach(s),xx.forEach(s),Nc.forEach(s),Mr.forEach(s),zc.forEach(s),Up=p(e),Ko=n(e,"P",{});var qx=l(Ko);j$=o(qx,"Por exemplo, vamos salvar nosso conjunto de dados limpo no formato Arrow:"),qx.forEach(s),Vp=p(e),v(Ot.$$.fragment,e),Fp=p(e),Zo=n(e,"P",{});var Dx=l(Zo);E$=o(Dx,"Isso criar\xE1 um diret\xF3rio com a seguinte estrutura:"),Dx.forEach(s),Lp=p(e),v(At.$$.fragment,e),Bp=p(e),fe=n(e,"P",{});var cs=l(fe);b$=o(cs,"onde podemos ver que cada divis\xE3o est\xE1 associada a sua pr\xF3pria tabela "),si=n(cs,"EM",{});var kx=l(si);x$=o(kx,"dataset.arrow"),kx.forEach(s),w$=o(cs," e alguns metadados em "),ti=n(cs,"EM",{});var Cx=l(ti);q$=o(Cx,"dataset_info.json"),Cx.forEach(s),D$=o(cs," e "),oi=n(cs,"EM",{});var yx=l(oi);k$=o(yx,"state.json"),yx.forEach(s),C$=o(cs,". Voc\xEA pode pensar no formato Arrow como uma tabela sofisticada de colunas e linhas otimizada para criar aplicativos de alto desempenho que processam e transportam grandes conjuntos de dados."),cs.forEach(s),Jp=p(e),Xa=n(e,"P",{});var Ic=l(Xa);y$=o(Ic,"Uma vez que o conjunto de dados \xE9 salvo, podemos carreg\xE1-lo usando a fun\xE7\xE3o "),ri=n(Ic,"CODE",{});var Tx=l(ri);T$=o(Tx,"load_from_disk()"),Tx.forEach(s),z$=o(Ic," da seguinte forma:"),Ic.forEach(s),Gp=p(e),v(Nt.$$.fragment,e),Yp=p(e),v(It.$$.fragment,e),Qp=p(e),Ka=n(e,"P",{});var Hc=l(Ka);P$=o(Hc,"Para os formatos CSV e JSON, temos que armazenar cada divis\xE3o como um arquivo separado. Uma maneira de fazer isso \xE9 iterando as chaves e os valores no objeto "),ni=n(Hc,"CODE",{});var zx=l(ni);O$=o(zx,"DatasetDict"),zx.forEach(s),A$=o(Hc,":"),Hc.forEach(s),Wp=p(e),v(Ht.$$.fragment,e),Xp=p(e),Za=n(e,"P",{});var Sc=l(Za);N$=o(Sc,"Isso salva cada divis\xE3o em "),St=n(Sc,"A",{href:!0,rel:!0});var Px=l(St);I$=o(Px,"formato de linhas JSON"),Px.forEach(s),H$=o(Sc,", em que cada linha no conjunto de dados \xE9 armazenada como uma \xFAnica linha de JSON. Veja como \xE9 o primeiro exemplo:"),Sc.forEach(s),Kp=p(e),v(Mt.$$.fragment,e),Zp=p(e),v(Rt.$$.fragment,e),ec=p(e),es=n(e,"P",{});var Mc=l(es);S$=o(Mc,"Podemos ent\xE3o usar as t\xE9cnicas da "),er=n(Mc,"A",{href:!0});var Ox=l(er);M$=o(Ox,"se\xE7\xE3o 2"),Ox.forEach(s),R$=o(Mc," para carregar os arquivos JSON da seguinte forma:"),Mc.forEach(s),ac=p(e),v(Ut.$$.fragment,e),sc=p(e),ar=n(e,"P",{});var Ax=l(ar);U$=o(Ax,"E \xE9 isso para nossa excurs\xE3o em dados com \u{1F917} Datasets! Agora que temos um conjunto de dados limpo para treinar um modelo, aqui est\xE3o algumas ideias que voc\xEA pode experimentar:"),Ax.forEach(s),tc=p(e),as=n(e,"OL",{});var Rc=l(as);Vt=n(Rc,"LI",{});var Uc=l(Vt);V$=o(Uc,"Use as t\xE9cnicas do "),sr=n(Uc,"A",{href:!0});var Nx=l(sr);F$=o(Nx,"Cap\xEDtulo 3"),Nx.forEach(s),L$=o(Uc," para treinar um classificador que possa prever a condi\xE7\xE3o do paciente com base na revis\xE3o do medicamento."),Uc.forEach(s),B$=p(Rc),ga=n(Rc,"LI",{});var Rr=l(ga);J$=o(Rr,"Use o pipeline "),li=n(Rr,"CODE",{});var Ix=l(li);G$=o(Ix,"summarization"),Ix.forEach(s),Y$=o(Rr," do "),tr=n(Rr,"A",{href:!0});var Hx=l(tr);Q$=o(Hx,"Cap\xEDtulo 1"),Hx.forEach(s),W$=o(Rr," para gerar resumos das revis\xF5es."),Rr.forEach(s),Rc.forEach(s),oc=p(e),or=n(e,"P",{});var Sx=l(or);X$=o(Sx,"A seguir, veremos como \u{1F917} Datasets pode permitir que voc\xEA trabalhe com grandes conjuntos de dados sem explodir seu laptop!"),Sx.forEach(s),this.h()},h(){u(c,"name","hf:doc:metadata"),u(c,"content",JSON.stringify(a0)),u(q,"id","hora-de-fatiar-e-dividir-os-dados"),u(q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(q,"href","#hora-de-fatiar-e-dividir-os-dados"),u(E,"class","relative group"),u(W,"id","slicing-and-dicing-our-data"),u(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(W,"href","#slicing-and-dicing-our-data"),u(U,"class","relative group"),u(Zt,"href","/course/chapter3"),u(vs,"href","https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29"),u(vs,"rel","nofollow"),u(hs,"href","https://archive.ics.uci.edu/ml/index.php"),u(hs,"rel","nofollow"),u(eo,"href","/course/chapter3"),u(Ts,"href","https://docs.python.org/3/reference/lexical_analysis.html#keywords"),u(Ts,"rel","nofollow"),u(Is,"href","https://realpython.com/python-lambda/"),u(Is,"rel","nofollow"),u(xa,"id","criando-novas-colunas"),u(xa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(xa,"href","#criando-novas-colunas"),u(Xe,"class","relative group"),u(Ta,"id","os-superpoderes-do-mtodo-map"),u(Ta,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(Ta,"href","#os-superpoderes-do-mtodo-map"),u(Ke,"class","relative group"),u(mo,"href","/course/chapter6"),u(po,"href","/course/chapter3"),u(uo,"align","center"),u(fo,"align","center"),u(vo,"align","center"),u(ho,"align","center"),u(_o,"align","center"),u(go,"align","center"),u($o,"align","center"),u(jo,"align","center"),u(Eo,"align","center"),u(wo,"align","center"),u(qo,"align","center"),u(Do,"align","center"),u(ko,"align","center"),u(Co,"align","center"),u(yo,"align","center"),u(To,"align","center"),u(zo,"align","center"),u(Po,"align","center"),u(Na,"align","center"),u(Oo,"align","center"),u(Ao,"align","center"),u(Ia,"align","center"),u(No,"align","center"),u(Io,"align","center"),u(Ho,"href","/course/chapter7"),u(dt,"href","https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map"),u(dt,"rel","nofollow"),u(Va,"id","de-datasets-para-dataframes-e-viceversa"),u(Va,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(Va,"href","#de-datasets-para-dataframes-e-viceversa"),u(la,"class","relative group"),Mx(I,"text-align","right"),u(Ne,"border","1"),u(Ne,"class","dataframe"),Mx(Se,"text-align","right"),u(He,"border","1"),u(He,"class","dataframe"),u(Ga,"id","criando-um-conjunto-de-validao"),u(Ga,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(Ga,"href","#criando-um-conjunto-de-validao"),u(va,"class","relative group"),u(Vo,"href","/course/chapter5/5"),u(Qa,"id","salvando-um-conjunto-de-dados"),u(Qa,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),u(Qa,"href","#salvando-um-conjunto-de-dados"),u(ha,"class","relative group"),u(Lo,"align","center"),u(Bo,"align","center"),u(Jo,"align","center"),u(Go,"align","center"),u(Yo,"align","center"),u(Qo,"align","center"),u(Wo,"align","center"),u(Xo,"align","center"),u(St,"href","https://jsonlines.org"),u(St,"rel","nofollow"),u(er,"href","/course/chapter5/2"),u(sr,"href","/course/chapter3"),u(tr,"href","/course/chapter1")},m(e,d){a(document.head,c),i(e,y,d),i(e,E,d),a(E,q),a(q,k),h(b,k,null),a(E,D),a(E,T),a(T,x),i(e,w,d),h(P,e,d),i(e,C,d),i(e,z,d),a(z,G),i(e,N,d),h(O,e,d),i(e,_e,d),i(e,U,d),a(U,W),a(W,oe),h(se,oe,null),a(U,fs),a(U,Ge),a(Ge,Ye),i(e,$a,d),i(e,V,d),a(V,Qe),a(V,A),a(A,Gt),a(V,Yt),a(V,ja),a(ja,Qt),a(V,Wt),a(V,Ea),a(Ea,Xt),a(V,Kt),a(V,Zt),a(Zt,Vc),a(V,Fc),i(e,fi,d),i(e,je,d),a(je,Lc),a(je,vs),a(vs,Bc),a(je,Jc),a(je,hs),a(hs,Gc),a(je,Yc),i(e,vi,d),i(e,Ee,d),a(Ee,Qc),a(Ee,Ur),a(Ur,Wc),a(Ee,Xc),a(Ee,Vr),a(Vr,Kc),a(Ee,Zc),i(e,hi,d),h(_s,e,d),i(e,_i,d),i(e,re,d),a(re,eu),a(re,Fr),a(Fr,au),a(re,su),a(re,Lr),a(Lr,tu),a(re,ou),a(re,Br),a(Br,ru),a(re,nu),i(e,gi,d),h(gs,e,d),i(e,$i,d),i(e,be,d),a(be,lu),a(be,Jr),a(Jr,du),a(be,iu),a(be,Gr),a(Gr,mu),a(be,pu),i(e,ji,d),h($s,e,d),i(e,Ei,d),h(js,e,d),i(e,bi,d),i(e,ne,d),a(ne,cu),a(ne,Yr),a(Yr,uu),a(ne,fu),a(ne,Qr),a(Qr,vu),a(ne,hu),a(ne,Wr),a(Wr,_u),a(ne,gu),i(e,xi,d),i(e,xe,d),a(xe,Es),a(Es,$u),a(Es,Xr),a(Xr,ju),a(Es,Eu),a(xe,bu),a(xe,bs),a(bs,xu),a(bs,Kr),a(Kr,wu),a(bs,qu),a(xe,Du),a(xe,We),a(We,ku),a(We,Zr),a(Zr,Cu),a(We,yu),a(We,en),a(en,Tu),a(We,zu),i(e,wi,d),i(e,we,d),a(we,Pu),a(we,an),a(an,Ou),a(we,Au),a(we,sn),a(sn,Nu),a(we,Iu),i(e,qi,d),h(xs,e,d),i(e,Di,d),i(e,qe,d),a(qe,Hu),a(qe,tn),a(tn,Su),a(qe,Mu),a(qe,on),a(on,Ru),a(qe,Uu),i(e,ki,d),h(ws,e,d),i(e,Ci,d),h(qs,e,d),i(e,yi,d),h(ba,e,d),i(e,Ti,d),i(e,X,d),a(X,Vu),a(X,rn),a(rn,Fu),a(X,Lu),a(X,nn),a(nn,Bu),a(X,Ju),a(X,eo),a(eo,Gu),a(X,Yu),a(X,ln),a(ln,Qu),a(X,Wu),i(e,zi,d),h(Ds,e,d),i(e,Pi,d),h(ks,e,d),i(e,Oi,d),i(e,K,d),a(K,Xu),a(K,dn),a(dn,Ku),a(K,Zu),a(K,mn),a(mn,ef),a(K,af),a(K,pn),a(pn,sf),a(K,tf),a(K,cn),a(cn,of),a(K,rf),i(e,Ai,d),h(Cs,e,d),i(e,Ni,d),i(e,De,d),a(De,nf),a(De,un),a(un,lf),a(De,df),a(De,fn),a(fn,mf),a(De,pf),i(e,Ii,d),h(ys,e,d),i(e,Hi,d),i(e,Z,d),a(Z,cf),a(Z,vn),a(vn,uf),a(Z,ff),a(Z,Ts),a(Ts,vf),a(Z,hf),a(Z,hn),a(hn,_f),a(Z,gf),a(Z,_n),a(_n,$f),a(Z,jf),i(e,Si,d),h(zs,e,d),i(e,Mi,d),i(e,ao,d),a(ao,Ef),i(e,Ri,d),h(Ps,e,d),i(e,Ui,d),h(Os,e,d),i(e,Vi,d),i(e,so,d),a(so,bf),i(e,Fi,d),h(As,e,d),i(e,Li,d),h(Ns,e,d),i(e,Bi,d),i(e,ke,d),a(ke,xf),a(ke,Is),a(Is,wf),a(ke,qf),a(ke,gn),a(gn,Df),a(ke,kf),i(e,Ji,d),h(Hs,e,d),i(e,Gi,d),i(e,Ce,d),a(Ce,Cf),a(Ce,$n),a($n,yf),a(Ce,Tf),a(Ce,jn),a(jn,zf),a(Ce,Pf),i(e,Yi,d),h(Ss,e,d),i(e,Qi,d),h(Ms,e,d),i(e,Wi,d),i(e,to,d),a(to,Of),i(e,Xi,d),i(e,Xe,d),a(Xe,xa),a(xa,En),h(Rs,En,null),a(Xe,Af),a(Xe,bn),a(bn,Nf),i(e,Ki,d),i(e,oo,d),a(oo,If),i(e,Zi,d),i(e,ro,d),a(ro,Hf),i(e,em,d),h(Us,e,d),i(e,am,d),i(e,Y,d),a(Y,Sf),a(Y,xn),a(xn,Mf),a(Y,Rf),a(Y,wn),a(wn,Uf),a(Y,Vf),a(Y,qn),a(qn,Ff),a(Y,Lf),a(Y,Dn),a(Dn,Bf),a(Y,Jf),a(Y,kn),a(kn,Gf),a(Y,Yf),i(e,sm,d),h(Vs,e,d),i(e,tm,d),h(Fs,e,d),i(e,om,d),i(e,ye,d),a(ye,Qf),a(ye,Cn),a(Cn,Wf),a(ye,Xf),a(ye,yn),a(yn,Kf),a(ye,Zf),i(e,rm,d),h(Ls,e,d),i(e,nm,d),h(Bs,e,d),i(e,lm,d),i(e,no,d),a(no,ev),i(e,dm,d),h(wa,e,d),i(e,im,d),i(e,qa,d),a(qa,av),a(qa,Tn),a(Tn,sv),a(qa,tv),i(e,mm,d),h(Js,e,d),i(e,pm,d),h(Gs,e,d),i(e,cm,d),i(e,lo,d),a(lo,ov),i(e,um,d),h(Da,e,d),i(e,fm,d),i(e,ka,d),a(ka,rv),a(ka,zn),a(zn,nv),a(ka,lv),i(e,vm,d),h(Ys,e,d),i(e,hm,d),h(Qs,e,d),i(e,_m,d),i(e,Ca,d),a(Ca,dv),a(Ca,Pn),a(Pn,iv),a(Ca,mv),i(e,gm,d),h(Ws,e,d),i(e,$m,d),i(e,ya,d),a(ya,pv),a(ya,On),a(On,cv),a(ya,uv),i(e,jm,d),i(e,Ke,d),a(Ke,Ta),a(Ta,An),h(Xs,An,null),a(Ke,fv),a(Ke,io),a(io,vv),a(io,Nn),a(Nn,hv),i(e,Em,d),i(e,le,d),a(le,_v),a(le,In),a(In,gv),a(le,$v),a(le,Hn),a(Hn,jv),a(le,Ev),a(le,Sn),a(Sn,bv),a(le,xv),i(e,bm,d),i(e,ee,d),a(ee,wv),a(ee,Mn),a(Mn,qv),a(ee,Dv),a(ee,Rn),a(Rn,kv),a(ee,Cv),a(ee,Un),a(Un,yv),a(ee,Tv),a(ee,Vn),a(Vn,zv),a(ee,Pv),i(e,xm,d),h(Ks,e,d),i(e,wm,d),i(e,Te,d),a(Te,Ov),a(Te,Fn),a(Fn,Av),a(Te,Nv),a(Te,Ln),a(Ln,Iv),a(Te,Hv),i(e,qm,d),i(e,de,d),a(de,Sv),a(de,Bn),a(Bn,Mv),a(de,Rv),a(de,Jn),a(Jn,Uv),a(de,Vv),a(de,mo),a(mo,Fv),a(de,Lv),i(e,Dm,d),h(Zs,e,d),i(e,km,d),i(e,ie,d),a(ie,Bv),a(ie,po),a(po,Jv),a(ie,Gv),a(ie,Gn),a(Gn,Yv),a(ie,Qv),a(ie,Yn),a(Yn,Wv),a(ie,Xv),i(e,Cm,d),h(et,e,d),i(e,ym,d),i(e,za,d),a(za,Kv),a(za,Qn),a(Qn,Zv),a(za,eh),i(e,Tm,d),h(Pa,e,d),i(e,zm,d),i(e,co,d),a(co,ah),i(e,Pm,d),i(e,Oa,d),a(Oa,Wn),a(Wn,Ze),a(Ze,uo),a(uo,sh),a(Ze,th),a(Ze,fo),a(fo,oh),a(Ze,rh),a(Ze,vo),a(vo,nh),a(Oa,lh),a(Oa,at),a(at,ea),a(ea,ho),a(ho,Xn),a(Xn,dh),a(ea,ih),a(ea,_o),a(_o,mh),a(ea,ph),a(ea,go),a(go,ch),a(at,uh),a(at,aa),a(aa,$o),a($o,Kn),a(Kn,fh),a(aa,vh),a(aa,jo),a(jo,hh),a(aa,_h),a(aa,Eo),a(Eo,gh),i(e,Om,d),i(e,ze,d),a(ze,$h),a(ze,Zn),a(Zn,jh),a(ze,Eh),a(ze,el),a(el,bh),a(ze,xh),i(e,Am,d),i(e,bo,d),a(bo,wh),i(e,Nm,d),i(e,ge,d),a(ge,al),a(al,qh),a(ge,Dh),a(ge,sl),a(sl,kh),a(ge,Ch),a(ge,tl),a(tl,yh),a(ge,Th),i(e,Im,d),h(st,e,d),i(e,Hm,d),i(e,xo,d),a(xo,zh),i(e,Sm,d),i(e,Aa,d),a(Aa,ol),a(ol,sa),a(sa,wo),a(wo,Ph),a(sa,Oh),a(sa,qo),a(qo,Ah),a(sa,Nh),a(sa,Do),a(Do,Ih),a(Aa,Hh),a(Aa,$e),a($e,ta),a(ta,ko),a(ko,rl),a(rl,Sh),a(ta,Mh),a(ta,Co),a(Co,Rh),a(ta,Uh),a(ta,yo),a(yo,Vh),a($e,Fh),a($e,oa),a(oa,To),a(To,nl),a(nl,Lh),a(oa,Bh),a(oa,zo),a(zo,Jh),a(oa,Gh),a(oa,Po),a(Po,Yh),a($e,Qh),a($e,ra),a(ra,Na),a(Na,ll),a(ll,Wh),a(Na,Xh),a(Na,dl),a(dl,Kh),a(ra,Zh),a(ra,Oo),a(Oo,e_),a(ra,a_),a(ra,Ao),a(Ao,s_),a($e,t_),a($e,na),a(na,Ia),a(Ia,il),a(il,o_),a(Ia,r_),a(Ia,ml),a(ml,n_),a(na,l_),a(na,No),a(No,d_),a(na,i_),a(na,Io),a(Io,m_),i(e,Mm,d),i(e,me,d),a(me,p_),a(me,pl),a(pl,c_),a(me,u_),a(me,cl),a(cl,f_),a(me,v_),a(me,ul),a(ul,h_),a(me,__),i(e,Rm,d),h(Ha,e,d),i(e,Um,d),i(e,pe,d),a(pe,g_),a(pe,fl),a(fl,$_),a(pe,j_),a(pe,vl),a(vl,E_),a(pe,b_),a(pe,Ho),a(Ho,x_),a(pe,w_),i(e,Vm,d),h(Sa,e,d),i(e,Fm,d),i(e,Pe,d),a(Pe,q_),a(Pe,hl),a(hl,D_),a(Pe,k_),a(Pe,_l),a(_l,C_),a(Pe,y_),i(e,Lm,d),h(tt,e,d),i(e,Bm,d),i(e,Ma,d),a(Ma,T_),a(Ma,gl),a(gl,z_),a(Ma,P_),i(e,Jm,d),h(ot,e,d),i(e,Gm,d),h(rt,e,d),i(e,Ym,d),i(e,So,d),a(So,O_),i(e,Qm,d),h(nt,e,d),i(e,Wm,d),h(lt,e,d),i(e,Xm,d),i(e,Oe,d),a(Oe,A_),a(Oe,$l),a($l,N_),a(Oe,I_),a(Oe,dt),a(dt,H_),a(Oe,S_),i(e,Km,d),i(e,ae,d),a(ae,M_),a(ae,jl),a(jl,R_),a(ae,U_),a(ae,El),a(El,V_),a(ae,F_),a(ae,bl),a(bl,L_),a(ae,B_),a(ae,xl),a(xl,J_),a(ae,G_),i(e,Zm,d),h(it,e,d),i(e,ep,d),i(e,Mo,d),a(Mo,Y_),i(e,ap,d),h(mt,e,d),i(e,sp,d),h(pt,e,d),i(e,tp,d),i(e,Ae,d),a(Ae,Q_),a(Ae,wl),a(wl,W_),a(Ae,X_),a(Ae,ql),a(ql,K_),a(Ae,Z_),i(e,op,d),h(ct,e,d),i(e,rp,d),i(e,Ra,d),a(Ra,e2),a(Ra,Dl),a(Dl,a2),a(Ra,s2),i(e,np,d),h(ut,e,d),i(e,lp,d),h(ft,e,d),i(e,dp,d),i(e,Ro,d),a(Ro,t2),i(e,ip,d),i(e,Ua,d),a(Ua,o2),a(Ua,kl),a(kl,r2),a(Ua,n2),i(e,mp,d),i(e,la,d),a(la,Va),a(Va,Cl),h(vt,Cl,null),a(la,l2),a(la,da),a(da,d2),a(da,yl),a(yl,i2),a(da,m2),a(da,Tl),a(Tl,p2),a(da,c2),i(e,pp,d),h(ht,e,d),i(e,cp,d),i(e,ce,d),a(ce,u2),a(ce,zl),a(zl,f2),a(ce,v2),a(ce,Pl),a(Pl,h2),a(ce,_2),a(ce,Ol),a(Ol,g2),a(ce,$2),i(e,up,d),h(_t,e,d),i(e,fp,d),i(e,Fa,d),a(Fa,j2),a(Fa,Al),a(Al,E2),a(Fa,b2),i(e,vp,d),h(gt,e,d),i(e,hp,d),i(e,Ne,d),a(Ne,Nl),a(Nl,I),a(I,_p),a(I,x2),a(I,Il),a(Il,w2),a(I,q2),a(I,Hl),a(Hl,D2),a(I,k2),a(I,Sl),a(Sl,C2),a(I,y2),a(I,Ml),a(Ml,T2),a(I,z2),a(I,Rl),a(Rl,P2),a(I,O2),a(I,Ul),a(Ul,A2),a(I,N2),a(I,Vl),a(Vl,I2),a(I,H2),a(I,Fl),a(Fl,S2),a(Ne,M2),a(Ne,ia),a(ia,H),a(H,Ll),a(Ll,R2),a(H,U2),a(H,Bl),a(Bl,V2),a(H,F2),a(H,Jl),a(Jl,L2),a(H,B2),a(H,Gl),a(Gl,J2),a(H,G2),a(H,Yl),a(Yl,Y2),a(H,Q2),a(H,Ql),a(Ql,W2),a(H,X2),a(H,Wl),a(Wl,K2),a(H,Z2),a(H,Xl),a(Xl,eg),a(H,ag),a(H,Kl),a(Kl,sg),a(ia,tg),a(ia,S),a(S,Zl),a(Zl,og),a(S,rg),a(S,ed),a(ed,ng),a(S,lg),a(S,ad),a(ad,dg),a(S,ig),a(S,sd),a(sd,mg),a(S,pg),a(S,td),a(td,cg),a(S,ug),a(S,od),a(od,fg),a(S,vg),a(S,rd),a(rd,hg),a(S,_g),a(S,nd),a(nd,gg),a(S,$g),a(S,ld),a(ld,jg),a(ia,Eg),a(ia,M),a(M,dd),a(dd,bg),a(M,xg),a(M,id),a(id,wg),a(M,qg),a(M,md),a(md,Dg),a(M,kg),a(M,pd),a(pd,Cg),a(M,yg),a(M,cd),a(cd,Tg),a(M,zg),a(M,ud),a(ud,Pg),a(M,Og),a(M,fd),a(fd,Ag),a(M,Ng),a(M,vd),a(vd,Ig),a(M,Hg),a(M,hd),a(hd,Sg),i(e,gp,d),i(e,Ie,d),a(Ie,Mg),a(Ie,_d),a(_d,Rg),a(Ie,Ug),a(Ie,gd),a(gd,Vg),a(Ie,Fg),i(e,$p,d),h($t,e,d),i(e,jp,d),h(La,e,d),i(e,Ep,d),i(e,Ba,d),a(Ba,Lg),a(Ba,$d),a($d,Bg),a(Ba,Jg),i(e,bp,d),h(jt,e,d),i(e,xp,d),i(e,He,d),a(He,jd),a(jd,Se),a(Se,wp),a(Se,Gg),a(Se,Ed),a(Ed,Yg),a(Se,Qg),a(Se,bd),a(bd,Wg),a(He,Xg),a(He,te),a(te,ma),a(ma,xd),a(xd,Kg),a(ma,Zg),a(ma,wd),a(wd,e1),a(ma,a1),a(ma,qd),a(qd,s1),a(te,t1),a(te,pa),a(pa,Dd),a(Dd,o1),a(pa,r1),a(pa,kd),a(kd,n1),a(pa,l1),a(pa,Cd),a(Cd,d1),a(te,i1),a(te,ca),a(ca,yd),a(yd,m1),a(ca,p1),a(ca,Td),a(Td,c1),a(ca,u1),a(ca,zd),a(zd,f1),a(te,v1),a(te,ua),a(ua,Pd),a(Pd,h1),a(ua,_1),a(ua,Od),a(Od,g1),a(ua,$1),a(ua,Ad),a(Ad,j1),a(te,E1),a(te,fa),a(fa,Nd),a(Nd,b1),a(fa,x1),a(fa,Id),a(Id,w1),a(fa,q1),a(fa,Hd),a(Hd,D1),i(e,qp,d),i(e,Me,d),a(Me,k1),a(Me,Sd),a(Sd,C1),a(Me,y1),a(Me,Md),a(Md,T1),a(Me,z1),i(e,Dp,d),h(Et,e,d),i(e,kp,d),h(bt,e,d),i(e,Cp,d),h(Ja,e,d),i(e,yp,d),i(e,ue,d),a(ue,P1),a(ue,Rd),a(Rd,O1),a(ue,A1),a(ue,Ud),a(Ud,N1),a(ue,I1),a(ue,Vd),a(Vd,H1),a(ue,S1),i(e,Tp,d),h(xt,e,d),i(e,zp,d),i(e,va,d),a(va,Ga),a(Ga,Fd),h(wt,Fd,null),a(va,M1),a(va,Ld),a(Ld,R1),i(e,Pp,d),i(e,Uo,d),a(Uo,U1),i(e,Op,d),i(e,Q,d),a(Q,V1),a(Q,Bd),a(Bd,F1),a(Q,L1),a(Q,Jd),a(Jd,B1),a(Q,J1),a(Q,Gd),a(Gd,G1),a(Q,Y1),a(Q,Yd),a(Yd,Q1),a(Q,W1),a(Q,Qd),a(Qd,X1),a(Q,K1),i(e,Ap,d),h(qt,e,d),i(e,Np,d),h(Dt,e,d),i(e,Ip,d),i(e,Ya,d),a(Ya,Z1),a(Ya,Vo),a(Vo,e$),a(Ya,a$),i(e,Hp,d),i(e,ha,d),a(ha,Qa),a(Qa,Wd),h(kt,Wd,null),a(ha,s$),a(ha,Xd),a(Xd,t$),i(e,Sp,d),h(Ct,e,d),i(e,Mp,d),i(e,Fo,d),a(Fo,o$),i(e,Rp,d),i(e,Wa,d),a(Wa,Kd),a(Kd,yt),a(yt,Lo),a(Lo,r$),a(yt,n$),a(yt,Bo),a(Bo,l$),a(Wa,d$),a(Wa,_a),a(_a,Tt),a(Tt,Jo),a(Jo,i$),a(Tt,m$),a(Tt,Go),a(Go,Zd),a(Zd,p$),a(_a,c$),a(_a,zt),a(zt,Yo),a(Yo,u$),a(zt,f$),a(zt,Qo),a(Qo,ei),a(ei,v$),a(_a,h$),a(_a,Pt),a(Pt,Wo),a(Wo,_$),a(Pt,g$),a(Pt,Xo),a(Xo,ai),a(ai,$$),i(e,Up,d),i(e,Ko,d),a(Ko,j$),i(e,Vp,d),h(Ot,e,d),i(e,Fp,d),i(e,Zo,d),a(Zo,E$),i(e,Lp,d),h(At,e,d),i(e,Bp,d),i(e,fe,d),a(fe,b$),a(fe,si),a(si,x$),a(fe,w$),a(fe,ti),a(ti,q$),a(fe,D$),a(fe,oi),a(oi,k$),a(fe,C$),i(e,Jp,d),i(e,Xa,d),a(Xa,y$),a(Xa,ri),a(ri,T$),a(Xa,z$),i(e,Gp,d),h(Nt,e,d),i(e,Yp,d),h(It,e,d),i(e,Qp,d),i(e,Ka,d),a(Ka,P$),a(Ka,ni),a(ni,O$),a(Ka,A$),i(e,Wp,d),h(Ht,e,d),i(e,Xp,d),i(e,Za,d),a(Za,N$),a(Za,St),a(St,I$),a(Za,H$),i(e,Kp,d),h(Mt,e,d),i(e,Zp,d),h(Rt,e,d),i(e,ec,d),i(e,es,d),a(es,S$),a(es,er),a(er,M$),a(es,R$),i(e,ac,d),h(Ut,e,d),i(e,sc,d),i(e,ar,d),a(ar,U$),i(e,tc,d),i(e,as,d),a(as,Vt),a(Vt,V$),a(Vt,sr),a(sr,F$),a(Vt,L$),a(as,B$),a(as,ga),a(ga,J$),a(ga,li),a(li,G$),a(ga,Y$),a(ga,tr),a(tr,Q$),a(ga,W$),i(e,oc,d),i(e,or,d),a(or,X$),rc=!0},p(e,[d]){const Ft={};d&2&&(Ft.$$scope={dirty:d,ctx:e}),ba.$set(Ft);const di={};d&2&&(di.$$scope={dirty:d,ctx:e}),wa.$set(di);const ii={};d&2&&(ii.$$scope={dirty:d,ctx:e}),Da.$set(ii);const mi={};d&2&&(mi.$$scope={dirty:d,ctx:e}),Pa.$set(mi);const pi={};d&2&&(pi.$$scope={dirty:d,ctx:e}),Ha.$set(pi);const Lt={};d&2&&(Lt.$$scope={dirty:d,ctx:e}),Sa.$set(Lt);const ci={};d&2&&(ci.$$scope={dirty:d,ctx:e}),La.$set(ci);const ui={};d&2&&(ui.$$scope={dirty:d,ctx:e}),Ja.$set(ui)},i(e){rc||(_(b.$$.fragment,e),_(P.$$.fragment,e),_(O.$$.fragment,e),_(se.$$.fragment,e),_(_s.$$.fragment,e),_(gs.$$.fragment,e),_($s.$$.fragment,e),_(js.$$.fragment,e),_(xs.$$.fragment,e),_(ws.$$.fragment,e),_(qs.$$.fragment,e),_(ba.$$.fragment,e),_(Ds.$$.fragment,e),_(ks.$$.fragment,e),_(Cs.$$.fragment,e),_(ys.$$.fragment,e),_(zs.$$.fragment,e),_(Ps.$$.fragment,e),_(Os.$$.fragment,e),_(As.$$.fragment,e),_(Ns.$$.fragment,e),_(Hs.$$.fragment,e),_(Ss.$$.fragment,e),_(Ms.$$.fragment,e),_(Rs.$$.fragment,e),_(Us.$$.fragment,e),_(Vs.$$.fragment,e),_(Fs.$$.fragment,e),_(Ls.$$.fragment,e),_(Bs.$$.fragment,e),_(wa.$$.fragment,e),_(Js.$$.fragment,e),_(Gs.$$.fragment,e),_(Da.$$.fragment,e),_(Ys.$$.fragment,e),_(Qs.$$.fragment,e),_(Ws.$$.fragment,e),_(Xs.$$.fragment,e),_(Ks.$$.fragment,e),_(Zs.$$.fragment,e),_(et.$$.fragment,e),_(Pa.$$.fragment,e),_(st.$$.fragment,e),_(Ha.$$.fragment,e),_(Sa.$$.fragment,e),_(tt.$$.fragment,e),_(ot.$$.fragment,e),_(rt.$$.fragment,e),_(nt.$$.fragment,e),_(lt.$$.fragment,e),_(it.$$.fragment,e),_(mt.$$.fragment,e),_(pt.$$.fragment,e),_(ct.$$.fragment,e),_(ut.$$.fragment,e),_(ft.$$.fragment,e),_(vt.$$.fragment,e),_(ht.$$.fragment,e),_(_t.$$.fragment,e),_(gt.$$.fragment,e),_($t.$$.fragment,e),_(La.$$.fragment,e),_(jt.$$.fragment,e),_(Et.$$.fragment,e),_(bt.$$.fragment,e),_(Ja.$$.fragment,e),_(xt.$$.fragment,e),_(wt.$$.fragment,e),_(qt.$$.fragment,e),_(Dt.$$.fragment,e),_(kt.$$.fragment,e),_(Ct.$$.fragment,e),_(Ot.$$.fragment,e),_(At.$$.fragment,e),_(Nt.$$.fragment,e),_(It.$$.fragment,e),_(Ht.$$.fragment,e),_(Mt.$$.fragment,e),_(Rt.$$.fragment,e),_(Ut.$$.fragment,e),rc=!0)},o(e){g(b.$$.fragment,e),g(P.$$.fragment,e),g(O.$$.fragment,e),g(se.$$.fragment,e),g(_s.$$.fragment,e),g(gs.$$.fragment,e),g($s.$$.fragment,e),g(js.$$.fragment,e),g(xs.$$.fragment,e),g(ws.$$.fragment,e),g(qs.$$.fragment,e),g(ba.$$.fragment,e),g(Ds.$$.fragment,e),g(ks.$$.fragment,e),g(Cs.$$.fragment,e),g(ys.$$.fragment,e),g(zs.$$.fragment,e),g(Ps.$$.fragment,e),g(Os.$$.fragment,e),g(As.$$.fragment,e),g(Ns.$$.fragment,e),g(Hs.$$.fragment,e),g(Ss.$$.fragment,e),g(Ms.$$.fragment,e),g(Rs.$$.fragment,e),g(Us.$$.fragment,e),g(Vs.$$.fragment,e),g(Fs.$$.fragment,e),g(Ls.$$.fragment,e),g(Bs.$$.fragment,e),g(wa.$$.fragment,e),g(Js.$$.fragment,e),g(Gs.$$.fragment,e),g(Da.$$.fragment,e),g(Ys.$$.fragment,e),g(Qs.$$.fragment,e),g(Ws.$$.fragment,e),g(Xs.$$.fragment,e),g(Ks.$$.fragment,e),g(Zs.$$.fragment,e),g(et.$$.fragment,e),g(Pa.$$.fragment,e),g(st.$$.fragment,e),g(Ha.$$.fragment,e),g(Sa.$$.fragment,e),g(tt.$$.fragment,e),g(ot.$$.fragment,e),g(rt.$$.fragment,e),g(nt.$$.fragment,e),g(lt.$$.fragment,e),g(it.$$.fragment,e),g(mt.$$.fragment,e),g(pt.$$.fragment,e),g(ct.$$.fragment,e),g(ut.$$.fragment,e),g(ft.$$.fragment,e),g(vt.$$.fragment,e),g(ht.$$.fragment,e),g(_t.$$.fragment,e),g(gt.$$.fragment,e),g($t.$$.fragment,e),g(La.$$.fragment,e),g(jt.$$.fragment,e),g(Et.$$.fragment,e),g(bt.$$.fragment,e),g(Ja.$$.fragment,e),g(xt.$$.fragment,e),g(wt.$$.fragment,e),g(qt.$$.fragment,e),g(Dt.$$.fragment,e),g(kt.$$.fragment,e),g(Ct.$$.fragment,e),g(Ot.$$.fragment,e),g(At.$$.fragment,e),g(Nt.$$.fragment,e),g(It.$$.fragment,e),g(Ht.$$.fragment,e),g(Mt.$$.fragment,e),g(Rt.$$.fragment,e),g(Ut.$$.fragment,e),rc=!1},d(e){s(c),e&&s(y),e&&s(E),$(b),e&&s(w),$(P,e),e&&s(C),e&&s(z),e&&s(N),$(O,e),e&&s(_e),e&&s(U),$(se),e&&s($a),e&&s(V),e&&s(fi),e&&s(je),e&&s(vi),e&&s(Ee),e&&s(hi),$(_s,e),e&&s(_i),e&&s(re),e&&s(gi),$(gs,e),e&&s($i),e&&s(be),e&&s(ji),$($s,e),e&&s(Ei),$(js,e),e&&s(bi),e&&s(ne),e&&s(xi),e&&s(xe),e&&s(wi),e&&s(we),e&&s(qi),$(xs,e),e&&s(Di),e&&s(qe),e&&s(ki),$(ws,e),e&&s(Ci),$(qs,e),e&&s(yi),$(ba,e),e&&s(Ti),e&&s(X),e&&s(zi),$(Ds,e),e&&s(Pi),$(ks,e),e&&s(Oi),e&&s(K),e&&s(Ai),$(Cs,e),e&&s(Ni),e&&s(De),e&&s(Ii),$(ys,e),e&&s(Hi),e&&s(Z),e&&s(Si),$(zs,e),e&&s(Mi),e&&s(ao),e&&s(Ri),$(Ps,e),e&&s(Ui),$(Os,e),e&&s(Vi),e&&s(so),e&&s(Fi),$(As,e),e&&s(Li),$(Ns,e),e&&s(Bi),e&&s(ke),e&&s(Ji),$(Hs,e),e&&s(Gi),e&&s(Ce),e&&s(Yi),$(Ss,e),e&&s(Qi),$(Ms,e),e&&s(Wi),e&&s(to),e&&s(Xi),e&&s(Xe),$(Rs),e&&s(Ki),e&&s(oo),e&&s(Zi),e&&s(ro),e&&s(em),$(Us,e),e&&s(am),e&&s(Y),e&&s(sm),$(Vs,e),e&&s(tm),$(Fs,e),e&&s(om),e&&s(ye),e&&s(rm),$(Ls,e),e&&s(nm),$(Bs,e),e&&s(lm),e&&s(no),e&&s(dm),$(wa,e),e&&s(im),e&&s(qa),e&&s(mm),$(Js,e),e&&s(pm),$(Gs,e),e&&s(cm),e&&s(lo),e&&s(um),$(Da,e),e&&s(fm),e&&s(ka),e&&s(vm),$(Ys,e),e&&s(hm),$(Qs,e),e&&s(_m),e&&s(Ca),e&&s(gm),$(Ws,e),e&&s($m),e&&s(ya),e&&s(jm),e&&s(Ke),$(Xs),e&&s(Em),e&&s(le),e&&s(bm),e&&s(ee),e&&s(xm),$(Ks,e),e&&s(wm),e&&s(Te),e&&s(qm),e&&s(de),e&&s(Dm),$(Zs,e),e&&s(km),e&&s(ie),e&&s(Cm),$(et,e),e&&s(ym),e&&s(za),e&&s(Tm),$(Pa,e),e&&s(zm),e&&s(co),e&&s(Pm),e&&s(Oa),e&&s(Om),e&&s(ze),e&&s(Am),e&&s(bo),e&&s(Nm),e&&s(ge),e&&s(Im),$(st,e),e&&s(Hm),e&&s(xo),e&&s(Sm),e&&s(Aa),e&&s(Mm),e&&s(me),e&&s(Rm),$(Ha,e),e&&s(Um),e&&s(pe),e&&s(Vm),$(Sa,e),e&&s(Fm),e&&s(Pe),e&&s(Lm),$(tt,e),e&&s(Bm),e&&s(Ma),e&&s(Jm),$(ot,e),e&&s(Gm),$(rt,e),e&&s(Ym),e&&s(So),e&&s(Qm),$(nt,e),e&&s(Wm),$(lt,e),e&&s(Xm),e&&s(Oe),e&&s(Km),e&&s(ae),e&&s(Zm),$(it,e),e&&s(ep),e&&s(Mo),e&&s(ap),$(mt,e),e&&s(sp),$(pt,e),e&&s(tp),e&&s(Ae),e&&s(op),$(ct,e),e&&s(rp),e&&s(Ra),e&&s(np),$(ut,e),e&&s(lp),$(ft,e),e&&s(dp),e&&s(Ro),e&&s(ip),e&&s(Ua),e&&s(mp),e&&s(la),$(vt),e&&s(pp),$(ht,e),e&&s(cp),e&&s(ce),e&&s(up),$(_t,e),e&&s(fp),e&&s(Fa),e&&s(vp),$(gt,e),e&&s(hp),e&&s(Ne),e&&s(gp),e&&s(Ie),e&&s($p),$($t,e),e&&s(jp),$(La,e),e&&s(Ep),e&&s(Ba),e&&s(bp),$(jt,e),e&&s(xp),e&&s(He),e&&s(qp),e&&s(Me),e&&s(Dp),$(Et,e),e&&s(kp),$(bt,e),e&&s(Cp),$(Ja,e),e&&s(yp),e&&s(ue),e&&s(Tp),$(xt,e),e&&s(zp),e&&s(va),$(wt),e&&s(Pp),e&&s(Uo),e&&s(Op),e&&s(Q),e&&s(Ap),$(qt,e),e&&s(Np),$(Dt,e),e&&s(Ip),e&&s(Ya),e&&s(Hp),e&&s(ha),$(kt),e&&s(Sp),$(Ct,e),e&&s(Mp),e&&s(Fo),e&&s(Rp),e&&s(Wa),e&&s(Up),e&&s(Ko),e&&s(Vp),$(Ot,e),e&&s(Fp),e&&s(Zo),e&&s(Lp),$(At,e),e&&s(Bp),e&&s(fe),e&&s(Jp),e&&s(Xa),e&&s(Gp),$(Nt,e),e&&s(Yp),$(It,e),e&&s(Qp),e&&s(Ka),e&&s(Wp),$(Ht,e),e&&s(Xp),e&&s(Za),e&&s(Kp),$(Mt,e),e&&s(Zp),$(Rt,e),e&&s(ec),e&&s(es),e&&s(ac),$(Ut,e),e&&s(sc),e&&s(ar),e&&s(tc),e&&s(as),e&&s(oc),e&&s(or)}}}const a0={local:"hora-de-fatiar-e-dividir-os-dados",sections:[{local:"slicing-and-dicing-our-data",title:"Slicing and dicing our data"},{local:"criando-novas-colunas",title:"Criando novas colunas"},{local:"os-superpoderes-do-mtodo-map",title:"Os superpoderes do m\xE9todo `map()`"},{local:"de-datasets-para-dataframes-e-viceversa",title:"De `Dataset`s para `DataFrame`s e vice-versa"},{local:"criando-um-conjunto-de-validao",title:"Criando um conjunto de valida\xE7\xE3o"},{local:"salvando-um-conjunto-de-dados",title:"Salvando um conjunto de dados"}],title:"Hora de fatiar e dividir os dados"};function s0(R){return Lx(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class i0 extends Rx{constructor(c){super();Ux(this,c,s0,e0,Vx,{})}}export{i0 as default,a0 as metadata};
