import{S as Kg,i as Qg,s as Yg,e as r,t as a,k as m,w as b,c as l,a as o,h as n,d as t,m as c,x as q,b as h,g as i,G as s,y as j,q as v,o as g,B as $,U as Ug,M as Xg,V as Hg,N as qo,p as jo,v as Zg,n as $o}from"../../chunks/vendor-hf-doc-builder.js";import{T as An}from"../../chunks/Tip-hf-doc-builder.js";import{Y as Nf}from"../../chunks/Youtube-hf-doc-builder.js";import{I as mt}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as T}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as Bg}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{F as e_}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function s_(Z){let d,x;return d=new Bg({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter7/section5_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter7/section5_tf.ipynb"}]}}),{c(){b(d.$$.fragment)},l(f){q(d.$$.fragment,f)},m(f,w){j(d,f,w),x=!0},i(f){x||(v(d.$$.fragment,f),x=!0)},o(f){g(d.$$.fragment,f),x=!1},d(f){$(d,f)}}}function t_(Z){let d,x;return d=new Bg({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter7/section5_pt.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter7/section5_pt.ipynb"}]}}),{c(){b(d.$$.fragment)},l(f){q(d.$$.fragment,f)},m(f,w){j(d,f,w),x=!0},i(f){x||(v(d.$$.fragment,f),x=!0)},o(f){g(d.$$.fragment,f),x=!1},d(f){$(d,f)}}}function a_(Z){let d,x,f,w,P,y,S,D,E,M,N;return{c(){d=r("p"),x=a("\u270F\uFE0F "),f=r("strong"),w=a("Essayez !"),P=a(" Changez la graine al\xE9atoire dans la commande "),y=r("code"),S=a("Dataset.shuffle()"),D=a(" pour explorer d\u2019autres critiques dans le corpus. Si vous parlez espagnol, jetez un coup d\u2019\u0153il  \xE0 certaines des critiques dans "),E=r("code"),M=a("spanish_dataset"),N=a(" pour voir si les titres semblent aussi \xEAtre des r\xE9sum\xE9s raisonnables.")},l(A){d=l(A,"P",{});var C=o(d);x=n(C,"\u270F\uFE0F "),f=l(C,"STRONG",{});var G=o(f);w=n(G,"Essayez !"),G.forEach(t),P=n(C," Changez la graine al\xE9atoire dans la commande "),y=l(C,"CODE",{});var L=o(y);S=n(L,"Dataset.shuffle()"),L.forEach(t),D=n(C," pour explorer d\u2019autres critiques dans le corpus. Si vous parlez espagnol, jetez un coup d\u2019\u0153il  \xE0 certaines des critiques dans "),E=l(C,"CODE",{});var V=o(E);M=n(V,"spanish_dataset"),V.forEach(t),N=n(C," pour voir si les titres semblent aussi \xEAtre des r\xE9sum\xE9s raisonnables."),C.forEach(t)},m(A,C){i(A,d,C),s(d,x),s(d,f),s(f,w),s(d,P),s(d,y),s(y,S),s(d,D),s(d,E),s(E,M),s(d,N)},d(A){A&&t(d)}}}function n_(Z){let d,x,f,w,P,y,S,D,E,M,N;return{c(){d=r("p"),x=a("\u270F\uFE0F "),f=r("strong"),w=a("Essayez"),P=a(" Une fois que vous avez travaill\xE9 sur cette section, voyez comment mT5 se compare \xE0 mBART en affinant ce dernier avec les m\xEAmes techniques. Pour des points bonus, vous pouvez aussi essayer de "),y=r("em"),S=a("finetuner"),D=a(" le T5 uniquement sur les critiques anglaises. Puisque le T5 a un pr\xE9fixe sp\xE9cial, vous devrez ajouter "),E=r("code"),M=a("summarize:"),N=a(" aux exemples d\u2019entr\xE9e dans les \xE9tapes de pr\xE9traitement ci-dessous.")},l(A){d=l(A,"P",{});var C=o(d);x=n(C,"\u270F\uFE0F "),f=l(C,"STRONG",{});var G=o(f);w=n(G,"Essayez"),G.forEach(t),P=n(C," Une fois que vous avez travaill\xE9 sur cette section, voyez comment mT5 se compare \xE0 mBART en affinant ce dernier avec les m\xEAmes techniques. Pour des points bonus, vous pouvez aussi essayer de "),y=l(C,"EM",{});var L=o(y);S=n(L,"finetuner"),L.forEach(t),D=n(C," le T5 uniquement sur les critiques anglaises. Puisque le T5 a un pr\xE9fixe sp\xE9cial, vous devrez ajouter "),E=l(C,"CODE",{});var V=o(E);M=n(V,"summarize:"),V.forEach(t),N=n(C," aux exemples d\u2019entr\xE9e dans les \xE9tapes de pr\xE9traitement ci-dessous."),C.forEach(t)},m(A,C){i(A,d,C),s(d,x),s(d,f),s(f,w),s(d,P),s(d,y),s(y,S),s(d,D),s(d,E),s(E,M),s(d,N)},d(A){A&&t(d)}}}function r_(Z){let d,x;return{c(){d=r("p"),x=a("\u{1F4A1} Aux premiers stades de vos projets de NLP, une bonne pratique consiste \xE0 entra\xEEner une classe de \u201Cpetits\u201D mod\xE8les sur un petit \xE9chantillon de donn\xE9es. Cela vous permet de d\xE9boguer et d\u2019it\xE9rer plus rapidement vers un flux de travail de bout en bout. Une fois que vous avez confiance dans les r\xE9sultats, vous pouvez toujours faire \xE9voluer le mod\xE8le en changeant simplement le point de contr\xF4le du mod\xE8le !")},l(f){d=l(f,"P",{});var w=o(d);x=n(w,"\u{1F4A1} Aux premiers stades de vos projets de NLP, une bonne pratique consiste \xE0 entra\xEEner une classe de \u201Cpetits\u201D mod\xE8les sur un petit \xE9chantillon de donn\xE9es. Cela vous permet de d\xE9boguer et d\u2019it\xE9rer plus rapidement vers un flux de travail de bout en bout. Une fois que vous avez confiance dans les r\xE9sultats, vous pouvez toujours faire \xE9voluer le mod\xE8le en changeant simplement le point de contr\xF4le du mod\xE8le !"),w.forEach(t)},m(f,w){i(f,d,w),s(d,x)},d(f){f&&t(d)}}}function l_(Z){let d,x,f,w,P,y,S,D,E,M,N,A,C,G,L,V,W;return{c(){d=r("p"),x=a("\u{1F4A1} Vous avez peut-\xEAtre remarqu\xE9 que nous avons utilis\xE9 "),f=r("code"),w=a("batched=True"),P=a(" dans notre fonction "),y=r("code"),S=a("Dataset.map()"),D=a(" ci-dessus. Cela permet de coder les exemples par lots de 1 000 (par d\xE9faut) et d\u2019utiliser les capacit\xE9s de multithreading des "),E=r("em"),M=a("tokenizers"),N=a(" rapides de \u{1F917} "),A=r("em"),C=a("Transformers"),G=a(". Lorsque cela est possible, essayez d\u2019utiliser "),L=r("code"),V=a("batched=True"),W=a(" pour tirer le meilleur parti de votre pr\xE9traitement !")},l(ee){d=l(ee,"P",{});var J=o(d);x=n(J,"\u{1F4A1} Vous avez peut-\xEAtre remarqu\xE9 que nous avons utilis\xE9 "),f=l(J,"CODE",{});var B=o(f);w=n(B,"batched=True"),B.forEach(t),P=n(J," dans notre fonction "),y=l(J,"CODE",{});var Y=o(y);S=n(Y,"Dataset.map()"),Y.forEach(t),D=n(J," ci-dessus. Cela permet de coder les exemples par lots de 1 000 (par d\xE9faut) et d\u2019utiliser les capacit\xE9s de multithreading des "),E=l(J,"EM",{});var le=o(E);M=n(le,"tokenizers"),le.forEach(t),N=n(J," rapides de \u{1F917} "),A=l(J,"EM",{});var O=o(A);C=n(O,"Transformers"),O.forEach(t),G=n(J,". Lorsque cela est possible, essayez d\u2019utiliser "),L=l(J,"CODE",{});var Q=o(L);V=n(Q,"batched=True"),Q.forEach(t),W=n(J," pour tirer le meilleur parti de votre pr\xE9traitement !"),J.forEach(t)},m(ee,J){i(ee,d,J),s(d,x),s(d,f),s(f,w),s(d,P),s(d,y),s(y,S),s(d,D),s(d,E),s(E,M),s(d,N),s(d,A),s(A,C),s(d,G),s(d,L),s(L,V),s(d,W)},d(ee){ee&&t(d)}}}function o_(Z){let d,x,f,w,P,y,S;return{c(){d=r("p"),x=a("\u{1F64B} Ne vous inqui\xE9tez pas si c\u2019est la premi\xE8re fois que vous entendez parler de pr\xE9cision et de rappel - nous allons parcourir ensemble quelques exemples explicites pour que tout soit clair. Ces m\xE9triques sont g\xE9n\xE9ralement rencontr\xE9es dans les t\xE2ches de classification, donc si vous voulez comprendre comment la pr\xE9cision et le rappel sont d\xE9finis dans ce contexte, nous vous recommandons de consulter les "),f=r("a"),w=a("guides de  "),P=r("code"),y=a("scikit-learn"),S=a("."),this.h()},l(D){d=l(D,"P",{});var E=o(d);x=n(E,"\u{1F64B} Ne vous inqui\xE9tez pas si c\u2019est la premi\xE8re fois que vous entendez parler de pr\xE9cision et de rappel - nous allons parcourir ensemble quelques exemples explicites pour que tout soit clair. Ces m\xE9triques sont g\xE9n\xE9ralement rencontr\xE9es dans les t\xE2ches de classification, donc si vous voulez comprendre comment la pr\xE9cision et le rappel sont d\xE9finis dans ce contexte, nous vous recommandons de consulter les "),f=l(E,"A",{href:!0,rel:!0});var M=o(f);w=n(M,"guides de  "),P=l(M,"CODE",{});var N=o(P);y=n(N,"scikit-learn"),N.forEach(t),M.forEach(t),S=n(E,"."),E.forEach(t),this.h()},h(){h(f,"href","https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html"),h(f,"rel","nofollow")},m(D,E){i(D,d,E),s(d,x),s(d,f),s(f,w),s(f,P),s(P,y),s(d,S)},d(D){D&&t(d)}}}function i_(Z){let d,x,f,w,P,y,S,D;return{c(){d=r("p"),x=a("\u270F\uFE0F "),f=r("strong"),w=a("Essayez"),P=a(" Cr\xE9ez votre propre exemple de r\xE9sum\xE9 g\xE9n\xE9r\xE9 et de r\xE9f\xE9rence et voyez si les scores ROUGE obtenus correspondent \xE0 un calcul manuel bas\xE9 sur les formules de pr\xE9cision et de rappel. Pour des points bonus, divisez le texte en bigrammes et comparez la pr\xE9cision et le rappel pour la m\xE9trique "),y=r("code"),S=a("rouge2"),D=a(".")},l(E){d=l(E,"P",{});var M=o(d);x=n(M,"\u270F\uFE0F "),f=l(M,"STRONG",{});var N=o(f);w=n(N,"Essayez"),N.forEach(t),P=n(M," Cr\xE9ez votre propre exemple de r\xE9sum\xE9 g\xE9n\xE9r\xE9 et de r\xE9f\xE9rence et voyez si les scores ROUGE obtenus correspondent \xE0 un calcul manuel bas\xE9 sur les formules de pr\xE9cision et de rappel. Pour des points bonus, divisez le texte en bigrammes et comparez la pr\xE9cision et le rappel pour la m\xE9trique "),y=l(M,"CODE",{});var A=o(y);S=n(A,"rouge2"),A.forEach(t),D=n(M,"."),M.forEach(t)},m(E,M){i(E,d,M),s(d,x),s(d,f),s(f,w),s(d,P),s(d,y),s(y,S),s(d,D)},d(E){E&&t(d)}}}function u_(Z){let d,x,f,w,P,y,S,D,E,M,N,A,C,G,L,V,W,ee,J,B,Y,le;return w=new mt({}),Y=new T({props:{code:`from transformers import TFAutoModelForSeq2SeqLM

model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSeq2SeqLM

model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)`}}),{c(){d=r("h2"),x=r("a"),f=r("span"),b(w.$$.fragment),P=m(),y=r("span"),S=a("*Finetuning* de mT5 avec  Keras"),D=m(),E=r("p"),M=a("Le "),N=r("em"),A=a("finetuning"),C=a(" d\u2019un mod\xE8le pour le r\xE9sum\xE9 est tr\xE8s similaire aux autres t\xE2ches que nous avons couvertes dans ce chapitre. La premi\xE8re chose \xE0 faire est de charger le mod\xE8le pr\xE9-entra\xEEn\xE9 \xE0 partir du point de contr\xF4le "),G=r("code"),L=a("mt5-small"),V=a(". Puisque la compression est une t\xE2che de s\xE9quence \xE0 s\xE9quence, nous pouvons charger le mod\xE8le avec la classe "),W=r("code"),ee=a("AutoModelForSeq2SeqLM"),J=a(", qui t\xE9l\xE9chargera automatiquement et mettra en cache les poids :"),B=m(),b(Y.$$.fragment),this.h()},l(O){d=l(O,"H2",{class:!0});var Q=o(d);x=l(Q,"A",{id:!0,class:!0,href:!0});var oe=o(x);f=l(oe,"SPAN",{});var H=o(f);q(w.$$.fragment,H),H.forEach(t),oe.forEach(t),P=c(Q),y=l(Q,"SPAN",{});var U=o(y);S=n(U,"*Finetuning* de mT5 avec  Keras"),U.forEach(t),Q.forEach(t),D=c(O),E=l(O,"P",{});var te=o(E);M=n(te,"Le "),N=l(te,"EM",{});var se=o(N);A=n(se,"finetuning"),se.forEach(t),C=n(te," d\u2019un mod\xE8le pour le r\xE9sum\xE9 est tr\xE8s similaire aux autres t\xE2ches que nous avons couvertes dans ce chapitre. La premi\xE8re chose \xE0 faire est de charger le mod\xE8le pr\xE9-entra\xEEn\xE9 \xE0 partir du point de contr\xF4le "),G=l(te,"CODE",{});var ie=o(G);L=n(ie,"mt5-small"),ie.forEach(t),V=n(te,". Puisque la compression est une t\xE2che de s\xE9quence \xE0 s\xE9quence, nous pouvons charger le mod\xE8le avec la classe "),W=l(te,"CODE",{});var X=o(W);ee=n(X,"AutoModelForSeq2SeqLM"),X.forEach(t),J=n(te,", qui t\xE9l\xE9chargera automatiquement et mettra en cache les poids :"),te.forEach(t),B=c(O),q(Y.$$.fragment,O),this.h()},h(){h(x,"id","finetuning-de-mt5-avec-keras"),h(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(x,"href","#finetuning-de-mt5-avec-keras"),h(d,"class","relative group")},m(O,Q){i(O,d,Q),s(d,x),s(x,f),j(w,f,null),s(d,P),s(d,y),s(y,S),i(O,D,Q),i(O,E,Q),s(E,M),s(E,N),s(N,A),s(E,C),s(E,G),s(G,L),s(E,V),s(E,W),s(W,ee),s(E,J),i(O,B,Q),j(Y,O,Q),le=!0},i(O){le||(v(w.$$.fragment,O),v(Y.$$.fragment,O),le=!0)},o(O){g(w.$$.fragment,O),g(Y.$$.fragment,O),le=!1},d(O){O&&t(d),$(w),O&&t(D),O&&t(E),O&&t(B),$(Y,O)}}}function p_(Z){let d,x,f,w,P,y,S,D,E,M,N,A,C,G,L,V,W,ee,J,B,Y,le,O,Q,oe;return w=new mt({}),Q=new T({props:{code:`from transformers import AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSeq2SeqLM

model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)`}}),{c(){d=r("h2"),x=r("a"),f=r("span"),b(w.$$.fragment),P=m(),y=r("span"),S=a("*Finetuning* de mT5 avec l'API "),D=r("code"),E=a("Trainer"),M=a("."),N=m(),A=r("p"),C=a("Le "),G=r("em"),L=a("finetuning"),V=a(" d\u2019un mod\xE8le pour le r\xE9sum\xE9 est tr\xE8s similaire aux autres t\xE2ches que nous avons couvertes dans ce chapitre. La premi\xE8re chose \xE0 faire est de charger le mod\xE8le pr\xE9-entra\xEEn\xE9 depuis le checkpoint "),W=r("code"),ee=a("mt5-small"),J=a(". Puisque la compression est une t\xE2che de s\xE9quence \xE0 s\xE9quence, nous pouvons charger le mod\xE8le avec la classe "),B=r("code"),Y=a("AutoModelForSeq2SeqLM"),le=a(", qui t\xE9l\xE9chargera automatiquement et mettra en cache les poids :"),O=m(),b(Q.$$.fragment),this.h()},l(H){d=l(H,"H2",{class:!0});var U=o(d);x=l(U,"A",{id:!0,class:!0,href:!0});var te=o(x);f=l(te,"SPAN",{});var se=o(f);q(w.$$.fragment,se),se.forEach(t),te.forEach(t),P=c(U),y=l(U,"SPAN",{});var ie=o(y);S=n(ie,"*Finetuning* de mT5 avec l'API "),D=l(ie,"CODE",{});var X=o(D);E=n(X,"Trainer"),X.forEach(t),M=n(ie,"."),ie.forEach(t),U.forEach(t),N=c(H),A=l(H,"P",{});var ae=o(A);C=n(ae,"Le "),G=l(ae,"EM",{});var _e=o(G);L=n(_e,"finetuning"),_e.forEach(t),V=n(ae," d\u2019un mod\xE8le pour le r\xE9sum\xE9 est tr\xE8s similaire aux autres t\xE2ches que nous avons couvertes dans ce chapitre. La premi\xE8re chose \xE0 faire est de charger le mod\xE8le pr\xE9-entra\xEEn\xE9 depuis le checkpoint "),W=l(ae,"CODE",{});var ce=o(W);ee=n(ce,"mt5-small"),ce.forEach(t),J=n(ae,". Puisque la compression est une t\xE2che de s\xE9quence \xE0 s\xE9quence, nous pouvons charger le mod\xE8le avec la classe "),B=l(ae,"CODE",{});var ne=o(B);Y=n(ne,"AutoModelForSeq2SeqLM"),ne.forEach(t),le=n(ae,", qui t\xE9l\xE9chargera automatiquement et mettra en cache les poids :"),ae.forEach(t),O=c(H),q(Q.$$.fragment,H),this.h()},h(){h(x,"id","finetuning-de-mt5-avec-lapi-trainer"),h(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(x,"href","#finetuning-de-mt5-avec-lapi-trainer"),h(d,"class","relative group")},m(H,U){i(H,d,U),s(d,x),s(x,f),j(w,f,null),s(d,P),s(d,y),s(y,S),s(y,D),s(D,E),s(y,M),i(H,N,U),i(H,A,U),s(A,C),s(A,G),s(G,L),s(A,V),s(A,W),s(W,ee),s(A,J),s(A,B),s(B,Y),s(A,le),i(H,O,U),j(Q,H,U),oe=!0},i(H){oe||(v(w.$$.fragment,H),v(Q.$$.fragment,H),oe=!0)},o(H){g(w.$$.fragment,H),g(Q.$$.fragment,H),oe=!1},d(H){H&&t(d),$(w),H&&t(N),H&&t(A),H&&t(O),$(Q,H)}}}function m_(Z){let d,x,f,w,P;return{c(){d=r("p"),x=a("\u{1F4A1} Si vous vous demandez pourquoi vous ne voyez aucun avertissement concernant l\u2019affinement du mod\xE8le sur une t\xE2che en aval, c\u2019est parce que pour les t\xE2ches de s\xE9quence \xE0 s\xE9quence, nous conservons tous les poids du r\xE9seau. Comparez cela \xE0 notre mod\xE8le de classification de texte dans "),f=r("a"),w=a("Chapitre 3"),P=a(", o\xF9 la t\xEAte du mod\xE8le pr\xE9-entra\xEEn\xE9 a \xE9t\xE9 remplac\xE9e par un r\xE9seau initialis\xE9 de mani\xE8re al\xE9atoire."),this.h()},l(y){d=l(y,"P",{});var S=o(d);x=n(S,"\u{1F4A1} Si vous vous demandez pourquoi vous ne voyez aucun avertissement concernant l\u2019affinement du mod\xE8le sur une t\xE2che en aval, c\u2019est parce que pour les t\xE2ches de s\xE9quence \xE0 s\xE9quence, nous conservons tous les poids du r\xE9seau. Comparez cela \xE0 notre mod\xE8le de classification de texte dans "),f=l(S,"A",{href:!0});var D=o(f);w=n(D,"Chapitre 3"),D.forEach(t),P=n(S,", o\xF9 la t\xEAte du mod\xE8le pr\xE9-entra\xEEn\xE9 a \xE9t\xE9 remplac\xE9e par un r\xE9seau initialis\xE9 de mani\xE8re al\xE9atoire."),S.forEach(t),this.h()},h(){h(f,"href","/course/fr/chapter3")},m(y,S){i(y,d,S),s(d,x),s(d,f),s(f,w),s(d,P)},d(y){y&&t(d)}}}function Fg(Z){let d,x,f,w,P,y,S,D,E,M,N,A,C,G,L,V,W,ee,J,B,Y,le,O,Q,oe,H,U,te,se,ie,X,ae,_e,ce,ne,je,Re,Pe,F,Ie,he,re,k,R,De,ke,Ee,ve,de,be,pe,Se,we,Ue,ls,$e,_,K,Be,Ze,ue,os,is,ge,Le,Ke,ye,us,fe,qs,Qe,es,vs,js,ss,Is,ts,Gs,ps,He;return C=new T({props:{code:`from transformers import Seq2SeqTrainingArguments

batch_size = 8
num_train_epochs = 8
# La perte d'entra\xEEnement \xE0 chaque \xE9poque
logging_steps = len(tokenized_datasets["train"]) // batch_size
model_name = model_checkpoint.split("/")[-1]

args = Seq2SeqTrainingArguments(
    output_dir=f"{model_name}-finetuned-amazon-en-es",
    evaluation_strategy="epoch",
    learning_rate=5.6e-5,
    per_device_train_batch_size=batch_size,
    per_device_eval_batch_size=batch_size,
    weight_decay=0.01,
    save_total_limit=3,
    num_train_epochs=num_train_epochs,
    predict_with_generate=True,
    logging_steps=logging_steps,
    push_to_hub=True,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainingArguments

batch_size = <span class="hljs-number">8</span>
num_train_epochs = <span class="hljs-number">8</span>
<span class="hljs-comment"># La perte d&#x27;entra\xEEnement \xE0 chaque \xE9poque</span>
logging_steps = <span class="hljs-built_in">len</span>(tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>]) // batch_size
model_name = model_checkpoint.split(<span class="hljs-string">&quot;/&quot;</span>)[-<span class="hljs-number">1</span>]

args = Seq2SeqTrainingArguments(
    output_dir=<span class="hljs-string">f&quot;<span class="hljs-subst">{model_name}</span>-finetuned-amazon-en-es&quot;</span>,
    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
    learning_rate=<span class="hljs-number">5.6e-5</span>,
    per_device_train_batch_size=batch_size,
    per_device_eval_batch_size=batch_size,
    weight_decay=<span class="hljs-number">0.01</span>,
    save_total_limit=<span class="hljs-number">3</span>,
    num_train_epochs=num_train_epochs,
    predict_with_generate=<span class="hljs-literal">True</span>,
    logging_steps=logging_steps,
    push_to_hub=<span class="hljs-literal">True</span>,
)`}}),ps=new T({props:{code:`import numpy as np


def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    # D\xE9coder les r\xE9sum\xE9s g\xE9n\xE9r\xE9s en texte
    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)
    # Remplacer -100 dans les \xE9tiquettes car nous ne pouvons pas les d\xE9coder
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    # D\xE9coder les r\xE9sum\xE9s de r\xE9f\xE9rence en texte
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)
    # ROUGE attend une nouvelle ligne apr\xE8s chaque phrase
    decoded_preds = ["\\n".join(sent_tokenize(pred.strip())) for pred in decoded_preds]
    decoded_labels = ["\\n".join(sent_tokenize(label.strip())) for label in decoded_labels]
    # Calcul des scores ROUGE
    result = rouge_score.compute(
        predictions=decoded_preds, references=decoded_labels, use_stemmer=True
    )
    # Extract the median scores
    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}
    return {k: round(v, 4) for k, v in result.items()}`,highlighted:`<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
    predictions, labels = eval_pred
    <span class="hljs-comment"># D\xE9coder les r\xE9sum\xE9s g\xE9n\xE9r\xE9s en texte</span>
    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=<span class="hljs-literal">True</span>)
    <span class="hljs-comment"># Remplacer -100 dans les \xE9tiquettes car nous ne pouvons pas les d\xE9coder</span>
    labels = np.where(labels != -<span class="hljs-number">100</span>, labels, tokenizer.pad_token_id)
    <span class="hljs-comment"># D\xE9coder les r\xE9sum\xE9s de r\xE9f\xE9rence en texte</span>
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=<span class="hljs-literal">True</span>)
    <span class="hljs-comment"># ROUGE attend une nouvelle ligne apr\xE8s chaque phrase</span>
    decoded_preds = [<span class="hljs-string">&quot;\\n&quot;</span>.join(sent_tokenize(pred.strip())) <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> decoded_preds]
    decoded_labels = [<span class="hljs-string">&quot;\\n&quot;</span>.join(sent_tokenize(label.strip())) <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> decoded_labels]
    <span class="hljs-comment"># Calcul des scores ROUGE</span>
    result = rouge_score.compute(
        predictions=decoded_preds, references=decoded_labels, use_stemmer=<span class="hljs-literal">True</span>
    )
    <span class="hljs-comment"># Extract the median scores</span>
    result = {key: value.mid.fmeasure * <span class="hljs-number">100</span> <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> result.items()}
    <span class="hljs-keyword">return</span> {k: <span class="hljs-built_in">round</span>(v, <span class="hljs-number">4</span>) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> result.items()}`}}),{c(){d=r("p"),x=a("Nous aurons besoin de g\xE9n\xE9rer des r\xE9sum\xE9s afin de calculer les scores ROUGE pendant l\u2019entra\xEEnement. Heureusement, \u{1F917} "),f=r("em"),w=a("Transformers"),P=a(" fournit des classes d\xE9di\xE9es "),y=r("code"),S=a("Seq2SeqTrainingArguments"),D=a(" et "),E=r("code"),M=a("Seq2SeqTrainer"),N=a(" qui peuvent faire cela pour nous automatiquement ! Pour voir comment cela fonctionne, d\xE9finissons d\u2019abord les hyperparam\xE8tres et autres arguments pour nos exp\xE9riences :"),A=m(),b(C.$$.fragment),G=m(),L=r("p"),V=a("Ici, l\u2019argument "),W=r("code"),ee=a("predict_with_generate"),J=a(" a \xE9t\xE9 d\xE9fini pour indiquer que nous devons g\xE9n\xE9rer des r\xE9sum\xE9s pendant l\u2019\xE9valuation afin de pouvoir calculer les scores ROUGE pour chaque \xE9poque. Comme discut\xE9 dans "),B=r("a"),Y=a("Chapter 1"),le=a(", le d\xE9codeur effectue l\u2019inf\xE9rence en pr\xE9disant les tokens un par un, et ceci est impl\xE9ment\xE9 par la m\xE9thode "),O=r("code"),Q=a("generate()"),oe=a(" du mod\xE8le. D\xE9finir "),H=r("code"),U=a("predict_with_generate=True"),te=a(" indique au "),se=r("code"),ie=a("Seq2SeqTrainer"),X=a(" d\u2019utiliser cette m\xE9thode pour l\u2019\xE9valuation. Nous avons \xE9galement ajust\xE9 certains des hyperparam\xE8tres par d\xE9faut, comme le taux d\u2019apprentissage, le nombre d\u2019\xE9poques, et le taux de d\xE9croissance des poids, et nous avons r\xE9gl\xE9 l\u2019option "),ae=r("code"),_e=a("save_total_limit"),ce=a(" pour ne sauvegarder que jusqu\u2019\xE0 3 "),ne=r("em"),je=a("checkpoints"),Re=a(" pendant l\u2019entra\xEEnement. C\u2019est parce que m\xEAme la \u201Cpetite\u201D version de mT5 utilise environ un Go d\u2019espace disque, et nous pouvons gagner un peu de place en limitant le nombre de copies que nous sauvegardons."),Pe=m(),F=r("p"),Ie=a("L\u2019argument "),he=r("code"),re=a("push_to_hub=True"),k=a(" nous permettra de pousser le mod\xE8le vers le Hub apr\xE8s l\u2019entra\xEEnement ; vous trouverez le d\xE9p\xF4t sous votre profil utilisateur dans l\u2019emplacement d\xE9fini par "),R=r("code"),De=a("output_dir"),ke=a(". Notez que vous pouvez sp\xE9cifier le nom du d\xE9p\xF4t vers lequel vous voulez pousser avec l\u2019argument "),Ee=r("code"),ve=a("hub_model_id"),de=a(" (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),be=r("a"),pe=r("code"),Se=a("huggingface-course"),we=a(", nous avons ajout\xE9 "),Ue=r("code"),ls=a('hub_model_id="huggingface-course/mt5-finetuned-amazon-en-es"'),$e=a("\xE0 "),_=r("code"),K=a("Seq2SeqTrainingArguments"),Be=a("."),Ze=m(),ue=r("p"),os=a("La prochaine chose que nous devons faire est de fournir \xE0 l\u2019entra\xEEneur une fonction "),is=r("code"),ge=a("compute_metrics()"),Le=a(" afin que nous puissions \xE9valuer notre mod\xE8le pendant l\u2019entra\xEEnement. Pour le r\xE9sum\xE9, c\u2019est un peu plus compliqu\xE9 que de simplement appeler "),Ke=r("code"),ye=a("rouge_score.compute()"),us=a(" sur les pr\xE9dictions du mod\xE8le, puisque nous devons "),fe=r("em"),qs=a("d\xE9coder"),Qe=a(" les sorties et les \xE9tiquettes en texte avant de pouvoir calculer les scores ROUGE. La fonction suivante fait exactement cela, et utilise \xE9galement la fonction "),es=r("code"),vs=a("sent_tokenize()"),js=a(" de "),ss=r("code"),Is=a("nltk"),ts=a(" pour s\xE9parer les phrases du r\xE9sum\xE9 avec des nouvelles lignes :"),Gs=m(),b(ps.$$.fragment),this.h()},l(I){d=l(I,"P",{});var me=o(d);x=n(me,"Nous aurons besoin de g\xE9n\xE9rer des r\xE9sum\xE9s afin de calculer les scores ROUGE pendant l\u2019entra\xEEnement. Heureusement, \u{1F917} "),f=l(me,"EM",{});var $s=o(f);w=n($s,"Transformers"),$s.forEach(t),P=n(me," fournit des classes d\xE9di\xE9es "),y=l(me,"CODE",{});var Ss=o(y);S=n(Ss,"Seq2SeqTrainingArguments"),Ss.forEach(t),D=n(me," et "),E=l(me,"CODE",{});var gs=o(E);M=n(gs,"Seq2SeqTrainer"),gs.forEach(t),N=n(me," qui peuvent faire cela pour nous automatiquement ! Pour voir comment cela fonctionne, d\xE9finissons d\u2019abord les hyperparam\xE8tres et autres arguments pour nos exp\xE9riences :"),me.forEach(t),A=c(I),q(C.$$.fragment,I),G=c(I),L=l(I,"P",{});var qe=o(L);V=n(qe,"Ici, l\u2019argument "),W=l(qe,"CODE",{});var Ge=o(W);ee=n(Ge,"predict_with_generate"),Ge.forEach(t),J=n(qe," a \xE9t\xE9 d\xE9fini pour indiquer que nous devons g\xE9n\xE9rer des r\xE9sum\xE9s pendant l\u2019\xE9valuation afin de pouvoir calculer les scores ROUGE pour chaque \xE9poque. Comme discut\xE9 dans "),B=l(qe,"A",{href:!0});var Ot=o(B);Y=n(Ot,"Chapter 1"),Ot.forEach(t),le=n(qe,", le d\xE9codeur effectue l\u2019inf\xE9rence en pr\xE9disant les tokens un par un, et ceci est impl\xE9ment\xE9 par la m\xE9thode "),O=l(qe,"CODE",{});var xs=o(O);Q=n(xs,"generate()"),xs.forEach(t),oe=n(qe," du mod\xE8le. D\xE9finir "),H=l(qe,"CODE",{});var Mt=o(H);U=n(Mt,"predict_with_generate=True"),Mt.forEach(t),te=n(qe," indique au "),se=l(qe,"CODE",{});var Nt=o(se);ie=n(Nt,"Seq2SeqTrainer"),Nt.forEach(t),X=n(qe," d\u2019utiliser cette m\xE9thode pour l\u2019\xE9valuation. Nous avons \xE9galement ajust\xE9 certains des hyperparam\xE8tres par d\xE9faut, comme le taux d\u2019apprentissage, le nombre d\u2019\xE9poques, et le taux de d\xE9croissance des poids, et nous avons r\xE9gl\xE9 l\u2019option "),ae=l(qe,"CODE",{});var Ls=o(ae);_e=n(Ls,"save_total_limit"),Ls.forEach(t),ce=n(qe," pour ne sauvegarder que jusqu\u2019\xE0 3 "),ne=l(qe,"EM",{});var As=o(ne);je=n(As,"checkpoints"),As.forEach(t),Re=n(qe," pendant l\u2019entra\xEEnement. C\u2019est parce que m\xEAme la \u201Cpetite\u201D version de mT5 utilise environ un Go d\u2019espace disque, et nous pouvons gagner un peu de place en limitant le nombre de copies que nous sauvegardons."),qe.forEach(t),Pe=c(I),F=l(I,"P",{});var Ae=o(F);Ie=n(Ae,"L\u2019argument "),he=l(Ae,"CODE",{});var Us=o(he);re=n(Us,"push_to_hub=True"),Us.forEach(t),k=n(Ae," nous permettra de pousser le mod\xE8le vers le Hub apr\xE8s l\u2019entra\xEEnement ; vous trouverez le d\xE9p\xF4t sous votre profil utilisateur dans l\u2019emplacement d\xE9fini par "),R=l(Ae,"CODE",{});var Ye=o(R);De=n(Ye,"output_dir"),Ye.forEach(t),ke=n(Ae,". Notez que vous pouvez sp\xE9cifier le nom du d\xE9p\xF4t vers lequel vous voulez pousser avec l\u2019argument "),Ee=l(Ae,"CODE",{});var Hs=o(Ee);ve=n(Hs,"hub_model_id"),Hs.forEach(t),de=n(Ae," (en particulier, vous devrez utiliser cet argument pour pousser vers une organisation). Par exemple, lorsque nous avons pouss\xE9 le mod\xE8le vers l\u2019organisation "),be=l(Ae,"A",{href:!0,rel:!0});var as=o(be);pe=l(as,"CODE",{});var ct=o(pe);Se=n(ct,"huggingface-course"),ct.forEach(t),as.forEach(t),we=n(Ae,", nous avons ajout\xE9 "),Ue=l(Ae,"CODE",{});var Oe=o(Ue);ls=n(Oe,'hub_model_id="huggingface-course/mt5-finetuned-amazon-en-es"'),Oe.forEach(t),$e=n(Ae,"\xE0 "),_=l(Ae,"CODE",{});var ks=o(_);K=n(ks,"Seq2SeqTrainingArguments"),ks.forEach(t),Be=n(Ae,"."),Ae.forEach(t),Ze=c(I),ue=l(I,"P",{});var ze=o(ue);os=n(ze,"La prochaine chose que nous devons faire est de fournir \xE0 l\u2019entra\xEEneur une fonction "),is=l(ze,"CODE",{});var ns=o(is);ge=n(ns,"compute_metrics()"),ns.forEach(t),Le=n(ze," afin que nous puissions \xE9valuer notre mod\xE8le pendant l\u2019entra\xEEnement. Pour le r\xE9sum\xE9, c\u2019est un peu plus compliqu\xE9 que de simplement appeler "),Ke=l(ze,"CODE",{});var Rt=o(Ke);ye=n(Rt,"rouge_score.compute()"),Rt.forEach(t),us=n(ze," sur les pr\xE9dictions du mod\xE8le, puisque nous devons "),fe=l(ze,"EM",{});var Es=o(fe);qs=n(Es,"d\xE9coder"),Es.forEach(t),Qe=n(ze," les sorties et les \xE9tiquettes en texte avant de pouvoir calculer les scores ROUGE. La fonction suivante fait exactement cela, et utilise \xE9galement la fonction "),es=l(ze,"CODE",{});var It=o(es);vs=n(It,"sent_tokenize()"),It.forEach(t),js=n(ze," de "),ss=l(ze,"CODE",{});var Gt=o(ss);Is=n(Gt,"nltk"),Gt.forEach(t),ts=n(ze," pour s\xE9parer les phrases du r\xE9sum\xE9 avec des nouvelles lignes :"),ze.forEach(t),Gs=c(I),q(ps.$$.fragment,I),this.h()},h(){h(B,"href","/course/fr/chapter1"),h(be,"href","https://huggingface.co/huggingface-course"),h(be,"rel","nofollow")},m(I,me){i(I,d,me),s(d,x),s(d,f),s(f,w),s(d,P),s(d,y),s(y,S),s(d,D),s(d,E),s(E,M),s(d,N),i(I,A,me),j(C,I,me),i(I,G,me),i(I,L,me),s(L,V),s(L,W),s(W,ee),s(L,J),s(L,B),s(B,Y),s(L,le),s(L,O),s(O,Q),s(L,oe),s(L,H),s(H,U),s(L,te),s(L,se),s(se,ie),s(L,X),s(L,ae),s(ae,_e),s(L,ce),s(L,ne),s(ne,je),s(L,Re),i(I,Pe,me),i(I,F,me),s(F,Ie),s(F,he),s(he,re),s(F,k),s(F,R),s(R,De),s(F,ke),s(F,Ee),s(Ee,ve),s(F,de),s(F,be),s(be,pe),s(pe,Se),s(F,we),s(F,Ue),s(Ue,ls),s(F,$e),s(F,_),s(_,K),s(F,Be),i(I,Ze,me),i(I,ue,me),s(ue,os),s(ue,is),s(is,ge),s(ue,Le),s(ue,Ke),s(Ke,ye),s(ue,us),s(ue,fe),s(fe,qs),s(ue,Qe),s(ue,es),s(es,vs),s(ue,js),s(ue,ss),s(ss,Is),s(ue,ts),i(I,Gs,me),j(ps,I,me),He=!0},i(I){He||(v(C.$$.fragment,I),v(ps.$$.fragment,I),He=!0)},o(I){g(C.$$.fragment,I),g(ps.$$.fragment,I),He=!1},d(I){I&&t(d),I&&t(A),$(C,I),I&&t(G),I&&t(L),I&&t(Pe),I&&t(F),I&&t(Ze),I&&t(ue),I&&t(Gs),$(ps,I)}}}function c_(Z){let d,x;return d=new T({props:{code:`from transformers import DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors="tf")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`}}),{c(){b(d.$$.fragment)},l(f){q(d.$$.fragment,f)},m(f,w){j(d,f,w),x=!0},i(f){x||(v(d.$$.fragment,f),x=!0)},o(f){g(d.$$.fragment,f),x=!1},d(f){$(d,f)}}}function d_(Z){let d,x;return d=new T({props:{code:`from transformers import DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForSeq2Seq

data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)`}}),{c(){b(d.$$.fragment)},l(f){q(d.$$.fragment,f)},m(f,w){j(d,f,w),x=!0},i(f){x||(v(d.$$.fragment,f),x=!0)},o(f){g(d.$$.fragment,f),x=!1},d(f){$(d,f)}}}function f_(Z){let d,x,f,w,P,y,S,D,E,M,N,A,C,G,L,V,W,ee,J,B,Y,le,O,Q,oe,H,U,te,se,ie,X,ae,_e,ce,ne,je,Re,Pe,F,Ie,he,re;return C=new T({props:{code:`tf_train_dataset = tokenized_datasets["train"].to_tf_dataset(
    columns=["input_ids", "attention_mask", "labels"],
    collate_fn=data_collator,
    shuffle=True,
    batch_size=8,
)
tf_eval_dataset = tokenized_datasets["validation"].to_tf_dataset(
    columns=["input_ids", "attention_mask", "labels"],
    collate_fn=data_collator,
    shuffle=False,
    batch_size=8,
)`,highlighted:`tf_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>],
    collate_fn=data_collator,
    shuffle=<span class="hljs-literal">True</span>,
    batch_size=<span class="hljs-number">8</span>,
)
tf_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>],
    collate_fn=data_collator,
    shuffle=<span class="hljs-literal">False</span>,
    batch_size=<span class="hljs-number">8</span>,
)`}}),ee=new T({props:{code:`from transformers import create_optimizer
import tensorflow as tf

# Le nombre d'\xE9tapes d'entra\xEEnement est le nombre d'\xE9chantillons dans l'ensemble de donn\xE9es, divis\xE9 par la taille du batch, puis multipli\xE9 par le nombre total d'\xE9poques.
# par le nombre total d'\xE9poques. Notez que le jeu de donn\xE9es tf_train_dataset est ici un batch tf.data.Dataset,
# et non le jeu de donn\xE9es original Hugging Face Dataset, donc son len() est d\xE9j\xE0 num_samples // batch_size.
num_train_epochs = 8
num_train_steps = len(tf_train_dataset) * num_train_epochs
model_name = model_checkpoint.split("/")[-1]

optimizer, schedule = create_optimizer(
    init_lr=5.6e-5,
    num_warmup_steps=0,
    num_train_steps=num_train_steps,
    weight_decay_rate=0.01,
)

model.compile(optimizer=optimizer)

# Entra\xEEner en mixed-precision float16
tf.keras.mixed_precision.set_global_policy("mixed_float16")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-comment"># Le nombre d&#x27;\xE9tapes d&#x27;entra\xEEnement est le nombre d&#x27;\xE9chantillons dans l&#x27;ensemble de donn\xE9es, divis\xE9 par la taille du batch, puis multipli\xE9 par le nombre total d&#x27;\xE9poques.</span>
<span class="hljs-comment"># par le nombre total d&#x27;\xE9poques. Notez que le jeu de donn\xE9es tf_train_dataset est ici un batch tf.data.Dataset,</span>
<span class="hljs-comment"># et non le jeu de donn\xE9es original Hugging Face Dataset, donc son len() est d\xE9j\xE0 num_samples // batch_size.</span>
num_train_epochs = <span class="hljs-number">8</span>
num_train_steps = <span class="hljs-built_in">len</span>(tf_train_dataset) * num_train_epochs
model_name = model_checkpoint.split(<span class="hljs-string">&quot;/&quot;</span>)[-<span class="hljs-number">1</span>]

optimizer, schedule = create_optimizer(
    init_lr=<span class="hljs-number">5.6e-5</span>,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_train_steps=num_train_steps,
    weight_decay_rate=<span class="hljs-number">0.01</span>,
)

model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)

<span class="hljs-comment"># Entra\xEEner en mixed-precision float16</span>
tf.keras.mixed_precision.set_global_policy(<span class="hljs-string">&quot;mixed_float16&quot;</span>)`}}),se=new T({props:{code:`from transformers.keras_callbacks import PushToHubCallback

callback = PushToHubCallback(
    output_dir=f"{model_name}-finetuned-amazon-en-es", tokenizer=tokenizer
)

model.fit(
    tf_train_dataset, validation_data=tf_eval_dataset, callbacks=[callback], epochs=8
)`,highlighted:`<span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback

callback = PushToHubCallback(
    output_dir=<span class="hljs-string">f&quot;<span class="hljs-subst">{model_name}</span>-finetuned-amazon-en-es&quot;</span>, tokenizer=tokenizer
)

model.fit(
    tf_train_dataset, validation_data=tf_eval_dataset, callbacks=[callback], epochs=<span class="hljs-number">8</span>
)`}}),ce=new T({props:{code:`from tqdm import tqdm
import numpy as np

all_preds = []
all_labels = []
for batch in tqdm(tf_eval_dataset):
    predictions = model.generate(**batch)
    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)
    labels = batch["labels"].numpy()
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)
    decoded_preds = ["\\n".join(sent_tokenize(pred.strip())) for pred in decoded_preds]
    decoded_labels = ["\\n".join(sent_tokenize(label.strip())) for label in decoded_labels]
    all_preds.extend(decoded_preds)
    all_labels.extend(decoded_labels)`,highlighted:`<span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

all_preds = []
all_labels = []
<span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> tqdm(tf_eval_dataset):
    predictions = model.generate(**batch)
    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=<span class="hljs-literal">True</span>)
    labels = batch[<span class="hljs-string">&quot;labels&quot;</span>].numpy()
    labels = np.where(labels != -<span class="hljs-number">100</span>, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=<span class="hljs-literal">True</span>)
    decoded_preds = [<span class="hljs-string">&quot;\\n&quot;</span>.join(sent_tokenize(pred.strip())) <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> decoded_preds]
    decoded_labels = [<span class="hljs-string">&quot;\\n&quot;</span>.join(sent_tokenize(label.strip())) <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> decoded_labels]
    all_preds.extend(decoded_preds)
    all_labels.extend(decoded_labels)`}}),F=new T({props:{code:`result = rouge_score.compute(
    predictions=decoded_preds, references=decoded_labels, use_stemmer=True
)
result = {key: value.mid.fmeasure * 100 for key, value in result.items()}
{k: round(v, 4) for k, v in result.items()}`,highlighted:`result = rouge_score.compute(
    predictions=decoded_preds, references=decoded_labels, use_stemmer=<span class="hljs-literal">True</span>
)
result = {key: value.mid.fmeasure * <span class="hljs-number">100</span> <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> result.items()}
{k: <span class="hljs-built_in">round</span>(v, <span class="hljs-number">4</span>) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> result.items()}`}}),he=new T({props:{code:"{'rouge1': 31.4815, 'rouge2': 25.4386, 'rougeL': 31.4815, 'rougeLsum': 31.4815}",highlighted:'{&#x27;rouge1&#x27;: <span class="hljs-number">31.4815</span>, &#x27;rouge2&#x27;: <span class="hljs-number">25.4386</span>, &#x27;rougeL&#x27;: <span class="hljs-number">31.4815</span>, &#x27;rougeLsum&#x27;: <span class="hljs-number">31.4815</span>}'}}),{c(){d=r("p"),x=a("Nous sommes presque pr\xEAts \xE0 nous entra\xEEner ! Nous devons juste convertir nos jeux de donn\xE9es en "),f=r("code"),w=a("tf.data.Dataset"),P=a("s en utilisant le collateur de donn\xE9es que nous avons d\xE9fini ci-dessus, et ensuite "),y=r("code"),S=a("compile()"),D=a(" et "),E=r("code"),M=a("fit()"),N=a(" le mod\xE8le. D\u2019abord, les jeux de donn\xE9es :"),A=m(),b(C.$$.fragment),G=m(),L=r("p"),V=a("Maintenant, nous d\xE9finissons nos hyperparam\xE8tres d\u2019entra\xEEnement et nous compilons :"),W=m(),b(ee.$$.fragment),J=m(),B=r("p"),Y=a("Et enfin, nous ajustons le mod\xE8le. Nous utilisons un "),le=r("code"),O=a("PushToHubCallback"),Q=a(" pour sauvegarder le mod\xE8le sur le "),oe=r("em"),H=a("Hub"),U=a(" apr\xE8s chaque \xE9poque, ce qui nous permettra de l\u2019utiliser pour l\u2019inf\xE9rence plus tard :"),te=m(),b(se.$$.fragment),ie=m(),X=r("p"),ae=a("Nous avons obtenu quelques valeurs de perte pendant l\u2019entra\xEEnement, mais nous aimerions vraiment voir les m\xE9triques ROUGE que nous avons calcul\xE9es plus t\xF4t. Pour obtenir ces m\xE9triques, nous devons g\xE9n\xE9rer les sorties du mod\xE8le et les convertir en cha\xEEnes de caract\xE8res. Construisons quelques listes d\u2019\xE9tiquettes et de pr\xE9dictions pour comparer la m\xE9trique ROUGE (notez que si vous obtenez des erreurs d\u2019importation pour cette section, vous pouvez avoir besoin de \u201Cpip install tqdm\u201D) :"),_e=m(),b(ce.$$.fragment),ne=m(),je=r("p"),Re=a("Une fois que nous avons nos listes d\u2019\xE9tiquettes et de cha\xEEnes de pr\xE9diction, le calcul du score ROUGE est facile :"),Pe=m(),b(F.$$.fragment),Ie=m(),b(he.$$.fragment)},l(k){d=l(k,"P",{});var R=o(d);x=n(R,"Nous sommes presque pr\xEAts \xE0 nous entra\xEEner ! Nous devons juste convertir nos jeux de donn\xE9es en "),f=l(R,"CODE",{});var De=o(f);w=n(De,"tf.data.Dataset"),De.forEach(t),P=n(R,"s en utilisant le collateur de donn\xE9es que nous avons d\xE9fini ci-dessus, et ensuite "),y=l(R,"CODE",{});var ke=o(y);S=n(ke,"compile()"),ke.forEach(t),D=n(R," et "),E=l(R,"CODE",{});var Ee=o(E);M=n(Ee,"fit()"),Ee.forEach(t),N=n(R," le mod\xE8le. D\u2019abord, les jeux de donn\xE9es :"),R.forEach(t),A=c(k),q(C.$$.fragment,k),G=c(k),L=l(k,"P",{});var ve=o(L);V=n(ve,"Maintenant, nous d\xE9finissons nos hyperparam\xE8tres d\u2019entra\xEEnement et nous compilons :"),ve.forEach(t),W=c(k),q(ee.$$.fragment,k),J=c(k),B=l(k,"P",{});var de=o(B);Y=n(de,"Et enfin, nous ajustons le mod\xE8le. Nous utilisons un "),le=l(de,"CODE",{});var be=o(le);O=n(be,"PushToHubCallback"),be.forEach(t),Q=n(de," pour sauvegarder le mod\xE8le sur le "),oe=l(de,"EM",{});var pe=o(oe);H=n(pe,"Hub"),pe.forEach(t),U=n(de," apr\xE8s chaque \xE9poque, ce qui nous permettra de l\u2019utiliser pour l\u2019inf\xE9rence plus tard :"),de.forEach(t),te=c(k),q(se.$$.fragment,k),ie=c(k),X=l(k,"P",{});var Se=o(X);ae=n(Se,"Nous avons obtenu quelques valeurs de perte pendant l\u2019entra\xEEnement, mais nous aimerions vraiment voir les m\xE9triques ROUGE que nous avons calcul\xE9es plus t\xF4t. Pour obtenir ces m\xE9triques, nous devons g\xE9n\xE9rer les sorties du mod\xE8le et les convertir en cha\xEEnes de caract\xE8res. Construisons quelques listes d\u2019\xE9tiquettes et de pr\xE9dictions pour comparer la m\xE9trique ROUGE (notez que si vous obtenez des erreurs d\u2019importation pour cette section, vous pouvez avoir besoin de \u201Cpip install tqdm\u201D) :"),Se.forEach(t),_e=c(k),q(ce.$$.fragment,k),ne=c(k),je=l(k,"P",{});var we=o(je);Re=n(we,"Une fois que nous avons nos listes d\u2019\xE9tiquettes et de cha\xEEnes de pr\xE9diction, le calcul du score ROUGE est facile :"),we.forEach(t),Pe=c(k),q(F.$$.fragment,k),Ie=c(k),q(he.$$.fragment,k)},m(k,R){i(k,d,R),s(d,x),s(d,f),s(f,w),s(d,P),s(d,y),s(y,S),s(d,D),s(d,E),s(E,M),s(d,N),i(k,A,R),j(C,k,R),i(k,G,R),i(k,L,R),s(L,V),i(k,W,R),j(ee,k,R),i(k,J,R),i(k,B,R),s(B,Y),s(B,le),s(le,O),s(B,Q),s(B,oe),s(oe,H),s(B,U),i(k,te,R),j(se,k,R),i(k,ie,R),i(k,X,R),s(X,ae),i(k,_e,R),j(ce,k,R),i(k,ne,R),i(k,je,R),s(je,Re),i(k,Pe,R),j(F,k,R),i(k,Ie,R),j(he,k,R),re=!0},i(k){re||(v(C.$$.fragment,k),v(ee.$$.fragment,k),v(se.$$.fragment,k),v(ce.$$.fragment,k),v(F.$$.fragment,k),v(he.$$.fragment,k),re=!0)},o(k){g(C.$$.fragment,k),g(ee.$$.fragment,k),g(se.$$.fragment,k),g(ce.$$.fragment,k),g(F.$$.fragment,k),g(he.$$.fragment,k),re=!1},d(k){k&&t(d),k&&t(A),$(C,k),k&&t(G),k&&t(L),k&&t(W),$(ee,k),k&&t(J),k&&t(B),k&&t(te),$(se,k),k&&t(ie),k&&t(X),k&&t(_e),$(ce,k),k&&t(ne),k&&t(je),k&&t(Pe),$(F,k),k&&t(Ie),$(he,k)}}}function h_(Z){let d,x,f,w,P,y,S,D,E,M,N,A,C,G,L,V,W,ee,J,B,Y,le,O,Q,oe,H,U,te,se,ie,X,ae,_e,ce,ne,je,Re,Pe,F,Ie,he,re,k,R,De,ke,Ee,ve,de,be,pe,Se,we,Ue,ls,$e;return w=new T({props:{code:`from transformers import Seq2SeqTrainer

trainer = Seq2SeqTrainer(
    model,
    args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Seq2SeqTrainer

trainer = Seq2SeqTrainer(
    model,
    args,
    train_dataset=tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    eval_dataset=tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
)`}}),E=new T({props:{code:"trainer.train()",highlighted:"trainer.train()"}}),W=new T({props:{code:"trainer.evaluate()",highlighted:"trainer.evaluate()"}}),J=new T({props:{code:`{'eval_loss': 3.028524398803711,
 'eval_rouge1': 16.9728,
 'eval_rouge2': 8.2969,
 'eval_rougeL': 16.8366,
 'eval_rougeLsum': 16.851,
 'eval_gen_len': 10.1597,
 'eval_runtime': 6.1054,
 'eval_samples_per_second': 38.982,
 'eval_steps_per_second': 4.914}`,highlighted:`{<span class="hljs-string">&#x27;eval_loss&#x27;</span>: <span class="hljs-number">3.028524398803711</span>,
 <span class="hljs-string">&#x27;eval_rouge1&#x27;</span>: <span class="hljs-number">16.9728</span>,
 <span class="hljs-string">&#x27;eval_rouge2&#x27;</span>: <span class="hljs-number">8.2969</span>,
 <span class="hljs-string">&#x27;eval_rougeL&#x27;</span>: <span class="hljs-number">16.8366</span>,
 <span class="hljs-string">&#x27;eval_rougeLsum&#x27;</span>: <span class="hljs-number">16.851</span>,
 <span class="hljs-string">&#x27;eval_gen_len&#x27;</span>: <span class="hljs-number">10.1597</span>,
 <span class="hljs-string">&#x27;eval_runtime&#x27;</span>: <span class="hljs-number">6.1054</span>,
 <span class="hljs-string">&#x27;eval_samples_per_second&#x27;</span>: <span class="hljs-number">38.982</span>,
 <span class="hljs-string">&#x27;eval_steps_per_second&#x27;</span>: <span class="hljs-number">4.914</span>}`}}),U=new T({props:{code:'trainer.push_to_hub(commit_message="Training complete", tags="summarization")',highlighted:'trainer.push_to_hub(<span class="hljs-attribute">commit_message</span>=<span class="hljs-string">&quot;Training complete&quot;</span>, <span class="hljs-attribute">tags</span>=<span class="hljs-string">&quot;summarization&quot;</span>)'}}),se=new T({props:{code:"'https://huggingface.co/huggingface-course/mt5-finetuned-amazon-en-es/commit/aa0536b829b28e73e1e4b94b8a5aacec420d40e0'",highlighted:'<span class="hljs-string">&#x27;https://huggingface.co/huggingface-course/mt5-finetuned-amazon-en-es/commit/aa0536b829b28e73e1e4b94b8a5aacec420d40e0&#x27;</span>'}}),{c(){d=r("p"),x=a("Nous avons enfin tous les ingr\xE9dients dont nous avons besoin pour nous entra\xEEner ! Nous devons maintenant simplement instancier le formateur avec les arguments standards :"),f=m(),b(w.$$.fragment),P=m(),y=r("p"),S=a("et lancer notre course d\u2019entra\xEEnement :"),D=m(),b(E.$$.fragment),M=m(),N=r("p"),A=a("Pendant l\u2019entra\xEEnement, vous devriez voir la perte d\u2019entra\xEEnement diminuer et les scores ROUGE augmenter \xE0 chaque \xE9poque. Une fois l\u2019entra\xEEnement termin\xE9, vous pouvez voir les scores ROUGE finaux en ex\xE9cutant "),C=r("code"),G=a("Trainer.evaluate()"),L=a(" :"),V=m(),b(W.$$.fragment),ee=m(),b(J.$$.fragment),B=m(),Y=r("p"),le=a("D\u2019apr\xE8s les scores, nous pouvons voir que notre mod\xE8le a largement surpass\xE9 notre ligne de base lead-3. Bien ! La derni\xE8re chose \xE0 faire est de pousser les poids du mod\xE8le vers le "),O=r("em"),Q=a("Hub"),oe=a(", comme suit :"),H=m(),b(U.$$.fragment),te=m(),b(se.$$.fragment),ie=m(),X=r("p"),ae=a("Ceci sauvegardera le point de contr\xF4le et les fichiers de configuration dans "),_e=r("code"),ce=a("output_dir"),ne=a(", avant de t\xE9l\xE9charger tous les fichiers sur le "),je=r("em"),Re=a("Hub"),Pe=a(". En sp\xE9cifiant l\u2019argument "),F=r("code"),Ie=a("tags"),he=a(", nous nous assurons \xE9galement que le widget sur le Hub sera celui d\u2019un pipeline de r\xE9sum\xE9 au lieu de celui de la g\xE9n\xE9ration de texte par d\xE9faut associ\xE9 \xE0 l\u2019architecture mT5 (pour plus d\u2019informations sur les balises de mod\xE8le, voir la "),re=r("a"),k=a("\u{1F917} documentation du "),R=r("em"),De=a("Hub"),ke=a("). La sortie de "),Ee=r("code"),ve=a("trainer.push_to_hub()"),de=a(" est une URL vers le hash du commit Git, donc vous pouvez facilement voir les changements qui ont \xE9t\xE9 faits au d\xE9p\xF4t de mod\xE8le !"),be=m(),pe=r("p"),Se=a("Pour conclure cette section, voyons comment nous pouvons \xE9galement affiner mT5 en utilisant les fonctionnalit\xE9s de bas niveau fournies par \u{1F917} "),we=r("em"),Ue=a("Accelerate"),ls=a("."),this.h()},l(_){d=l(_,"P",{});var K=o(d);x=n(K,"Nous avons enfin tous les ingr\xE9dients dont nous avons besoin pour nous entra\xEEner ! Nous devons maintenant simplement instancier le formateur avec les arguments standards :"),K.forEach(t),f=c(_),q(w.$$.fragment,_),P=c(_),y=l(_,"P",{});var Be=o(y);S=n(Be,"et lancer notre course d\u2019entra\xEEnement :"),Be.forEach(t),D=c(_),q(E.$$.fragment,_),M=c(_),N=l(_,"P",{});var Ze=o(N);A=n(Ze,"Pendant l\u2019entra\xEEnement, vous devriez voir la perte d\u2019entra\xEEnement diminuer et les scores ROUGE augmenter \xE0 chaque \xE9poque. Une fois l\u2019entra\xEEnement termin\xE9, vous pouvez voir les scores ROUGE finaux en ex\xE9cutant "),C=l(Ze,"CODE",{});var ue=o(C);G=n(ue,"Trainer.evaluate()"),ue.forEach(t),L=n(Ze," :"),Ze.forEach(t),V=c(_),q(W.$$.fragment,_),ee=c(_),q(J.$$.fragment,_),B=c(_),Y=l(_,"P",{});var os=o(Y);le=n(os,"D\u2019apr\xE8s les scores, nous pouvons voir que notre mod\xE8le a largement surpass\xE9 notre ligne de base lead-3. Bien ! La derni\xE8re chose \xE0 faire est de pousser les poids du mod\xE8le vers le "),O=l(os,"EM",{});var is=o(O);Q=n(is,"Hub"),is.forEach(t),oe=n(os,", comme suit :"),os.forEach(t),H=c(_),q(U.$$.fragment,_),te=c(_),q(se.$$.fragment,_),ie=c(_),X=l(_,"P",{});var ge=o(X);ae=n(ge,"Ceci sauvegardera le point de contr\xF4le et les fichiers de configuration dans "),_e=l(ge,"CODE",{});var Le=o(_e);ce=n(Le,"output_dir"),Le.forEach(t),ne=n(ge,", avant de t\xE9l\xE9charger tous les fichiers sur le "),je=l(ge,"EM",{});var Ke=o(je);Re=n(Ke,"Hub"),Ke.forEach(t),Pe=n(ge,". En sp\xE9cifiant l\u2019argument "),F=l(ge,"CODE",{});var ye=o(F);Ie=n(ye,"tags"),ye.forEach(t),he=n(ge,", nous nous assurons \xE9galement que le widget sur le Hub sera celui d\u2019un pipeline de r\xE9sum\xE9 au lieu de celui de la g\xE9n\xE9ration de texte par d\xE9faut associ\xE9 \xE0 l\u2019architecture mT5 (pour plus d\u2019informations sur les balises de mod\xE8le, voir la "),re=l(ge,"A",{href:!0,rel:!0});var us=o(re);k=n(us,"\u{1F917} documentation du "),R=l(us,"EM",{});var fe=o(R);De=n(fe,"Hub"),fe.forEach(t),us.forEach(t),ke=n(ge,"). La sortie de "),Ee=l(ge,"CODE",{});var qs=o(Ee);ve=n(qs,"trainer.push_to_hub()"),qs.forEach(t),de=n(ge," est une URL vers le hash du commit Git, donc vous pouvez facilement voir les changements qui ont \xE9t\xE9 faits au d\xE9p\xF4t de mod\xE8le !"),ge.forEach(t),be=c(_),pe=l(_,"P",{});var Qe=o(pe);Se=n(Qe,"Pour conclure cette section, voyons comment nous pouvons \xE9galement affiner mT5 en utilisant les fonctionnalit\xE9s de bas niveau fournies par \u{1F917} "),we=l(Qe,"EM",{});var es=o(we);Ue=n(es,"Accelerate"),es.forEach(t),ls=n(Qe,"."),Qe.forEach(t),this.h()},h(){h(re,"href","https://huggingface.co/docs/hub/main#how-is-a-models-type-of-inference-api-and-widget-determined"),h(re,"rel","nofollow")},m(_,K){i(_,d,K),s(d,x),i(_,f,K),j(w,_,K),i(_,P,K),i(_,y,K),s(y,S),i(_,D,K),j(E,_,K),i(_,M,K),i(_,N,K),s(N,A),s(N,C),s(C,G),s(N,L),i(_,V,K),j(W,_,K),i(_,ee,K),j(J,_,K),i(_,B,K),i(_,Y,K),s(Y,le),s(Y,O),s(O,Q),s(Y,oe),i(_,H,K),j(U,_,K),i(_,te,K),j(se,_,K),i(_,ie,K),i(_,X,K),s(X,ae),s(X,_e),s(_e,ce),s(X,ne),s(X,je),s(je,Re),s(X,Pe),s(X,F),s(F,Ie),s(X,he),s(X,re),s(re,k),s(re,R),s(R,De),s(X,ke),s(X,Ee),s(Ee,ve),s(X,de),i(_,be,K),i(_,pe,K),s(pe,Se),s(pe,we),s(we,Ue),s(pe,ls),$e=!0},i(_){$e||(v(w.$$.fragment,_),v(E.$$.fragment,_),v(W.$$.fragment,_),v(J.$$.fragment,_),v(U.$$.fragment,_),v(se.$$.fragment,_),$e=!0)},o(_){g(w.$$.fragment,_),g(E.$$.fragment,_),g(W.$$.fragment,_),g(J.$$.fragment,_),g(U.$$.fragment,_),g(se.$$.fragment,_),$e=!1},d(_){_&&t(d),_&&t(f),$(w,_),_&&t(P),_&&t(y),_&&t(D),$(E,_),_&&t(M),_&&t(N),_&&t(V),$(W,_),_&&t(ee),$(J,_),_&&t(B),_&&t(Y),_&&t(H),$(U,_),_&&t(te),$(se,_),_&&t(ie),_&&t(X),_&&t(be),_&&t(pe)}}}function Jg(Z){let d,x,f,w,P,y,S,D,E,M,N,A,C,G,L,V,W,ee,J,B,Y,le,O,Q,oe,H,U,te,se,ie,X,ae,_e,ce,ne,je,Re,Pe,F,Ie,he,re,k,R,De,ke,Ee,ve,de,be,pe,Se,we,Ue,ls,$e,_,K,Be,Ze,ue,os,is,ge,Le,Ke,ye,us,fe,qs,Qe,es,vs,js,ss,Is,ts,Gs,ps,He,I,me,$s,Ss,gs,qe,Ge,Ot,xs,Mt,Nt,Ls,As,Ae,Us,Ye,Hs,as,ct,Oe,ks,ze,ns,Rt,Es,It,Gt,Fs,On,Mn,Ut,ws,Nn,Ht,dt,Na,Me,Rn,pa,Ra,ft,Ft,ht,Ia,Js,In,Ga,Os,Ua,Bs,ma,ca,Gn,Ha,Vs,ys,_s,da,Ws,vt,Jt,gt,fa,Te,Un,_t,Hn,Fn,Bt,ms,bt,ha,va,Jn,ga,Bn,qt,Fa,Ms,Ja,jt,Ba,Ks,Vn,Va,Ce,$t,Wa,Wn,xt,Ka,Qa,Qs,_a,ba,Kn,qa,Ya,kt,ja,rs,Qn,Vt,Et,Xa,Ns,Za,Ys,en,bs,Xs,$a,Zs;return w=new mt({}),ie=new mt({}),R=new T({props:{code:'tokenized_datasets.set_format("torch")',highlighted:'tokenized_datasets.set_format(<span class="hljs-string">&quot;torch&quot;</span>)'}}),Se=new T({props:{code:"model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)",highlighted:"model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"}}),_=new T({props:{code:`from torch.utils.data import DataLoader

batch_size = 8
train_dataloader = DataLoader(
    tokenized_datasets["train"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=batch_size,
)
eval_dataloader = DataLoader(
    tokenized_datasets["validation"], collate_fn=data_collator, batch_size=batch_size
)`,highlighted:`<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

batch_size = <span class="hljs-number">8</span>
train_dataloader = DataLoader(
    tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>],
    shuffle=<span class="hljs-literal">True</span>,
    collate_fn=data_collator,
    batch_size=batch_size,
)
eval_dataloader = DataLoader(
    tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>], collate_fn=data_collator, batch_size=batch_size
)`}}),Le=new T({props:{code:`from torch.optim import AdamW

optimizer = AdamW(model.parameters(), lr=2e-5)`,highlighted:`<span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW

optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">2e-5</span>)`}}),vs=new T({props:{code:`from accelerate import Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)`,highlighted:`<span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator

accelerator = Accelerator()
model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(
    model, optimizer, train_dataloader, eval_dataloader
)`}}),ss=new An({props:{$$slots:{default:[v_]},$$scope:{ctx:Z}}}),Ye=new T({props:{code:`from transformers import get_scheduler

num_train_epochs = 10
num_update_steps_per_epoch = len(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    "linear",
    optimizer=optimizer,
    num_warmup_steps=0,
    num_training_steps=num_training_steps,
)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler

num_train_epochs = <span class="hljs-number">10</span>
num_update_steps_per_epoch = <span class="hljs-built_in">len</span>(train_dataloader)
num_training_steps = num_train_epochs * num_update_steps_per_epoch

lr_scheduler = get_scheduler(
    <span class="hljs-string">&quot;linear&quot;</span>,
    optimizer=optimizer,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_training_steps=num_training_steps,
)`}}),ks=new T({props:{code:`def postprocess_text(preds, labels):
    preds = [pred.strip() for pred in preds]
    labels = [label.strip() for label in labels]

    # ROUGE attend une nouvelle ligne apr\xE8s chaque phrase
    preds = ["\\n".join(nltk.sent_tokenize(pred)) for pred in preds]
    labels = ["\\n".join(nltk.sent_tokenize(label)) for label in labels]

    return preds, labels`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">postprocess_text</span>(<span class="hljs-params">preds, labels</span>):
    preds = [pred.strip() <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
    labels = [label.strip() <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels]

    <span class="hljs-comment"># ROUGE attend une nouvelle ligne apr\xE8s chaque phrase</span>
    preds = [<span class="hljs-string">&quot;\\n&quot;</span>.join(nltk.sent_tokenize(pred)) <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
    labels = [<span class="hljs-string">&quot;\\n&quot;</span>.join(nltk.sent_tokenize(label)) <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels]

    <span class="hljs-keyword">return</span> preds, labels`}}),ft=new T({props:{code:`from huggingface_hub import get_full_repo_name

model_name = "test-bert-finetuned-squad-accelerate"
repo_name = get_full_repo_name(model_name)
repo_name`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> get_full_repo_name

model_name = <span class="hljs-string">&quot;test-bert-finetuned-squad-accelerate&quot;</span>
repo_name = get_full_repo_name(model_name)
repo_name`}}),ht=new T({props:{code:"'lewtun/mt5-finetuned-amazon-en-es-accelerate'",highlighted:'<span class="hljs-string">&#x27;lewtun/mt5-finetuned-amazon-en-es-accelerate&#x27;</span>'}}),Os=new T({props:{code:`from huggingface_hub import Repository

output_dir = "results-mt5-finetuned-squad-accelerate"
repo = Repository(output_dir, clone_from=repo_name)`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> Repository

output_dir = <span class="hljs-string">&quot;results-mt5-finetuned-squad-accelerate&quot;</span>
repo = Repository(output_dir, clone_from=repo_name)`}}),Ws=new mt({}),Et=new T({props:{code:`from tqdm.auto import tqdm
import torch
import numpy as np

progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_train_epochs):
    # Entra\xEEnement
    model.train()
    for step, batch in enumerate(train_dataloader):
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

    # Evaluation
    model.eval()
    for step, batch in enumerate(eval_dataloader):
        with torch.no_grad():
            generated_tokens = accelerator.unwrap_model(model).generate(
                batch["input_ids"],
                attention_mask=batch["attention_mask"],
            )

            generated_tokens = accelerator.pad_across_processes(
                generated_tokens, dim=1, pad_index=tokenizer.pad_token_id
            )
            labels = batch["labels"]

            # Si nous n'avons pas rempli la longueur maximale, nous devons \xE9galement remplir les \xE9tiquettes.
            labels = accelerator.pad_across_processes(
                batch["labels"], dim=1, pad_index=tokenizer.pad_token_id
            )

            generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()
            labels = accelerator.gather(labels).cpu().numpy()

            # Remplacer -100 dans les \xE9tiquettes car nous ne pouvons pas les d\xE9coder.
            labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
            if isinstance(generated_tokens, tuple):
                generated_tokens = generated_tokens[0]
            decoded_preds = tokenizer.batch_decode(
                generated_tokens, skip_special_tokens=True
            )
            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

            decoded_preds, decoded_labels = postprocess_text(
                decoded_preds, decoded_labels
            )

            rouge_score.add_batch(predictions=decoded_preds, references=decoded_labels)

    # Calculer les m\xE9triques
    result = rouge_score.compute()
    # Extract the median ROUGE scores
    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}
    result = {k: round(v, 4) for k, v in result.items()}
    print(f"Epoch {epoch}:", result)

    # Sauvegarder et t\xE9l\xE9charger
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    if accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=f"Training in progress epoch {epoch}", blocking=False
        )`,highlighted:`<span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_train_epochs):
    <span class="hljs-comment"># Entra\xEEnement</span>
    model.train()
    <span class="hljs-keyword">for</span> step, batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_dataloader):
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(<span class="hljs-number">1</span>)

    <span class="hljs-comment"># Evaluation</span>
    model.<span class="hljs-built_in">eval</span>()
    <span class="hljs-keyword">for</span> step, batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(eval_dataloader):
        <span class="hljs-keyword">with</span> torch.no_grad():
            generated_tokens = accelerator.unwrap_model(model).generate(
                batch[<span class="hljs-string">&quot;input_ids&quot;</span>],
                attention_mask=batch[<span class="hljs-string">&quot;attention_mask&quot;</span>],
            )

            generated_tokens = accelerator.pad_across_processes(
                generated_tokens, dim=<span class="hljs-number">1</span>, pad_index=tokenizer.pad_token_id
            )
            labels = batch[<span class="hljs-string">&quot;labels&quot;</span>]

            <span class="hljs-comment"># Si nous n&#x27;avons pas rempli la longueur maximale, nous devons \xE9galement remplir les \xE9tiquettes.</span>
            labels = accelerator.pad_across_processes(
                batch[<span class="hljs-string">&quot;labels&quot;</span>], dim=<span class="hljs-number">1</span>, pad_index=tokenizer.pad_token_id
            )

            generated_tokens = accelerator.gather(generated_tokens).cpu().numpy()
            labels = accelerator.gather(labels).cpu().numpy()

            <span class="hljs-comment"># Remplacer -100 dans les \xE9tiquettes car nous ne pouvons pas les d\xE9coder.</span>
            labels = np.where(labels != -<span class="hljs-number">100</span>, labels, tokenizer.pad_token_id)
            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(generated_tokens, <span class="hljs-built_in">tuple</span>):
                generated_tokens = generated_tokens[<span class="hljs-number">0</span>]
            decoded_preds = tokenizer.batch_decode(
                generated_tokens, skip_special_tokens=<span class="hljs-literal">True</span>
            )
            decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=<span class="hljs-literal">True</span>)

            decoded_preds, decoded_labels = postprocess_text(
                decoded_preds, decoded_labels
            )

            rouge_score.add_batch(predictions=decoded_preds, references=decoded_labels)

    <span class="hljs-comment"># Calculer les m\xE9triques</span>
    result = rouge_score.compute()
    <span class="hljs-comment"># Extract the median ROUGE scores</span>
    result = {key: value.mid.fmeasure * <span class="hljs-number">100</span> <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> result.items()}
    result = {k: <span class="hljs-built_in">round</span>(v, <span class="hljs-number">4</span>) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> result.items()}
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Epoch <span class="hljs-subst">{epoch}</span>:&quot;</span>, result)

    <span class="hljs-comment"># Sauvegarder et t\xE9l\xE9charger</span>
    accelerator.wait_for_everyone()
    unwrapped_model = accelerator.unwrap_model(model)
    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)
    <span class="hljs-keyword">if</span> accelerator.is_main_process:
        tokenizer.save_pretrained(output_dir)
        repo.push_to_hub(
            commit_message=<span class="hljs-string">f&quot;Training in progress epoch <span class="hljs-subst">{epoch}</span>&quot;</span>, blocking=<span class="hljs-literal">False</span>
        )`}}),Ns=new T({props:{code:`Epoch 0: {'rouge1': 5.6351, 'rouge2': 1.1625, 'rougeL': 5.4866, 'rougeLsum': 5.5005}
Epoch 1: {'rouge1': 9.8646, 'rouge2': 3.4106, 'rougeL': 9.9439, 'rougeLsum': 9.9306}
Epoch 2: {'rouge1': 11.0872, 'rouge2': 3.3273, 'rougeL': 11.0508, 'rougeLsum': 10.9468}
Epoch 3: {'rouge1': 11.8587, 'rouge2': 4.8167, 'rougeL': 11.7986, 'rougeLsum': 11.7518}
Epoch 4: {'rouge1': 12.9842, 'rouge2': 5.5887, 'rougeL': 12.7546, 'rougeLsum': 12.7029}
Epoch 5: {'rouge1': 13.4628, 'rouge2': 6.4598, 'rougeL': 13.312, 'rougeLsum': 13.2913}
Epoch 6: {'rouge1': 12.9131, 'rouge2': 5.8914, 'rougeL': 12.6896, 'rougeLsum': 12.5701}
Epoch 7: {'rouge1': 13.3079, 'rouge2': 6.2994, 'rougeL': 13.1536, 'rougeLsum': 13.1194}
Epoch 8: {'rouge1': 13.96, 'rouge2': 6.5998, 'rougeL': 13.9123, 'rougeLsum': 13.7744}
Epoch 9: {'rouge1': 14.1192, 'rouge2': 7.0059, 'rougeL': 14.1172, 'rougeLsum': 13.9509}`,highlighted:`Epoch <span class="hljs-number">0</span>: {<span class="hljs-string">&#x27;rouge1&#x27;</span>: <span class="hljs-number">5.6351</span>, <span class="hljs-string">&#x27;rouge2&#x27;</span>: <span class="hljs-number">1.1625</span>, <span class="hljs-string">&#x27;rougeL&#x27;</span>: <span class="hljs-number">5.4866</span>, <span class="hljs-string">&#x27;rougeLsum&#x27;</span>: <span class="hljs-number">5.5005</span>}
Epoch <span class="hljs-number">1</span>: {<span class="hljs-string">&#x27;rouge1&#x27;</span>: <span class="hljs-number">9.8646</span>, <span class="hljs-string">&#x27;rouge2&#x27;</span>: <span class="hljs-number">3.4106</span>, <span class="hljs-string">&#x27;rougeL&#x27;</span>: <span class="hljs-number">9.9439</span>, <span class="hljs-string">&#x27;rougeLsum&#x27;</span>: <span class="hljs-number">9.9306</span>}
Epoch <span class="hljs-number">2</span>: {<span class="hljs-string">&#x27;rouge1&#x27;</span>: <span class="hljs-number">11.0872</span>, <span class="hljs-string">&#x27;rouge2&#x27;</span>: <span class="hljs-number">3.3273</span>, <span class="hljs-string">&#x27;rougeL&#x27;</span>: <span class="hljs-number">11.0508</span>, <span class="hljs-string">&#x27;rougeLsum&#x27;</span>: <span class="hljs-number">10.9468</span>}
Epoch <span class="hljs-number">3</span>: {<span class="hljs-string">&#x27;rouge1&#x27;</span>: <span class="hljs-number">11.8587</span>, <span class="hljs-string">&#x27;rouge2&#x27;</span>: <span class="hljs-number">4.8167</span>, <span class="hljs-string">&#x27;rougeL&#x27;</span>: <span class="hljs-number">11.7986</span>, <span class="hljs-string">&#x27;rougeLsum&#x27;</span>: <span class="hljs-number">11.7518</span>}
Epoch <span class="hljs-number">4</span>: {<span class="hljs-string">&#x27;rouge1&#x27;</span>: <span class="hljs-number">12.9842</span>, <span class="hljs-string">&#x27;rouge2&#x27;</span>: <span class="hljs-number">5.5887</span>, <span class="hljs-string">&#x27;rougeL&#x27;</span>: <span class="hljs-number">12.7546</span>, <span class="hljs-string">&#x27;rougeLsum&#x27;</span>: <span class="hljs-number">12.7029</span>}
Epoch <span class="hljs-number">5</span>: {<span class="hljs-string">&#x27;rouge1&#x27;</span>: <span class="hljs-number">13.4628</span>, <span class="hljs-string">&#x27;rouge2&#x27;</span>: <span class="hljs-number">6.4598</span>, <span class="hljs-string">&#x27;rougeL&#x27;</span>: <span class="hljs-number">13.312</span>, <span class="hljs-string">&#x27;rougeLsum&#x27;</span>: <span class="hljs-number">13.2913</span>}
Epoch <span class="hljs-number">6</span>: {<span class="hljs-string">&#x27;rouge1&#x27;</span>: <span class="hljs-number">12.9131</span>, <span class="hljs-string">&#x27;rouge2&#x27;</span>: <span class="hljs-number">5.8914</span>, <span class="hljs-string">&#x27;rougeL&#x27;</span>: <span class="hljs-number">12.6896</span>, <span class="hljs-string">&#x27;rougeLsum&#x27;</span>: <span class="hljs-number">12.5701</span>}
Epoch <span class="hljs-number">7</span>: {<span class="hljs-string">&#x27;rouge1&#x27;</span>: <span class="hljs-number">13.3079</span>, <span class="hljs-string">&#x27;rouge2&#x27;</span>: <span class="hljs-number">6.2994</span>, <span class="hljs-string">&#x27;rougeL&#x27;</span>: <span class="hljs-number">13.1536</span>, <span class="hljs-string">&#x27;rougeLsum&#x27;</span>: <span class="hljs-number">13.1194</span>}
Epoch <span class="hljs-number">8</span>: {<span class="hljs-string">&#x27;rouge1&#x27;</span>: <span class="hljs-number">13.96</span>, <span class="hljs-string">&#x27;rouge2&#x27;</span>: <span class="hljs-number">6.5998</span>, <span class="hljs-string">&#x27;rougeL&#x27;</span>: <span class="hljs-number">13.9123</span>, <span class="hljs-string">&#x27;rougeLsum&#x27;</span>: <span class="hljs-number">13.7744</span>}
Epoch <span class="hljs-number">9</span>: {<span class="hljs-string">&#x27;rouge1&#x27;</span>: <span class="hljs-number">14.1192</span>, <span class="hljs-string">&#x27;rouge2&#x27;</span>: <span class="hljs-number">7.0059</span>, <span class="hljs-string">&#x27;rougeL&#x27;</span>: <span class="hljs-number">14.1172</span>, <span class="hljs-string">&#x27;rougeLsum&#x27;</span>: <span class="hljs-number">13.9509</span>}`}}),{c(){d=r("h2"),x=r("a"),f=r("span"),b(w.$$.fragment),P=m(),y=r("span"),S=a("*Finetuning* de mT5 avec \u{1F917} *Accelerate*"),D=m(),E=r("p"),M=a("Le "),N=r("em"),A=a("finetuning"),C=a(" de notre mod\xE8le avec \u{1F917} "),G=r("em"),L=a("Accelerate"),V=a(" est tr\xE8s similaire \xE0 l\u2019exemple de classification de texte que nous avons rencontr\xE9 dans "),W=r("a"),ee=a("Chapitre 3"),J=a(". Les principales diff\xE9rences seront la n\xE9cessit\xE9 de g\xE9n\xE9rer explicitement nos r\xE9sum\xE9s pendant l\u2019Entra\xEEnement et de d\xE9finir comment nous calculons les scores ROUGE (rappelons que le "),B=r("code"),Y=a("Seq2SeqTrainer"),le=a(" s\u2019est occup\xE9 de la g\xE9n\xE9ration pour nous). Voyons comment nous pouvons mettre en \u0153uvre ces deux exigences dans \u{1F917} "),O=r("em"),Q=a("Accelerate"),oe=a(" !"),H=m(),U=r("h3"),te=r("a"),se=r("span"),b(ie.$$.fragment),X=m(),ae=r("span"),_e=a("Pr\xE9parer tout pour l'entra\xEEnement"),ce=m(),ne=r("p"),je=a("La premi\xE8re chose que nous devons faire est de cr\xE9er un "),Re=r("code"),Pe=a("DataLoader"),F=a(" pour chacun de nos splits. Puisque les chargeurs de donn\xE9es PyTorch attendent des batchs de tenseurs, nous devons d\xE9finir le format \xE0 "),Ie=r("code"),he=a('"torch"'),re=a(" dans nos jeux de donn\xE9es :"),k=m(),b(R.$$.fragment),De=m(),ke=r("p"),Ee=a("Maintenant que nous avons des jeux de donn\xE9es constitu\xE9s uniquement de tenseurs, la prochaine chose \xE0 faire est d\u2019instancier \xE0 nouveau le "),ve=r("code"),de=a("DataCollatorForSeq2Seq"),be=a(". Pour cela, nous devons fournir une nouvelle version du mod\xE8le, donc chargeons-le \xE0 nouveau depuis notre cache :"),pe=m(),b(Se.$$.fragment),we=m(),Ue=r("p"),ls=a("Nous pouvons ensuite instancier le collateur de donn\xE9es et l\u2019utiliser pour d\xE9finir nos chargeurs de donn\xE9es :"),$e=m(),b(_.$$.fragment),K=m(),Be=r("p"),Ze=a("La prochaine chose \xE0 faire est de d\xE9finir l\u2019optimiseur que nous voulons utiliser. Comme dans nos autres exemples, nous allons utiliser "),ue=r("code"),os=a("AdamW"),is=a(", qui fonctionne bien pour la plupart des probl\xE8mes :"),ge=m(),b(Le.$$.fragment),Ke=m(),ye=r("p"),us=a("Enfin, nous introduisons notre mod\xE8le, notre optimiseur et nos chargeurs de donn\xE9es dans la m\xE9thode "),fe=r("code"),qs=a("accelerator.prepare()"),Qe=a(" :"),es=m(),b(vs.$$.fragment),js=m(),b(ss.$$.fragment),Is=m(),ts=r("p"),Gs=a("Maintenant que nous avons pr\xE9par\xE9 nos objets, il reste trois choses \xE0 faire :"),ps=m(),He=r("ul"),I=r("li"),me=a("d\xE9finir le programme du taux d\u2019apprentissage,"),$s=m(),Ss=r("li"),gs=a("impl\xE9menter une fonction pour post-traiter les r\xE9sum\xE9s pour l\u2019\xE9valuation,"),qe=m(),Ge=r("li"),Ot=a("cr\xE9er un r\xE9f\xE9rentiel sur le "),xs=r("em"),Mt=a("Hub"),Nt=a(" vers lequel nous pouvons pousser notre mod\xE8le."),Ls=m(),As=r("p"),Ae=a("Pour le programme de taux d\u2019apprentissage, nous utiliserons le programme lin\xE9aire standard des sections pr\xE9c\xE9dentes :"),Us=m(),b(Ye.$$.fragment),Hs=m(),as=r("p"),ct=a("Pour le post-traitement, nous avons besoin d\u2019une fonction qui divise les r\xE9sum\xE9s g\xE9n\xE9r\xE9s en phrases s\xE9par\xE9es par des nouvelles lignes. C\u2019est le format attendu par la m\xE9trique ROUGE, et nous pouvons y parvenir avec le bout de code suivant :"),Oe=m(),b(ks.$$.fragment),ze=m(),ns=r("p"),Rt=a("Cela devrait vous sembler familier si vous vous rappelez comment nous avons d\xE9fini la fonction "),Es=r("code"),It=a("compute_metrics()"),Gt=a(" du "),Fs=r("code"),On=a("Seq2SeqTrainer"),Mn=a("."),Ut=m(),ws=r("p"),Nn=a("Enfin, nous devons cr\xE9er un d\xE9p\xF4t de mod\xE8les sur le "),Ht=r("em"),dt=a("Hub"),Na=a(". Pour cela, nous pouvons utiliser la biblioth\xE8que \u{1F917} "),Me=r("em"),Rn=a("Hub"),pa=a(", qui porte le nom appropri\xE9. Nous avons juste besoin de d\xE9finir un nom pour notre r\xE9f\xE9rentiel, et la biblioth\xE8que a une fonction utilitaire pour combiner l\u2019ID du r\xE9f\xE9rentiel avec le profil de l\u2019utilisateur :"),Ra=m(),b(ft.$$.fragment),Ft=m(),b(ht.$$.fragment),Ia=m(),Js=r("p"),In=a("Nous pouvons maintenant utiliser ce nom de r\xE9f\xE9rentiel pour cloner une version locale dans notre r\xE9pertoire de r\xE9sultats qui stockera les artefacts d\u2019entra\xEEnement :"),Ga=m(),b(Os.$$.fragment),Ua=m(),Bs=r("p"),ma=a("This will allow us to push the artifacts back to the Hub by calling the "),ca=r("code"),Gn=a("repo.push_to_hub()"),Ha=a(" method during training! Let\u2019s now wrap up our analysis by writing out the training loop."),Vs=m(),ys=r("h3"),_s=r("a"),da=r("span"),b(Ws.$$.fragment),vt=m(),Jt=r("span"),gt=a("Boucle d'entra\xEEnement"),fa=m(),Te=r("p"),Un=a("La boucle d\u2019entra\xEEnement pour le r\xE9sum\xE9 est assez similaire aux autres exemples \u{1F917} "),_t=r("em"),Hn=a("Accelerate"),Fn=a(" que nous avons rencontr\xE9s et est grossi\xE8rement divis\xE9e en quatre \xE9tapes principales :"),Bt=m(),ms=r("ol"),bt=r("li"),ha=a("entra\xEEner le mod\xE8le en it\xE9rant sur tous les exemples dans "),va=r("code"),Jn=a("train_dataloader"),ga=a(" pour chaque \xE9poque,"),Bn=m(),qt=r("li"),Fa=a("g\xE9n\xE9rer les r\xE9sum\xE9s du mod\xE8le \xE0 la fin de chaque \xE9poque, en g\xE9n\xE9rant d\u2019abord les "),Ms=r("em"),Ja=a("tokens"),jt=a(" puis en les d\xE9codant (ainsi que les r\xE9sum\xE9s de r\xE9f\xE9rence) en texte,"),Ba=m(),Ks=r("li"),Vn=a("calculer les scores ROUGE en utilisant les m\xEAmes techniques que nous avons vues pr\xE9c\xE9demment,"),Va=m(),Ce=r("li"),$t=a("sauvegarder les points de contr\xF4le et pousser le tout vers le "),Wa=r("em"),Wn=a("Hub"),xt=a(". Ici, nous nous appuyons sur l\u2019argument "),Ka=r("code"),Qa=a("blocking=False"),Qs=a(" de l\u2019objet "),_a=r("code"),ba=a("Repository"),Kn=a(" afin de pouvoir pousser les points de contr\xF4le par \xE9poque de mani\xE8re "),qa=r("em"),Ya=a("asynchrone"),kt=a(". Cela nous permet de poursuivre l\u2019entra\xEEnement sans avoir \xE0 attendre le t\xE9l\xE9chargement quelque peu lent associ\xE9 \xE0 un mod\xE8le de la taille d\u2019un Go !"),ja=m(),rs=r("p"),Qn=a("Ces \xE9tapes peuvent \xEAtre vues dans le bloc de code suivant :"),Vt=m(),b(Et.$$.fragment),Xa=m(),b(Ns.$$.fragment),Za=m(),Ys=r("p"),en=a("Et c\u2019est tout ! Une fois que vous l\u2019aurez ex\xE9cut\xE9, vous aurez un mod\xE8le et des r\xE9sultats assez similaires \xE0 ceux que nous avons obtenus avec le "),bs=r("code"),Xs=a("Trainer"),$a=a("."),this.h()},l(p){d=l(p,"H2",{class:!0});var z=o(d);x=l(z,"A",{id:!0,class:!0,href:!0});var Yr=o(x);f=l(Yr,"SPAN",{});var Yn=o(f);q(w.$$.fragment,Yn),Yn.forEach(t),Yr.forEach(t),P=c(z),y=l(z,"SPAN",{});var Rs=o(y);S=n(Rs,"*Finetuning* de mT5 avec \u{1F917} *Accelerate*"),Rs.forEach(t),z.forEach(t),D=c(p),E=l(p,"P",{});var cs=o(E);M=n(cs,"Le "),N=l(cs,"EM",{});var xa=o(N);A=n(xa,"finetuning"),xa.forEach(t),C=n(cs," de notre mod\xE8le avec \u{1F917} "),G=l(cs,"EM",{});var Xr=o(G);L=n(Xr,"Accelerate"),Xr.forEach(t),V=n(cs," est tr\xE8s similaire \xE0 l\u2019exemple de classification de texte que nous avons rencontr\xE9 dans "),W=l(cs,"A",{href:!0});var Zr=o(W);ee=n(Zr,"Chapitre 3"),Zr.forEach(t),J=n(cs,". Les principales diff\xE9rences seront la n\xE9cessit\xE9 de g\xE9n\xE9rer explicitement nos r\xE9sum\xE9s pendant l\u2019Entra\xEEnement et de d\xE9finir comment nous calculons les scores ROUGE (rappelons que le "),B=l(cs,"CODE",{});var sn=o(B);Y=n(sn,"Seq2SeqTrainer"),sn.forEach(t),le=n(cs," s\u2019est occup\xE9 de la g\xE9n\xE9ration pour nous). Voyons comment nous pouvons mettre en \u0153uvre ces deux exigences dans \u{1F917} "),O=l(cs,"EM",{});var el=o(O);Q=n(el,"Accelerate"),el.forEach(t),oe=n(cs," !"),cs.forEach(t),H=c(p),U=l(p,"H3",{class:!0});var tn=o(U);te=l(tn,"A",{id:!0,class:!0,href:!0});var Xn=o(te);se=l(Xn,"SPAN",{});var wt=o(se);q(ie.$$.fragment,wt),wt.forEach(t),Xn.forEach(t),X=c(tn),ae=l(tn,"SPAN",{});var an=o(ae);_e=n(an,"Pr\xE9parer tout pour l'entra\xEEnement"),an.forEach(t),tn.forEach(t),ce=c(p),ne=l(p,"P",{});var ds=o(ne);je=n(ds,"La premi\xE8re chose que nous devons faire est de cr\xE9er un "),Re=l(ds,"CODE",{});var ka=o(Re);Pe=n(ka,"DataLoader"),ka.forEach(t),F=n(ds," pour chacun de nos splits. Puisque les chargeurs de donn\xE9es PyTorch attendent des batchs de tenseurs, nous devons d\xE9finir le format \xE0 "),Ie=l(ds,"CODE",{});var nn=o(Ie);he=n(nn,'"torch"'),nn.forEach(t),re=n(ds," dans nos jeux de donn\xE9es :"),ds.forEach(t),k=c(p),q(R.$$.fragment,p),De=c(p),ke=l(p,"P",{});var rn=o(ke);Ee=n(rn,"Maintenant que nous avons des jeux de donn\xE9es constitu\xE9s uniquement de tenseurs, la prochaine chose \xE0 faire est d\u2019instancier \xE0 nouveau le "),ve=l(rn,"CODE",{});var sl=o(ve);de=n(sl,"DataCollatorForSeq2Seq"),sl.forEach(t),be=n(rn,". Pour cela, nous devons fournir une nouvelle version du mod\xE8le, donc chargeons-le \xE0 nouveau depuis notre cache :"),rn.forEach(t),pe=c(p),q(Se.$$.fragment,p),we=c(p),Ue=l(p,"P",{});var ln=o(Ue);ls=n(ln,"Nous pouvons ensuite instancier le collateur de donn\xE9es et l\u2019utiliser pour d\xE9finir nos chargeurs de donn\xE9es :"),ln.forEach(t),$e=c(p),q(_.$$.fragment,p),K=c(p),Be=l(p,"P",{});var on=o(Be);Ze=n(on,"La prochaine chose \xE0 faire est de d\xE9finir l\u2019optimiseur que nous voulons utiliser. Comme dans nos autres exemples, nous allons utiliser "),ue=l(on,"CODE",{});var tl=o(ue);os=n(tl,"AdamW"),tl.forEach(t),is=n(on,", qui fonctionne bien pour la plupart des probl\xE8mes :"),on.forEach(t),ge=c(p),q(Le.$$.fragment,p),Ke=c(p),ye=l(p,"P",{});var yt=o(ye);us=n(yt,"Enfin, nous introduisons notre mod\xE8le, notre optimiseur et nos chargeurs de donn\xE9es dans la m\xE9thode "),fe=l(yt,"CODE",{});var al=o(fe);qs=n(al,"accelerator.prepare()"),al.forEach(t),Qe=n(yt," :"),yt.forEach(t),es=c(p),q(vs.$$.fragment,p),js=c(p),q(ss.$$.fragment,p),Is=c(p),ts=l(p,"P",{});var nl=o(ts);Gs=n(nl,"Maintenant que nous avons pr\xE9par\xE9 nos objets, il reste trois choses \xE0 faire :"),nl.forEach(t),ps=c(p),He=l(p,"UL",{});var Ne=o(He);I=l(Ne,"LI",{});var et=o(I);me=n(et,"d\xE9finir le programme du taux d\u2019apprentissage,"),et.forEach(t),$s=c(Ne),Ss=l(Ne,"LI",{});var Ea=o(Ss);gs=n(Ea,"impl\xE9menter une fonction pour post-traiter les r\xE9sum\xE9s pour l\u2019\xE9valuation,"),Ea.forEach(t),qe=c(Ne),Ge=l(Ne,"LI",{});var st=o(Ge);Ot=n(st,"cr\xE9er un r\xE9f\xE9rentiel sur le "),xs=l(st,"EM",{});var rl=o(xs);Mt=n(rl,"Hub"),rl.forEach(t),Nt=n(st," vers lequel nous pouvons pousser notre mod\xE8le."),st.forEach(t),Ne.forEach(t),Ls=c(p),As=l(p,"P",{});var ll=o(As);Ae=n(ll,"Pour le programme de taux d\u2019apprentissage, nous utiliserons le programme lin\xE9aire standard des sections pr\xE9c\xE9dentes :"),ll.forEach(t),Us=c(p),q(Ye.$$.fragment,p),Hs=c(p),as=l(p,"P",{});var un=o(as);ct=n(un,"Pour le post-traitement, nous avons besoin d\u2019une fonction qui divise les r\xE9sum\xE9s g\xE9n\xE9r\xE9s en phrases s\xE9par\xE9es par des nouvelles lignes. C\u2019est le format attendu par la m\xE9trique ROUGE, et nous pouvons y parvenir avec le bout de code suivant :"),un.forEach(t),Oe=c(p),q(ks.$$.fragment,p),ze=c(p),ns=l(p,"P",{});var Wt=o(ns);Rt=n(Wt,"Cela devrait vous sembler familier si vous vous rappelez comment nous avons d\xE9fini la fonction "),Es=l(Wt,"CODE",{});var ol=o(Es);It=n(ol,"compute_metrics()"),ol.forEach(t),Gt=n(Wt," du "),Fs=l(Wt,"CODE",{});var wa=o(Fs);On=n(wa,"Seq2SeqTrainer"),wa.forEach(t),Mn=n(Wt,"."),Wt.forEach(t),Ut=c(p),ws=l(p,"P",{});var Kt=o(ws);Nn=n(Kt,"Enfin, nous devons cr\xE9er un d\xE9p\xF4t de mod\xE8les sur le "),Ht=l(Kt,"EM",{});var il=o(Ht);dt=n(il,"Hub"),il.forEach(t),Na=n(Kt,". Pour cela, nous pouvons utiliser la biblioth\xE8que \u{1F917} "),Me=l(Kt,"EM",{});var tt=o(Me);Rn=n(tt,"Hub"),tt.forEach(t),pa=n(Kt,", qui porte le nom appropri\xE9. Nous avons juste besoin de d\xE9finir un nom pour notre r\xE9f\xE9rentiel, et la biblioth\xE8que a une fonction utilitaire pour combiner l\u2019ID du r\xE9f\xE9rentiel avec le profil de l\u2019utilisateur :"),Kt.forEach(t),Ra=c(p),q(ft.$$.fragment,p),Ft=c(p),q(ht.$$.fragment,p),Ia=c(p),Js=l(p,"P",{});var ya=o(Js);In=n(ya,"Nous pouvons maintenant utiliser ce nom de r\xE9f\xE9rentiel pour cloner une version locale dans notre r\xE9pertoire de r\xE9sultats qui stockera les artefacts d\u2019entra\xEEnement :"),ya.forEach(t),Ga=c(p),q(Os.$$.fragment,p),Ua=c(p),Bs=l(p,"P",{});var at=o(Bs);ma=n(at,"This will allow us to push the artifacts back to the Hub by calling the "),ca=l(at,"CODE",{});var ul=o(ca);Gn=n(ul,"repo.push_to_hub()"),ul.forEach(t),Ha=n(at," method during training! Let\u2019s now wrap up our analysis by writing out the training loop."),at.forEach(t),Vs=c(p),ys=l(p,"H3",{class:!0});var pn=o(ys);_s=l(pn,"A",{id:!0,class:!0,href:!0});var mn=o(_s);da=l(mn,"SPAN",{});var pl=o(da);q(Ws.$$.fragment,pl),pl.forEach(t),mn.forEach(t),vt=c(pn),Jt=l(pn,"SPAN",{});var ml=o(Jt);gt=n(ml,"Boucle d'entra\xEEnement"),ml.forEach(t),pn.forEach(t),fa=c(p),Te=l(p,"P",{});var zt=o(Te);Un=n(zt,"La boucle d\u2019entra\xEEnement pour le r\xE9sum\xE9 est assez similaire aux autres exemples \u{1F917} "),_t=l(zt,"EM",{});var cl=o(_t);Hn=n(cl,"Accelerate"),cl.forEach(t),Fn=n(zt," que nous avons rencontr\xE9s et est grossi\xE8rement divis\xE9e en quatre \xE9tapes principales :"),zt.forEach(t),Bt=c(p),ms=l(p,"OL",{});var nt=o(ms);bt=l(nt,"LI",{});var zs=o(bt);ha=n(zs,"entra\xEEner le mod\xE8le en it\xE9rant sur tous les exemples dans "),va=l(zs,"CODE",{});var za=o(va);Jn=n(za,"train_dataloader"),za.forEach(t),ga=n(zs," pour chaque \xE9poque,"),zs.forEach(t),Bn=c(nt),qt=l(nt,"LI",{});var rt=o(qt);Fa=n(rt,"g\xE9n\xE9rer les r\xE9sum\xE9s du mod\xE8le \xE0 la fin de chaque \xE9poque, en g\xE9n\xE9rant d\u2019abord les "),Ms=l(rt,"EM",{});var dl=o(Ms);Ja=n(dl,"tokens"),dl.forEach(t),jt=n(rt," puis en les d\xE9codant (ainsi que les r\xE9sum\xE9s de r\xE9f\xE9rence) en texte,"),rt.forEach(t),Ba=c(nt),Ks=l(nt,"LI",{});var fl=o(Ks);Vn=n(fl,"calculer les scores ROUGE en utilisant les m\xEAmes techniques que nous avons vues pr\xE9c\xE9demment,"),fl.forEach(t),Va=c(nt),Ce=l(nt,"LI",{});var Fe=o(Ce);$t=n(Fe,"sauvegarder les points de contr\xF4le et pousser le tout vers le "),Wa=l(Fe,"EM",{});var hl=o(Wa);Wn=n(hl,"Hub"),hl.forEach(t),xt=n(Fe,". Ici, nous nous appuyons sur l\u2019argument "),Ka=l(Fe,"CODE",{});var cn=o(Ka);Qa=n(cn,"blocking=False"),cn.forEach(t),Qs=n(Fe," de l\u2019objet "),_a=l(Fe,"CODE",{});var vl=o(_a);ba=n(vl,"Repository"),vl.forEach(t),Kn=n(Fe," afin de pouvoir pousser les points de contr\xF4le par \xE9poque de mani\xE8re "),qa=l(Fe,"EM",{});var gl=o(qa);Ya=n(gl,"asynchrone"),gl.forEach(t),kt=n(Fe,". Cela nous permet de poursuivre l\u2019entra\xEEnement sans avoir \xE0 attendre le t\xE9l\xE9chargement quelque peu lent associ\xE9 \xE0 un mod\xE8le de la taille d\u2019un Go !"),Fe.forEach(t),nt.forEach(t),ja=c(p),rs=l(p,"P",{});var dn=o(rs);Qn=n(dn,"Ces \xE9tapes peuvent \xEAtre vues dans le bloc de code suivant :"),dn.forEach(t),Vt=c(p),q(Et.$$.fragment,p),Xa=c(p),q(Ns.$$.fragment,p),Za=c(p),Ys=l(p,"P",{});var fn=o(Ys);en=n(fn,"Et c\u2019est tout ! Une fois que vous l\u2019aurez ex\xE9cut\xE9, vous aurez un mod\xE8le et des r\xE9sultats assez similaires \xE0 ceux que nous avons obtenus avec le "),bs=l(fn,"CODE",{});var _l=o(bs);Xs=n(_l,"Trainer"),_l.forEach(t),$a=n(fn,"."),fn.forEach(t),this.h()},h(){h(x,"id","finetuning-de-mt5-avec-accelerate"),h(x,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(x,"href","#finetuning-de-mt5-avec-accelerate"),h(d,"class","relative group"),h(W,"href","/course/fr/chapter3"),h(te,"id","prparer-tout-pour-lentranement"),h(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(te,"href","#prparer-tout-pour-lentranement"),h(U,"class","relative group"),h(_s,"id","boucle-dentranement"),h(_s,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(_s,"href","#boucle-dentranement"),h(ys,"class","relative group")},m(p,z){i(p,d,z),s(d,x),s(x,f),j(w,f,null),s(d,P),s(d,y),s(y,S),i(p,D,z),i(p,E,z),s(E,M),s(E,N),s(N,A),s(E,C),s(E,G),s(G,L),s(E,V),s(E,W),s(W,ee),s(E,J),s(E,B),s(B,Y),s(E,le),s(E,O),s(O,Q),s(E,oe),i(p,H,z),i(p,U,z),s(U,te),s(te,se),j(ie,se,null),s(U,X),s(U,ae),s(ae,_e),i(p,ce,z),i(p,ne,z),s(ne,je),s(ne,Re),s(Re,Pe),s(ne,F),s(ne,Ie),s(Ie,he),s(ne,re),i(p,k,z),j(R,p,z),i(p,De,z),i(p,ke,z),s(ke,Ee),s(ke,ve),s(ve,de),s(ke,be),i(p,pe,z),j(Se,p,z),i(p,we,z),i(p,Ue,z),s(Ue,ls),i(p,$e,z),j(_,p,z),i(p,K,z),i(p,Be,z),s(Be,Ze),s(Be,ue),s(ue,os),s(Be,is),i(p,ge,z),j(Le,p,z),i(p,Ke,z),i(p,ye,z),s(ye,us),s(ye,fe),s(fe,qs),s(ye,Qe),i(p,es,z),j(vs,p,z),i(p,js,z),j(ss,p,z),i(p,Is,z),i(p,ts,z),s(ts,Gs),i(p,ps,z),i(p,He,z),s(He,I),s(I,me),s(He,$s),s(He,Ss),s(Ss,gs),s(He,qe),s(He,Ge),s(Ge,Ot),s(Ge,xs),s(xs,Mt),s(Ge,Nt),i(p,Ls,z),i(p,As,z),s(As,Ae),i(p,Us,z),j(Ye,p,z),i(p,Hs,z),i(p,as,z),s(as,ct),i(p,Oe,z),j(ks,p,z),i(p,ze,z),i(p,ns,z),s(ns,Rt),s(ns,Es),s(Es,It),s(ns,Gt),s(ns,Fs),s(Fs,On),s(ns,Mn),i(p,Ut,z),i(p,ws,z),s(ws,Nn),s(ws,Ht),s(Ht,dt),s(ws,Na),s(ws,Me),s(Me,Rn),s(ws,pa),i(p,Ra,z),j(ft,p,z),i(p,Ft,z),j(ht,p,z),i(p,Ia,z),i(p,Js,z),s(Js,In),i(p,Ga,z),j(Os,p,z),i(p,Ua,z),i(p,Bs,z),s(Bs,ma),s(Bs,ca),s(ca,Gn),s(Bs,Ha),i(p,Vs,z),i(p,ys,z),s(ys,_s),s(_s,da),j(Ws,da,null),s(ys,vt),s(ys,Jt),s(Jt,gt),i(p,fa,z),i(p,Te,z),s(Te,Un),s(Te,_t),s(_t,Hn),s(Te,Fn),i(p,Bt,z),i(p,ms,z),s(ms,bt),s(bt,ha),s(bt,va),s(va,Jn),s(bt,ga),s(ms,Bn),s(ms,qt),s(qt,Fa),s(qt,Ms),s(Ms,Ja),s(qt,jt),s(ms,Ba),s(ms,Ks),s(Ks,Vn),s(ms,Va),s(ms,Ce),s(Ce,$t),s(Ce,Wa),s(Wa,Wn),s(Ce,xt),s(Ce,Ka),s(Ka,Qa),s(Ce,Qs),s(Ce,_a),s(_a,ba),s(Ce,Kn),s(Ce,qa),s(qa,Ya),s(Ce,kt),i(p,ja,z),i(p,rs,z),s(rs,Qn),i(p,Vt,z),j(Et,p,z),i(p,Xa,z),j(Ns,p,z),i(p,Za,z),i(p,Ys,z),s(Ys,en),s(Ys,bs),s(bs,Xs),s(Ys,$a),Zs=!0},i(p){Zs||(v(w.$$.fragment,p),v(ie.$$.fragment,p),v(R.$$.fragment,p),v(Se.$$.fragment,p),v(_.$$.fragment,p),v(Le.$$.fragment,p),v(vs.$$.fragment,p),v(ss.$$.fragment,p),v(Ye.$$.fragment,p),v(ks.$$.fragment,p),v(ft.$$.fragment,p),v(ht.$$.fragment,p),v(Os.$$.fragment,p),v(Ws.$$.fragment,p),v(Et.$$.fragment,p),v(Ns.$$.fragment,p),Zs=!0)},o(p){g(w.$$.fragment,p),g(ie.$$.fragment,p),g(R.$$.fragment,p),g(Se.$$.fragment,p),g(_.$$.fragment,p),g(Le.$$.fragment,p),g(vs.$$.fragment,p),g(ss.$$.fragment,p),g(Ye.$$.fragment,p),g(ks.$$.fragment,p),g(ft.$$.fragment,p),g(ht.$$.fragment,p),g(Os.$$.fragment,p),g(Ws.$$.fragment,p),g(Et.$$.fragment,p),g(Ns.$$.fragment,p),Zs=!1},d(p){p&&t(d),$(w),p&&t(D),p&&t(E),p&&t(H),p&&t(U),$(ie),p&&t(ce),p&&t(ne),p&&t(k),$(R,p),p&&t(De),p&&t(ke),p&&t(pe),$(Se,p),p&&t(we),p&&t(Ue),p&&t($e),$(_,p),p&&t(K),p&&t(Be),p&&t(ge),$(Le,p),p&&t(Ke),p&&t(ye),p&&t(es),$(vs,p),p&&t(js),$(ss,p),p&&t(Is),p&&t(ts),p&&t(ps),p&&t(He),p&&t(Ls),p&&t(As),p&&t(Us),$(Ye,p),p&&t(Hs),p&&t(as),p&&t(Oe),$(ks,p),p&&t(ze),p&&t(ns),p&&t(Ut),p&&t(ws),p&&t(Ra),$(ft,p),p&&t(Ft),$(ht,p),p&&t(Ia),p&&t(Js),p&&t(Ga),$(Os,p),p&&t(Ua),p&&t(Bs),p&&t(Vs),p&&t(ys),$(Ws),p&&t(fa),p&&t(Te),p&&t(Bt),p&&t(ms),p&&t(ja),p&&t(rs),p&&t(Vt),$(Et,p),p&&t(Xa),$(Ns,p),p&&t(Za),p&&t(Ys)}}}function v_(Z){let d,x,f,w,P;return{c(){d=r("p"),x=a("\u{1F6A8} Si vous vous entra\xEEnez sur un TPU, vous devrez d\xE9placer tout le code ci-dessus dans une fonction d\u2019entra\xEEnement d\xE9di\xE9e. Voir le "),f=r("a"),w=a("Chapitre 3"),P=a(" pour plus de d\xE9tails."),this.h()},l(y){d=l(y,"P",{});var S=o(d);x=n(S,"\u{1F6A8} Si vous vous entra\xEEnez sur un TPU, vous devrez d\xE9placer tout le code ci-dessus dans une fonction d\u2019entra\xEEnement d\xE9di\xE9e. Voir le "),f=l(S,"A",{href:!0});var D=o(f);w=n(D,"Chapitre 3"),D.forEach(t),P=n(S," pour plus de d\xE9tails."),S.forEach(t),this.h()},h(){h(f,"href","/course/fr/chapter3")},m(y,S){i(y,d,S),s(d,x),s(d,f),s(f,w),s(d,P)},d(y){y&&t(d)}}}function g_(Z){let d,x,f,w,P,y,S,D,E,M,N,A,C,G,L,V,W,ee,J,B,Y,le,O,Q,oe,H,U,te,se,ie,X,ae,_e,ce,ne,je,Re,Pe,F,Ie,he,re,k,R,De,ke,Ee,ve,de,be,pe,Se,we,Ue,ls,$e,_,K,Be,Ze,ue,os,is,ge,Le,Ke,ye,us,fe,qs,Qe,es,vs,js,ss,Is,ts,Gs,ps,He,I,me,$s,Ss,gs,qe,Ge,Ot,xs,Mt,Nt,Ls,As,Ae,Us,Ye,Hs,as,ct,Oe,ks,ze,ns,Rt,Es,It,Gt,Fs,On,Mn,Ut,ws,Nn,Ht,dt,Na,Me,Rn,pa,Ra,ft,Ft,ht,Ia,Js,In,Ga,Os,Ua,Bs,ma,ca,Gn,Ha,Vs,ys,_s,da,Ws,vt,Jt,gt,fa,Te,Un,_t,Hn,Fn,Bt,ms,bt,ha,va,Jn,ga,Bn,qt,Fa,Ms,Ja,jt,Ba,Ks,Vn,Va,Ce,$t,Wa,Wn,xt,Ka,Qa,Qs,_a,ba,Kn,qa,Ya,kt,ja,rs,Qn,Vt,Et,Xa,Ns,Za,Ys,en,bs,Xs,$a,Zs,p,z,Yr,Yn,Rs,cs,xa,Xr,Zr,sn,el,tn,Xn,wt,an,ds,ka,nn,rn,sl,ln,on,tl,yt,al,nl,Ne,et,Ea,st,rl,ll,un,Wt,ol,wa,Kt,il,tt,ya,at,ul,pn,mn,pl,ml,zt,cl,nt,zs,za,rt,dl,fl,Fe,hl,cn,vl,gl,dn,fn,_l,Vp,bl,Wp,Kp,Ta,ql,Zn,Qp,Yp,xo,Xp,Zp,jl,em,sm,Ca,$l,er,tm,am,sr,nm,ko,rm,lm,om,xl,im,um,Pa,kl,tr,pm,mm,Eo,cm,dm,El,fm,Vi,wl,hm,Wi,hn,vm,wo,gm,_m,Ki,Da,ar,Rf,bm,nr,If,Qi,yl,qm,Yi,vn,Xi,Sa,gn,yo,rr,jm,zo,$m,Zi,lr,eu,Qt,xm,To,km,Em,Co,wm,ym,su,or,tu,_n,au,bn,zm,Po,Tm,Cm,nu,ir,ru,ur,lu,Ts,Pm,Do,Dm,Sm,So,Lm,Am,zl,Om,Mm,Lo,Nm,Rm,ou,pr,iu,mr,uu,fs,Im,Ao,Gm,Um,Oo,Hm,Fm,Mo,Jm,Bm,No,Vm,Wm,Tl,Km,Qm,pu,Yt,Ym,Ro,Xm,Zm,Io,ec,sc,mu,cr,cu,Cs,tc,Go,ac,nc,Uo,rc,lc,Ho,oc,ic,Fo,uc,pc,du,Xt,mc,Jo,cc,dc,Bo,fc,hc,fu,dr,hu,Cl,vc,vu,qn,gu,La,jn,Vo,fr,gc,Wo,_c,_u,hr,bu,Pl,bc,qu,$n,qc,vr,jc,$c,ju,gr,$u,Zt,xc,Ko,kc,Ec,Qo,wc,yc,xu,xn,ku,_r,zc,Eu,Vg='<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">R</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">l</mi></mrow><mo>=</mo><mfrac><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">b</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mtext>\u2009</mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">f</mi><mtext>\u2009</mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">v</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">g</mi><mtext>\u2009</mtext><mi mathvariant="normal">w</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">s</mi></mrow><mrow><mi mathvariant="normal">T</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mtext>\u2009</mtext><mi mathvariant="normal">n</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">b</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mtext>\u2009</mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">f</mi><mtext>\u2009</mtext><mi mathvariant="normal">w</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">s</mi><mtext>\u2009</mtext><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mtext>\u2009</mtext><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">f</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">e</mi><mtext>\u2009</mtext><mi mathvariant="normal">s</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">y</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex"> \\mathrm{Recall} = \\frac{\\mathrm{Number\\,of\\,overlapping\\, words}}{\\mathrm{Total\\, number\\, of\\, words\\, in\\, reference\\, summary}} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord"><span class="mord mathrm">Recall</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2519em;vertical-align:-0.8804em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">Total</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm">number</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm" style="margin-right:0.07778em;">of</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm">words</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm">in</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm">reference</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm" style="margin-right:0.01389em;">summary</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">Number</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm" style="margin-right:0.07778em;">of</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm" style="margin-right:0.01389em;">overlapping</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm">words</span></span></span></span></span><span class="vlist-s">\u200B</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>',wu,br,Tc,yu,Wg='<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">P</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi></mrow><mo>=</mo><mfrac><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">b</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mtext>\u2009</mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">f</mi><mtext>\u2009</mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">v</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">g</mi><mtext>\u2009</mtext><mi mathvariant="normal">w</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">s</mi></mrow><mrow><mi mathvariant="normal">T</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mtext>\u2009</mtext><mi mathvariant="normal">n</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">b</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mtext>\u2009</mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">f</mi><mtext>\u2009</mtext><mi mathvariant="normal">w</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">s</mi><mtext>\u2009</mtext><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi><mtext>\u2009</mtext><mi mathvariant="normal">g</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">d</mi><mtext>\u2009</mtext><mi mathvariant="normal">s</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">y</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex"> \\mathrm{Precision} = \\frac{\\mathrm{Number\\,of\\,overlapping\\, words}}{\\mathrm{Total\\, number\\, of\\, words\\, in\\, generated\\, summary}} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"><span class="mord mathrm">Precision</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2519em;vertical-align:-0.8804em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">Total</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm">number</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm" style="margin-right:0.07778em;">of</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm">words</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm">in</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm">generated</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm" style="margin-right:0.01389em;">summary</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">Number</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm" style="margin-right:0.07778em;">of</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm" style="margin-right:0.01389em;">overlapping</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathrm">words</span></span></span></span></span><span class="vlist-s">\u200B</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>',zu,ea,Cc,Yo,Pc,Dc,Xo,Sc,Lc,Tu,qr,Cu,Dl,Ac,Pu,jr,Du,kn,Oc,Zo,Mc,Nc,Su,$r,Lu,xr,Au,Xe,Rc,ei,Ic,Gc,si,Uc,Hc,ti,Fc,Jc,ai,Bc,Vc,ni,Wc,Kc,ri,Qc,Yc,Ou,kr,Mu,Er,Nu,hs,Xc,li,Zc,ed,oi,sd,td,ii,ad,nd,ui,rd,ld,pi,od,id,Ru,En,Iu,Sl,ud,Gu,Aa,wn,mi,wr,pd,ci,md,Uu,lt,cd,di,dd,fd,fi,hd,vd,hi,gd,_d,Hu,yr,Fu,Ll,bd,Ju,zr,Bu,sa,qd,vi,jd,$d,gi,xd,kd,Vu,Tr,Wu,Cr,Ku,Al,Ed,Qu,Pr,Yu,Ol,wd,Xu,Dr,Zu,Sr,ep,yn,yd,_i,zd,Td,sp,Tt,Ct,Ml,zn,tp,ta,Cd,bi,Pd,Dd,qi,Sd,Ld,ap,Lr,np,Tn,Ad,ji,Od,Md,rp,Ar,lp,Nl,Cn,Nd,Rl,Rd,Id,op,Ps,Gd,$i,Ud,Hd,xi,Fd,Jd,ki,Bd,Vd,Ei,Wd,Kd,ip,Pt,Dt,Il,Gl,Qd,up,Or,pp,aa,Yd,wi,Xd,Zd,yi,ef,sf,mp,Mr,cp,Nr,dp,xe,tf,zi,af,nf,Ti,rf,lf,Ci,of,uf,Pi,pf,mf,Di,cf,df,Si,ff,hf,Li,vf,gf,Ai,_f,bf,Oi,qf,jf,fp,St,Lt,Ul,Hl,Oa,Pn,Mi,Rr,$f,Ni,xf,hp,na,kf,Ri,Ef,wf,Ii,yf,zf,vp,Ir,gp,Fl,Tf,_p,Gr,bp,Jl,Cf,qp,Ur,jp,Hr,$p,Dn,Pf,Gi,Df,Sf,xp,Fr,kp,Jr,Ep,Bl,Lf,wp,Vl,Af,yp;f=new e_({props:{fw:Z[0]}}),D=new mt({});const Gf=[t_,s_],Br=[];function Uf(e,u){return e[0]==="pt"?0:1}C=Uf(Z),G=Br[C]=Gf[C](Z),oe=new Nf({props:{id:"yHnr5Dk2zCI"}}),pe=new mt({}),Le=new T({props:{code:`from datasets import load_dataset

spanish_dataset = load_dataset("amazon_reviews_multi", "es")
english_dataset = load_dataset("amazon_reviews_multi", "en")
english_dataset`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

spanish_dataset = load_dataset(<span class="hljs-string">&quot;amazon_reviews_multi&quot;</span>, <span class="hljs-string">&quot;es&quot;</span>)
english_dataset = load_dataset(<span class="hljs-string">&quot;amazon_reviews_multi&quot;</span>, <span class="hljs-string">&quot;en&quot;</span>)
english_dataset`}}),ye=new T({props:{code:`DatasetDict({
    train: Dataset({
        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],
        num_rows: 200000
    })
    validation: Dataset({
        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],
        num_rows: 5000
    })
    test: Dataset({
        features: ['review_id', 'product_id', 'reviewer_id', 'stars', 'review_body', 'review_title', 'language', 'product_category'],
        num_rows: 5000
    })
})`,highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;review_id&#x27;</span>, <span class="hljs-string">&#x27;product_id&#x27;</span>, <span class="hljs-string">&#x27;reviewer_id&#x27;</span>, <span class="hljs-string">&#x27;stars&#x27;</span>, <span class="hljs-string">&#x27;review_body&#x27;</span>, <span class="hljs-string">&#x27;review_title&#x27;</span>, <span class="hljs-string">&#x27;language&#x27;</span>, <span class="hljs-string">&#x27;product_category&#x27;</span>],
        num_rows: <span class="hljs-number">200000</span>
    })
    validation: Dataset({
        features: [<span class="hljs-string">&#x27;review_id&#x27;</span>, <span class="hljs-string">&#x27;product_id&#x27;</span>, <span class="hljs-string">&#x27;reviewer_id&#x27;</span>, <span class="hljs-string">&#x27;stars&#x27;</span>, <span class="hljs-string">&#x27;review_body&#x27;</span>, <span class="hljs-string">&#x27;review_title&#x27;</span>, <span class="hljs-string">&#x27;language&#x27;</span>, <span class="hljs-string">&#x27;product_category&#x27;</span>],
        num_rows: <span class="hljs-number">5000</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;review_id&#x27;</span>, <span class="hljs-string">&#x27;product_id&#x27;</span>, <span class="hljs-string">&#x27;reviewer_id&#x27;</span>, <span class="hljs-string">&#x27;stars&#x27;</span>, <span class="hljs-string">&#x27;review_body&#x27;</span>, <span class="hljs-string">&#x27;review_title&#x27;</span>, <span class="hljs-string">&#x27;language&#x27;</span>, <span class="hljs-string">&#x27;product_category&#x27;</span>],
        num_rows: <span class="hljs-number">5000</span>
    })
})`}}),I=new T({props:{code:`def show_samples(dataset, num_samples=3, seed=42):
    sample = dataset["train"].shuffle(seed=seed).select(range(num_samples))
    for example in sample:
        print(f"\\n'>> Title: {example['review_title']}'")
        print(f"'>> Review: {example['review_body']}'")


show_samples(english_dataset)`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">show_samples</span>(<span class="hljs-params">dataset, num_samples=<span class="hljs-number">3</span>, seed=<span class="hljs-number">42</span></span>):
    sample = dataset[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=seed).select(<span class="hljs-built_in">range</span>(num_samples))
    <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> sample:
        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;\\n&#x27;&gt;&gt; Title: <span class="hljs-subst">{example[<span class="hljs-string">&#x27;review_title&#x27;</span>]}</span>&#x27;&quot;</span>)
        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;&#x27;&gt;&gt; Review: <span class="hljs-subst">{example[<span class="hljs-string">&#x27;review_body&#x27;</span>]}</span>&#x27;&quot;</span>)


show_samples(english_dataset)`}}),$s=new T({props:{code:`'>> Title: Worked in front position, not rear' # Travaill\xE9 en position avant, pas arri\xE8re
'>> Review: 3 stars because these are not rear brakes as stated in the item description. At least the mount adapter only worked on the front fork of the bike that I got it for.'
# 3 \xE9toiles car ce ne sont pas des freins arri\xE8re comme indiqu\xE9 dans la description de l'article. Au moins, l'adaptateur de montage ne fonctionnait que sur la fourche avant du v\xE9lo pour lequel je l'ai achet\xE9.''

'>> Title: meh'
'>> Review: Does it\u2019s job and it\u2019s gorgeous but mine is falling apart, I had to basically put it together again with hot glue'
# Il fait son travail et il est magnifique mais le mien est en train de tomber en morceaux, j'ai d\xFB le recoller avec de la colle chaude.

'>> Title: Can\\'t beat these for the money' # On ne peut pas faire mieux pour le prix
'>> Review: Bought this for handling miscellaneous aircraft parts and hanger "stuff" that I needed to organize; it really fit the bill. The unit arrived quickly, was well packaged and arrived intact (always a good sign). There are five wall mounts-- three on the top and two on the bottom. I wanted to mount it on the wall, so all I had to do was to remove the top two layers of plastic drawers, as well as the bottom corner drawers, place it when I wanted and mark it; I then used some of the new plastic screw in wall anchors (the 50 pound variety) and it easily mounted to the wall. Some have remarked that they wanted dividers for the drawers, and that they made those. Good idea. My application was that I needed something that I can see the contents at about eye level, so I wanted the fuller-sized drawers. I also like that these are the new plastic that doesn\\'t get brittle and split like my older plastic drawers did. I like the all-plastic construction. It\\'s heavy duty enough to hold metal parts, but being made of plastic it\\'s not as heavy as a metal frame, so you can easily mount it to the wall and still load it up with heavy stuff, or light stuff. No problem there. For the money, you can\\'t beat it. Best one of these I\\'ve bought to date-- and I\\'ve been using some version of these for over forty years.'
# Je l'ai achet\xE9 pour manipuler diverses pi\xE8ces d'avion et des "trucs" de hangar que je devais organiser ; il a vraiment fait l'affaire. L'unit\xE9 est arriv\xE9e rapidement, \xE9tait bien emball\xE9e et est arriv\xE9e intacte (toujours un bon signe). Il y a cinq supports muraux - trois sur le dessus et deux sur le dessous. Je voulais le monter sur le mur, alors tout ce que j'ai eu \xE0 faire \xE9tait d'enlever les deux couches sup\xE9rieures de tiroirs en plastique, ainsi que les tiroirs d'angle inf\xE9rieurs, de le placer o\xF9 je voulais et de le marquer ; j'ai ensuite utilis\xE9 quelques-uns des nouveaux ancrages muraux \xE0 vis en plastique (la vari\xE9t\xE9 de 50 livres) et il s'est facilement mont\xE9 sur le mur. Certains ont fait remarquer qu'ils voulaient des s\xE9parateurs pour les tiroirs, et qu'ils les ont fabriqu\xE9s. Bonne id\xE9e. Pour ma part, j'avais besoin de quelque chose dont je pouvais voir le contenu \xE0 hauteur des yeux, et je voulais donc des tiroirs plus grands. J'aime aussi le fait qu'il s'agisse du nouveau plastique qui ne se fragilise pas et ne se fend pas comme mes anciens tiroirs en plastique. J'aime la construction enti\xE8rement en plastique. Elle est suffisamment r\xE9sistante pour contenir des pi\xE8ces m\xE9talliques, mais \xE9tant en plastique, elle n'est pas aussi lourde qu'un cadre m\xE9tallique, ce qui permet de la fixer facilement au mur et de la charger d'objets lourds ou l\xE9gers. Aucun probl\xE8me. Pour le prix, c'est imbattable. C'est le meilleur que j'ai achet\xE9 \xE0 ce jour, et j'utilise des versions de ce type depuis plus de quarante ans.
`,highlighted:`<span class="hljs-string">&#x27;&gt;&gt; Title: Worked in front position, not rear&#x27;</span> <span class="hljs-comment"># Travaill\xE9 en position avant, pas arri\xE8re</span>
<span class="hljs-string">&#x27;&gt;&gt; Review: 3 stars because these are not rear brakes as stated in the item description. At least the mount adapter only worked on the front fork of the bike that I got it for.&#x27;</span>
<span class="hljs-comment"># 3 \xE9toiles car ce ne sont pas des freins arri\xE8re comme indiqu\xE9 dans la description de l&#x27;article. Au moins, l&#x27;adaptateur de montage ne fonctionnait que sur la fourche avant du v\xE9lo pour lequel je l&#x27;ai achet\xE9.&#x27;&#x27;</span>

<span class="hljs-string">&#x27;&gt;&gt; Title: meh&#x27;</span>
<span class="hljs-string">&#x27;&gt;&gt; Review: Does it\u2019s job and it\u2019s gorgeous but mine is falling apart, I had to basically put it together again with hot glue&#x27;</span>
<span class="hljs-comment"># Il fait son travail et il est magnifique mais le mien est en train de tomber en morceaux, j&#x27;ai d\xFB le recoller avec de la colle chaude.</span>

<span class="hljs-string">&#x27;&gt;&gt; Title: Can\\&#x27;t beat these for the money&#x27;</span> <span class="hljs-comment"># On ne peut pas faire mieux pour le prix</span>
<span class="hljs-string">&#x27;&gt;&gt; Review: Bought this for handling miscellaneous aircraft parts and hanger &quot;stuff&quot; that I needed to organize; it really fit the bill. The unit arrived quickly, was well packaged and arrived intact (always a good sign). There are five wall mounts-- three on the top and two on the bottom. I wanted to mount it on the wall, so all I had to do was to remove the top two layers of plastic drawers, as well as the bottom corner drawers, place it when I wanted and mark it; I then used some of the new plastic screw in wall anchors (the 50 pound variety) and it easily mounted to the wall. Some have remarked that they wanted dividers for the drawers, and that they made those. Good idea. My application was that I needed something that I can see the contents at about eye level, so I wanted the fuller-sized drawers. I also like that these are the new plastic that doesn\\&#x27;t get brittle and split like my older plastic drawers did. I like the all-plastic construction. It\\&#x27;s heavy duty enough to hold metal parts, but being made of plastic it\\&#x27;s not as heavy as a metal frame, so you can easily mount it to the wall and still load it up with heavy stuff, or light stuff. No problem there. For the money, you can\\&#x27;t beat it. Best one of these I\\&#x27;ve bought to date-- and I\\&#x27;ve been using some version of these for over forty years.&#x27;</span>
<span class="hljs-comment"># Je l&#x27;ai achet\xE9 pour manipuler diverses pi\xE8ces d&#x27;avion et des &quot;trucs&quot; de hangar que je devais organiser ; il a vraiment fait l&#x27;affaire. L&#x27;unit\xE9 est arriv\xE9e rapidement, \xE9tait bien emball\xE9e et est arriv\xE9e intacte (toujours un bon signe). Il y a cinq supports muraux - trois sur le dessus et deux sur le dessous. Je voulais le monter sur le mur, alors tout ce que j&#x27;ai eu \xE0 faire \xE9tait d&#x27;enlever les deux couches sup\xE9rieures de tiroirs en plastique, ainsi que les tiroirs d&#x27;angle inf\xE9rieurs, de le placer o\xF9 je voulais et de le marquer ; j&#x27;ai ensuite utilis\xE9 quelques-uns des nouveaux ancrages muraux \xE0 vis en plastique (la vari\xE9t\xE9 de 50 livres) et il s&#x27;est facilement mont\xE9 sur le mur. Certains ont fait remarquer qu&#x27;ils voulaient des s\xE9parateurs pour les tiroirs, et qu&#x27;ils les ont fabriqu\xE9s. Bonne id\xE9e. Pour ma part, j&#x27;avais besoin de quelque chose dont je pouvais voir le contenu \xE0 hauteur des yeux, et je voulais donc des tiroirs plus grands. J&#x27;aime aussi le fait qu&#x27;il s&#x27;agisse du nouveau plastique qui ne se fragilise pas et ne se fend pas comme mes anciens tiroirs en plastique. J&#x27;aime la construction enti\xE8rement en plastique. Elle est suffisamment r\xE9sistante pour contenir des pi\xE8ces m\xE9talliques, mais \xE9tant en plastique, elle n&#x27;est pas aussi lourde qu&#x27;un cadre m\xE9tallique, ce qui permet de la fixer facilement au mur et de la charger d&#x27;objets lourds ou l\xE9gers. Aucun probl\xE8me. Pour le prix, c&#x27;est imbattable. C&#x27;est le meilleur que j&#x27;ai achet\xE9 \xE0 ce jour, et j&#x27;utilise des versions de ce type depuis plus de quarante ans.</span>
`}}),gs=new An({props:{$$slots:{default:[a_]},$$scope:{ctx:Z}}}),Ye=new T({props:{code:`english_dataset.set_format("pandas")
english_df = english_dataset["train"][:]
# Afficher les comptes des 20 premiers produits
english_df["product_category"].value_counts()[:20]`,highlighted:`english_dataset.set_format(<span class="hljs-string">&quot;pandas&quot;</span>)
english_df = english_dataset[<span class="hljs-string">&quot;train&quot;</span>][:]
<span class="hljs-comment"># Afficher les comptes des 20 premiers produits</span>
english_df[<span class="hljs-string">&quot;product_category&quot;</span>].value_counts()[:<span class="hljs-number">20</span>]`}}),as=new T({props:{code:`home                      17679
apparel                   15951
wireless                  15717
other                     13418
beauty                    12091
drugstore                 11730
kitchen                   10382
toy                        8745
sports                     8277
automotive                 7506
lawn_and_garden            7327
home_improvement           7136
pet_products               7082
digital_ebook_purchase     6749
pc                         6401
electronics                6186
office_product             5521
shoes                      5197
grocery                    4730
book                       3756
Name: product_category, dtype: int64`,highlighted:`home                      <span class="hljs-number">17679</span>
apparel                   <span class="hljs-number">15951</span>
wireless                  <span class="hljs-number">15717</span>
other                     <span class="hljs-number">13418</span>
beauty                    <span class="hljs-number">12091</span>
drugstore                 <span class="hljs-number">11730</span>
kitchen                   <span class="hljs-number">10382</span>
toy                        <span class="hljs-number">8745</span>
sports                     <span class="hljs-number">8277</span>
automotive                 <span class="hljs-number">7506</span>
lawn_and_garden            <span class="hljs-number">7327</span>
home_improvement           <span class="hljs-number">7136</span>
pet_products               <span class="hljs-number">7082</span>
digital_ebook_purchase     <span class="hljs-number">6749</span>
pc                         <span class="hljs-number">6401</span>
electronics                <span class="hljs-number">6186</span>
office_product             <span class="hljs-number">5521</span>
shoes                      <span class="hljs-number">5197</span>
grocery                    <span class="hljs-number">4730</span>
book                       <span class="hljs-number">3756</span>
Name: product_category, dtype: int64`}}),dt=new T({props:{code:`def filter_books(example):
    return (
        example["product_category"] == "book"
        or example["product_category"] == "digital_ebook_purchase"
    )`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">filter_books</span>(<span class="hljs-params">example</span>):
    <span class="hljs-keyword">return</span> (
        example[<span class="hljs-string">&quot;product_category&quot;</span>] == <span class="hljs-string">&quot;book&quot;</span>
        <span class="hljs-keyword">or</span> example[<span class="hljs-string">&quot;product_category&quot;</span>] == <span class="hljs-string">&quot;digital_ebook_purchase&quot;</span>
    )`}}),Vs=new T({props:{code:"english_dataset.reset_format()",highlighted:"english_dataset.reset_format()"}}),vt=new T({props:{code:`spanish_books = spanish_dataset.filter(filter_books)
english_books = english_dataset.filter(filter_books)
show_samples(english_books)`,highlighted:`spanish_books = spanish_dataset.<span class="hljs-built_in">filter</span>(filter_books)
english_books = english_dataset.<span class="hljs-built_in">filter</span>(filter_books)
show_samples(english_books)`}}),gt=new T({props:{code:`'>> Title: I\\'m dissapointed.' # Je suis d\xE9\xE7u
'>> Review: I guess I had higher expectations for this book from the reviews. I really thought I\\'d at least like it. The plot idea was great. I loved Ash but, it just didnt go anywhere. Most of the book was about their radio show and talking to callers. I wanted the author to dig deeper so we could really get to know the characters. All we know about Grace is that she is attractive looking, Latino and is kind of a brat. I\\'m dissapointed.'
# Je suppose que j'avais de plus grandes attentes pour ce livre d'apr\xE8s les critiques. Je pensais vraiment que j'allais au moins l'aimer. L'id\xE9e de l'intrigue \xE9tait g\xE9niale. J'aimais Ash, mais \xE7a n'allait nulle part. La plus grande partie du livre \xE9tait consacr\xE9e \xE0 leur \xE9mission de radio et aux conversations avec les auditeurs. Je voulais que l'auteur creuse plus profond\xE9ment pour que nous puissions vraiment conna\xEEtre les personnages. Tout ce que nous savons de Grace, c'est qu'elle est s\xE9duisante, qu'elle est latino et qu'elle est une sorte de garce. Je suis d\xE9\xE7ue.

'>> Title: Good art, good price, poor design' # Un bon art, un bon prix, un mauvais design
'>> Review: I had gotten the DC Vintage calendar the past two years, but it was on backorder forever this year and I saw they had shrunk the dimensions for no good reason. This one has good art choices but the design has the fold going through the picture, so it\\'s less aesthetically pleasing, especially if you want to keep a picture to hang. For the price, a good calendar'
# J'ai eu le calendrier DC Vintage ces deux derni\xE8res ann\xE9es, mais il \xE9tait en rupture de stock pour toujours cette ann\xE9e et j'ai vu qu'ils avaient r\xE9duit les dimensions sans raison valable. Celui-ci a de bons choix artistiques mais le design a le pli qui traverse l'image, donc c'est moins esth\xE9tique, surtout si vous voulez garder une image \xE0 accrocher. Pour le prix, c'est un bon calendrier.

'>> Title: Helpful'  Utile
'>> Review: Nearly all the tips useful and. I consider myself an intermediate to advanced user of OneNote. I would highly recommend.'
# Presque tous les conseils sont utiles et. Je me consid\xE8re comme un utilisateur interm\xE9diaire \xE0 avanc\xE9 de OneNote. Je le recommande vivement.`,highlighted:`<span class="hljs-string">&#x27;&gt;&gt; Title: I\\&#x27;m dissapointed.&#x27;</span> <span class="hljs-comment"># Je suis d\xE9\xE7u</span>
<span class="hljs-string">&#x27;&gt;&gt; Review: I guess I had higher expectations for this book from the reviews. I really thought I\\&#x27;d at least like it. The plot idea was great. I loved Ash but, it just didnt go anywhere. Most of the book was about their radio show and talking to callers. I wanted the author to dig deeper so we could really get to know the characters. All we know about Grace is that she is attractive looking, Latino and is kind of a brat. I\\&#x27;m dissapointed.&#x27;</span>
<span class="hljs-comment"># Je suppose que j&#x27;avais de plus grandes attentes pour ce livre d&#x27;apr\xE8s les critiques. Je pensais vraiment que j&#x27;allais au moins l&#x27;aimer. L&#x27;id\xE9e de l&#x27;intrigue \xE9tait g\xE9niale. J&#x27;aimais Ash, mais \xE7a n&#x27;allait nulle part. La plus grande partie du livre \xE9tait consacr\xE9e \xE0 leur \xE9mission de radio et aux conversations avec les auditeurs. Je voulais que l&#x27;auteur creuse plus profond\xE9ment pour que nous puissions vraiment conna\xEEtre les personnages. Tout ce que nous savons de Grace, c&#x27;est qu&#x27;elle est s\xE9duisante, qu&#x27;elle est latino et qu&#x27;elle est une sorte de garce. Je suis d\xE9\xE7ue.</span>

<span class="hljs-string">&#x27;&gt;&gt; Title: Good art, good price, poor design&#x27;</span> <span class="hljs-comment"># Un bon art, un bon prix, un mauvais design</span>
<span class="hljs-string">&#x27;&gt;&gt; Review: I had gotten the DC Vintage calendar the past two years, but it was on backorder forever this year and I saw they had shrunk the dimensions for no good reason. This one has good art choices but the design has the fold going through the picture, so it\\&#x27;s less aesthetically pleasing, especially if you want to keep a picture to hang. For the price, a good calendar&#x27;</span>
<span class="hljs-comment"># J&#x27;ai eu le calendrier DC Vintage ces deux derni\xE8res ann\xE9es, mais il \xE9tait en rupture de stock pour toujours cette ann\xE9e et j&#x27;ai vu qu&#x27;ils avaient r\xE9duit les dimensions sans raison valable. Celui-ci a de bons choix artistiques mais le design a le pli qui traverse l&#x27;image, donc c&#x27;est moins esth\xE9tique, surtout si vous voulez garder une image \xE0 accrocher. Pour le prix, c&#x27;est un bon calendrier.</span>

<span class="hljs-string">&#x27;&gt;&gt; Title: Helpful&#x27;</span>  Utile
<span class="hljs-string">&#x27;&gt;&gt; Review: Nearly all the tips useful and. I consider myself an intermediate to advanced user of OneNote. I would highly recommend.&#x27;</span>
<span class="hljs-comment"># Presque tous les conseils sont utiles et. Je me consid\xE8re comme un utilisateur interm\xE9diaire \xE0 avanc\xE9 de OneNote. Je le recommande vivement.</span>`}}),Ms=new T({props:{code:`from datasets import concatenate_datasets, DatasetDict

books_dataset = DatasetDict()

for split in english_books.keys():
    books_dataset[split] = concatenate_datasets(
        [english_books[split], spanish_books[split]]
    )
    books_dataset[split] = books_dataset[split].shuffle(seed=42)

# Quelques exemples
show_samples(books_dataset)`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> concatenate_datasets, DatasetDict

books_dataset = DatasetDict()

<span class="hljs-keyword">for</span> split <span class="hljs-keyword">in</span> english_books.keys():
    books_dataset[split] = concatenate_datasets(
        [english_books[split], spanish_books[split]]
    )
    books_dataset[split] = books_dataset[split].shuffle(seed=<span class="hljs-number">42</span>)

<span class="hljs-comment"># Quelques exemples</span>
show_samples(books_dataset)`}}),jt=new T({props:{code:`'>> Title: Easy to follow!!!!' # Facile \xE0 suivre!!!!
'>> Review: I loved The dash diet weight loss Solution. Never hungry. I would recommend this diet. Also the menus are well rounded. Try it. Has lots of the information need thanks.'
# J'ai ador\xE9 The dash diet weight loss Solution. Jamais faim. Je recommande ce r\xE9gime. Les menus sont \xE9galement bien arrondis. Essayez-le. Il contient beaucoup d'informations, merci.

'>> Title: PARCIALMENTE DA\xD1ADO' # PARTIELLEMENT ENDOMMAG\xC9
'>> Review: Me lleg\xF3 el d\xEDa que tocaba, junto a otros libros que ped\xED, pero la caja lleg\xF3 en mal estado lo cual da\xF1\xF3 las esquinas de los libros porque ven\xEDan sin protecci\xF3n (forro).'
# Il est arriv\xE9 le jour pr\xE9vu, avec d'autres livres que j'avais command\xE9s, mais la bo\xEEte est arriv\xE9e en mauvais \xE9tat, ce qui a endommag\xE9 les coins des livres car ils \xE9taient livr\xE9s sans protection (doublure).

'>> Title: no lo he podido descargar' # Je n'ai pas pu le t\xE9l\xE9charger
'>> Review: igual que el anterior' # m\xEAme chose que ci-dessus`,highlighted:`<span class="hljs-string">&#x27;&gt;&gt; Title: Easy to follow!!!!&#x27;</span> <span class="hljs-comment"># Facile \xE0 suivre!!!!</span>
<span class="hljs-string">&#x27;&gt;&gt; Review: I loved The dash diet weight loss Solution. Never hungry. I would recommend this diet. Also the menus are well rounded. Try it. Has lots of the information need thanks.&#x27;</span>
<span class="hljs-comment"># J&#x27;ai ador\xE9 The dash diet weight loss Solution. Jamais faim. Je recommande ce r\xE9gime. Les menus sont \xE9galement bien arrondis. Essayez-le. Il contient beaucoup d&#x27;informations, merci.</span>

<span class="hljs-string">&#x27;&gt;&gt; Title: PARCIALMENTE DA\xD1ADO&#x27;</span> <span class="hljs-comment"># PARTIELLEMENT ENDOMMAG\xC9</span>
<span class="hljs-string">&#x27;&gt;&gt; Review: Me lleg\xF3 el d\xEDa que tocaba, junto a otros libros que ped\xED, pero la caja lleg\xF3 en mal estado lo cual da\xF1\xF3 las esquinas de los libros porque ven\xEDan sin protecci\xF3n (forro).&#x27;</span>
<span class="hljs-comment"># Il est arriv\xE9 le jour pr\xE9vu, avec d&#x27;autres livres que j&#x27;avais command\xE9s, mais la bo\xEEte est arriv\xE9e en mauvais \xE9tat, ce qui a endommag\xE9 les coins des livres car ils \xE9taient livr\xE9s sans protection (doublure).</span>

<span class="hljs-string">&#x27;&gt;&gt; Title: no lo he podido descargar&#x27;</span> <span class="hljs-comment"># Je n&#x27;ai pas pu le t\xE9l\xE9charger</span>
<span class="hljs-string">&#x27;&gt;&gt; Review: igual que el anterior&#x27;</span> <span class="hljs-comment"># m\xEAme chose que ci-dessus</span>`}}),kt=new T({props:{code:'books_dataset = books_dataset.filter(lambda x: len(x["review_title"].split()) > 2)',highlighted:'books_dataset = books_dataset.<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x[<span class="hljs-string">&quot;review_title&quot;</span>].split()) &gt; <span class="hljs-number">2</span>)'}}),Zs=new mt({}),vn=new An({props:{$$slots:{default:[n_]},$$scope:{ctx:Z}}}),rr=new mt({}),lr=new Nf({props:{id:"1m7BerpSq8A"}}),or=new T({props:{code:`from transformers import AutoTokenizer

model_checkpoint = "google/mt5-small"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

model_checkpoint = <span class="hljs-string">&quot;google/mt5-small&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)`}}),_n=new An({props:{$$slots:{default:[r_]},$$scope:{ctx:Z}}}),ir=new T({props:{code:`inputs = tokenizer(
    "I loved reading the Hunger Games!"
)  # J'ai ador\xE9 lire les Hunger Games !
inputs`,highlighted:`inputs = tokenizer(
    <span class="hljs-string">&quot;I loved reading the Hunger Games!&quot;</span>
)  <span class="hljs-comment"># J&#x27;ai ador\xE9 lire les Hunger Games !</span>
inputs`}}),ur=new T({props:{code:"{'input_ids': [336, 259, 28387, 11807, 287, 62893, 295, 12507, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}",highlighted:'{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">336</span>, <span class="hljs-number">259</span>, <span class="hljs-number">28387</span>, <span class="hljs-number">11807</span>, <span class="hljs-number">287</span>, <span class="hljs-number">62893</span>, <span class="hljs-number">295</span>, <span class="hljs-number">12507</span>, <span class="hljs-number">1</span>], <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}'}}),pr=new T({props:{code:"tokenizer.convert_ids_to_tokens(inputs.input_ids)",highlighted:"tokenizer.convert_ids_to_tokens(inputs.input_ids)"}}),mr=new T({props:{code:"['\u2581I', '\u2581', 'loved', '\u2581reading', '\u2581the', '\u2581Hung', 'er', '\u2581Games', '</s>']",highlighted:'[<span class="hljs-string">&#x27;\u2581I&#x27;</span>, <span class="hljs-string">&#x27;\u2581&#x27;</span>, <span class="hljs-string">&#x27;loved&#x27;</span>, <span class="hljs-string">&#x27;\u2581reading&#x27;</span>, <span class="hljs-string">&#x27;\u2581the&#x27;</span>, <span class="hljs-string">&#x27;\u2581Hung&#x27;</span>, <span class="hljs-string">&#x27;er&#x27;</span>, <span class="hljs-string">&#x27;\u2581Games&#x27;</span>, <span class="hljs-string">&#x27;&lt;/s&gt;&#x27;</span>]'}}),cr=new T({props:{code:`max_input_length = 512
max_target_length = 30


def preprocess_function(examples):
    model_inputs = tokenizer(
        examples["review_body"], max_length=max_input_length, truncation=True
    )
    # Configurer le *tokenizer* pour les cibles.
    with tokenizer.as_target_tokenizer():
        labels = tokenizer(
            examples["review_title"], max_length=max_target_length, truncation=True
        )

    model_inputs["labels"] = labels["input_ids"]
    return model_inputs`,highlighted:`max_input_length = <span class="hljs-number">512</span>
max_target_length = <span class="hljs-number">30</span>


<span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
    model_inputs = tokenizer(
        examples[<span class="hljs-string">&quot;review_body&quot;</span>], max_length=max_input_length, truncation=<span class="hljs-literal">True</span>
    )
    <span class="hljs-comment"># Configurer le *tokenizer* pour les cibles.</span>
    <span class="hljs-keyword">with</span> tokenizer.as_target_tokenizer():
        labels = tokenizer(
            examples[<span class="hljs-string">&quot;review_title&quot;</span>], max_length=max_target_length, truncation=<span class="hljs-literal">True</span>
        )

    model_inputs[<span class="hljs-string">&quot;labels&quot;</span>] = labels[<span class="hljs-string">&quot;input_ids&quot;</span>]
    <span class="hljs-keyword">return</span> model_inputs`}}),dr=new T({props:{code:"tokenized_datasets = books_dataset.map(preprocess_function, batched=True)",highlighted:'tokenized_datasets = books_dataset.<span class="hljs-built_in">map</span>(preprocess_function, batched=<span class="hljs-literal">True</span>)'}}),qn=new An({props:{$$slots:{default:[l_]},$$scope:{ctx:Z}}}),fr=new mt({}),hr=new Nf({props:{id:"TMshhnrEXlg"}}),gr=new T({props:{code:`generated_summary = "I absolutely loved reading the Hunger Games"
reference_summary = "I loved reading the Hunger Games"`,highlighted:`generated_summary = <span class="hljs-string">&quot;I absolutely loved reading the Hunger Games&quot;</span>
reference_summary = <span class="hljs-string">&quot;I loved reading the Hunger Games&quot;</span>`}}),xn=new An({props:{$$slots:{default:[o_]},$$scope:{ctx:Z}}}),qr=new T({props:{code:"!pip install rouge_score",highlighted:"!pip install rouge_score"}}),jr=new T({props:{code:`from datasets import load_metric

rouge_score = load_metric("rouge")`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric

rouge_score = load_metric(<span class="hljs-string">&quot;rouge&quot;</span>)`}}),$r=new T({props:{code:`scores = rouge_score.compute(
    predictions=[generated_summary], references=[reference_summary]
)
scores`,highlighted:`scores = rouge_score.compute(
    predictions=[generated_summary], references=[reference_summary]
)
scores`}}),xr=new T({props:{code:`{'rouge1': AggregateScore(low=Score(precision=0.86, recall=1.0, fmeasure=0.92), mid=Score(precision=0.86, recall=1.0, fmeasure=0.92), high=Score(precision=0.86, recall=1.0, fmeasure=0.92)),
 'rouge2': AggregateScore(low=Score(precision=0.67, recall=0.8, fmeasure=0.73), mid=Score(precision=0.67, recall=0.8, fmeasure=0.73), high=Score(precision=0.67, recall=0.8, fmeasure=0.73)),
 'rougeL': AggregateScore(low=Score(precision=0.86, recall=1.0, fmeasure=0.92), mid=Score(precision=0.86, recall=1.0, fmeasure=0.92), high=Score(precision=0.86, recall=1.0, fmeasure=0.92)),
 'rougeLsum': AggregateScore(low=Score(precision=0.86, recall=1.0, fmeasure=0.92), mid=Score(precision=0.86, recall=1.0, fmeasure=0.92), high=Score(precision=0.86, recall=1.0, fmeasure=0.92))}`,highlighted:`{<span class="hljs-string">&#x27;rouge1&#x27;</span>: AggregateScore(low=Score(precision=<span class="hljs-number">0.86</span>, recall=<span class="hljs-number">1.0</span>, fmeasure=<span class="hljs-number">0.92</span>), mid=Score(precision=<span class="hljs-number">0.86</span>, recall=<span class="hljs-number">1.0</span>, fmeasure=<span class="hljs-number">0.92</span>), high=Score(precision=<span class="hljs-number">0.86</span>, recall=<span class="hljs-number">1.0</span>, fmeasure=<span class="hljs-number">0.92</span>)),
 <span class="hljs-string">&#x27;rouge2&#x27;</span>: AggregateScore(low=Score(precision=<span class="hljs-number">0.67</span>, recall=<span class="hljs-number">0.8</span>, fmeasure=<span class="hljs-number">0.73</span>), mid=Score(precision=<span class="hljs-number">0.67</span>, recall=<span class="hljs-number">0.8</span>, fmeasure=<span class="hljs-number">0.73</span>), high=Score(precision=<span class="hljs-number">0.67</span>, recall=<span class="hljs-number">0.8</span>, fmeasure=<span class="hljs-number">0.73</span>)),
 <span class="hljs-string">&#x27;rougeL&#x27;</span>: AggregateScore(low=Score(precision=<span class="hljs-number">0.86</span>, recall=<span class="hljs-number">1.0</span>, fmeasure=<span class="hljs-number">0.92</span>), mid=Score(precision=<span class="hljs-number">0.86</span>, recall=<span class="hljs-number">1.0</span>, fmeasure=<span class="hljs-number">0.92</span>), high=Score(precision=<span class="hljs-number">0.86</span>, recall=<span class="hljs-number">1.0</span>, fmeasure=<span class="hljs-number">0.92</span>)),
 <span class="hljs-string">&#x27;rougeLsum&#x27;</span>: AggregateScore(low=Score(precision=<span class="hljs-number">0.86</span>, recall=<span class="hljs-number">1.0</span>, fmeasure=<span class="hljs-number">0.92</span>), mid=Score(precision=<span class="hljs-number">0.86</span>, recall=<span class="hljs-number">1.0</span>, fmeasure=<span class="hljs-number">0.92</span>), high=Score(precision=<span class="hljs-number">0.86</span>, recall=<span class="hljs-number">1.0</span>, fmeasure=<span class="hljs-number">0.92</span>))}`}}),kr=new T({props:{code:'scores["rouge1"].mid',highlighted:'scores[<span class="hljs-string">&quot;rouge1&quot;</span>].mid'}}),Er=new T({props:{code:"Score(precision=0.86, recall=1.0, fmeasure=0.92)",highlighted:'Score(precision=<span class="hljs-number">0.86</span>, recall=<span class="hljs-number">1.0</span>, fmeasure=<span class="hljs-number">0.92</span>)'}}),En=new An({props:{$$slots:{default:[i_]},$$scope:{ctx:Z}}}),wr=new mt({}),yr=new T({props:{code:"!pip install nltk",highlighted:"!pip install nltk"}}),zr=new T({props:{code:`import nltk

nltk.download("punkt")`,highlighted:`<span class="hljs-keyword">import</span> nltk

nltk.download(<span class="hljs-string">&quot;punkt&quot;</span>)`}}),Tr=new T({props:{code:`from nltk.tokenize import sent_tokenize


def three_sentence_summary(text):
    return "\\n".join(sent_tokenize(text)[:3])


print(three_sentence_summary(books_dataset["train"][1]["review_body"]))`,highlighted:`<span class="hljs-keyword">from</span> nltk.tokenize <span class="hljs-keyword">import</span> sent_tokenize


<span class="hljs-keyword">def</span> <span class="hljs-title function_">three_sentence_summary</span>(<span class="hljs-params">text</span>):
    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;\\n&quot;</span>.join(sent_tokenize(text)[:<span class="hljs-number">3</span>])


<span class="hljs-built_in">print</span>(three_sentence_summary(books_dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">1</span>][<span class="hljs-string">&quot;review_body&quot;</span>]))`}}),Cr=new T({props:{code:`'I grew up reading Koontz, and years ago, I stopped,convinced i had "outgrown" him.' # J'ai grandi en lisant Koontz, et il y a des ann\xE9es, j'ai arr\xEAt\xE9, convaincu que je l'avais "d\xE9pass\xE9"
'Still,when a friend was looking for something suspenseful too read, I suggested Koontz.' " Pourtant, quand une amie cherchait un livre \xE0 suspense, je lui ai sugg\xE9r\xE9 Koontz.
'She found Strangers.' # Elle a trouv\xE9 Strangers.`,highlighted:`<span class="hljs-string">&#x27;I grew up reading Koontz, and years ago, I stopped,convinced i had &quot;outgrown&quot; him.&#x27;</span> <span class="hljs-comment"># J&#x27;ai grandi en lisant Koontz, et il y a des ann\xE9es, j&#x27;ai arr\xEAt\xE9, convaincu que je l&#x27;avais &quot;d\xE9pass\xE9&quot;</span>
<span class="hljs-string">&#x27;Still,when a friend was looking for something suspenseful too read, I suggested Koontz.&#x27;</span> <span class="hljs-string">&quot; Pourtant, quand une amie cherchait un livre \xE0 suspense, je lui ai sugg\xE9r\xE9 Koontz.
&#x27;She found Strangers.&#x27; # Elle a trouv\xE9 Strangers.</span>`}}),Pr=new T({props:{code:`def evaluate_baseline(dataset, metric):
    summaries = [three_sentence_summary(text) for text in dataset["review_body"]]
    return metric.compute(predictions=summaries, references=dataset["review_title"])`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate_baseline</span>(<span class="hljs-params">dataset, metric</span>):
    summaries = [three_sentence_summary(text) <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> dataset[<span class="hljs-string">&quot;review_body&quot;</span>]]
    <span class="hljs-keyword">return</span> metric.compute(predictions=summaries, references=dataset[<span class="hljs-string">&quot;review_title&quot;</span>])`}}),Dr=new T({props:{code:`import pandas as pd

score = evaluate_baseline(books_dataset["validation"], rouge_score)
rouge_names = ["rouge1", "rouge2", "rougeL", "rougeLsum"]
rouge_dict = dict((rn, round(score[rn].mid.fmeasure * 100, 2)) for rn in rouge_names)
rouge_dict`,highlighted:`<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd

score = evaluate_baseline(books_dataset[<span class="hljs-string">&quot;validation&quot;</span>], rouge_score)
rouge_names = [<span class="hljs-string">&quot;rouge1&quot;</span>, <span class="hljs-string">&quot;rouge2&quot;</span>, <span class="hljs-string">&quot;rougeL&quot;</span>, <span class="hljs-string">&quot;rougeLsum&quot;</span>]
rouge_dict = <span class="hljs-built_in">dict</span>((rn, <span class="hljs-built_in">round</span>(score[rn].mid.fmeasure * <span class="hljs-number">100</span>, <span class="hljs-number">2</span>)) <span class="hljs-keyword">for</span> rn <span class="hljs-keyword">in</span> rouge_names)
rouge_dict`}}),Sr=new T({props:{code:"{'rouge1': 16.74, 'rouge2': 8.83, 'rougeL': 15.6, 'rougeLsum': 15.96}",highlighted:'{<span class="hljs-string">&#x27;rouge1&#x27;</span>: <span class="hljs-number">16.74</span>, <span class="hljs-string">&#x27;rouge2&#x27;</span>: <span class="hljs-number">8.83</span>, <span class="hljs-string">&#x27;rougeL&#x27;</span>: <span class="hljs-number">15.6</span>, <span class="hljs-string">&#x27;rougeLsum&#x27;</span>: <span class="hljs-number">15.96</span>}'}});const Hf=[p_,u_],Vr=[];function Ff(e,u){return e[0]==="pt"?0:1}Tt=Ff(Z),Ct=Vr[Tt]=Hf[Tt](Z),zn=new An({props:{$$slots:{default:[m_]},$$scope:{ctx:Z}}}),Lr=new T({props:{code:`from huggingface_hub import notebook_login

notebook_login()`,highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`}}),Ar=new T({props:{code:"huggingface-cli login",highlighted:'huggingface-<span class="hljs-keyword">cli</span> login'}});let Ve=Z[0]==="pt"&&Fg();const Jf=[d_,c_],Wr=[];function Bf(e,u){return e[0]==="pt"?0:1}Pt=Bf(Z),Dt=Wr[Pt]=Jf[Pt](Z),Or=new T({props:{code:`tokenized_datasets = tokenized_datasets.remove_columns(
    books_dataset["train"].column_names
)`,highlighted:`tokenized_datasets = tokenized_datasets.remove_columns(
    books_dataset[<span class="hljs-string">&quot;train&quot;</span>].column_names
)`}}),Mr=new T({props:{code:`features = [tokenized_datasets["train"][i] for i in range(2)]
data_collator(features)`,highlighted:`features = [tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>][i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>)]
data_collator(features)`}}),Nr=new T({props:{code:`{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'input_ids': tensor([[  1494,    259,   8622,    390,    259,    262,   2316,   3435,    955,
            772,    281,    772,   1617,    263,    305,  14701,    260,   1385,
           3031,    259,  24146,    332,   1037,    259,  43906,    305,    336,
            260,      1,      0,      0,      0,      0,      0,      0],
        [   259,  27531,  13483,    259,   7505,    260, 112240,  15192,    305,
          53198,    276,    259,  74060,    263,    260,    459,  25640,    776,
           2119,    336,    259,   2220,    259,  18896,    288,   4906,    288,
           1037,   3931,    260,   7083, 101476,   1143,    260,      1]]), 'labels': tensor([[ 7483,   259,  2364, 15695,     1,  -100],
        [  259, 27531, 13483,   259,  7505,     1]]), 'decoder_input_ids': tensor([[    0,  7483,   259,  2364, 15695,     1],
        [    0,   259, 27531, 13483,   259,  7505]])}`,highlighted:`{<span class="hljs-string">&#x27;attention_mask&#x27;</span>: tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>,
         <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
        [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>,
         <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]]), <span class="hljs-string">&#x27;input_ids&#x27;</span>: tensor([[  <span class="hljs-number">1494</span>,    <span class="hljs-number">259</span>,   <span class="hljs-number">8622</span>,    <span class="hljs-number">390</span>,    <span class="hljs-number">259</span>,    <span class="hljs-number">262</span>,   <span class="hljs-number">2316</span>,   <span class="hljs-number">3435</span>,    <span class="hljs-number">955</span>,
            <span class="hljs-number">772</span>,    <span class="hljs-number">281</span>,    <span class="hljs-number">772</span>,   <span class="hljs-number">1617</span>,    <span class="hljs-number">263</span>,    <span class="hljs-number">305</span>,  <span class="hljs-number">14701</span>,    <span class="hljs-number">260</span>,   <span class="hljs-number">1385</span>,
           <span class="hljs-number">3031</span>,    <span class="hljs-number">259</span>,  <span class="hljs-number">24146</span>,    <span class="hljs-number">332</span>,   <span class="hljs-number">1037</span>,    <span class="hljs-number">259</span>,  <span class="hljs-number">43906</span>,    <span class="hljs-number">305</span>,    <span class="hljs-number">336</span>,
            <span class="hljs-number">260</span>,      <span class="hljs-number">1</span>,      <span class="hljs-number">0</span>,      <span class="hljs-number">0</span>,      <span class="hljs-number">0</span>,      <span class="hljs-number">0</span>,      <span class="hljs-number">0</span>,      <span class="hljs-number">0</span>],
        [   <span class="hljs-number">259</span>,  <span class="hljs-number">27531</span>,  <span class="hljs-number">13483</span>,    <span class="hljs-number">259</span>,   <span class="hljs-number">7505</span>,    <span class="hljs-number">260</span>, <span class="hljs-number">112240</span>,  <span class="hljs-number">15192</span>,    <span class="hljs-number">305</span>,
          <span class="hljs-number">53198</span>,    <span class="hljs-number">276</span>,    <span class="hljs-number">259</span>,  <span class="hljs-number">74060</span>,    <span class="hljs-number">263</span>,    <span class="hljs-number">260</span>,    <span class="hljs-number">459</span>,  <span class="hljs-number">25640</span>,    <span class="hljs-number">776</span>,
           <span class="hljs-number">2119</span>,    <span class="hljs-number">336</span>,    <span class="hljs-number">259</span>,   <span class="hljs-number">2220</span>,    <span class="hljs-number">259</span>,  <span class="hljs-number">18896</span>,    <span class="hljs-number">288</span>,   <span class="hljs-number">4906</span>,    <span class="hljs-number">288</span>,
           <span class="hljs-number">1037</span>,   <span class="hljs-number">3931</span>,    <span class="hljs-number">260</span>,   <span class="hljs-number">7083</span>, <span class="hljs-number">101476</span>,   <span class="hljs-number">1143</span>,    <span class="hljs-number">260</span>,      <span class="hljs-number">1</span>]]), <span class="hljs-string">&#x27;labels&#x27;</span>: tensor([[ <span class="hljs-number">7483</span>,   <span class="hljs-number">259</span>,  <span class="hljs-number">2364</span>, <span class="hljs-number">15695</span>,     <span class="hljs-number">1</span>,  -<span class="hljs-number">100</span>],
        [  <span class="hljs-number">259</span>, <span class="hljs-number">27531</span>, <span class="hljs-number">13483</span>,   <span class="hljs-number">259</span>,  <span class="hljs-number">7505</span>,     <span class="hljs-number">1</span>]]), <span class="hljs-string">&#x27;decoder_input_ids&#x27;</span>: tensor([[    <span class="hljs-number">0</span>,  <span class="hljs-number">7483</span>,   <span class="hljs-number">259</span>,  <span class="hljs-number">2364</span>, <span class="hljs-number">15695</span>,     <span class="hljs-number">1</span>],
        [    <span class="hljs-number">0</span>,   <span class="hljs-number">259</span>, <span class="hljs-number">27531</span>, <span class="hljs-number">13483</span>,   <span class="hljs-number">259</span>,  <span class="hljs-number">7505</span>]])}`}});const Vf=[h_,f_],Kr=[];function Wf(e,u){return e[0]==="pt"?0:1}St=Wf(Z),Lt=Kr[St]=Vf[St](Z);let We=Z[0]==="pt"&&Jg(Z);return Rr=new mt({}),Ir=new T({props:{code:`from transformers import pipeline

hub_model_id = "huggingface-course/mt5-small-finetuned-amazon-en-es"
summarizer = pipeline("summarization", model=hub_model_id)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

hub_model_id = <span class="hljs-string">&quot;huggingface-course/mt5-small-finetuned-amazon-en-es&quot;</span>
summarizer = pipeline(<span class="hljs-string">&quot;summarization&quot;</span>, model=hub_model_id)`}}),Gr=new T({props:{code:`def print_summary(idx):
    review = books_dataset["test"][idx]["review_body"]
    title = books_dataset["test"][idx]["review_title"]
    summary = summarizer(books_dataset["test"][idx]["review_body"])[0]["summary_text"]
    print(f"'>>> Review: {review}'")
    print(f"\\n'>>> Title: {title}'")
    print(f"\\n'>>> Summary: {summary}'")`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">print_summary</span>(<span class="hljs-params">idx</span>):
    review = books_dataset[<span class="hljs-string">&quot;test&quot;</span>][idx][<span class="hljs-string">&quot;review_body&quot;</span>]
    title = books_dataset[<span class="hljs-string">&quot;test&quot;</span>][idx][<span class="hljs-string">&quot;review_title&quot;</span>]
    summary = summarizer(books_dataset[<span class="hljs-string">&quot;test&quot;</span>][idx][<span class="hljs-string">&quot;review_body&quot;</span>])[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;summary_text&quot;</span>]
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;&#x27;&gt;&gt;&gt; Review: <span class="hljs-subst">{review}</span>&#x27;&quot;</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;\\n&#x27;&gt;&gt;&gt; Title: <span class="hljs-subst">{title}</span>&#x27;&quot;</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;\\n&#x27;&gt;&gt;&gt; Summary: <span class="hljs-subst">{summary}</span>&#x27;&quot;</span>)`}}),Ur=new T({props:{code:"print_summary(100)",highlighted:'print_summary(<span class="hljs-number">100</span>)'}}),Hr=new T({props:{code:`'>>> Review: Nothing special at all about this product... the book is too small and stiff and hard to write in. The huge sticker on the back doesn\u2019t come off and looks super tacky. I would not purchase this again. I could have just bought a journal from the dollar store and it would be basically the same thing. It\u2019s also really expensive for what it is.'
# Ce produit n'a rien de sp\xE9cial... le livre est trop petit et rigide et il est difficile d'y \xE9crire. L'\xE9norme autocollant au dos ne se d\xE9tache pas et a l'air super collant. Je n'ach\xE8terai plus jamais ce produit. J'aurais pu simplement acheter un journal dans un magasin \xE0 un dollar et ce serait \xE0 peu pr\xE8s la m\xEAme chose. Il est \xE9galement tr\xE8s cher pour ce qu'il est.

'>>> Title: Not impressed at all... buy something else' # Pas du tout impressionn\xE9... achetez autre chose.

'>>> Summary: Nothing special at all about this product' # Rien de sp\xE9cial \xE0 propos de ce produit`,highlighted:`<span class="hljs-string">&#x27;&gt;&gt;&gt; Review: Nothing special at all about this product... the book is too small and stiff and hard to write in. The huge sticker on the back doesn\u2019t come off and looks super tacky. I would not purchase this again. I could have just bought a journal from the dollar store and it would be basically the same thing. It\u2019s also really expensive for what it is.&#x27;</span>
<span class="hljs-comment"># Ce produit n&#x27;a rien de sp\xE9cial... le livre est trop petit et rigide et il est difficile d&#x27;y \xE9crire. L&#x27;\xE9norme autocollant au dos ne se d\xE9tache pas et a l&#x27;air super collant. Je n&#x27;ach\xE8terai plus jamais ce produit. J&#x27;aurais pu simplement acheter un journal dans un magasin \xE0 un dollar et ce serait \xE0 peu pr\xE8s la m\xEAme chose. Il est \xE9galement tr\xE8s cher pour ce qu&#x27;il est.</span>

<span class="hljs-string">&#x27;&gt;&gt;&gt; Title: Not impressed at all... buy something else&#x27;</span> <span class="hljs-comment"># Pas du tout impressionn\xE9... achetez autre chose.</span>

<span class="hljs-string">&#x27;&gt;&gt;&gt; Summary: Nothing special at all about this product&#x27;</span> <span class="hljs-comment"># Rien de sp\xE9cial \xE0 propos de ce produit</span>`}}),Fr=new T({props:{code:"print_summary(0)",highlighted:'print_summary(<span class="hljs-number">0</span>)'}}),Jr=new T({props:{code:`'>>> Review: Es una trilogia que se hace muy facil de leer. Me ha gustado, no me esperaba el final para nada' # C'est une trilogie qui se lit tr\xE8s facilement. J'ai aim\xE9, je ne m'attendais pas du tout \xE0 la fin.

'>>> Title: Buena literatura para adolescentes' # Bonne litt\xE9rature pour les adolescents

'>>> Summary: Muy facil de leer' # Tr\xE8s facile \xE0 lire`,highlighted:`<span class="hljs-string">&#x27;&gt;&gt;&gt; Review: Es una trilogia que se hace muy facil de leer. Me ha gustado, no me esperaba el final para nada&#x27;</span> <span class="hljs-comment"># C&#x27;est une trilogie qui se lit tr\xE8s facilement. J&#x27;ai aim\xE9, je ne m&#x27;attendais pas du tout \xE0 la fin.</span>

<span class="hljs-string">&#x27;&gt;&gt;&gt; Title: Buena literatura para adolescentes&#x27;</span> <span class="hljs-comment"># Bonne litt\xE9rature pour les adolescents</span>

<span class="hljs-string">&#x27;&gt;&gt;&gt; Summary: Muy facil de leer&#x27;</span> <span class="hljs-comment"># Tr\xE8s facile \xE0 lire</span>`}}),{c(){d=r("meta"),x=m(),b(f.$$.fragment),w=m(),P=r("h1"),y=r("a"),S=r("span"),b(D.$$.fragment),E=m(),M=r("span"),N=a("R\xE9sum\xE9 de textes"),A=m(),G.c(),L=m(),V=r("p"),W=a("Dans cette section, nous allons voir comment les "),ee=r("em"),J=a("transformers"),B=a(" peuvent \xEAtre utilis\xE9s pour condenser de longs documents en r\xE9sum\xE9s, une t\xE2che connue sous le nom de "),Y=r("em"),le=a("r\xE9sum\xE9 de texte"),O=a(". Il s\u2019agit de l\u2019une des t\xE2ches de NLP les plus difficiles car elle requiert une s\xE9rie de capacit\xE9s, telles que la compr\xE9hension de longs passages et la g\xE9n\xE9ration d\u2019un texte coh\xE9rent qui capture les sujets principaux d\u2019un document. Cependant, lorsqu\u2019il est bien fait, le r\xE9sum\xE9 de texte est un outil puissant qui peut acc\xE9l\xE9rer divers processus commerciaux en soulageant les experts du domaine de la lecture d\xE9taill\xE9e de longs documents."),Q=m(),b(oe.$$.fragment),H=m(),U=r("p"),te=a("Bien qu\u2019il existe d\xE9j\xE0 plusieurs mod\xE8les "),se=r("em"),ie=a("finetun\xE9s"),X=a(" pour le r\xE9sum\xE9 sur le "),ae=r("a"),_e=a("Hugging Face Hub"),ce=a(", la plupart d\u2019entre eux ne sont adapt\xE9s qu\u2019aux documents en anglais. Ainsi, pour ajouter une touche d\u2019originalit\xE9 \xE0 cette section, nous allons entra\xEEner un mod\xE8le bilingue pour l\u2019anglais et l\u2019espagnol. \xC0 la fin de cette section, vous disposerez d\u2019un "),ne=r("a"),je=a("mod\xE8le"),Re=a(" capable de r\xE9sumer les commentaires des clients comme celui pr\xE9sent\xE9 ici :"),Pe=m(),F=r("iframe"),he=m(),re=r("iframe"),R=m(),De=r("p"),ke=a("Comme nous allons le voir, ces r\xE9sum\xE9s sont concis car ils sont appris \xE0 partir des titres que les clients fournissent dans leurs commentaires sur les produits. Commen\xE7ons par constituer un corpus bilingue appropri\xE9 pour cette t\xE2che."),Ee=m(),ve=r("h2"),de=r("a"),be=r("span"),b(pe.$$.fragment),Se=m(),we=r("span"),Ue=a("Pr\xE9paration d'un corpus multilingue"),ls=m(),$e=r("p"),_=a("Nous allons utiliser le "),K=r("a"),Be=a("Multilingual Amazon Reviews Corpus"),Ze=a(" pour cr\xE9er notre r\xE9sumeur bilingue. Ce corpus est constitu\xE9 d\u2019\xE9valuations de produits Amazon en six langues et est g\xE9n\xE9ralement utilis\xE9 pour \xE9valuer les classificateurs multilingues. Cependant, comme chaque critique est accompagn\xE9e d\u2019un titre court, nous pouvons utiliser les titres comme r\xE9sum\xE9s cibles pour l\u2019apprentissage de notre mod\xE8le ! Pour commencer, t\xE9l\xE9chargeons les sous-ensembles anglais et espagnols depuis le "),ue=r("em"),os=a("Hub"),is=a(" :"),ge=m(),b(Le.$$.fragment),Ke=m(),b(ye.$$.fragment),us=m(),fe=r("p"),qs=a("Comme vous pouvez le voir, pour chaque langue, il y a 200 000 \xE9valuations pour la partie \u201Centra\xEEnement\u201D, et 5 000 \xE9valuations pour chacune des parties \u201Cvalidation\u201D et \u201Ctest\u201D. Les informations qui nous int\xE9ressent sont contenues dans les colonnes "),Qe=r("code"),es=a("review_body"),vs=a(" et "),js=r("code"),ss=a("review_title"),Is=a(". Voyons quelques exemples en cr\xE9ant une fonction simple qui prend un \xE9chantillon al\xE9atoire de l\u2019ensemble d\u2019entra\xEEnement avec les techniques apprises au "),ts=r("a"),Gs=a("Chapitre 5"),ps=a(" :"),He=m(),b(I.$$.fragment),me=m(),b($s.$$.fragment),Ss=m(),b(gs.$$.fragment),qe=m(),Ge=r("p"),Ot=a("Cet \xE9chantillon montre la diversit\xE9 des critiques que l\u2019on trouve g\xE9n\xE9ralement en ligne, allant du positif au n\xE9gatif (et tout ce qui se trouve entre les deux !). Bien que l\u2019exemple avec le titre \u201Cmeh\u201D ne soit pas tr\xE8s informatif, les autres titres semblent \xEAtre des r\xE9sum\xE9s d\xE9cents des critiques elles-m\xEAmes. Entra\xEEner un mod\xE8le de r\xE9sum\xE9 sur l\u2019ensemble des 400 000 avis prendrait beaucoup trop de temps sur un seul GPU, nous allons donc nous concentrer sur la g\xE9n\xE9ration de r\xE9sum\xE9s pour un seul domaine de produits. Pour avoir une id\xE9e des domaines parmi lesquels nous pouvons choisir, convertissons "),xs=r("code"),Mt=a("english_dataset"),Nt=a(" en "),Ls=r("code"),As=a("pandas.DataFrame"),Ae=a(" et calculons le nombre d\u2019avis par cat\xE9gorie de produits :"),Us=m(),b(Ye.$$.fragment),Hs=m(),b(as.$$.fragment),ct=m(),Oe=r("p"),ks=a("Les produits les plus populaires dans l\u2019ensemble de donn\xE9es anglaises concernent les articles m\xE9nagers, les v\xEAtements et l\u2019\xE9lectronique sans fil. Pour rester dans le th\xE8me d\u2019Amazon, nous allons nous concentrer sur le r\xE9sum\xE9 des critiques de livres. Apr\xE8s tout, c\u2019est la raison d\u2019\xEAtre de l\u2019entreprise ! Nous pouvons voir deux cat\xE9gories de produits qui correspondent \xE0 nos besoins ("),ze=r("code"),ns=a("book"),Rt=a(" et "),Es=r("code"),It=a("digital_ebook_purchase"),Gt=a("), nous allons donc filtrer les ensembles de donn\xE9es dans les deux langues pour ces produits uniquement. Comme nous l\u2019avons vu dans le "),Fs=r("a"),On=a("Chapitre 5"),Mn=a(", la fonction "),Ut=r("code"),ws=a("Dataset.filter()"),Nn=a(" nous permet de d\xE9couper un jeu de donn\xE9es de mani\xE8re tr\xE8s efficace, nous pouvons donc d\xE9finir une fonction simple pour le faire :"),Ht=m(),b(dt.$$.fragment),Na=m(),Me=r("p"),Rn=a("Maintenant, lorsque nous appliquons cette fonction \xE0 "),pa=r("code"),Ra=a("english_dataset"),ft=a(" et "),Ft=r("code"),ht=a("spanish_dataset"),Ia=a(", le r\xE9sultat ne contiendra que les lignes impliquant les cat\xE9gories de livres. Avant d\u2019appliquer le filtre, changeons le format de "),Js=r("code"),In=a("english_dataset"),Ga=a(" de "),Os=r("code"),Ua=a('"pandas"'),Bs=a(" \xE0 "),ma=r("code"),ca=a('"arrow"'),Gn=a(" :"),Ha=m(),b(Vs.$$.fragment),ys=m(),_s=r("p"),da=a("Nous pouvons ensuite appliquer la fonction de filtrage et, \xE0 titre de v\xE9rification, inspecter un \xE9chantillon de critiques pour voir si elles portent bien sur des livres :"),Ws=m(),b(vt.$$.fragment),Jt=m(),b(gt.$$.fragment),fa=m(),Te=r("p"),Un=a("D\u2019accord, nous pouvons voir que les critiques ne concernent pas strictement les livres et peuvent se r\xE9f\xE9rer \xE0 des choses comme des calendriers et des applications \xE9lectroniques telles que OneNote. N\xE9anmoins, le domaine semble appropri\xE9 pour entra\xEEner un mod\xE8le de r\xE9sum\xE9. Avant de regarder les diff\xE9rents mod\xE8les qui conviennent \xE0 cette t\xE2che, nous avons une derni\xE8re pr\xE9paration de donn\xE9es \xE0 faire : combiner les critiques anglaises et espagnoles en un seul objet "),_t=r("code"),Hn=a("DatasetDict"),Fn=a(". \u{1F917} "),Bt=r("em"),ms=a("Datasets"),bt=a(" fournit une fonction pratique "),ha=r("code"),va=a("concatenate_datasets()"),Jn=a(" qui (comme son nom l\u2019indique) va empiler deux objets "),ga=r("code"),Bn=a("Dataset"),qt=a(" l\u2019un sur l\u2019autre. Ainsi, pour cr\xE9er notre jeu de donn\xE9es bilingue, nous allons boucler sur chaque division, concat\xE9ner les jeux de donn\xE9es pour cette division, et m\xE9langer le r\xE9sultat pour s\u2019assurer que notre mod\xE8le ne s\u2019adapte pas trop \xE0 une seule langue :"),Fa=m(),b(Ms.$$.fragment),Ja=m(),b(jt.$$.fragment),Ba=m(),Ks=r("p"),Vn=a("Cela ressemble certainement \xE0 un m\xE9lange de critiques anglaises et espagnoles ! Maintenant que nous avons un corpus d\u2019entra\xEEnement, une derni\xE8re chose \xE0 v\xE9rifier est la distribution des mots dans les critiques et leurs titres. Ceci est particuli\xE8rement important pour les t\xE2ches de r\xE9sum\xE9, o\xF9 les r\xE9sum\xE9s de r\xE9f\xE9rence courts dans les donn\xE9es peuvent biaiser le mod\xE8le pour qu\u2019il ne produise qu\u2019un ou deux mots dans les r\xE9sum\xE9s g\xE9n\xE9r\xE9s. Les graphiques ci-dessous montrent les distributions de mots, et nous pouvons voir que les titres sont fortement biais\xE9s vers seulement 1 ou 2 mots :"),Va=m(),Ce=r("div"),$t=r("img"),Wn=m(),xt=r("img"),Qa=m(),Qs=r("p"),_a=a("Pour y rem\xE9dier, nous allons filtrer les exemples avec des titres tr\xE8s courts afin que notre mod\xE8le puisse produire des r\xE9sum\xE9s plus int\xE9ressants. Puisque nous avons affaire \xE0 des textes anglais et espagnols, nous pouvons utiliser une heuristique grossi\xE8re pour s\xE9parer les titres sur les espaces blancs, puis utiliser notre fid\xE8le m\xE9thode "),ba=r("code"),Kn=a("Dataset.filter()"),qa=a(" comme suit :"),Ya=m(),b(kt.$$.fragment),ja=m(),rs=r("p"),Qn=a("Maintenant que nous avons pr\xE9par\xE9 notre corpus, voyons quelques "),Vt=r("em"),Et=a("transformers"),Xa=a(" possibles que l\u2019on pourrait "),Ns=r("em"),Za=a("finetun\xE9"),Ys=a(" dessus !"),en=m(),bs=r("h2"),Xs=r("a"),$a=r("span"),b(Zs.$$.fragment),p=m(),z=r("span"),Yr=a("Mod\xE8les pour le r\xE9sum\xE9 de texte"),Yn=m(),Rs=r("p"),cs=a("Si vous y pensez, le r\xE9sum\xE9 de texte est une t\xE2che similaire \xE0 la traduction automatique : nous avons un corps de texte, comme une critique, que nous aimerions \u201Ctraduire\u201D en une version plus courte qui capture les caract\xE9ristiques saillantes de l\u2019entr\xE9e. En cons\xE9quence, la plupart des mod\xE8les Transformer pour le r\xE9sum\xE9 adoptent l\u2019architecture encodeur-d\xE9codeur que nous avons rencontr\xE9e pour la premi\xE8re fois dans le "),xa=r("a"),Xr=a("Chapitre 1"),Zr=a(", bien qu\u2019il y ait quelques exceptions comme la famille de mod\xE8les GPT qui peut \xE9galement \xEAtre utilis\xE9e pour le r\xE9sum\xE9 dans des contextes peu complexes. Le tableau suivant pr\xE9sente quelques mod\xE8les pr\xE9-entra\xEEn\xE9s populaires qui peuvent \xEAtre "),sn=r("em"),el=a("finetun\xE9s"),tn=a(" pour le r\xE9sum\xE9."),Xn=m(),wt=r("table"),an=r("thead"),ds=r("tr"),ka=r("th"),nn=r("em"),rn=a("Transformers"),sl=m(),ln=r("th"),on=a("Description"),tl=m(),yt=r("th"),al=a("Multilingue ?"),nl=m(),Ne=r("tbody"),et=r("tr"),Ea=r("td"),st=r("a"),rl=a("GPT-2"),ll=m(),un=r("td"),Wt=a("Bien qu\u2019il soit entra\xEEn\xE9 comme un mod\xE8le de langage autor\xE9gressif, vous pouvez faire en sorte que GPT-2 g\xE9n\xE8re des r\xE9sum\xE9s en ajoutant \u201CTL;DR\u201D \xE0 la fin du texte d\u2019entr\xE9e."),ol=m(),wa=r("td"),Kt=a("\u274C"),il=m(),tt=r("tr"),ya=r("td"),at=r("a"),ul=a("PEGASUS"),pn=m(),mn=r("td"),pl=a("Utilise un objectif de pr\xE9-entra\xEEnement pour pr\xE9dire les phrases masqu\xE9es dans les textes \xE0 plusieurs phrases. Cet objectif de pr\xE9-entra\xEEnement est plus proche du r\xE9sum\xE9 que de la mod\xE9lisation du langage standard et obtient des scores \xE9lev\xE9s sur des benchmarks populaires."),ml=m(),zt=r("td"),cl=a("\u274C"),nt=m(),zs=r("tr"),za=r("td"),rt=r("a"),dl=a("T5"),fl=m(),Fe=r("td"),hl=a("Une architecture universelle de "),cn=r("em"),vl=a("transformer"),gl=a(" qui formule toutes les t\xE2ches dans un cadre texte \xE0 texte ; par exemple, le format d\u2019entr\xE9e du mod\xE8le pour r\xE9sumer un document est "),dn=r("code"),fn=a("summarize : ARTICLE"),_l=a("."),Vp=m(),bl=r("td"),Wp=a("\u274C"),Kp=m(),Ta=r("tr"),ql=r("td"),Zn=r("a"),Qp=a("mT5"),Yp=m(),xo=r("td"),Xp=a("Une version multilingue de T5, pr\xE9-entra\xEEn\xE9e sur le corpus multilingue Common Crawl (mC4), couvrant 101 langues."),Zp=m(),jl=r("td"),em=a("\u2705"),sm=m(),Ca=r("tr"),$l=r("td"),er=r("a"),tm=a("BART"),am=m(),sr=r("td"),nm=a("Une architecture de "),ko=r("em"),rm=a("transformer"),lm=a(" avec une pile d\u2019encodeurs et de d\xE9codeurs entra\xEEn\xE9s pour reconstruire l\u2019entr\xE9e corrompue qui combine les sch\xE9mas de pr\xE9-entra\xEEnement de BERT et GPT-2."),om=m(),xl=r("td"),im=a("\u274C"),um=m(),Pa=r("tr"),kl=r("td"),tr=r("a"),pm=a("mBART-50"),mm=m(),Eo=r("td"),cm=a("Une version multilingue de BART, pr\xE9-entra\xEEn\xE9e sur 50 langues."),dm=m(),El=r("td"),fm=a("\u2705"),Vi=m(),wl=r("p"),hm=a("Comme vous pouvez le voir dans ce tableau, la majorit\xE9 des mod\xE8les Transformer pour le r\xE9sum\xE9 (et en fait la plupart des t\xE2ches de NLP) sont monolingues. C\u2019est une bonne chose si votre t\xE2che se d\xE9roule dans une langue \u201C\xE0 haute ressource\u201D comme l\u2019anglais ou l\u2019allemand, mais moins pour les milliers d\u2019autres langues utilis\xE9es dans le monde. Heureusement, il existe une cat\xE9gorie de mod\xE8les Transformer multilingues, comme mT5 et mBART, qui viennent \xE0 la rescousse. Ces mod\xE8les sont pr\xE9-entra\xEEn\xE9s en utilisant la mod\xE9lisation du langage, mais avec une particularit\xE9 : au lieu de s\u2019entra\xEEner sur un corpus d\u2019une seule langue, ils sont entra\xEEn\xE9s conjointement sur des textes dans plus de 50 langues \xE0 la fois !"),Wi=m(),hn=r("p"),vm=a("Nous allons nous concentrer sur mT5, une architecture int\xE9ressante bas\xE9e sur T5 qui a \xE9t\xE9 pr\xE9-entra\xEEn\xE9e dans un cadre texte \xE0 texte. Dans T5, chaque t\xE2che NLP est formul\xE9e en termes d\u2019un pr\xE9fixe d\u2019invite comme "),wo=r("code"),gm=a("summarize:"),_m=a(" qui conditionne le mod\xE8le \xE0 adapter le texte g\xE9n\xE9r\xE9 \xE0 l\u2019invite. Comme le montre la figure ci-dessous, cela rend T5 extr\xEAmement polyvalent, car vous pouvez r\xE9soudre de nombreuses t\xE2ches avec un seul mod\xE8le !"),Ki=m(),Da=r("div"),ar=r("img"),bm=m(),nr=r("img"),Qi=m(),yl=r("p"),qm=a("mT5 n\u2019utilise pas de pr\xE9fixes, mais partage une grande partie de la polyvalence de T5 et a l\u2019avantage d\u2019\xEAtre multilingue. Maintenant que nous avons choisi un mod\xE8le, voyons comment pr\xE9parer nos donn\xE9es pour l\u2019entra\xEEnement."),Yi=m(),b(vn.$$.fragment),Xi=m(),Sa=r("h2"),gn=r("a"),yo=r("span"),b(rr.$$.fragment),jm=m(),zo=r("span"),$m=a("Pr\xE9traitement des donn\xE9es"),Zi=m(),b(lr.$$.fragment),eu=m(),Qt=r("p"),xm=a("Notre prochaine t\xE2che est de tokeniser et d\u2019encoder nos critiques et leurs titres. Comme d\u2019habitude, nous commen\xE7ons par charger le "),To=r("em"),km=a("tokenizer"),Em=a(" associ\xE9 au point de contr\xF4le du mod\xE8le pr\xE9-entra\xEEn\xE9. Nous utiliserons "),Co=r("code"),wm=a("mt5-small"),ym=a(" comme point de contr\xF4le afin de pouvoir affiner le mod\xE8le en un temps raisonnable :"),su=m(),b(or.$$.fragment),tu=m(),b(_n.$$.fragment),au=m(),bn=r("p"),zm=a("Testons le "),Po=r("em"),Tm=a("tokenizer"),Cm=a(" de mT5 sur un petit exemple :"),nu=m(),b(ir.$$.fragment),ru=m(),b(ur.$$.fragment),lu=m(),Ts=r("p"),Pm=a("Ici nous pouvons voir les familiers "),Do=r("code"),Dm=a("input_ids"),Sm=a(" et "),So=r("code"),Lm=a("attention_mask"),Am=a(" que nous avons rencontr\xE9s dans nos premi\xE8res exp\xE9riences de fine-tuning au "),zl=r("a"),Om=a("Chapitre 3"),Mm=a(". D\xE9codons ces identifiants d\u2019entr\xE9e avec la fonction "),Lo=r("code"),Nm=a("convert_ids_to_tokens()"),Rm=a(" du tokenizer pour voir \xE0 quel type de tokenizer nous avons affaire :"),ou=m(),b(pr.$$.fragment),iu=m(),b(mr.$$.fragment),uu=m(),fs=r("p"),Im=a("Le caract\xE8re sp\xE9cial Unicode "),Ao=r("code"),Gm=a("\u2581"),Um=a(" et le "),Oo=r("em"),Hm=a("token"),Fm=a(" de fin de s\xE9quence "),Mo=r("code"),Jm=a("</s>"),Bm=a(" indiquent que nous avons affaire au "),No=r("em"),Vm=a("tokenizer"),Wm=a(" de SentencePiece, qui est bas\xE9 sur l\u2019algorithme de segmentation Unigram discut\xE9 dans le "),Tl=r("a"),Km=a("Chapitre 6"),Qm=a(". Unigram est particuli\xE8rement utile pour les corpus multilingues car il permet \xE0 SentencePiece d\u2019\xEAtre agnostique vis-\xE0-vis des accents, de la ponctuation et du fait que de nombreuses langues, comme le japonais, n\u2019ont pas de caract\xE8res d\u2019espacement."),pu=m(),Yt=r("p"),Ym=a("Pour tokeniser notre corpus, nous devons faire face \xE0 une subtilit\xE9 associ\xE9e au r\xE9sum\xE9 : comme nos \xE9tiquettes sont \xE9galement du texte, il est possible qu\u2019elles d\xE9passent la taille maximale du contexte du mod\xE8le. Cela signifie que nous devons appliquer une troncature \xE0 la fois aux critiques et \xE0 leurs titres pour nous assurer de ne pas transmettre des entr\xE9es trop longues \xE0 notre mod\xE8le. Les tokenizers de \u{1F917} "),Ro=r("em"),Xm=a("Transformers"),Zm=a(" fournissent une fonction tr\xE8s pratique "),Io=r("code"),ec=a("as_target_tokenizer()"),sc=a(" qui vous permet de tokeniser les \xE9tiquettes en parall\xE8le avec les entr\xE9es. Ceci est typiquement fait en utilisant un gestionnaire de contexte \xE0 l\u2019int\xE9rieur d\u2019une fonction de pr\xE9traitement qui encode d\u2019abord les entr\xE9es, et ensuite encode les \xE9tiquettes comme une colonne s\xE9par\xE9e. Voici un exemple d\u2019une telle fonction pour mT5 :"),mu=m(),b(cr.$$.fragment),cu=m(),Cs=r("p"),tc=a("Parcourons ce code pour comprendre ce qui se passe. La premi\xE8re chose que nous avons faite est de d\xE9finir des valeurs pour "),Go=r("code"),ac=a("max_input_length"),nc=a(" et "),Uo=r("code"),rc=a("max_target_length"),lc=a(", qui fixent les limites sup\xE9rieures de la longueur des commentaires et des titres. Comme le corps de la critique est g\xE9n\xE9ralement beaucoup plus long que le titre, nous avons mis ces valeurs \xE0 l\u2019\xE9chelle en cons\xE9quence. Ensuite, dans la "),Ho=r("code"),oc=a("preprocess_function()"),ic=a(" elle-m\xEAme, nous pouvons voir que les commentaires sont d\u2019abord tokeniz\xE9s, suivis par les titres avec "),Fo=r("code"),uc=a("as_target_tokenizer()"),pc=a("."),du=m(),Xt=r("p"),mc=a("Avec la fonction "),Jo=r("code"),cc=a("preprocess_function()"),dc=a(", il est alors simple de tokeniser l\u2019ensemble du corpus en utilisant la fonction pratique "),Bo=r("code"),fc=a("Dataset.map()"),hc=a(" que nous avons largement utilis\xE9e dans ce cours :"),fu=m(),b(dr.$$.fragment),hu=m(),Cl=r("p"),vc=a("Maintenant que le corpus a \xE9t\xE9 pr\xE9trait\xE9, examinons certaines m\xE9triques couramment utilis\xE9es pour le r\xE9sum\xE9. Comme nous allons le voir, il n\u2019existe pas de solution miracle pour mesurer la qualit\xE9 d\u2019un texte g\xE9n\xE9r\xE9 par une machine."),vu=m(),b(qn.$$.fragment),gu=m(),La=r("h2"),jn=r("a"),Vo=r("span"),b(fr.$$.fragment),gc=m(),Wo=r("span"),_c=a("M\xE9triques pour le r\xE9sum\xE9 de texte"),_u=m(),b(hr.$$.fragment),bu=m(),Pl=r("p"),bc=a("Par rapport \xE0 la plupart des autres t\xE2ches que nous avons abord\xE9es dans ce cours, la mesure des performances des t\xE2ches de g\xE9n\xE9ration de texte comme le r\xE9sum\xE9 ou la traduction n\u2019est pas aussi simple. Par exemple, pour une critique telle que \u201CJ\u2019ai ador\xE9 lire les Hunger Games\u201D, il existe plusieurs r\xE9sum\xE9s valides, comme \u201CJ\u2019ai ador\xE9 Hunger Games\u201D ou \u201CHunger Games est une excellente lecture\u201D. Il est clair que l\u2019application d\u2019une sorte de correspondance exacte entre le r\xE9sum\xE9 g\xE9n\xE9r\xE9 et l\u2019\xE9tiquette n\u2019est pas une bonne solution - m\xEAme les humains auraient de mauvais r\xE9sultats avec une telle mesure, car nous avons tous notre propre style d\u2019\xE9criture."),qu=m(),$n=r("p"),qc=a("Pour le r\xE9sum\xE9, l\u2019une des m\xE9triques les plus couramment utilis\xE9es est le "),vr=r("a"),jc=a("score ROUGE"),$c=a(" (abr\xE9viation de Recall-Oriented Understudy for Gisting Evaluation). L\u2019id\xE9e de base de cette m\xE9trique est de comparer un r\xE9sum\xE9 g\xE9n\xE9r\xE9 avec un ensemble de r\xE9sum\xE9s de r\xE9f\xE9rence qui sont g\xE9n\xE9ralement cr\xE9\xE9s par des humains. Pour \xEAtre plus pr\xE9cis, supposons que nous voulions comparer les deux r\xE9sum\xE9s suivants :"),ju=m(),b(gr.$$.fragment),$u=m(),Zt=r("p"),xc=a("Une fa\xE7on de les comparer pourrait \xEAtre de compter le nombre de mots qui se chevauchent, qui dans ce cas serait de 6. Cependant, cette m\xE9thode est un peu grossi\xE8re, c\u2019est pourquoi ROUGE se base sur le calcul des scores de "),Ko=r("em"),kc=a("pr\xE9cision"),Ec=a(" et de "),Qo=r("em"),wc=a("rappel"),yc=a(" pour le chevauchement."),xu=m(),b(xn.$$.fragment),ku=m(),_r=r("p"),zc=a(`Pour ROUGE, le rappel mesure la proportion du r\xE9sum\xE9 de r\xE9f\xE9rence qui est captur\xE9e par le r\xE9sum\xE9 g\xE9n\xE9r\xE9. Si nous ne faisons que comparer des mots, le rappel peut \xEAtre calcul\xE9 selon la formule suivante :
`),Eu=new Ug,wu=m(),br=r("p"),Tc=a(`Pour notre exemple simple ci-dessus, cette formule donne un rappel parfait de 6/6 = 1 ; c\u2019est-\xE0-dire que tous les mots du r\xE9sum\xE9 de r\xE9f\xE9rence ont \xE9t\xE9 produits par le mod\xE8le. Cela peut sembler g\xE9nial, mais imaginez que le r\xE9sum\xE9 g\xE9n\xE9r\xE9 ait \xE9t\xE9 \u201CJ\u2019ai vraiment aim\xE9 lire les Hunger Games toute la nuit\u201D. Le rappel serait \xE9galement parfait, mais le r\xE9sum\xE9 serait sans doute moins bon puisqu\u2019il serait verbeux. Pour traiter ces sc\xE9narios, nous calculons \xE9galement la pr\xE9cision, qui, dans le contexte de ROUGE, mesure la proportion du r\xE9sum\xE9 g\xE9n\xE9r\xE9 qui \xE9tait pertinente :
`),yu=new Ug,zu=m(),ea=r("p"),Cc=a("En appliquant cela \xE0 notre r\xE9sum\xE9 verbeux, on obtient une pr\xE9cision de 6/10 = 0,6, ce qui est consid\xE9rablement moins bon que la pr\xE9cision de 6/7 = 0,86 obtenue par notre r\xE9sum\xE9 plus court. En pratique, la pr\xE9cision et le rappel sont g\xE9n\xE9ralement calcul\xE9s, puis le score F1 (la moyenne harmonique de la pr\xE9cision et du rappel) est indiqu\xE9. Nous pouvons le faire facilement dans \u{1F917} "),Yo=r("em"),Pc=a("Datasets"),Dc=a(" en installant d\u2019abord le paquet "),Xo=r("code"),Sc=a("rouge_score"),Lc=a(" :"),Tu=m(),b(qr.$$.fragment),Cu=m(),Dl=r("p"),Ac=a("et ensuite charger la m\xE9trique ROUGE comme suit :"),Pu=m(),b(jr.$$.fragment),Du=m(),kn=r("p"),Oc=a("Ensuite, nous pouvons utiliser la fonction "),Zo=r("code"),Mc=a("rouge_score.compute()"),Nc=a(" pour calculer toutes les m\xE9triques en une seule fois :"),Su=m(),b($r.$$.fragment),Lu=m(),b(xr.$$.fragment),Au=m(),Xe=r("p"),Rc=a("Whoa, il y a un batch d\u2019informations dans cette sortie. Qu\u2019est-ce que \xE7a veut dire ? Tout d\u2019abord, \u{1F917} "),ei=r("em"),Ic=a("Datasets"),Gc=a(" calcule en fait des intervalles de confiance pour la pr\xE9cision, le rappel et le score F1 ; ce sont les attributs "),si=r("code"),Uc=a("low"),Hc=a(", "),ti=r("code"),Fc=a("mid"),Jc=a(", et "),ai=r("code"),Bc=a("high"),Vc=a(" que vous pouvez voir ici. De plus, \u{1F917} "),ni=r("em"),Wc=a("Datasets"),Kc=a(" calcule une vari\xE9t\xE9 de scores ROUGE qui sont bas\xE9s sur diff\xE9rents types de granularit\xE9 du texte lors de la comparaison des r\xE9sum\xE9s g\xE9n\xE9r\xE9s et de r\xE9f\xE9rence. La variante "),ri=r("code"),Qc=a("rouge1"),Yc=a(" est le chevauchement des unigrammes. C\u2019est juste une fa\xE7on fantaisiste de dire le chevauchement des mots et c\u2019est exactement la m\xE9trique dont nous avons discut\xE9 ci-dessus. Pour v\xE9rifier cela, nous allons extraire la valeur \u201Cmoyenne\u201D de nos scores :"),Ou=m(),b(kr.$$.fragment),Mu=m(),b(Er.$$.fragment),Nu=m(),hs=r("p"),Xc=a("Super, les chiffres de pr\xE9cision et de rappel correspondent ! Maintenant, qu\u2019en est-il des autres scores ROUGE ? "),li=r("code"),Zc=a("rouge2"),ed=a(" mesure le chevauchement entre les bigrammes (pensez au chevauchement des paires de mots), tandis que "),oi=r("code"),sd=a("rougeL"),td=a(" et "),ii=r("code"),ad=a("rougeLsum"),nd=a(" mesurent les plus longues s\xE9quences de mots correspondants en recherchant les plus longues sous-souches communes dans les r\xE9sum\xE9s g\xE9n\xE9r\xE9s et de r\xE9f\xE9rence. La \u201Csomme\u201D dans "),ui=r("code"),rd=a("rougeLsum"),ld=a(" fait r\xE9f\xE9rence au fait que cette m\xE9trique est calcul\xE9e sur un r\xE9sum\xE9 entier, alors que "),pi=r("code"),od=a("rougeL"),id=a(" est calcul\xE9e comme une moyenne sur des phrases individuelles."),Ru=m(),b(En.$$.fragment),Iu=m(),Sl=r("p"),ud=a("Nous utiliserons ces scores ROUGE pour suivre les performances de notre mod\xE8le, mais avant cela, faisons ce que tout bon praticien de NLP devrait faire : cr\xE9er une base de r\xE9f\xE9rence solide, mais simple !"),Gu=m(),Aa=r("h3"),wn=r("a"),mi=r("span"),b(wr.$$.fragment),pd=m(),ci=r("span"),md=a("Cr\xE9ation d'une base de r\xE9f\xE9rence solide"),Uu=m(),lt=r("p"),cd=a("Une base de r\xE9f\xE9rence commune pour le r\xE9sum\xE9 de texte consiste \xE0 prendre simplement les trois premi\xE8res phrases d\u2019un article, souvent appel\xE9e la base de r\xE9f\xE9rence "),di=r("em"),dd=a("lead-3"),fd=a(". Nous pourrions utiliser des points pour suivre les limites de la phrase, mais cela \xE9chouera avec des acronymes comme \u201CU.S.\u201D ou \u201CU.N.\u201D. \u2014 Nous allons donc utiliser la biblioth\xE8que "),fi=r("code"),hd=a("nltk"),vd=a(", qui inclut un meilleur algorithme pour g\xE9rer ces cas. Vous pouvez installer le paquetage en utilisant "),hi=r("code"),gd=a("pip"),_d=a(" comme suit :"),Hu=m(),b(yr.$$.fragment),Fu=m(),Ll=r("p"),bd=a("puis t\xE9l\xE9chargez les r\xE8gles de ponctuation :"),Ju=m(),b(zr.$$.fragment),Bu=m(),sa=r("p"),qd=a("Ensuite, nous importons le "),vi=r("em"),jd=a("tokenizer"),$d=a(" de "),gi=r("code"),xd=a("nltk"),kd=a(" et cr\xE9ons une fonction simple pour extraire les trois premi\xE8res phrases d\u2019une critique. La convention dans le r\xE9sum\xE9 de texte est de s\xE9parer chaque r\xE9sum\xE9 avec une nouvelle ligne, donc nous allons \xE9galement inclure ceci et le tester sur un exemple d\u2019entra\xEEnement :"),Vu=m(),b(Tr.$$.fragment),Wu=m(),b(Cr.$$.fragment),Ku=m(),Al=r("p"),Ed=a("Cela semble fonctionner, alors impl\xE9mentons maintenant une fonction qui extrait ces \u201Cr\xE9sum\xE9s\u201D d\u2019un ensemble de donn\xE9es et calcule les scores ROUGE pour la ligne de base :"),Qu=m(),b(Pr.$$.fragment),Yu=m(),Ol=r("p"),wd=a("Nous pouvons ensuite utiliser cette fonction pour calculer les scores ROUGE sur l\u2019ensemble de validation et les embellir un peu en utilisant Pandas :"),Xu=m(),b(Dr.$$.fragment),Zu=m(),b(Sr.$$.fragment),ep=m(),yn=r("p"),yd=a("Nous pouvons voir que le score de "),_i=r("code"),zd=a("rouge2"),Td=a(" est significativement plus bas que le reste ; ceci refl\xE8te probablement le fait que les titres des revues sont typiquement concis et donc que la ligne de base de lead-3 est trop verbeuse. Maintenant que nous disposons d\u2019une bonne base de travail, concentrons-nous sur le r\xE9glage fin de mT5 !"),sp=m(),Ct.c(),Ml=m(),b(zn.$$.fragment),tp=m(),ta=r("p"),Cd=a("La prochaine chose que nous devons faire est de nous connecter au "),bi=r("em"),Pd=a("Hub"),Dd=a(". Si vous ex\xE9cutez ce code dans un "),qi=r("em"),Sd=a("notebook"),Ld=a(", vous pouvez le faire avec la fonction utilitaire suivante :"),ap=m(),b(Lr.$$.fragment),np=m(),Tn=r("p"),Ad=a("qui affichera un "),ji=r("em"),Od=a("widget"),Md=a(" o\xF9 vous pourrez saisir vos informations d\u2019identification. Vous pouvez \xE9galement ex\xE9cuter cette commande dans votre terminal et vous connecter \xE0 partir de l\xE0 :"),rp=m(),b(Ar.$$.fragment),lp=m(),Ve&&Ve.c(),Nl=m(),Cn=r("p"),Nd=a("Ensuite, nous devons d\xE9finir un collateur de donn\xE9es pour notre t\xE2che de s\xE9quence \xE0 s\xE9quence. Comme mT5 est un mod\xE8le Transformer encodeur-d\xE9codeur, une des subtilit\xE9s de la pr\xE9paration de nos lots est que, pendant le d\xE9codage, nous devons d\xE9caler les \xE9tiquettes d\u2019une unit\xE9 vers la droite. Ceci est n\xE9cessaire pour garantir que le d\xE9codeur ne voit que les \xE9tiquettes de v\xE9rit\xE9 terrain pr\xE9c\xE9dentes et non les \xE9tiquettes actuelles ou futures, qui seraient faciles \xE0 m\xE9moriser pour le mod\xE8le. Cela ressemble \xE0 la fa\xE7on dont l\u2019auto-attention masqu\xE9e est appliqu\xE9e aux entr\xE9es dans une t\xE2che comme "),Rl=r("a"),Rd=a("la mod\xE9lisation causale du langage"),Id=a("."),op=m(),Ps=r("p"),Gd=a("Heureusement, \u{1F917} "),$i=r("em"),Ud=a("Transformers"),Hd=a(" fournit un collateur "),xi=r("code"),Fd=a("DataCollatorForSeq2Seq"),Jd=a(" qui rembourrera dynamiquement les entr\xE9es et les \xE9tiquettes pour nous. Pour instancier ce collateur, nous devons simplement fournir le "),ki=r("em"),Bd=a("tokenizer"),Vd=a(" et le "),Ei=r("code"),Wd=a("model"),Kd=a(" :"),ip=m(),Dt.c(),Il=m(),Gl=r("p"),Qd=a("Voyons ce que produit ce collateur lorsqu\u2019on lui donne un petit lot d\u2019exemples. Tout d\u2019abord, nous devons supprimer les colonnes contenant des cha\xEEnes de caract\xE8res, car le collateur ne saura pas comment remplir ces \xE9l\xE9ments :"),up=m(),b(Or.$$.fragment),pp=m(),aa=r("p"),Yd=a("Comme le collateur attend une liste de "),wi=r("code"),Xd=a("dict"),Zd=a("s, o\xF9 chaque "),yi=r("code"),ef=a("dict"),sf=a(" repr\xE9sente un seul exemple dans l\u2019ensemble de donn\xE9es, nous devons \xE9galement mettre les donn\xE9es dans le format attendu avant de les transmettre au collateur de donn\xE9es :"),mp=m(),b(Mr.$$.fragment),cp=m(),b(Nr.$$.fragment),dp=m(),xe=r("p"),tf=a("La principale chose \xE0 remarquer ici est que le premier exemple est plus long que le second, donc les "),zi=r("code"),af=a("input_ids"),nf=a(" et "),Ti=r("code"),rf=a("attention_mask"),lf=a(" du second exemple ont \xE9t\xE9 compl\xE9t\xE9s sur la droite avec un jeton "),Ci=r("code"),of=a("[PAD]"),uf=a(" (dont l\u2019ID est "),Pi=r("code"),pf=a("0"),mf=a("). De m\xEAme, nous pouvons voir que les "),Di=r("code"),cf=a("labels"),df=a(" ont \xE9t\xE9 compl\xE9t\xE9s par des "),Si=r("code"),ff=a("-100"),hf=a("s, pour s\u2019assurer que les "),Li=r("em"),vf=a("tokens"),gf=a(" de remplissage sont ignor\xE9s par la fonction de perte. Et enfin, nous pouvons voir un nouveau "),Ai=r("code"),_f=a("decoder_input_ids"),bf=a(" qui a d\xE9plac\xE9 les \xE9tiquettes vers la droite en ins\xE9rant un jeton "),Oi=r("code"),qf=a("[PAD]"),jf=a(" dans la premi\xE8re entr\xE9e."),fp=m(),Lt.c(),Ul=m(),We&&We.c(),Hl=m(),Oa=r("h2"),Pn=r("a"),Mi=r("span"),b(Rr.$$.fragment),$f=m(),Ni=r("span"),xf=a("Utilisation de votre mod\xE8le *finetun\xE9*"),hp=m(),na=r("p"),kf=a("Une fois que vous avez pouss\xE9 le mod\xE8le vers le "),Ri=r("em"),Ef=a("Hub"),wf=a(", vous pouvez jouer avec lui soit via le widget d\u2019inf\xE9rence, soit avec un objet "),Ii=r("code"),yf=a("pipeline"),zf=a(", comme suit :"),vp=m(),b(Ir.$$.fragment),gp=m(),Fl=r("p"),Tf=a("Nous pouvons alimenter notre pipeline avec quelques exemples de l\u2019ensemble de test (que le mod\xE8le n\u2019a pas vu) pour avoir une id\xE9e de la qualit\xE9 des r\xE9sum\xE9s. Tout d\u2019abord, impl\xE9mentons une fonction simple pour afficher ensemble la critique, le titre et le r\xE9sum\xE9 g\xE9n\xE9r\xE9 :"),_p=m(),b(Gr.$$.fragment),bp=m(),Jl=r("p"),Cf=a("Examinons l\u2019un des exemples anglais que nous recevons :"),qp=m(),b(Ur.$$.fragment),jp=m(),b(Hr.$$.fragment),$p=m(),Dn=r("p"),Pf=a("Ce n\u2019est pas si mal ! Nous pouvons voir que notre mod\xE8le a \xE9t\xE9 capable d\u2019effectuer un r\xE9sum\xE9 "),Gi=r("em"),Df=a("abstractif"),Sf=a(" en augmentant certaines parties de la critique avec de nouveaux mots. Et peut-\xEAtre que l\u2019aspect le plus cool de notre mod\xE8le est qu\u2019il est bilingue, donc nous pouvons \xE9galement g\xE9n\xE9rer des r\xE9sum\xE9s de critiques en espagnol :"),xp=m(),b(Fr.$$.fragment),kp=m(),b(Jr.$$.fragment),Ep=m(),Bl=r("p"),Lf=a("Le r\xE9sum\xE9 se traduit par \u201CTr\xE8s facile \xE0 lire\u201D, ce qui, comme nous pouvons le constater, a \xE9t\xE9 extrait directement de la critique. N\xE9anmoins, cela montre la polyvalence du mod\xE8le mT5 et vous a donn\xE9 un aper\xE7u de ce que c\u2019est que de traiter un corpus multilingue !"),wp=m(),Vl=r("p"),Af=a("Ensuite, nous allons nous int\xE9resser \xE0 une t\xE2che un peu plus complexe : entra\xEEner un mod\xE8le de langue \xE0 partir de z\xE9ro."),this.h()},l(e){const u=Xg('[data-svelte="svelte-1phssyn"]',document.head);d=l(u,"META",{name:!0,content:!0}),u.forEach(t),x=c(e),q(f.$$.fragment,e),w=c(e),P=l(e,"H1",{class:!0});var Qr=o(P);y=l(Qr,"A",{id:!0,class:!0,href:!0});var Wl=o(y);S=l(Wl,"SPAN",{});var Ui=o(S);q(D.$$.fragment,Ui),Ui.forEach(t),Wl.forEach(t),E=c(Qr),M=l(Qr,"SPAN",{});var Hi=o(M);N=n(Hi,"R\xE9sum\xE9 de textes"),Hi.forEach(t),Qr.forEach(t),A=c(e),G.l(e),L=c(e),V=l(e,"P",{});var Ma=o(V);W=n(Ma,"Dans cette section, nous allons voir comment les "),ee=l(Ma,"EM",{});var Fi=o(ee);J=n(Fi,"transformers"),Fi.forEach(t),B=n(Ma," peuvent \xEAtre utilis\xE9s pour condenser de longs documents en r\xE9sum\xE9s, une t\xE2che connue sous le nom de "),Y=l(Ma,"EM",{});var Ji=o(Y);le=n(Ji,"r\xE9sum\xE9 de texte"),Ji.forEach(t),O=n(Ma,". Il s\u2019agit de l\u2019une des t\xE2ches de NLP les plus difficiles car elle requiert une s\xE9rie de capacit\xE9s, telles que la compr\xE9hension de longs passages et la g\xE9n\xE9ration d\u2019un texte coh\xE9rent qui capture les sujets principaux d\u2019un document. Cependant, lorsqu\u2019il est bien fait, le r\xE9sum\xE9 de texte est un outil puissant qui peut acc\xE9l\xE9rer divers processus commerciaux en soulageant les experts du domaine de la lecture d\xE9taill\xE9e de longs documents."),Ma.forEach(t),Q=c(e),q(oe.$$.fragment,e),H=c(e),U=l(e,"P",{});var At=o(U);te=n(At,"Bien qu\u2019il existe d\xE9j\xE0 plusieurs mod\xE8les "),se=l(At,"EM",{});var Kl=o(se);ie=n(Kl,"finetun\xE9s"),Kl.forEach(t),X=n(At," pour le r\xE9sum\xE9 sur le "),ae=l(At,"A",{href:!0,rel:!0});var Bi=o(ae);_e=n(Bi,"Hugging Face Hub"),Bi.forEach(t),ce=n(At,", la plupart d\u2019entre eux ne sont adapt\xE9s qu\u2019aux documents en anglais. Ainsi, pour ajouter une touche d\u2019originalit\xE9 \xE0 cette section, nous allons entra\xEEner un mod\xE8le bilingue pour l\u2019anglais et l\u2019espagnol. \xC0 la fin de cette section, vous disposerez d\u2019un "),ne=l(At,"A",{href:!0,rel:!0});var Ql=o(ne);je=n(Ql,"mod\xE8le"),Ql.forEach(t),Re=n(At," capable de r\xE9sumer les commentaires des clients comme celui pr\xE9sent\xE9 ici :"),At.forEach(t),Pe=c(e),F=l(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),o(F).forEach(t),he=c(e),re=l(e,"IFRAME",{src:!0,frameborder:!0,height:!0,title:!0,class:!0,allow:!0,sandbox:!0}),o(re).forEach(t),R=c(e),De=l(e,"P",{});var Yl=o(De);ke=n(Yl,"Comme nous allons le voir, ces r\xE9sum\xE9s sont concis car ils sont appris \xE0 partir des titres que les clients fournissent dans leurs commentaires sur les produits. Commen\xE7ons par constituer un corpus bilingue appropri\xE9 pour cette t\xE2che."),Yl.forEach(t),Ee=c(e),ve=l(e,"H2",{class:!0});var zp=o(ve);de=l(zp,"A",{id:!0,class:!0,href:!0});var Kf=o(de);be=l(Kf,"SPAN",{});var Qf=o(be);q(pe.$$.fragment,Qf),Qf.forEach(t),Kf.forEach(t),Se=c(zp),we=l(zp,"SPAN",{});var Yf=o(we);Ue=n(Yf,"Pr\xE9paration d'un corpus multilingue"),Yf.forEach(t),zp.forEach(t),ls=c(e),$e=l(e,"P",{});var Xl=o($e);_=n(Xl,"Nous allons utiliser le "),K=l(Xl,"A",{href:!0,rel:!0});var Xf=o(K);Be=n(Xf,"Multilingual Amazon Reviews Corpus"),Xf.forEach(t),Ze=n(Xl," pour cr\xE9er notre r\xE9sumeur bilingue. Ce corpus est constitu\xE9 d\u2019\xE9valuations de produits Amazon en six langues et est g\xE9n\xE9ralement utilis\xE9 pour \xE9valuer les classificateurs multilingues. Cependant, comme chaque critique est accompagn\xE9e d\u2019un titre court, nous pouvons utiliser les titres comme r\xE9sum\xE9s cibles pour l\u2019apprentissage de notre mod\xE8le ! Pour commencer, t\xE9l\xE9chargeons les sous-ensembles anglais et espagnols depuis le "),ue=l(Xl,"EM",{});var Zf=o(ue);os=n(Zf,"Hub"),Zf.forEach(t),is=n(Xl," :"),Xl.forEach(t),ge=c(e),q(Le.$$.fragment,e),Ke=c(e),q(ye.$$.fragment,e),us=c(e),fe=l(e,"P",{});var Sn=o(fe);qs=n(Sn,"Comme vous pouvez le voir, pour chaque langue, il y a 200 000 \xE9valuations pour la partie \u201Centra\xEEnement\u201D, et 5 000 \xE9valuations pour chacune des parties \u201Cvalidation\u201D et \u201Ctest\u201D. Les informations qui nous int\xE9ressent sont contenues dans les colonnes "),Qe=l(Sn,"CODE",{});var eh=o(Qe);es=n(eh,"review_body"),eh.forEach(t),vs=n(Sn," et "),js=l(Sn,"CODE",{});var sh=o(js);ss=n(sh,"review_title"),sh.forEach(t),Is=n(Sn,". Voyons quelques exemples en cr\xE9ant une fonction simple qui prend un \xE9chantillon al\xE9atoire de l\u2019ensemble d\u2019entra\xEEnement avec les techniques apprises au "),ts=l(Sn,"A",{href:!0});var th=o(ts);Gs=n(th,"Chapitre 5"),th.forEach(t),ps=n(Sn," :"),Sn.forEach(t),He=c(e),q(I.$$.fragment,e),me=c(e),q($s.$$.fragment,e),Ss=c(e),q(gs.$$.fragment,e),qe=c(e),Ge=l(e,"P",{});var Zl=o(Ge);Ot=n(Zl,"Cet \xE9chantillon montre la diversit\xE9 des critiques que l\u2019on trouve g\xE9n\xE9ralement en ligne, allant du positif au n\xE9gatif (et tout ce qui se trouve entre les deux !). Bien que l\u2019exemple avec le titre \u201Cmeh\u201D ne soit pas tr\xE8s informatif, les autres titres semblent \xEAtre des r\xE9sum\xE9s d\xE9cents des critiques elles-m\xEAmes. Entra\xEEner un mod\xE8le de r\xE9sum\xE9 sur l\u2019ensemble des 400 000 avis prendrait beaucoup trop de temps sur un seul GPU, nous allons donc nous concentrer sur la g\xE9n\xE9ration de r\xE9sum\xE9s pour un seul domaine de produits. Pour avoir une id\xE9e des domaines parmi lesquels nous pouvons choisir, convertissons "),xs=l(Zl,"CODE",{});var ah=o(xs);Mt=n(ah,"english_dataset"),ah.forEach(t),Nt=n(Zl," en "),Ls=l(Zl,"CODE",{});var nh=o(Ls);As=n(nh,"pandas.DataFrame"),nh.forEach(t),Ae=n(Zl," et calculons le nombre d\u2019avis par cat\xE9gorie de produits :"),Zl.forEach(t),Us=c(e),q(Ye.$$.fragment,e),Hs=c(e),q(as.$$.fragment,e),ct=c(e),Oe=l(e,"P",{});var ra=o(Oe);ks=n(ra,"Les produits les plus populaires dans l\u2019ensemble de donn\xE9es anglaises concernent les articles m\xE9nagers, les v\xEAtements et l\u2019\xE9lectronique sans fil. Pour rester dans le th\xE8me d\u2019Amazon, nous allons nous concentrer sur le r\xE9sum\xE9 des critiques de livres. Apr\xE8s tout, c\u2019est la raison d\u2019\xEAtre de l\u2019entreprise ! Nous pouvons voir deux cat\xE9gories de produits qui correspondent \xE0 nos besoins ("),ze=l(ra,"CODE",{});var rh=o(ze);ns=n(rh,"book"),rh.forEach(t),Rt=n(ra," et "),Es=l(ra,"CODE",{});var lh=o(Es);It=n(lh,"digital_ebook_purchase"),lh.forEach(t),Gt=n(ra,"), nous allons donc filtrer les ensembles de donn\xE9es dans les deux langues pour ces produits uniquement. Comme nous l\u2019avons vu dans le "),Fs=l(ra,"A",{href:!0});var oh=o(Fs);On=n(oh,"Chapitre 5"),oh.forEach(t),Mn=n(ra,", la fonction "),Ut=l(ra,"CODE",{});var ih=o(Ut);ws=n(ih,"Dataset.filter()"),ih.forEach(t),Nn=n(ra," nous permet de d\xE9couper un jeu de donn\xE9es de mani\xE8re tr\xE8s efficace, nous pouvons donc d\xE9finir une fonction simple pour le faire :"),ra.forEach(t),Ht=c(e),q(dt.$$.fragment,e),Na=c(e),Me=l(e,"P",{});var ot=o(Me);Rn=n(ot,"Maintenant, lorsque nous appliquons cette fonction \xE0 "),pa=l(ot,"CODE",{});var uh=o(pa);Ra=n(uh,"english_dataset"),uh.forEach(t),ft=n(ot," et "),Ft=l(ot,"CODE",{});var ph=o(Ft);ht=n(ph,"spanish_dataset"),ph.forEach(t),Ia=n(ot,", le r\xE9sultat ne contiendra que les lignes impliquant les cat\xE9gories de livres. Avant d\u2019appliquer le filtre, changeons le format de "),Js=l(ot,"CODE",{});var mh=o(Js);In=n(mh,"english_dataset"),mh.forEach(t),Ga=n(ot," de "),Os=l(ot,"CODE",{});var ch=o(Os);Ua=n(ch,'"pandas"'),ch.forEach(t),Bs=n(ot," \xE0 "),ma=l(ot,"CODE",{});var dh=o(ma);ca=n(dh,'"arrow"'),dh.forEach(t),Gn=n(ot," :"),ot.forEach(t),Ha=c(e),q(Vs.$$.fragment,e),ys=c(e),_s=l(e,"P",{});var fh=o(_s);da=n(fh,"Nous pouvons ensuite appliquer la fonction de filtrage et, \xE0 titre de v\xE9rification, inspecter un \xE9chantillon de critiques pour voir si elles portent bien sur des livres :"),fh.forEach(t),Ws=c(e),q(vt.$$.fragment,e),Jt=c(e),q(gt.$$.fragment,e),fa=c(e),Te=l(e,"P",{});var la=o(Te);Un=n(la,"D\u2019accord, nous pouvons voir que les critiques ne concernent pas strictement les livres et peuvent se r\xE9f\xE9rer \xE0 des choses comme des calendriers et des applications \xE9lectroniques telles que OneNote. N\xE9anmoins, le domaine semble appropri\xE9 pour entra\xEEner un mod\xE8le de r\xE9sum\xE9. Avant de regarder les diff\xE9rents mod\xE8les qui conviennent \xE0 cette t\xE2che, nous avons une derni\xE8re pr\xE9paration de donn\xE9es \xE0 faire : combiner les critiques anglaises et espagnoles en un seul objet "),_t=l(la,"CODE",{});var hh=o(_t);Hn=n(hh,"DatasetDict"),hh.forEach(t),Fn=n(la,". \u{1F917} "),Bt=l(la,"EM",{});var vh=o(Bt);ms=n(vh,"Datasets"),vh.forEach(t),bt=n(la," fournit une fonction pratique "),ha=l(la,"CODE",{});var gh=o(ha);va=n(gh,"concatenate_datasets()"),gh.forEach(t),Jn=n(la," qui (comme son nom l\u2019indique) va empiler deux objets "),ga=l(la,"CODE",{});var _h=o(ga);Bn=n(_h,"Dataset"),_h.forEach(t),qt=n(la," l\u2019un sur l\u2019autre. Ainsi, pour cr\xE9er notre jeu de donn\xE9es bilingue, nous allons boucler sur chaque division, concat\xE9ner les jeux de donn\xE9es pour cette division, et m\xE9langer le r\xE9sultat pour s\u2019assurer que notre mod\xE8le ne s\u2019adapte pas trop \xE0 une seule langue :"),la.forEach(t),Fa=c(e),q(Ms.$$.fragment,e),Ja=c(e),q(jt.$$.fragment,e),Ba=c(e),Ks=l(e,"P",{});var bh=o(Ks);Vn=n(bh,"Cela ressemble certainement \xE0 un m\xE9lange de critiques anglaises et espagnoles ! Maintenant que nous avons un corpus d\u2019entra\xEEnement, une derni\xE8re chose \xE0 v\xE9rifier est la distribution des mots dans les critiques et leurs titres. Ceci est particuli\xE8rement important pour les t\xE2ches de r\xE9sum\xE9, o\xF9 les r\xE9sum\xE9s de r\xE9f\xE9rence courts dans les donn\xE9es peuvent biaiser le mod\xE8le pour qu\u2019il ne produise qu\u2019un ou deux mots dans les r\xE9sum\xE9s g\xE9n\xE9r\xE9s. Les graphiques ci-dessous montrent les distributions de mots, et nous pouvons voir que les titres sont fortement biais\xE9s vers seulement 1 ou 2 mots :"),bh.forEach(t),Va=c(e),Ce=l(e,"DIV",{class:!0});var Tp=o(Ce);$t=l(Tp,"IMG",{class:!0,src:!0,alt:!0}),Wn=c(Tp),xt=l(Tp,"IMG",{class:!0,src:!0,alt:!0}),Tp.forEach(t),Qa=c(e),Qs=l(e,"P",{});var Cp=o(Qs);_a=n(Cp,"Pour y rem\xE9dier, nous allons filtrer les exemples avec des titres tr\xE8s courts afin que notre mod\xE8le puisse produire des r\xE9sum\xE9s plus int\xE9ressants. Puisque nous avons affaire \xE0 des textes anglais et espagnols, nous pouvons utiliser une heuristique grossi\xE8re pour s\xE9parer les titres sur les espaces blancs, puis utiliser notre fid\xE8le m\xE9thode "),ba=l(Cp,"CODE",{});var qh=o(ba);Kn=n(qh,"Dataset.filter()"),qh.forEach(t),qa=n(Cp," comme suit :"),Cp.forEach(t),Ya=c(e),q(kt.$$.fragment,e),ja=c(e),rs=l(e,"P",{});var eo=o(rs);Qn=n(eo,"Maintenant que nous avons pr\xE9par\xE9 notre corpus, voyons quelques "),Vt=l(eo,"EM",{});var jh=o(Vt);Et=n(jh,"transformers"),jh.forEach(t),Xa=n(eo," possibles que l\u2019on pourrait "),Ns=l(eo,"EM",{});var $h=o(Ns);Za=n($h,"finetun\xE9"),$h.forEach(t),Ys=n(eo," dessus !"),eo.forEach(t),en=c(e),bs=l(e,"H2",{class:!0});var Pp=o(bs);Xs=l(Pp,"A",{id:!0,class:!0,href:!0});var xh=o(Xs);$a=l(xh,"SPAN",{});var kh=o($a);q(Zs.$$.fragment,kh),kh.forEach(t),xh.forEach(t),p=c(Pp),z=l(Pp,"SPAN",{});var Eh=o(z);Yr=n(Eh,"Mod\xE8les pour le r\xE9sum\xE9 de texte"),Eh.forEach(t),Pp.forEach(t),Yn=c(e),Rs=l(e,"P",{});var so=o(Rs);cs=n(so,"Si vous y pensez, le r\xE9sum\xE9 de texte est une t\xE2che similaire \xE0 la traduction automatique : nous avons un corps de texte, comme une critique, que nous aimerions \u201Ctraduire\u201D en une version plus courte qui capture les caract\xE9ristiques saillantes de l\u2019entr\xE9e. En cons\xE9quence, la plupart des mod\xE8les Transformer pour le r\xE9sum\xE9 adoptent l\u2019architecture encodeur-d\xE9codeur que nous avons rencontr\xE9e pour la premi\xE8re fois dans le "),xa=l(so,"A",{href:!0});var wh=o(xa);Xr=n(wh,"Chapitre 1"),wh.forEach(t),Zr=n(so,", bien qu\u2019il y ait quelques exceptions comme la famille de mod\xE8les GPT qui peut \xE9galement \xEAtre utilis\xE9e pour le r\xE9sum\xE9 dans des contextes peu complexes. Le tableau suivant pr\xE9sente quelques mod\xE8les pr\xE9-entra\xEEn\xE9s populaires qui peuvent \xEAtre "),sn=l(so,"EM",{});var yh=o(sn);el=n(yh,"finetun\xE9s"),yh.forEach(t),tn=n(so," pour le r\xE9sum\xE9."),so.forEach(t),Xn=c(e),wt=l(e,"TABLE",{});var Dp=o(wt);an=l(Dp,"THEAD",{});var zh=o(an);ds=l(zh,"TR",{});var to=o(ds);ka=l(to,"TH",{align:!0});var Th=o(ka);nn=l(Th,"EM",{});var Ch=o(nn);rn=n(Ch,"Transformers"),Ch.forEach(t),Th.forEach(t),sl=c(to),ln=l(to,"TH",{});var Ph=o(ln);on=n(Ph,"Description"),Ph.forEach(t),tl=c(to),yt=l(to,"TH",{align:!0});var Dh=o(yt);al=n(Dh,"Multilingue ?"),Dh.forEach(t),to.forEach(t),zh.forEach(t),nl=c(Dp),Ne=l(Dp,"TBODY",{});var it=o(Ne);et=l(it,"TR",{});var ao=o(et);Ea=l(ao,"TD",{align:!0});var Sh=o(Ea);st=l(Sh,"A",{href:!0,rel:!0});var Lh=o(st);rl=n(Lh,"GPT-2"),Lh.forEach(t),Sh.forEach(t),ll=c(ao),un=l(ao,"TD",{});var Ah=o(un);Wt=n(Ah,"Bien qu\u2019il soit entra\xEEn\xE9 comme un mod\xE8le de langage autor\xE9gressif, vous pouvez faire en sorte que GPT-2 g\xE9n\xE8re des r\xE9sum\xE9s en ajoutant \u201CTL;DR\u201D \xE0 la fin du texte d\u2019entr\xE9e."),Ah.forEach(t),ol=c(ao),wa=l(ao,"TD",{align:!0});var Oh=o(wa);Kt=n(Oh,"\u274C"),Oh.forEach(t),ao.forEach(t),il=c(it),tt=l(it,"TR",{});var no=o(tt);ya=l(no,"TD",{align:!0});var Mh=o(ya);at=l(Mh,"A",{href:!0,rel:!0});var Nh=o(at);ul=n(Nh,"PEGASUS"),Nh.forEach(t),Mh.forEach(t),pn=c(no),mn=l(no,"TD",{});var Rh=o(mn);pl=n(Rh,"Utilise un objectif de pr\xE9-entra\xEEnement pour pr\xE9dire les phrases masqu\xE9es dans les textes \xE0 plusieurs phrases. Cet objectif de pr\xE9-entra\xEEnement est plus proche du r\xE9sum\xE9 que de la mod\xE9lisation du langage standard et obtient des scores \xE9lev\xE9s sur des benchmarks populaires."),Rh.forEach(t),ml=c(no),zt=l(no,"TD",{align:!0});var Ih=o(zt);cl=n(Ih,"\u274C"),Ih.forEach(t),no.forEach(t),nt=c(it),zs=l(it,"TR",{});var ro=o(zs);za=l(ro,"TD",{align:!0});var Gh=o(za);rt=l(Gh,"A",{href:!0,rel:!0});var Uh=o(rt);dl=n(Uh,"T5"),Uh.forEach(t),Gh.forEach(t),fl=c(ro),Fe=l(ro,"TD",{});var lo=o(Fe);hl=n(lo,"Une architecture universelle de "),cn=l(lo,"EM",{});var Hh=o(cn);vl=n(Hh,"transformer"),Hh.forEach(t),gl=n(lo," qui formule toutes les t\xE2ches dans un cadre texte \xE0 texte ; par exemple, le format d\u2019entr\xE9e du mod\xE8le pour r\xE9sumer un document est "),dn=l(lo,"CODE",{});var Fh=o(dn);fn=n(Fh,"summarize : ARTICLE"),Fh.forEach(t),_l=n(lo,"."),lo.forEach(t),Vp=c(ro),bl=l(ro,"TD",{align:!0});var Jh=o(bl);Wp=n(Jh,"\u274C"),Jh.forEach(t),ro.forEach(t),Kp=c(it),Ta=l(it,"TR",{});var oo=o(Ta);ql=l(oo,"TD",{align:!0});var Bh=o(ql);Zn=l(Bh,"A",{href:!0,rel:!0});var Vh=o(Zn);Qp=n(Vh,"mT5"),Vh.forEach(t),Bh.forEach(t),Yp=c(oo),xo=l(oo,"TD",{});var Wh=o(xo);Xp=n(Wh,"Une version multilingue de T5, pr\xE9-entra\xEEn\xE9e sur le corpus multilingue Common Crawl (mC4), couvrant 101 langues."),Wh.forEach(t),Zp=c(oo),jl=l(oo,"TD",{align:!0});var Kh=o(jl);em=n(Kh,"\u2705"),Kh.forEach(t),oo.forEach(t),sm=c(it),Ca=l(it,"TR",{});var io=o(Ca);$l=l(io,"TD",{align:!0});var Qh=o($l);er=l(Qh,"A",{href:!0,rel:!0});var Yh=o(er);tm=n(Yh,"BART"),Yh.forEach(t),Qh.forEach(t),am=c(io),sr=l(io,"TD",{});var Sp=o(sr);nm=n(Sp,"Une architecture de "),ko=l(Sp,"EM",{});var Xh=o(ko);rm=n(Xh,"transformer"),Xh.forEach(t),lm=n(Sp," avec une pile d\u2019encodeurs et de d\xE9codeurs entra\xEEn\xE9s pour reconstruire l\u2019entr\xE9e corrompue qui combine les sch\xE9mas de pr\xE9-entra\xEEnement de BERT et GPT-2."),Sp.forEach(t),om=c(io),xl=l(io,"TD",{align:!0});var Zh=o(xl);im=n(Zh,"\u274C"),Zh.forEach(t),io.forEach(t),um=c(it),Pa=l(it,"TR",{});var uo=o(Pa);kl=l(uo,"TD",{align:!0});var ev=o(kl);tr=l(ev,"A",{href:!0,rel:!0});var sv=o(tr);pm=n(sv,"mBART-50"),sv.forEach(t),ev.forEach(t),mm=c(uo),Eo=l(uo,"TD",{});var tv=o(Eo);cm=n(tv,"Une version multilingue de BART, pr\xE9-entra\xEEn\xE9e sur 50 langues."),tv.forEach(t),dm=c(uo),El=l(uo,"TD",{align:!0});var av=o(El);fm=n(av,"\u2705"),av.forEach(t),uo.forEach(t),it.forEach(t),Dp.forEach(t),Vi=c(e),wl=l(e,"P",{});var nv=o(wl);hm=n(nv,"Comme vous pouvez le voir dans ce tableau, la majorit\xE9 des mod\xE8les Transformer pour le r\xE9sum\xE9 (et en fait la plupart des t\xE2ches de NLP) sont monolingues. C\u2019est une bonne chose si votre t\xE2che se d\xE9roule dans une langue \u201C\xE0 haute ressource\u201D comme l\u2019anglais ou l\u2019allemand, mais moins pour les milliers d\u2019autres langues utilis\xE9es dans le monde. Heureusement, il existe une cat\xE9gorie de mod\xE8les Transformer multilingues, comme mT5 et mBART, qui viennent \xE0 la rescousse. Ces mod\xE8les sont pr\xE9-entra\xEEn\xE9s en utilisant la mod\xE9lisation du langage, mais avec une particularit\xE9 : au lieu de s\u2019entra\xEEner sur un corpus d\u2019une seule langue, ils sont entra\xEEn\xE9s conjointement sur des textes dans plus de 50 langues \xE0 la fois !"),nv.forEach(t),Wi=c(e),hn=l(e,"P",{});var Lp=o(hn);vm=n(Lp,"Nous allons nous concentrer sur mT5, une architecture int\xE9ressante bas\xE9e sur T5 qui a \xE9t\xE9 pr\xE9-entra\xEEn\xE9e dans un cadre texte \xE0 texte. Dans T5, chaque t\xE2che NLP est formul\xE9e en termes d\u2019un pr\xE9fixe d\u2019invite comme "),wo=l(Lp,"CODE",{});var rv=o(wo);gm=n(rv,"summarize:"),rv.forEach(t),_m=n(Lp," qui conditionne le mod\xE8le \xE0 adapter le texte g\xE9n\xE9r\xE9 \xE0 l\u2019invite. Comme le montre la figure ci-dessous, cela rend T5 extr\xEAmement polyvalent, car vous pouvez r\xE9soudre de nombreuses t\xE2ches avec un seul mod\xE8le !"),Lp.forEach(t),Ki=c(e),Da=l(e,"DIV",{class:!0});var Ap=o(Da);ar=l(Ap,"IMG",{class:!0,src:!0,alt:!0}),bm=c(Ap),nr=l(Ap,"IMG",{class:!0,src:!0,alt:!0}),Ap.forEach(t),Qi=c(e),yl=l(e,"P",{});var lv=o(yl);qm=n(lv,"mT5 n\u2019utilise pas de pr\xE9fixes, mais partage une grande partie de la polyvalence de T5 et a l\u2019avantage d\u2019\xEAtre multilingue. Maintenant que nous avons choisi un mod\xE8le, voyons comment pr\xE9parer nos donn\xE9es pour l\u2019entra\xEEnement."),lv.forEach(t),Yi=c(e),q(vn.$$.fragment,e),Xi=c(e),Sa=l(e,"H2",{class:!0});var Op=o(Sa);gn=l(Op,"A",{id:!0,class:!0,href:!0});var ov=o(gn);yo=l(ov,"SPAN",{});var iv=o(yo);q(rr.$$.fragment,iv),iv.forEach(t),ov.forEach(t),jm=c(Op),zo=l(Op,"SPAN",{});var uv=o(zo);$m=n(uv,"Pr\xE9traitement des donn\xE9es"),uv.forEach(t),Op.forEach(t),Zi=c(e),q(lr.$$.fragment,e),eu=c(e),Qt=l(e,"P",{});var po=o(Qt);xm=n(po,"Notre prochaine t\xE2che est de tokeniser et d\u2019encoder nos critiques et leurs titres. Comme d\u2019habitude, nous commen\xE7ons par charger le "),To=l(po,"EM",{});var pv=o(To);km=n(pv,"tokenizer"),pv.forEach(t),Em=n(po," associ\xE9 au point de contr\xF4le du mod\xE8le pr\xE9-entra\xEEn\xE9. Nous utiliserons "),Co=l(po,"CODE",{});var mv=o(Co);wm=n(mv,"mt5-small"),mv.forEach(t),ym=n(po," comme point de contr\xF4le afin de pouvoir affiner le mod\xE8le en un temps raisonnable :"),po.forEach(t),su=c(e),q(or.$$.fragment,e),tu=c(e),q(_n.$$.fragment,e),au=c(e),bn=l(e,"P",{});var Mp=o(bn);zm=n(Mp,"Testons le "),Po=l(Mp,"EM",{});var cv=o(Po);Tm=n(cv,"tokenizer"),cv.forEach(t),Cm=n(Mp," de mT5 sur un petit exemple :"),Mp.forEach(t),nu=c(e),q(ir.$$.fragment,e),ru=c(e),q(ur.$$.fragment,e),lu=c(e),Ts=l(e,"P",{});var oa=o(Ts);Pm=n(oa,"Ici nous pouvons voir les familiers "),Do=l(oa,"CODE",{});var dv=o(Do);Dm=n(dv,"input_ids"),dv.forEach(t),Sm=n(oa," et "),So=l(oa,"CODE",{});var fv=o(So);Lm=n(fv,"attention_mask"),fv.forEach(t),Am=n(oa," que nous avons rencontr\xE9s dans nos premi\xE8res exp\xE9riences de fine-tuning au "),zl=l(oa,"A",{href:!0});var hv=o(zl);Om=n(hv,"Chapitre 3"),hv.forEach(t),Mm=n(oa,". D\xE9codons ces identifiants d\u2019entr\xE9e avec la fonction "),Lo=l(oa,"CODE",{});var vv=o(Lo);Nm=n(vv,"convert_ids_to_tokens()"),vv.forEach(t),Rm=n(oa," du tokenizer pour voir \xE0 quel type de tokenizer nous avons affaire :"),oa.forEach(t),ou=c(e),q(pr.$$.fragment,e),iu=c(e),q(mr.$$.fragment,e),uu=c(e),fs=l(e,"P",{});var ut=o(fs);Im=n(ut,"Le caract\xE8re sp\xE9cial Unicode "),Ao=l(ut,"CODE",{});var gv=o(Ao);Gm=n(gv,"\u2581"),gv.forEach(t),Um=n(ut," et le "),Oo=l(ut,"EM",{});var _v=o(Oo);Hm=n(_v,"token"),_v.forEach(t),Fm=n(ut," de fin de s\xE9quence "),Mo=l(ut,"CODE",{});var bv=o(Mo);Jm=n(bv,"</s>"),bv.forEach(t),Bm=n(ut," indiquent que nous avons affaire au "),No=l(ut,"EM",{});var qv=o(No);Vm=n(qv,"tokenizer"),qv.forEach(t),Wm=n(ut," de SentencePiece, qui est bas\xE9 sur l\u2019algorithme de segmentation Unigram discut\xE9 dans le "),Tl=l(ut,"A",{href:!0});var jv=o(Tl);Km=n(jv,"Chapitre 6"),jv.forEach(t),Qm=n(ut,". Unigram est particuli\xE8rement utile pour les corpus multilingues car il permet \xE0 SentencePiece d\u2019\xEAtre agnostique vis-\xE0-vis des accents, de la ponctuation et du fait que de nombreuses langues, comme le japonais, n\u2019ont pas de caract\xE8res d\u2019espacement."),ut.forEach(t),pu=c(e),Yt=l(e,"P",{});var mo=o(Yt);Ym=n(mo,"Pour tokeniser notre corpus, nous devons faire face \xE0 une subtilit\xE9 associ\xE9e au r\xE9sum\xE9 : comme nos \xE9tiquettes sont \xE9galement du texte, il est possible qu\u2019elles d\xE9passent la taille maximale du contexte du mod\xE8le. Cela signifie que nous devons appliquer une troncature \xE0 la fois aux critiques et \xE0 leurs titres pour nous assurer de ne pas transmettre des entr\xE9es trop longues \xE0 notre mod\xE8le. Les tokenizers de \u{1F917} "),Ro=l(mo,"EM",{});var $v=o(Ro);Xm=n($v,"Transformers"),$v.forEach(t),Zm=n(mo," fournissent une fonction tr\xE8s pratique "),Io=l(mo,"CODE",{});var xv=o(Io);ec=n(xv,"as_target_tokenizer()"),xv.forEach(t),sc=n(mo," qui vous permet de tokeniser les \xE9tiquettes en parall\xE8le avec les entr\xE9es. Ceci est typiquement fait en utilisant un gestionnaire de contexte \xE0 l\u2019int\xE9rieur d\u2019une fonction de pr\xE9traitement qui encode d\u2019abord les entr\xE9es, et ensuite encode les \xE9tiquettes comme une colonne s\xE9par\xE9e. Voici un exemple d\u2019une telle fonction pour mT5 :"),mo.forEach(t),mu=c(e),q(cr.$$.fragment,e),cu=c(e),Cs=l(e,"P",{});var ia=o(Cs);tc=n(ia,"Parcourons ce code pour comprendre ce qui se passe. La premi\xE8re chose que nous avons faite est de d\xE9finir des valeurs pour "),Go=l(ia,"CODE",{});var kv=o(Go);ac=n(kv,"max_input_length"),kv.forEach(t),nc=n(ia," et "),Uo=l(ia,"CODE",{});var Ev=o(Uo);rc=n(Ev,"max_target_length"),Ev.forEach(t),lc=n(ia,", qui fixent les limites sup\xE9rieures de la longueur des commentaires et des titres. Comme le corps de la critique est g\xE9n\xE9ralement beaucoup plus long que le titre, nous avons mis ces valeurs \xE0 l\u2019\xE9chelle en cons\xE9quence. Ensuite, dans la "),Ho=l(ia,"CODE",{});var wv=o(Ho);oc=n(wv,"preprocess_function()"),wv.forEach(t),ic=n(ia," elle-m\xEAme, nous pouvons voir que les commentaires sont d\u2019abord tokeniz\xE9s, suivis par les titres avec "),Fo=l(ia,"CODE",{});var yv=o(Fo);uc=n(yv,"as_target_tokenizer()"),yv.forEach(t),pc=n(ia,"."),ia.forEach(t),du=c(e),Xt=l(e,"P",{});var co=o(Xt);mc=n(co,"Avec la fonction "),Jo=l(co,"CODE",{});var zv=o(Jo);cc=n(zv,"preprocess_function()"),zv.forEach(t),dc=n(co,", il est alors simple de tokeniser l\u2019ensemble du corpus en utilisant la fonction pratique "),Bo=l(co,"CODE",{});var Tv=o(Bo);fc=n(Tv,"Dataset.map()"),Tv.forEach(t),hc=n(co," que nous avons largement utilis\xE9e dans ce cours :"),co.forEach(t),fu=c(e),q(dr.$$.fragment,e),hu=c(e),Cl=l(e,"P",{});var Cv=o(Cl);vc=n(Cv,"Maintenant que le corpus a \xE9t\xE9 pr\xE9trait\xE9, examinons certaines m\xE9triques couramment utilis\xE9es pour le r\xE9sum\xE9. Comme nous allons le voir, il n\u2019existe pas de solution miracle pour mesurer la qualit\xE9 d\u2019un texte g\xE9n\xE9r\xE9 par une machine."),Cv.forEach(t),vu=c(e),q(qn.$$.fragment,e),gu=c(e),La=l(e,"H2",{class:!0});var Np=o(La);jn=l(Np,"A",{id:!0,class:!0,href:!0});var Pv=o(jn);Vo=l(Pv,"SPAN",{});var Dv=o(Vo);q(fr.$$.fragment,Dv),Dv.forEach(t),Pv.forEach(t),gc=c(Np),Wo=l(Np,"SPAN",{});var Sv=o(Wo);_c=n(Sv,"M\xE9triques pour le r\xE9sum\xE9 de texte"),Sv.forEach(t),Np.forEach(t),_u=c(e),q(hr.$$.fragment,e),bu=c(e),Pl=l(e,"P",{});var Lv=o(Pl);bc=n(Lv,"Par rapport \xE0 la plupart des autres t\xE2ches que nous avons abord\xE9es dans ce cours, la mesure des performances des t\xE2ches de g\xE9n\xE9ration de texte comme le r\xE9sum\xE9 ou la traduction n\u2019est pas aussi simple. Par exemple, pour une critique telle que \u201CJ\u2019ai ador\xE9 lire les Hunger Games\u201D, il existe plusieurs r\xE9sum\xE9s valides, comme \u201CJ\u2019ai ador\xE9 Hunger Games\u201D ou \u201CHunger Games est une excellente lecture\u201D. Il est clair que l\u2019application d\u2019une sorte de correspondance exacte entre le r\xE9sum\xE9 g\xE9n\xE9r\xE9 et l\u2019\xE9tiquette n\u2019est pas une bonne solution - m\xEAme les humains auraient de mauvais r\xE9sultats avec une telle mesure, car nous avons tous notre propre style d\u2019\xE9criture."),Lv.forEach(t),qu=c(e),$n=l(e,"P",{});var Rp=o($n);qc=n(Rp,"Pour le r\xE9sum\xE9, l\u2019une des m\xE9triques les plus couramment utilis\xE9es est le "),vr=l(Rp,"A",{href:!0,rel:!0});var Av=o(vr);jc=n(Av,"score ROUGE"),Av.forEach(t),$c=n(Rp," (abr\xE9viation de Recall-Oriented Understudy for Gisting Evaluation). L\u2019id\xE9e de base de cette m\xE9trique est de comparer un r\xE9sum\xE9 g\xE9n\xE9r\xE9 avec un ensemble de r\xE9sum\xE9s de r\xE9f\xE9rence qui sont g\xE9n\xE9ralement cr\xE9\xE9s par des humains. Pour \xEAtre plus pr\xE9cis, supposons que nous voulions comparer les deux r\xE9sum\xE9s suivants :"),Rp.forEach(t),ju=c(e),q(gr.$$.fragment,e),$u=c(e),Zt=l(e,"P",{});var fo=o(Zt);xc=n(fo,"Une fa\xE7on de les comparer pourrait \xEAtre de compter le nombre de mots qui se chevauchent, qui dans ce cas serait de 6. Cependant, cette m\xE9thode est un peu grossi\xE8re, c\u2019est pourquoi ROUGE se base sur le calcul des scores de "),Ko=l(fo,"EM",{});var Ov=o(Ko);kc=n(Ov,"pr\xE9cision"),Ov.forEach(t),Ec=n(fo," et de "),Qo=l(fo,"EM",{});var Mv=o(Qo);wc=n(Mv,"rappel"),Mv.forEach(t),yc=n(fo," pour le chevauchement."),fo.forEach(t),xu=c(e),q(xn.$$.fragment,e),ku=c(e),_r=l(e,"P",{});var Of=o(_r);zc=n(Of,`Pour ROUGE, le rappel mesure la proportion du r\xE9sum\xE9 de r\xE9f\xE9rence qui est captur\xE9e par le r\xE9sum\xE9 g\xE9n\xE9r\xE9. Si nous ne faisons que comparer des mots, le rappel peut \xEAtre calcul\xE9 selon la formule suivante :
`),Eu=Hg(Of),Of.forEach(t),wu=c(e),br=l(e,"P",{});var Mf=o(br);Tc=n(Mf,`Pour notre exemple simple ci-dessus, cette formule donne un rappel parfait de 6/6 = 1 ; c\u2019est-\xE0-dire que tous les mots du r\xE9sum\xE9 de r\xE9f\xE9rence ont \xE9t\xE9 produits par le mod\xE8le. Cela peut sembler g\xE9nial, mais imaginez que le r\xE9sum\xE9 g\xE9n\xE9r\xE9 ait \xE9t\xE9 \u201CJ\u2019ai vraiment aim\xE9 lire les Hunger Games toute la nuit\u201D. Le rappel serait \xE9galement parfait, mais le r\xE9sum\xE9 serait sans doute moins bon puisqu\u2019il serait verbeux. Pour traiter ces sc\xE9narios, nous calculons \xE9galement la pr\xE9cision, qui, dans le contexte de ROUGE, mesure la proportion du r\xE9sum\xE9 g\xE9n\xE9r\xE9 qui \xE9tait pertinente :
`),yu=Hg(Mf),Mf.forEach(t),zu=c(e),ea=l(e,"P",{});var ho=o(ea);Cc=n(ho,"En appliquant cela \xE0 notre r\xE9sum\xE9 verbeux, on obtient une pr\xE9cision de 6/10 = 0,6, ce qui est consid\xE9rablement moins bon que la pr\xE9cision de 6/7 = 0,86 obtenue par notre r\xE9sum\xE9 plus court. En pratique, la pr\xE9cision et le rappel sont g\xE9n\xE9ralement calcul\xE9s, puis le score F1 (la moyenne harmonique de la pr\xE9cision et du rappel) est indiqu\xE9. Nous pouvons le faire facilement dans \u{1F917} "),Yo=l(ho,"EM",{});var Nv=o(Yo);Pc=n(Nv,"Datasets"),Nv.forEach(t),Dc=n(ho," en installant d\u2019abord le paquet "),Xo=l(ho,"CODE",{});var Rv=o(Xo);Sc=n(Rv,"rouge_score"),Rv.forEach(t),Lc=n(ho," :"),ho.forEach(t),Tu=c(e),q(qr.$$.fragment,e),Cu=c(e),Dl=l(e,"P",{});var Iv=o(Dl);Ac=n(Iv,"et ensuite charger la m\xE9trique ROUGE comme suit :"),Iv.forEach(t),Pu=c(e),q(jr.$$.fragment,e),Du=c(e),kn=l(e,"P",{});var Ip=o(kn);Oc=n(Ip,"Ensuite, nous pouvons utiliser la fonction "),Zo=l(Ip,"CODE",{});var Gv=o(Zo);Mc=n(Gv,"rouge_score.compute()"),Gv.forEach(t),Nc=n(Ip," pour calculer toutes les m\xE9triques en une seule fois :"),Ip.forEach(t),Su=c(e),q($r.$$.fragment,e),Lu=c(e),q(xr.$$.fragment,e),Au=c(e),Xe=l(e,"P",{});var Ds=o(Xe);Rc=n(Ds,"Whoa, il y a un batch d\u2019informations dans cette sortie. Qu\u2019est-ce que \xE7a veut dire ? Tout d\u2019abord, \u{1F917} "),ei=l(Ds,"EM",{});var Uv=o(ei);Ic=n(Uv,"Datasets"),Uv.forEach(t),Gc=n(Ds," calcule en fait des intervalles de confiance pour la pr\xE9cision, le rappel et le score F1 ; ce sont les attributs "),si=l(Ds,"CODE",{});var Hv=o(si);Uc=n(Hv,"low"),Hv.forEach(t),Hc=n(Ds,", "),ti=l(Ds,"CODE",{});var Fv=o(ti);Fc=n(Fv,"mid"),Fv.forEach(t),Jc=n(Ds,", et "),ai=l(Ds,"CODE",{});var Jv=o(ai);Bc=n(Jv,"high"),Jv.forEach(t),Vc=n(Ds," que vous pouvez voir ici. De plus, \u{1F917} "),ni=l(Ds,"EM",{});var Bv=o(ni);Wc=n(Bv,"Datasets"),Bv.forEach(t),Kc=n(Ds," calcule une vari\xE9t\xE9 de scores ROUGE qui sont bas\xE9s sur diff\xE9rents types de granularit\xE9 du texte lors de la comparaison des r\xE9sum\xE9s g\xE9n\xE9r\xE9s et de r\xE9f\xE9rence. La variante "),ri=l(Ds,"CODE",{});var Vv=o(ri);Qc=n(Vv,"rouge1"),Vv.forEach(t),Yc=n(Ds," est le chevauchement des unigrammes. C\u2019est juste une fa\xE7on fantaisiste de dire le chevauchement des mots et c\u2019est exactement la m\xE9trique dont nous avons discut\xE9 ci-dessus. Pour v\xE9rifier cela, nous allons extraire la valeur \u201Cmoyenne\u201D de nos scores :"),Ds.forEach(t),Ou=c(e),q(kr.$$.fragment,e),Mu=c(e),q(Er.$$.fragment,e),Nu=c(e),hs=l(e,"P",{});var pt=o(hs);Xc=n(pt,"Super, les chiffres de pr\xE9cision et de rappel correspondent ! Maintenant, qu\u2019en est-il des autres scores ROUGE ? "),li=l(pt,"CODE",{});var Wv=o(li);Zc=n(Wv,"rouge2"),Wv.forEach(t),ed=n(pt," mesure le chevauchement entre les bigrammes (pensez au chevauchement des paires de mots), tandis que "),oi=l(pt,"CODE",{});var Kv=o(oi);sd=n(Kv,"rougeL"),Kv.forEach(t),td=n(pt," et "),ii=l(pt,"CODE",{});var Qv=o(ii);ad=n(Qv,"rougeLsum"),Qv.forEach(t),nd=n(pt," mesurent les plus longues s\xE9quences de mots correspondants en recherchant les plus longues sous-souches communes dans les r\xE9sum\xE9s g\xE9n\xE9r\xE9s et de r\xE9f\xE9rence. La \u201Csomme\u201D dans "),ui=l(pt,"CODE",{});var Yv=o(ui);rd=n(Yv,"rougeLsum"),Yv.forEach(t),ld=n(pt," fait r\xE9f\xE9rence au fait que cette m\xE9trique est calcul\xE9e sur un r\xE9sum\xE9 entier, alors que "),pi=l(pt,"CODE",{});var Xv=o(pi);od=n(Xv,"rougeL"),Xv.forEach(t),id=n(pt," est calcul\xE9e comme une moyenne sur des phrases individuelles."),pt.forEach(t),Ru=c(e),q(En.$$.fragment,e),Iu=c(e),Sl=l(e,"P",{});var Zv=o(Sl);ud=n(Zv,"Nous utiliserons ces scores ROUGE pour suivre les performances de notre mod\xE8le, mais avant cela, faisons ce que tout bon praticien de NLP devrait faire : cr\xE9er une base de r\xE9f\xE9rence solide, mais simple !"),Zv.forEach(t),Gu=c(e),Aa=l(e,"H3",{class:!0});var Gp=o(Aa);wn=l(Gp,"A",{id:!0,class:!0,href:!0});var eg=o(wn);mi=l(eg,"SPAN",{});var sg=o(mi);q(wr.$$.fragment,sg),sg.forEach(t),eg.forEach(t),pd=c(Gp),ci=l(Gp,"SPAN",{});var tg=o(ci);md=n(tg,"Cr\xE9ation d'une base de r\xE9f\xE9rence solide"),tg.forEach(t),Gp.forEach(t),Uu=c(e),lt=l(e,"P",{});var Ln=o(lt);cd=n(Ln,"Une base de r\xE9f\xE9rence commune pour le r\xE9sum\xE9 de texte consiste \xE0 prendre simplement les trois premi\xE8res phrases d\u2019un article, souvent appel\xE9e la base de r\xE9f\xE9rence "),di=l(Ln,"EM",{});var ag=o(di);dd=n(ag,"lead-3"),ag.forEach(t),fd=n(Ln,". Nous pourrions utiliser des points pour suivre les limites de la phrase, mais cela \xE9chouera avec des acronymes comme \u201CU.S.\u201D ou \u201CU.N.\u201D. \u2014 Nous allons donc utiliser la biblioth\xE8que "),fi=l(Ln,"CODE",{});var ng=o(fi);hd=n(ng,"nltk"),ng.forEach(t),vd=n(Ln,", qui inclut un meilleur algorithme pour g\xE9rer ces cas. Vous pouvez installer le paquetage en utilisant "),hi=l(Ln,"CODE",{});var rg=o(hi);gd=n(rg,"pip"),rg.forEach(t),_d=n(Ln," comme suit :"),Ln.forEach(t),Hu=c(e),q(yr.$$.fragment,e),Fu=c(e),Ll=l(e,"P",{});var lg=o(Ll);bd=n(lg,"puis t\xE9l\xE9chargez les r\xE8gles de ponctuation :"),lg.forEach(t),Ju=c(e),q(zr.$$.fragment,e),Bu=c(e),sa=l(e,"P",{});var vo=o(sa);qd=n(vo,"Ensuite, nous importons le "),vi=l(vo,"EM",{});var og=o(vi);jd=n(og,"tokenizer"),og.forEach(t),$d=n(vo," de "),gi=l(vo,"CODE",{});var ig=o(gi);xd=n(ig,"nltk"),ig.forEach(t),kd=n(vo," et cr\xE9ons une fonction simple pour extraire les trois premi\xE8res phrases d\u2019une critique. La convention dans le r\xE9sum\xE9 de texte est de s\xE9parer chaque r\xE9sum\xE9 avec une nouvelle ligne, donc nous allons \xE9galement inclure ceci et le tester sur un exemple d\u2019entra\xEEnement :"),vo.forEach(t),Vu=c(e),q(Tr.$$.fragment,e),Wu=c(e),q(Cr.$$.fragment,e),Ku=c(e),Al=l(e,"P",{});var ug=o(Al);Ed=n(ug,"Cela semble fonctionner, alors impl\xE9mentons maintenant une fonction qui extrait ces \u201Cr\xE9sum\xE9s\u201D d\u2019un ensemble de donn\xE9es et calcule les scores ROUGE pour la ligne de base :"),ug.forEach(t),Qu=c(e),q(Pr.$$.fragment,e),Yu=c(e),Ol=l(e,"P",{});var pg=o(Ol);wd=n(pg,"Nous pouvons ensuite utiliser cette fonction pour calculer les scores ROUGE sur l\u2019ensemble de validation et les embellir un peu en utilisant Pandas :"),pg.forEach(t),Xu=c(e),q(Dr.$$.fragment,e),Zu=c(e),q(Sr.$$.fragment,e),ep=c(e),yn=l(e,"P",{});var Up=o(yn);yd=n(Up,"Nous pouvons voir que le score de "),_i=l(Up,"CODE",{});var mg=o(_i);zd=n(mg,"rouge2"),mg.forEach(t),Td=n(Up," est significativement plus bas que le reste ; ceci refl\xE8te probablement le fait que les titres des revues sont typiquement concis et donc que la ligne de base de lead-3 est trop verbeuse. Maintenant que nous disposons d\u2019une bonne base de travail, concentrons-nous sur le r\xE9glage fin de mT5 !"),Up.forEach(t),sp=c(e),Ct.l(e),Ml=c(e),q(zn.$$.fragment,e),tp=c(e),ta=l(e,"P",{});var go=o(ta);Cd=n(go,"La prochaine chose que nous devons faire est de nous connecter au "),bi=l(go,"EM",{});var cg=o(bi);Pd=n(cg,"Hub"),cg.forEach(t),Dd=n(go,". Si vous ex\xE9cutez ce code dans un "),qi=l(go,"EM",{});var dg=o(qi);Sd=n(dg,"notebook"),dg.forEach(t),Ld=n(go,", vous pouvez le faire avec la fonction utilitaire suivante :"),go.forEach(t),ap=c(e),q(Lr.$$.fragment,e),np=c(e),Tn=l(e,"P",{});var Hp=o(Tn);Ad=n(Hp,"qui affichera un "),ji=l(Hp,"EM",{});var fg=o(ji);Od=n(fg,"widget"),fg.forEach(t),Md=n(Hp," o\xF9 vous pourrez saisir vos informations d\u2019identification. Vous pouvez \xE9galement ex\xE9cuter cette commande dans votre terminal et vous connecter \xE0 partir de l\xE0 :"),Hp.forEach(t),rp=c(e),q(Ar.$$.fragment,e),lp=c(e),Ve&&Ve.l(e),Nl=c(e),Cn=l(e,"P",{});var Fp=o(Cn);Nd=n(Fp,"Ensuite, nous devons d\xE9finir un collateur de donn\xE9es pour notre t\xE2che de s\xE9quence \xE0 s\xE9quence. Comme mT5 est un mod\xE8le Transformer encodeur-d\xE9codeur, une des subtilit\xE9s de la pr\xE9paration de nos lots est que, pendant le d\xE9codage, nous devons d\xE9caler les \xE9tiquettes d\u2019une unit\xE9 vers la droite. Ceci est n\xE9cessaire pour garantir que le d\xE9codeur ne voit que les \xE9tiquettes de v\xE9rit\xE9 terrain pr\xE9c\xE9dentes et non les \xE9tiquettes actuelles ou futures, qui seraient faciles \xE0 m\xE9moriser pour le mod\xE8le. Cela ressemble \xE0 la fa\xE7on dont l\u2019auto-attention masqu\xE9e est appliqu\xE9e aux entr\xE9es dans une t\xE2che comme "),Rl=l(Fp,"A",{href:!0});var hg=o(Rl);Rd=n(hg,"la mod\xE9lisation causale du langage"),hg.forEach(t),Id=n(Fp,"."),Fp.forEach(t),op=c(e),Ps=l(e,"P",{});var ua=o(Ps);Gd=n(ua,"Heureusement, \u{1F917} "),$i=l(ua,"EM",{});var vg=o($i);Ud=n(vg,"Transformers"),vg.forEach(t),Hd=n(ua," fournit un collateur "),xi=l(ua,"CODE",{});var gg=o(xi);Fd=n(gg,"DataCollatorForSeq2Seq"),gg.forEach(t),Jd=n(ua," qui rembourrera dynamiquement les entr\xE9es et les \xE9tiquettes pour nous. Pour instancier ce collateur, nous devons simplement fournir le "),ki=l(ua,"EM",{});var _g=o(ki);Bd=n(_g,"tokenizer"),_g.forEach(t),Vd=n(ua," et le "),Ei=l(ua,"CODE",{});var bg=o(Ei);Wd=n(bg,"model"),bg.forEach(t),Kd=n(ua," :"),ua.forEach(t),ip=c(e),Dt.l(e),Il=c(e),Gl=l(e,"P",{});var qg=o(Gl);Qd=n(qg,"Voyons ce que produit ce collateur lorsqu\u2019on lui donne un petit lot d\u2019exemples. Tout d\u2019abord, nous devons supprimer les colonnes contenant des cha\xEEnes de caract\xE8res, car le collateur ne saura pas comment remplir ces \xE9l\xE9ments :"),qg.forEach(t),up=c(e),q(Or.$$.fragment,e),pp=c(e),aa=l(e,"P",{});var _o=o(aa);Yd=n(_o,"Comme le collateur attend une liste de "),wi=l(_o,"CODE",{});var jg=o(wi);Xd=n(jg,"dict"),jg.forEach(t),Zd=n(_o,"s, o\xF9 chaque "),yi=l(_o,"CODE",{});var $g=o(yi);ef=n($g,"dict"),$g.forEach(t),sf=n(_o," repr\xE9sente un seul exemple dans l\u2019ensemble de donn\xE9es, nous devons \xE9galement mettre les donn\xE9es dans le format attendu avant de les transmettre au collateur de donn\xE9es :"),_o.forEach(t),mp=c(e),q(Mr.$$.fragment,e),cp=c(e),q(Nr.$$.fragment,e),dp=c(e),xe=l(e,"P",{});var Je=o(xe);tf=n(Je,"La principale chose \xE0 remarquer ici est que le premier exemple est plus long que le second, donc les "),zi=l(Je,"CODE",{});var xg=o(zi);af=n(xg,"input_ids"),xg.forEach(t),nf=n(Je," et "),Ti=l(Je,"CODE",{});var kg=o(Ti);rf=n(kg,"attention_mask"),kg.forEach(t),lf=n(Je," du second exemple ont \xE9t\xE9 compl\xE9t\xE9s sur la droite avec un jeton "),Ci=l(Je,"CODE",{});var Eg=o(Ci);of=n(Eg,"[PAD]"),Eg.forEach(t),uf=n(Je," (dont l\u2019ID est "),Pi=l(Je,"CODE",{});var wg=o(Pi);pf=n(wg,"0"),wg.forEach(t),mf=n(Je,"). De m\xEAme, nous pouvons voir que les "),Di=l(Je,"CODE",{});var yg=o(Di);cf=n(yg,"labels"),yg.forEach(t),df=n(Je," ont \xE9t\xE9 compl\xE9t\xE9s par des "),Si=l(Je,"CODE",{});var zg=o(Si);ff=n(zg,"-100"),zg.forEach(t),hf=n(Je,"s, pour s\u2019assurer que les "),Li=l(Je,"EM",{});var Tg=o(Li);vf=n(Tg,"tokens"),Tg.forEach(t),gf=n(Je," de remplissage sont ignor\xE9s par la fonction de perte. Et enfin, nous pouvons voir un nouveau "),Ai=l(Je,"CODE",{});var Cg=o(Ai);_f=n(Cg,"decoder_input_ids"),Cg.forEach(t),bf=n(Je," qui a d\xE9plac\xE9 les \xE9tiquettes vers la droite en ins\xE9rant un jeton "),Oi=l(Je,"CODE",{});var Pg=o(Oi);qf=n(Pg,"[PAD]"),Pg.forEach(t),jf=n(Je," dans la premi\xE8re entr\xE9e."),Je.forEach(t),fp=c(e),Lt.l(e),Ul=c(e),We&&We.l(e),Hl=c(e),Oa=l(e,"H2",{class:!0});var Jp=o(Oa);Pn=l(Jp,"A",{id:!0,class:!0,href:!0});var Dg=o(Pn);Mi=l(Dg,"SPAN",{});var Sg=o(Mi);q(Rr.$$.fragment,Sg),Sg.forEach(t),Dg.forEach(t),$f=c(Jp),Ni=l(Jp,"SPAN",{});var Lg=o(Ni);xf=n(Lg,"Utilisation de votre mod\xE8le *finetun\xE9*"),Lg.forEach(t),Jp.forEach(t),hp=c(e),na=l(e,"P",{});var bo=o(na);kf=n(bo,"Une fois que vous avez pouss\xE9 le mod\xE8le vers le "),Ri=l(bo,"EM",{});var Ag=o(Ri);Ef=n(Ag,"Hub"),Ag.forEach(t),wf=n(bo,", vous pouvez jouer avec lui soit via le widget d\u2019inf\xE9rence, soit avec un objet "),Ii=l(bo,"CODE",{});var Og=o(Ii);yf=n(Og,"pipeline"),Og.forEach(t),zf=n(bo,", comme suit :"),bo.forEach(t),vp=c(e),q(Ir.$$.fragment,e),gp=c(e),Fl=l(e,"P",{});var Mg=o(Fl);Tf=n(Mg,"Nous pouvons alimenter notre pipeline avec quelques exemples de l\u2019ensemble de test (que le mod\xE8le n\u2019a pas vu) pour avoir une id\xE9e de la qualit\xE9 des r\xE9sum\xE9s. Tout d\u2019abord, impl\xE9mentons une fonction simple pour afficher ensemble la critique, le titre et le r\xE9sum\xE9 g\xE9n\xE9r\xE9 :"),Mg.forEach(t),_p=c(e),q(Gr.$$.fragment,e),bp=c(e),Jl=l(e,"P",{});var Ng=o(Jl);Cf=n(Ng,"Examinons l\u2019un des exemples anglais que nous recevons :"),Ng.forEach(t),qp=c(e),q(Ur.$$.fragment,e),jp=c(e),q(Hr.$$.fragment,e),$p=c(e),Dn=l(e,"P",{});var Bp=o(Dn);Pf=n(Bp,"Ce n\u2019est pas si mal ! Nous pouvons voir que notre mod\xE8le a \xE9t\xE9 capable d\u2019effectuer un r\xE9sum\xE9 "),Gi=l(Bp,"EM",{});var Rg=o(Gi);Df=n(Rg,"abstractif"),Rg.forEach(t),Sf=n(Bp," en augmentant certaines parties de la critique avec de nouveaux mots. Et peut-\xEAtre que l\u2019aspect le plus cool de notre mod\xE8le est qu\u2019il est bilingue, donc nous pouvons \xE9galement g\xE9n\xE9rer des r\xE9sum\xE9s de critiques en espagnol :"),Bp.forEach(t),xp=c(e),q(Fr.$$.fragment,e),kp=c(e),q(Jr.$$.fragment,e),Ep=c(e),Bl=l(e,"P",{});var Ig=o(Bl);Lf=n(Ig,"Le r\xE9sum\xE9 se traduit par \u201CTr\xE8s facile \xE0 lire\u201D, ce qui, comme nous pouvons le constater, a \xE9t\xE9 extrait directement de la critique. N\xE9anmoins, cela montre la polyvalence du mod\xE8le mT5 et vous a donn\xE9 un aper\xE7u de ce que c\u2019est que de traiter un corpus multilingue !"),Ig.forEach(t),wp=c(e),Vl=l(e,"P",{});var Gg=o(Vl);Af=n(Gg,"Ensuite, nous allons nous int\xE9resser \xE0 une t\xE2che un peu plus complexe : entra\xEEner un mod\xE8le de langue \xE0 partir de z\xE9ro."),Gg.forEach(t),this.h()},h(){h(d,"name","hf:doc:metadata"),h(d,"content",JSON.stringify(__)),h(y,"id","rsum-de-textes"),h(y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(y,"href","#rsum-de-textes"),h(P,"class","relative group"),h(ae,"href","https://huggingface.co/models?pipeline_tag=summarization&sort=downloads"),h(ae,"rel","nofollow"),h(ne,"href","https://huggingface.co/huggingface-course/mt5-small-finetuned-amazon-en-es"),h(ne,"rel","nofollow"),qo(F.src,Ie="https://hf.space/gradioiframe/course-demos/mt5-small-finetuned-amazon-en-es/+")||h(F,"src",Ie),h(F,"frameborder","0"),h(F,"height","400"),h(F,"title","Gradio app"),h(F,"class","block dark:hidden container p-0 flex-grow space-iframe"),h(F,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),h(F,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),qo(re.src,k="https://hf.space/gradioiframe/course-demos/mt5-small-finetuned-amazon-en-es-darkmode/+")||h(re,"src",k),h(re,"frameborder","0"),h(re,"height","400"),h(re,"title","Gradio app"),h(re,"class","hidden dark:block container p-0 flex-grow space-iframe"),h(re,"allow","accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking"),h(re,"sandbox","allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads"),h(de,"id","prparation-dun-corpus-multilingue"),h(de,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(de,"href","#prparation-dun-corpus-multilingue"),h(ve,"class","relative group"),h(K,"href","https://huggingface.co/datasets/amazon_reviews_multi"),h(K,"rel","nofollow"),h(ts,"href","/course/fr/chapter5"),h(Fs,"href","/course/fr/chapter5"),h($t,"class","block dark:hidden"),qo($t.src,Wa="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/review-lengths.svg")||h($t,"src",Wa),h($t,"alt","Word count distributions for the review titles and texts."),h(xt,"class","hidden dark:block"),qo(xt.src,Ka="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/review-lengths-dark.svg")||h(xt,"src",Ka),h(xt,"alt","Word count distributions for the review titles and texts."),h(Ce,"class","flex justify-center"),h(Xs,"id","modles-pour-le-rsum-de-texte"),h(Xs,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Xs,"href","#modles-pour-le-rsum-de-texte"),h(bs,"class","relative group"),h(xa,"href","/course/fr/chapter1"),h(ka,"align","center"),h(yt,"align","center"),h(st,"href","https://huggingface.co/gpt2-xl"),h(st,"rel","nofollow"),h(Ea,"align","center"),h(wa,"align","center"),h(at,"href","https://huggingface.co/google/pegasus-large"),h(at,"rel","nofollow"),h(ya,"align","center"),h(zt,"align","center"),h(rt,"href","https://huggingface.co/t5-base"),h(rt,"rel","nofollow"),h(za,"align","center"),h(bl,"align","center"),h(Zn,"href","https://huggingface.co/google/mt5-base"),h(Zn,"rel","nofollow"),h(ql,"align","center"),h(jl,"align","center"),h(er,"href","https://huggingface.co/facebook/bart-base"),h(er,"rel","nofollow"),h($l,"align","center"),h(xl,"align","center"),h(tr,"href","https://huggingface.co/facebook/mbart-large-50"),h(tr,"rel","nofollow"),h(kl,"align","center"),h(El,"align","center"),h(ar,"class","block dark:hidden"),qo(ar.src,Rf="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/t5.svg")||h(ar,"src",Rf),h(ar,"alt","Different tasks performed by the T5 architecture."),h(nr,"class","hidden dark:block"),qo(nr.src,If="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter7/t5-dark.svg")||h(nr,"src",If),h(nr,"alt","Different tasks performed by the T5 architecture."),h(Da,"class","flex justify-center"),h(gn,"id","prtraitement-des-donnes"),h(gn,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(gn,"href","#prtraitement-des-donnes"),h(Sa,"class","relative group"),h(zl,"href","/course/fr/chapter3"),h(Tl,"href","/course/chapter6"),h(jn,"id","mtriques-pour-le-rsum-de-texte"),h(jn,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(jn,"href","#mtriques-pour-le-rsum-de-texte"),h(La,"class","relative group"),h(vr,"href","https://en.wikipedia.org/wiki/ROUGE_(metric)"),h(vr,"rel","nofollow"),Eu.a=null,yu.a=null,h(wn,"id","cration-dune-base-de-rfrence-solide"),h(wn,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(wn,"href","#cration-dune-base-de-rfrence-solide"),h(Aa,"class","relative group"),h(Rl,"href","/course/fr/chapter7/6"),h(Pn,"id","utilisation-de-votre-modle-finetun"),h(Pn,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),h(Pn,"href","#utilisation-de-votre-modle-finetun"),h(Oa,"class","relative group")},m(e,u){s(document.head,d),i(e,x,u),j(f,e,u),i(e,w,u),i(e,P,u),s(P,y),s(y,S),j(D,S,null),s(P,E),s(P,M),s(M,N),i(e,A,u),Br[C].m(e,u),i(e,L,u),i(e,V,u),s(V,W),s(V,ee),s(ee,J),s(V,B),s(V,Y),s(Y,le),s(V,O),i(e,Q,u),j(oe,e,u),i(e,H,u),i(e,U,u),s(U,te),s(U,se),s(se,ie),s(U,X),s(U,ae),s(ae,_e),s(U,ce),s(U,ne),s(ne,je),s(U,Re),i(e,Pe,u),i(e,F,u),i(e,he,u),i(e,re,u),i(e,R,u),i(e,De,u),s(De,ke),i(e,Ee,u),i(e,ve,u),s(ve,de),s(de,be),j(pe,be,null),s(ve,Se),s(ve,we),s(we,Ue),i(e,ls,u),i(e,$e,u),s($e,_),s($e,K),s(K,Be),s($e,Ze),s($e,ue),s(ue,os),s($e,is),i(e,ge,u),j(Le,e,u),i(e,Ke,u),j(ye,e,u),i(e,us,u),i(e,fe,u),s(fe,qs),s(fe,Qe),s(Qe,es),s(fe,vs),s(fe,js),s(js,ss),s(fe,Is),s(fe,ts),s(ts,Gs),s(fe,ps),i(e,He,u),j(I,e,u),i(e,me,u),j($s,e,u),i(e,Ss,u),j(gs,e,u),i(e,qe,u),i(e,Ge,u),s(Ge,Ot),s(Ge,xs),s(xs,Mt),s(Ge,Nt),s(Ge,Ls),s(Ls,As),s(Ge,Ae),i(e,Us,u),j(Ye,e,u),i(e,Hs,u),j(as,e,u),i(e,ct,u),i(e,Oe,u),s(Oe,ks),s(Oe,ze),s(ze,ns),s(Oe,Rt),s(Oe,Es),s(Es,It),s(Oe,Gt),s(Oe,Fs),s(Fs,On),s(Oe,Mn),s(Oe,Ut),s(Ut,ws),s(Oe,Nn),i(e,Ht,u),j(dt,e,u),i(e,Na,u),i(e,Me,u),s(Me,Rn),s(Me,pa),s(pa,Ra),s(Me,ft),s(Me,Ft),s(Ft,ht),s(Me,Ia),s(Me,Js),s(Js,In),s(Me,Ga),s(Me,Os),s(Os,Ua),s(Me,Bs),s(Me,ma),s(ma,ca),s(Me,Gn),i(e,Ha,u),j(Vs,e,u),i(e,ys,u),i(e,_s,u),s(_s,da),i(e,Ws,u),j(vt,e,u),i(e,Jt,u),j(gt,e,u),i(e,fa,u),i(e,Te,u),s(Te,Un),s(Te,_t),s(_t,Hn),s(Te,Fn),s(Te,Bt),s(Bt,ms),s(Te,bt),s(Te,ha),s(ha,va),s(Te,Jn),s(Te,ga),s(ga,Bn),s(Te,qt),i(e,Fa,u),j(Ms,e,u),i(e,Ja,u),j(jt,e,u),i(e,Ba,u),i(e,Ks,u),s(Ks,Vn),i(e,Va,u),i(e,Ce,u),s(Ce,$t),s(Ce,Wn),s(Ce,xt),i(e,Qa,u),i(e,Qs,u),s(Qs,_a),s(Qs,ba),s(ba,Kn),s(Qs,qa),i(e,Ya,u),j(kt,e,u),i(e,ja,u),i(e,rs,u),s(rs,Qn),s(rs,Vt),s(Vt,Et),s(rs,Xa),s(rs,Ns),s(Ns,Za),s(rs,Ys),i(e,en,u),i(e,bs,u),s(bs,Xs),s(Xs,$a),j(Zs,$a,null),s(bs,p),s(bs,z),s(z,Yr),i(e,Yn,u),i(e,Rs,u),s(Rs,cs),s(Rs,xa),s(xa,Xr),s(Rs,Zr),s(Rs,sn),s(sn,el),s(Rs,tn),i(e,Xn,u),i(e,wt,u),s(wt,an),s(an,ds),s(ds,ka),s(ka,nn),s(nn,rn),s(ds,sl),s(ds,ln),s(ln,on),s(ds,tl),s(ds,yt),s(yt,al),s(wt,nl),s(wt,Ne),s(Ne,et),s(et,Ea),s(Ea,st),s(st,rl),s(et,ll),s(et,un),s(un,Wt),s(et,ol),s(et,wa),s(wa,Kt),s(Ne,il),s(Ne,tt),s(tt,ya),s(ya,at),s(at,ul),s(tt,pn),s(tt,mn),s(mn,pl),s(tt,ml),s(tt,zt),s(zt,cl),s(Ne,nt),s(Ne,zs),s(zs,za),s(za,rt),s(rt,dl),s(zs,fl),s(zs,Fe),s(Fe,hl),s(Fe,cn),s(cn,vl),s(Fe,gl),s(Fe,dn),s(dn,fn),s(Fe,_l),s(zs,Vp),s(zs,bl),s(bl,Wp),s(Ne,Kp),s(Ne,Ta),s(Ta,ql),s(ql,Zn),s(Zn,Qp),s(Ta,Yp),s(Ta,xo),s(xo,Xp),s(Ta,Zp),s(Ta,jl),s(jl,em),s(Ne,sm),s(Ne,Ca),s(Ca,$l),s($l,er),s(er,tm),s(Ca,am),s(Ca,sr),s(sr,nm),s(sr,ko),s(ko,rm),s(sr,lm),s(Ca,om),s(Ca,xl),s(xl,im),s(Ne,um),s(Ne,Pa),s(Pa,kl),s(kl,tr),s(tr,pm),s(Pa,mm),s(Pa,Eo),s(Eo,cm),s(Pa,dm),s(Pa,El),s(El,fm),i(e,Vi,u),i(e,wl,u),s(wl,hm),i(e,Wi,u),i(e,hn,u),s(hn,vm),s(hn,wo),s(wo,gm),s(hn,_m),i(e,Ki,u),i(e,Da,u),s(Da,ar),s(Da,bm),s(Da,nr),i(e,Qi,u),i(e,yl,u),s(yl,qm),i(e,Yi,u),j(vn,e,u),i(e,Xi,u),i(e,Sa,u),s(Sa,gn),s(gn,yo),j(rr,yo,null),s(Sa,jm),s(Sa,zo),s(zo,$m),i(e,Zi,u),j(lr,e,u),i(e,eu,u),i(e,Qt,u),s(Qt,xm),s(Qt,To),s(To,km),s(Qt,Em),s(Qt,Co),s(Co,wm),s(Qt,ym),i(e,su,u),j(or,e,u),i(e,tu,u),j(_n,e,u),i(e,au,u),i(e,bn,u),s(bn,zm),s(bn,Po),s(Po,Tm),s(bn,Cm),i(e,nu,u),j(ir,e,u),i(e,ru,u),j(ur,e,u),i(e,lu,u),i(e,Ts,u),s(Ts,Pm),s(Ts,Do),s(Do,Dm),s(Ts,Sm),s(Ts,So),s(So,Lm),s(Ts,Am),s(Ts,zl),s(zl,Om),s(Ts,Mm),s(Ts,Lo),s(Lo,Nm),s(Ts,Rm),i(e,ou,u),j(pr,e,u),i(e,iu,u),j(mr,e,u),i(e,uu,u),i(e,fs,u),s(fs,Im),s(fs,Ao),s(Ao,Gm),s(fs,Um),s(fs,Oo),s(Oo,Hm),s(fs,Fm),s(fs,Mo),s(Mo,Jm),s(fs,Bm),s(fs,No),s(No,Vm),s(fs,Wm),s(fs,Tl),s(Tl,Km),s(fs,Qm),i(e,pu,u),i(e,Yt,u),s(Yt,Ym),s(Yt,Ro),s(Ro,Xm),s(Yt,Zm),s(Yt,Io),s(Io,ec),s(Yt,sc),i(e,mu,u),j(cr,e,u),i(e,cu,u),i(e,Cs,u),s(Cs,tc),s(Cs,Go),s(Go,ac),s(Cs,nc),s(Cs,Uo),s(Uo,rc),s(Cs,lc),s(Cs,Ho),s(Ho,oc),s(Cs,ic),s(Cs,Fo),s(Fo,uc),s(Cs,pc),i(e,du,u),i(e,Xt,u),s(Xt,mc),s(Xt,Jo),s(Jo,cc),s(Xt,dc),s(Xt,Bo),s(Bo,fc),s(Xt,hc),i(e,fu,u),j(dr,e,u),i(e,hu,u),i(e,Cl,u),s(Cl,vc),i(e,vu,u),j(qn,e,u),i(e,gu,u),i(e,La,u),s(La,jn),s(jn,Vo),j(fr,Vo,null),s(La,gc),s(La,Wo),s(Wo,_c),i(e,_u,u),j(hr,e,u),i(e,bu,u),i(e,Pl,u),s(Pl,bc),i(e,qu,u),i(e,$n,u),s($n,qc),s($n,vr),s(vr,jc),s($n,$c),i(e,ju,u),j(gr,e,u),i(e,$u,u),i(e,Zt,u),s(Zt,xc),s(Zt,Ko),s(Ko,kc),s(Zt,Ec),s(Zt,Qo),s(Qo,wc),s(Zt,yc),i(e,xu,u),j(xn,e,u),i(e,ku,u),i(e,_r,u),s(_r,zc),Eu.m(Vg,_r),i(e,wu,u),i(e,br,u),s(br,Tc),yu.m(Wg,br),i(e,zu,u),i(e,ea,u),s(ea,Cc),s(ea,Yo),s(Yo,Pc),s(ea,Dc),s(ea,Xo),s(Xo,Sc),s(ea,Lc),i(e,Tu,u),j(qr,e,u),i(e,Cu,u),i(e,Dl,u),s(Dl,Ac),i(e,Pu,u),j(jr,e,u),i(e,Du,u),i(e,kn,u),s(kn,Oc),s(kn,Zo),s(Zo,Mc),s(kn,Nc),i(e,Su,u),j($r,e,u),i(e,Lu,u),j(xr,e,u),i(e,Au,u),i(e,Xe,u),s(Xe,Rc),s(Xe,ei),s(ei,Ic),s(Xe,Gc),s(Xe,si),s(si,Uc),s(Xe,Hc),s(Xe,ti),s(ti,Fc),s(Xe,Jc),s(Xe,ai),s(ai,Bc),s(Xe,Vc),s(Xe,ni),s(ni,Wc),s(Xe,Kc),s(Xe,ri),s(ri,Qc),s(Xe,Yc),i(e,Ou,u),j(kr,e,u),i(e,Mu,u),j(Er,e,u),i(e,Nu,u),i(e,hs,u),s(hs,Xc),s(hs,li),s(li,Zc),s(hs,ed),s(hs,oi),s(oi,sd),s(hs,td),s(hs,ii),s(ii,ad),s(hs,nd),s(hs,ui),s(ui,rd),s(hs,ld),s(hs,pi),s(pi,od),s(hs,id),i(e,Ru,u),j(En,e,u),i(e,Iu,u),i(e,Sl,u),s(Sl,ud),i(e,Gu,u),i(e,Aa,u),s(Aa,wn),s(wn,mi),j(wr,mi,null),s(Aa,pd),s(Aa,ci),s(ci,md),i(e,Uu,u),i(e,lt,u),s(lt,cd),s(lt,di),s(di,dd),s(lt,fd),s(lt,fi),s(fi,hd),s(lt,vd),s(lt,hi),s(hi,gd),s(lt,_d),i(e,Hu,u),j(yr,e,u),i(e,Fu,u),i(e,Ll,u),s(Ll,bd),i(e,Ju,u),j(zr,e,u),i(e,Bu,u),i(e,sa,u),s(sa,qd),s(sa,vi),s(vi,jd),s(sa,$d),s(sa,gi),s(gi,xd),s(sa,kd),i(e,Vu,u),j(Tr,e,u),i(e,Wu,u),j(Cr,e,u),i(e,Ku,u),i(e,Al,u),s(Al,Ed),i(e,Qu,u),j(Pr,e,u),i(e,Yu,u),i(e,Ol,u),s(Ol,wd),i(e,Xu,u),j(Dr,e,u),i(e,Zu,u),j(Sr,e,u),i(e,ep,u),i(e,yn,u),s(yn,yd),s(yn,_i),s(_i,zd),s(yn,Td),i(e,sp,u),Vr[Tt].m(e,u),i(e,Ml,u),j(zn,e,u),i(e,tp,u),i(e,ta,u),s(ta,Cd),s(ta,bi),s(bi,Pd),s(ta,Dd),s(ta,qi),s(qi,Sd),s(ta,Ld),i(e,ap,u),j(Lr,e,u),i(e,np,u),i(e,Tn,u),s(Tn,Ad),s(Tn,ji),s(ji,Od),s(Tn,Md),i(e,rp,u),j(Ar,e,u),i(e,lp,u),Ve&&Ve.m(e,u),i(e,Nl,u),i(e,Cn,u),s(Cn,Nd),s(Cn,Rl),s(Rl,Rd),s(Cn,Id),i(e,op,u),i(e,Ps,u),s(Ps,Gd),s(Ps,$i),s($i,Ud),s(Ps,Hd),s(Ps,xi),s(xi,Fd),s(Ps,Jd),s(Ps,ki),s(ki,Bd),s(Ps,Vd),s(Ps,Ei),s(Ei,Wd),s(Ps,Kd),i(e,ip,u),Wr[Pt].m(e,u),i(e,Il,u),i(e,Gl,u),s(Gl,Qd),i(e,up,u),j(Or,e,u),i(e,pp,u),i(e,aa,u),s(aa,Yd),s(aa,wi),s(wi,Xd),s(aa,Zd),s(aa,yi),s(yi,ef),s(aa,sf),i(e,mp,u),j(Mr,e,u),i(e,cp,u),j(Nr,e,u),i(e,dp,u),i(e,xe,u),s(xe,tf),s(xe,zi),s(zi,af),s(xe,nf),s(xe,Ti),s(Ti,rf),s(xe,lf),s(xe,Ci),s(Ci,of),s(xe,uf),s(xe,Pi),s(Pi,pf),s(xe,mf),s(xe,Di),s(Di,cf),s(xe,df),s(xe,Si),s(Si,ff),s(xe,hf),s(xe,Li),s(Li,vf),s(xe,gf),s(xe,Ai),s(Ai,_f),s(xe,bf),s(xe,Oi),s(Oi,qf),s(xe,jf),i(e,fp,u),Kr[St].m(e,u),i(e,Ul,u),We&&We.m(e,u),i(e,Hl,u),i(e,Oa,u),s(Oa,Pn),s(Pn,Mi),j(Rr,Mi,null),s(Oa,$f),s(Oa,Ni),s(Ni,xf),i(e,hp,u),i(e,na,u),s(na,kf),s(na,Ri),s(Ri,Ef),s(na,wf),s(na,Ii),s(Ii,yf),s(na,zf),i(e,vp,u),j(Ir,e,u),i(e,gp,u),i(e,Fl,u),s(Fl,Tf),i(e,_p,u),j(Gr,e,u),i(e,bp,u),i(e,Jl,u),s(Jl,Cf),i(e,qp,u),j(Ur,e,u),i(e,jp,u),j(Hr,e,u),i(e,$p,u),i(e,Dn,u),s(Dn,Pf),s(Dn,Gi),s(Gi,Df),s(Dn,Sf),i(e,xp,u),j(Fr,e,u),i(e,kp,u),j(Jr,e,u),i(e,Ep,u),i(e,Bl,u),s(Bl,Lf),i(e,wp,u),i(e,Vl,u),s(Vl,Af),yp=!0},p(e,[u]){const Qr={};u&1&&(Qr.fw=e[0]),f.$set(Qr);let Wl=C;C=Uf(e),C!==Wl&&($o(),g(Br[Wl],1,1,()=>{Br[Wl]=null}),jo(),G=Br[C],G||(G=Br[C]=Gf[C](e),G.c()),v(G,1),G.m(L.parentNode,L));const Ui={};u&2&&(Ui.$$scope={dirty:u,ctx:e}),gs.$set(Ui);const Hi={};u&2&&(Hi.$$scope={dirty:u,ctx:e}),vn.$set(Hi);const Ma={};u&2&&(Ma.$$scope={dirty:u,ctx:e}),_n.$set(Ma);const Fi={};u&2&&(Fi.$$scope={dirty:u,ctx:e}),qn.$set(Fi);const Ji={};u&2&&(Ji.$$scope={dirty:u,ctx:e}),xn.$set(Ji);const At={};u&2&&(At.$$scope={dirty:u,ctx:e}),En.$set(At);let Kl=Tt;Tt=Ff(e),Tt!==Kl&&($o(),g(Vr[Kl],1,1,()=>{Vr[Kl]=null}),jo(),Ct=Vr[Tt],Ct||(Ct=Vr[Tt]=Hf[Tt](e),Ct.c()),v(Ct,1),Ct.m(Ml.parentNode,Ml));const Bi={};u&2&&(Bi.$$scope={dirty:u,ctx:e}),zn.$set(Bi),e[0]==="pt"?Ve?u&1&&v(Ve,1):(Ve=Fg(),Ve.c(),v(Ve,1),Ve.m(Nl.parentNode,Nl)):Ve&&($o(),g(Ve,1,1,()=>{Ve=null}),jo());let Ql=Pt;Pt=Bf(e),Pt!==Ql&&($o(),g(Wr[Ql],1,1,()=>{Wr[Ql]=null}),jo(),Dt=Wr[Pt],Dt||(Dt=Wr[Pt]=Jf[Pt](e),Dt.c()),v(Dt,1),Dt.m(Il.parentNode,Il));let Yl=St;St=Wf(e),St!==Yl&&($o(),g(Kr[Yl],1,1,()=>{Kr[Yl]=null}),jo(),Lt=Kr[St],Lt||(Lt=Kr[St]=Vf[St](e),Lt.c()),v(Lt,1),Lt.m(Ul.parentNode,Ul)),e[0]==="pt"?We?u&1&&v(We,1):(We=Jg(e),We.c(),v(We,1),We.m(Hl.parentNode,Hl)):We&&($o(),g(We,1,1,()=>{We=null}),jo())},i(e){yp||(v(f.$$.fragment,e),v(D.$$.fragment,e),v(G),v(oe.$$.fragment,e),v(pe.$$.fragment,e),v(Le.$$.fragment,e),v(ye.$$.fragment,e),v(I.$$.fragment,e),v($s.$$.fragment,e),v(gs.$$.fragment,e),v(Ye.$$.fragment,e),v(as.$$.fragment,e),v(dt.$$.fragment,e),v(Vs.$$.fragment,e),v(vt.$$.fragment,e),v(gt.$$.fragment,e),v(Ms.$$.fragment,e),v(jt.$$.fragment,e),v(kt.$$.fragment,e),v(Zs.$$.fragment,e),v(vn.$$.fragment,e),v(rr.$$.fragment,e),v(lr.$$.fragment,e),v(or.$$.fragment,e),v(_n.$$.fragment,e),v(ir.$$.fragment,e),v(ur.$$.fragment,e),v(pr.$$.fragment,e),v(mr.$$.fragment,e),v(cr.$$.fragment,e),v(dr.$$.fragment,e),v(qn.$$.fragment,e),v(fr.$$.fragment,e),v(hr.$$.fragment,e),v(gr.$$.fragment,e),v(xn.$$.fragment,e),v(qr.$$.fragment,e),v(jr.$$.fragment,e),v($r.$$.fragment,e),v(xr.$$.fragment,e),v(kr.$$.fragment,e),v(Er.$$.fragment,e),v(En.$$.fragment,e),v(wr.$$.fragment,e),v(yr.$$.fragment,e),v(zr.$$.fragment,e),v(Tr.$$.fragment,e),v(Cr.$$.fragment,e),v(Pr.$$.fragment,e),v(Dr.$$.fragment,e),v(Sr.$$.fragment,e),v(Ct),v(zn.$$.fragment,e),v(Lr.$$.fragment,e),v(Ar.$$.fragment,e),v(Ve),v(Dt),v(Or.$$.fragment,e),v(Mr.$$.fragment,e),v(Nr.$$.fragment,e),v(Lt),v(We),v(Rr.$$.fragment,e),v(Ir.$$.fragment,e),v(Gr.$$.fragment,e),v(Ur.$$.fragment,e),v(Hr.$$.fragment,e),v(Fr.$$.fragment,e),v(Jr.$$.fragment,e),yp=!0)},o(e){g(f.$$.fragment,e),g(D.$$.fragment,e),g(G),g(oe.$$.fragment,e),g(pe.$$.fragment,e),g(Le.$$.fragment,e),g(ye.$$.fragment,e),g(I.$$.fragment,e),g($s.$$.fragment,e),g(gs.$$.fragment,e),g(Ye.$$.fragment,e),g(as.$$.fragment,e),g(dt.$$.fragment,e),g(Vs.$$.fragment,e),g(vt.$$.fragment,e),g(gt.$$.fragment,e),g(Ms.$$.fragment,e),g(jt.$$.fragment,e),g(kt.$$.fragment,e),g(Zs.$$.fragment,e),g(vn.$$.fragment,e),g(rr.$$.fragment,e),g(lr.$$.fragment,e),g(or.$$.fragment,e),g(_n.$$.fragment,e),g(ir.$$.fragment,e),g(ur.$$.fragment,e),g(pr.$$.fragment,e),g(mr.$$.fragment,e),g(cr.$$.fragment,e),g(dr.$$.fragment,e),g(qn.$$.fragment,e),g(fr.$$.fragment,e),g(hr.$$.fragment,e),g(gr.$$.fragment,e),g(xn.$$.fragment,e),g(qr.$$.fragment,e),g(jr.$$.fragment,e),g($r.$$.fragment,e),g(xr.$$.fragment,e),g(kr.$$.fragment,e),g(Er.$$.fragment,e),g(En.$$.fragment,e),g(wr.$$.fragment,e),g(yr.$$.fragment,e),g(zr.$$.fragment,e),g(Tr.$$.fragment,e),g(Cr.$$.fragment,e),g(Pr.$$.fragment,e),g(Dr.$$.fragment,e),g(Sr.$$.fragment,e),g(Ct),g(zn.$$.fragment,e),g(Lr.$$.fragment,e),g(Ar.$$.fragment,e),g(Ve),g(Dt),g(Or.$$.fragment,e),g(Mr.$$.fragment,e),g(Nr.$$.fragment,e),g(Lt),g(We),g(Rr.$$.fragment,e),g(Ir.$$.fragment,e),g(Gr.$$.fragment,e),g(Ur.$$.fragment,e),g(Hr.$$.fragment,e),g(Fr.$$.fragment,e),g(Jr.$$.fragment,e),yp=!1},d(e){t(d),e&&t(x),$(f,e),e&&t(w),e&&t(P),$(D),e&&t(A),Br[C].d(e),e&&t(L),e&&t(V),e&&t(Q),$(oe,e),e&&t(H),e&&t(U),e&&t(Pe),e&&t(F),e&&t(he),e&&t(re),e&&t(R),e&&t(De),e&&t(Ee),e&&t(ve),$(pe),e&&t(ls),e&&t($e),e&&t(ge),$(Le,e),e&&t(Ke),$(ye,e),e&&t(us),e&&t(fe),e&&t(He),$(I,e),e&&t(me),$($s,e),e&&t(Ss),$(gs,e),e&&t(qe),e&&t(Ge),e&&t(Us),$(Ye,e),e&&t(Hs),$(as,e),e&&t(ct),e&&t(Oe),e&&t(Ht),$(dt,e),e&&t(Na),e&&t(Me),e&&t(Ha),$(Vs,e),e&&t(ys),e&&t(_s),e&&t(Ws),$(vt,e),e&&t(Jt),$(gt,e),e&&t(fa),e&&t(Te),e&&t(Fa),$(Ms,e),e&&t(Ja),$(jt,e),e&&t(Ba),e&&t(Ks),e&&t(Va),e&&t(Ce),e&&t(Qa),e&&t(Qs),e&&t(Ya),$(kt,e),e&&t(ja),e&&t(rs),e&&t(en),e&&t(bs),$(Zs),e&&t(Yn),e&&t(Rs),e&&t(Xn),e&&t(wt),e&&t(Vi),e&&t(wl),e&&t(Wi),e&&t(hn),e&&t(Ki),e&&t(Da),e&&t(Qi),e&&t(yl),e&&t(Yi),$(vn,e),e&&t(Xi),e&&t(Sa),$(rr),e&&t(Zi),$(lr,e),e&&t(eu),e&&t(Qt),e&&t(su),$(or,e),e&&t(tu),$(_n,e),e&&t(au),e&&t(bn),e&&t(nu),$(ir,e),e&&t(ru),$(ur,e),e&&t(lu),e&&t(Ts),e&&t(ou),$(pr,e),e&&t(iu),$(mr,e),e&&t(uu),e&&t(fs),e&&t(pu),e&&t(Yt),e&&t(mu),$(cr,e),e&&t(cu),e&&t(Cs),e&&t(du),e&&t(Xt),e&&t(fu),$(dr,e),e&&t(hu),e&&t(Cl),e&&t(vu),$(qn,e),e&&t(gu),e&&t(La),$(fr),e&&t(_u),$(hr,e),e&&t(bu),e&&t(Pl),e&&t(qu),e&&t($n),e&&t(ju),$(gr,e),e&&t($u),e&&t(Zt),e&&t(xu),$(xn,e),e&&t(ku),e&&t(_r),e&&t(wu),e&&t(br),e&&t(zu),e&&t(ea),e&&t(Tu),$(qr,e),e&&t(Cu),e&&t(Dl),e&&t(Pu),$(jr,e),e&&t(Du),e&&t(kn),e&&t(Su),$($r,e),e&&t(Lu),$(xr,e),e&&t(Au),e&&t(Xe),e&&t(Ou),$(kr,e),e&&t(Mu),$(Er,e),e&&t(Nu),e&&t(hs),e&&t(Ru),$(En,e),e&&t(Iu),e&&t(Sl),e&&t(Gu),e&&t(Aa),$(wr),e&&t(Uu),e&&t(lt),e&&t(Hu),$(yr,e),e&&t(Fu),e&&t(Ll),e&&t(Ju),$(zr,e),e&&t(Bu),e&&t(sa),e&&t(Vu),$(Tr,e),e&&t(Wu),$(Cr,e),e&&t(Ku),e&&t(Al),e&&t(Qu),$(Pr,e),e&&t(Yu),e&&t(Ol),e&&t(Xu),$(Dr,e),e&&t(Zu),$(Sr,e),e&&t(ep),e&&t(yn),e&&t(sp),Vr[Tt].d(e),e&&t(Ml),$(zn,e),e&&t(tp),e&&t(ta),e&&t(ap),$(Lr,e),e&&t(np),e&&t(Tn),e&&t(rp),$(Ar,e),e&&t(lp),Ve&&Ve.d(e),e&&t(Nl),e&&t(Cn),e&&t(op),e&&t(Ps),e&&t(ip),Wr[Pt].d(e),e&&t(Il),e&&t(Gl),e&&t(up),$(Or,e),e&&t(pp),e&&t(aa),e&&t(mp),$(Mr,e),e&&t(cp),$(Nr,e),e&&t(dp),e&&t(xe),e&&t(fp),Kr[St].d(e),e&&t(Ul),We&&We.d(e),e&&t(Hl),e&&t(Oa),$(Rr),e&&t(hp),e&&t(na),e&&t(vp),$(Ir,e),e&&t(gp),e&&t(Fl),e&&t(_p),$(Gr,e),e&&t(bp),e&&t(Jl),e&&t(qp),$(Ur,e),e&&t(jp),$(Hr,e),e&&t($p),e&&t(Dn),e&&t(xp),$(Fr,e),e&&t(kp),$(Jr,e),e&&t(Ep),e&&t(Bl),e&&t(wp),e&&t(Vl)}}}const __={local:"rsum-de-textes",sections:[{local:"prparation-dun-corpus-multilingue",title:"Pr\xE9paration d'un corpus multilingue"},{local:"modles-pour-le-rsum-de-texte",title:"Mod\xE8les pour le r\xE9sum\xE9 de texte"},{local:"prtraitement-des-donnes",title:"Pr\xE9traitement des donn\xE9es"},{local:"mtriques-pour-le-rsum-de-texte",sections:[{local:"cration-dune-base-de-rfrence-solide",title:"Cr\xE9ation d'une base de r\xE9f\xE9rence solide"}],title:"M\xE9triques pour le r\xE9sum\xE9 de texte"},{local:"finetuning-de-mt5-avec-lapi-trainer",title:"*Finetuning* de mT5 avec l'API `Trainer`."},{local:"finetuning-de-mt5-avec-keras",title:"*Finetuning* de mT5 avec  Keras"},{local:"finetuning-de-mt5-avec-accelerate",sections:[{local:"prparer-tout-pour-lentranement",title:"Pr\xE9parer tout pour l'entra\xEEnement"},{local:"boucle-dentranement",title:"Boucle d'entra\xEEnement"}],title:"*Finetuning* de mT5 avec \u{1F917} *Accelerate*"},{local:"utilisation-de-votre-modle-finetun",title:"Utilisation de votre mod\xE8le *finetun\xE9*"}],title:"R\xE9sum\xE9 de textes"};function b_(Z,d,x){let f="pt";return Zg(()=>{const w=new URLSearchParams(window.location.search);x(0,f=w.get("fw")||"pt")}),[f]}class y_ extends Kg{constructor(d){super();Qg(this,d,b_,g_,Yg,{})}}export{y_ as default,__ as metadata};
