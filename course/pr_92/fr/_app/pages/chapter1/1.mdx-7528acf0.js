import{S as $l,i as Nl,s as zl,e as l,k as p,w as wt,t as s,M as Tl,c as o,d as r,m as d,a as n,x as Lt,h as a,b as i,N as Al,F as e,g as c,y as Pt,L as Il,q as yt,o as qt,B as At,v as Ml}from"../../chunks/vendor-1e8b365d.js";import{Y as xl}from"../../chunks/Youtube-c2a8cc39.js";import{I as ar}from"../../chunks/IconCopyLink-483c28ba.js";function Sl(ma){let P,$t,y,D,Ae,Q,lr,$e,or,Nt,q,F,Ne,V,nr,ze,ir,zt,W,Tt,m,ur,Y,cr,pr,C,dr,Te,mr,fr,G,hr,Ie,vr,gr,j,Er,Me,_r,br,B,wr,xe,Lr,Pr,K,Se,yr,qr,It,A,O,He,X,Ar,ke,$r,Mt,ve,Nr,xt,$,Z,fa,zr,ee,ha,St,b,f,Tr,De,Ir,Mr,Fe,xr,Sr,te,Ce,Hr,kr,Ge,Dr,Fr,je,Cr,Gr,jr,N,Br,Be,Or,Rr,Oe,Ur,Jr,Qr,z,Vr,Re,Wr,Yr,Ue,Kr,Xr,Ht,ge,Zr,kt,w,Je,es,ts,g,rs,re,ss,as,se,Qe,ls,os,ae,Ve,ns,is,us,T,cs,le,ps,ds,oe,ms,fs,Dt,R,hs,ne,vs,gs,Ft,I,U,We,ie,Es,Ye,_s,Ct,Ee,bs,Gt,M,Ke,ws,Ls,Xe,Ps,ys,jt,x,Ze,qs,As,et,$s,Ns,Bt,E,tt,zs,Ts,rt,Is,Ms,ue,st,xs,Ss,Ot,S,at,Hs,ks,lt,Ds,Fs,Rt,H,ot,Cs,Gs,nt,js,Bs,Ut,k,it,Os,Rs,ce,ut,Us,Js,Jt,_,ct,Qs,Vs,pt,Ws,Ys,pe,dt,Ks,Xs,Qt,_e,Zs,Vt,L,de,ea,mt,ta,ra,sa,me,aa,ft,la,oa,na,ht,ia,Wt;return Q=new ar({}),V=new ar({}),W=new xl({props:{id:"00GKzGyWFEs"}}),X=new ar({}),ie=new ar({}),{c(){P=l("meta"),$t=p(),y=l("h1"),D=l("a"),Ae=l("span"),wt(Q.$$.fragment),lr=p(),$e=l("span"),or=s("Introduction"),Nt=p(),q=l("h2"),F=l("a"),Ne=l("span"),wt(V.$$.fragment),nr=p(),ze=l("span"),ir=s("Bienvenue au cours \u{1F917} !"),zt=p(),wt(W.$$.fragment),Tt=p(),m=l("p"),ur=s("Ce cours vous apprendra \xE0 utiliser les biblioth\xE8ques de NLP de l\u2019\xE9cosyst\xE8me "),Y=l("a"),cr=s("Hugging Face"),pr=s(" : "),C=l("a"),dr=s("\u{1F917} "),Te=l("em"),mr=s("Transformers"),fr=s(", "),G=l("a"),hr=s("\u{1F917} "),Ie=l("em"),vr=s("Datasets"),gr=s(", "),j=l("a"),Er=s("\u{1F917} "),Me=l("em"),_r=s("Tokenizers"),br=s(" et "),B=l("a"),wr=s("\u{1F917} "),xe=l("em"),Lr=s("Accelerate"),Pr=s(", ainsi que le "),K=l("a"),Se=l("em"),yr=s("Hub"),qr=s(". C\u2019est totalement gratuit et sans publicit\xE9."),It=p(),A=l("h2"),O=l("a"),He=l("span"),wt(X.$$.fragment),Ar=p(),ke=l("span"),$r=s("\xC0 quoi s'attendre ?"),Mt=p(),ve=l("p"),Nr=s("Voici un bref aper\xE7u du cours :"),xt=p(),$=l("div"),Z=l("img"),zr=p(),ee=l("img"),St=p(),b=l("ul"),f=l("li"),Tr=s("Les chapitres 1 \xE0 4 pr\xE9sentent les principaux concepts de la biblioth\xE8que \u{1F917} "),De=l("em"),Ir=s("Transformers"),Mr=s(". \xC0 la fin de ce chapitre, vous serez familier avec le fonctionnement des "),Fe=l("em"),xr=s("transformers"),Sr=s(" et vous saurez comment utiliser un mod\xE8le pr\xE9sent sur le "),te=l("a"),Ce=l("em"),Hr=s("Hub"),kr=s(", le "),Ge=l("em"),Dr=s("finetuner"),Fr=s(" sur un jeu de donn\xE9es, et partager vos r\xE9sultats sur le "),je=l("em"),Cr=s("Hub"),Gr=s(" !"),jr=p(),N=l("li"),Br=s("Les chapitres 5 \xE0 8 pr\xE9sentent les bases des librairies \u{1F917} "),Be=l("em"),Or=s("Datasets"),Rr=s(" et \u{1F917} "),Oe=l("em"),Ur=s("Tokenizers"),Jr=s(" ainsi qu\u2019une d\xE9couverte des probl\xE8mes classiques de NLP. \xC0 la fin de ce chapitre, vous serez capable de r\xE9soudre les probl\xE8mes de NLP les plus communs par vous-m\xEAme."),Qr=p(),z=l("li"),Vr=s("Les chapitres 9 \xE0 12 proposent d\u2019aller plus loin et d\u2019explorer comment les "),Re=l("em"),Wr=s("transformers"),Yr=s(" peuvent \xEAtre utilis\xE9s pour r\xE9soudre des probl\xE8mes de traitement de la parole et de vision par ordinateur. En suivant ces chapitres, vous apprendrez \xE0 construire et \xE0 partager vos mod\xE8les via des d\xE9monstrateurs, et vous serez capable d\u2019optimiser ces mod\xE8les pour des environnements de production. Enfin, vous serez pr\xEAt \xE0 appliquer \u{1F917} "),Ue=l("em"),Kr=s("Transformers"),Xr=s(" \xE0 (presque) n\u2019importe quel probl\xE8me d\u2019apprentissage automatique !"),Ht=p(),ge=l("p"),Zr=s("Ce cours :"),kt=p(),w=l("ul"),Je=l("li"),es=s("requiert un bon niveau en Python,"),ts=p(),g=l("li"),rs=s("se comprend mieux si vous avez d\xE9j\xE0 suivi un cours d\u2019introduction \xE0 l\u2019apprentissage profond comme "),re=l("a"),ss=s("fast.ai\u2019s"),as=s(", "),se=l("a"),Qe=l("em"),ls=s("Practical Deep Learning for Coders"),os=s(" ou un des cours d\xE9velopp\xE9s par "),ae=l("a"),Ve=l("em"),ns=s("DeepLearning.AI"),is=s(","),us=p(),T=l("li"),cs=s("n\u2019attend pas une connaissance appronfondie de "),le=l("a"),ps=s("PyTorch"),ds=s(" ou de "),oe=l("a"),ms=s("TensorFlow"),fs=s(", bien qu\u2019\xEAtre familiaris\xE9 avec l\u2019un d\u2019entre eux peut aider."),Dt=p(),R=l("p"),hs=s("Apr\xE8s avoir termin\xE9 ce cours, nous vous recommandons de suivre la "),ne=l("a"),vs=s("Sp\xE9cialisation en NLP"),gs=s(" dispens\xE9e par DeepLearning.AI, qui couvre une grande partie des mod\xE8les traditionnels de NLP comme le Bay\xE9sien na\xEFf et les LSTMs qui sont importants \xE0 conna\xEEtre!"),Ft=p(),I=l("h2"),U=l("a"),We=l("span"),wt(ie.$$.fragment),Es=p(),Ye=l("span"),_s=s("Qui sommes-nous ?"),Ct=p(),Ee=l("p"),bs=s("\xC0 propos des auteurs de ce cours :"),Gt=p(),M=l("p"),Ke=l("strong"),ws=s("Matthew Carrigan"),Ls=s(" est ing\xE9nieur en apprentissage machine chez Hugging Face. Il vit \xE0 Dublin en Irlande. Il a travaill\xE9 auparavant comme ing\xE9nieur en apprentissage machine chez Parse.ly et avant cela comme chercheur postdoctoral au Trinity College Dublin. Il ne croit pas que nous arrivions \xE0 l\u2019"),Xe=l("em"),Ps=s("AGI"),ys=s(" en mettant \xE0 l\u2019\xE9chelle les architectures existantes mais a tout de m\xEAme beaucoup d\u2019espoir dans l\u2019immortalit\xE9 des robots."),jt=p(),x=l("p"),Ze=l("strong"),qs=s("Lysandre Debut"),As=s(" est ing\xE9nieur en apprentissage machine chez Hugging Face et a travaill\xE9 sur la biblioth\xE8que \u{1F917} "),et=l("em"),$s=s("Transformers"),Ns=s(" depuis les premi\xE8res phases de d\xE9veloppement. Son but est de rendre le NLP accessible \xE0 tous en d\xE9veloppant des outils disposant d\u2019une API tr\xE8s simple."),Bt=p(),E=l("p"),tt=l("strong"),zs=s("Sylvain Gugger"),Ts=s(" est ing\xE9nieur recherche chez Hugging Face et un des principaux responsables de la biblioth\xE8que \u{1F917} "),rt=l("em"),Is=s("Transformers"),Ms=s(". Avant cela, il \xE9tait chercheur en en apprentissage machine chez fast.ai et a \xE9crit le livre "),ue=l("a"),st=l("em"),xs=s("Deep Learning for Coders with fastai and PyTorch"),Ss=s(" avec Jeremy Howard. Son but est de rendre l\u2019apprentissage profond plus accessible, en d\xE9veloppant et en am\xE9liorant des techniques permettant aux mod\xE8les d\u2019apprendre rapidement sur des ressources limit\xE9es."),Ot=p(),S=l("p"),at=l("strong"),Hs=s("Merve Noyan"),ks=s(" est d\xE9veloppeuse "),lt=l("em"),Ds=s("advocate"),Fs=s(" chez Hugging Face et travaille \xE0 la cr\xE9ation d\u2019outils et de contenus visant \xE0 d\xE9mocratiser l\u2019apprentissage machine pour tous."),Rt=p(),H=l("p"),ot=l("strong"),Cs=s("Lucile Saulnier"),Gs=s(" est ing\xE9nieure en apprentissage machine chez Hugging Face et travaille au d\xE9veloppement et \xE0 l\u2019impl\xE9mentation de nombreux outils "),nt=l("em"),js=s("open source"),Bs=s(". Elle est \xE9galement activement impliqu\xE9e dans de nombreux projets de recherche dans le domaine du NLP comme l\u2019entra\xEEnement collaboratif de mod\xE8les et le projet BigScience."),Ut=p(),k=l("p"),it=l("strong"),Os=s("Lewis Tunstall"),Rs=s(" est ing\xE9nieur en apprentissage machine chez Hugging Face et d\xE9vou\xE9 au d\xE9veloppement d\u2019outils open source avec la volont\xE9 de les rendre accessibles \xE0 une communaut\xE9 plus large. Il est \xE9galement co-auteur du livre "),ce=l("a"),ut=l("em"),Us=s("Natural Language Processing with Transformers"),Js=s("."),Jt=p(),_=l("p"),ct=l("strong"),Qs=s("Leandro von Werra"),Vs=s(" est ing\xE9nieur en apprentissage machine dans l\u2019\xE9quipe "),pt=l("em"),Ws=s("open source"),Ys=s(" d\u2019Hugging Face et \xE9galement co-auteur du livre "),pe=l("a"),dt=l("em"),Ks=s("Natural Language Processing with Transformers"),Xs=s(". Il a plusieurs ann\xE9es d\u2019exp\xE9rience dans l\u2019industrie o\xF9 il a pu d\xE9ployer des projets de NLP en production et travailler sur toutes les \xE9tapes clefs du d\xE9ploiement."),Qt=p(),_e=l("p"),Zs=s("\xCAtes-vous pr\xEAt \xE0 commencer ? Dans ce chapitre, vous apprendrez :"),Vt=p(),L=l("ul"),de=l("li"),ea=s("\xE0 utiliser la fonction "),mt=l("code"),ta=s("pipeline()"),ra=s(" pour r\xE9soudre des probl\xE8mes de NLP comme la g\xE9n\xE9ration de texte et la classification,"),sa=p(),me=l("li"),aa=s("l\u2019architecture d\u2019un "),ft=l("em"),la=s("transformer"),oa=s(","),na=p(),ht=l("li"),ia=s("comment faire la distinction entre les diff\xE9rentes architectures d\u2019encodeur, de d\xE9codeur et d\u2019encodeur-d\xE9codeur ainsi que leurs diff\xE9rents cas d\u2019usage."),this.h()},l(t){const u=Tl('[data-svelte="svelte-1phssyn"]',document.head);P=o(u,"META",{name:!0,content:!0}),u.forEach(r),$t=d(t),y=o(t,"H1",{class:!0});var Yt=n(y);D=o(Yt,"A",{id:!0,class:!0,href:!0});var va=n(D);Ae=o(va,"SPAN",{});var ga=n(Ae);Lt(Q.$$.fragment,ga),ga.forEach(r),va.forEach(r),lr=d(Yt),$e=o(Yt,"SPAN",{});var Ea=n($e);or=a(Ea,"Introduction"),Ea.forEach(r),Yt.forEach(r),Nt=d(t),q=o(t,"H2",{class:!0});var Kt=n(q);F=o(Kt,"A",{id:!0,class:!0,href:!0});var _a=n(F);Ne=o(_a,"SPAN",{});var ba=n(Ne);Lt(V.$$.fragment,ba),ba.forEach(r),_a.forEach(r),nr=d(Kt),ze=o(Kt,"SPAN",{});var wa=n(ze);ir=a(wa,"Bienvenue au cours \u{1F917} !"),wa.forEach(r),Kt.forEach(r),zt=d(t),Lt(W.$$.fragment,t),Tt=d(t),m=o(t,"P",{});var h=n(m);ur=a(h,"Ce cours vous apprendra \xE0 utiliser les biblioth\xE8ques de NLP de l\u2019\xE9cosyst\xE8me "),Y=o(h,"A",{href:!0,rel:!0});var La=n(Y);cr=a(La,"Hugging Face"),La.forEach(r),pr=a(h," : "),C=o(h,"A",{href:!0,rel:!0});var ua=n(C);dr=a(ua,"\u{1F917} "),Te=o(ua,"EM",{});var Pa=n(Te);mr=a(Pa,"Transformers"),Pa.forEach(r),ua.forEach(r),fr=a(h,", "),G=o(h,"A",{href:!0,rel:!0});var ca=n(G);hr=a(ca,"\u{1F917} "),Ie=o(ca,"EM",{});var ya=n(Ie);vr=a(ya,"Datasets"),ya.forEach(r),ca.forEach(r),gr=a(h,", "),j=o(h,"A",{href:!0,rel:!0});var pa=n(j);Er=a(pa,"\u{1F917} "),Me=o(pa,"EM",{});var qa=n(Me);_r=a(qa,"Tokenizers"),qa.forEach(r),pa.forEach(r),br=a(h," et "),B=o(h,"A",{href:!0,rel:!0});var da=n(B);wr=a(da,"\u{1F917} "),xe=o(da,"EM",{});var Aa=n(xe);Lr=a(Aa,"Accelerate"),Aa.forEach(r),da.forEach(r),Pr=a(h,", ainsi que le "),K=o(h,"A",{href:!0,rel:!0});var $a=n(K);Se=o($a,"EM",{});var Na=n(Se);yr=a(Na,"Hub"),Na.forEach(r),$a.forEach(r),qr=a(h,". C\u2019est totalement gratuit et sans publicit\xE9."),h.forEach(r),It=d(t),A=o(t,"H2",{class:!0});var Xt=n(A);O=o(Xt,"A",{id:!0,class:!0,href:!0});var za=n(O);He=o(za,"SPAN",{});var Ta=n(He);Lt(X.$$.fragment,Ta),Ta.forEach(r),za.forEach(r),Ar=d(Xt),ke=o(Xt,"SPAN",{});var Ia=n(ke);$r=a(Ia,"\xC0 quoi s'attendre ?"),Ia.forEach(r),Xt.forEach(r),Mt=d(t),ve=o(t,"P",{});var Ma=n(ve);Nr=a(Ma,"Voici un bref aper\xE7u du cours :"),Ma.forEach(r),xt=d(t),$=o(t,"DIV",{class:!0});var Zt=n($);Z=o(Zt,"IMG",{class:!0,src:!0,alt:!0}),zr=d(Zt),ee=o(Zt,"IMG",{class:!0,src:!0,alt:!0}),Zt.forEach(r),St=d(t),b=o(t,"UL",{});var be=n(b);f=o(be,"LI",{});var v=n(f);Tr=a(v,"Les chapitres 1 \xE0 4 pr\xE9sentent les principaux concepts de la biblioth\xE8que \u{1F917} "),De=o(v,"EM",{});var xa=n(De);Ir=a(xa,"Transformers"),xa.forEach(r),Mr=a(v,". \xC0 la fin de ce chapitre, vous serez familier avec le fonctionnement des "),Fe=o(v,"EM",{});var Sa=n(Fe);xr=a(Sa,"transformers"),Sa.forEach(r),Sr=a(v," et vous saurez comment utiliser un mod\xE8le pr\xE9sent sur le "),te=o(v,"A",{href:!0,rel:!0});var Ha=n(te);Ce=o(Ha,"EM",{});var ka=n(Ce);Hr=a(ka,"Hub"),ka.forEach(r),Ha.forEach(r),kr=a(v,", le "),Ge=o(v,"EM",{});var Da=n(Ge);Dr=a(Da,"finetuner"),Da.forEach(r),Fr=a(v," sur un jeu de donn\xE9es, et partager vos r\xE9sultats sur le "),je=o(v,"EM",{});var Fa=n(je);Cr=a(Fa,"Hub"),Fa.forEach(r),Gr=a(v," !"),v.forEach(r),jr=d(be),N=o(be,"LI",{});var we=n(N);Br=a(we,"Les chapitres 5 \xE0 8 pr\xE9sentent les bases des librairies \u{1F917} "),Be=o(we,"EM",{});var Ca=n(Be);Or=a(Ca,"Datasets"),Ca.forEach(r),Rr=a(we," et \u{1F917} "),Oe=o(we,"EM",{});var Ga=n(Oe);Ur=a(Ga,"Tokenizers"),Ga.forEach(r),Jr=a(we," ainsi qu\u2019une d\xE9couverte des probl\xE8mes classiques de NLP. \xC0 la fin de ce chapitre, vous serez capable de r\xE9soudre les probl\xE8mes de NLP les plus communs par vous-m\xEAme."),we.forEach(r),Qr=d(be),z=o(be,"LI",{});var Le=n(z);Vr=a(Le,"Les chapitres 9 \xE0 12 proposent d\u2019aller plus loin et d\u2019explorer comment les "),Re=o(Le,"EM",{});var ja=n(Re);Wr=a(ja,"transformers"),ja.forEach(r),Yr=a(Le," peuvent \xEAtre utilis\xE9s pour r\xE9soudre des probl\xE8mes de traitement de la parole et de vision par ordinateur. En suivant ces chapitres, vous apprendrez \xE0 construire et \xE0 partager vos mod\xE8les via des d\xE9monstrateurs, et vous serez capable d\u2019optimiser ces mod\xE8les pour des environnements de production. Enfin, vous serez pr\xEAt \xE0 appliquer \u{1F917} "),Ue=o(Le,"EM",{});var Ba=n(Ue);Kr=a(Ba,"Transformers"),Ba.forEach(r),Xr=a(Le," \xE0 (presque) n\u2019importe quel probl\xE8me d\u2019apprentissage automatique !"),Le.forEach(r),be.forEach(r),Ht=d(t),ge=o(t,"P",{});var Oa=n(ge);Zr=a(Oa,"Ce cours :"),Oa.forEach(r),kt=d(t),w=o(t,"UL",{});var Pe=n(w);Je=o(Pe,"LI",{});var Ra=n(Je);es=a(Ra,"requiert un bon niveau en Python,"),Ra.forEach(r),ts=d(Pe),g=o(Pe,"LI",{});var J=n(g);rs=a(J,"se comprend mieux si vous avez d\xE9j\xE0 suivi un cours d\u2019introduction \xE0 l\u2019apprentissage profond comme "),re=o(J,"A",{href:!0,rel:!0});var Ua=n(re);ss=a(Ua,"fast.ai\u2019s"),Ua.forEach(r),as=a(J,", "),se=o(J,"A",{href:!0,rel:!0});var Ja=n(se);Qe=o(Ja,"EM",{});var Qa=n(Qe);ls=a(Qa,"Practical Deep Learning for Coders"),Qa.forEach(r),Ja.forEach(r),os=a(J," ou un des cours d\xE9velopp\xE9s par "),ae=o(J,"A",{href:!0,rel:!0});var Va=n(ae);Ve=o(Va,"EM",{});var Wa=n(Ve);ns=a(Wa,"DeepLearning.AI"),Wa.forEach(r),Va.forEach(r),is=a(J,","),J.forEach(r),us=d(Pe),T=o(Pe,"LI",{});var ye=n(T);cs=a(ye,"n\u2019attend pas une connaissance appronfondie de "),le=o(ye,"A",{href:!0,rel:!0});var Ya=n(le);ps=a(Ya,"PyTorch"),Ya.forEach(r),ds=a(ye," ou de "),oe=o(ye,"A",{href:!0,rel:!0});var Ka=n(oe);ms=a(Ka,"TensorFlow"),Ka.forEach(r),fs=a(ye,", bien qu\u2019\xEAtre familiaris\xE9 avec l\u2019un d\u2019entre eux peut aider."),ye.forEach(r),Pe.forEach(r),Dt=d(t),R=o(t,"P",{});var er=n(R);hs=a(er,"Apr\xE8s avoir termin\xE9 ce cours, nous vous recommandons de suivre la "),ne=o(er,"A",{href:!0,rel:!0});var Xa=n(ne);vs=a(Xa,"Sp\xE9cialisation en NLP"),Xa.forEach(r),gs=a(er," dispens\xE9e par DeepLearning.AI, qui couvre une grande partie des mod\xE8les traditionnels de NLP comme le Bay\xE9sien na\xEFf et les LSTMs qui sont importants \xE0 conna\xEEtre!"),er.forEach(r),Ft=d(t),I=o(t,"H2",{class:!0});var tr=n(I);U=o(tr,"A",{id:!0,class:!0,href:!0});var Za=n(U);We=o(Za,"SPAN",{});var el=n(We);Lt(ie.$$.fragment,el),el.forEach(r),Za.forEach(r),Es=d(tr),Ye=o(tr,"SPAN",{});var tl=n(Ye);_s=a(tl,"Qui sommes-nous ?"),tl.forEach(r),tr.forEach(r),Ct=d(t),Ee=o(t,"P",{});var rl=n(Ee);bs=a(rl,"\xC0 propos des auteurs de ce cours :"),rl.forEach(r),Gt=d(t),M=o(t,"P",{});var vt=n(M);Ke=o(vt,"STRONG",{});var sl=n(Ke);ws=a(sl,"Matthew Carrigan"),sl.forEach(r),Ls=a(vt," est ing\xE9nieur en apprentissage machine chez Hugging Face. Il vit \xE0 Dublin en Irlande. Il a travaill\xE9 auparavant comme ing\xE9nieur en apprentissage machine chez Parse.ly et avant cela comme chercheur postdoctoral au Trinity College Dublin. Il ne croit pas que nous arrivions \xE0 l\u2019"),Xe=o(vt,"EM",{});var al=n(Xe);Ps=a(al,"AGI"),al.forEach(r),ys=a(vt," en mettant \xE0 l\u2019\xE9chelle les architectures existantes mais a tout de m\xEAme beaucoup d\u2019espoir dans l\u2019immortalit\xE9 des robots."),vt.forEach(r),jt=d(t),x=o(t,"P",{});var gt=n(x);Ze=o(gt,"STRONG",{});var ll=n(Ze);qs=a(ll,"Lysandre Debut"),ll.forEach(r),As=a(gt," est ing\xE9nieur en apprentissage machine chez Hugging Face et a travaill\xE9 sur la biblioth\xE8que \u{1F917} "),et=o(gt,"EM",{});var ol=n(et);$s=a(ol,"Transformers"),ol.forEach(r),Ns=a(gt," depuis les premi\xE8res phases de d\xE9veloppement. Son but est de rendre le NLP accessible \xE0 tous en d\xE9veloppant des outils disposant d\u2019une API tr\xE8s simple."),gt.forEach(r),Bt=d(t),E=o(t,"P",{});var fe=n(E);tt=o(fe,"STRONG",{});var nl=n(tt);zs=a(nl,"Sylvain Gugger"),nl.forEach(r),Ts=a(fe," est ing\xE9nieur recherche chez Hugging Face et un des principaux responsables de la biblioth\xE8que \u{1F917} "),rt=o(fe,"EM",{});var il=n(rt);Is=a(il,"Transformers"),il.forEach(r),Ms=a(fe,". Avant cela, il \xE9tait chercheur en en apprentissage machine chez fast.ai et a \xE9crit le livre "),ue=o(fe,"A",{href:!0,rel:!0});var ul=n(ue);st=o(ul,"EM",{});var cl=n(st);xs=a(cl,"Deep Learning for Coders with fastai and PyTorch"),cl.forEach(r),ul.forEach(r),Ss=a(fe," avec Jeremy Howard. Son but est de rendre l\u2019apprentissage profond plus accessible, en d\xE9veloppant et en am\xE9liorant des techniques permettant aux mod\xE8les d\u2019apprendre rapidement sur des ressources limit\xE9es."),fe.forEach(r),Ot=d(t),S=o(t,"P",{});var Et=n(S);at=o(Et,"STRONG",{});var pl=n(at);Hs=a(pl,"Merve Noyan"),pl.forEach(r),ks=a(Et," est d\xE9veloppeuse "),lt=o(Et,"EM",{});var dl=n(lt);Ds=a(dl,"advocate"),dl.forEach(r),Fs=a(Et," chez Hugging Face et travaille \xE0 la cr\xE9ation d\u2019outils et de contenus visant \xE0 d\xE9mocratiser l\u2019apprentissage machine pour tous."),Et.forEach(r),Rt=d(t),H=o(t,"P",{});var _t=n(H);ot=o(_t,"STRONG",{});var ml=n(ot);Cs=a(ml,"Lucile Saulnier"),ml.forEach(r),Gs=a(_t," est ing\xE9nieure en apprentissage machine chez Hugging Face et travaille au d\xE9veloppement et \xE0 l\u2019impl\xE9mentation de nombreux outils "),nt=o(_t,"EM",{});var fl=n(nt);js=a(fl,"open source"),fl.forEach(r),Bs=a(_t,". Elle est \xE9galement activement impliqu\xE9e dans de nombreux projets de recherche dans le domaine du NLP comme l\u2019entra\xEEnement collaboratif de mod\xE8les et le projet BigScience."),_t.forEach(r),Ut=d(t),k=o(t,"P",{});var bt=n(k);it=o(bt,"STRONG",{});var hl=n(it);Os=a(hl,"Lewis Tunstall"),hl.forEach(r),Rs=a(bt," est ing\xE9nieur en apprentissage machine chez Hugging Face et d\xE9vou\xE9 au d\xE9veloppement d\u2019outils open source avec la volont\xE9 de les rendre accessibles \xE0 une communaut\xE9 plus large. Il est \xE9galement co-auteur du livre "),ce=o(bt,"A",{href:!0,rel:!0});var vl=n(ce);ut=o(vl,"EM",{});var gl=n(ut);Us=a(gl,"Natural Language Processing with Transformers"),gl.forEach(r),vl.forEach(r),Js=a(bt,"."),bt.forEach(r),Jt=d(t),_=o(t,"P",{});var he=n(_);ct=o(he,"STRONG",{});var El=n(ct);Qs=a(El,"Leandro von Werra"),El.forEach(r),Vs=a(he," est ing\xE9nieur en apprentissage machine dans l\u2019\xE9quipe "),pt=o(he,"EM",{});var _l=n(pt);Ws=a(_l,"open source"),_l.forEach(r),Ys=a(he," d\u2019Hugging Face et \xE9galement co-auteur du livre "),pe=o(he,"A",{href:!0,rel:!0});var bl=n(pe);dt=o(bl,"EM",{});var wl=n(dt);Ks=a(wl,"Natural Language Processing with Transformers"),wl.forEach(r),bl.forEach(r),Xs=a(he,". Il a plusieurs ann\xE9es d\u2019exp\xE9rience dans l\u2019industrie o\xF9 il a pu d\xE9ployer des projets de NLP en production et travailler sur toutes les \xE9tapes clefs du d\xE9ploiement."),he.forEach(r),Qt=d(t),_e=o(t,"P",{});var Ll=n(_e);Zs=a(Ll,"\xCAtes-vous pr\xEAt \xE0 commencer ? Dans ce chapitre, vous apprendrez :"),Ll.forEach(r),Vt=d(t),L=o(t,"UL",{});var qe=n(L);de=o(qe,"LI",{});var rr=n(de);ea=a(rr,"\xE0 utiliser la fonction "),mt=o(rr,"CODE",{});var Pl=n(mt);ta=a(Pl,"pipeline()"),Pl.forEach(r),ra=a(rr," pour r\xE9soudre des probl\xE8mes de NLP comme la g\xE9n\xE9ration de texte et la classification,"),rr.forEach(r),sa=d(qe),me=o(qe,"LI",{});var sr=n(me);aa=a(sr,"l\u2019architecture d\u2019un "),ft=o(sr,"EM",{});var yl=n(ft);la=a(yl,"transformer"),yl.forEach(r),oa=a(sr,","),sr.forEach(r),na=d(qe),ht=o(qe,"LI",{});var ql=n(ht);ia=a(ql,"comment faire la distinction entre les diff\xE9rentes architectures d\u2019encodeur, de d\xE9codeur et d\u2019encodeur-d\xE9codeur ainsi que leurs diff\xE9rents cas d\u2019usage."),ql.forEach(r),qe.forEach(r),this.h()},h(){i(P,"name","hf:doc:metadata"),i(P,"content",JSON.stringify(Hl)),i(D,"id","introduction"),i(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(D,"href","#introduction"),i(y,"class","relative group"),i(F,"id","bienvenue-au-cours"),i(F,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(F,"href","#bienvenue-au-cours"),i(q,"class","relative group"),i(Y,"href","https://huggingface.co/"),i(Y,"rel","nofollow"),i(C,"href","https://github.com/huggingface/transformers"),i(C,"rel","nofollow"),i(G,"href","https://github.com/huggingface/datasets"),i(G,"rel","nofollow"),i(j,"href","https://github.com/huggingface/tokenizers"),i(j,"rel","nofollow"),i(B,"href","https://github.com/huggingface/accelerate"),i(B,"rel","nofollow"),i(K,"href","https://huggingface.co/models"),i(K,"rel","nofollow"),i(O,"id","quoi-sattendre"),i(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(O,"href","#quoi-sattendre"),i(A,"class","relative group"),i(Z,"class","block dark:hidden"),Al(Z.src,fa="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary.svg")||i(Z,"src",fa),i(Z,"alt","Bref aper\xE7u du contenu du cours."),i(ee,"class","hidden dark:block"),Al(ee.src,ha="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/summary-dark.svg")||i(ee,"src",ha),i(ee,"alt","Bref aper\xE7u des diff\xE9rents chapitres du cours."),i($,"class","flex justify-center"),i(te,"href","https://huggingface.co/models"),i(te,"rel","nofollow"),i(re,"href","https://www.fast.ai/"),i(re,"rel","nofollow"),i(se,"href","https://course.fast.ai/"),i(se,"rel","nofollow"),i(ae,"href","https://www.deeplearning.ai/"),i(ae,"rel","nofollow"),i(le,"href","https://pytorch.org/"),i(le,"rel","nofollow"),i(oe,"href","https://www.tensorflow.org/"),i(oe,"rel","nofollow"),i(ne,"href","https://www.coursera.org/specializations/natural-language-processing?utm_source=deeplearning-ai&utm_medium=institutions&utm_campaign=20211011-nlp-2-hugging_face-page-nlp-refresh"),i(ne,"rel","nofollow"),i(U,"id","qui-sommesnous"),i(U,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),i(U,"href","#qui-sommesnous"),i(I,"class","relative group"),i(ue,"href","https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/"),i(ue,"rel","nofollow"),i(ce,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098103231/"),i(ce,"rel","nofollow"),i(pe,"href","https://www.oreilly.com/library/view/natural-language-processing/9781098103231/"),i(pe,"rel","nofollow")},m(t,u){e(document.head,P),c(t,$t,u),c(t,y,u),e(y,D),e(D,Ae),Pt(Q,Ae,null),e(y,lr),e(y,$e),e($e,or),c(t,Nt,u),c(t,q,u),e(q,F),e(F,Ne),Pt(V,Ne,null),e(q,nr),e(q,ze),e(ze,ir),c(t,zt,u),Pt(W,t,u),c(t,Tt,u),c(t,m,u),e(m,ur),e(m,Y),e(Y,cr),e(m,pr),e(m,C),e(C,dr),e(C,Te),e(Te,mr),e(m,fr),e(m,G),e(G,hr),e(G,Ie),e(Ie,vr),e(m,gr),e(m,j),e(j,Er),e(j,Me),e(Me,_r),e(m,br),e(m,B),e(B,wr),e(B,xe),e(xe,Lr),e(m,Pr),e(m,K),e(K,Se),e(Se,yr),e(m,qr),c(t,It,u),c(t,A,u),e(A,O),e(O,He),Pt(X,He,null),e(A,Ar),e(A,ke),e(ke,$r),c(t,Mt,u),c(t,ve,u),e(ve,Nr),c(t,xt,u),c(t,$,u),e($,Z),e($,zr),e($,ee),c(t,St,u),c(t,b,u),e(b,f),e(f,Tr),e(f,De),e(De,Ir),e(f,Mr),e(f,Fe),e(Fe,xr),e(f,Sr),e(f,te),e(te,Ce),e(Ce,Hr),e(f,kr),e(f,Ge),e(Ge,Dr),e(f,Fr),e(f,je),e(je,Cr),e(f,Gr),e(b,jr),e(b,N),e(N,Br),e(N,Be),e(Be,Or),e(N,Rr),e(N,Oe),e(Oe,Ur),e(N,Jr),e(b,Qr),e(b,z),e(z,Vr),e(z,Re),e(Re,Wr),e(z,Yr),e(z,Ue),e(Ue,Kr),e(z,Xr),c(t,Ht,u),c(t,ge,u),e(ge,Zr),c(t,kt,u),c(t,w,u),e(w,Je),e(Je,es),e(w,ts),e(w,g),e(g,rs),e(g,re),e(re,ss),e(g,as),e(g,se),e(se,Qe),e(Qe,ls),e(g,os),e(g,ae),e(ae,Ve),e(Ve,ns),e(g,is),e(w,us),e(w,T),e(T,cs),e(T,le),e(le,ps),e(T,ds),e(T,oe),e(oe,ms),e(T,fs),c(t,Dt,u),c(t,R,u),e(R,hs),e(R,ne),e(ne,vs),e(R,gs),c(t,Ft,u),c(t,I,u),e(I,U),e(U,We),Pt(ie,We,null),e(I,Es),e(I,Ye),e(Ye,_s),c(t,Ct,u),c(t,Ee,u),e(Ee,bs),c(t,Gt,u),c(t,M,u),e(M,Ke),e(Ke,ws),e(M,Ls),e(M,Xe),e(Xe,Ps),e(M,ys),c(t,jt,u),c(t,x,u),e(x,Ze),e(Ze,qs),e(x,As),e(x,et),e(et,$s),e(x,Ns),c(t,Bt,u),c(t,E,u),e(E,tt),e(tt,zs),e(E,Ts),e(E,rt),e(rt,Is),e(E,Ms),e(E,ue),e(ue,st),e(st,xs),e(E,Ss),c(t,Ot,u),c(t,S,u),e(S,at),e(at,Hs),e(S,ks),e(S,lt),e(lt,Ds),e(S,Fs),c(t,Rt,u),c(t,H,u),e(H,ot),e(ot,Cs),e(H,Gs),e(H,nt),e(nt,js),e(H,Bs),c(t,Ut,u),c(t,k,u),e(k,it),e(it,Os),e(k,Rs),e(k,ce),e(ce,ut),e(ut,Us),e(k,Js),c(t,Jt,u),c(t,_,u),e(_,ct),e(ct,Qs),e(_,Vs),e(_,pt),e(pt,Ws),e(_,Ys),e(_,pe),e(pe,dt),e(dt,Ks),e(_,Xs),c(t,Qt,u),c(t,_e,u),e(_e,Zs),c(t,Vt,u),c(t,L,u),e(L,de),e(de,ea),e(de,mt),e(mt,ta),e(de,ra),e(L,sa),e(L,me),e(me,aa),e(me,ft),e(ft,la),e(me,oa),e(L,na),e(L,ht),e(ht,ia),Wt=!0},p:Il,i(t){Wt||(yt(Q.$$.fragment,t),yt(V.$$.fragment,t),yt(W.$$.fragment,t),yt(X.$$.fragment,t),yt(ie.$$.fragment,t),Wt=!0)},o(t){qt(Q.$$.fragment,t),qt(V.$$.fragment,t),qt(W.$$.fragment,t),qt(X.$$.fragment,t),qt(ie.$$.fragment,t),Wt=!1},d(t){r(P),t&&r($t),t&&r(y),At(Q),t&&r(Nt),t&&r(q),At(V),t&&r(zt),At(W,t),t&&r(Tt),t&&r(m),t&&r(It),t&&r(A),At(X),t&&r(Mt),t&&r(ve),t&&r(xt),t&&r($),t&&r(St),t&&r(b),t&&r(Ht),t&&r(ge),t&&r(kt),t&&r(w),t&&r(Dt),t&&r(R),t&&r(Ft),t&&r(I),At(ie),t&&r(Ct),t&&r(Ee),t&&r(Gt),t&&r(M),t&&r(jt),t&&r(x),t&&r(Bt),t&&r(E),t&&r(Ot),t&&r(S),t&&r(Rt),t&&r(H),t&&r(Ut),t&&r(k),t&&r(Jt),t&&r(_),t&&r(Qt),t&&r(_e),t&&r(Vt),t&&r(L)}}}const Hl={local:"introduction",sections:[{local:"bienvenue-au-cours",title:"Bienvenue au cours \u{1F917} !"},{local:"quoi-sattendre",title:"\xC0 quoi s'attendre ?"},{local:"qui-sommesnous",title:"Qui sommes-nous ?"}],title:"Introduction"};function kl(ma){return Ml(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Gl extends $l{constructor(P){super();Nl(this,P,kl,Sl,zl,{})}}export{Gl as default,Hl as metadata};
