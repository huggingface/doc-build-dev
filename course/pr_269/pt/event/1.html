<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;evento-de-lanamento-da-parte-2&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;dia-1-uma-viso-de-alto-nvel-dos-transformers-e-como-treinlos&quot;,&quot;title&quot;:&quot;Dia 1: Uma visão de alto nível dos Transformers e como treiná-los&quot;},{&quot;local&quot;:&quot;dia-2-as-ferramentas-a-serem-usadas&quot;,&quot;title&quot;:&quot;Dia 2: As ferramentas a serem usadas&quot;}],&quot;title&quot;:&quot;Evento de lançamento da Parte 2&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/course/pr_269/pt/_app/assets/pages/__layout.svelte-hf-doc-builder.css">
	<link rel="modulepreload" href="/docs/course/pr_269/pt/_app/start-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/pr_269/pt/_app/chunks/vendor-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/pr_269/pt/_app/chunks/paths-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/pr_269/pt/_app/pages/__layout.svelte-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/pr_269/pt/_app/pages/event/1.mdx-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/pr_269/pt/_app/chunks/Youtube-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/pr_269/pt/_app/chunks/IconCopyLink-hf-doc-builder.js"> 





<h1 class="relative group"><a id="evento-de-lanamento-da-parte-2" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#evento-de-lanamento-da-parte-2"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Evento de lançamento da Parte 2
	</span></h1>

<p>Para o lançamento da parte 2 do curso, organizamos um evento ao vivo com dois dias de palestras antes de um sprint de ajuste. Se você perdeu, pode acompanhar as palestras que estão listadas abaixo!</p>
<h2 class="relative group"><a id="dia-1-uma-viso-de-alto-nvel-dos-transformers-e-como-treinlos" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#dia-1-uma-viso-de-alto-nvel-dos-transformers-e-como-treinlos"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Dia 1: Uma visão de alto nível dos Transformers e como treiná-los
	</span></h2>

<p><strong>Thomas Wolf:</strong> <em>Transfer Learning and the birth of the Transformers library</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/wCYVeahJES0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/9eq8oUi.png" alt="A visual summary of Thom's talk" width="80%"></p>
<p>Thomas Wolf é cofundador e Chief Science Officer da Hugging Face. As ferramentas criadas por Thomas Wolf e a equipe Hugging Face são usadas em mais de 5.000 organizações de pesquisa, incluindo Facebook Artificial Intelligence Research, Google Research, DeepMind, Amazon Research, Apple, Allen Institute for Artificial Intelligence e na maioria dos departamentos universitários. Thomas Wolf é o iniciador e presidente sênior da maior colaboração de pesquisa que já existiu em Inteligência Artificial: <a href="https://bigscience.huggingface.co" rel="nofollow">“BigScience”</a>, bem como um conjunto de <a href="https://github.com/huggingface/" rel="nofollow">bibliotecas e ferramentas amplamente utilizadas </a>. Thomas Wolf também é um educador prolífico, um líder de pensamento no campo de Inteligência Artificial e Processamento de Linguagem Natural e um orador convidado regular para conferências em todo o mundo <a href="https://thomwolf.io" rel="nofollow">https://thomwolf.io</a>.</p>
<p><strong>Jay Alammar:</strong> <em>A gentle visual intro to Transformers models</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/VzvG23gmcYU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/rOZAuE9.png" alt="A visual summary of Jay's talk" width="80%"></p>
<p>Por meio de seu popular blog de ML, Jay ajudou milhões de pesquisadores e engenheiros a entender visualmente ferramentas e conceitos de aprendizado de máquina desde o básico (terminando em NumPy, Pandas docs) até o de ponta (Transformers, BERT, GPT-3).</p>
<p><strong>Margaret Mitchell:</strong> <em>On Values in ML Development</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/8j9HRMjh_s8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/NuIsnY3.png" alt="A visual summary of Margaret's talk" width="80%"></p>
<p>Margaret Mitchell é uma pesquisadora que trabalha em IA ética, atualmente focada nos meandros do desenvolvimento de IA informada pela ética em tecnologia. Ela publicou mais de 50 artigos sobre geração de linguagem natural, tecnologia assistiva, visão computacional e ética em IA, e possui várias patentes nas áreas de geração de conversas e classificação de sentimentos. Ela trabalhou anteriormente no Google AI como Staff Research Scientist, onde fundou e co-liderou o grupo Ethical AI do Google, focado na pesquisa básica de ética em IA e na operacionalização da ética de IA internamente no Google. Antes de ingressar no Google, ela foi pesquisadora da Microsoft Research, focada na geração de visão computacional para linguagem; e fez pós-doutorado na Johns Hopkins, com foco em modelagem bayesiana e extração de informações. Ela possui doutorado em Ciência da Computação pela Universidade de Aberdeen e mestrado em linguística computacional pela Universidade de Washington. Enquanto se formava, ela também trabalhou de 2005 a 2012 em aprendizado de máquina, distúrbios neurológicos e tecnologia assistiva na Oregon Health and Science University. Ela liderou uma série de workshops e iniciativas nas interseções de diversidade, inclusão, ciência da computação e ética. Seu trabalho recebeu prêmios do Secretário de Defesa Ash Carter e da Fundação Americana para Cegos e foi implementado por várias empresas de tecnologia. Ela gosta de jardinagem, cães e gatos.</p>
<p><strong>Matthew Watson and Chen Qian:</strong> <em>NLP workflows with Keras</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/gZIP-_2XYMM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/1vD2az8.png" alt="A visual summary of Matt and Chen's talk" width="80%"></p>
<p>Matthew Watson é engenheiro de aprendizado de máquina na equipe Keras, com foco em APIs de modelagem de alto nível. Ele estudou Computação Gráfica durante a graduação e mestrado na Universidade de Stanford. Um quase graduado em inglês que se voltou para a ciência da computação, ele é apaixonado por trabalhar em várias disciplinas e tornar a PNL acessível a um público mais amplo.</p>
<p>Chen Qian é engenheiro de software da equipe Keras, com foco em APIs de modelagem de alto nível. Chen obteve um mestrado em Engenharia Elétrica pela Universidade de Stanford e está especialmente interessado em simplificar as implementações de código de tarefas de ML e ML em larga escala.</p>
<p><strong>Mark Saroufim:</strong> <em>How to Train a Model with Pytorch</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/KmvPlW2cbIo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/TPmlkm8.png" alt="A visual summary of Mark's talk" width="80%"></p>
<p>Mark Saroufim é um engenheiro parceiro do Pytorch trabalhando em ferramentas de produção OSS, incluindo TorchServe e Pytorch Enterprise. Em suas vidas passadas, Mark foi Cientista Aplicado e Gerente de Produto na Graphcore, <a href="http://yuri.ai/" rel="nofollow">yuri.ai</a>, Microsoft e JPL da NASA. Sua principal paixão é tornar a programação mais divertida.</p>
<p><strong>Jakob Uszkoreit:</strong> <em>It Ain’t Broke So <del>Don’t Fix</del> Let’s Break It</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/C6jweXYFHSA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/5dWQeNB.png" alt="A visual summary of Jakob's talk" width="80%"></p>
<p>Jakob Uszkoreit é o cofundador da Inceptive. A Inceptive projeta moléculas de RNA para vacinas e terapias usando aprendizado profundo em larga escala em um circuito fechado com experimentos de alto rendimento com o objetivo de tornar os medicamentos baseados em RNA mais acessíveis, mais eficazes e mais amplamente aplicáveis. Anteriormente, Jakob trabalhou no Google por mais de uma década, liderando equipes de pesquisa e desenvolvimento no Google Brain, Research and Search trabalhando em fundamentos de aprendizado profundo, visão computacional, compreensão de idiomas e tradução automática.</p>
<h2 class="relative group"><a id="dia-2-as-ferramentas-a-serem-usadas" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#dia-2-as-ferramentas-a-serem-usadas"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Dia 2: As ferramentas a serem usadas
	</span></h2>

<p><strong>Lewis Tunstall:</strong> <em>Simple Training with the 🤗 Transformers Trainer</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/u--UVvH-LIQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Lewis é machine learning engineer no Hugging Face, focado em desenvolver ferramentas de código aberto e torná-las acessíveis para a comunidade em geral. Ele também é coautor do livro de O’Reilly <a href="https://www.oreilly.com/library/view/natural-language-processing/9781098103231/" rel="nofollow">Natural Language Processing with Transformers</a>. Você pode segui-lo no Twitter (@_lewtun) para dicas e truques de PNL!</p>
<p><strong>Matthew Carrigan:</strong> <em>New TensorFlow Features for 🤗 Transformers and 🤗 Datasets</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/gQUlXp1691w" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Matt é responsável pela manutenção do TensorFlow em Transformers e, eventualmente, liderará um golpe contra a facção PyTorch, que provavelmente será coordenada por meio de sua conta no Twitter @carrigmat.</p>
<p><strong>Lysandre Debut:</strong> <em>The Hugging Face Hub as a means to collaborate on and share Machine Learning projects</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/RBw1TmdEZp0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/TarIPCz.png" alt="A visual summary of Lysandre's talk" width="80%"></p>
<p>Lysandre é machine learning engineer no Hugging Face, onde está envolvido em muitos projetos de código aberto. Seu objetivo é tornar o Machine Learning acessível a todos, desenvolvendo ferramentas poderosas com uma API muito simples.</p>
<p><strong>Lucile Saulnier:</strong> <em>Get your own tokenizer with 🤗 Transformers &amp; 🤗 Tokenizers</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/UkNmyTFKriI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Lucile é engenheira de aprendizado de máquina na Hugging Face, desenvolvendo e dando suporte ao uso de ferramentas de código aberto. Ela também está ativamente envolvida em muitos projetos de pesquisa na área de Processamento de Linguagem Natural, como treinamento colaborativo e BigScience.</p>
<p><strong>Sylvain Gugger:</strong> <em>Supercharge your PyTorch training loop with 🤗 Accelerate</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/t8Krzu-nSeY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Sylvain é um Research Engineer no Hugging Face e um dos principais mantenedores do 🤗 Transformers e o desenvolvedor por trás do 🤗 Accelerate. Ele gosta de tornar o treinamento de modelo mais acessível.</p>
<p><strong>Merve Noyan:</strong> <em>Showcase your model demos with 🤗 Spaces</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/vbaKOa4UXoM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Merve é um desenvolvedor defensor da Hugging Face, trabalhando no desenvolvimento de ferramentas e na criação de conteúdo em torno delas para democratizar o aprendizado de máquina para todos.</p>
<p><strong>Abubakar Abid:</strong> <em>Building Machine Learning Applications Fast</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/c7mle2yYpwQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/qWIFeiF.png" alt="A visual summary of Abubakar's talk" width="80%"></p>
<p>Abubakar Abid é o CEO da <a href="www.gradio.app">Gradio</a>. Ele recebeu seu bacharelado em Engenharia Elétrica e Ciência da Computação do MIT em 2015 e seu PhD em Aprendizado de Máquina Aplicado de Stanford em 2021. Em seu papel como CEO da Gradio, Abubakar trabalha para tornar os modelos de aprendizado de máquina mais fáceis de demonstrar, debugar, e implantar.</p>
<p><strong>Mathieu Desvé:</strong> <em>AWS ML Vision: Making Machine Learning Accessible to all Customers</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/O2e3pXO4aRE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/oLdZTKy.png" alt="A visual summary of Mathieu's talk" width="80%"></p>
<p>Entusiasta da tecnologia, maker nas horas vagas. Gosto de desafios e resolução de problemas de clientes e usuários, e trabalho com pessoas talentosas para aprender todos os dias. Desde 2004, atuo em várias posições alternando entre frontend, backend, infraestrutura, operações e gerenciamentos. Tente resolver problemas técnicos e gerenciais comuns de maneira ágil.</p>
<p><strong>Philipp Schmid:</strong> <em>Managed Training with Amazon SageMaker and 🤗 Transformers</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/yG6J2Zfo8iw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Philipp Schmid é Machine Learning Engineer and Tech Lead no Hugging Face, onde lidera a colaboração com a equipe do Amazon SageMaker. Ele é apaixonado por democratizar e produzir modelos de PNL de ponta e melhorar a facilidade de uso do Deep Learning.</p>


		<script type="module" data-hydrate="dmzu0c">
		import { start } from "/docs/course/pr_269/pt/_app/start-hf-doc-builder.js";
		start({
			target: document.querySelector('[data-hydrate="dmzu0c"]').parentNode,
			paths: {"base":"/docs/course/pr_269/pt","assets":"/docs/course/pr_269/pt"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/course/pr_269/pt/_app/pages/__layout.svelte-hf-doc-builder.js"),
						import("/docs/course/pr_269/pt/_app/pages/event/1.mdx-hf-doc-builder.js")
				],
				params: {}
			}
		});
	</script>
