<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;vnement-pour-le-lancement-de-la-partie-2&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;jour-1-une-vue-densemble-des-itransformersi-et-comment-les-entraner&quot;,&quot;title&quot;:&quot;Jour 1 : Une vue d&#39;ensemble des &lt;i&gt;transformers&lt;/i&gt; et comment les entraÃ®ner&quot;},{&quot;local&quot;:&quot;jour-2-les-outils-utiliser&quot;,&quot;title&quot;:&quot;Jour 2 : Les outils Ã  utiliser&quot;}],&quot;title&quot;:&quot;Ã‰vÃ©nement pour le lancement de la partie 2&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/course/pr_191/fr/_app/assets/pages/__layout.svelte-86c37201.css">
	<link rel="modulepreload" href="/docs/course/pr_191/fr/_app/start-6e0b8311.js">
	<link rel="modulepreload" href="/docs/course/pr_191/fr/_app/chunks/vendor-1e8b365d.js">
	<link rel="modulepreload" href="/docs/course/pr_191/fr/_app/chunks/paths-4b3c6e7e.js">
	<link rel="modulepreload" href="/docs/course/pr_191/fr/_app/pages/__layout.svelte-05c2fb0c.js">
	<link rel="modulepreload" href="/docs/course/pr_191/fr/_app/pages/event/1.mdx-bc3e8d22.js">
	<link rel="modulepreload" href="/docs/course/pr_191/fr/_app/chunks/Youtube-c2a8cc39.js">
	<link rel="modulepreload" href="/docs/course/pr_191/fr/_app/chunks/IconCopyLink-483c28ba.js"> 





<h1 class="relative group"><a id="vnement-pour-le-lancement-de-la-partie-2" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#vnement-pour-le-lancement-de-la-partie-2"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Ã‰vÃ©nement pour le lancement de la partie 2
	</span></h1>

<p>Pour la sortie de la deuxiÃ¨me partie du cours, nous avons organisÃ© un Ã©vÃ©nement en direct consistant en deux jours de confÃ©rences suivies dâ€™un <em>sprint</em> de <em>finetuning</em>. Si vous lâ€™avez manquÃ©, vous pouvez rattraper les prÃ©sentations qui sont toutes listÃ©es ci-dessous !</p>
<h2 class="relative group"><a id="jour-1-une-vue-densemble-des-itransformersi-et-comment-les-entraner" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#jour-1-une-vue-densemble-des-itransformersi-et-comment-les-entraner"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Jour 1 : Une vue d&#39;ensemble des <i>transformers</i> et comment les entraÃ®ner
	</span></h2>

<p><strong>Thomas Wolf :</strong> <em>Lâ€™apprentissage par transfert et la naissance de la bibliothÃ¨que ğŸ¤— Transformers</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/wCYVeahJES0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/9eq8oUi.png" alt="A visual summary of Thom's talk" width="80%"></p>
<p>Thomas Wolf est cofondateur et directeur scientifique dâ€™Hugging Face. Les outils crÃ©Ã©s par Thomas Wolf et lâ€™Ã©quipe dâ€™Hugging Face sont utilisÃ©s par plus de 5 000 organismes de recherche, dont Facebook Artificial Intelligence Research, Google Research, DeepMind, Amazon Research, Apple, lâ€™Allen Institute for Artificial Intelligence ainsi que la plupart des dÃ©partements universitaires. Thomas Wolf est lâ€™initiateur et le prÃ©sident principal de la plus grande collaboration de recherche qui ait jamais existÃ© dans le domaine de lâ€™intelligence artificielle : <a href="https://bigscience.huggingface.co" rel="nofollow">Â« BigScience Â»</a>, ainsi que dâ€™un ensemble de <a href="https://github.com/huggingface/" rel="nofollow">bibliothÃ¨ques et outils</a> largement utilisÃ©s. Thomas Wolf est Ã©galement un Ã©ducateur prolifique, un <em>leader</em> dâ€™opinion dans le domaine de lâ€™intelligence artificielle et du traitement du langage naturel, et un orateur rÃ©guliÃ¨rement invitÃ© Ã  des confÃ©rences dans le monde entier <a href="https://thomwolf.io" rel="nofollow">https://thomwolf.io</a>.</p>
<p><strong>Jay Alammar :</strong> <em>Une introduction visuelle douce aux transformers</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/VzvG23gmcYU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/rOZAuE9.png" alt="A visual summary of Jay's talk" width="80%"></p>
<p>GrÃ¢ce Ã  son blog dâ€™apprentissage automatique trÃ¨s populaire, Jay a aidÃ© des millions de chercheurs et dâ€™ingÃ©nieurs Ã  comprendre visuellement les outils et les concepts de lâ€™apprentissage automatique, des plus Ã©lÃ©mentaires (qui se retrouvent dans les docs NumPy et Pandas) aux plus pointus (Transformer, BERT, GPT-3).</p>
<p><strong>Margaret Mitchell :</strong> <em>Les valeurs dans le dÃ©veloppement de lâ€™apprentissage automatique</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/8j9HRMjh_s8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/NuIsnY3.png" alt="A visual summary of Margaret's talk" width="80%"></p>
<p>Margaret Mitchell est une chercheuse travaillant sur lâ€™IA Ã©thique. Elle se concentre actuellement sur les tenants et aboutissants du dÃ©veloppement de lâ€™IA Ã©thique dans le domaine de la technologie. Elle a publiÃ© plus de cinquante articles sur la gÃ©nÃ©ration de langage naturel, les technologies dâ€™assistance, la vision par ordinateur et lâ€™IA Ã©thique. Elle dÃ©tient plusieurs brevets dans le domaine de la gÃ©nÃ©ration de conversations et celui de la classification des sentiments. Elle a prÃ©cÃ©demment travaillÃ© chez Google AI en tant que chercheuse oÃ¹ elle a fondÃ© et codirigÃ© le groupe dâ€™IA Ã©thique de Google. Ce groupe est axÃ© sur la recherche fondamentale en matiÃ¨re dâ€™IA Ã©thique et lâ€™opÃ©rationnalisation de dâ€™IA Ã©thique en interne Ã  Google. Avant de rejoindre Google, elle a Ã©tÃ© chercheuse chez Microsoft Research oÃ¹ elle sâ€™est concentrÃ©e sur la gÃ©nÃ©ration de la vision par ordinateur vers le langage et a Ã©tÃ© post-doc Ã  Johns Hopkins oÃ¹ elle sâ€™est concentrÃ©e sur la modÃ©lisation bayÃ©sienne et lâ€™extraction dâ€™informations. Elle est titulaire dâ€™un doctorat en informatique de lâ€™universitÃ© dâ€™Aberdeen et dâ€™une maÃ®trise en linguistique informatique de lâ€™universitÃ© de Washington. Tout en obtenant ses diplÃ´mes, elle a Ã©galement travaillÃ© de 2005 Ã  2012 sur lâ€™apprentissage automatique, les troubles neurologiques et les technologies dâ€™assistance Ã  lâ€™Oregon Health and Science University. Elle a dirigÃ© un certain nombre dâ€™ateliers et dâ€™initiatives au croisement de la diversitÃ©, de lâ€™inclusion, de lâ€™informatique et de lâ€™Ã©thique. Ses travaux ont Ã©tÃ© rÃ©compensÃ©s par le secrÃ©taire Ã  la dÃ©fense Ash Carter et la Fondation amÃ©ricaine pour les aveugles, et ont Ã©tÃ© implÃ©mentÃ© par plusieurs entreprises technologiques.</p>
<p><strong>Matthew Watson et Chen Qian :</strong> <em>Les flux de travail en NLP avec Keras</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/gZIP-_2XYMM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/1vD2az8.png" alt="A visual summary of Matt and Chen's talk" width="80%"></p>
<p>Matthew Watson est ingÃ©nieur en apprentissage automatique au sein de lâ€™Ã©quipe Keras et se concentre sur les API de modÃ©lisation de haut niveau. Il a Ã©tudiÃ© lâ€™infographie pendant ses Ã©tudes et a obtenu un master Ã  lâ€™universitÃ© de Stanford. Il sâ€™est orientÃ© vers lâ€™informatique aprÃ¨s avoir Ã©tudiÃ© lâ€™anglais. Il est passionnÃ© par le travail interdisciplinaire et par la volontÃ© de rendre le traitement automatique des langues accessible Ã  un public plus large.</p>
<p>Chen Qian est un ingÃ©nieur logiciel de lâ€™Ã©quipe Keras spÃ©cialisÃ© dans les API de modÃ©lisation de haut niveau. Chen est titulaire dâ€™un master en gÃ©nie Ã©lectrique de lâ€™universitÃ© de Stanford et sâ€™intÃ©resse particuliÃ¨rement Ã  la simplification de lâ€™implÃ©mentation du code des tÃ¢ches dâ€™apprentissage automatique et le passage Ã  grande Ã©chelle de ces codes.</p>
<p><strong>Mark Saroufim :</strong> <em>Comment entraÃ®ner un modÃ¨le avec PyTorch</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/KmvPlW2cbIo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/TPmlkm8.png" alt="A visual summary of Mark's talk" width="80%"></p>
<p>Mark Saroufim est ingÃ©nieur partenaire chez PyTorch et travaille sur les outils de production OSS, notamment TorchServe et PyTorch Enterprise. Dans ses vies antÃ©rieures, Mark a Ã©tÃ© un scientifique appliquÃ© et un chef de produit chez Graphcore, <a href="http://yuri.ai/" rel="nofollow">yuri.ai</a>, Microsoft et au JPL de la NASA. Sa principale passion est de rendre la programmation plus amusante.</p>
<p><strong>Jakob Uszkoreit :</strong> <em>Ce nâ€™est pas cassÃ© alors <del>ne rÃ©parez pas</del> cassez tout</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/C6jweXYFHSA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/5dWQeNB.png" alt="A visual summary of Jakob's talk" width="80%"></p>
<p>Jakob Uszkoreit est le cofondateur dâ€™Inceptive. Inceptive conÃ§oit des molÃ©cules dâ€™ARN pour les vaccins et les thÃ©rapies en utilisant lâ€™apprentissage profond Ã  grande Ã©chelle. Le tout en boucle Ã©troite avec des expÃ©riences Ã  haut dÃ©bit, dans le but de rendre les mÃ©dicaments Ã  base dâ€™ARN plus accessibles, plus efficaces et plus largement applicables. Auparavant, Jakob a travaillÃ© chez Google pendant plus de dix ans, dirigeant des Ã©quipes de recherche et de dÃ©veloppement au sein de Google Brain, Research et Search, travaillant sur les fondamentaux de lâ€™apprentissage profond, la vision par ordinateur, la comprÃ©hension du langage et la traduction automatique.</p>
<h2 class="relative group"><a id="jour-2-les-outils-utiliser" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#jour-2-les-outils-utiliser"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Jour 2 : Les outils Ã  utiliser
	</span></h2>

<p><strong>Lewis Tunstall :</strong> <em>Un entraÃ®nement simple avec la fonction </em>Trainer<em>de la bibliotÃ¨que ğŸ¤— Transformers</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/u--UVvH-LIQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Lewis est un ingÃ©nieur en apprentissage machine chez Hugging Face qui se concentre sur le dÃ©veloppement dâ€™outils open-source et les rend accessibles Ã  la communautÃ©. Il est Ã©galement co-auteur du livre <a href="https://www.oreilly.com/library/view/natural-language-processing/9781098103231/" rel="nofollow">Natural Language Processing with Transformers</a> paru chez Oâ€™Reilly. Vous pouvez le suivre sur Twitter (@_lewtun) pour des conseils et astuces en traitement du langage naturel !</p>
<p><strong>Matthew Carrigan :</strong> <em>Nouvelles fonctionnalitÃ©s en TensorFlow pour ğŸ¤— Transformers et ğŸ¤— Datasets</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/gQUlXp1691w" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Matt est responsable de la maintenance des modÃ¨les en TensorFlow chez <em>Transformers</em>. Il finira par mener un coup dâ€™Ã‰tat contre la faction PyTorch en place Celui sera probablement coordonnÃ© via son compte Twitter @carrigmat.</p>
<p><strong>Lysandre Debut :</strong> <em>Le Hub dâ€™Hugging Face, un moyen de collaborer et de partager des projets dâ€™apprentissage automatique</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/RBw1TmdEZp0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/TarIPCz.png" alt="A visual summary of Lysandre's talk" width="80%"></p>
<p>Lysandre est ingÃ©nieur en apprentissage machine chez Hugging Face oÃ¹ il participe Ã  de nombreux projets open source. Son objectif est de rendre lâ€™apprentissage automatique accessible Ã  tous en dÃ©veloppant des outils puissants avec une API trÃ¨s simple.</p>
<p><strong>Lucile Saulnier :</strong> <em>Avoir son propre tokenizer avec ğŸ¤— Transformers &amp; ğŸ¤— Tokenizers</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/UkNmyTFKriI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Lucile est ingÃ©nieure en apprentissage automatique chez Hugging Face oÃ¹ elle dÃ©veloppe et soutient lâ€™utilisation dâ€™outils open source. Elle est Ã©galement activement impliquÃ©e dans de nombreux projets de recherche dans le domaine du traitement du langage naturel tels que lâ€™entraÃ®nement collaboratif et BigScience.</p>
<p><strong>Sylvain Gugger :</strong> <em>Optimisez votre boucle dâ€™entraÃ®nement PyTorch avec
ğŸ¤— Accelerate</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/t8Krzu-nSeY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Sylvain est ingÃ©nieur de recherche chez Hugging Face. Il est lâ€™un des principaux mainteneurs de ğŸ¤— Transformers et le dÃ©veloppeur derriÃ¨re ğŸ¤— Accelerate. Il aime rendre lâ€™apprentissage des modÃ¨les plus accessible.</p>
<p><strong>Merve Noyan :</strong> <em>PrÃ©sentez vos dÃ©monstrations de modÃ¨les avec
ğŸ¤— Spaces</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/vbaKOa4UXoM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Merve est <em>developer advocate</em> chez Hugging Face travaillant au dÃ©veloppement dâ€™outils et Ã  la crÃ©ation de contenu autour dâ€™eux afin de dÃ©mocratiser lâ€™apprentissage automatique pour tous.</p>
<p><strong>Abubakar Abid :</strong> <em>CrÃ©er rapidement des applications dâ€™apprentissage automatique</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/c7mle2yYpwQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/qWIFeiF.png" alt="A visual summary of Abubakar's talk" width="80%"></p>
<p>Abubakar Abid est le PDG de <a href="www.gradio.app">Gradio</a>. Il a obtenu sa licence en gÃ©nie Ã©lectrique et en informatique au MIT en 2015, et son doctorat en apprentissage automatique appliquÃ© Ã  Stanford en 2021. En tant que PDG de Gradio, Abubakar sâ€™efforce de faciliter la dÃ©monstration, le dÃ©bogage et le dÃ©ploiement des modÃ¨les dâ€™apprentissage automatique.</p>
<p><strong>Mathieu DesvÃ© :</strong> <em>AWS ML Vision : Rendre lâ€™apprentissage automatique accessible Ã  tous les clients</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/O2e3pXO4aRE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p align="center"><img src="https://i.imgur.com/oLdZTKy.png" alt="A visual summary of Mathieu's talk" width="80%"></p>
<p>PassionnÃ© de technologie, il est un crÃ©ateur pendant son temps libre. Il aime les dÃ©fis et rÃ©soudre les problÃ¨mes des clients et des utilisateurs ainsi que travailler avec des personnes talentueuses pour apprendre chaque jour. Depuis 2004, il a occupÃ© plusieurs postes, passant du frontend au backend, de lâ€™infrastructure aux opÃ©rations et Ã  la gestion. Il essaie de rÃ©soudre les problÃ¨mes techniques et de gestion courants de maniÃ¨re agile.</p>
<p><strong>Philipp Schmid :</strong> <em>EntraÃ®nement dirigÃ© avec Amazon SageMaker et ğŸ¤— Transformers</em></p>
<div class="flex justify-center"><iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/yG6J2Zfo8iw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div>
<p>Philipp Schmid est ingÃ©nieur en apprentissage machine et <em>Tech Lead</em> chez Hugging Face oÃ¹ il dirige la collaboration avec lâ€™Ã©quipe Amazon SageMaker. Il est passionnÃ© par la dÃ©mocratisation et la mise en production de modÃ¨les de traitement du langage naturel de pointe et par lâ€™amÃ©lioration de la facilitÃ© dâ€™utilisation de lâ€™apprentissage profond.</p>


		<script type="module" data-hydrate="k3z8t7">
		import { start } from "/docs/course/pr_191/fr/_app/start-6e0b8311.js";
		start({
			target: document.querySelector('[data-hydrate="k3z8t7"]').parentNode,
			paths: {"base":"/docs/course/pr_191/fr","assets":"/docs/course/pr_191/fr"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/course/pr_191/fr/_app/pages/__layout.svelte-05c2fb0c.js"),
						import("/docs/course/pr_191/fr/_app/pages/event/1.mdx-bc3e8d22.js")
				],
				params: {}
			}
		});
	</script>
