import{S as Yt,i as Qt,s as Xt,e as a,k as f,w as v,t as r,M as er,c as l,d as n,m as p,x as _,a as o,h as i,b as D,G as s,g as d,y as k,q as z,o as E,B as M,v as nr}from"../../chunks/vendor-hf-doc-builder.js";import{D as sr,Y as is,T as fn}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";import{I as as}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as L}from"../../chunks/CodeBlock-hf-doc-builder.js";import{F as tr}from"../../chunks/FrameworkSwitchCourse-hf-doc-builder.js";function rr(q){let u,b,m,$,g;return{c(){u=a("p"),b=r("\u{1F917} Transformer Modelle haben eine besondere F\xE4higkeit, die die meisten Keras Modelle nicht haben - sie k\xF6nnen automatisch einen geeigneten Verlust verwenden, der intern berechnet wird. Dieser Verlust wird standardm\xE4\xDFig verwendet, wenn in "),m=a("code"),$=r("compile()"),g=r(" kein Verlustargument angegeben wird. Um den internen Verlust zu verwenden, musst du deine Labels als Teil des Input \xFCbergeben und nicht als separates Label, wie es normalerweise bei Keras-Modellen der Fall ist. Beispiele daf\xFCr gibt es in Teil 2 des Kurses, wobei die Definition der richtigen Verlustfunktion schwierig sein kann. F\xFCr die Klassifizierung von Sequenzen eignet sich jedoch eine der Standardverlustfunktionen von Keras, die wir hier verwenden werden.")},l(h){u=l(h,"P",{});var c=o(u);b=i(c,"\u{1F917} Transformer Modelle haben eine besondere F\xE4higkeit, die die meisten Keras Modelle nicht haben - sie k\xF6nnen automatisch einen geeigneten Verlust verwenden, der intern berechnet wird. Dieser Verlust wird standardm\xE4\xDFig verwendet, wenn in "),m=l(c,"CODE",{});var j=o(m);$=i(j,"compile()"),j.forEach(n),g=i(c," kein Verlustargument angegeben wird. Um den internen Verlust zu verwenden, musst du deine Labels als Teil des Input \xFCbergeben und nicht als separates Label, wie es normalerweise bei Keras-Modellen der Fall ist. Beispiele daf\xFCr gibt es in Teil 2 des Kurses, wobei die Definition der richtigen Verlustfunktion schwierig sein kann. F\xFCr die Klassifizierung von Sequenzen eignet sich jedoch eine der Standardverlustfunktionen von Keras, die wir hier verwenden werden."),c.forEach(n)},m(h,c){d(h,u,c),s(u,b),s(u,m),s(m,$),s(u,g)},d(h){h&&n(u)}}}function ir(q){let u,b,m,$,g,h,c,j;return{c(){u=a("p"),b=r("Hier gibt es einen sehr h\xE4ufigen Stolperstein - du "),m=a("em"),$=r("kannst"),g=r(" Keras einfach den Namen des Verlusts als String \xFCbergeben, aber standardm\xE4\xDFig geht Keras davon aus, dass du bereits einen Softmax auf die Outputs angewendet hast. Viele Modelle geben jedoch die Werte direkt vor der Anwendung des Softmax als "),h=a("em"),c=r("Logits"),j=r(" aus. Hier ist es wichtig der Keras Verlustfunktion mitzuteilen, dass unser Modell genau diess tut, und das geht nur indem sie direkt aufgerufen wird, und nicht \xFCber den Namen mit einem String.")},l(T){u=l(T,"P",{});var w=o(u);b=i(w,"Hier gibt es einen sehr h\xE4ufigen Stolperstein - du "),m=l(w,"EM",{});var P=o(m);$=i(P,"kannst"),P.forEach(n),g=i(w," Keras einfach den Namen des Verlusts als String \xFCbergeben, aber standardm\xE4\xDFig geht Keras davon aus, dass du bereits einen Softmax auf die Outputs angewendet hast. Viele Modelle geben jedoch die Werte direkt vor der Anwendung des Softmax als "),h=l(w,"EM",{});var S=o(h);c=i(S,"Logits"),S.forEach(n),j=i(w," aus. Hier ist es wichtig der Keras Verlustfunktion mitzuteilen, dass unser Modell genau diess tut, und das geht nur indem sie direkt aufgerufen wird, und nicht \xFCber den Namen mit einem String."),w.forEach(n)},m(T,w){d(T,u,w),s(u,b),s(u,m),s(m,$),s(u,g),s(u,h),s(h,c),s(u,j)},d(T){T&&n(u)}}}function ar(q){let u,b,m,$,g,h,c,j;return{c(){u=a("p"),b=r("Die \u{1F917} Transformer Bibliothek hat eine "),m=a("code"),$=r("create_optimizer()"),g=r("-Funktion, die einen "),h=a("code"),c=r("AdamW"),j=r("-Optimierer mit Lernratenabfall erzeugt. Das ist eine praktisches Tool, auf das wir in den n\xE4chsten Abschnitten des Kurses im Detail eingehen werden.")},l(T){u=l(T,"P",{});var w=o(u);b=i(w,"Die \u{1F917} Transformer Bibliothek hat eine "),m=l(w,"CODE",{});var P=o(m);$=i(P,"create_optimizer()"),P.forEach(n),g=i(w,"-Funktion, die einen "),h=l(w,"CODE",{});var S=o(h);c=i(S,"AdamW"),S.forEach(n),j=i(w,"-Optimierer mit Lernratenabfall erzeugt. Das ist eine praktisches Tool, auf das wir in den n\xE4chsten Abschnitten des Kurses im Detail eingehen werden."),w.forEach(n)},m(T,w){d(T,u,w),s(u,b),s(u,m),s(m,$),s(u,g),s(u,h),s(h,c),s(u,j)},d(T){T&&n(u)}}}function lr(q){let u,b,m,$,g,h,c,j,T,w;return{c(){u=a("p"),b=r("\u{1F4A1} Wenn du dein Modell w\xE4hrend des Trainings automatisch in den Hub hochladen m\xF6chtest, kannst du in der Methode "),m=a("code"),$=r("model.fit()"),g=r(" einen "),h=a("code"),c=r("PushToHubCallback"),j=r(" mitgeben. Mehr dar\xFCber erfahren wir in "),T=a("a"),w=r("Kapitel 4"),this.h()},l(P){u=l(P,"P",{});var S=o(u);b=i(S,"\u{1F4A1} Wenn du dein Modell w\xE4hrend des Trainings automatisch in den Hub hochladen m\xF6chtest, kannst du in der Methode "),m=l(S,"CODE",{});var F=o(m);$=i(F,"model.fit()"),F.forEach(n),g=i(S," einen "),h=l(S,"CODE",{});var ie=o(h);c=i(ie,"PushToHubCallback"),ie.forEach(n),j=i(S," mitgeben. Mehr dar\xFCber erfahren wir in "),T=l(S,"A",{href:!0});var y=o(T);w=i(y,"Kapitel 4"),y.forEach(n),S.forEach(n),this.h()},h(){D(T,"href","/course/chapter4/3")},m(P,S){d(P,u,S),s(u,b),s(u,m),s(m,$),s(u,g),s(u,h),s(h,c),s(u,j),s(u,T),s(T,w)},d(P){P&&n(u)}}}function dr(q){let u,b,m,$,g;return{c(){u=a("p"),b=r("\u270F\uFE0F "),m=a("strong"),$=r("Probier es aus!"),g=r(" Fein-tune ein Modell mit dem GLUE SST-2 Datensatz, indem du die Datenverarbeitung aus Abschnitt 2 verwendest.")},l(h){u=l(h,"P",{});var c=o(u);b=i(c,"\u270F\uFE0F "),m=l(c,"STRONG",{});var j=o(m);$=i(j,"Probier es aus!"),j.forEach(n),g=i(c," Fein-tune ein Modell mit dem GLUE SST-2 Datensatz, indem du die Datenverarbeitung aus Abschnitt 2 verwendest."),c.forEach(n)},m(h,c){d(h,u,c),s(u,b),s(u,m),s(m,$),s(u,g)},d(h){h&&n(u)}}}function or(q){let u,b,m,$,g,h,c,j,T,w,P,S,F,ie,y,ls,Fe,ds,os,ae,us,fs,pn,De,ps,mn,le,hn,G,N,Oe,de,ms,Ve,hs,cn,Te,cs,gn,oe,wn,Se,gs,bn,ue,$n,O,ws,Ke,bs,$s,Be,vs,_s,vn,fe,_n,H,ks,Pe,zs,Es,kn,V,Ms,Ge,js,Ds,We,Ts,Ss,zn,I,En,pe,Mn,R,jn,W,Z,xe,me,Ks,Ue,Ps,Dn,he,Tn,J,qs,Ne,ys,As,Sn,K,Cs,He,Ls,Fs,Ie,Os,Vs,Re,Bs,Gs,Ze,Ws,xs,Je,Us,Ns,Kn,ce,Pn,Y,qn,qe,Hs,yn,ge,An,Q,Is,Ye,Rs,Zs,Cn,we,Ln,X,Fn,x,ee,Qe,be,Js,Xe,Ys,On,$e,Vn,B,Qs,en,Xs,et,nn,nt,st,Bn,ve,Gn,ne,tt,sn,rt,it,Wn,_e,xn,ke,Un,se,at,tn,lt,dt,Nn,ze,Hn,Ee,In,A,ot,Me,ut,ft,rn,pt,mt,an,ht,ct,Rn,ye,gt,Zn,te,Jn;return m=new tr({props:{fw:q[0]}}),j=new as({}),F=new sr({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter3/section3_tf.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter3/section3_tf.ipynb"}]}}),le=new L({props:{code:`






`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, DataCollatorWithPadding
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

raw_datasets = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>)
checkpoint = <span class="hljs-string">&quot;bert-base-uncased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">example</span>):
    <span class="hljs-keyword">return</span> tokenizer(example[<span class="hljs-string">&quot;sentence1&quot;</span>], example[<span class="hljs-string">&quot;sentence2&quot;</span>], truncation=<span class="hljs-literal">True</span>)


tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)

data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)

tf_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
    shuffle=<span class="hljs-literal">True</span>,
    collate_fn=data_collator,
    batch_size=<span class="hljs-number">8</span>,
)

tf_validation_dataset = tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>].to_tf_dataset(
    columns=[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>],
    label_cols=[<span class="hljs-string">&quot;labels&quot;</span>],
    shuffle=<span class="hljs-literal">False</span>,
    collate_fn=data_collator,
    batch_size=<span class="hljs-number">8</span>,
)`}}),de=new as({}),oe=new is({props:{id:"rnTGBy2ax1c"}}),ue=new is({props:{id:"AUozVp78dhk"}}),fe=new L({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">2</span>)`}}),I=new fn({props:{$$slots:{default:[rr]},$$scope:{ctx:q}}}),pe=new L({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> tensorflow.keras.losses <span class="hljs-keyword">import</span> SparseCategoricalCrossentropy

model.<span class="hljs-built_in">compile</span>(
    optimizer=<span class="hljs-string">&quot;adam&quot;</span>,
    loss=SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>),
    metrics=[<span class="hljs-string">&quot;accuracy&quot;</span>],
)
model.fit(
    tf_train_dataset,
    validation_data=tf_validation_dataset,
)`}}),R=new fn({props:{warning:!0,$$slots:{default:[ir]},$$scope:{ctx:q}}}),me=new as({}),he=new is({props:{id:"cpzq6ESSM5c"}}),ce=new L({props:{code:`
`,highlighted:`<span class="hljs-keyword">from</span> tensorflow.keras.optimizers.schedules <span class="hljs-keyword">import</span> PolynomialDecay

batch_size = <span class="hljs-number">8</span>
num_epochs = <span class="hljs-number">3</span>
<span class="hljs-comment"># The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied</span>
<span class="hljs-comment"># by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,</span>
<span class="hljs-comment"># not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.</span>
num_train_steps = <span class="hljs-built_in">len</span>(tf_train_dataset) * num_epochs
lr_scheduler = PolynomialDecay(
    initial_learning_rate=<span class="hljs-number">5e-5</span>, end_learning_rate=<span class="hljs-number">0.0</span>, decay_steps=num_train_steps
)
<span class="hljs-keyword">from</span> tensorflow.keras.optimizers <span class="hljs-keyword">import</span> Adam

opt = Adam(learning_rate=lr_scheduler)`}}),Y=new fn({props:{$$slots:{default:[ar]},$$scope:{ctx:q}}}),ge=new L({props:{code:"",highlighted:`<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">2</span>)
loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>)
model.<span class="hljs-built_in">compile</span>(optimizer=opt, loss=loss, metrics=[<span class="hljs-string">&quot;accuracy&quot;</span>])`}}),we=new L({props:{code:"model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)",highlighted:'model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=<span class="hljs-number">3</span>)'}}),X=new fn({props:{$$slots:{default:[lr]},$$scope:{ctx:q}}}),be=new as({}),$e=new is({props:{id:"nx10eh4CoOs"}}),ve=new L({props:{code:'preds = model.predict(tf_validation_dataset)["logits"]',highlighted:'preds = model.predict(tf_validation_dataset)[<span class="hljs-string">&quot;logits&quot;</span>]'}}),_e=new L({props:{code:`class_preds = np.argmax(preds, axis=1)
print(preds.shape, class_preds.shape)`,highlighted:`class_preds = np.argmax(preds, axis=<span class="hljs-number">1</span>)
<span class="hljs-built_in">print</span>(preds.shape, class_preds.shape)`}}),ke=new L({props:{code:"(408, 2) (408,)",highlighted:'(<span class="hljs-number">408</span>, <span class="hljs-number">2</span>) (<span class="hljs-number">408</span>,)'}}),ze=new L({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric

metric = load_metric(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>)
metric.compute(predictions=class_preds, references=raw_datasets[<span class="hljs-string">&quot;validation&quot;</span>][<span class="hljs-string">&quot;label&quot;</span>])`}}),Ee=new L({props:{code:"{'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}",highlighted:'{<span class="hljs-string">&#x27;accuracy&#x27;</span>: <span class="hljs-number">0.8578431372549019</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.8996539792387542</span>}'}}),te=new fn({props:{$$slots:{default:[dr]},$$scope:{ctx:q}}}),{c(){u=a("meta"),b=f(),v(m.$$.fragment),$=f(),g=a("h1"),h=a("a"),c=a("span"),v(j.$$.fragment),T=f(),w=a("span"),P=r("Modell mit Keras fein-tunen"),S=f(),v(F.$$.fragment),ie=f(),y=a("p"),ls=r("Wenn du die Datenvorverarbeitung im letzten Abschnitt abgeschlossen hast, brauchst es nur noch wenige Schritte, um das Modell zu trainieren. Beachte jedoch, dass der Befehl "),Fe=a("code"),ds=r("model.fit()"),os=r(" auf einer CPU sehr langsam l\xE4uft. Wenn du keinen GPU hast, kannst du auf [Google Colab] ("),ae=a("a"),us=r("https://colab.research.google.com/"),fs=r(") kostenlos auf GPUs und TPUs zugreifen."),pn=f(),De=a("p"),ps=r("Bei den folgenden Codebeispielen wird davon ausgegangen, dass du die Beispiele aus dem vorherigen Abschnitt bereits ausgef\xFChrt hast. Hier ist eine kurze Zusammenfassung, die aufzeigt was erwartet wird:"),mn=f(),v(le.$$.fragment),hn=f(),G=a("h3"),N=a("a"),Oe=a("span"),v(de.$$.fragment),ms=f(),Ve=a("span"),hs=r("Training"),cn=f(),Te=a("p"),cs=r("Tensorflow Modelle, die von \u{1F917} Transformers importiert werden, sind bereits Keras Modelle. Hier ist eine kurze Einf\xFChrung in Keras."),gn=f(),v(oe.$$.fragment),wn=f(),Se=a("p"),gs=r("Sobald wir die Daten haben, braucht es nur noch sehr wenig Arbeit, um mit dem Training zu beginnen."),bn=f(),v(ue.$$.fragment),$n=f(),O=a("p"),ws=r("Wie im "),Ke=a("a"),bs=r("vorherigen Kapitel"),$s=r(" verwenden wir die Klasse "),Be=a("code"),vs=r("TFAutoModelForSequenceClassification"),_s=r(" mit zwei Labels:"),vn=f(),v(fe.$$.fragment),_n=f(),H=a("p"),ks=r("Im Gegensatz zu "),Pe=a("a"),zs=r("Kapitel 2"),Es=r(" wird eine Warnung angezeigt, nachdem das Modell instanziiert wurde. Das liegt daran, dass BERT nicht auf die Klassifizierung von Satzpaaren vortrainiert wurde. Deshalb wurde der Kopf des vortrainierten Modells verworfen und stattdessen ein neuer Kopf eingef\xFCgt, der f\xFCr die Klassifizierung von Sequenzen geeignet ist. Die Warnungen zeigen an, dass Teil der Gewichtung nicht verwendet wurden (die Gewichte f\xFCr den verworfenen Kopf) und dass einige andere zuf\xE4llig initialisiert wurden (die Gewichte f\xFCr den neuen Kopf). Abschlie\xDFend wirst du aufgefordert, das Modell zu trainieren, und genau das werden wir jetzt tun."),kn=f(),V=a("p"),Ms=r("Um das Modell mit unserem Datensatz fein-tunen zu k\xF6nnen, m\xFCssen wir das Modell "),Ge=a("code"),js=r("kompilieren()"),Ds=r(" und unsere Daten an die "),We=a("code"),Ts=r("fit()"),Ss=r("-Methode \xFCbergeben. Damit wird das Fein-tuning gestartet (dies sollte auf einer GPU ein paar Minuten dauern) und der Trainingsverlust sowie der Validierungsverlust am Ende jeder Epoche gemeldet."),zn=f(),v(I.$$.fragment),En=f(),v(pe.$$.fragment),Mn=f(),v(R.$$.fragment),jn=f(),W=a("h3"),Z=a("a"),xe=a("span"),v(me.$$.fragment),Ks=f(),Ue=a("span"),Ps=r("Verbesserung der Trainingsperformance"),Dn=f(),v(he.$$.fragment),Tn=f(),J=a("p"),qs=r("Wenn du den obigen Code ausprobierst, l\xE4uft er zwar, aber du wirst feststellen, dass der Verlust nur langsam oder sporadisch zur\xFCckgeht. Die Ursache hierf\xFCr ist die "),Ne=a("em"),ys=r("Lernrate"),As=r(". Wenn der Namen eines Optimierers als String an Keras \xFCbergeben wird, initialisiert Keras diesen Optimierer mit Standardwerten f\xFCr alle Parameter, einschlie\xDFlich der Lernrate. Aus langj\xE4hriger Erfahrung wissen wir, dass Transformer Modelle von einer wesentlich niedrigeren Lernrate profitieren als der Standardwert f\xFCr Adam. Dieser Standardwert liegt bei 1e-3, auch geschrieben als 10 hoch -3 oder 0,001. F\xFCr Transformer ist 5e-5 (0,00005), was etwa zwanzigmal niedriger ist, ist ein viel besserer Ausgangspunkt."),Sn=f(),K=a("p"),Cs=r("Zus\xE4tzlich zur Senkung der Lernrate haben wir noch einen zweiten Trick in petto: Wir k\xF6nnen die Lernrate langsam im Laufe des Trainings verringern. In der Literatur wird dies manchmal als "),He=a("em"),Ls=r("Decay"),Fs=r(" oder "),Ie=a("em"),Os=r("Annealing"),Vs=r(" der Lernrate bezeichnet. In Keras kannst das am besten mit dem "),Re=a("em"),Bs=r("Lernraten-Scheduler"),Gs=r(" umgesetzt werden. Ein guter Scheduler ist "),Ze=a("code"),Ws=r("PolynomialDecay"),xs=r(" - trotz des Namens l\xE4sst er die Lernrate in den Standardeinstellungen einfach linear vom Anfangswert bis zum Endwert abfallen. Dies ist genau was wir wollen. Um einen Scheduler richtig zu nutzen, m\xFCssen wir ihm allerdings sagen, wie lange das Training dauern soll. Das berechnen wir im Folgenden als "),Je=a("code"),Us=r("num_train_steps"),Ns=r("."),Kn=f(),v(ce.$$.fragment),Pn=f(),v(Y.$$.fragment),qn=f(),qe=a("p"),Hs=r("Somit haben wir einen neuen Optimierer definiert und k\xF6nnen ihn zum Training verwenden. Zuerst laden wir das Modell neu, um die \xC4nderungen an der Gewichtung aus dem letzten Trainingslauf zur\xFCckzusetzen, und dann k\xF6nnen wir es mit dem neuen Optimierer kompilieren:"),yn=f(),v(ge.$$.fragment),An=f(),Q=a("p"),Is=r("Jetzt starten wir einen erneuten Trainingslauf mit "),Ye=a("code"),Rs=r("fit"),Zs=r(":"),Cn=f(),v(we.$$.fragment),Ln=f(),v(X.$$.fragment),Fn=f(),x=a("h3"),ee=a("a"),Qe=a("span"),v(be.$$.fragment),Js=f(),Xe=a("span"),Ys=r("Modell-Vorhersagen"),On=f(),v($e.$$.fragment),Vn=f(),B=a("p"),Qs=r("Trainieren und zusehen, wie der Verlust sinkt, ist ja ganz nett, aber was ist, wenn wir tats\xE4chlich die Ergebnisse des trainierten Modells erhalten wollen? Entweder um Metriken zu berechnen oder um das Modell in der Produktion einzusetzen. Daf\xFCr k\xF6nnen wir einfach die Methode "),en=a("code"),Xs=r("predict()"),et=r(" verwenden. Sie liefert uns die "),nn=a("em"),nt=r("Logits"),st=r(" aus dem Ausgabekopf des Modells, und zwar eine pro Klasse."),Bn=f(),v(ve.$$.fragment),Gn=f(),ne=a("p"),tt=r("Wir k\xF6nnen diese Logits in die Klassenvorhersagen des Modells umwandeln, indem wir "),sn=a("code"),rt=r("argmax"),it=r(" verwenden, um den h\xF6chsten Logit zu finden, der der wahrscheinlichsten Klasse entspricht:"),Wn=f(),v(_e.$$.fragment),xn=f(),v(ke.$$.fragment),Un=f(),se=a("p"),at=r("Nun k\xF6nnen wir diese Vorhersagen in "),tn=a("code"),lt=r("preds"),dt=r(" nutzen, um einige Metriken zu berechnen! Wir k\xF6nnen die Metriken, die mit dem MRPC-Datensatz verbunden sind, genauso einfach laden, wie wir den Datensatz geladen haben, in diesem Fall mit der Funktion \u201Cload_metric()\u201C. Das zur\xFCckgegebene Objekt verf\xFCgt \xFCber eine Berechnungsmethode, mit der wir die Metrik berechnen k\xF6nnen:"),Nn=f(),v(ze.$$.fragment),Hn=f(),v(Ee.$$.fragment),In=f(),A=a("p"),ot=r("Die genauen Ergebnisse k\xF6nnen variieren, da die zuf\xE4llige Initialisierung des Modellkopfes die errechneten Metriken ver\xE4ndern kann. Das Modell erreicht \xFCber den Validierungsdaten eine Genauigkeit von 85,78 % und ein F1-Ma\xDF von 89,97. Dies sind die beiden Kennzahlen, die zur Bewertung der Ergebnisse des MRPC-Datensatzes f\xFCr das GLUE-Benchmark verwendet werden. In der Tabelle im [BERT-Paper] ("),Me=a("a"),ut=r("https://arxiv.org/pdf/1810.04805.pdf"),ft=r(") wird f\xFCr das Basismodell ein F1-Ma\xDF von 88,9 angegeben. Dort wurde das "),rn=a("code"),pt=r("uncased"),mt=r(" Modell verwendet, w\xE4hrend wir hier das "),an=a("code"),ht=r("cased"),ct=r(" Modell verwenden, was das bessere Ergebnis erkl\xE4rt."),Rn=f(),ye=a("p"),gt=r("Damit ist die Einf\xFChrung in das Fein-tunen mit der Keras-API abgeschlossen. Beispiele f\xFCr die g\xE4ngigsten CL-Aufgaben findest du in Kapitel 7."),Zn=f(),v(te.$$.fragment),this.h()},l(e){const t=er('[data-svelte="svelte-1phssyn"]',document.head);u=l(t,"META",{name:!0,content:!0}),t.forEach(n),b=p(e),_(m.$$.fragment,e),$=p(e),g=l(e,"H1",{class:!0});var je=o(g);h=l(je,"A",{id:!0,class:!0,href:!0});var ln=o(h);c=l(ln,"SPAN",{});var dn=o(c);_(j.$$.fragment,dn),dn.forEach(n),ln.forEach(n),T=p(je),w=l(je,"SPAN",{});var on=o(w);P=i(on,"Modell mit Keras fein-tunen"),on.forEach(n),je.forEach(n),S=p(e),_(F.$$.fragment,e),ie=p(e),y=l(e,"P",{});var U=o(y);ls=i(U,"Wenn du die Datenvorverarbeitung im letzten Abschnitt abgeschlossen hast, brauchst es nur noch wenige Schritte, um das Modell zu trainieren. Beachte jedoch, dass der Befehl "),Fe=l(U,"CODE",{});var un=o(Fe);ds=i(un,"model.fit()"),un.forEach(n),os=i(U," auf einer CPU sehr langsam l\xE4uft. Wenn du keinen GPU hast, kannst du auf [Google Colab] ("),ae=l(U,"A",{href:!0,rel:!0});var wt=o(ae);us=i(wt,"https://colab.research.google.com/"),wt.forEach(n),fs=i(U,") kostenlos auf GPUs und TPUs zugreifen."),U.forEach(n),pn=p(e),De=l(e,"P",{});var bt=o(De);ps=i(bt,"Bei den folgenden Codebeispielen wird davon ausgegangen, dass du die Beispiele aus dem vorherigen Abschnitt bereits ausgef\xFChrt hast. Hier ist eine kurze Zusammenfassung, die aufzeigt was erwartet wird:"),bt.forEach(n),mn=p(e),_(le.$$.fragment,e),hn=p(e),G=l(e,"H3",{class:!0});var Yn=o(G);N=l(Yn,"A",{id:!0,class:!0,href:!0});var $t=o(N);Oe=l($t,"SPAN",{});var vt=o(Oe);_(de.$$.fragment,vt),vt.forEach(n),$t.forEach(n),ms=p(Yn),Ve=l(Yn,"SPAN",{});var _t=o(Ve);hs=i(_t,"Training"),_t.forEach(n),Yn.forEach(n),cn=p(e),Te=l(e,"P",{});var kt=o(Te);cs=i(kt,"Tensorflow Modelle, die von \u{1F917} Transformers importiert werden, sind bereits Keras Modelle. Hier ist eine kurze Einf\xFChrung in Keras."),kt.forEach(n),gn=p(e),_(oe.$$.fragment,e),wn=p(e),Se=l(e,"P",{});var zt=o(Se);gs=i(zt,"Sobald wir die Daten haben, braucht es nur noch sehr wenig Arbeit, um mit dem Training zu beginnen."),zt.forEach(n),bn=p(e),_(ue.$$.fragment,e),$n=p(e),O=l(e,"P",{});var Ae=o(O);ws=i(Ae,"Wie im "),Ke=l(Ae,"A",{href:!0});var Et=o(Ke);bs=i(Et,"vorherigen Kapitel"),Et.forEach(n),$s=i(Ae," verwenden wir die Klasse "),Be=l(Ae,"CODE",{});var Mt=o(Be);vs=i(Mt,"TFAutoModelForSequenceClassification"),Mt.forEach(n),_s=i(Ae," mit zwei Labels:"),Ae.forEach(n),vn=p(e),_(fe.$$.fragment,e),_n=p(e),H=l(e,"P",{});var Qn=o(H);ks=i(Qn,"Im Gegensatz zu "),Pe=l(Qn,"A",{href:!0});var jt=o(Pe);zs=i(jt,"Kapitel 2"),jt.forEach(n),Es=i(Qn," wird eine Warnung angezeigt, nachdem das Modell instanziiert wurde. Das liegt daran, dass BERT nicht auf die Klassifizierung von Satzpaaren vortrainiert wurde. Deshalb wurde der Kopf des vortrainierten Modells verworfen und stattdessen ein neuer Kopf eingef\xFCgt, der f\xFCr die Klassifizierung von Sequenzen geeignet ist. Die Warnungen zeigen an, dass Teil der Gewichtung nicht verwendet wurden (die Gewichte f\xFCr den verworfenen Kopf) und dass einige andere zuf\xE4llig initialisiert wurden (die Gewichte f\xFCr den neuen Kopf). Abschlie\xDFend wirst du aufgefordert, das Modell zu trainieren, und genau das werden wir jetzt tun."),Qn.forEach(n),kn=p(e),V=l(e,"P",{});var Ce=o(V);Ms=i(Ce,"Um das Modell mit unserem Datensatz fein-tunen zu k\xF6nnen, m\xFCssen wir das Modell "),Ge=l(Ce,"CODE",{});var Dt=o(Ge);js=i(Dt,"kompilieren()"),Dt.forEach(n),Ds=i(Ce," und unsere Daten an die "),We=l(Ce,"CODE",{});var Tt=o(We);Ts=i(Tt,"fit()"),Tt.forEach(n),Ss=i(Ce,"-Methode \xFCbergeben. Damit wird das Fein-tuning gestartet (dies sollte auf einer GPU ein paar Minuten dauern) und der Trainingsverlust sowie der Validierungsverlust am Ende jeder Epoche gemeldet."),Ce.forEach(n),zn=p(e),_(I.$$.fragment,e),En=p(e),_(pe.$$.fragment,e),Mn=p(e),_(R.$$.fragment,e),jn=p(e),W=l(e,"H3",{class:!0});var Xn=o(W);Z=l(Xn,"A",{id:!0,class:!0,href:!0});var St=o(Z);xe=l(St,"SPAN",{});var Kt=o(xe);_(me.$$.fragment,Kt),Kt.forEach(n),St.forEach(n),Ks=p(Xn),Ue=l(Xn,"SPAN",{});var Pt=o(Ue);Ps=i(Pt,"Verbesserung der Trainingsperformance"),Pt.forEach(n),Xn.forEach(n),Dn=p(e),_(he.$$.fragment,e),Tn=p(e),J=l(e,"P",{});var es=o(J);qs=i(es,"Wenn du den obigen Code ausprobierst, l\xE4uft er zwar, aber du wirst feststellen, dass der Verlust nur langsam oder sporadisch zur\xFCckgeht. Die Ursache hierf\xFCr ist die "),Ne=l(es,"EM",{});var qt=o(Ne);ys=i(qt,"Lernrate"),qt.forEach(n),As=i(es,". Wenn der Namen eines Optimierers als String an Keras \xFCbergeben wird, initialisiert Keras diesen Optimierer mit Standardwerten f\xFCr alle Parameter, einschlie\xDFlich der Lernrate. Aus langj\xE4hriger Erfahrung wissen wir, dass Transformer Modelle von einer wesentlich niedrigeren Lernrate profitieren als der Standardwert f\xFCr Adam. Dieser Standardwert liegt bei 1e-3, auch geschrieben als 10 hoch -3 oder 0,001. F\xFCr Transformer ist 5e-5 (0,00005), was etwa zwanzigmal niedriger ist, ist ein viel besserer Ausgangspunkt."),es.forEach(n),Sn=p(e),K=l(e,"P",{});var C=o(K);Cs=i(C,"Zus\xE4tzlich zur Senkung der Lernrate haben wir noch einen zweiten Trick in petto: Wir k\xF6nnen die Lernrate langsam im Laufe des Trainings verringern. In der Literatur wird dies manchmal als "),He=l(C,"EM",{});var yt=o(He);Ls=i(yt,"Decay"),yt.forEach(n),Fs=i(C," oder "),Ie=l(C,"EM",{});var At=o(Ie);Os=i(At,"Annealing"),At.forEach(n),Vs=i(C," der Lernrate bezeichnet. In Keras kannst das am besten mit dem "),Re=l(C,"EM",{});var Ct=o(Re);Bs=i(Ct,"Lernraten-Scheduler"),Ct.forEach(n),Gs=i(C," umgesetzt werden. Ein guter Scheduler ist "),Ze=l(C,"CODE",{});var Lt=o(Ze);Ws=i(Lt,"PolynomialDecay"),Lt.forEach(n),xs=i(C," - trotz des Namens l\xE4sst er die Lernrate in den Standardeinstellungen einfach linear vom Anfangswert bis zum Endwert abfallen. Dies ist genau was wir wollen. Um einen Scheduler richtig zu nutzen, m\xFCssen wir ihm allerdings sagen, wie lange das Training dauern soll. Das berechnen wir im Folgenden als "),Je=l(C,"CODE",{});var Ft=o(Je);Us=i(Ft,"num_train_steps"),Ft.forEach(n),Ns=i(C,"."),C.forEach(n),Kn=p(e),_(ce.$$.fragment,e),Pn=p(e),_(Y.$$.fragment,e),qn=p(e),qe=l(e,"P",{});var Ot=o(qe);Hs=i(Ot,"Somit haben wir einen neuen Optimierer definiert und k\xF6nnen ihn zum Training verwenden. Zuerst laden wir das Modell neu, um die \xC4nderungen an der Gewichtung aus dem letzten Trainingslauf zur\xFCckzusetzen, und dann k\xF6nnen wir es mit dem neuen Optimierer kompilieren:"),Ot.forEach(n),yn=p(e),_(ge.$$.fragment,e),An=p(e),Q=l(e,"P",{});var ns=o(Q);Is=i(ns,"Jetzt starten wir einen erneuten Trainingslauf mit "),Ye=l(ns,"CODE",{});var Vt=o(Ye);Rs=i(Vt,"fit"),Vt.forEach(n),Zs=i(ns,":"),ns.forEach(n),Cn=p(e),_(we.$$.fragment,e),Ln=p(e),_(X.$$.fragment,e),Fn=p(e),x=l(e,"H3",{class:!0});var ss=o(x);ee=l(ss,"A",{id:!0,class:!0,href:!0});var Bt=o(ee);Qe=l(Bt,"SPAN",{});var Gt=o(Qe);_(be.$$.fragment,Gt),Gt.forEach(n),Bt.forEach(n),Js=p(ss),Xe=l(ss,"SPAN",{});var Wt=o(Xe);Ys=i(Wt,"Modell-Vorhersagen"),Wt.forEach(n),ss.forEach(n),On=p(e),_($e.$$.fragment,e),Vn=p(e),B=l(e,"P",{});var Le=o(B);Qs=i(Le,"Trainieren und zusehen, wie der Verlust sinkt, ist ja ganz nett, aber was ist, wenn wir tats\xE4chlich die Ergebnisse des trainierten Modells erhalten wollen? Entweder um Metriken zu berechnen oder um das Modell in der Produktion einzusetzen. Daf\xFCr k\xF6nnen wir einfach die Methode "),en=l(Le,"CODE",{});var xt=o(en);Xs=i(xt,"predict()"),xt.forEach(n),et=i(Le," verwenden. Sie liefert uns die "),nn=l(Le,"EM",{});var Ut=o(nn);nt=i(Ut,"Logits"),Ut.forEach(n),st=i(Le," aus dem Ausgabekopf des Modells, und zwar eine pro Klasse."),Le.forEach(n),Bn=p(e),_(ve.$$.fragment,e),Gn=p(e),ne=l(e,"P",{});var ts=o(ne);tt=i(ts,"Wir k\xF6nnen diese Logits in die Klassenvorhersagen des Modells umwandeln, indem wir "),sn=l(ts,"CODE",{});var Nt=o(sn);rt=i(Nt,"argmax"),Nt.forEach(n),it=i(ts," verwenden, um den h\xF6chsten Logit zu finden, der der wahrscheinlichsten Klasse entspricht:"),ts.forEach(n),Wn=p(e),_(_e.$$.fragment,e),xn=p(e),_(ke.$$.fragment,e),Un=p(e),se=l(e,"P",{});var rs=o(se);at=i(rs,"Nun k\xF6nnen wir diese Vorhersagen in "),tn=l(rs,"CODE",{});var Ht=o(tn);lt=i(Ht,"preds"),Ht.forEach(n),dt=i(rs," nutzen, um einige Metriken zu berechnen! Wir k\xF6nnen die Metriken, die mit dem MRPC-Datensatz verbunden sind, genauso einfach laden, wie wir den Datensatz geladen haben, in diesem Fall mit der Funktion \u201Cload_metric()\u201C. Das zur\xFCckgegebene Objekt verf\xFCgt \xFCber eine Berechnungsmethode, mit der wir die Metrik berechnen k\xF6nnen:"),rs.forEach(n),Nn=p(e),_(ze.$$.fragment,e),Hn=p(e),_(Ee.$$.fragment,e),In=p(e),A=l(e,"P",{});var re=o(A);ot=i(re,"Die genauen Ergebnisse k\xF6nnen variieren, da die zuf\xE4llige Initialisierung des Modellkopfes die errechneten Metriken ver\xE4ndern kann. Das Modell erreicht \xFCber den Validierungsdaten eine Genauigkeit von 85,78 % und ein F1-Ma\xDF von 89,97. Dies sind die beiden Kennzahlen, die zur Bewertung der Ergebnisse des MRPC-Datensatzes f\xFCr das GLUE-Benchmark verwendet werden. In der Tabelle im [BERT-Paper] ("),Me=l(re,"A",{href:!0,rel:!0});var It=o(Me);ut=i(It,"https://arxiv.org/pdf/1810.04805.pdf"),It.forEach(n),ft=i(re,") wird f\xFCr das Basismodell ein F1-Ma\xDF von 88,9 angegeben. Dort wurde das "),rn=l(re,"CODE",{});var Rt=o(rn);pt=i(Rt,"uncased"),Rt.forEach(n),mt=i(re," Modell verwendet, w\xE4hrend wir hier das "),an=l(re,"CODE",{});var Zt=o(an);ht=i(Zt,"cased"),Zt.forEach(n),ct=i(re," Modell verwenden, was das bessere Ergebnis erkl\xE4rt."),re.forEach(n),Rn=p(e),ye=l(e,"P",{});var Jt=o(ye);gt=i(Jt,"Damit ist die Einf\xFChrung in das Fein-tunen mit der Keras-API abgeschlossen. Beispiele f\xFCr die g\xE4ngigsten CL-Aufgaben findest du in Kapitel 7."),Jt.forEach(n),Zn=p(e),_(te.$$.fragment,e),this.h()},h(){D(u,"name","hf:doc:metadata"),D(u,"content",JSON.stringify(ur)),D(h,"id","modell-mit-keras-feintunen"),D(h,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),D(h,"href","#modell-mit-keras-feintunen"),D(g,"class","relative group"),D(ae,"href","https://colab.research.google.com/"),D(ae,"rel","nofollow"),D(N,"id","training"),D(N,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),D(N,"href","#training"),D(G,"class","relative group"),D(Ke,"href","/course/chapter2"),D(Pe,"href","/course/chapter2"),D(Z,"id","verbesserung-der-trainingsperformance"),D(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),D(Z,"href","#verbesserung-der-trainingsperformance"),D(W,"class","relative group"),D(ee,"id","modellvorhersagen"),D(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),D(ee,"href","#modellvorhersagen"),D(x,"class","relative group"),D(Me,"href","https://arxiv.org/pdf/1810.04805.pdf"),D(Me,"rel","nofollow")},m(e,t){s(document.head,u),d(e,b,t),k(m,e,t),d(e,$,t),d(e,g,t),s(g,h),s(h,c),k(j,c,null),s(g,T),s(g,w),s(w,P),d(e,S,t),k(F,e,t),d(e,ie,t),d(e,y,t),s(y,ls),s(y,Fe),s(Fe,ds),s(y,os),s(y,ae),s(ae,us),s(y,fs),d(e,pn,t),d(e,De,t),s(De,ps),d(e,mn,t),k(le,e,t),d(e,hn,t),d(e,G,t),s(G,N),s(N,Oe),k(de,Oe,null),s(G,ms),s(G,Ve),s(Ve,hs),d(e,cn,t),d(e,Te,t),s(Te,cs),d(e,gn,t),k(oe,e,t),d(e,wn,t),d(e,Se,t),s(Se,gs),d(e,bn,t),k(ue,e,t),d(e,$n,t),d(e,O,t),s(O,ws),s(O,Ke),s(Ke,bs),s(O,$s),s(O,Be),s(Be,vs),s(O,_s),d(e,vn,t),k(fe,e,t),d(e,_n,t),d(e,H,t),s(H,ks),s(H,Pe),s(Pe,zs),s(H,Es),d(e,kn,t),d(e,V,t),s(V,Ms),s(V,Ge),s(Ge,js),s(V,Ds),s(V,We),s(We,Ts),s(V,Ss),d(e,zn,t),k(I,e,t),d(e,En,t),k(pe,e,t),d(e,Mn,t),k(R,e,t),d(e,jn,t),d(e,W,t),s(W,Z),s(Z,xe),k(me,xe,null),s(W,Ks),s(W,Ue),s(Ue,Ps),d(e,Dn,t),k(he,e,t),d(e,Tn,t),d(e,J,t),s(J,qs),s(J,Ne),s(Ne,ys),s(J,As),d(e,Sn,t),d(e,K,t),s(K,Cs),s(K,He),s(He,Ls),s(K,Fs),s(K,Ie),s(Ie,Os),s(K,Vs),s(K,Re),s(Re,Bs),s(K,Gs),s(K,Ze),s(Ze,Ws),s(K,xs),s(K,Je),s(Je,Us),s(K,Ns),d(e,Kn,t),k(ce,e,t),d(e,Pn,t),k(Y,e,t),d(e,qn,t),d(e,qe,t),s(qe,Hs),d(e,yn,t),k(ge,e,t),d(e,An,t),d(e,Q,t),s(Q,Is),s(Q,Ye),s(Ye,Rs),s(Q,Zs),d(e,Cn,t),k(we,e,t),d(e,Ln,t),k(X,e,t),d(e,Fn,t),d(e,x,t),s(x,ee),s(ee,Qe),k(be,Qe,null),s(x,Js),s(x,Xe),s(Xe,Ys),d(e,On,t),k($e,e,t),d(e,Vn,t),d(e,B,t),s(B,Qs),s(B,en),s(en,Xs),s(B,et),s(B,nn),s(nn,nt),s(B,st),d(e,Bn,t),k(ve,e,t),d(e,Gn,t),d(e,ne,t),s(ne,tt),s(ne,sn),s(sn,rt),s(ne,it),d(e,Wn,t),k(_e,e,t),d(e,xn,t),k(ke,e,t),d(e,Un,t),d(e,se,t),s(se,at),s(se,tn),s(tn,lt),s(se,dt),d(e,Nn,t),k(ze,e,t),d(e,Hn,t),k(Ee,e,t),d(e,In,t),d(e,A,t),s(A,ot),s(A,Me),s(Me,ut),s(A,ft),s(A,rn),s(rn,pt),s(A,mt),s(A,an),s(an,ht),s(A,ct),d(e,Rn,t),d(e,ye,t),s(ye,gt),d(e,Zn,t),k(te,e,t),Jn=!0},p(e,[t]){const je={};t&1&&(je.fw=e[0]),m.$set(je);const ln={};t&2&&(ln.$$scope={dirty:t,ctx:e}),I.$set(ln);const dn={};t&2&&(dn.$$scope={dirty:t,ctx:e}),R.$set(dn);const on={};t&2&&(on.$$scope={dirty:t,ctx:e}),Y.$set(on);const U={};t&2&&(U.$$scope={dirty:t,ctx:e}),X.$set(U);const un={};t&2&&(un.$$scope={dirty:t,ctx:e}),te.$set(un)},i(e){Jn||(z(m.$$.fragment,e),z(j.$$.fragment,e),z(F.$$.fragment,e),z(le.$$.fragment,e),z(de.$$.fragment,e),z(oe.$$.fragment,e),z(ue.$$.fragment,e),z(fe.$$.fragment,e),z(I.$$.fragment,e),z(pe.$$.fragment,e),z(R.$$.fragment,e),z(me.$$.fragment,e),z(he.$$.fragment,e),z(ce.$$.fragment,e),z(Y.$$.fragment,e),z(ge.$$.fragment,e),z(we.$$.fragment,e),z(X.$$.fragment,e),z(be.$$.fragment,e),z($e.$$.fragment,e),z(ve.$$.fragment,e),z(_e.$$.fragment,e),z(ke.$$.fragment,e),z(ze.$$.fragment,e),z(Ee.$$.fragment,e),z(te.$$.fragment,e),Jn=!0)},o(e){E(m.$$.fragment,e),E(j.$$.fragment,e),E(F.$$.fragment,e),E(le.$$.fragment,e),E(de.$$.fragment,e),E(oe.$$.fragment,e),E(ue.$$.fragment,e),E(fe.$$.fragment,e),E(I.$$.fragment,e),E(pe.$$.fragment,e),E(R.$$.fragment,e),E(me.$$.fragment,e),E(he.$$.fragment,e),E(ce.$$.fragment,e),E(Y.$$.fragment,e),E(ge.$$.fragment,e),E(we.$$.fragment,e),E(X.$$.fragment,e),E(be.$$.fragment,e),E($e.$$.fragment,e),E(ve.$$.fragment,e),E(_e.$$.fragment,e),E(ke.$$.fragment,e),E(ze.$$.fragment,e),E(Ee.$$.fragment,e),E(te.$$.fragment,e),Jn=!1},d(e){n(u),e&&n(b),M(m,e),e&&n($),e&&n(g),M(j),e&&n(S),M(F,e),e&&n(ie),e&&n(y),e&&n(pn),e&&n(De),e&&n(mn),M(le,e),e&&n(hn),e&&n(G),M(de),e&&n(cn),e&&n(Te),e&&n(gn),M(oe,e),e&&n(wn),e&&n(Se),e&&n(bn),M(ue,e),e&&n($n),e&&n(O),e&&n(vn),M(fe,e),e&&n(_n),e&&n(H),e&&n(kn),e&&n(V),e&&n(zn),M(I,e),e&&n(En),M(pe,e),e&&n(Mn),M(R,e),e&&n(jn),e&&n(W),M(me),e&&n(Dn),M(he,e),e&&n(Tn),e&&n(J),e&&n(Sn),e&&n(K),e&&n(Kn),M(ce,e),e&&n(Pn),M(Y,e),e&&n(qn),e&&n(qe),e&&n(yn),M(ge,e),e&&n(An),e&&n(Q),e&&n(Cn),M(we,e),e&&n(Ln),M(X,e),e&&n(Fn),e&&n(x),M(be),e&&n(On),M($e,e),e&&n(Vn),e&&n(B),e&&n(Bn),M(ve,e),e&&n(Gn),e&&n(ne),e&&n(Wn),M(_e,e),e&&n(xn),M(ke,e),e&&n(Un),e&&n(se),e&&n(Nn),M(ze,e),e&&n(Hn),M(Ee,e),e&&n(In),e&&n(A),e&&n(Rn),e&&n(ye),e&&n(Zn),M(te,e)}}}const ur={local:"modell-mit-keras-feintunen",sections:[{local:"training",title:"Training"},{local:"verbesserung-der-trainingsperformance",title:"Verbesserung der Trainingsperformance"},{local:"modellvorhersagen",title:"Modell-Vorhersagen"}],title:"Modell mit Keras fein-tunen"};function fr(q,u,b){let m="pt";return nr(()=>{const $=new URLSearchParams(window.location.search);b(0,m=$.get("fw")||"pt")}),[m]}class wr extends Yt{constructor(u){super();Qt(this,u,fr,or,Xt,{})}}export{wr as default,ur as metadata};
