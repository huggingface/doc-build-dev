import{S as jo,i as ko,s as Eo,e as l,k as p,w as d,t as a,M as go,c as o,d as t,m as c,a as i,x as m,h as n,b,G as s,g as u,y as f,q as h,o as v,B as _,v as wo}from"../../chunks/vendor-hf-doc-builder.js";import{T as $o}from"../../chunks/Tip-hf-doc-builder.js";import{Y as qo}from"../../chunks/Youtube-hf-doc-builder.js";import{I as dt}from"../../chunks/IconCopyLink-hf-doc-builder.js";import{C as q}from"../../chunks/CodeBlock-hf-doc-builder.js";import{D as yo}from"../../chunks/DocNotebookDropdown-hf-doc-builder.js";function zo(Je){let $,y,E,w,j,k,he,V;return{c(){$=l("p"),y=a("\u270F\uFE0F "),E=l("strong"),w=a("Essayez"),j=a(" Modifiez la boucle d\u2019entra\xEEnement pr\xE9c\xE9dente pour "),k=l("em"),he=a("finetuner"),V=a(" votre mod\xE8le sur le jeu de donn\xE9es SST-2.")},l(H){$=o(H,"P",{});var C=i($);y=n(C,"\u270F\uFE0F "),E=o(C,"STRONG",{});var M=i(E);w=n(M,"Essayez"),M.forEach(t),j=n(C," Modifiez la boucle d\u2019entra\xEEnement pr\xE9c\xE9dente pour "),k=o(C,"EM",{});var ve=i(k);he=n(ve,"finetuner"),ve.forEach(t),V=n(C," votre mod\xE8le sur le jeu de donn\xE9es SST-2."),C.forEach(t)},m(H,C){u(H,$,C),s($,y),s($,E),s(E,w),s($,j),s($,k),s(k,he),s($,V)},d(H){H&&t($)}}}function Po(Je){let $,y,E,w;return{c(){$=a('\u26A0\uFE0F Afin de b\xE9n\xE9ficier de la rapidit\xE9 offerte par les TPUs du Cloud, nous vous recommandons de rembourrer vos \xE9chantillons \xE0 une longueur fixe avec les arguments `padding="max_length"` et `max_length` du '),y=l("i"),E=a("tokenizer"),w=a(".")},l(j){$=n(j,'\u26A0\uFE0F Afin de b\xE9n\xE9ficier de la rapidit\xE9 offerte par les TPUs du Cloud, nous vous recommandons de rembourrer vos \xE9chantillons \xE0 une longueur fixe avec les arguments `padding="max_length"` et `max_length` du '),y=o(j,"I",{});var k=i(y);E=n(k,"tokenizer"),k.forEach(t),w=n(j,".")},m(j,k){u(j,$,k),u(j,y,k),s(y,E),u(j,w,k)},d(j){j&&t($),j&&t(y),j&&t(w)}}}function xo(Je){let $,y,E,w,j,k,he,V,H,C,M,ve,_e,mt,K,Aa,ds,Ca,Da,ft,be,ht,R,X,ms,$e,Sa,fs,Ma,vt,D,Oa,hs,Ta,La,vs,Na,Ua,_s,Wa,Ia,_t,O,B,Fa,bs,Ga,Va,$s,Ha,Ra,Ba,S,Ja,qs,Ya,Qa,js,Ka,Xa,ks,Za,en,sn,Es,tn,bt,Z,an,gs,nn,rn,$t,qe,qt,Ye,ln,jt,je,kt,ee,on,ws,un,pn,Et,ke,gt,Qe,cn,wt,Ee,yt,ge,zt,T,dn,ys,mn,fn,zs,hn,vn,Pt,Ke,_n,xt,we,At,Xe,bn,Ct,ye,Dt,ze,St,L,$n,Ps,qn,jn,xs,kn,En,Mt,z,gn,As,wn,yn,Cs,zn,Pn,Ds,xn,An,Pe,Ss,Cn,Dn,Ot,xe,Tt,N,Sn,Ms,Mn,On,Os,Tn,Ln,Lt,Ae,Nt,Ce,Ut,J,se,Ts,De,Nn,Ls,Un,Wt,te,Wn,Ns,In,Fn,It,Se,Ft,Me,Gt,ae,Gn,Us,Vn,Hn,Vt,Oe,Ht,Ze,Rn,Rt,Y,ne,Ws,Te,Bn,Is,Jn,Bt,P,Yn,Fs,Qn,Kn,Gs,Xn,Zn,Vs,er,sr,Hs,tr,ar,Jt,Le,Yt,Ne,Qt,es,nr,Kt,re,Xt,Q,le,Rs,Ue,rr,ss,lr,Bs,or,Zt,We,ea,U,ir,oe,ur,Js,pr,cr,Ys,dr,mr,sa,Ie,ta,ts,fr,aa,Fe,na,x,hr,Qs,vr,_r,Ks,br,$r,Xs,qr,jr,Zs,kr,Er,ra,g,gr,et,wr,yr,st,zr,Pr,tt,xr,Ar,at,Cr,Dr,nt,Sr,Mr,rt,Or,Tr,la,ie,oa,ue,Lr,lt,Nr,Ur,ia,Ge,ua,pe,Wr,ot,Ir,Fr,pa,Ve,ca,as,Gr,da,He,ma,ns,Vr,fa,W,Hr,it,Rr,Br,ut,Jr,Yr,ha,Re,va,ce,Qr,de,Kr,pt,Xr,Zr,_a;return k=new dt({}),M=new yo({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Google Colab",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/chapter3/section4.ipynb"},{label:"Aws Studio",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/chapter3/section4.ipynb"}]}}),_e=new qo({props:{id:"Dh9CL8fyG80"}}),be=new q({props:{code:`



`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>)
checkpoint = <span class="hljs-string">&quot;bert-base-uncased&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">example</span>):
    <span class="hljs-keyword">return</span> tokenizer(example[<span class="hljs-string">&quot;sentence1&quot;</span>], example[<span class="hljs-string">&quot;sentence2&quot;</span>], truncation=<span class="hljs-literal">True</span>)


tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)`}}),$e=new dt({}),qe=new q({props:{code:`tokenized_datasets = tokenized_datasets.remove_columns(["sentence1", "sentence2", "idx"])
tokenized_datasets = tokenized_datasets.rename_column("label", "labels")
tokenized_datasets.set_format("torch")
tokenized_datasets["train"].column_names`,highlighted:`tokenized_datasets = tokenized_datasets.remove_columns([<span class="hljs-string">&quot;sentence1&quot;</span>, <span class="hljs-string">&quot;sentence2&quot;</span>, <span class="hljs-string">&quot;idx&quot;</span>])
tokenized_datasets = tokenized_datasets.rename_column(<span class="hljs-string">&quot;label&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>)
tokenized_datasets.set_format(<span class="hljs-string">&quot;torch&quot;</span>)
tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].column_names`}}),je=new q({props:{code:'["attention_mask", "input_ids", "labels", "token_type_ids"]',highlighted:'[<span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>, <span class="hljs-string">&quot;token_type_ids&quot;</span>]'}}),ke=new q({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader

train_dataloader = DataLoader(
    tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>], shuffle=<span class="hljs-literal">True</span>, batch_size=<span class="hljs-number">8</span>, collate_fn=data_collator
)
eval_dataloader = DataLoader(
    tokenized_datasets[<span class="hljs-string">&quot;validation&quot;</span>], batch_size=<span class="hljs-number">8</span>, collate_fn=data_collator
)`}}),Ee=new q({props:{code:`for batch in train_dataloader:
    break
{k: v.shape for k, v in batch.items()}`,highlighted:`<span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:
    <span class="hljs-keyword">break</span>
{k: v.shape <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}`}}),ge=new q({props:{code:`{'attention_mask': torch.Size([8, 65]),
 'input_ids': torch.Size([8, 65]),
 'labels': torch.Size([8]),
 'token_type_ids': torch.Size([8, 65])}`,highlighted:`{<span class="hljs-string">&#x27;attention_mask&#x27;</span>: torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">65</span>]),
 <span class="hljs-string">&#x27;input_ids&#x27;</span>: torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">65</span>]),
 <span class="hljs-string">&#x27;labels&#x27;</span>: torch.Size([<span class="hljs-number">8</span>]),
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">65</span>])}`}}),we=new q({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">2</span>)`}}),ye=new q({props:{code:`outputs = model(**batch)
print(outputs.loss, outputs.logits.shape)`,highlighted:`outputs = model(**batch)
<span class="hljs-built_in">print</span>(outputs.loss, outputs.logits.shape)`}}),ze=new q({props:{code:"tensor(0.5441, grad_fn=<NllLossBackward>) torch.Size([8, 2])",highlighted:'tensor(<span class="hljs-number">0.5441</span>, grad_fn=&lt;NllLossBackward&gt;) torch.Size([<span class="hljs-number">8</span>, <span class="hljs-number">2</span>])'}}),xe=new q({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW

optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">5e-5</span>)`}}),Ae=new q({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler

num_epochs = <span class="hljs-number">3</span>
num_training_steps = num_epochs * <span class="hljs-built_in">len</span>(train_dataloader)
lr_scheduler = get_scheduler(
    <span class="hljs-string">&quot;linear&quot;</span>,
    optimizer=optimizer,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_training_steps=num_training_steps,
)
<span class="hljs-built_in">print</span>(num_training_steps)`}}),Ce=new q({props:{code:"1377",highlighted:'<span class="hljs-number">1377</span>'}}),De=new dt({}),Se=new q({props:{code:"",highlighted:`<span class="hljs-keyword">import</span> torch

device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)
model.to(device)
device`}}),Me=new q({props:{code:"device(type='cuda')",highlighted:'device(<span class="hljs-built_in">type</span>=<span class="hljs-string">&#x27;cuda&#x27;</span>)'}}),Oe=new q({props:{code:`

`,highlighted:`<span class="hljs-keyword">from</span> tqdm.auto <span class="hljs-keyword">import</span> tqdm

progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

model.train()
<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:
        batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
        outputs = model(**batch)
        loss = outputs.loss
        loss.backward()

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(<span class="hljs-number">1</span>)`}}),Te=new dt({}),Le=new q({props:{code:`

`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_metric

metric = load_metric(<span class="hljs-string">&quot;glue&quot;</span>, <span class="hljs-string">&quot;mrpc&quot;</span>)
model.<span class="hljs-built_in">eval</span>()
<span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> eval_dataloader:
    batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
    <span class="hljs-keyword">with</span> torch.no_grad():
        outputs = model(**batch)

    logits = outputs.logits
    predictions = torch.argmax(logits, dim=-<span class="hljs-number">1</span>)
    metric.add_batch(predictions=predictions, references=batch[<span class="hljs-string">&quot;labels&quot;</span>])

metric.compute()`}}),Ne=new q({props:{code:"{'accuracy': 0.8431372549019608, 'f1': 0.8907849829351535}",highlighted:'{<span class="hljs-string">&#x27;accuracy&#x27;</span>: <span class="hljs-number">0.8431372549019608</span>, <span class="hljs-string">&#x27;f1&#x27;</span>: <span class="hljs-number">0.8907849829351535</span>}'}}),re=new $o({props:{$$slots:{default:[zo]},$$scope:{ctx:Je}}}),Ue=new dt({}),We=new qo({props:{id:"s7dy8QRgjJ0"}}),Ie=new q({props:{code:`




`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW, AutoModelForSequenceClassification, get_scheduler

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">2</span>)
optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">3e-5</span>)

device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>) <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)
model.to(device)

num_epochs = <span class="hljs-number">3</span>
num_training_steps = num_epochs * <span class="hljs-built_in">len</span>(train_dataloader)
lr_scheduler = get_scheduler(
    <span class="hljs-string">&quot;linear&quot;</span>,
    optimizer=optimizer,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_training_steps=num_training_steps,
)

progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

model.train()
<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dataloader:
        batch = {k: v.to(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
        outputs = model(**batch)
        loss = outputs.loss
        loss.backward()

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(<span class="hljs-number">1</span>)`}}),Fe=new q({props:{code:`






`,highlighted:`<span class="hljs-addition">+ from accelerate import Accelerator</span>
  from transformers import AdamW, AutoModelForSequenceClassification, get_scheduler

<span class="hljs-addition">+ accelerator = Accelerator()</span>

  model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
  optimizer = AdamW(model.parameters(), lr=3e-5)

<span class="hljs-deletion">- device = torch.device(&quot;cuda&quot;) if torch.cuda.is_available() else torch.device(&quot;cpu&quot;)</span>
<span class="hljs-deletion">- model.to(device)</span>

<span class="hljs-addition">+ train_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(</span>
<span class="hljs-addition">+     train_dataloader, eval_dataloader, model, optimizer</span>
<span class="hljs-addition">+ )</span>

  num_epochs = 3
  num_training_steps = num_epochs * len(train_dataloader)
  lr_scheduler = get_scheduler(
      &quot;linear&quot;,
      optimizer=optimizer,
      num_warmup_steps=0,
      num_training_steps=num_training_steps
  )

  progress_bar = tqdm(range(num_training_steps))

  model.train()
  for epoch in range(num_epochs):
      for batch in train_dataloader:
<span class="hljs-deletion">-         batch = {k: v.to(device) for k, v in batch.items()}</span>
          outputs = model(**batch)
          loss = outputs.loss
<span class="hljs-deletion">-         loss.backward()</span>
<span class="hljs-addition">+         accelerator.backward(loss)</span>

          optimizer.step()
          lr_scheduler.step()
          optimizer.zero_grad()
          progress_bar.update(1)`}}),ie=new $o({props:{$$slots:{default:[Po]},$$scope:{ctx:Je}}}),Ge=new q({props:{code:`





`,highlighted:`<span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> Accelerator
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW, AutoModelForSequenceClassification, get_scheduler

accelerator = Accelerator()

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=<span class="hljs-number">2</span>)
optimizer = AdamW(model.parameters(), lr=<span class="hljs-number">3e-5</span>)

train_dl, eval_dl, model, optimizer = accelerator.prepare(
    train_dataloader, eval_dataloader, model, optimizer
)

num_epochs = <span class="hljs-number">3</span>
num_training_steps = num_epochs * <span class="hljs-built_in">len</span>(train_dl)
lr_scheduler = get_scheduler(
    <span class="hljs-string">&quot;linear&quot;</span>,
    optimizer=optimizer,
    num_warmup_steps=<span class="hljs-number">0</span>,
    num_training_steps=num_training_steps,
)

progress_bar = tqdm(<span class="hljs-built_in">range</span>(num_training_steps))

model.train()
<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_dl:
        outputs = model(**batch)
        loss = outputs.loss
        accelerator.backward(loss)

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(<span class="hljs-number">1</span>)`}}),Ve=new q({props:{code:"accelerate config",highlighted:"accelerate config"}}),He=new q({props:{code:"accelerate launch train.py",highlighted:'accelerate <span class="hljs-built_in">launch</span> train.py'}}),Re=new q({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> accelerate <span class="hljs-keyword">import</span> notebook_launcher

notebook_launcher(training_function)`}}),{c(){$=l("meta"),y=p(),E=l("h1"),w=l("a"),j=l("span"),d(k.$$.fragment),he=p(),V=l("span"),H=a("Un entra\xEEnement complet"),C=p(),d(M.$$.fragment),ve=p(),d(_e.$$.fragment),mt=p(),K=l("p"),Aa=a("Maintenant nous allons voir comment obtenir les m\xEAmes r\xE9sultats que dans la derni\xE8re section sans utiliser la classe "),ds=l("code"),Ca=a("Trainer"),Da=a(". Encore une fois, nous supposons que vous avez fait le traitement des donn\xE9es dans la section 2. Voici un court r\xE9sum\xE9 couvrant tout ce dont vous aurez besoin :"),ft=p(),d(be.$$.fragment),ht=p(),R=l("h3"),X=l("a"),ms=l("span"),d($e.$$.fragment),Sa=p(),fs=l("span"),Ma=a("Pr\xE9parer l'entra\xEEnement"),vt=p(),D=l("p"),Oa=a("Avant d\u2019\xE9crire r\xE9ellement notre boucle d\u2019entra\xEEnement, nous devons d\xE9finir quelques objets. Les premiers sont les "),hs=l("em"),Ta=a("dataloaders"),La=a(" que nous utiliserons pour it\xE9rer sur les batchs. Mais avant de pouvoir d\xE9finir ces chargeurs de donn\xE9es, nous devons appliquer un peu de post-traitement \xE0 nos "),vs=l("code"),Na=a("tokenized_datasets"),Ua=a(", pour prendre soin de certaines choses que le "),_s=l("code"),Wa=a("Trainer"),Ia=a(" fait pour nous automatiquement. Sp\xE9cifiquement, nous devons :"),_t=p(),O=l("ul"),B=l("li"),Fa=a("supprimer les colonnes correspondant aux valeurs que le mod\xE8le n\u2019attend pas (comme les colonnes "),bs=l("code"),Ga=a("sentence1"),Va=a(" et "),$s=l("code"),Ha=a("sentence2"),Ra=a("),"),Ba=p(),S=l("li"),Ja=a("renommer la colonne "),qs=l("code"),Ya=a("label"),Qa=a(" en "),js=l("code"),Ka=a("labels"),Xa=a(" (parce que le mod\xE8le s\u2019attend \xE0 ce que l\u2019argument soit nomm\xE9 "),ks=l("code"),Za=a("labels"),en=a("),"),sn=p(),Es=l("li"),tn=a("d\xE9finir le format des jeux de donn\xE9es pour qu\u2019ils retournent des tenseurs PyTorch au lieu de listes."),bt=p(),Z=l("p"),an=a("Notre "),gs=l("code"),nn=a("tokenized_datasets"),rn=a(" a une m\xE9thode pour chacune de ces \xE9tapes :"),$t=p(),d(qe.$$.fragment),qt=p(),Ye=l("p"),ln=a("Nous pouvons alors v\xE9rifier que le r\xE9sultat ne comporte que des colonnes que notre mod\xE8le acceptera :"),jt=p(),d(je.$$.fragment),kt=p(),ee=l("p"),on=a("Maintenant que cela est fait, nous pouvons facilement d\xE9finir nos "),ws=l("em"),un=a("dataloaders"),pn=a(" :"),Et=p(),d(ke.$$.fragment),gt=p(),Qe=l("p"),cn=a("Pour v\xE9rifier rapidement qu\u2019il n\u2019y a pas d\u2019erreur dans le traitement des donn\xE9es, nous pouvons inspecter un batch comme celui-ci :"),wt=p(),d(Ee.$$.fragment),yt=p(),d(ge.$$.fragment),zt=p(),T=l("p"),dn=a("Notez que les formes r\xE9elles seront probablement l\xE9g\xE8rement diff\xE9rentes pour vous puisque nous avons d\xE9fini "),ys=l("code"),mn=a("shuffle=True"),fn=a(" pour le chargeur de donn\xE9es d\u2019entra\xEEnement et que nous "),zs=l("em"),hn=a("paddons"),vn=a(" \xE0 la longueur maximale dans le batch."),Pt=p(),Ke=l("p"),_n=a("Maintenant que nous en avons termin\xE9 avec le pr\xE9traitement des donn\xE9es (un objectif satisfaisant mais difficile \xE0 atteindre pour tout praticien d\u2019apprentissage automatique), passons au mod\xE8le. Nous l\u2019instancions exactement comme nous l\u2019avons fait dans la section pr\xE9c\xE9dente :"),xt=p(),d(we.$$.fragment),At=p(),Xe=l("p"),bn=a("Pour s\u2019assurer que tout se passera bien pendant l\u2019entra\xEEnement, nous transmettons notre batch \xE0 ce mod\xE8le :"),Ct=p(),d(ye.$$.fragment),Dt=p(),d(ze.$$.fragment),St=p(),L=l("p"),$n=a("Tous les mod\xE8les \u{1F917} "),Ps=l("em"),qn=a("Transformers"),jn=a(" renvoient la perte lorsque les "),xs=l("code"),kn=a("labels"),En=a(" sont fournis. Nous obtenons \xE9galement les logits (deux pour chaque entr\xE9e de notre batch, donc un tenseur de taille 8 x 2)."),Mt=p(),z=l("p"),gn=a("Nous sommes presque pr\xEAts \xE0 \xE9crire notre boucle d\u2019entra\xEEnement ! Il nous manque juste deux choses : un optimiseur et un planificateur de taux d\u2019apprentissage. Puisque nous essayons de reproduire \xE0 la main ce que fait la fonction "),As=l("code"),wn=a("Trainer"),yn=a(", utilisons les m\xEAmes param\xE8tres par d\xE9faut. L\u2019optimiseur utilis\xE9 par "),Cs=l("code"),zn=a("Trainer"),Pn=a(" est "),Ds=l("code"),xn=a("AdamW"),An=a(", qui est le m\xEAme qu\u2019Adam, mais avec une torsion pour la r\xE9gularisation par d\xE9croissance de poids (voir "),Pe=l("a"),Ss=l("em"),Cn=a("Decoupled Weight Decay Regularization"),Dn=a(" par Ilya Loshchilov et Frank Hutter) :"),Ot=p(),d(xe.$$.fragment),Tt=p(),N=l("p"),Sn=a("Enfin, le planificateur du taux d\u2019apprentissage utilis\xE9 par d\xE9faut est juste une d\xE9croissance lin\xE9aire de la valeur maximale (5e-5) \xE0 0. Pour le d\xE9finir correctement, nous devons conna\xEEtre le nombre d\u2019\xE9tapes d\u2019entra\xEEnement que nous prendrons, qui est le nombre d\u2019\xE9poques que nous voulons ex\xE9cuter multipli\xE9 par le nombre de batch d\u2019entra\xEEnement (qui est la longueur de notre "),Ms=l("em"),Mn=a("dataloader"),On=a(" d\u2019entra\xEEnement). Le "),Os=l("code"),Tn=a("Trainer"),Ln=a(" utilise trois \xE9poques par d\xE9faut, nous allons donc suivre \xE7a :"),Lt=p(),d(Ae.$$.fragment),Nt=p(),d(Ce.$$.fragment),Ut=p(),J=l("h3"),se=l("a"),Ts=l("span"),d(De.$$.fragment),Nn=p(),Ls=l("span"),Un=a("La boucle d'entra\xEEnement"),Wt=p(),te=l("p"),Wn=a("Une derni\xE8re chose : nous voulons utiliser le GPU si nous en avons un (sur un CPU, l\u2019entra\xEEnement peut prendre plusieurs heures au lieu de quelques minutes). Pour ce faire, nous d\xE9finissons un "),Ns=l("code"),In=a("device"),Fn=a(" sur lequel nous allons placer notre mod\xE8le et nos batchs :"),It=p(),d(Se.$$.fragment),Ft=p(),d(Me.$$.fragment),Gt=p(),ae=l("p"),Gn=a("Nous sommes maintenant pr\xEAts \xE0 entra\xEEner ! Pour avoir une id\xE9e du moment o\xF9 l\u2019entra\xEEnement sera termin\xE9, nous ajoutons une barre de progression sur le nombre d\u2019\xE9tapes d\u2019entra\xEEnement, en utilisant la biblioth\xE8que "),Us=l("code"),Vn=a("tqdm"),Hn=a(" :"),Vt=p(),d(Oe.$$.fragment),Ht=p(),Ze=l("p"),Rn=a("Vous pouvez voir que le c\u0153ur de la boucle d\u2019entra\xEEnement ressemble beaucoup \xE0 celui de l\u2019introduction. Nous n\u2019avons pas demand\xE9 de rapport, donc cette boucle d\u2019entra\xEEnement ne nous dira rien sur les r\xE9sultats du mod\xE8le. Pour cela, nous devons ajouter une boucle d\u2019\xE9valuation."),Rt=p(),Y=l("h3"),ne=l("a"),Ws=l("span"),d(Te.$$.fragment),Bn=p(),Is=l("span"),Jn=a("La boucle d'\xE9valuation"),Bt=p(),P=l("p"),Yn=a("Comme nous l\u2019avons fait pr\xE9c\xE9demment, nous allons utiliser une m\xE9trique fournie par la biblioth\xE8que \u{1F917} "),Fs=l("em"),Qn=a("Datasets"),Kn=a(". Nous avons d\xE9j\xE0 vu la m\xE9thode "),Gs=l("code"),Xn=a("metric.compute()"),Zn=a(", mais les m\xE9triques peuvent en fait accumuler des batchs pour nous au fur et \xE0 mesure que nous parcourons la boucle de pr\xE9diction avec la m\xE9thode "),Vs=l("code"),er=a("add_batch()"),sr=a(". Une fois que nous avons accumul\xE9 tous les batchs, nous pouvons obtenir le r\xE9sultat final avec "),Hs=l("code"),tr=a("metric.compute()"),ar=a(". Voici comment impl\xE9menter tout cela dans une boucle d\u2019\xE9valuation :"),Jt=p(),d(Le.$$.fragment),Yt=p(),d(Ne.$$.fragment),Qt=p(),es=l("p"),nr=a("Une fois encore, vos r\xE9sultats seront l\xE9g\xE8rement diff\xE9rents en raison du caract\xE8re al\xE9atoire de l\u2019initialisation de la t\xEAte du mod\xE8le et du m\xE9lange des donn\xE9es, mais ils devraient se situer dans la m\xEAme fourchette."),Kt=p(),d(re.$$.fragment),Xt=p(),Q=l("h3"),le=l("a"),Rs=l("span"),d(Ue.$$.fragment),rr=p(),ss=l("span"),lr=a("Optimisez votre boucle d'entra\xEEnement avec \u{1F917} "),Bs=l("i"),or=a("Accelerate"),Zt=p(),d(We.$$.fragment),ea=p(),U=l("p"),ir=a("La boucle d\u2019entra\xEEnement que nous avons d\xE9finie pr\xE9c\xE9demment fonctionne bien sur un seul CPU ou GPU. Mais en utilisant la biblioth\xE8que "),oe=l("a"),ur=a("\u{1F917} "),Js=l("em"),pr=a("Accelerate"),cr=a(", il suffit de quelques ajustements pour permettre un entra\xEEnement distribu\xE9 sur plusieurs GPUs ou TPUs. En partant de la cr\xE9ation des "),Ys=l("em"),dr=a("dataloaders"),mr=a(" d\u2019entra\xEEnement et de validation, voici \xE0 quoi ressemble notre boucle d\u2019entra\xEEnement manuel :"),sa=p(),d(Ie.$$.fragment),ta=p(),ts=l("p"),fr=a("Et voici les changements :"),aa=p(),d(Fe.$$.fragment),na=p(),x=l("p"),hr=a("La premi\xE8re ligne \xE0 ajouter est la ligne d\u2019importation. La deuxi\xE8me ligne instancie un objet "),Qs=l("code"),vr=a("Accelerator"),_r=a(" qui va regarder l\u2019environnement et initialiser la bonne configuration distribu\xE9e. \u{1F917} "),Ks=l("em"),br=a("Accelerate"),$r=a(" g\xE8re le placement des p\xE9riph\xE9riques pour vous, donc vous pouvez enlever les lignes qui placent le mod\xE8le sur le p\xE9riph\xE9rique (ou, si vous pr\xE9f\xE9rez, les changer pour utiliser "),Xs=l("code"),qr=a("accelerator.device"),jr=a(" au lieu de "),Zs=l("code"),kr=a("device"),Er=a(")."),ra=p(),g=l("p"),gr=a("Ensuite, le gros du travail est fait dans la ligne qui envoie les "),et=l("em"),wr=a("dataloaders"),yr=a(", le mod\xE8le, et l\u2019optimiseur \xE0 "),st=l("code"),zr=a("accelerator.prepare()"),Pr=a(". Cela va envelopper ces objets dans le conteneur appropri\xE9 pour s\u2019assurer que votre entra\xEEnement distribu\xE9 fonctionne comme pr\xE9vu. Les changements restants \xE0 faire sont la suppression de la ligne qui met le batch sur le "),tt=l("code"),xr=a("device"),Ar=a(" (encore une fois, si vous voulez le garder, vous pouvez juste le changer pour utiliser "),at=l("code"),Cr=a("accelerator.device"),Dr=a(") et le remplacement de "),nt=l("code"),Sr=a("loss.backward()"),Mr=a(" par "),rt=l("code"),Or=a("accelerator.backward(loss)"),Tr=a("."),la=p(),d(ie.$$.fragment),oa=p(),ue=l("p"),Lr=a("Si vous souhaitez faire un copier-coller pour jouer, voici \xE0 quoi ressemble la boucle d\u2019entra\xEEnement compl\xE8te avec \u{1F917} "),lt=l("i"),Nr=a("Accelerate"),Ur=a(" :"),ia=p(),d(Ge.$$.fragment),ua=p(),pe=l("p"),Wr=a("En pla\xE7ant ceci dans un script "),ot=l("code"),Ir=a("train.py"),Fr=a(", cela sera ex\xE9cutable sur n\u2019importe quel type d\u2019installation distribu\xE9e. Pour l\u2019essayer dans votre installation distribu\xE9e, ex\xE9cutez la commande :"),pa=p(),d(Ve.$$.fragment),ca=p(),as=l("p"),Gr=a("qui vous demandera de r\xE9pondre \xE0 quelques questions et enregistrera vos r\xE9ponses dans un fichier de configuration utilis\xE9 par cette commande :"),da=p(),d(He.$$.fragment),ma=p(),ns=l("p"),Vr=a("qui lancera l\u2019entra\xEEnement distribu\xE9."),fa=p(),W=l("p"),Hr=a("Si vous voulez essayer ceci dans un "),it=l("em"),Rr=a("notebook"),Br=a(" (par exemple, pour le tester avec des TPUs sur Colab), collez simplement le code dans une "),ut=l("code"),Jr=a("training_function()"),Yr=a(" et lancez une derni\xE8re cellule avec :"),ha=p(),d(Re.$$.fragment),va=p(),ce=l("p"),Qr=a("Vous trouverez d\u2019autres exemples dans le d\xE9p\xF4t d\u2019"),de=l("a"),Kr=a("\u{1F917} "),pt=l("em"),Xr=a("Accelerate"),Zr=a("."),this.h()},l(e){const r=go('[data-svelte="svelte-1phssyn"]',document.head);$=o(r,"META",{name:!0,content:!0}),r.forEach(t),y=c(e),E=o(e,"H1",{class:!0});var Be=i(E);w=o(Be,"A",{id:!0,class:!0,href:!0});var ct=i(w);j=o(ct,"SPAN",{});var al=i(j);m(k.$$.fragment,al),al.forEach(t),ct.forEach(t),he=c(Be),V=o(Be,"SPAN",{});var nl=i(V);H=n(nl,"Un entra\xEEnement complet"),nl.forEach(t),Be.forEach(t),C=c(e),m(M.$$.fragment,e),ve=c(e),m(_e.$$.fragment,e),mt=c(e),K=o(e,"P",{});var ba=i(K);Aa=n(ba,"Maintenant nous allons voir comment obtenir les m\xEAmes r\xE9sultats que dans la derni\xE8re section sans utiliser la classe "),ds=o(ba,"CODE",{});var rl=i(ds);Ca=n(rl,"Trainer"),rl.forEach(t),Da=n(ba,". Encore une fois, nous supposons que vous avez fait le traitement des donn\xE9es dans la section 2. Voici un court r\xE9sum\xE9 couvrant tout ce dont vous aurez besoin :"),ba.forEach(t),ft=c(e),m(be.$$.fragment,e),ht=c(e),R=o(e,"H3",{class:!0});var $a=i(R);X=o($a,"A",{id:!0,class:!0,href:!0});var ll=i(X);ms=o(ll,"SPAN",{});var ol=i(ms);m($e.$$.fragment,ol),ol.forEach(t),ll.forEach(t),Sa=c($a),fs=o($a,"SPAN",{});var il=i(fs);Ma=n(il,"Pr\xE9parer l'entra\xEEnement"),il.forEach(t),$a.forEach(t),vt=c(e),D=o(e,"P",{});var me=i(D);Oa=n(me,"Avant d\u2019\xE9crire r\xE9ellement notre boucle d\u2019entra\xEEnement, nous devons d\xE9finir quelques objets. Les premiers sont les "),hs=o(me,"EM",{});var ul=i(hs);Ta=n(ul,"dataloaders"),ul.forEach(t),La=n(me," que nous utiliserons pour it\xE9rer sur les batchs. Mais avant de pouvoir d\xE9finir ces chargeurs de donn\xE9es, nous devons appliquer un peu de post-traitement \xE0 nos "),vs=o(me,"CODE",{});var pl=i(vs);Na=n(pl,"tokenized_datasets"),pl.forEach(t),Ua=n(me,", pour prendre soin de certaines choses que le "),_s=o(me,"CODE",{});var cl=i(_s);Wa=n(cl,"Trainer"),cl.forEach(t),Ia=n(me," fait pour nous automatiquement. Sp\xE9cifiquement, nous devons :"),me.forEach(t),_t=c(e),O=o(e,"UL",{});var rs=i(O);B=o(rs,"LI",{});var ls=i(B);Fa=n(ls,"supprimer les colonnes correspondant aux valeurs que le mod\xE8le n\u2019attend pas (comme les colonnes "),bs=o(ls,"CODE",{});var dl=i(bs);Ga=n(dl,"sentence1"),dl.forEach(t),Va=n(ls," et "),$s=o(ls,"CODE",{});var ml=i($s);Ha=n(ml,"sentence2"),ml.forEach(t),Ra=n(ls,"),"),ls.forEach(t),Ba=c(rs),S=o(rs,"LI",{});var fe=i(S);Ja=n(fe,"renommer la colonne "),qs=o(fe,"CODE",{});var fl=i(qs);Ya=n(fl,"label"),fl.forEach(t),Qa=n(fe," en "),js=o(fe,"CODE",{});var hl=i(js);Ka=n(hl,"labels"),hl.forEach(t),Xa=n(fe," (parce que le mod\xE8le s\u2019attend \xE0 ce que l\u2019argument soit nomm\xE9 "),ks=o(fe,"CODE",{});var vl=i(ks);Za=n(vl,"labels"),vl.forEach(t),en=n(fe,"),"),fe.forEach(t),sn=c(rs),Es=o(rs,"LI",{});var _l=i(Es);tn=n(_l,"d\xE9finir le format des jeux de donn\xE9es pour qu\u2019ils retournent des tenseurs PyTorch au lieu de listes."),_l.forEach(t),rs.forEach(t),bt=c(e),Z=o(e,"P",{});var qa=i(Z);an=n(qa,"Notre "),gs=o(qa,"CODE",{});var bl=i(gs);nn=n(bl,"tokenized_datasets"),bl.forEach(t),rn=n(qa," a une m\xE9thode pour chacune de ces \xE9tapes :"),qa.forEach(t),$t=c(e),m(qe.$$.fragment,e),qt=c(e),Ye=o(e,"P",{});var $l=i(Ye);ln=n($l,"Nous pouvons alors v\xE9rifier que le r\xE9sultat ne comporte que des colonnes que notre mod\xE8le acceptera :"),$l.forEach(t),jt=c(e),m(je.$$.fragment,e),kt=c(e),ee=o(e,"P",{});var ja=i(ee);on=n(ja,"Maintenant que cela est fait, nous pouvons facilement d\xE9finir nos "),ws=o(ja,"EM",{});var ql=i(ws);un=n(ql,"dataloaders"),ql.forEach(t),pn=n(ja," :"),ja.forEach(t),Et=c(e),m(ke.$$.fragment,e),gt=c(e),Qe=o(e,"P",{});var jl=i(Qe);cn=n(jl,"Pour v\xE9rifier rapidement qu\u2019il n\u2019y a pas d\u2019erreur dans le traitement des donn\xE9es, nous pouvons inspecter un batch comme celui-ci :"),jl.forEach(t),wt=c(e),m(Ee.$$.fragment,e),yt=c(e),m(ge.$$.fragment,e),zt=c(e),T=o(e,"P",{});var os=i(T);dn=n(os,"Notez que les formes r\xE9elles seront probablement l\xE9g\xE8rement diff\xE9rentes pour vous puisque nous avons d\xE9fini "),ys=o(os,"CODE",{});var kl=i(ys);mn=n(kl,"shuffle=True"),kl.forEach(t),fn=n(os," pour le chargeur de donn\xE9es d\u2019entra\xEEnement et que nous "),zs=o(os,"EM",{});var El=i(zs);hn=n(El,"paddons"),El.forEach(t),vn=n(os," \xE0 la longueur maximale dans le batch."),os.forEach(t),Pt=c(e),Ke=o(e,"P",{});var gl=i(Ke);_n=n(gl,"Maintenant que nous en avons termin\xE9 avec le pr\xE9traitement des donn\xE9es (un objectif satisfaisant mais difficile \xE0 atteindre pour tout praticien d\u2019apprentissage automatique), passons au mod\xE8le. Nous l\u2019instancions exactement comme nous l\u2019avons fait dans la section pr\xE9c\xE9dente :"),gl.forEach(t),xt=c(e),m(we.$$.fragment,e),At=c(e),Xe=o(e,"P",{});var wl=i(Xe);bn=n(wl,"Pour s\u2019assurer que tout se passera bien pendant l\u2019entra\xEEnement, nous transmettons notre batch \xE0 ce mod\xE8le :"),wl.forEach(t),Ct=c(e),m(ye.$$.fragment,e),Dt=c(e),m(ze.$$.fragment,e),St=c(e),L=o(e,"P",{});var is=i(L);$n=n(is,"Tous les mod\xE8les \u{1F917} "),Ps=o(is,"EM",{});var yl=i(Ps);qn=n(yl,"Transformers"),yl.forEach(t),jn=n(is," renvoient la perte lorsque les "),xs=o(is,"CODE",{});var zl=i(xs);kn=n(zl,"labels"),zl.forEach(t),En=n(is," sont fournis. Nous obtenons \xE9galement les logits (deux pour chaque entr\xE9e de notre batch, donc un tenseur de taille 8 x 2)."),is.forEach(t),Mt=c(e),z=o(e,"P",{});var I=i(z);gn=n(I,"Nous sommes presque pr\xEAts \xE0 \xE9crire notre boucle d\u2019entra\xEEnement ! Il nous manque juste deux choses : un optimiseur et un planificateur de taux d\u2019apprentissage. Puisque nous essayons de reproduire \xE0 la main ce que fait la fonction "),As=o(I,"CODE",{});var Pl=i(As);wn=n(Pl,"Trainer"),Pl.forEach(t),yn=n(I,", utilisons les m\xEAmes param\xE8tres par d\xE9faut. L\u2019optimiseur utilis\xE9 par "),Cs=o(I,"CODE",{});var xl=i(Cs);zn=n(xl,"Trainer"),xl.forEach(t),Pn=n(I," est "),Ds=o(I,"CODE",{});var Al=i(Ds);xn=n(Al,"AdamW"),Al.forEach(t),An=n(I,", qui est le m\xEAme qu\u2019Adam, mais avec une torsion pour la r\xE9gularisation par d\xE9croissance de poids (voir "),Pe=o(I,"A",{href:!0,rel:!0});var Cl=i(Pe);Ss=o(Cl,"EM",{});var Dl=i(Ss);Cn=n(Dl,"Decoupled Weight Decay Regularization"),Dl.forEach(t),Cl.forEach(t),Dn=n(I," par Ilya Loshchilov et Frank Hutter) :"),I.forEach(t),Ot=c(e),m(xe.$$.fragment,e),Tt=c(e),N=o(e,"P",{});var us=i(N);Sn=n(us,"Enfin, le planificateur du taux d\u2019apprentissage utilis\xE9 par d\xE9faut est juste une d\xE9croissance lin\xE9aire de la valeur maximale (5e-5) \xE0 0. Pour le d\xE9finir correctement, nous devons conna\xEEtre le nombre d\u2019\xE9tapes d\u2019entra\xEEnement que nous prendrons, qui est le nombre d\u2019\xE9poques que nous voulons ex\xE9cuter multipli\xE9 par le nombre de batch d\u2019entra\xEEnement (qui est la longueur de notre "),Ms=o(us,"EM",{});var Sl=i(Ms);Mn=n(Sl,"dataloader"),Sl.forEach(t),On=n(us," d\u2019entra\xEEnement). Le "),Os=o(us,"CODE",{});var Ml=i(Os);Tn=n(Ml,"Trainer"),Ml.forEach(t),Ln=n(us," utilise trois \xE9poques par d\xE9faut, nous allons donc suivre \xE7a :"),us.forEach(t),Lt=c(e),m(Ae.$$.fragment,e),Nt=c(e),m(Ce.$$.fragment,e),Ut=c(e),J=o(e,"H3",{class:!0});var ka=i(J);se=o(ka,"A",{id:!0,class:!0,href:!0});var Ol=i(se);Ts=o(Ol,"SPAN",{});var Tl=i(Ts);m(De.$$.fragment,Tl),Tl.forEach(t),Ol.forEach(t),Nn=c(ka),Ls=o(ka,"SPAN",{});var Ll=i(Ls);Un=n(Ll,"La boucle d'entra\xEEnement"),Ll.forEach(t),ka.forEach(t),Wt=c(e),te=o(e,"P",{});var Ea=i(te);Wn=n(Ea,"Une derni\xE8re chose : nous voulons utiliser le GPU si nous en avons un (sur un CPU, l\u2019entra\xEEnement peut prendre plusieurs heures au lieu de quelques minutes). Pour ce faire, nous d\xE9finissons un "),Ns=o(Ea,"CODE",{});var Nl=i(Ns);In=n(Nl,"device"),Nl.forEach(t),Fn=n(Ea," sur lequel nous allons placer notre mod\xE8le et nos batchs :"),Ea.forEach(t),It=c(e),m(Se.$$.fragment,e),Ft=c(e),m(Me.$$.fragment,e),Gt=c(e),ae=o(e,"P",{});var ga=i(ae);Gn=n(ga,"Nous sommes maintenant pr\xEAts \xE0 entra\xEEner ! Pour avoir une id\xE9e du moment o\xF9 l\u2019entra\xEEnement sera termin\xE9, nous ajoutons une barre de progression sur le nombre d\u2019\xE9tapes d\u2019entra\xEEnement, en utilisant la biblioth\xE8que "),Us=o(ga,"CODE",{});var Ul=i(Us);Vn=n(Ul,"tqdm"),Ul.forEach(t),Hn=n(ga," :"),ga.forEach(t),Vt=c(e),m(Oe.$$.fragment,e),Ht=c(e),Ze=o(e,"P",{});var Wl=i(Ze);Rn=n(Wl,"Vous pouvez voir que le c\u0153ur de la boucle d\u2019entra\xEEnement ressemble beaucoup \xE0 celui de l\u2019introduction. Nous n\u2019avons pas demand\xE9 de rapport, donc cette boucle d\u2019entra\xEEnement ne nous dira rien sur les r\xE9sultats du mod\xE8le. Pour cela, nous devons ajouter une boucle d\u2019\xE9valuation."),Wl.forEach(t),Rt=c(e),Y=o(e,"H3",{class:!0});var wa=i(Y);ne=o(wa,"A",{id:!0,class:!0,href:!0});var Il=i(ne);Ws=o(Il,"SPAN",{});var Fl=i(Ws);m(Te.$$.fragment,Fl),Fl.forEach(t),Il.forEach(t),Bn=c(wa),Is=o(wa,"SPAN",{});var Gl=i(Is);Jn=n(Gl,"La boucle d'\xE9valuation"),Gl.forEach(t),wa.forEach(t),Bt=c(e),P=o(e,"P",{});var F=i(P);Yn=n(F,"Comme nous l\u2019avons fait pr\xE9c\xE9demment, nous allons utiliser une m\xE9trique fournie par la biblioth\xE8que \u{1F917} "),Fs=o(F,"EM",{});var Vl=i(Fs);Qn=n(Vl,"Datasets"),Vl.forEach(t),Kn=n(F,". Nous avons d\xE9j\xE0 vu la m\xE9thode "),Gs=o(F,"CODE",{});var Hl=i(Gs);Xn=n(Hl,"metric.compute()"),Hl.forEach(t),Zn=n(F,", mais les m\xE9triques peuvent en fait accumuler des batchs pour nous au fur et \xE0 mesure que nous parcourons la boucle de pr\xE9diction avec la m\xE9thode "),Vs=o(F,"CODE",{});var Rl=i(Vs);er=n(Rl,"add_batch()"),Rl.forEach(t),sr=n(F,". Une fois que nous avons accumul\xE9 tous les batchs, nous pouvons obtenir le r\xE9sultat final avec "),Hs=o(F,"CODE",{});var Bl=i(Hs);tr=n(Bl,"metric.compute()"),Bl.forEach(t),ar=n(F,". Voici comment impl\xE9menter tout cela dans une boucle d\u2019\xE9valuation :"),F.forEach(t),Jt=c(e),m(Le.$$.fragment,e),Yt=c(e),m(Ne.$$.fragment,e),Qt=c(e),es=o(e,"P",{});var Jl=i(es);nr=n(Jl,"Une fois encore, vos r\xE9sultats seront l\xE9g\xE8rement diff\xE9rents en raison du caract\xE8re al\xE9atoire de l\u2019initialisation de la t\xEAte du mod\xE8le et du m\xE9lange des donn\xE9es, mais ils devraient se situer dans la m\xEAme fourchette."),Jl.forEach(t),Kt=c(e),m(re.$$.fragment,e),Xt=c(e),Q=o(e,"H3",{class:!0});var ya=i(Q);le=o(ya,"A",{id:!0,class:!0,href:!0});var Yl=i(le);Rs=o(Yl,"SPAN",{});var Ql=i(Rs);m(Ue.$$.fragment,Ql),Ql.forEach(t),Yl.forEach(t),rr=c(ya),ss=o(ya,"SPAN",{});var el=i(ss);lr=n(el,"Optimisez votre boucle d'entra\xEEnement avec \u{1F917} "),Bs=o(el,"I",{});var Kl=i(Bs);or=n(Kl,"Accelerate"),Kl.forEach(t),el.forEach(t),ya.forEach(t),Zt=c(e),m(We.$$.fragment,e),ea=c(e),U=o(e,"P",{});var ps=i(U);ir=n(ps,"La boucle d\u2019entra\xEEnement que nous avons d\xE9finie pr\xE9c\xE9demment fonctionne bien sur un seul CPU ou GPU. Mais en utilisant la biblioth\xE8que "),oe=o(ps,"A",{href:!0,rel:!0});var sl=i(oe);ur=n(sl,"\u{1F917} "),Js=o(sl,"EM",{});var Xl=i(Js);pr=n(Xl,"Accelerate"),Xl.forEach(t),sl.forEach(t),cr=n(ps,", il suffit de quelques ajustements pour permettre un entra\xEEnement distribu\xE9 sur plusieurs GPUs ou TPUs. En partant de la cr\xE9ation des "),Ys=o(ps,"EM",{});var Zl=i(Ys);dr=n(Zl,"dataloaders"),Zl.forEach(t),mr=n(ps," d\u2019entra\xEEnement et de validation, voici \xE0 quoi ressemble notre boucle d\u2019entra\xEEnement manuel :"),ps.forEach(t),sa=c(e),m(Ie.$$.fragment,e),ta=c(e),ts=o(e,"P",{});var eo=i(ts);fr=n(eo,"Et voici les changements :"),eo.forEach(t),aa=c(e),m(Fe.$$.fragment,e),na=c(e),x=o(e,"P",{});var G=i(x);hr=n(G,"La premi\xE8re ligne \xE0 ajouter est la ligne d\u2019importation. La deuxi\xE8me ligne instancie un objet "),Qs=o(G,"CODE",{});var so=i(Qs);vr=n(so,"Accelerator"),so.forEach(t),_r=n(G," qui va regarder l\u2019environnement et initialiser la bonne configuration distribu\xE9e. \u{1F917} "),Ks=o(G,"EM",{});var to=i(Ks);br=n(to,"Accelerate"),to.forEach(t),$r=n(G," g\xE8re le placement des p\xE9riph\xE9riques pour vous, donc vous pouvez enlever les lignes qui placent le mod\xE8le sur le p\xE9riph\xE9rique (ou, si vous pr\xE9f\xE9rez, les changer pour utiliser "),Xs=o(G,"CODE",{});var ao=i(Xs);qr=n(ao,"accelerator.device"),ao.forEach(t),jr=n(G," au lieu de "),Zs=o(G,"CODE",{});var no=i(Zs);kr=n(no,"device"),no.forEach(t),Er=n(G,")."),G.forEach(t),ra=c(e),g=o(e,"P",{});var A=i(g);gr=n(A,"Ensuite, le gros du travail est fait dans la ligne qui envoie les "),et=o(A,"EM",{});var ro=i(et);wr=n(ro,"dataloaders"),ro.forEach(t),yr=n(A,", le mod\xE8le, et l\u2019optimiseur \xE0 "),st=o(A,"CODE",{});var lo=i(st);zr=n(lo,"accelerator.prepare()"),lo.forEach(t),Pr=n(A,". Cela va envelopper ces objets dans le conteneur appropri\xE9 pour s\u2019assurer que votre entra\xEEnement distribu\xE9 fonctionne comme pr\xE9vu. Les changements restants \xE0 faire sont la suppression de la ligne qui met le batch sur le "),tt=o(A,"CODE",{});var oo=i(tt);xr=n(oo,"device"),oo.forEach(t),Ar=n(A," (encore une fois, si vous voulez le garder, vous pouvez juste le changer pour utiliser "),at=o(A,"CODE",{});var io=i(at);Cr=n(io,"accelerator.device"),io.forEach(t),Dr=n(A,") et le remplacement de "),nt=o(A,"CODE",{});var uo=i(nt);Sr=n(uo,"loss.backward()"),uo.forEach(t),Mr=n(A," par "),rt=o(A,"CODE",{});var po=i(rt);Or=n(po,"accelerator.backward(loss)"),po.forEach(t),Tr=n(A,"."),A.forEach(t),la=c(e),m(ie.$$.fragment,e),oa=c(e),ue=o(e,"P",{});var za=i(ue);Lr=n(za,"Si vous souhaitez faire un copier-coller pour jouer, voici \xE0 quoi ressemble la boucle d\u2019entra\xEEnement compl\xE8te avec \u{1F917} "),lt=o(za,"I",{});var co=i(lt);Nr=n(co,"Accelerate"),co.forEach(t),Ur=n(za," :"),za.forEach(t),ia=c(e),m(Ge.$$.fragment,e),ua=c(e),pe=o(e,"P",{});var Pa=i(pe);Wr=n(Pa,"En pla\xE7ant ceci dans un script "),ot=o(Pa,"CODE",{});var mo=i(ot);Ir=n(mo,"train.py"),mo.forEach(t),Fr=n(Pa,", cela sera ex\xE9cutable sur n\u2019importe quel type d\u2019installation distribu\xE9e. Pour l\u2019essayer dans votre installation distribu\xE9e, ex\xE9cutez la commande :"),Pa.forEach(t),pa=c(e),m(Ve.$$.fragment,e),ca=c(e),as=o(e,"P",{});var fo=i(as);Gr=n(fo,"qui vous demandera de r\xE9pondre \xE0 quelques questions et enregistrera vos r\xE9ponses dans un fichier de configuration utilis\xE9 par cette commande :"),fo.forEach(t),da=c(e),m(He.$$.fragment,e),ma=c(e),ns=o(e,"P",{});var ho=i(ns);Vr=n(ho,"qui lancera l\u2019entra\xEEnement distribu\xE9."),ho.forEach(t),fa=c(e),W=o(e,"P",{});var cs=i(W);Hr=n(cs,"Si vous voulez essayer ceci dans un "),it=o(cs,"EM",{});var vo=i(it);Rr=n(vo,"notebook"),vo.forEach(t),Br=n(cs," (par exemple, pour le tester avec des TPUs sur Colab), collez simplement le code dans une "),ut=o(cs,"CODE",{});var _o=i(ut);Jr=n(_o,"training_function()"),_o.forEach(t),Yr=n(cs," et lancez une derni\xE8re cellule avec :"),cs.forEach(t),ha=c(e),m(Re.$$.fragment,e),va=c(e),ce=o(e,"P",{});var xa=i(ce);Qr=n(xa,"Vous trouverez d\u2019autres exemples dans le d\xE9p\xF4t d\u2019"),de=o(xa,"A",{href:!0,rel:!0});var tl=i(de);Kr=n(tl,"\u{1F917} "),pt=o(tl,"EM",{});var bo=i(pt);Xr=n(bo,"Accelerate"),bo.forEach(t),tl.forEach(t),Zr=n(xa,"."),xa.forEach(t),this.h()},h(){b($,"name","hf:doc:metadata"),b($,"content",JSON.stringify(Ao)),b(w,"id","un-entranement-complet"),b(w,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(w,"href","#un-entranement-complet"),b(E,"class","relative group"),b(X,"id","prparer-lentranement"),b(X,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(X,"href","#prparer-lentranement"),b(R,"class","relative group"),b(Pe,"href","https://arxiv.org/abs/1711.05101"),b(Pe,"rel","nofollow"),b(se,"id","la-boucle-dentranement"),b(se,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(se,"href","#la-boucle-dentranement"),b(J,"class","relative group"),b(ne,"id","la-boucle-dvaluation"),b(ne,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(ne,"href","#la-boucle-dvaluation"),b(Y,"class","relative group"),b(le,"id","optimisez-votre-boucle-dentranement-avec-iacceleratei"),b(le,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),b(le,"href","#optimisez-votre-boucle-dentranement-avec-iacceleratei"),b(Q,"class","relative group"),b(oe,"href","https://github.com/huggingface/accelerate"),b(oe,"rel","nofollow"),b(de,"href","https://github.com/huggingface/accelerate/tree/main/examples"),b(de,"rel","nofollow")},m(e,r){s(document.head,$),u(e,y,r),u(e,E,r),s(E,w),s(w,j),f(k,j,null),s(E,he),s(E,V),s(V,H),u(e,C,r),f(M,e,r),u(e,ve,r),f(_e,e,r),u(e,mt,r),u(e,K,r),s(K,Aa),s(K,ds),s(ds,Ca),s(K,Da),u(e,ft,r),f(be,e,r),u(e,ht,r),u(e,R,r),s(R,X),s(X,ms),f($e,ms,null),s(R,Sa),s(R,fs),s(fs,Ma),u(e,vt,r),u(e,D,r),s(D,Oa),s(D,hs),s(hs,Ta),s(D,La),s(D,vs),s(vs,Na),s(D,Ua),s(D,_s),s(_s,Wa),s(D,Ia),u(e,_t,r),u(e,O,r),s(O,B),s(B,Fa),s(B,bs),s(bs,Ga),s(B,Va),s(B,$s),s($s,Ha),s(B,Ra),s(O,Ba),s(O,S),s(S,Ja),s(S,qs),s(qs,Ya),s(S,Qa),s(S,js),s(js,Ka),s(S,Xa),s(S,ks),s(ks,Za),s(S,en),s(O,sn),s(O,Es),s(Es,tn),u(e,bt,r),u(e,Z,r),s(Z,an),s(Z,gs),s(gs,nn),s(Z,rn),u(e,$t,r),f(qe,e,r),u(e,qt,r),u(e,Ye,r),s(Ye,ln),u(e,jt,r),f(je,e,r),u(e,kt,r),u(e,ee,r),s(ee,on),s(ee,ws),s(ws,un),s(ee,pn),u(e,Et,r),f(ke,e,r),u(e,gt,r),u(e,Qe,r),s(Qe,cn),u(e,wt,r),f(Ee,e,r),u(e,yt,r),f(ge,e,r),u(e,zt,r),u(e,T,r),s(T,dn),s(T,ys),s(ys,mn),s(T,fn),s(T,zs),s(zs,hn),s(T,vn),u(e,Pt,r),u(e,Ke,r),s(Ke,_n),u(e,xt,r),f(we,e,r),u(e,At,r),u(e,Xe,r),s(Xe,bn),u(e,Ct,r),f(ye,e,r),u(e,Dt,r),f(ze,e,r),u(e,St,r),u(e,L,r),s(L,$n),s(L,Ps),s(Ps,qn),s(L,jn),s(L,xs),s(xs,kn),s(L,En),u(e,Mt,r),u(e,z,r),s(z,gn),s(z,As),s(As,wn),s(z,yn),s(z,Cs),s(Cs,zn),s(z,Pn),s(z,Ds),s(Ds,xn),s(z,An),s(z,Pe),s(Pe,Ss),s(Ss,Cn),s(z,Dn),u(e,Ot,r),f(xe,e,r),u(e,Tt,r),u(e,N,r),s(N,Sn),s(N,Ms),s(Ms,Mn),s(N,On),s(N,Os),s(Os,Tn),s(N,Ln),u(e,Lt,r),f(Ae,e,r),u(e,Nt,r),f(Ce,e,r),u(e,Ut,r),u(e,J,r),s(J,se),s(se,Ts),f(De,Ts,null),s(J,Nn),s(J,Ls),s(Ls,Un),u(e,Wt,r),u(e,te,r),s(te,Wn),s(te,Ns),s(Ns,In),s(te,Fn),u(e,It,r),f(Se,e,r),u(e,Ft,r),f(Me,e,r),u(e,Gt,r),u(e,ae,r),s(ae,Gn),s(ae,Us),s(Us,Vn),s(ae,Hn),u(e,Vt,r),f(Oe,e,r),u(e,Ht,r),u(e,Ze,r),s(Ze,Rn),u(e,Rt,r),u(e,Y,r),s(Y,ne),s(ne,Ws),f(Te,Ws,null),s(Y,Bn),s(Y,Is),s(Is,Jn),u(e,Bt,r),u(e,P,r),s(P,Yn),s(P,Fs),s(Fs,Qn),s(P,Kn),s(P,Gs),s(Gs,Xn),s(P,Zn),s(P,Vs),s(Vs,er),s(P,sr),s(P,Hs),s(Hs,tr),s(P,ar),u(e,Jt,r),f(Le,e,r),u(e,Yt,r),f(Ne,e,r),u(e,Qt,r),u(e,es,r),s(es,nr),u(e,Kt,r),f(re,e,r),u(e,Xt,r),u(e,Q,r),s(Q,le),s(le,Rs),f(Ue,Rs,null),s(Q,rr),s(Q,ss),s(ss,lr),s(ss,Bs),s(Bs,or),u(e,Zt,r),f(We,e,r),u(e,ea,r),u(e,U,r),s(U,ir),s(U,oe),s(oe,ur),s(oe,Js),s(Js,pr),s(U,cr),s(U,Ys),s(Ys,dr),s(U,mr),u(e,sa,r),f(Ie,e,r),u(e,ta,r),u(e,ts,r),s(ts,fr),u(e,aa,r),f(Fe,e,r),u(e,na,r),u(e,x,r),s(x,hr),s(x,Qs),s(Qs,vr),s(x,_r),s(x,Ks),s(Ks,br),s(x,$r),s(x,Xs),s(Xs,qr),s(x,jr),s(x,Zs),s(Zs,kr),s(x,Er),u(e,ra,r),u(e,g,r),s(g,gr),s(g,et),s(et,wr),s(g,yr),s(g,st),s(st,zr),s(g,Pr),s(g,tt),s(tt,xr),s(g,Ar),s(g,at),s(at,Cr),s(g,Dr),s(g,nt),s(nt,Sr),s(g,Mr),s(g,rt),s(rt,Or),s(g,Tr),u(e,la,r),f(ie,e,r),u(e,oa,r),u(e,ue,r),s(ue,Lr),s(ue,lt),s(lt,Nr),s(ue,Ur),u(e,ia,r),f(Ge,e,r),u(e,ua,r),u(e,pe,r),s(pe,Wr),s(pe,ot),s(ot,Ir),s(pe,Fr),u(e,pa,r),f(Ve,e,r),u(e,ca,r),u(e,as,r),s(as,Gr),u(e,da,r),f(He,e,r),u(e,ma,r),u(e,ns,r),s(ns,Vr),u(e,fa,r),u(e,W,r),s(W,Hr),s(W,it),s(it,Rr),s(W,Br),s(W,ut),s(ut,Jr),s(W,Yr),u(e,ha,r),f(Re,e,r),u(e,va,r),u(e,ce,r),s(ce,Qr),s(ce,de),s(de,Kr),s(de,pt),s(pt,Xr),s(ce,Zr),_a=!0},p(e,[r]){const Be={};r&2&&(Be.$$scope={dirty:r,ctx:e}),re.$set(Be);const ct={};r&2&&(ct.$$scope={dirty:r,ctx:e}),ie.$set(ct)},i(e){_a||(h(k.$$.fragment,e),h(M.$$.fragment,e),h(_e.$$.fragment,e),h(be.$$.fragment,e),h($e.$$.fragment,e),h(qe.$$.fragment,e),h(je.$$.fragment,e),h(ke.$$.fragment,e),h(Ee.$$.fragment,e),h(ge.$$.fragment,e),h(we.$$.fragment,e),h(ye.$$.fragment,e),h(ze.$$.fragment,e),h(xe.$$.fragment,e),h(Ae.$$.fragment,e),h(Ce.$$.fragment,e),h(De.$$.fragment,e),h(Se.$$.fragment,e),h(Me.$$.fragment,e),h(Oe.$$.fragment,e),h(Te.$$.fragment,e),h(Le.$$.fragment,e),h(Ne.$$.fragment,e),h(re.$$.fragment,e),h(Ue.$$.fragment,e),h(We.$$.fragment,e),h(Ie.$$.fragment,e),h(Fe.$$.fragment,e),h(ie.$$.fragment,e),h(Ge.$$.fragment,e),h(Ve.$$.fragment,e),h(He.$$.fragment,e),h(Re.$$.fragment,e),_a=!0)},o(e){v(k.$$.fragment,e),v(M.$$.fragment,e),v(_e.$$.fragment,e),v(be.$$.fragment,e),v($e.$$.fragment,e),v(qe.$$.fragment,e),v(je.$$.fragment,e),v(ke.$$.fragment,e),v(Ee.$$.fragment,e),v(ge.$$.fragment,e),v(we.$$.fragment,e),v(ye.$$.fragment,e),v(ze.$$.fragment,e),v(xe.$$.fragment,e),v(Ae.$$.fragment,e),v(Ce.$$.fragment,e),v(De.$$.fragment,e),v(Se.$$.fragment,e),v(Me.$$.fragment,e),v(Oe.$$.fragment,e),v(Te.$$.fragment,e),v(Le.$$.fragment,e),v(Ne.$$.fragment,e),v(re.$$.fragment,e),v(Ue.$$.fragment,e),v(We.$$.fragment,e),v(Ie.$$.fragment,e),v(Fe.$$.fragment,e),v(ie.$$.fragment,e),v(Ge.$$.fragment,e),v(Ve.$$.fragment,e),v(He.$$.fragment,e),v(Re.$$.fragment,e),_a=!1},d(e){t($),e&&t(y),e&&t(E),_(k),e&&t(C),_(M,e),e&&t(ve),_(_e,e),e&&t(mt),e&&t(K),e&&t(ft),_(be,e),e&&t(ht),e&&t(R),_($e),e&&t(vt),e&&t(D),e&&t(_t),e&&t(O),e&&t(bt),e&&t(Z),e&&t($t),_(qe,e),e&&t(qt),e&&t(Ye),e&&t(jt),_(je,e),e&&t(kt),e&&t(ee),e&&t(Et),_(ke,e),e&&t(gt),e&&t(Qe),e&&t(wt),_(Ee,e),e&&t(yt),_(ge,e),e&&t(zt),e&&t(T),e&&t(Pt),e&&t(Ke),e&&t(xt),_(we,e),e&&t(At),e&&t(Xe),e&&t(Ct),_(ye,e),e&&t(Dt),_(ze,e),e&&t(St),e&&t(L),e&&t(Mt),e&&t(z),e&&t(Ot),_(xe,e),e&&t(Tt),e&&t(N),e&&t(Lt),_(Ae,e),e&&t(Nt),_(Ce,e),e&&t(Ut),e&&t(J),_(De),e&&t(Wt),e&&t(te),e&&t(It),_(Se,e),e&&t(Ft),_(Me,e),e&&t(Gt),e&&t(ae),e&&t(Vt),_(Oe,e),e&&t(Ht),e&&t(Ze),e&&t(Rt),e&&t(Y),_(Te),e&&t(Bt),e&&t(P),e&&t(Jt),_(Le,e),e&&t(Yt),_(Ne,e),e&&t(Qt),e&&t(es),e&&t(Kt),_(re,e),e&&t(Xt),e&&t(Q),_(Ue),e&&t(Zt),_(We,e),e&&t(ea),e&&t(U),e&&t(sa),_(Ie,e),e&&t(ta),e&&t(ts),e&&t(aa),_(Fe,e),e&&t(na),e&&t(x),e&&t(ra),e&&t(g),e&&t(la),_(ie,e),e&&t(oa),e&&t(ue),e&&t(ia),_(Ge,e),e&&t(ua),e&&t(pe),e&&t(pa),_(Ve,e),e&&t(ca),e&&t(as),e&&t(da),_(He,e),e&&t(ma),e&&t(ns),e&&t(fa),e&&t(W),e&&t(ha),_(Re,e),e&&t(va),e&&t(ce)}}}const Ao={local:"un-entranement-complet",sections:[{local:"prparer-lentranement",title:"Pr\xE9parer l'entra\xEEnement"},{local:"la-boucle-dentranement",title:"La boucle d'entra\xEEnement"},{local:"la-boucle-dvaluation",title:"La boucle d'\xE9valuation"},{local:"optimisez-votre-boucle-dentranement-avec-iacceleratei",title:"Optimisez votre boucle d'entra\xEEnement avec \u{1F917} <i>Accelerate</i>"}],title:"Un entra\xEEnement complet"};function Co(Je){return wo(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class No extends jo{constructor($){super();ko(this,$,Co,xo,Eo,{})}}export{No as default,Ao as metadata};
