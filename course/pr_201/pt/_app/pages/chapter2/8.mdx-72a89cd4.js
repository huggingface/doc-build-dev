import{S as vo,i as $o,s as go,e as s,k as p,w,t as T,l as po,M as ko,c as n,d as a,m as f,x as z,a as i,h as O,b as l,F as o,g as c,y as A,o as g,p as fo,q as k,B as E,v as xo,n as ho}from"../../chunks/vendor-e6c5d93e.js";import{I as H}from"../../chunks/IconCopyLink-7b8d27fe.js";import{C as Ia}from"../../chunks/CodeBlock-37867453.js";import{Q as C}from"../../chunks/Question-ee65cb95.js";import{F as _o}from"../../chunks/FrameworkSwitchCourse-ab838f47.js";function bo(Q){let d,u,$,h,N,v,S,_,y,P,b,x,t;return h=new H({}),x=new C({props:{choices:[{text:"Um modelo que treina automaticamente com seus dados",explain:"Incorreto. Voc\xEA est\xE1 confundindo isto com nosso produto de <a href='https://huggingface.co/autonlp'>AutoNLP</a>?"},{text:"Um objeto que devolve a arquitetura correta com base em um checkpoint",explain:"Exatamente: o <code>TFAutoModel</code> s\xF3 precisa saber o checkpoint para saber como inicializar ent\xE3o devolver a arquitetura correta.",correct:!0},{text:"Um modelo que detecta automaticamente a linguagem utilizada para suas entradas a fim de carregar os pesos corretos",explain:"Incorreto; embora alguns checkpoints e modelos sejam capazes de lidar com v\xE1rios idiomas, n\xE3o h\xE1 ferramentas embutidas para sele\xE7\xE3o autom\xE1tica de checkpoints de acordo com o idioma. Voc\xEA deve ir para o  <a href='https://huggingface.co/models'>Model Hub</a> para encontrar o melhor checkpoint para realizar sua tarefa!"}]}}),{c(){d=s("h3"),u=s("a"),$=s("span"),w(h.$$.fragment),N=p(),v=s("span"),S=T("5. O que seria um "),_=s("code"),y=T("TFAutoModel"),P=T("?"),b=p(),w(x.$$.fragment),this.h()},l(r){d=n(r,"H3",{class:!0});var q=i(d);u=n(q,"A",{id:!0,class:!0,href:!0});var j=i(u);$=n(j,"SPAN",{});var M=i($);z(h.$$.fragment,M),M.forEach(a),j.forEach(a),N=f(q),v=n(q,"SPAN",{});var I=i(v);S=O(I,"5. O que seria um "),_=n(I,"CODE",{});var V=i(_);y=O(V,"TFAutoModel"),V.forEach(a),P=O(I,"?"),I.forEach(a),q.forEach(a),b=f(r),z(x.$$.fragment,r),this.h()},h(){l(u,"id","5.-o-que-seria-um-<code>tfautomodel</code>?"),l(u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(u,"href","#5.-o-que-seria-um-<code>tfautomodel</code>?"),l(d,"class","relative group")},m(r,q){c(r,d,q),o(d,u),o(u,$),A(h,$,null),o(d,N),o(d,v),o(v,S),o(v,_),o(_,y),o(v,P),c(r,b,q),A(x,r,q),t=!0},i(r){t||(k(h.$$.fragment,r),k(x.$$.fragment,r),t=!0)},o(r){g(h.$$.fragment,r),g(x.$$.fragment,r),t=!1},d(r){r&&a(d),E(h),r&&a(b),E(x,r)}}}function qo(Q){let d,u,$,h,N,v,S,_,y,P,b,x,t;return h=new H({}),x=new C({props:{choices:[{text:"Um modelo que treina automaticamente com seus dados",explain:"Incorreto. Voc\xEA est\xE1 confundindo isto com nosso produto de <a href='https://huggingface.co/autonlp'>AutoNLP</a>?"},{text:"Um objeto que devolve a arquitetura correta com base em um checkpoint",explain:"Exatamente: o <code>AutoModel</code> s\xF3 precisa saber o checkpoint para saber como inicializar ent\xE3o devolver a arquitetura correta.",correct:!0},{text:"Um modelo que detecta automaticamente a linguagem utilizada para suas entradas a fim de carregar os pesos corretos",explain:"Incorreto; embora alguns checkpoints e modelos sejam capazes de lidar com v\xE1rios idiomas, n\xE3o h\xE1 ferramentas embutidas para sele\xE7\xE3o autom\xE1tica de checkpoints de acordo com o idioma. Voc\xEA deve ir para o  <a href='https://huggingface.co/models'>Model Hub</a> para encontrar o melhor checkpoint para realizar sua tarefa!"}]}}),{c(){d=s("h3"),u=s("a"),$=s("span"),w(h.$$.fragment),N=p(),v=s("span"),S=T("5. O que seria um "),_=s("code"),y=T("AutoModel"),P=T("?"),b=p(),w(x.$$.fragment),this.h()},l(r){d=n(r,"H3",{class:!0});var q=i(d);u=n(q,"A",{id:!0,class:!0,href:!0});var j=i(u);$=n(j,"SPAN",{});var M=i($);z(h.$$.fragment,M),M.forEach(a),j.forEach(a),N=f(q),v=n(q,"SPAN",{});var I=i(v);S=O(I,"5. O que seria um "),_=n(I,"CODE",{});var V=i(_);y=O(V,"AutoModel"),V.forEach(a),P=O(I,"?"),I.forEach(a),q.forEach(a),b=f(r),z(x.$$.fragment,r),this.h()},h(){l(u,"id","5.-o-que-seria-um-<code>automodel</code>?"),l(u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(u,"href","#5.-o-que-seria-um-<code>automodel</code>?"),l(d,"class","relative group")},m(r,q){c(r,d,q),o(d,u),o(u,$),A(h,$,null),o(d,N),o(d,v),o(v,S),o(v,_),o(_,y),o(v,P),c(r,b,q),A(x,r,q),t=!0},i(r){t||(k(h.$$.fragment,r),k(x.$$.fragment,r),t=!0)},o(r){g(h.$$.fragment,r),g(x.$$.fragment,r),t=!1},d(r){r&&a(d),E(h),r&&a(b),E(x,r)}}}function wo(Q){let d,u,$,h,N,v,S,_,y,P,b,x;return h=new H({}),y=new Ia({props:{code:`from transformers import AutoTokenizer, TFAutoModel

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
model = TFAutoModel.from_pretrained("gpt2")

encoded = tokenizer("Hey!", return_tensors="pt")
result = model(**encoded)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModel

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
model = TFAutoModel.from_pretrained(<span class="hljs-string">&quot;gpt2&quot;</span>)

encoded = tokenizer(<span class="hljs-string">&quot;Hey!&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
result = model(**encoded)`}}),b=new C({props:{choices:[{text:"N\xE3o, parece correto.",explain:"Infelizmente, acoplar um modelo com um tokenizer que foi treinado com um checkpoint diferente raramente \xE9 uma boa ideia. O modelo n\xE3o foi treinado para fazer sentido a partir da sa\xEDda deste tokenizer, ent\xE3o a sa\xEDda do modelo (isto se ele realmente funcionar!) n\xE3o far\xE1 nenhum sentido."},{text:"O tokenizer e o modelo devem ser sempre a partir do mesmo checkpoint.",explain:"Correto!",correct:!0},{text:"\xC9 uma boa pr\xE1tica realizar o padding e truncar com o tokenizer, pois cada entrada \xE9 um batch.",explain:"\xC9 verdade que cada entrada do modelo precisa ser um batch. Entretanto, truncando ou realizando o padding desta sequ\xEAncia n\xE3o faria necessariamente sentido, pois existe apenas uma delas, e estas s\xE3o t\xE9cnicas para criar batches de uma lista de senten\xE7as."}]}}),{c(){d=s("h3"),u=s("a"),$=s("span"),w(h.$$.fragment),N=p(),v=s("span"),S=T("10. Tem algo errado com o c\xF3digo abaixo?"),_=p(),w(y.$$.fragment),P=p(),w(b.$$.fragment),this.h()},l(t){d=n(t,"H3",{class:!0});var r=i(d);u=n(r,"A",{id:!0,class:!0,href:!0});var q=i(u);$=n(q,"SPAN",{});var j=i($);z(h.$$.fragment,j),j.forEach(a),q.forEach(a),N=f(r),v=n(r,"SPAN",{});var M=i(v);S=O(M,"10. Tem algo errado com o c\xF3digo abaixo?"),M.forEach(a),r.forEach(a),_=f(t),z(y.$$.fragment,t),P=f(t),z(b.$$.fragment,t),this.h()},h(){l(u,"id","10.-tem-algo-errado-com-o-c\xF3digo-abaixo?"),l(u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(u,"href","#10.-tem-algo-errado-com-o-c\xF3digo-abaixo?"),l(d,"class","relative group")},m(t,r){c(t,d,r),o(d,u),o(u,$),A(h,$,null),o(d,N),o(d,v),o(v,S),c(t,_,r),A(y,t,r),c(t,P,r),A(b,t,r),x=!0},i(t){x||(k(h.$$.fragment,t),k(y.$$.fragment,t),k(b.$$.fragment,t),x=!0)},o(t){g(h.$$.fragment,t),g(y.$$.fragment,t),g(b.$$.fragment,t),x=!1},d(t){t&&a(d),E(h),t&&a(_),E(y,t),t&&a(P),E(b,t)}}}function zo(Q){let d,u,$,h,N,v,S,_,y,P,b,x;return h=new H({}),y=new Ia({props:{code:`from transformers import AutoTokenizer, AutoModel

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
model = AutoModel.from_pretrained("gpt2")

encoded = tokenizer("Hey!", return_tensors="pt")
result = model(**encoded)`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModel

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
model = AutoModel.from_pretrained(<span class="hljs-string">&quot;gpt2&quot;</span>)

encoded = tokenizer(<span class="hljs-string">&quot;Hey!&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
result = model(**encoded)`}}),b=new C({props:{choices:[{text:"N\xE3o, parece correto.",explain:"Infelizmente, acoplar um modelo com um tokenizer que foi treinado com um checkpoint diferente raramente \xE9 uma boa ideia. O modelo n\xE3o foi treinado para fazer sentido a partir da sa\xEDda deste tokenizer, ent\xE3o a sa\xEDda do modelo (isto se ele realmente funcionar!) n\xE3o far\xE1 nenhum sentido."},{text:"O tokenizer e o modelo devem ser sempre a partir do mesmo checkpoint.",explain:"Correto!",correct:!0},{text:"\xC9 uma boa pr\xE1tica realizar o padding e truncar com o tokenizer, pois cada entrada \xE9 um batch.",explain:"\xC9 verdade que cada entrada do modelo precisa ser um batch. Entretanto, truncando ou realizando o padding desta sequ\xEAncia n\xE3o faria necessariamente sentido, pois existe apenas uma delas, e estas s\xE3o t\xE9cnicas para criar batches de uma lista de senten\xE7as."}]}}),{c(){d=s("h3"),u=s("a"),$=s("span"),w(h.$$.fragment),N=p(),v=s("span"),S=T("10. Tem algo errado com o c\xF3digo abaixo?"),_=p(),w(y.$$.fragment),P=p(),w(b.$$.fragment),this.h()},l(t){d=n(t,"H3",{class:!0});var r=i(d);u=n(r,"A",{id:!0,class:!0,href:!0});var q=i(u);$=n(q,"SPAN",{});var j=i($);z(h.$$.fragment,j),j.forEach(a),q.forEach(a),N=f(r),v=n(r,"SPAN",{});var M=i(v);S=O(M,"10. Tem algo errado com o c\xF3digo abaixo?"),M.forEach(a),r.forEach(a),_=f(t),z(y.$$.fragment,t),P=f(t),z(b.$$.fragment,t),this.h()},h(){l(u,"id","10.-tem-algo-errado-com-o-c\xF3digo-abaixo?"),l(u,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(u,"href","#10.-tem-algo-errado-com-o-c\xF3digo-abaixo?"),l(d,"class","relative group")},m(t,r){c(t,d,r),o(d,u),o(u,$),A(h,$,null),o(d,N),o(d,v),o(v,S),c(t,_,r),A(y,t,r),c(t,P,r),A(b,t,r),x=!0},i(t){x||(k(h.$$.fragment,t),k(y.$$.fragment,t),k(b.$$.fragment,t),x=!0)},o(t){g(h.$$.fragment,t),g(y.$$.fragment,t),g(b.$$.fragment,t),x=!1},d(t){t&&a(d),E(h),t&&a(_),E(y,t),t&&a(P),E(b,t)}}}function Ao(Q){let d,u,$,h,N,v,S,_,y,P,b,x,t,r,q,j,M,I,V,Ve,se,Be,B,Y,Pe,ne,ga,Se,ka,Re,ie,Je,R,Z,Te,le,xa,Oe,_a,We,me,Ge,J,ee,je,de,ba,ue,qa,Me,wa,za,Ke,ce,Xe,U,D,Ae,W,ae,Ie,pe,Aa,He,Ea,Ye,fe,Ze,G,oe,Ce,he,ya,Qe,Na,ea,ve,aa,K,te,Ue,$e,Pa,De,Sa,oa,ge,ta,X,re,Fe,ke,Ta,xe,Oa,Le,ja,Ma,ra,_e,sa,be,na,F,L,Ee,ia;$=new _o({props:{fw:Q[0]}}),_=new H({}),j=new H({}),se=new C({props:{choices:[{text:"Primeiro, o modelo trata de textos e devolve previs\xF5es em bruto. O tokenizer, ent\xE3o, tr\xE1s sentido a estas previs\xF5es e as converte de volta ao texto quando necess\xE1rio.",explain:"O modelo n\xE3o consegue entender o texto! O tokenizer deve primeiro simbolizar o texto e convert\xEA-lo em IDs para que seja compreens\xEDvel pelo modelo."},{text:"Primeiro, o tokenizer trata de textos e devolve as identifica\xE7\xF5es (IDs). O modelo lida com estas identifica\xE7\xF5es e produz uma predi\xE7\xE3o, que pode ser algum texto.",explain:"A predi\xE7\xE3o do modelo n\xE3o pode ser feita de imediato. O tokenizer tem que ser usado para converter a predi\xE7\xE3o de volta ao texto!"},{text:"O tokenizer trata de textos e devolve os IDs. O modelo lida com estes IDs e produz uma predi\xE7\xE3o. O tokenizer pode ent\xE3o ser usado mais uma vez para converter estas previs\xF5es de volta para algum texto.",explain:"Correto! O tokenizer pode ser usado tanto para a tokeniza\xE7\xE3o quanto para a destokeniza\xE7\xE3o.",correct:!0}]}}),ne=new H({}),ie=new C({props:{choices:[{text:"2: O comprimento da sequ\xEAncia e o tamanho do batch (lote)",explain:"Falso! A sa\xEDda do tensor pelo modelo tem uma terceira dimens\xE3o: o tamanho das camadas ocultas"},{text:"2: O comprimento da sequ\xEAncia e o tamanho das camadas ocultas",explain:"Falso! Todos os Transformer lidam com batches, mesmo com uma \xFAnica sequ\xEAncia; isso seria um tamanho de batch de 1!"},{text:"3: O comprimento da sequ\xEAncia, o tamanho do batch (lote) e o tamanho das camadas ocultas",explain:"Correto!",correct:!0}]}}),le=new H({}),me=new C({props:{choices:[{text:"WordPiece",explain:"Exatamente, este \xE9 um exemplo de Tokeniza\xE7\xE3o por sub-palavra!",correct:!0},{text:"Character-based tokenization",explain:"Character-based tokenization n\xE3o \xE9 uma tokeniza\xE7\xE3o por sub-palavra!."},{text:"Divis\xE3o no espa\xE7o em branco e pontua\xE7\xE3o",explain:"Esse \xE9 um esquema de tokenization baseado em palavras!"},{text:"BPE",explain:"Exatamente, este \xE9 um exemplo de Tokeniza\xE7\xE3o por sub-palavra!",correct:!0},{text:"Unigram",explain:"Exatamente, este \xE9 um exemplo de Tokeniza\xE7\xE3o por sub-palavra!",correct:!0},{text:"Nenhuma das acimas",explain:"Errado!"}]}}),de=new H({}),ce=new C({props:{choices:[{text:"Um componente dos transformers de base que redireciona os tensores para suas camadas corretas",explain:"Incorreto! N\xE3o existe tal componente."},{text:"Tamb\xE9m conhecido como mecanismo de auto-aten\xE7\xE3o (*self-attention*), ele adapta a representa\xE7\xE3o de um s\xEDmbolo de acordo com os outros tokens da sequ\xEAncia",explain:"Incorreto! A camada de auto-aten\xE7\xE3o cont\xE9m 'attention heads', mas estas n\xE3o s\xE3o as heads de adapta\xE7\xE3o."},{text:"Um componente adicional, geralmente composto de uma ou poucas camadas, para converter as previs\xF5es do Transformer em uma sa\xEDda espec\xEDfica de tarefa",explain:"\xC9 isso mesmo. As heads de adapta\xE7\xE3o, tamb\xE9m conhecidos simplesmente como heads, surgem em diferentes formas: heads de modelagem de linguagem, heads de resposta a perguntas, heads de classifica\xE7\xE3o de sequ\xEAncia.. ",correct:!0}]}});const Ha=[qo,bo],qe=[];function Ca(e,m){return e[0]==="pt"?0:1}U=Ca(Q),D=qe[U]=Ha[U](Q),pe=new H({}),fe=new C({props:{choices:[{text:"Truncar",explain:"Sim, a truncagem \xE9 uma forma correta de sequ\xEAncias de sa\xEDda noturna para que elas se encaixem em forma retangular.No entanto, seria a \xFAnica?",correct:!0},{text:"Retornar tensores",explain:"Enquanto as outras t\xE9cnicas permitem retornar tensores retangulares, retornar tensores n\xE3o \xE9 \xFAtil quando realizar batches de sequ\xEAncias juntas."},{text:"Padding",explain:"Sim, padding \xE9 uma forma correta para as sequ\xEAncias de sa\xEDda para que elas se encaixem em uma forma retangular. No entanto, seria a \xFAnica?",correct:!0},{text:"Attention masking",explain:"Exatamente! As attention masks s\xE3o de primordial import\xE2ncia quando se trata de sequ\xEAncias de diferentes tamanhos. No entanto, essa n\xE3o \xE9 a \xFAnica t\xE9cnica a ser conhecida.",correct:!0}]}}),he=new H({}),ve=new C({props:{choices:[{text:"Suaviza os logits para que sejam mais confi\xE1veis.",explain:"N\xE3o, a fun\xE7\xE3o SoftMax n\xE3o afeta a confiabilidade dos resultados."},{text:"Aplica um limite inferior e um limite superior para que eles sejam compreens\xEDveis.",explain:"Correto! Os valores resultantes est\xE3o vinculados entre 0 e 1. Mas essa n\xE3o \xE9 a \xFAnica raz\xE3o pela qual usamos uma fun\xE7\xE3o SoftMax.",correct:!0},{text:"A soma total da sa\xEDda \xE9 1, resultando em uma poss\xEDvel interpreta\xE7\xE3o probabil\xEDstica.",explain:"Correto! Mas essa n\xE3o \xE9 a \xFAnica raz\xE3o pela qual usamos uma fun\xE7\xE3o SoftMax.",correct:!0}]}}),$e=new H({}),ge=new C({props:{choices:[{text:"<code>encode</code>, pois pode codificar texto em IDs e IDs em predi\xE7\xF5es",explain:"Errado! O m\xE9todo <code>encode</code> existe na tokeniza\xE7\xE3o, por\xE9m n\xE3o existe nos modelos."},{text:"Chamando diretamente o objeto de tokeniza\xE7\xE3o (tokenizer).",explain:"Exatamente! O m\xE9todo <code>__call__</code> do tokenizer \xE9 um m\xE9todo muito poderoso que pode lidar com praticamente qualquer coisa. \xC9 tamb\xE9m o m\xE9todo usado para recuperar as predi\xE7\xF5es de um modelo.",correct:!0},{text:"<code>padding</code>",explain:"Errado! O padding \xE9 muito \xFAtil, mas \xE9 apenas uma parte da API do tokenizer."},{text:"<code>tokenize</code>",explain:"O m\xE9todo <code>tokenize</code> \xE9 indiscutivelmente um dos m\xE9todos mais \xFAteis, mas n\xE3o \xE9 o n\xFAcleo do API do tokenizer."}]}}),ke=new H({}),_e=new Ia({props:{code:`from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")
result = tokenizer.tokenize("Hello!")`,highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;bert-base-cased&quot;</span>)
result = tokenizer.tokenize(<span class="hljs-string">&quot;Hello!&quot;</span>)`}}),be=new C({props:{choices:[{text:"Uma lista de strings, sendo cada uma delas um token",explain:"Exatamente! Converta isto em IDs, e envie-os para um modelo!",correct:!0},{text:"Uma lista de IDs",explain:"Incorreto; isto \xE9 o para o os m\xE9todos <code>__call__</code> ou <code>convert_tokens_to_ids</code>!"},{text:"Uma string contendo todos os tokens ",explain:"Isto seria sub\xF3timo, pois o objetivo \xE9 dividir a string em v\xE1rios tokens."}]}});const Qa=[zo,wo],we=[];function Ua(e,m){return e[0]==="pt"?0:1}return F=Ua(Q),L=we[F]=Qa[F](Q),{c(){d=s("meta"),u=p(),w($.$$.fragment),h=p(),N=s("h1"),v=s("a"),S=s("span"),w(_.$$.fragment),y=p(),P=s("span"),b=T("Question\xE1rio de fim de cap\xEDtulo"),x=p(),t=s("h3"),r=s("a"),q=s("span"),w(j.$$.fragment),M=p(),I=s("span"),V=T("1. Qual \xE9 a ordem do pipeline para a modelagem de linguagem?"),Ve=p(),w(se.$$.fragment),Be=p(),B=s("h3"),Y=s("a"),Pe=s("span"),w(ne.$$.fragment),ga=p(),Se=s("span"),ka=T("2. Quantas dimens\xF5es tem o tensor do Transformer de base, e quais s\xE3o elas?"),Re=p(),w(ie.$$.fragment),Je=p(),R=s("h3"),Z=s("a"),Te=s("span"),w(le.$$.fragment),xa=p(),Oe=s("span"),_a=T("3. Qual dos seguintes \xE9 um exemplo de Tokeniza\xE7\xE3o por sub-palavras?"),We=p(),w(me.$$.fragment),Ge=p(),J=s("h3"),ee=s("a"),je=s("span"),w(de.$$.fragment),ba=p(),ue=s("span"),qa=T("4. O que \xE9 uma "),Me=s("em"),wa=T("model head"),za=T("?"),Ke=p(),w(ce.$$.fragment),Xe=p(),D.c(),Ae=p(),W=s("h3"),ae=s("a"),Ie=s("span"),w(pe.$$.fragment),Aa=p(),He=s("span"),Ea=T("6. Quais s\xE3o as t\xE9cnicas a serem observadas quando realizar batches com sequ\xEAncias de diferentes tamanhos?"),Ye=p(),w(fe.$$.fragment),Ze=p(),G=s("h3"),oe=s("a"),Ce=s("span"),w(he.$$.fragment),ya=p(),Qe=s("span"),Na=T("7. Qual \xE9 o objetivo de aplicar uma fun\xE7\xE3o SoftMax \xE0 sa\xEDda de logits para um modelo de classifica\xE7\xE3o sequencial??"),ea=p(),w(ve.$$.fragment),aa=p(),K=s("h3"),te=s("a"),Ue=s("span"),w($e.$$.fragment),Pa=p(),De=s("span"),Sa=T("8. Qual \xE9 o m\xE9todo core da API tokenizer?"),oa=p(),w(ge.$$.fragment),ta=p(),X=s("h3"),re=s("a"),Fe=s("span"),w(ke.$$.fragment),Ta=p(),xe=s("span"),Oa=T("9. O que a vari\xE1vel "),Le=s("code"),ja=T("result"),Ma=T(" cont\xE9m nesta peda\xE7o de c\xF3digo?"),ra=p(),w(_e.$$.fragment),sa=p(),w(be.$$.fragment),na=p(),L.c(),Ee=po(),this.h()},l(e){const m=ko('[data-svelte="svelte-1phssyn"]',document.head);d=n(m,"META",{name:!0,content:!0}),m.forEach(a),u=f(e),z($.$$.fragment,e),h=f(e),N=n(e,"H1",{class:!0});var ze=i(N);v=n(ze,"A",{id:!0,class:!0,href:!0});var ye=i(v);S=n(ye,"SPAN",{});var Ne=i(S);z(_.$$.fragment,Ne),Ne.forEach(a),ye.forEach(a),y=f(ze),P=n(ze,"SPAN",{});var Da=i(P);b=O(Da,"Question\xE1rio de fim de cap\xEDtulo"),Da.forEach(a),ze.forEach(a),x=f(e),t=n(e,"H3",{class:!0});var la=i(t);r=n(la,"A",{id:!0,class:!0,href:!0});var Fa=i(r);q=n(Fa,"SPAN",{});var La=i(q);z(j.$$.fragment,La),La.forEach(a),Fa.forEach(a),M=f(la),I=n(la,"SPAN",{});var Va=i(I);V=O(Va,"1. Qual \xE9 a ordem do pipeline para a modelagem de linguagem?"),Va.forEach(a),la.forEach(a),Ve=f(e),z(se.$$.fragment,e),Be=f(e),B=n(e,"H3",{class:!0});var ma=i(B);Y=n(ma,"A",{id:!0,class:!0,href:!0});var Ba=i(Y);Pe=n(Ba,"SPAN",{});var Ra=i(Pe);z(ne.$$.fragment,Ra),Ra.forEach(a),Ba.forEach(a),ga=f(ma),Se=n(ma,"SPAN",{});var Ja=i(Se);ka=O(Ja,"2. Quantas dimens\xF5es tem o tensor do Transformer de base, e quais s\xE3o elas?"),Ja.forEach(a),ma.forEach(a),Re=f(e),z(ie.$$.fragment,e),Je=f(e),R=n(e,"H3",{class:!0});var da=i(R);Z=n(da,"A",{id:!0,class:!0,href:!0});var Wa=i(Z);Te=n(Wa,"SPAN",{});var Ga=i(Te);z(le.$$.fragment,Ga),Ga.forEach(a),Wa.forEach(a),xa=f(da),Oe=n(da,"SPAN",{});var Ka=i(Oe);_a=O(Ka,"3. Qual dos seguintes \xE9 um exemplo de Tokeniza\xE7\xE3o por sub-palavras?"),Ka.forEach(a),da.forEach(a),We=f(e),z(me.$$.fragment,e),Ge=f(e),J=n(e,"H3",{class:!0});var ua=i(J);ee=n(ua,"A",{id:!0,class:!0,href:!0});var Xa=i(ee);je=n(Xa,"SPAN",{});var Ya=i(je);z(de.$$.fragment,Ya),Ya.forEach(a),Xa.forEach(a),ba=f(ua),ue=n(ua,"SPAN",{});var ca=i(ue);qa=O(ca,"4. O que \xE9 uma "),Me=n(ca,"EM",{});var Za=i(Me);wa=O(Za,"model head"),Za.forEach(a),za=O(ca,"?"),ca.forEach(a),ua.forEach(a),Ke=f(e),z(ce.$$.fragment,e),Xe=f(e),D.l(e),Ae=f(e),W=n(e,"H3",{class:!0});var pa=i(W);ae=n(pa,"A",{id:!0,class:!0,href:!0});var eo=i(ae);Ie=n(eo,"SPAN",{});var ao=i(Ie);z(pe.$$.fragment,ao),ao.forEach(a),eo.forEach(a),Aa=f(pa),He=n(pa,"SPAN",{});var oo=i(He);Ea=O(oo,"6. Quais s\xE3o as t\xE9cnicas a serem observadas quando realizar batches com sequ\xEAncias de diferentes tamanhos?"),oo.forEach(a),pa.forEach(a),Ye=f(e),z(fe.$$.fragment,e),Ze=f(e),G=n(e,"H3",{class:!0});var fa=i(G);oe=n(fa,"A",{id:!0,class:!0,href:!0});var to=i(oe);Ce=n(to,"SPAN",{});var ro=i(Ce);z(he.$$.fragment,ro),ro.forEach(a),to.forEach(a),ya=f(fa),Qe=n(fa,"SPAN",{});var so=i(Qe);Na=O(so,"7. Qual \xE9 o objetivo de aplicar uma fun\xE7\xE3o SoftMax \xE0 sa\xEDda de logits para um modelo de classifica\xE7\xE3o sequencial??"),so.forEach(a),fa.forEach(a),ea=f(e),z(ve.$$.fragment,e),aa=f(e),K=n(e,"H3",{class:!0});var ha=i(K);te=n(ha,"A",{id:!0,class:!0,href:!0});var no=i(te);Ue=n(no,"SPAN",{});var io=i(Ue);z($e.$$.fragment,io),io.forEach(a),no.forEach(a),Pa=f(ha),De=n(ha,"SPAN",{});var lo=i(De);Sa=O(lo,"8. Qual \xE9 o m\xE9todo core da API tokenizer?"),lo.forEach(a),ha.forEach(a),oa=f(e),z(ge.$$.fragment,e),ta=f(e),X=n(e,"H3",{class:!0});var va=i(X);re=n(va,"A",{id:!0,class:!0,href:!0});var mo=i(re);Fe=n(mo,"SPAN",{});var uo=i(Fe);z(ke.$$.fragment,uo),uo.forEach(a),mo.forEach(a),Ta=f(va),xe=n(va,"SPAN",{});var $a=i(xe);Oa=O($a,"9. O que a vari\xE1vel "),Le=n($a,"CODE",{});var co=i(Le);ja=O(co,"result"),co.forEach(a),Ma=O($a," cont\xE9m nesta peda\xE7o de c\xF3digo?"),$a.forEach(a),va.forEach(a),ra=f(e),z(_e.$$.fragment,e),sa=f(e),z(be.$$.fragment,e),na=f(e),L.l(e),Ee=po(),this.h()},h(){l(d,"name","hf:doc:metadata"),l(d,"content",JSON.stringify(Eo)),l(v,"id","questionrio-de-fim-de-captulo"),l(v,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(v,"href","#questionrio-de-fim-de-captulo"),l(N,"class","relative group"),l(r,"id","1.-qual-\xE9-a-ordem-do-pipeline-para-a-modelagem-de-linguagem?"),l(r,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(r,"href","#1.-qual-\xE9-a-ordem-do-pipeline-para-a-modelagem-de-linguagem?"),l(t,"class","relative group"),l(Y,"id","2.-quantas-dimens\xF5es-tem-o-tensor-do-transformer-de-base,-e-quais-s\xE3o-elas?"),l(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(Y,"href","#2.-quantas-dimens\xF5es-tem-o-tensor-do-transformer-de-base,-e-quais-s\xE3o-elas?"),l(B,"class","relative group"),l(Z,"id","3.-qual-dos-seguintes-\xE9-um-exemplo-de-tokeniza\xE7\xE3o-por-sub-palavras?"),l(Z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(Z,"href","#3.-qual-dos-seguintes-\xE9-um-exemplo-de-tokeniza\xE7\xE3o-por-sub-palavras?"),l(R,"class","relative group"),l(ee,"id","4.-o-que-\xE9-uma-<em>model-head</em>?"),l(ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(ee,"href","#4.-o-que-\xE9-uma-<em>model-head</em>?"),l(J,"class","relative group"),l(ae,"id","6.-quais-s\xE3o-as-t\xE9cnicas-a-serem-observadas-quando-realizar-batches-com-sequ\xEAncias-de-diferentes-tamanhos?"),l(ae,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(ae,"href","#6.-quais-s\xE3o-as-t\xE9cnicas-a-serem-observadas-quando-realizar-batches-com-sequ\xEAncias-de-diferentes-tamanhos?"),l(W,"class","relative group"),l(oe,"id","7.-qual-\xE9-o-objetivo-de-aplicar-uma-fun\xE7\xE3o-softmax-\xE0-sa\xEDda-de-logits-para-um-modelo-de-classifica\xE7\xE3o-sequencial??"),l(oe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(oe,"href","#7.-qual-\xE9-o-objetivo-de-aplicar-uma-fun\xE7\xE3o-softmax-\xE0-sa\xEDda-de-logits-para-um-modelo-de-classifica\xE7\xE3o-sequencial??"),l(G,"class","relative group"),l(te,"id","8.-qual-\xE9-o-m\xE9todo-core-da-api-tokenizer?"),l(te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(te,"href","#8.-qual-\xE9-o-m\xE9todo-core-da-api-tokenizer?"),l(K,"class","relative group"),l(re,"id","9.-o-que-a-vari\xE1vel-<code>result</code>-cont\xE9m-nesta-peda\xE7o-de-c\xF3digo?"),l(re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),l(re,"href","#9.-o-que-a-vari\xE1vel-<code>result</code>-cont\xE9m-nesta-peda\xE7o-de-c\xF3digo?"),l(X,"class","relative group")},m(e,m){o(document.head,d),c(e,u,m),A($,e,m),c(e,h,m),c(e,N,m),o(N,v),o(v,S),A(_,S,null),o(N,y),o(N,P),o(P,b),c(e,x,m),c(e,t,m),o(t,r),o(r,q),A(j,q,null),o(t,M),o(t,I),o(I,V),c(e,Ve,m),A(se,e,m),c(e,Be,m),c(e,B,m),o(B,Y),o(Y,Pe),A(ne,Pe,null),o(B,ga),o(B,Se),o(Se,ka),c(e,Re,m),A(ie,e,m),c(e,Je,m),c(e,R,m),o(R,Z),o(Z,Te),A(le,Te,null),o(R,xa),o(R,Oe),o(Oe,_a),c(e,We,m),A(me,e,m),c(e,Ge,m),c(e,J,m),o(J,ee),o(ee,je),A(de,je,null),o(J,ba),o(J,ue),o(ue,qa),o(ue,Me),o(Me,wa),o(ue,za),c(e,Ke,m),A(ce,e,m),c(e,Xe,m),qe[U].m(e,m),c(e,Ae,m),c(e,W,m),o(W,ae),o(ae,Ie),A(pe,Ie,null),o(W,Aa),o(W,He),o(He,Ea),c(e,Ye,m),A(fe,e,m),c(e,Ze,m),c(e,G,m),o(G,oe),o(oe,Ce),A(he,Ce,null),o(G,ya),o(G,Qe),o(Qe,Na),c(e,ea,m),A(ve,e,m),c(e,aa,m),c(e,K,m),o(K,te),o(te,Ue),A($e,Ue,null),o(K,Pa),o(K,De),o(De,Sa),c(e,oa,m),A(ge,e,m),c(e,ta,m),c(e,X,m),o(X,re),o(re,Fe),A(ke,Fe,null),o(X,Ta),o(X,xe),o(xe,Oa),o(xe,Le),o(Le,ja),o(xe,Ma),c(e,ra,m),A(_e,e,m),c(e,sa,m),A(be,e,m),c(e,na,m),we[F].m(e,m),c(e,Ee,m),ia=!0},p(e,[m]){const ze={};m&1&&(ze.fw=e[0]),$.$set(ze);let ye=U;U=Ca(e),U!==ye&&(ho(),g(qe[ye],1,1,()=>{qe[ye]=null}),fo(),D=qe[U],D||(D=qe[U]=Ha[U](e),D.c()),k(D,1),D.m(Ae.parentNode,Ae));let Ne=F;F=Ua(e),F!==Ne&&(ho(),g(we[Ne],1,1,()=>{we[Ne]=null}),fo(),L=we[F],L||(L=we[F]=Qa[F](e),L.c()),k(L,1),L.m(Ee.parentNode,Ee))},i(e){ia||(k($.$$.fragment,e),k(_.$$.fragment,e),k(j.$$.fragment,e),k(se.$$.fragment,e),k(ne.$$.fragment,e),k(ie.$$.fragment,e),k(le.$$.fragment,e),k(me.$$.fragment,e),k(de.$$.fragment,e),k(ce.$$.fragment,e),k(D),k(pe.$$.fragment,e),k(fe.$$.fragment,e),k(he.$$.fragment,e),k(ve.$$.fragment,e),k($e.$$.fragment,e),k(ge.$$.fragment,e),k(ke.$$.fragment,e),k(_e.$$.fragment,e),k(be.$$.fragment,e),k(L),ia=!0)},o(e){g($.$$.fragment,e),g(_.$$.fragment,e),g(j.$$.fragment,e),g(se.$$.fragment,e),g(ne.$$.fragment,e),g(ie.$$.fragment,e),g(le.$$.fragment,e),g(me.$$.fragment,e),g(de.$$.fragment,e),g(ce.$$.fragment,e),g(D),g(pe.$$.fragment,e),g(fe.$$.fragment,e),g(he.$$.fragment,e),g(ve.$$.fragment,e),g($e.$$.fragment,e),g(ge.$$.fragment,e),g(ke.$$.fragment,e),g(_e.$$.fragment,e),g(be.$$.fragment,e),g(L),ia=!1},d(e){a(d),e&&a(u),E($,e),e&&a(h),e&&a(N),E(_),e&&a(x),e&&a(t),E(j),e&&a(Ve),E(se,e),e&&a(Be),e&&a(B),E(ne),e&&a(Re),E(ie,e),e&&a(Je),e&&a(R),E(le),e&&a(We),E(me,e),e&&a(Ge),e&&a(J),E(de),e&&a(Ke),E(ce,e),e&&a(Xe),qe[U].d(e),e&&a(Ae),e&&a(W),E(pe),e&&a(Ye),E(fe,e),e&&a(Ze),e&&a(G),E(he),e&&a(ea),E(ve,e),e&&a(aa),e&&a(K),E($e),e&&a(oa),E(ge,e),e&&a(ta),e&&a(X),E(ke),e&&a(ra),E(_e,e),e&&a(sa),E(be,e),e&&a(na),we[F].d(e),e&&a(Ee)}}}const Eo={local:"questionrio-de-fim-de-captulo",title:"Question\xE1rio de fim de cap\xEDtulo"};function yo(Q,d,u){let $="pt";return xo(()=>{const h=new URLSearchParams(window.location.search);u(0,$=h.get("fw")||"pt")}),[$]}class jo extends vo{constructor(d){super();$o(this,d,yo,Ao,go,{})}}export{jo as default,Eo as metadata};
