<meta charset="utf-8" /><meta http-equiv="content-security-policy" content=""><meta name="hf:doc:metadata" content="{&quot;local&quot;:&quot;reference&quot;,&quot;sections&quot;:[{&quot;local&quot;:&quot;deep-learning-container&quot;,&quot;title&quot;:&quot;Deep Learning Container&quot;},{&quot;local&quot;:&quot;training-dlc-overview&quot;,&quot;title&quot;:&quot;Training DLC Overview&quot;},{&quot;local&quot;:&quot;inference-dlc-overview&quot;,&quot;title&quot;:&quot;Inference DLC Overview&quot;},{&quot;local&quot;:&quot;hugging-face-transformers-amazon-sagemaker-examples&quot;,&quot;title&quot;:&quot;Hugging Face Transformers Amazon SageMaker Examples&quot;},{&quot;local&quot;:&quot;inference-toolkit-api&quot;,&quot;title&quot;:&quot;Inference Toolkit API&quot;},{&quot;local&quot;:&quot;inference-toolkit-environment-variables&quot;,&quot;title&quot;:&quot;Inference Toolkit environment variables&quot;}],&quot;title&quot;:&quot;Reference&quot;}" data-svelte="svelte-1phssyn">
	<link rel="modulepreload" href="/docs/sagemaker/pr_224/en/_app/assets/pages/__layout.svelte-hf-doc-builder.css">
	<link rel="modulepreload" href="/docs/sagemaker/pr_224/en/_app/start-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/sagemaker/pr_224/en/_app/chunks/vendor-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/sagemaker/pr_224/en/_app/chunks/paths-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/sagemaker/pr_224/en/_app/pages/__layout.svelte-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/sagemaker/pr_224/en/_app/pages/reference.mdx-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/sagemaker/pr_224/en/_app/chunks/IconCopyLink-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/sagemaker/pr_224/en/_app/chunks/CodeBlock-hf-doc-builder.js"> 





<h1 class="relative group"><a id="reference" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#reference"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Reference
	</span></h1>

<h2 class="relative group"><a id="deep-learning-container" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#deep-learning-container"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Deep Learning Container
	</span></h2>

<p>Below you can find a version table of currently available Hugging Face DLCs. The table doesnâ€™t include the full <code>image_uri</code> here are two examples on how to construct those if needed.</p>
<p><strong>Manually construction the <code>image_uri</code></strong></p>
<p><code>{dlc-aws-account-id}.dkr.ecr.{region}.amazonaws.com/huggingface-{framework}-{(training | inference)}:{framework-version}-transformers{transformers-version}-{device}-{python-version}-{device-tag}</code></p>
<ul><li><code>dlc-aws-account-id</code>: The AWS account ID of the account that owns the ECR repository. You can find them in the <a href="https://github.com/aws/sagemaker-python-sdk/blob/e0b9d38e1e3b48647a02af23c4be54980e53dc61/src/sagemaker/image_uri_config/huggingface.json#L21" rel="nofollow">here</a></li>
<li><code>region</code>: The AWS region where you want to use it.</li>
<li><code>framework</code>: The framework you want to use, either <code>pytorch</code> or <code>tensorflow</code>.</li>
<li><code>(training | inference)</code>: The training or inference mode.</li>
<li><code>framework-version</code>: The version of the framework you want to use.</li>
<li><code>transformers-version</code>: The version of the transformers library you want to use.</li>
<li><code>device</code>: The device you want to use, either <code>cpu</code> or <code>gpu</code>.</li>
<li><code>python-version</code>: The version of the python of the DLC.</li>
<li><code>device-tag</code>: The device tag you want to use. The device tag can include os version and cuda version</li></ul>
<p><strong>Example 1: PyTorch Training:</strong>
<code>763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:1.6.0-transformers4.4.2-gpu-py36-cu110-ubuntu18.04</code>
<strong>Example 2: Tensorflow Inference:</strong>
<code>763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-tensorflow-inference:2.4.1-transformers4.6.1-cpu-py37-ubuntu18.04</code></p>
<h2 class="relative group"><a id="training-dlc-overview" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#training-dlc-overview"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Training DLC Overview
	</span></h2>

<p>The Training DLC overview includes all released and available Hugging Face Training DLCs. It includes PyTorch and TensorFlow flavored
versions for GPU.</p>
<table><thead><tr><th>ðŸ¤— Transformers version</th>
<th>ðŸ¤— Datasets version</th>
<th>PyTorch/TensorFlow version</th>
<th>type</th>
<th>device</th>
<th>Python Version</th></tr></thead>
<tbody><tr><td>4.4.2</td>
<td>1.5.0</td>
<td>PyTorch 1.6.0</td>
<td>training</td>
<td>GPU</td>
<td>3.6</td></tr>
<tr><td>4.4.2</td>
<td>1.5.0</td>
<td>TensorFlow 2.4.1</td>
<td>training</td>
<td>GPU</td>
<td>3.7</td></tr>
<tr><td>4.5.0</td>
<td>1.5.0</td>
<td>PyTorch 1.6.0</td>
<td>training</td>
<td>GPU</td>
<td>3.6</td></tr>
<tr><td>4.5.0</td>
<td>1.5.0</td>
<td>TensorFlow 2.4.1</td>
<td>training</td>
<td>GPU</td>
<td>3.7</td></tr>
<tr><td>4.6.1</td>
<td>1.6.2</td>
<td>PyTorch 1.6.0</td>
<td>training</td>
<td>GPU</td>
<td>3.6</td></tr>
<tr><td>4.6.1</td>
<td>1.6.2</td>
<td>PyTorch 1.7.1</td>
<td>training</td>
<td>GPU</td>
<td>3.6</td></tr>
<tr><td>4.6.1</td>
<td>1.6.2</td>
<td>TensorFlow 2.4.1</td>
<td>training</td>
<td>GPU</td>
<td>3.7</td></tr>
<tr><td>4.10.2</td>
<td>1.11.0</td>
<td>PyTorch 1.8.1</td>
<td>training</td>
<td>GPU</td>
<td>3.6</td></tr>
<tr><td>4.10.2</td>
<td>1.11.0</td>
<td>PyTorch 1.9.0</td>
<td>training</td>
<td>GPU</td>
<td>3.8</td></tr>
<tr><td>4.10.2</td>
<td>1.11.0</td>
<td>TensorFlow 2.4.1</td>
<td>training</td>
<td>GPU</td>
<td>3.7</td></tr>
<tr><td>4.10.2</td>
<td>1.11.0</td>
<td>TensorFlow 2.5.1</td>
<td>training</td>
<td>GPU</td>
<td>3.7</td></tr>
<tr><td>4.11.0</td>
<td>1.12.1</td>
<td>PyTorch 1.9.0</td>
<td>training</td>
<td>GPU</td>
<td>3.8</td></tr>
<tr><td>4.11.0</td>
<td>1.12.1</td>
<td>TensorFlow 2.5.1</td>
<td>training</td>
<td>GPU</td>
<td>3.7</td></tr>
<tr><td>4.12.3</td>
<td>1.15.1</td>
<td>PyTorch 1.9.1</td>
<td>training</td>
<td>GPU</td>
<td>3.8</td></tr>
<tr><td>4.12.3</td>
<td>1.15.1</td>
<td>TensorFlow 2.5.1</td>
<td>training</td>
<td>GPU</td>
<td>3.7</td></tr>
<tr><td>4.17.0</td>
<td>1.18.4</td>
<td>PyTorch 1.10.2</td>
<td>training</td>
<td>GPU</td>
<td>3.8</td></tr>
<tr><td>4.17.0</td>
<td>1.18.4</td>
<td>TensorFlow 2.6.3</td>
<td>training</td>
<td>GPU</td>
<td>3.8</td></tr></tbody></table>
<h2 class="relative group"><a id="inference-dlc-overview" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#inference-dlc-overview"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Inference DLC Overview
	</span></h2>

<p>The Inference DLC overview includes all released and available Hugging Face Inference DLCs. It includes PyTorch and TensorFlow flavored
versions for CPU, GPU &amp; AWS Inferentia.</p>
<table><thead><tr><th>ðŸ¤— Transformers version</th>
<th>PyTorch/TensorFlow version</th>
<th>type</th>
<th>device</th>
<th>Python Version</th></tr></thead>
<tbody><tr><td>4.6.1</td>
<td>PyTorch 1.7.1</td>
<td>inference</td>
<td>CPU</td>
<td>3.6</td></tr>
<tr><td>4.6.1</td>
<td>PyTorch 1.7.1</td>
<td>inference</td>
<td>GPU</td>
<td>3.6</td></tr>
<tr><td>4.6.1</td>
<td>TensorFlow 2.4.1</td>
<td>inference</td>
<td>CPU</td>
<td>3.7</td></tr>
<tr><td>4.6.1</td>
<td>TensorFlow 2.4.1</td>
<td>inference</td>
<td>GPU</td>
<td>3.7</td></tr>
<tr><td>4.10.2</td>
<td>PyTorch 1.8.1</td>
<td>inference</td>
<td>GPU</td>
<td>3.6</td></tr>
<tr><td>4.10.2</td>
<td>PyTorch 1.9.0</td>
<td>inference</td>
<td>GPU</td>
<td>3.8</td></tr>
<tr><td>4.10.2</td>
<td>TensorFlow 2.4.1</td>
<td>inference</td>
<td>GPU</td>
<td>3.7</td></tr>
<tr><td>4.10.2</td>
<td>TensorFlow 2.5.1</td>
<td>inference</td>
<td>GPU</td>
<td>3.7</td></tr>
<tr><td>4.10.2</td>
<td>PyTorch 1.8.1</td>
<td>inference</td>
<td>CPU</td>
<td>3.6</td></tr>
<tr><td>4.10.2</td>
<td>PyTorch 1.9.0</td>
<td>inference</td>
<td>CPU</td>
<td>3.8</td></tr>
<tr><td>4.10.2</td>
<td>TensorFlow 2.4.1</td>
<td>inference</td>
<td>CPU</td>
<td>3.7</td></tr>
<tr><td>4.10.2</td>
<td>TensorFlow 2.5.1</td>
<td>inference</td>
<td>CPU</td>
<td>3.7</td></tr>
<tr><td>4.11.0</td>
<td>PyTorch 1.9.0</td>
<td>inference</td>
<td>GPU</td>
<td>3.8</td></tr>
<tr><td>4.11.0</td>
<td>TensorFlow 2.5.1</td>
<td>inference</td>
<td>GPU</td>
<td>3.7</td></tr>
<tr><td>4.11.0</td>
<td>PyTorch 1.9.0</td>
<td>inference</td>
<td>CPU</td>
<td>3.8</td></tr>
<tr><td>4.11.0</td>
<td>TensorFlow 2.5.1</td>
<td>inference</td>
<td>CPU</td>
<td>3.7</td></tr>
<tr><td>4.12.3</td>
<td>PyTorch 1.9.1</td>
<td>inference</td>
<td>GPU</td>
<td>3.8</td></tr>
<tr><td>4.12.3</td>
<td>TensorFlow 2.5.1</td>
<td>inference</td>
<td>GPU</td>
<td>3.7</td></tr>
<tr><td>4.12.3</td>
<td>PyTorch 1.9.1</td>
<td>inference</td>
<td>CPU</td>
<td>3.8</td></tr>
<tr><td>4.12.3</td>
<td>TensorFlow 2.5.1</td>
<td>inference</td>
<td>CPU</td>
<td>3.7</td></tr>
<tr><td>4.12.3</td>
<td>PyTorch 1.9.1</td>
<td>inference</td>
<td>Inferentia</td>
<td>3.7</td></tr>
<tr><td>4.17.0</td>
<td>PyTorch 1.10.2</td>
<td>inference</td>
<td>GPU</td>
<td>3.8</td></tr>
<tr><td>4.17.0</td>
<td>TensorFlow 2.6.3</td>
<td>inference</td>
<td>GPU</td>
<td>3.8</td></tr>
<tr><td>4.17.0</td>
<td>PyTorch 1.10.2</td>
<td>inference</td>
<td>CPU</td>
<td>3.8</td></tr>
<tr><td>4.17.0</td>
<td>TensorFlow 2.6.3</td>
<td>inference</td>
<td>CPU</td>
<td>3.8</td></tr></tbody></table>
<h2 class="relative group"><a id="hugging-face-transformers-amazon-sagemaker-examples" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#hugging-face-transformers-amazon-sagemaker-examples"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Hugging Face Transformers Amazon SageMaker Examples
	</span></h2>

<p>Example Jupyter notebooks that demonstrate how to build, train, and deploy <a href="https://github.com/huggingface/transformers" rel="nofollow">Hugging Face Transformers</a> using <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/whatis.html" rel="nofollow">Amazon SageMaker</a> and the <a href="https://sagemaker.readthedocs.io/en/stable/" rel="nofollow">Amazon SageMaker Python SDK</a>.</p>
<table><thead><tr><th>Notebook</th>
<th>Type</th>
<th>Description</th></tr></thead>
<tbody><tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/01_getting_started_pytorch/sagemaker-notebook.ipynb" rel="nofollow">01 Getting started with PyTorch</a></td>
<td>Training</td>
<td>Getting started end-to-end example on how to fine-tune a pre-trained Hugging Face Transformer for Text-Classification using PyTorch</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/02_getting_started_tensorflow/sagemaker-notebook.ipynb" rel="nofollow">02 getting started with TensorFlow</a></td>
<td>Training</td>
<td>Getting started end-to-end example on how to fine-tune a pre-trained Hugging Face Transformer for Text-Classification using TensorFlow</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/03_distributed_training_data_parallelism/sagemaker-notebook.ipynb" rel="nofollow">03 Distributed Training: Data Parallelism</a></td>
<td>Training</td>
<td>End-to-end example on how to use distributed training with data-parallelism strategy for fine-tuning a pre-trained Hugging Face Transformer for Question-Answering using Amazon SageMaker Data Parallelism</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/04_distributed_training_model_parallelism/sagemaker-notebook.ipynb" rel="nofollow">04 Distributed Training: Model Parallelism</a></td>
<td>Training</td>
<td>End-to-end example on how to use distributed training with model-parallelism strategy to pre-trained Hugging Face Transformer using Amazon SageMaker Model Parallelism</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/05_spot_instances/sagemaker-notebook.ipynb" rel="nofollow">05 How to use Spot Instances &amp; Checkpointing</a></td>
<td>Training</td>
<td>End-to-end example on how to use Spot Instances and Checkpointing to reduce training cost</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/06_sagemaker_metrics/sagemaker-notebook.ipynb" rel="nofollow">06 Experiment Tracking with SageMaker Metrics</a></td>
<td>Training</td>
<td>End-to-end example on how to use SageMaker metrics to track your experiments and training jobs</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/07_tensorflow_distributed_training_data_parallelism/sagemaker-notebook.ipynb" rel="nofollow">07 Distributed Training: Data Parallelism</a></td>
<td>Training</td>
<td>End-to-end example on how to use Amazon SageMaker Data Parallelism with TensorFlow</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/08_distributed_summarization_bart_t5/sagemaker-notebook.ipynb" rel="nofollow">08 Distributed Training: Summarization with T5/BART</a></td>
<td>Training</td>
<td>End-to-end example on how to fine-tune BART/T5 for Summarization using Amazon SageMaker Data Parallelism</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/09_image_classification_vision_transformer/sagemaker-notebook.ipynb" rel="nofollow">09 Vision: Fine-tune ViT</a></td>
<td>Training</td>
<td>End-to-end example on how to fine-tune Vision Transformer for Image-Classification</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/10_deploy_model_from_s3/deploy_transformer_model_from_s3.ipynb" rel="nofollow">10 Deploy HF Transformer from Amazon S3</a></td>
<td>Inference</td>
<td>End-to-end example on how to deploy a model from Amazon S3</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/11_deploy_model_from_hf_hub/deploy_transformer_model_from_hf_hub.ipynb" rel="nofollow">11 Deploy HF Transformer from Hugging Face Hub</a></td>
<td>Inference</td>
<td>End-to-end example on how to deploy a model from the Hugging Face Hub</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/12_batch_transform_inference/sagemaker-notebook.ipynb" rel="nofollow">12 Batch Processing with Amazon SageMaker Batch Transform</a></td>
<td>Inference</td>
<td>End-to-end example on how to do batch processing with Amazon SageMaker Batch Transform</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/13_deploy_and_autoscaling_transformers/sagemaker-notebook.ipynb" rel="nofollow">13 Autoscaling SageMaker Endpoints</a></td>
<td>Inference</td>
<td>End-to-end example on how to do use autoscaling for a HF Endpoint</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/14_train_and_push_to_hub/sagemaker-notebook.ipynb" rel="nofollow">14 Fine-tune and push to Hub</a></td>
<td>Training</td>
<td>End-to-end example on how to do use the Hugging Face Hub as MLOps backend for saving checkpoints during training</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/15_training_compiler/sagemaker-notebook.ipynb" rel="nofollow">15 Training Compiler</a></td>
<td>Training</td>
<td>End-to-end example on how to do use Amazon SageMaker Training Compiler to speed up training time</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/16_async_inference_hf_hub/sagemaker-notebook.ipynb" rel="nofollow">16 Asynchronous Inference</a></td>
<td>Inference</td>
<td>End-to-end example on how to do use Amazon SageMaker Asynchronous Inference endpoints with Hugging Face Transformers</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/17_custom_inference_script/sagemaker-notebook.ipynb" rel="nofollow">17 Custom inference.py script</a></td>
<td>Inference</td>
<td>End-to-end example on how to create a custom inference.py for Sentence Transformers and sentence embeddings</td></tr>
<tr><td><a href="https://github.com/huggingface/notebooks/blob/main/sagemaker/18_inferentia_inference/sagemaker-notebook.ipynb" rel="nofollow">18 AWS Inferentia</a></td>
<td>Inference</td>
<td>End-to-end example on how to AWS Inferentia to speed up inference time</td></tr></tbody></table>
<h2 class="relative group"><a id="inference-toolkit-api" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#inference-toolkit-api"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Inference Toolkit API
	</span></h2>

<p>The Inference Toolkit accepts inputs in the <code>inputs</code> key, and supports additional <a href="https://huggingface.co/transformers/main_classes/pipelines.html" rel="nofollow"><code>pipelines</code></a> parameters in the <code>parameters</code> key. You can provide any of the supported <code>kwargs</code> from <code>pipelines</code> as <code>parameters</code>.</p>
<p>Tasks supported by the Inference Toolkit API include:</p>
<ul><li><strong><code>text-classification</code></strong></li>
<li><strong><code>sentiment-analysis</code></strong></li>
<li><strong><code>token-classification</code></strong></li>
<li><strong><code>feature-extraction</code></strong></li>
<li><strong><code>fill-mask</code></strong></li>
<li><strong><code>summarization</code></strong></li>
<li><strong><code>translation_xx_to_yy</code></strong></li>
<li><strong><code>text2text-generation</code></strong></li>
<li><strong><code>text-generation</code></strong></li>
<li><strong><code>audio-classificatin</code></strong></li>
<li><strong><code>automatic-speech-recognition</code></strong></li>
<li><strong><code>conversational</code></strong></li>
<li><strong><code>image-classification</code></strong></li>
<li><strong><code>image-segmentation</code></strong></li>
<li><strong><code>object-detection</code></strong></li>
<li><strong><code>table-question-answering</code></strong></li>
<li><strong><code>zero-shot-classification</code></strong></li>
<li><strong><code>zero-shot-image-classification</code></strong></li></ul>
<p>See the following request examples for some of the tasks:</p>
<p><strong><code>text-classification</code></strong></p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;This sound track was beautiful! It paints the senery in your mind so well I would recomend it
  even to people who hate vid. game music!&quot;</span>
<span class="hljs-punctuation">}</span><!-- HTML_TAG_END --></pre></div>
<p><strong><code>sentiment-analysis</code></strong></p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Don&#x27;t waste your time.  We had two different people come to our house to give us estimates for
a deck (one of them the OWNER).  Both times, we never heard from them.  Not a call, not the estimate, nothing.&quot;</span>
<span class="hljs-punctuation">}</span><!-- HTML_TAG_END --></pre></div>
<p><strong><code>token-classification</code></strong></p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;My name is Sylvain and I work at Hugging Face in Brooklyn.&quot;</span>
<span class="hljs-punctuation">}</span><!-- HTML_TAG_END --></pre></div>
<p><strong><code>question-answering</code></strong></p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
    <span class="hljs-attr">&quot;question&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;What is used for inference?&quot;</span><span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;context&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;My Name is Philipp and I live in Nuremberg. This model is used with sagemaker for inference.&quot;</span>
  <span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">}</span><!-- HTML_TAG_END --></pre></div>
<p><strong><code>zero-shot-classification</code></strong></p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Hi, I recently bought a device from your company but it is not working as advertised and I would like to get reimbursed!&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;parameters&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
    <span class="hljs-attr">&quot;candidate_labels&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;refund&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;legal&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;faq&quot;</span><span class="hljs-punctuation">]</span>
  <span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">}</span><!-- HTML_TAG_END --></pre></div>
<p><strong><code>table-question-answering</code></strong></p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
    <span class="hljs-attr">&quot;query&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;How many stars does the transformers repository have?&quot;</span><span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;table&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
      <span class="hljs-attr">&quot;Repository&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;Transformers&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Datasets&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Tokenizers&quot;</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">&quot;Stars&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;36542&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;4512&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;3934&quot;</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">&quot;Contributors&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;651&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;77&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;34&quot;</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">&quot;Programming language&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;Python&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Python&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;Rust, Python and NodeJS&quot;</span><span class="hljs-punctuation">]</span>
    <span class="hljs-punctuation">}</span>
  <span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">}</span><!-- HTML_TAG_END --></pre></div>
<p><strong><code>parameterized-request</code></strong></p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START --><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Hugging Face, the winner of VentureBeatâ€™s Innovation in Natural Language Process/Understanding Award for 2021, is looking to level the playing field. The team, launched by ClÃ©ment Delangue and Julien Chaumond in 2016, was recognized for its work in democratizing NLP, the global market value for which is expected to hit $35.1 billion by 2026. This week, Googleâ€™s former head of Ethical AI Margaret Mitchell joined the team.&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;parameters&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
    <span class="hljs-attr">&quot;repetition_penalty&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4.0</span><span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;length_penalty&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1.5</span>
  <span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">}</span><!-- HTML_TAG_END --></pre></div>
<h2 class="relative group"><a id="inference-toolkit-environment-variables" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#inference-toolkit-environment-variables"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Inference Toolkit environment variables
	</span></h2>

<p>The Inference Toolkit implements various additional environment variables to simplify deployment. A complete list of Hugging Face specific environment variables is shown below:</p>
<p><strong><code>HF_TASK</code></strong></p>
<p><code>HF_TASK</code> defines the task for the ðŸ¤— Transformers pipeline used . See <a href="https://huggingface.co/transformers/main_classes/pipelines.html" rel="nofollow">here</a> for a complete list of tasks.</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START -->HF_TASK=<span class="hljs-string">&quot;question-answering&quot;</span><!-- HTML_TAG_END --></pre></div>
<p><strong><code>HF_MODEL_ID</code></strong></p>
<p><code>HF_MODEL_ID</code> defines the model ID which is automatically loaded from <a href="https://huggingface.co/models" rel="nofollow">hf.co/models</a> when creating a SageMaker endpoint. All of the ðŸ¤— Hubâ€™s 10,000+ models are available through this environment variable.</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START -->HF_MODEL_ID=<span class="hljs-string">&quot;distilbert-base-uncased-finetuned-sst-2-english&quot;</span><!-- HTML_TAG_END --></pre></div>
<p><strong><code>HF_MODEL_REVISION</code></strong></p>
<p><code>HF_MODEL_REVISION</code> is an extension to <code>HF_MODEL_ID</code> and allows you to define or pin a model revision to make sure you always load the same model on your SageMaker endpoint.</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START -->HF_MODEL_REVISION=<span class="hljs-string">&quot;03b4d196c19d0a73c7e0322684e97db1ec397613&quot;</span><!-- HTML_TAG_END --></pre></div>
<p><strong><code>HF_API_TOKEN</code></strong></p>
<p><code>HF_API_TOKEN</code> defines your Hugging Face authorization token. The <code>HF_API_TOKEN</code> is used as a HTTP bearer authorization for remote files like private models. You can find your token under <a href="https://huggingface.co/settings/tokens" rel="nofollow">Settings</a> of your Hugging Face account.</p>

	<div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg>
	<div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div>
	Copied</div></button></div>
	<pre><!-- HTML_TAG_START -->HF_API_TOKEN=<span class="hljs-string">&quot;api_XXXXXXXXXXXXXXXXXXXXXXXXXXXXX&quot;</span><!-- HTML_TAG_END --></pre></div>


		<script type="module" data-hydrate="1wshgo5">
		import { start } from "/docs/sagemaker/pr_224/en/_app/start-hf-doc-builder.js";
		start({
			target: document.querySelector('[data-hydrate="1wshgo5"]').parentNode,
			paths: {"base":"/docs/sagemaker/pr_224/en","assets":"/docs/sagemaker/pr_224/en"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/sagemaker/pr_224/en/_app/pages/__layout.svelte-hf-doc-builder.js"),
						import("/docs/sagemaker/pr_224/en/_app/pages/reference.mdx-hf-doc-builder.js")
				],
				params: {}
			}
		});
	</script>
