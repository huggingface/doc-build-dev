import{S as Zu,i as Vu,s as Xu,e as l,k as c,w as u,t as a,M as em,c as r,d as o,m as d,a as n,x as m,h as s,b as f,N as id,G as t,g as p,y as h,L as tm,q as _,o as g,B as v,v as om}from"../chunks/vendor-hf-doc-builder.js";import{I as ne}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as E}from"../chunks/CodeBlock-hf-doc-builder.js";function am(pd){let K,_s,Q,ie,wo,Fe,hr,$o,_r,gs,Ht,gr,vs,Ne,ys,P,vr,Re,yr,Er,pe,ko,wr,$r,kr,Es,k,Pt,zt,br,jr,Sr,Lt,Ft,Dr,qr,xr,Nt,Rt,Cr,Tr,Or,Ut,Bt,Mr,Ar,Ir,Yt,Wt,Hr,Pr,ws,Z,ce,bo,Ue,zr,jo,Lr,$s,de,Fr,Be,Nr,Rr,ks,Gt,Ur,bs,z,So,Ye,Br,Yr,Do,We,Wr,Gr,qo,Jr,js,fe,Kr,Ge,Qr,Zr,Ss,ue,Vr,xo,Xr,en,Ds,Je,qs,Jt,Co,tn,xs,Kt,on,Cs,Ke,Ts,Qt,V,an,To,sn,ln,Oo,rn,nn,Os,Zt,Mo,pn,Ms,Vt,cn,As,Qe,Is,X,me,Ao,Ze,dn,Io,fn,Hs,q,cd,Ps,Xt,un,zs,he,Ho,mn,hn,Ve,_n,Po,gn,vn,Ls,_e,yn,Xe,En,wn,Fs,ee,ge,zo,et,$n,Lo,kn,Ns,eo,bn,Rs,O,jn,Fo,Sn,Dn,No,qn,xn,Ro,Cn,Tn,Us,tt,Bs,to,On,Ys,ot,Ws,te,ve,Uo,at,Mn,oo,An,Bo,In,Gs,ye,Hn,Yo,Pn,zn,Js,st,Ks,ao,Ln,Qs,lt,Zs,oe,Ee,Wo,rt,Fn,Go,Nn,Vs,we,Rn,Jo,Un,Bn,Xs,M,Ko,Qo,Yn,Wn,Zo,Vo,Gn,Jn,Xo,ea,Kn,Qn,ta,oa,Zn,el,so,Vn,tl,nt,ol,$e,Xn,aa,ei,ti,al,lo,sa,oi,sl,it,ll,pt,ct,ai,la,si,li,rl,dt,nl,ft,ut,ri,ra,ni,ii,il,mt,pl,ke,pi,na,ci,di,cl,ae,be,ia,ht,fi,pa,ui,dl,x,dd,fl,je,mi,ca,hi,_i,ul,Se,De,da,gi,vi,_t,yi,Ei,wi,L,fa,$i,ki,ua,bi,ji,gt,Si,Di,ml,vt,hl,ro,qi,_l,yt,gl,qe,xi,Et,Ci,Ti,vl,se,xe,ma,wt,Oi,ha,Mi,yl,C,fd,El,F,Ai,$t,Ii,Hi,kt,Pi,zi,wl,Ce,Li,_a,Fi,Ni,$l,no,le,Ri,ga,Ui,Bi,va,Yi,Wi,kl,N,Gi,ya,Ji,Ki,bt,Qi,Zi,bl,jt,jl,R,Vi,Ea,Xi,ep,wa,tp,op,Sl,St,Dl,Te,ap,$a,sp,lp,ql,Dt,xl,Oe,rp,qt,np,ip,Cl,re,Me,ka,xt,pp,ba,cp,Tl,b,dp,ja,fp,up,Sa,mp,hp,Da,_p,gp,io,vp,yp,Ol,Ct,Ml,U,Ep,qa,wp,$p,xa,kp,bp,Al,j,$,Ca,jp,Sp,Ta,Dp,qp,Oa,xp,Cp,Ma,Tp,Op,Aa,Mp,Ap,Ia,Ip,Hp,Pp,y,Ha,zp,Lp,Pa,Fp,Np,za,Rp,Up,La,Bp,Yp,Fa,Wp,Gp,Na,Jp,Kp,Ra,Qp,Zp,Ua,Vp,Xp,ec,A,Ba,tc,oc,Ya,ac,sc,Wa,lc,rc,Tt,po,Ga,nc,ic,pc,co,Ja,cc,dc,fc,S,Ka,uc,mc,Qa,hc,_c,Za,gc,vc,Va,yc,Ec,Xa,wc,$c,kc,I,es,bc,jc,ts,Sc,Dc,os,qc,xc,Ot,Ae,as,Cc,Tc,ss,Oc,Mc,Ac,Ie,ls,Ic,Hc,rs,Pc,zc,Il,D,Lc,ns,Fc,Nc,is,Rc,Uc,ps,Bc,Yc,cs,Wc,Gc,Hl,Mt,Pl,B,Jc,ds,Kc,Qc,fs,Zc,Vc,zl,At,Ll;return Fe=new ne({}),Ne=new E({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> sagemaker.huggingface <span class="hljs-keyword">import</span> HuggingFaceModel

<span class="hljs-comment"># create Hugging Face Model Class and deploy it as SageMaker endpoint</span>
huggingface_model = HuggingFaceModel(...).deploy()`}}),Ue=new ne({}),Je=new E({props:{code:"pip install sagemaker --upgrade",highlighted:"pip install sagemaker --upgrade"}}),Ke=new E({props:{code:`import sagemaker
sess = sagemaker.Session()
role = sagemaker.get_execution_role()`,highlighted:`<span class="hljs-keyword">import</span> sagemaker
sess = sagemaker.Session()
role = sagemaker.get_execution_role()`}}),Qe=new E({props:{code:"",highlighted:`<span class="hljs-keyword">import</span> sagemaker
<span class="hljs-keyword">import</span> boto3

iam_client = boto3.client(<span class="hljs-string">&#x27;iam&#x27;</span>)
role = iam_client.get_role(RoleName=<span class="hljs-string">&#x27;role-name-of-your-iam-role-with-right-permissions&#x27;</span>)[<span class="hljs-string">&#x27;Role&#x27;</span>][<span class="hljs-string">&#x27;Arn&#x27;</span>]
sess = sagemaker.Session()`}}),Ze=new ne({}),et=new ne({}),tt=new E({props:{code:`





`,highlighted:`<span class="hljs-keyword">from</span> sagemaker.huggingface <span class="hljs-keyword">import</span> HuggingFace

<span class="hljs-comment">############ pseudo code start ############</span>

<span class="hljs-comment"># create Hugging Face Estimator for training</span>
huggingface_estimator = HuggingFace(....)

<span class="hljs-comment"># start the train job with our uploaded datasets as input</span>
huggingface_estimator.fit(...)

<span class="hljs-comment">############ pseudo code end ############</span>

<span class="hljs-comment"># deploy model to SageMaker Inference</span>
predictor = hf_estimator.deploy(initial_instance_count=<span class="hljs-number">1</span>, instance_type=<span class="hljs-string">&quot;ml.m5.xlarge&quot;</span>)

<span class="hljs-comment"># example request: you always need to define &quot;inputs&quot;</span>
data = {
   <span class="hljs-string">&quot;inputs&quot;</span>: <span class="hljs-string">&quot;Camera - You are awarded a SiPix Digital Camera! call 09061221066 fromm landline. Delivery within 28 days.&quot;</span>
}

<span class="hljs-comment"># request</span>
predictor.predict(data)`}}),ot=new E({props:{code:`# delete endpoint
predictor.delete_endpoint()`,highlighted:`<span class="hljs-comment"># delete endpoint</span>
predictor.delete_endpoint()`}}),at=new ne({}),st=new E({props:{code:`


`,highlighted:`<span class="hljs-keyword">from</span> sagemaker.huggingface.model <span class="hljs-keyword">import</span> HuggingFaceModel

<span class="hljs-comment"># create Hugging Face Model Class</span>
huggingface_model = HuggingFaceModel(
   model_data=<span class="hljs-string">&quot;s3://models/my-bert-model/model.tar.gz&quot;</span>,  <span class="hljs-comment"># path to your trained SageMaker model</span>
   role=role,                                            <span class="hljs-comment"># IAM role with permissions to create an endpoint</span>
   transformers_version=<span class="hljs-string">&quot;4.6&quot;</span>,                           <span class="hljs-comment"># Transformers version used</span>
   pytorch_version=<span class="hljs-string">&quot;1.7&quot;</span>,                                <span class="hljs-comment"># PyTorch version used</span>
   py_version=<span class="hljs-string">&#x27;py36&#x27;</span>,                                    <span class="hljs-comment"># Python version used</span>
)

<span class="hljs-comment"># deploy model to SageMaker Inference</span>
predictor = huggingface_model.deploy(
   initial_instance_count=<span class="hljs-number">1</span>,
   instance_type=<span class="hljs-string">&quot;ml.m5.xlarge&quot;</span>
)

<span class="hljs-comment"># example request: you always need to define &quot;inputs&quot;</span>
data = {
   <span class="hljs-string">&quot;inputs&quot;</span>: <span class="hljs-string">&quot;Camera - You are awarded a SiPix Digital Camera! call 09061221066 fromm landline. Delivery within 28 days.&quot;</span>
}

<span class="hljs-comment"># request</span>
predictor.predict(data)`}}),lt=new E({props:{code:`# delete endpoint
predictor.delete_endpoint()`,highlighted:`<span class="hljs-comment"># delete endpoint</span>
predictor.delete_endpoint()`}}),rt=new ne({}),nt=new E({props:{code:`model.tar.gz/
|- pytorch_model.bin
|- vocab.txt
|- tokenizer_config.json
|- config.json
|- special_tokens_map.json`,highlighted:`model.tar.gz/
|- pytorch_model.bin
|- vocab.txt
|- tokenizer_config.json
|- config.json
|- special_tokens_map.json`}}),it=new E({props:{code:`git lfs install
git clone https://huggingface.co/{repository}`,highlighted:`git lfs install
git <span class="hljs-built_in">clone</span> https://huggingface.co/{repository}`}}),dt=new E({props:{code:`cd {repository}
tar zcvf model.tar.gz *`,highlighted:`<span class="hljs-built_in">cd</span> {repository}
tar zcvf model.tar.gz *`}}),mt=new E({props:{code:"aws s3 cp model.tar.gz <s3://{my-s3-path}>",highlighted:'aws s3 <span class="hljs-built_in">cp</span> model.tar.gz &lt;s3://{my-s3-path}&gt;'}}),ht=new ne({}),vt=new E({props:{code:`



`,highlighted:`<span class="hljs-keyword">from</span> sagemaker.huggingface.model <span class="hljs-keyword">import</span> HuggingFaceModel

<span class="hljs-comment"># Hub model configuration &lt;https://huggingface.co/models&gt;</span>
hub = {
  <span class="hljs-string">&#x27;HF_MODEL_ID&#x27;</span>:<span class="hljs-string">&#x27;distilbert-base-uncased-distilled-squad&#x27;</span>, <span class="hljs-comment"># model_id from hf.co/models</span>
  <span class="hljs-string">&#x27;HF_TASK&#x27;</span>:<span class="hljs-string">&#x27;question-answering&#x27;</span>                           <span class="hljs-comment"># NLP task you want to use for predictions</span>
}

<span class="hljs-comment"># create Hugging Face Model Class</span>
huggingface_model = HuggingFaceModel(
   env=hub,                                                <span class="hljs-comment"># configuration for loading model from Hub</span>
   role=role,                                              <span class="hljs-comment"># IAM role with permissions to create an endpoint</span>
   transformers_version=<span class="hljs-string">&quot;4.6&quot;</span>,                             <span class="hljs-comment"># Transformers version used</span>
   pytorch_version=<span class="hljs-string">&quot;1.7&quot;</span>,                                  <span class="hljs-comment"># PyTorch version used</span>
   py_version=<span class="hljs-string">&#x27;py36&#x27;</span>,                                      <span class="hljs-comment"># Python version used</span>
)

<span class="hljs-comment"># deploy model to SageMaker Inference</span>
predictor = huggingface_model.deploy(
   initial_instance_count=<span class="hljs-number">1</span>,
   instance_type=<span class="hljs-string">&quot;ml.m5.xlarge&quot;</span>
)

<span class="hljs-comment"># example request: you always need to define &quot;inputs&quot;</span>
data = {
<span class="hljs-string">&quot;inputs&quot;</span>: {
	<span class="hljs-string">&quot;question&quot;</span>: <span class="hljs-string">&quot;What is used for inference?&quot;</span>,
	<span class="hljs-string">&quot;context&quot;</span>: <span class="hljs-string">&quot;My Name is Philipp and I live in Nuremberg. This model is used with sagemaker for inference.&quot;</span>
	}
}

<span class="hljs-comment"># request</span>
predictor.predict(data)`}}),yt=new E({props:{code:`# delete endpoint
predictor.delete_endpoint()`,highlighted:`<span class="hljs-comment"># delete endpoint</span>
predictor.delete_endpoint()`}}),wt=new ne({}),jt=new E({props:{code:`
`,highlighted:`batch_job = huggingface_estimator.transformer(
    instance_count=<span class="hljs-number">1</span>,
    instance_type=<span class="hljs-string">&#x27;ml.p3.2xlarge&#x27;</span>,
    strategy=<span class="hljs-string">&#x27;SingleRecord&#x27;</span>)


batch_job.transform(
    data=<span class="hljs-string">&#x27;s3://s3-uri-to-batch-data&#x27;</span>,
    content_type=<span class="hljs-string">&#x27;application/json&#x27;</span>,    
    split_type=<span class="hljs-string">&#x27;Line&#x27;</span>)`}}),St=new E({props:{code:`


`,highlighted:`<span class="hljs-keyword">from</span> sagemaker.huggingface.model <span class="hljs-keyword">import</span> HuggingFaceModel

<span class="hljs-comment"># Hub model configuration &lt;https://huggingface.co/models&gt;</span>
hub = {
	<span class="hljs-string">&#x27;HF_MODEL_ID&#x27;</span>:<span class="hljs-string">&#x27;distilbert-base-uncased-finetuned-sst-2-english&#x27;</span>,
	<span class="hljs-string">&#x27;HF_TASK&#x27;</span>:<span class="hljs-string">&#x27;text-classification&#x27;</span>
}

<span class="hljs-comment"># create Hugging Face Model Class</span>
huggingface_model = HuggingFaceModel(
   env=hub,                                                <span class="hljs-comment"># configuration for loading model from Hub</span>
   role=role,                                              <span class="hljs-comment"># IAM role with permissions to create an endpoint</span>
   transformers_version=<span class="hljs-string">&quot;4.6&quot;</span>,                             <span class="hljs-comment"># Transformers version used</span>
   pytorch_version=<span class="hljs-string">&quot;1.7&quot;</span>,                                  <span class="hljs-comment"># PyTorch version used</span>
   py_version=<span class="hljs-string">&#x27;py36&#x27;</span>,                                      <span class="hljs-comment"># Python version used</span>
)

<span class="hljs-comment"># create transformer to run a batch job</span>
batch_job = huggingface_model.transformer(
    instance_count=<span class="hljs-number">1</span>,
    instance_type=<span class="hljs-string">&#x27;ml.p3.2xlarge&#x27;</span>,
    strategy=<span class="hljs-string">&#x27;SingleRecord&#x27;</span>
)

<span class="hljs-comment"># starts batch transform job and uses S3 data as input</span>
batch_job.transform(
    data=<span class="hljs-string">&#x27;s3://sagemaker-s3-demo-test/samples/input.jsonl&#x27;</span>,
    content_type=<span class="hljs-string">&#x27;application/json&#x27;</span>,    
    split_type=<span class="hljs-string">&#x27;Line&#x27;</span>
)`}}),Dt=new E({props:{code:`{"inputs":"this movie is terrible"}
{"inputs":"this movie is amazing"}
{"inputs":"SageMaker is pretty cool"}
{"inputs":"SageMaker is pretty cool"}
{"inputs":"this movie is terrible"}
{"inputs":"this movie is amazing"}`,highlighted:`<span class="hljs-punctuation">{</span><span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;this movie is terrible&quot;</span><span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">{</span><span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;this movie is amazing&quot;</span><span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">{</span><span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;SageMaker is pretty cool&quot;</span><span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">{</span><span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;SageMaker is pretty cool&quot;</span><span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">{</span><span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;this movie is terrible&quot;</span><span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">{</span><span class="hljs-attr">&quot;inputs&quot;</span><span class="hljs-punctuation">:</span><span class="hljs-string">&quot;this movie is amazing&quot;</span><span class="hljs-punctuation">}</span>`}}),xt=new ne({}),Ct=new E({props:{code:`model.tar.gz/
|- pytorch_model.bin
|- ....
|- code/
  |- inference.py
  |- requirements.txt `,highlighted:`model.tar.gz/
|- pytorch_model.bin
|- ....
|- code/
  |- inference.py
  |- requirements.txt `}}),Mt=new E({props:{code:`

`,highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">model_fn</span>(<span class="hljs-params">model_dir</span>):
    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;model&quot;</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">input_fn</span>(<span class="hljs-params">data, content_type</span>):
    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;data&quot;</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">predict_fn</span>(<span class="hljs-params">data, model</span>):
    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;output&quot;</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">output_fn</span>(<span class="hljs-params">prediction, accept</span>):
    <span class="hljs-keyword">return</span> prediction`}}),At=new E({props:{code:"",highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">model_fn</span>(<span class="hljs-params">model_dir</span>):
    <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;loading model&quot;</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">transform_fn</span>(<span class="hljs-params">model, input_data, content_type, accept</span>):
    <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;output&quot;</span>`}}),{c(){K=l("meta"),_s=c(),Q=l("h1"),ie=l("a"),wo=l("span"),u(Fe.$$.fragment),hr=c(),$o=l("span"),_r=a("Deploy models to Amazon SageMaker"),gs=c(),Ht=l("p"),gr=a("Deploying a \u{1F917} Transformers models in SageMaker for inference is as easy as:"),vs=c(),u(Ne.$$.fragment),ys=c(),P=l("p"),vr=a("This guide will show you how to deploy models with zero-code using the "),Re=l("a"),yr=a("Inference Toolkit"),Er=a(". The Inference Toolkit builds on top of the "),pe=l("a"),ko=l("code"),wr=a("pipeline"),$r=a(" feature"),kr=a(" from \u{1F917} Transformers. Learn how to:"),Es=c(),k=l("ul"),Pt=l("li"),zt=l("a"),br=a("Install and setup the Inference Toolkit"),jr=a("."),Sr=c(),Lt=l("li"),Ft=l("a"),Dr=a("Deploy a \u{1F917} Transformers model trained in SageMaker"),qr=a("."),xr=c(),Nt=l("li"),Rt=l("a"),Cr=a("Deploy a \u{1F917} Transformers model from the Hugging Face [model Hub](https://huggingface.co/models)"),Tr=a("."),Or=c(),Ut=l("li"),Bt=l("a"),Mr=a("Run a Batch Transform Job using \u{1F917} Transformers and Amazon SageMaker"),Ar=a("."),Ir=c(),Yt=l("li"),Wt=l("a"),Hr=a("Create a custom inference module"),Pr=a("."),ws=c(),Z=l("h2"),ce=l("a"),bo=l("span"),u(Ue.$$.fragment),zr=c(),jo=l("span"),Lr=a("Installation and setup"),$s=c(),de=l("p"),Fr=a("Before deploying a \u{1F917} Transformers model to SageMaker, you need to sign up for an AWS account. If you don\u2019t have an AWS account yet, learn more "),Be=l("a"),Nr=a("here"),Rr=a("."),ks=c(),Gt=l("p"),Ur=a("Once you have an AWS account, get started using one of the following:"),bs=c(),z=l("ul"),So=l("li"),Ye=l("a"),Br=a("SageMaker Studio"),Yr=c(),Do=l("li"),We=l("a"),Wr=a("SageMaker notebook instance"),Gr=c(),qo=l("li"),Jr=a("Local environment"),js=c(),fe=l("p"),Kr=a("To start training locally, you need to setup an appropriate "),Ge=l("a"),Qr=a("IAM role"),Zr=a("."),Ss=c(),ue=l("p"),Vr=a("Upgrade to the latest "),xo=l("code"),Xr=a("sagemaker"),en=a(" version."),Ds=c(),u(Je.$$.fragment),qs=c(),Jt=l("p"),Co=l("strong"),tn=a("SageMaker environment"),xs=c(),Kt=l("p"),on=a("Setup your SageMaker environment as shown below:"),Cs=c(),u(Ke.$$.fragment),Ts=c(),Qt=l("p"),V=l("em"),an=a("Note: The execution role is only available when running a notebook within SageMaker. If you run "),To=l("code"),sn=a("get_execution_role"),ln=a(" in a notebook not on SageMaker, expect a "),Oo=l("code"),rn=a("region"),nn=a(" error."),Os=c(),Zt=l("p"),Mo=l("strong"),pn=a("Local environment"),Ms=c(),Vt=l("p"),cn=a("Setup your local environment as shown below:"),As=c(),u(Qe.$$.fragment),Is=c(),X=l("h2"),me=l("a"),Ao=l("span"),u(Ze.$$.fragment),dn=c(),Io=l("span"),fn=a("Deploy a \u{1F917} Transformers model trained in SageMaker"),Hs=c(),q=l("iframe"),Ps=c(),Xt=l("p"),un=a("There are two ways to deploy your Hugging Face model trained in SageMaker:"),zs=c(),he=l("ul"),Ho=l("li"),mn=a("Deploy it after your training has finished."),hn=c(),Ve=l("li"),_n=a("Deploy your saved model at a later time from S3 with the "),Po=l("code"),gn=a("model_data"),vn=a("."),Ls=c(),_e=l("p"),yn=a("\u{1F4D3} Open the "),Xe=l("a"),En=a("notebook"),wn=a(" for an example of how to deploy a model from S3 to SageMaker for inference."),Fs=c(),ee=l("h3"),ge=l("a"),zo=l("span"),u(et.$$.fragment),$n=c(),Lo=l("span"),kn=a("Deploy after training"),Ns=c(),eo=l("p"),bn=a("To deploy your model directly after training, ensure all required files are saved in your training script, including the tokenizer and the model."),Rs=c(),O=l("p"),jn=a("If you use the Hugging Face "),Fo=l("code"),Sn=a("Trainer"),Dn=a(", you can pass your tokenizer as an argument to the "),No=l("code"),qn=a("Trainer"),xn=a(". It will be automatically saved when you call "),Ro=l("code"),Cn=a("trainer.save_model()"),Tn=a("."),Us=c(),u(tt.$$.fragment),Bs=c(),to=l("p"),On=a("After you run your request you can delete the endpoint as shown:"),Ys=c(),u(ot.$$.fragment),Ws=c(),te=l("h3"),ve=l("a"),Uo=l("span"),u(at.$$.fragment),Mn=c(),oo=l("span"),An=a("Deploy with "),Bo=l("code"),In=a("model_data"),Gs=c(),ye=l("p"),Hn=a("If you\u2019ve already trained your model and want to deploy it at a later time, use the "),Yo=l("code"),Pn=a("model_data"),zn=a(" argument to specify the location of your tokenizer and model weights."),Js=c(),u(st.$$.fragment),Ks=c(),ao=l("p"),Ln=a("After you run our request, you can delete the endpoint again with:"),Qs=c(),u(lt.$$.fragment),Zs=c(),oe=l("h3"),Ee=l("a"),Wo=l("span"),u(rt.$$.fragment),Fn=c(),Go=l("span"),Nn=a("Create a model artifact for deployment"),Vs=c(),we=l("p"),Rn=a("For later deployment, you can create a "),Jo=l("code"),Un=a("model.tar.gz"),Bn=a(" file that contains all the required files, such as:"),Xs=c(),M=l("ul"),Ko=l("li"),Qo=l("code"),Yn=a("pytorch_model.bin"),Wn=c(),Zo=l("li"),Vo=l("code"),Gn=a("tf_model.h5"),Jn=c(),Xo=l("li"),ea=l("code"),Kn=a("tokenizer.json"),Qn=c(),ta=l("li"),oa=l("code"),Zn=a("tokenizer_config.json"),el=c(),so=l("p"),Vn=a("For example, your file should look like this:"),tl=c(),u(nt.$$.fragment),ol=c(),$e=l("p"),Xn=a("Create your own "),aa=l("code"),ei=a("model.tar.gz"),ti=a(" from a model from the \u{1F917} Hub:"),al=c(),lo=l("ol"),sa=l("li"),oi=a("Download a model:"),sl=c(),u(it.$$.fragment),ll=c(),pt=l("ol"),ct=l("li"),ai=a("Create a "),la=l("code"),si=a("tar"),li=a(" file:"),rl=c(),u(dt.$$.fragment),nl=c(),ft=l("ol"),ut=l("li"),ri=a("Upload "),ra=l("code"),ni=a("model.tar.gz"),ii=a(" to S3:"),il=c(),u(mt.$$.fragment),pl=c(),ke=l("p"),pi=a("Now you can provide the S3 URI to the "),na=l("code"),ci=a("model_data"),di=a(" argument to deploy your model later."),cl=c(),ae=l("h2"),be=l("a"),ia=l("span"),u(ht.$$.fragment),fi=c(),pa=l("span"),ui=a("Deploy a model from the \u{1F917} Hub"),dl=c(),x=l("iframe"),fl=c(),je=l("p"),mi=a("To deploy a model directly from the \u{1F917} Hub to SageMaker, define two environment variables when you create a "),ca=l("code"),hi=a("HuggingFaceModel"),_i=a(":"),ul=c(),Se=l("ul"),De=l("li"),da=l("code"),gi=a("HF_MODEL_ID"),vi=a(" defines the model ID which is automatically loaded from "),_t=l("a"),yi=a("huggingface.co/models"),Ei=a(" when you create a SageMaker endpoint. Access 10,000+ models on he \u{1F917} Hub through this environment variable."),wi=c(),L=l("li"),fa=l("code"),$i=a("HF_TASK"),ki=a(" defines the task for the \u{1F917} Transformers "),ua=l("code"),bi=a("pipeline"),ji=a(". A complete list of tasks can be found "),gt=l("a"),Si=a("here"),Di=a("."),ml=c(),u(vt.$$.fragment),hl=c(),ro=l("p"),qi=a("After you run our request, you can delete the endpoint again with:"),_l=c(),u(yt.$$.fragment),gl=c(),qe=l("p"),xi=a("\u{1F4D3} Open the "),Et=l("a"),Ci=a("notebook"),Ti=a(" for an example of how to deploy a model from the \u{1F917} Hub to SageMaker for inference."),vl=c(),se=l("h2"),xe=l("a"),ma=l("span"),u(wt.$$.fragment),Oi=c(),ha=l("span"),Mi=a("Run batch transform with \u{1F917} Transformers and SageMaker"),yl=c(),C=l("iframe"),El=c(),F=l("p"),Ai=a("After training a model, you can use "),$t=l("a"),Ii=a("SageMaker batch transform"),Hi=a(" to perform inference with the model. Batch transform accepts your inference data as an S3 URI  and then SageMaker will take care of downloading the data, running the prediction, and uploading the results to S3. For more details about batch transform, take a look "),kt=l("a"),Pi=a("here"),zi=a("."),wl=c(),Ce=l("p"),Li=a("\u26A0\uFE0F The Hugging Face Inference DLC currently only supports "),_a=l("code"),Fi=a(".jsonl"),Ni=a(" for batch transform due to the complex structure of textual data."),$l=c(),no=l("p"),le=l("em"),Ri=a("Note: Make sure your "),ga=l("code"),Ui=a("inputs"),Bi=a(" fit the "),va=l("code"),Yi=a("max_length"),Wi=a(" of the model during preprocessing."),kl=c(),N=l("p"),Gi=a("If you trained a model using the Hugging Face Estimator, call the "),ya=l("code"),Ji=a("transformer()"),Ki=a(" method to create a transform job for a model based on the training job (see "),bt=l("a"),Qi=a("here"),Zi=a(" for more details):"),bl=c(),u(jt.$$.fragment),jl=c(),R=l("p"),Vi=a("If you want to run your batch transform job later or with a model from the \u{1F917} Hub, create a "),Ea=l("code"),Xi=a("HuggingFaceModel"),ep=a(" instance and then call the "),wa=l("code"),tp=a("transformer()"),op=a(" method:"),Sl=c(),u(St.$$.fragment),Dl=c(),Te=l("p"),ap=a("The "),$a=l("code"),sp=a("input.jsonl"),lp=a(" looks like this:"),ql=c(),u(Dt.$$.fragment),xl=c(),Oe=l("p"),rp=a("\u{1F4D3} Open the "),qt=l("a"),np=a("notebook"),ip=a(" for an example of how to run a batch transform job for inference."),Cl=c(),re=l("h2"),Me=l("a"),ka=l("span"),u(xt.$$.fragment),pp=c(),ba=l("span"),cp=a("User defined code and modules"),Tl=c(),b=l("p"),dp=a("The Hugging Face Inference Toolkit allows the user to override the default methods of the "),ja=l("code"),fp=a("HuggingFaceHandlerService"),up=a(". You will need to create a folder named "),Sa=l("code"),mp=a("code/"),hp=a(" with an "),Da=l("code"),_p=a("inference.py"),gp=a(" file in it. See "),io=l("a"),vp=a("here"),yp=a(" for more details on how to archive your model artifacts. For example:"),Ol=c(),u(Ct.$$.fragment),Ml=c(),U=l("p"),Ep=a("The "),qa=l("code"),wp=a("inference.py"),$p=a(" file contains your custom inference module, and the "),xa=l("code"),kp=a("requirements.txt"),bp=a(" file contains additional dependencies that should be added. The custom module can override the following methods:"),Al=c(),j=l("ul"),$=l("li"),Ca=l("code"),jp=a("model_fn(model_dir)"),Sp=a(" overrides the default method for loading a model. The return value "),Ta=l("code"),Dp=a("model"),qp=a(" will be used in "),Oa=l("code"),xp=a("predict"),Cp=a(" for predictions. "),Ma=l("code"),Tp=a("predict"),Op=a(" receives argument the "),Aa=l("code"),Mp=a("model_dir"),Ap=a(", the path to your unzipped "),Ia=l("code"),Ip=a("model.tar.gz"),Hp=a("."),Pp=c(),y=l("li"),Ha=l("code"),zp=a("transform_fn(model, data, content_type, accept_type)"),Lp=a(" overrides the default transform function with your custom implementation. You will need to implement your own "),Pa=l("code"),Fp=a("preprocess"),Np=a(", "),za=l("code"),Rp=a("predict"),Up=a(" and "),La=l("code"),Bp=a("postprocess"),Yp=a(" steps in the "),Fa=l("code"),Wp=a("transform_fn"),Gp=a(". This method can\u2019t be combined with "),Na=l("code"),Jp=a("input_fn"),Kp=a(", "),Ra=l("code"),Qp=a("predict_fn"),Zp=a(" or "),Ua=l("code"),Vp=a("output_fn"),Xp=a(" mentioned below."),ec=c(),A=l("li"),Ba=l("code"),tc=a("input_fn(input_data, content_type)"),oc=a(" overrides the default method for preprocessing. The return value "),Ya=l("code"),ac=a("data"),sc=a(" will be used in "),Wa=l("code"),lc=a("predict"),rc=a(" for predicitions. The inputs are:"),Tt=l("ul"),po=l("li"),Ga=l("code"),nc=a("input_data"),ic=a(" is the raw body of your request."),pc=c(),co=l("li"),Ja=l("code"),cc=a("content_type"),dc=a(" is the content type from the request header."),fc=c(),S=l("li"),Ka=l("code"),uc=a("predict_fn(processed_data, model)"),mc=a(" overrides the default method for predictions. The return value "),Qa=l("code"),hc=a("predictions"),_c=a(" will be used in "),Za=l("code"),gc=a("postprocess"),vc=a(". The input is "),Va=l("code"),yc=a("processed_data"),Ec=a(", the result from "),Xa=l("code"),wc=a("preprocess"),$c=a("."),kc=c(),I=l("li"),es=l("code"),bc=a("output_fn(prediction, accept)"),jc=a(" overrides the default method for postprocessing. The return value "),ts=l("code"),Sc=a("result"),Dc=a(" will be the response of your request (e.g."),os=l("code"),qc=a("JSON"),xc=a("). The inputs are:"),Ot=l("ul"),Ae=l("li"),as=l("code"),Cc=a("predictions"),Tc=a(" is the result from "),ss=l("code"),Oc=a("predict"),Mc=a("."),Ac=c(),Ie=l("li"),ls=l("code"),Ic=a("accept"),Hc=a(" is the return accept type from the HTTP Request, e.g. "),rs=l("code"),Pc=a("application/json"),zc=a("."),Il=c(),D=l("p"),Lc=a("Here is an example of a custom inference module with "),ns=l("code"),Fc=a("model_fn"),Nc=a(", "),is=l("code"),Rc=a("input_fn"),Uc=a(", "),ps=l("code"),Bc=a("predict_fn"),Yc=a(", and "),cs=l("code"),Wc=a("output_fn"),Gc=a(":"),Hl=c(),u(Mt.$$.fragment),Pl=c(),B=l("p"),Jc=a("Customize your inference module with only "),ds=l("code"),Kc=a("model_fn"),Qc=a(" and "),fs=l("code"),Zc=a("transform_fn"),Vc=a(":"),zl=c(),u(At.$$.fragment),this.h()},l(e){const i=em('[data-svelte="svelte-1phssyn"]',document.head);K=r(i,"META",{name:!0,content:!0}),i.forEach(o),_s=d(e),Q=r(e,"H1",{class:!0});var Fl=n(Q);ie=r(Fl,"A",{id:!0,class:!0,href:!0});var ud=n(ie);wo=r(ud,"SPAN",{});var md=n(wo);m(Fe.$$.fragment,md),md.forEach(o),ud.forEach(o),hr=d(Fl),$o=r(Fl,"SPAN",{});var hd=n($o);_r=s(hd,"Deploy models to Amazon SageMaker"),hd.forEach(o),Fl.forEach(o),gs=d(e),Ht=r(e,"P",{});var _d=n(Ht);gr=s(_d,"Deploying a \u{1F917} Transformers models in SageMaker for inference is as easy as:"),_d.forEach(o),vs=d(e),m(Ne.$$.fragment,e),ys=d(e),P=r(e,"P",{});var fo=n(P);vr=s(fo,"This guide will show you how to deploy models with zero-code using the "),Re=r(fo,"A",{href:!0,rel:!0});var gd=n(Re);yr=s(gd,"Inference Toolkit"),gd.forEach(o),Er=s(fo,". The Inference Toolkit builds on top of the "),pe=r(fo,"A",{href:!0,rel:!0});var Xc=n(pe);ko=r(Xc,"CODE",{});var vd=n(ko);wr=s(vd,"pipeline"),vd.forEach(o),$r=s(Xc," feature"),Xc.forEach(o),kr=s(fo," from \u{1F917} Transformers. Learn how to:"),fo.forEach(o),Es=d(e),k=r(e,"UL",{});var Y=n(k);Pt=r(Y,"LI",{});var ed=n(Pt);zt=r(ed,"A",{href:!0});var yd=n(zt);br=s(yd,"Install and setup the Inference Toolkit"),yd.forEach(o),jr=s(ed,"."),ed.forEach(o),Sr=d(Y),Lt=r(Y,"LI",{});var td=n(Lt);Ft=r(td,"A",{href:!0});var Ed=n(Ft);Dr=s(Ed,"Deploy a \u{1F917} Transformers model trained in SageMaker"),Ed.forEach(o),qr=s(td,"."),td.forEach(o),xr=d(Y),Nt=r(Y,"LI",{});var od=n(Nt);Rt=r(od,"A",{href:!0});var wd=n(Rt);Cr=s(wd,"Deploy a \u{1F917} Transformers model from the Hugging Face [model Hub](https://huggingface.co/models)"),wd.forEach(o),Tr=s(od,"."),od.forEach(o),Or=d(Y),Ut=r(Y,"LI",{});var ad=n(Ut);Bt=r(ad,"A",{href:!0});var $d=n(Bt);Mr=s($d,"Run a Batch Transform Job using \u{1F917} Transformers and Amazon SageMaker"),$d.forEach(o),Ar=s(ad,"."),ad.forEach(o),Ir=d(Y),Yt=r(Y,"LI",{});var sd=n(Yt);Wt=r(sd,"A",{href:!0});var kd=n(Wt);Hr=s(kd,"Create a custom inference module"),kd.forEach(o),Pr=s(sd,"."),sd.forEach(o),Y.forEach(o),ws=d(e),Z=r(e,"H2",{class:!0});var Nl=n(Z);ce=r(Nl,"A",{id:!0,class:!0,href:!0});var bd=n(ce);bo=r(bd,"SPAN",{});var jd=n(bo);m(Ue.$$.fragment,jd),jd.forEach(o),bd.forEach(o),zr=d(Nl),jo=r(Nl,"SPAN",{});var Sd=n(jo);Lr=s(Sd,"Installation and setup"),Sd.forEach(o),Nl.forEach(o),$s=d(e),de=r(e,"P",{});var Rl=n(de);Fr=s(Rl,"Before deploying a \u{1F917} Transformers model to SageMaker, you need to sign up for an AWS account. If you don\u2019t have an AWS account yet, learn more "),Be=r(Rl,"A",{href:!0,rel:!0});var Dd=n(Be);Nr=s(Dd,"here"),Dd.forEach(o),Rr=s(Rl,"."),Rl.forEach(o),ks=d(e),Gt=r(e,"P",{});var qd=n(Gt);Ur=s(qd,"Once you have an AWS account, get started using one of the following:"),qd.forEach(o),bs=d(e),z=r(e,"UL",{});var uo=n(z);So=r(uo,"LI",{});var xd=n(So);Ye=r(xd,"A",{href:!0,rel:!0});var Cd=n(Ye);Br=s(Cd,"SageMaker Studio"),Cd.forEach(o),xd.forEach(o),Yr=d(uo),Do=r(uo,"LI",{});var Td=n(Do);We=r(Td,"A",{href:!0,rel:!0});var Od=n(We);Wr=s(Od,"SageMaker notebook instance"),Od.forEach(o),Td.forEach(o),Gr=d(uo),qo=r(uo,"LI",{});var Md=n(qo);Jr=s(Md,"Local environment"),Md.forEach(o),uo.forEach(o),js=d(e),fe=r(e,"P",{});var Ul=n(fe);Kr=s(Ul,"To start training locally, you need to setup an appropriate "),Ge=r(Ul,"A",{href:!0,rel:!0});var Ad=n(Ge);Qr=s(Ad,"IAM role"),Ad.forEach(o),Zr=s(Ul,"."),Ul.forEach(o),Ss=d(e),ue=r(e,"P",{});var Bl=n(ue);Vr=s(Bl,"Upgrade to the latest "),xo=r(Bl,"CODE",{});var Id=n(xo);Xr=s(Id,"sagemaker"),Id.forEach(o),en=s(Bl," version."),Bl.forEach(o),Ds=d(e),m(Je.$$.fragment,e),qs=d(e),Jt=r(e,"P",{});var Hd=n(Jt);Co=r(Hd,"STRONG",{});var Pd=n(Co);tn=s(Pd,"SageMaker environment"),Pd.forEach(o),Hd.forEach(o),xs=d(e),Kt=r(e,"P",{});var zd=n(Kt);on=s(zd,"Setup your SageMaker environment as shown below:"),zd.forEach(o),Cs=d(e),m(Ke.$$.fragment,e),Ts=d(e),Qt=r(e,"P",{});var Ld=n(Qt);V=r(Ld,"EM",{});var mo=n(V);an=s(mo,"Note: The execution role is only available when running a notebook within SageMaker. If you run "),To=r(mo,"CODE",{});var Fd=n(To);sn=s(Fd,"get_execution_role"),Fd.forEach(o),ln=s(mo," in a notebook not on SageMaker, expect a "),Oo=r(mo,"CODE",{});var Nd=n(Oo);rn=s(Nd,"region"),Nd.forEach(o),nn=s(mo," error."),mo.forEach(o),Ld.forEach(o),Os=d(e),Zt=r(e,"P",{});var Rd=n(Zt);Mo=r(Rd,"STRONG",{});var Ud=n(Mo);pn=s(Ud,"Local environment"),Ud.forEach(o),Rd.forEach(o),Ms=d(e),Vt=r(e,"P",{});var Bd=n(Vt);cn=s(Bd,"Setup your local environment as shown below:"),Bd.forEach(o),As=d(e),m(Qe.$$.fragment,e),Is=d(e),X=r(e,"H2",{class:!0});var Yl=n(X);me=r(Yl,"A",{id:!0,class:!0,href:!0});var Yd=n(me);Ao=r(Yd,"SPAN",{});var Wd=n(Ao);m(Ze.$$.fragment,Wd),Wd.forEach(o),Yd.forEach(o),dn=d(Yl),Io=r(Yl,"SPAN",{});var Gd=n(Io);fn=s(Gd,"Deploy a \u{1F917} Transformers model trained in SageMaker"),Gd.forEach(o),Yl.forEach(o),Hs=d(e),q=r(e,"IFRAME",{width:!0,height:!0,src:!0,title:!0,frameborder:!0,allow:!0}),n(q).forEach(o),Ps=d(e),Xt=r(e,"P",{});var Jd=n(Xt);un=s(Jd,"There are two ways to deploy your Hugging Face model trained in SageMaker:"),Jd.forEach(o),zs=d(e),he=r(e,"UL",{});var Wl=n(he);Ho=r(Wl,"LI",{});var Kd=n(Ho);mn=s(Kd,"Deploy it after your training has finished."),Kd.forEach(o),hn=d(Wl),Ve=r(Wl,"LI",{});var Gl=n(Ve);_n=s(Gl,"Deploy your saved model at a later time from S3 with the "),Po=r(Gl,"CODE",{});var Qd=n(Po);gn=s(Qd,"model_data"),Qd.forEach(o),vn=s(Gl,"."),Gl.forEach(o),Wl.forEach(o),Ls=d(e),_e=r(e,"P",{});var Jl=n(_e);yn=s(Jl,"\u{1F4D3} Open the "),Xe=r(Jl,"A",{href:!0,rel:!0});var Zd=n(Xe);En=s(Zd,"notebook"),Zd.forEach(o),wn=s(Jl," for an example of how to deploy a model from S3 to SageMaker for inference."),Jl.forEach(o),Fs=d(e),ee=r(e,"H3",{class:!0});var Kl=n(ee);ge=r(Kl,"A",{id:!0,class:!0,href:!0});var Vd=n(ge);zo=r(Vd,"SPAN",{});var Xd=n(zo);m(et.$$.fragment,Xd),Xd.forEach(o),Vd.forEach(o),$n=d(Kl),Lo=r(Kl,"SPAN",{});var ef=n(Lo);kn=s(ef,"Deploy after training"),ef.forEach(o),Kl.forEach(o),Ns=d(e),eo=r(e,"P",{});var tf=n(eo);bn=s(tf,"To deploy your model directly after training, ensure all required files are saved in your training script, including the tokenizer and the model."),tf.forEach(o),Rs=d(e),O=r(e,"P",{});var He=n(O);jn=s(He,"If you use the Hugging Face "),Fo=r(He,"CODE",{});var of=n(Fo);Sn=s(of,"Trainer"),of.forEach(o),Dn=s(He,", you can pass your tokenizer as an argument to the "),No=r(He,"CODE",{});var af=n(No);qn=s(af,"Trainer"),af.forEach(o),xn=s(He,". It will be automatically saved when you call "),Ro=r(He,"CODE",{});var sf=n(Ro);Cn=s(sf,"trainer.save_model()"),sf.forEach(o),Tn=s(He,"."),He.forEach(o),Us=d(e),m(tt.$$.fragment,e),Bs=d(e),to=r(e,"P",{});var lf=n(to);On=s(lf,"After you run your request you can delete the endpoint as shown:"),lf.forEach(o),Ys=d(e),m(ot.$$.fragment,e),Ws=d(e),te=r(e,"H3",{class:!0});var Ql=n(te);ve=r(Ql,"A",{id:!0,class:!0,href:!0});var rf=n(ve);Uo=r(rf,"SPAN",{});var nf=n(Uo);m(at.$$.fragment,nf),nf.forEach(o),rf.forEach(o),Mn=d(Ql),oo=r(Ql,"SPAN",{});var ld=n(oo);An=s(ld,"Deploy with "),Bo=r(ld,"CODE",{});var pf=n(Bo);In=s(pf,"model_data"),pf.forEach(o),ld.forEach(o),Ql.forEach(o),Gs=d(e),ye=r(e,"P",{});var Zl=n(ye);Hn=s(Zl,"If you\u2019ve already trained your model and want to deploy it at a later time, use the "),Yo=r(Zl,"CODE",{});var cf=n(Yo);Pn=s(cf,"model_data"),cf.forEach(o),zn=s(Zl," argument to specify the location of your tokenizer and model weights."),Zl.forEach(o),Js=d(e),m(st.$$.fragment,e),Ks=d(e),ao=r(e,"P",{});var df=n(ao);Ln=s(df,"After you run our request, you can delete the endpoint again with:"),df.forEach(o),Qs=d(e),m(lt.$$.fragment,e),Zs=d(e),oe=r(e,"H3",{class:!0});var Vl=n(oe);Ee=r(Vl,"A",{id:!0,class:!0,href:!0});var ff=n(Ee);Wo=r(ff,"SPAN",{});var uf=n(Wo);m(rt.$$.fragment,uf),uf.forEach(o),ff.forEach(o),Fn=d(Vl),Go=r(Vl,"SPAN",{});var mf=n(Go);Nn=s(mf,"Create a model artifact for deployment"),mf.forEach(o),Vl.forEach(o),Vs=d(e),we=r(e,"P",{});var Xl=n(we);Rn=s(Xl,"For later deployment, you can create a "),Jo=r(Xl,"CODE",{});var hf=n(Jo);Un=s(hf,"model.tar.gz"),hf.forEach(o),Bn=s(Xl," file that contains all the required files, such as:"),Xl.forEach(o),Xs=d(e),M=r(e,"UL",{});var Pe=n(M);Ko=r(Pe,"LI",{});var _f=n(Ko);Qo=r(_f,"CODE",{});var gf=n(Qo);Yn=s(gf,"pytorch_model.bin"),gf.forEach(o),_f.forEach(o),Wn=d(Pe),Zo=r(Pe,"LI",{});var vf=n(Zo);Vo=r(vf,"CODE",{});var yf=n(Vo);Gn=s(yf,"tf_model.h5"),yf.forEach(o),vf.forEach(o),Jn=d(Pe),Xo=r(Pe,"LI",{});var Ef=n(Xo);ea=r(Ef,"CODE",{});var wf=n(ea);Kn=s(wf,"tokenizer.json"),wf.forEach(o),Ef.forEach(o),Qn=d(Pe),ta=r(Pe,"LI",{});var $f=n(ta);oa=r($f,"CODE",{});var kf=n(oa);Zn=s(kf,"tokenizer_config.json"),kf.forEach(o),$f.forEach(o),Pe.forEach(o),el=d(e),so=r(e,"P",{});var bf=n(so);Vn=s(bf,"For example, your file should look like this:"),bf.forEach(o),tl=d(e),m(nt.$$.fragment,e),ol=d(e),$e=r(e,"P",{});var er=n($e);Xn=s(er,"Create your own "),aa=r(er,"CODE",{});var jf=n(aa);ei=s(jf,"model.tar.gz"),jf.forEach(o),ti=s(er," from a model from the \u{1F917} Hub:"),er.forEach(o),al=d(e),lo=r(e,"OL",{});var Sf=n(lo);sa=r(Sf,"LI",{});var Df=n(sa);oi=s(Df,"Download a model:"),Df.forEach(o),Sf.forEach(o),sl=d(e),m(it.$$.fragment,e),ll=d(e),pt=r(e,"OL",{start:!0});var qf=n(pt);ct=r(qf,"LI",{});var tr=n(ct);ai=s(tr,"Create a "),la=r(tr,"CODE",{});var xf=n(la);si=s(xf,"tar"),xf.forEach(o),li=s(tr," file:"),tr.forEach(o),qf.forEach(o),rl=d(e),m(dt.$$.fragment,e),nl=d(e),ft=r(e,"OL",{start:!0});var Cf=n(ft);ut=r(Cf,"LI",{});var or=n(ut);ri=s(or,"Upload "),ra=r(or,"CODE",{});var Tf=n(ra);ni=s(Tf,"model.tar.gz"),Tf.forEach(o),ii=s(or," to S3:"),or.forEach(o),Cf.forEach(o),il=d(e),m(mt.$$.fragment,e),pl=d(e),ke=r(e,"P",{});var ar=n(ke);pi=s(ar,"Now you can provide the S3 URI to the "),na=r(ar,"CODE",{});var Of=n(na);ci=s(Of,"model_data"),Of.forEach(o),di=s(ar," argument to deploy your model later."),ar.forEach(o),cl=d(e),ae=r(e,"H2",{class:!0});var sr=n(ae);be=r(sr,"A",{id:!0,class:!0,href:!0});var Mf=n(be);ia=r(Mf,"SPAN",{});var Af=n(ia);m(ht.$$.fragment,Af),Af.forEach(o),Mf.forEach(o),fi=d(sr),pa=r(sr,"SPAN",{});var If=n(pa);ui=s(If,"Deploy a model from the \u{1F917} Hub"),If.forEach(o),sr.forEach(o),dl=d(e),x=r(e,"IFRAME",{width:!0,height:!0,src:!0,title:!0,frameborder:!0,allow:!0}),n(x).forEach(o),fl=d(e),je=r(e,"P",{});var lr=n(je);mi=s(lr,"To deploy a model directly from the \u{1F917} Hub to SageMaker, define two environment variables when you create a "),ca=r(lr,"CODE",{});var Hf=n(ca);hi=s(Hf,"HuggingFaceModel"),Hf.forEach(o),_i=s(lr,":"),lr.forEach(o),ul=d(e),Se=r(e,"UL",{});var rr=n(Se);De=r(rr,"LI",{});var us=n(De);da=r(us,"CODE",{});var Pf=n(da);gi=s(Pf,"HF_MODEL_ID"),Pf.forEach(o),vi=s(us," defines the model ID which is automatically loaded from "),_t=r(us,"A",{href:!0,rel:!0});var zf=n(_t);yi=s(zf,"huggingface.co/models"),zf.forEach(o),Ei=s(us," when you create a SageMaker endpoint. Access 10,000+ models on he \u{1F917} Hub through this environment variable."),us.forEach(o),wi=d(rr),L=r(rr,"LI",{});var It=n(L);fa=r(It,"CODE",{});var Lf=n(fa);$i=s(Lf,"HF_TASK"),Lf.forEach(o),ki=s(It," defines the task for the \u{1F917} Transformers "),ua=r(It,"CODE",{});var Ff=n(ua);bi=s(Ff,"pipeline"),Ff.forEach(o),ji=s(It,". A complete list of tasks can be found "),gt=r(It,"A",{href:!0,rel:!0});var Nf=n(gt);Si=s(Nf,"here"),Nf.forEach(o),Di=s(It,"."),It.forEach(o),rr.forEach(o),ml=d(e),m(vt.$$.fragment,e),hl=d(e),ro=r(e,"P",{});var Rf=n(ro);qi=s(Rf,"After you run our request, you can delete the endpoint again with:"),Rf.forEach(o),_l=d(e),m(yt.$$.fragment,e),gl=d(e),qe=r(e,"P",{});var nr=n(qe);xi=s(nr,"\u{1F4D3} Open the "),Et=r(nr,"A",{href:!0,rel:!0});var Uf=n(Et);Ci=s(Uf,"notebook"),Uf.forEach(o),Ti=s(nr," for an example of how to deploy a model from the \u{1F917} Hub to SageMaker for inference."),nr.forEach(o),vl=d(e),se=r(e,"H2",{class:!0});var ir=n(se);xe=r(ir,"A",{id:!0,class:!0,href:!0});var Bf=n(xe);ma=r(Bf,"SPAN",{});var Yf=n(ma);m(wt.$$.fragment,Yf),Yf.forEach(o),Bf.forEach(o),Oi=d(ir),ha=r(ir,"SPAN",{});var Wf=n(ha);Mi=s(Wf,"Run batch transform with \u{1F917} Transformers and SageMaker"),Wf.forEach(o),ir.forEach(o),yl=d(e),C=r(e,"IFRAME",{width:!0,height:!0,src:!0,title:!0,frameborder:!0,allow:!0}),n(C).forEach(o),El=d(e),F=r(e,"P",{});var ho=n(F);Ai=s(ho,"After training a model, you can use "),$t=r(ho,"A",{href:!0,rel:!0});var Gf=n($t);Ii=s(Gf,"SageMaker batch transform"),Gf.forEach(o),Hi=s(ho," to perform inference with the model. Batch transform accepts your inference data as an S3 URI  and then SageMaker will take care of downloading the data, running the prediction, and uploading the results to S3. For more details about batch transform, take a look "),kt=r(ho,"A",{href:!0,rel:!0});var Jf=n(kt);Pi=s(Jf,"here"),Jf.forEach(o),zi=s(ho,"."),ho.forEach(o),wl=d(e),Ce=r(e,"P",{});var pr=n(Ce);Li=s(pr,"\u26A0\uFE0F The Hugging Face Inference DLC currently only supports "),_a=r(pr,"CODE",{});var Kf=n(_a);Fi=s(Kf,".jsonl"),Kf.forEach(o),Ni=s(pr," for batch transform due to the complex structure of textual data."),pr.forEach(o),$l=d(e),no=r(e,"P",{});var Qf=n(no);le=r(Qf,"EM",{});var _o=n(le);Ri=s(_o,"Note: Make sure your "),ga=r(_o,"CODE",{});var Zf=n(ga);Ui=s(Zf,"inputs"),Zf.forEach(o),Bi=s(_o," fit the "),va=r(_o,"CODE",{});var Vf=n(va);Yi=s(Vf,"max_length"),Vf.forEach(o),Wi=s(_o," of the model during preprocessing."),_o.forEach(o),Qf.forEach(o),kl=d(e),N=r(e,"P",{});var go=n(N);Gi=s(go,"If you trained a model using the Hugging Face Estimator, call the "),ya=r(go,"CODE",{});var Xf=n(ya);Ji=s(Xf,"transformer()"),Xf.forEach(o),Ki=s(go," method to create a transform job for a model based on the training job (see "),bt=r(go,"A",{href:!0,rel:!0});var eu=n(bt);Qi=s(eu,"here"),eu.forEach(o),Zi=s(go," for more details):"),go.forEach(o),bl=d(e),m(jt.$$.fragment,e),jl=d(e),R=r(e,"P",{});var vo=n(R);Vi=s(vo,"If you want to run your batch transform job later or with a model from the \u{1F917} Hub, create a "),Ea=r(vo,"CODE",{});var tu=n(Ea);Xi=s(tu,"HuggingFaceModel"),tu.forEach(o),ep=s(vo," instance and then call the "),wa=r(vo,"CODE",{});var ou=n(wa);tp=s(ou,"transformer()"),ou.forEach(o),op=s(vo," method:"),vo.forEach(o),Sl=d(e),m(St.$$.fragment,e),Dl=d(e),Te=r(e,"P",{});var cr=n(Te);ap=s(cr,"The "),$a=r(cr,"CODE",{});var au=n($a);sp=s(au,"input.jsonl"),au.forEach(o),lp=s(cr," looks like this:"),cr.forEach(o),ql=d(e),m(Dt.$$.fragment,e),xl=d(e),Oe=r(e,"P",{});var dr=n(Oe);rp=s(dr,"\u{1F4D3} Open the "),qt=r(dr,"A",{href:!0,rel:!0});var su=n(qt);np=s(su,"notebook"),su.forEach(o),ip=s(dr," for an example of how to run a batch transform job for inference."),dr.forEach(o),Cl=d(e),re=r(e,"H2",{class:!0});var fr=n(re);Me=r(fr,"A",{id:!0,class:!0,href:!0});var lu=n(Me);ka=r(lu,"SPAN",{});var ru=n(ka);m(xt.$$.fragment,ru),ru.forEach(o),lu.forEach(o),pp=d(fr),ba=r(fr,"SPAN",{});var nu=n(ba);cp=s(nu,"User defined code and modules"),nu.forEach(o),fr.forEach(o),Tl=d(e),b=r(e,"P",{});var W=n(b);dp=s(W,"The Hugging Face Inference Toolkit allows the user to override the default methods of the "),ja=r(W,"CODE",{});var iu=n(ja);fp=s(iu,"HuggingFaceHandlerService"),iu.forEach(o),up=s(W,". You will need to create a folder named "),Sa=r(W,"CODE",{});var pu=n(Sa);mp=s(pu,"code/"),pu.forEach(o),hp=s(W," with an "),Da=r(W,"CODE",{});var cu=n(Da);_p=s(cu,"inference.py"),cu.forEach(o),gp=s(W," file in it. See "),io=r(W,"A",{href:!0});var du=n(io);vp=s(du,"here"),du.forEach(o),yp=s(W," for more details on how to archive your model artifacts. For example:"),W.forEach(o),Ol=d(e),m(Ct.$$.fragment,e),Ml=d(e),U=r(e,"P",{});var yo=n(U);Ep=s(yo,"The "),qa=r(yo,"CODE",{});var fu=n(qa);wp=s(fu,"inference.py"),fu.forEach(o),$p=s(yo," file contains your custom inference module, and the "),xa=r(yo,"CODE",{});var uu=n(xa);kp=s(uu,"requirements.txt"),uu.forEach(o),bp=s(yo," file contains additional dependencies that should be added. The custom module can override the following methods:"),yo.forEach(o),Al=d(e),j=r(e,"UL",{});var G=n(j);$=r(G,"LI",{});var T=n($);Ca=r(T,"CODE",{});var mu=n(Ca);jp=s(mu,"model_fn(model_dir)"),mu.forEach(o),Sp=s(T," overrides the default method for loading a model. The return value "),Ta=r(T,"CODE",{});var hu=n(Ta);Dp=s(hu,"model"),hu.forEach(o),qp=s(T," will be used in "),Oa=r(T,"CODE",{});var _u=n(Oa);xp=s(_u,"predict"),_u.forEach(o),Cp=s(T," for predictions. "),Ma=r(T,"CODE",{});var gu=n(Ma);Tp=s(gu,"predict"),gu.forEach(o),Op=s(T," receives argument the "),Aa=r(T,"CODE",{});var vu=n(Aa);Mp=s(vu,"model_dir"),vu.forEach(o),Ap=s(T,", the path to your unzipped "),Ia=r(T,"CODE",{});var yu=n(Ia);Ip=s(yu,"model.tar.gz"),yu.forEach(o),Hp=s(T,"."),T.forEach(o),Pp=d(G),y=r(G,"LI",{});var w=n(y);Ha=r(w,"CODE",{});var Eu=n(Ha);zp=s(Eu,"transform_fn(model, data, content_type, accept_type)"),Eu.forEach(o),Lp=s(w," overrides the default transform function with your custom implementation. You will need to implement your own "),Pa=r(w,"CODE",{});var wu=n(Pa);Fp=s(wu,"preprocess"),wu.forEach(o),Np=s(w,", "),za=r(w,"CODE",{});var $u=n(za);Rp=s($u,"predict"),$u.forEach(o),Up=s(w," and "),La=r(w,"CODE",{});var ku=n(La);Bp=s(ku,"postprocess"),ku.forEach(o),Yp=s(w," steps in the "),Fa=r(w,"CODE",{});var bu=n(Fa);Wp=s(bu,"transform_fn"),bu.forEach(o),Gp=s(w,". This method can\u2019t be combined with "),Na=r(w,"CODE",{});var ju=n(Na);Jp=s(ju,"input_fn"),ju.forEach(o),Kp=s(w,", "),Ra=r(w,"CODE",{});var Su=n(Ra);Qp=s(Su,"predict_fn"),Su.forEach(o),Zp=s(w," or "),Ua=r(w,"CODE",{});var Du=n(Ua);Vp=s(Du,"output_fn"),Du.forEach(o),Xp=s(w," mentioned below."),w.forEach(o),ec=d(G),A=r(G,"LI",{});var ze=n(A);Ba=r(ze,"CODE",{});var qu=n(Ba);tc=s(qu,"input_fn(input_data, content_type)"),qu.forEach(o),oc=s(ze," overrides the default method for preprocessing. The return value "),Ya=r(ze,"CODE",{});var xu=n(Ya);ac=s(xu,"data"),xu.forEach(o),sc=s(ze," will be used in "),Wa=r(ze,"CODE",{});var Cu=n(Wa);lc=s(Cu,"predict"),Cu.forEach(o),rc=s(ze," for predicitions. The inputs are:"),Tt=r(ze,"UL",{});var ur=n(Tt);po=r(ur,"LI",{});var rd=n(po);Ga=r(rd,"CODE",{});var Tu=n(Ga);nc=s(Tu,"input_data"),Tu.forEach(o),ic=s(rd," is the raw body of your request."),rd.forEach(o),pc=d(ur),co=r(ur,"LI",{});var nd=n(co);Ja=r(nd,"CODE",{});var Ou=n(Ja);cc=s(Ou,"content_type"),Ou.forEach(o),dc=s(nd," is the content type from the request header."),nd.forEach(o),ur.forEach(o),ze.forEach(o),fc=d(G),S=r(G,"LI",{});var H=n(S);Ka=r(H,"CODE",{});var Mu=n(Ka);uc=s(Mu,"predict_fn(processed_data, model)"),Mu.forEach(o),mc=s(H," overrides the default method for predictions. The return value "),Qa=r(H,"CODE",{});var Au=n(Qa);hc=s(Au,"predictions"),Au.forEach(o),_c=s(H," will be used in "),Za=r(H,"CODE",{});var Iu=n(Za);gc=s(Iu,"postprocess"),Iu.forEach(o),vc=s(H,". The input is "),Va=r(H,"CODE",{});var Hu=n(Va);yc=s(Hu,"processed_data"),Hu.forEach(o),Ec=s(H,", the result from "),Xa=r(H,"CODE",{});var Pu=n(Xa);wc=s(Pu,"preprocess"),Pu.forEach(o),$c=s(H,"."),H.forEach(o),kc=d(G),I=r(G,"LI",{});var Le=n(I);es=r(Le,"CODE",{});var zu=n(es);bc=s(zu,"output_fn(prediction, accept)"),zu.forEach(o),jc=s(Le," overrides the default method for postprocessing. The return value "),ts=r(Le,"CODE",{});var Lu=n(ts);Sc=s(Lu,"result"),Lu.forEach(o),Dc=s(Le," will be the response of your request (e.g."),os=r(Le,"CODE",{});var Fu=n(os);qc=s(Fu,"JSON"),Fu.forEach(o),xc=s(Le,"). The inputs are:"),Ot=r(Le,"UL",{});var mr=n(Ot);Ae=r(mr,"LI",{});var ms=n(Ae);as=r(ms,"CODE",{});var Nu=n(as);Cc=s(Nu,"predictions"),Nu.forEach(o),Tc=s(ms," is the result from "),ss=r(ms,"CODE",{});var Ru=n(ss);Oc=s(Ru,"predict"),Ru.forEach(o),Mc=s(ms,"."),ms.forEach(o),Ac=d(mr),Ie=r(mr,"LI",{});var hs=n(Ie);ls=r(hs,"CODE",{});var Uu=n(ls);Ic=s(Uu,"accept"),Uu.forEach(o),Hc=s(hs," is the return accept type from the HTTP Request, e.g. "),rs=r(hs,"CODE",{});var Bu=n(rs);Pc=s(Bu,"application/json"),Bu.forEach(o),zc=s(hs,"."),hs.forEach(o),mr.forEach(o),Le.forEach(o),G.forEach(o),Il=d(e),D=r(e,"P",{});var J=n(D);Lc=s(J,"Here is an example of a custom inference module with "),ns=r(J,"CODE",{});var Yu=n(ns);Fc=s(Yu,"model_fn"),Yu.forEach(o),Nc=s(J,", "),is=r(J,"CODE",{});var Wu=n(is);Rc=s(Wu,"input_fn"),Wu.forEach(o),Uc=s(J,", "),ps=r(J,"CODE",{});var Gu=n(ps);Bc=s(Gu,"predict_fn"),Gu.forEach(o),Yc=s(J,", and "),cs=r(J,"CODE",{});var Ju=n(cs);Wc=s(Ju,"output_fn"),Ju.forEach(o),Gc=s(J,":"),J.forEach(o),Hl=d(e),m(Mt.$$.fragment,e),Pl=d(e),B=r(e,"P",{});var Eo=n(B);Jc=s(Eo,"Customize your inference module with only "),ds=r(Eo,"CODE",{});var Ku=n(ds);Kc=s(Ku,"model_fn"),Ku.forEach(o),Qc=s(Eo," and "),fs=r(Eo,"CODE",{});var Qu=n(fs);Zc=s(Qu,"transform_fn"),Qu.forEach(o),Vc=s(Eo,":"),Eo.forEach(o),zl=d(e),m(At.$$.fragment,e),this.h()},h(){f(K,"name","hf:doc:metadata"),f(K,"content",JSON.stringify(sm)),f(ie,"id","deploy-models-to-amazon-sagemaker"),f(ie,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ie,"href","#deploy-models-to-amazon-sagemaker"),f(Q,"class","relative group"),f(Re,"href","https://github.com/aws/sagemaker-huggingface-inference-toolkit"),f(Re,"rel","nofollow"),f(pe,"href","https://huggingface.co/transformers/main_classes/pipelines.html"),f(pe,"rel","nofollow"),f(zt,"href","#installation-and-setup"),f(Ft,"href","#deploy-a-transformer-model-trained-in-sagemaker"),f(Rt,"href","#deploy-a-model-from-the-hub"),f(Bt,"href","#run-batch-transform-with-transformers-and-sagemaker"),f(Wt,"href","#user-defined-code-and-modules"),f(ce,"id","installation-and-setup"),f(ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ce,"href","#installation-and-setup"),f(Z,"class","relative group"),f(Be,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/gs-set-up.html"),f(Be,"rel","nofollow"),f(Ye,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.html"),f(Ye,"rel","nofollow"),f(We,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/gs-console.html"),f(We,"rel","nofollow"),f(Ge,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html"),f(Ge,"rel","nofollow"),f(me,"id","deploy-a-transformers-model-trained-in-sagemaker"),f(me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(me,"href","#deploy-a-transformers-model-trained-in-sagemaker"),f(X,"class","relative group"),f(q,"width","700"),f(q,"height","394"),id(q.src,cd="https://www.youtube.com/embed/pfBGgSGnYLs")||f(q,"src",cd),f(q,"title","YouTube video player"),f(q,"frameborder","0"),f(q,"allow","accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"),q.allowFullscreen=!0,f(Xe,"href","https://github.com/huggingface/notebooks/blob/main/sagemaker/10_deploy_model_from_s3/deploy_transformer_model_from_s3.ipynb"),f(Xe,"rel","nofollow"),f(ge,"id","deploy-after-training"),f(ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ge,"href","#deploy-after-training"),f(ee,"class","relative group"),f(ve,"id","deploy-with-modeldata"),f(ve,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(ve,"href","#deploy-with-modeldata"),f(te,"class","relative group"),f(Ee,"id","create-a-model-artifact-for-deployment"),f(Ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(Ee,"href","#create-a-model-artifact-for-deployment"),f(oe,"class","relative group"),f(pt,"start","2"),f(ft,"start","3"),f(be,"id","deploy-a-model-from-the-hub"),f(be,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(be,"href","#deploy-a-model-from-the-hub"),f(ae,"class","relative group"),f(x,"width","700"),f(x,"height","394"),id(x.src,dd="https://www.youtube.com/embed/l9QZuazbzWM")||f(x,"src",dd),f(x,"title","YouTube video player"),f(x,"frameborder","0"),f(x,"allow","accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"),x.allowFullscreen=!0,f(_t,"href","http://huggingface.co/models"),f(_t,"rel","nofollow"),f(gt,"href","https://huggingface.co/transformers/main_classes/pipelines.html"),f(gt,"rel","nofollow"),f(Et,"href","https://github.com/huggingface/notebooks/blob/main/sagemaker/11_deploy_model_from_hf_hub/deploy_transformer_model_from_hf_hub.ipynb"),f(Et,"rel","nofollow"),f(xe,"id","run-batch-transform-with-transformers-and-sagemaker"),f(xe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(xe,"href","#run-batch-transform-with-transformers-and-sagemaker"),f(se,"class","relative group"),f(C,"width","700"),f(C,"height","394"),id(C.src,fd="https://www.youtube.com/embed/lnTixz0tUBg")||f(C,"src",fd),f(C,"title","YouTube video player"),f(C,"frameborder","0"),f(C,"allow","accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"),C.allowFullscreen=!0,f($t,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html"),f($t,"rel","nofollow"),f(kt,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html"),f(kt,"rel","nofollow"),f(bt,"href","https://sagemaker.readthedocs.io/en/stable/overview.html#sagemaker-batch-transform"),f(bt,"rel","nofollow"),f(qt,"href","https://github.com/huggingface/notebooks/blob/main/sagemaker/12_batch_transform_inference/sagemaker-notebook.ipynb"),f(qt,"rel","nofollow"),f(Me,"id","user-defined-code-and-modules"),f(Me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),f(Me,"href","#user-defined-code-and-modules"),f(re,"class","relative group"),f(io,"href","#create-a-model-artifact-for-deployment")},m(e,i){t(document.head,K),p(e,_s,i),p(e,Q,i),t(Q,ie),t(ie,wo),h(Fe,wo,null),t(Q,hr),t(Q,$o),t($o,_r),p(e,gs,i),p(e,Ht,i),t(Ht,gr),p(e,vs,i),h(Ne,e,i),p(e,ys,i),p(e,P,i),t(P,vr),t(P,Re),t(Re,yr),t(P,Er),t(P,pe),t(pe,ko),t(ko,wr),t(pe,$r),t(P,kr),p(e,Es,i),p(e,k,i),t(k,Pt),t(Pt,zt),t(zt,br),t(Pt,jr),t(k,Sr),t(k,Lt),t(Lt,Ft),t(Ft,Dr),t(Lt,qr),t(k,xr),t(k,Nt),t(Nt,Rt),t(Rt,Cr),t(Nt,Tr),t(k,Or),t(k,Ut),t(Ut,Bt),t(Bt,Mr),t(Ut,Ar),t(k,Ir),t(k,Yt),t(Yt,Wt),t(Wt,Hr),t(Yt,Pr),p(e,ws,i),p(e,Z,i),t(Z,ce),t(ce,bo),h(Ue,bo,null),t(Z,zr),t(Z,jo),t(jo,Lr),p(e,$s,i),p(e,de,i),t(de,Fr),t(de,Be),t(Be,Nr),t(de,Rr),p(e,ks,i),p(e,Gt,i),t(Gt,Ur),p(e,bs,i),p(e,z,i),t(z,So),t(So,Ye),t(Ye,Br),t(z,Yr),t(z,Do),t(Do,We),t(We,Wr),t(z,Gr),t(z,qo),t(qo,Jr),p(e,js,i),p(e,fe,i),t(fe,Kr),t(fe,Ge),t(Ge,Qr),t(fe,Zr),p(e,Ss,i),p(e,ue,i),t(ue,Vr),t(ue,xo),t(xo,Xr),t(ue,en),p(e,Ds,i),h(Je,e,i),p(e,qs,i),p(e,Jt,i),t(Jt,Co),t(Co,tn),p(e,xs,i),p(e,Kt,i),t(Kt,on),p(e,Cs,i),h(Ke,e,i),p(e,Ts,i),p(e,Qt,i),t(Qt,V),t(V,an),t(V,To),t(To,sn),t(V,ln),t(V,Oo),t(Oo,rn),t(V,nn),p(e,Os,i),p(e,Zt,i),t(Zt,Mo),t(Mo,pn),p(e,Ms,i),p(e,Vt,i),t(Vt,cn),p(e,As,i),h(Qe,e,i),p(e,Is,i),p(e,X,i),t(X,me),t(me,Ao),h(Ze,Ao,null),t(X,dn),t(X,Io),t(Io,fn),p(e,Hs,i),p(e,q,i),p(e,Ps,i),p(e,Xt,i),t(Xt,un),p(e,zs,i),p(e,he,i),t(he,Ho),t(Ho,mn),t(he,hn),t(he,Ve),t(Ve,_n),t(Ve,Po),t(Po,gn),t(Ve,vn),p(e,Ls,i),p(e,_e,i),t(_e,yn),t(_e,Xe),t(Xe,En),t(_e,wn),p(e,Fs,i),p(e,ee,i),t(ee,ge),t(ge,zo),h(et,zo,null),t(ee,$n),t(ee,Lo),t(Lo,kn),p(e,Ns,i),p(e,eo,i),t(eo,bn),p(e,Rs,i),p(e,O,i),t(O,jn),t(O,Fo),t(Fo,Sn),t(O,Dn),t(O,No),t(No,qn),t(O,xn),t(O,Ro),t(Ro,Cn),t(O,Tn),p(e,Us,i),h(tt,e,i),p(e,Bs,i),p(e,to,i),t(to,On),p(e,Ys,i),h(ot,e,i),p(e,Ws,i),p(e,te,i),t(te,ve),t(ve,Uo),h(at,Uo,null),t(te,Mn),t(te,oo),t(oo,An),t(oo,Bo),t(Bo,In),p(e,Gs,i),p(e,ye,i),t(ye,Hn),t(ye,Yo),t(Yo,Pn),t(ye,zn),p(e,Js,i),h(st,e,i),p(e,Ks,i),p(e,ao,i),t(ao,Ln),p(e,Qs,i),h(lt,e,i),p(e,Zs,i),p(e,oe,i),t(oe,Ee),t(Ee,Wo),h(rt,Wo,null),t(oe,Fn),t(oe,Go),t(Go,Nn),p(e,Vs,i),p(e,we,i),t(we,Rn),t(we,Jo),t(Jo,Un),t(we,Bn),p(e,Xs,i),p(e,M,i),t(M,Ko),t(Ko,Qo),t(Qo,Yn),t(M,Wn),t(M,Zo),t(Zo,Vo),t(Vo,Gn),t(M,Jn),t(M,Xo),t(Xo,ea),t(ea,Kn),t(M,Qn),t(M,ta),t(ta,oa),t(oa,Zn),p(e,el,i),p(e,so,i),t(so,Vn),p(e,tl,i),h(nt,e,i),p(e,ol,i),p(e,$e,i),t($e,Xn),t($e,aa),t(aa,ei),t($e,ti),p(e,al,i),p(e,lo,i),t(lo,sa),t(sa,oi),p(e,sl,i),h(it,e,i),p(e,ll,i),p(e,pt,i),t(pt,ct),t(ct,ai),t(ct,la),t(la,si),t(ct,li),p(e,rl,i),h(dt,e,i),p(e,nl,i),p(e,ft,i),t(ft,ut),t(ut,ri),t(ut,ra),t(ra,ni),t(ut,ii),p(e,il,i),h(mt,e,i),p(e,pl,i),p(e,ke,i),t(ke,pi),t(ke,na),t(na,ci),t(ke,di),p(e,cl,i),p(e,ae,i),t(ae,be),t(be,ia),h(ht,ia,null),t(ae,fi),t(ae,pa),t(pa,ui),p(e,dl,i),p(e,x,i),p(e,fl,i),p(e,je,i),t(je,mi),t(je,ca),t(ca,hi),t(je,_i),p(e,ul,i),p(e,Se,i),t(Se,De),t(De,da),t(da,gi),t(De,vi),t(De,_t),t(_t,yi),t(De,Ei),t(Se,wi),t(Se,L),t(L,fa),t(fa,$i),t(L,ki),t(L,ua),t(ua,bi),t(L,ji),t(L,gt),t(gt,Si),t(L,Di),p(e,ml,i),h(vt,e,i),p(e,hl,i),p(e,ro,i),t(ro,qi),p(e,_l,i),h(yt,e,i),p(e,gl,i),p(e,qe,i),t(qe,xi),t(qe,Et),t(Et,Ci),t(qe,Ti),p(e,vl,i),p(e,se,i),t(se,xe),t(xe,ma),h(wt,ma,null),t(se,Oi),t(se,ha),t(ha,Mi),p(e,yl,i),p(e,C,i),p(e,El,i),p(e,F,i),t(F,Ai),t(F,$t),t($t,Ii),t(F,Hi),t(F,kt),t(kt,Pi),t(F,zi),p(e,wl,i),p(e,Ce,i),t(Ce,Li),t(Ce,_a),t(_a,Fi),t(Ce,Ni),p(e,$l,i),p(e,no,i),t(no,le),t(le,Ri),t(le,ga),t(ga,Ui),t(le,Bi),t(le,va),t(va,Yi),t(le,Wi),p(e,kl,i),p(e,N,i),t(N,Gi),t(N,ya),t(ya,Ji),t(N,Ki),t(N,bt),t(bt,Qi),t(N,Zi),p(e,bl,i),h(jt,e,i),p(e,jl,i),p(e,R,i),t(R,Vi),t(R,Ea),t(Ea,Xi),t(R,ep),t(R,wa),t(wa,tp),t(R,op),p(e,Sl,i),h(St,e,i),p(e,Dl,i),p(e,Te,i),t(Te,ap),t(Te,$a),t($a,sp),t(Te,lp),p(e,ql,i),h(Dt,e,i),p(e,xl,i),p(e,Oe,i),t(Oe,rp),t(Oe,qt),t(qt,np),t(Oe,ip),p(e,Cl,i),p(e,re,i),t(re,Me),t(Me,ka),h(xt,ka,null),t(re,pp),t(re,ba),t(ba,cp),p(e,Tl,i),p(e,b,i),t(b,dp),t(b,ja),t(ja,fp),t(b,up),t(b,Sa),t(Sa,mp),t(b,hp),t(b,Da),t(Da,_p),t(b,gp),t(b,io),t(io,vp),t(b,yp),p(e,Ol,i),h(Ct,e,i),p(e,Ml,i),p(e,U,i),t(U,Ep),t(U,qa),t(qa,wp),t(U,$p),t(U,xa),t(xa,kp),t(U,bp),p(e,Al,i),p(e,j,i),t(j,$),t($,Ca),t(Ca,jp),t($,Sp),t($,Ta),t(Ta,Dp),t($,qp),t($,Oa),t(Oa,xp),t($,Cp),t($,Ma),t(Ma,Tp),t($,Op),t($,Aa),t(Aa,Mp),t($,Ap),t($,Ia),t(Ia,Ip),t($,Hp),t(j,Pp),t(j,y),t(y,Ha),t(Ha,zp),t(y,Lp),t(y,Pa),t(Pa,Fp),t(y,Np),t(y,za),t(za,Rp),t(y,Up),t(y,La),t(La,Bp),t(y,Yp),t(y,Fa),t(Fa,Wp),t(y,Gp),t(y,Na),t(Na,Jp),t(y,Kp),t(y,Ra),t(Ra,Qp),t(y,Zp),t(y,Ua),t(Ua,Vp),t(y,Xp),t(j,ec),t(j,A),t(A,Ba),t(Ba,tc),t(A,oc),t(A,Ya),t(Ya,ac),t(A,sc),t(A,Wa),t(Wa,lc),t(A,rc),t(A,Tt),t(Tt,po),t(po,Ga),t(Ga,nc),t(po,ic),t(Tt,pc),t(Tt,co),t(co,Ja),t(Ja,cc),t(co,dc),t(j,fc),t(j,S),t(S,Ka),t(Ka,uc),t(S,mc),t(S,Qa),t(Qa,hc),t(S,_c),t(S,Za),t(Za,gc),t(S,vc),t(S,Va),t(Va,yc),t(S,Ec),t(S,Xa),t(Xa,wc),t(S,$c),t(j,kc),t(j,I),t(I,es),t(es,bc),t(I,jc),t(I,ts),t(ts,Sc),t(I,Dc),t(I,os),t(os,qc),t(I,xc),t(I,Ot),t(Ot,Ae),t(Ae,as),t(as,Cc),t(Ae,Tc),t(Ae,ss),t(ss,Oc),t(Ae,Mc),t(Ot,Ac),t(Ot,Ie),t(Ie,ls),t(ls,Ic),t(Ie,Hc),t(Ie,rs),t(rs,Pc),t(Ie,zc),p(e,Il,i),p(e,D,i),t(D,Lc),t(D,ns),t(ns,Fc),t(D,Nc),t(D,is),t(is,Rc),t(D,Uc),t(D,ps),t(ps,Bc),t(D,Yc),t(D,cs),t(cs,Wc),t(D,Gc),p(e,Hl,i),h(Mt,e,i),p(e,Pl,i),p(e,B,i),t(B,Jc),t(B,ds),t(ds,Kc),t(B,Qc),t(B,fs),t(fs,Zc),t(B,Vc),p(e,zl,i),h(At,e,i),Ll=!0},p:tm,i(e){Ll||(_(Fe.$$.fragment,e),_(Ne.$$.fragment,e),_(Ue.$$.fragment,e),_(Je.$$.fragment,e),_(Ke.$$.fragment,e),_(Qe.$$.fragment,e),_(Ze.$$.fragment,e),_(et.$$.fragment,e),_(tt.$$.fragment,e),_(ot.$$.fragment,e),_(at.$$.fragment,e),_(st.$$.fragment,e),_(lt.$$.fragment,e),_(rt.$$.fragment,e),_(nt.$$.fragment,e),_(it.$$.fragment,e),_(dt.$$.fragment,e),_(mt.$$.fragment,e),_(ht.$$.fragment,e),_(vt.$$.fragment,e),_(yt.$$.fragment,e),_(wt.$$.fragment,e),_(jt.$$.fragment,e),_(St.$$.fragment,e),_(Dt.$$.fragment,e),_(xt.$$.fragment,e),_(Ct.$$.fragment,e),_(Mt.$$.fragment,e),_(At.$$.fragment,e),Ll=!0)},o(e){g(Fe.$$.fragment,e),g(Ne.$$.fragment,e),g(Ue.$$.fragment,e),g(Je.$$.fragment,e),g(Ke.$$.fragment,e),g(Qe.$$.fragment,e),g(Ze.$$.fragment,e),g(et.$$.fragment,e),g(tt.$$.fragment,e),g(ot.$$.fragment,e),g(at.$$.fragment,e),g(st.$$.fragment,e),g(lt.$$.fragment,e),g(rt.$$.fragment,e),g(nt.$$.fragment,e),g(it.$$.fragment,e),g(dt.$$.fragment,e),g(mt.$$.fragment,e),g(ht.$$.fragment,e),g(vt.$$.fragment,e),g(yt.$$.fragment,e),g(wt.$$.fragment,e),g(jt.$$.fragment,e),g(St.$$.fragment,e),g(Dt.$$.fragment,e),g(xt.$$.fragment,e),g(Ct.$$.fragment,e),g(Mt.$$.fragment,e),g(At.$$.fragment,e),Ll=!1},d(e){o(K),e&&o(_s),e&&o(Q),v(Fe),e&&o(gs),e&&o(Ht),e&&o(vs),v(Ne,e),e&&o(ys),e&&o(P),e&&o(Es),e&&o(k),e&&o(ws),e&&o(Z),v(Ue),e&&o($s),e&&o(de),e&&o(ks),e&&o(Gt),e&&o(bs),e&&o(z),e&&o(js),e&&o(fe),e&&o(Ss),e&&o(ue),e&&o(Ds),v(Je,e),e&&o(qs),e&&o(Jt),e&&o(xs),e&&o(Kt),e&&o(Cs),v(Ke,e),e&&o(Ts),e&&o(Qt),e&&o(Os),e&&o(Zt),e&&o(Ms),e&&o(Vt),e&&o(As),v(Qe,e),e&&o(Is),e&&o(X),v(Ze),e&&o(Hs),e&&o(q),e&&o(Ps),e&&o(Xt),e&&o(zs),e&&o(he),e&&o(Ls),e&&o(_e),e&&o(Fs),e&&o(ee),v(et),e&&o(Ns),e&&o(eo),e&&o(Rs),e&&o(O),e&&o(Us),v(tt,e),e&&o(Bs),e&&o(to),e&&o(Ys),v(ot,e),e&&o(Ws),e&&o(te),v(at),e&&o(Gs),e&&o(ye),e&&o(Js),v(st,e),e&&o(Ks),e&&o(ao),e&&o(Qs),v(lt,e),e&&o(Zs),e&&o(oe),v(rt),e&&o(Vs),e&&o(we),e&&o(Xs),e&&o(M),e&&o(el),e&&o(so),e&&o(tl),v(nt,e),e&&o(ol),e&&o($e),e&&o(al),e&&o(lo),e&&o(sl),v(it,e),e&&o(ll),e&&o(pt),e&&o(rl),v(dt,e),e&&o(nl),e&&o(ft),e&&o(il),v(mt,e),e&&o(pl),e&&o(ke),e&&o(cl),e&&o(ae),v(ht),e&&o(dl),e&&o(x),e&&o(fl),e&&o(je),e&&o(ul),e&&o(Se),e&&o(ml),v(vt,e),e&&o(hl),e&&o(ro),e&&o(_l),v(yt,e),e&&o(gl),e&&o(qe),e&&o(vl),e&&o(se),v(wt),e&&o(yl),e&&o(C),e&&o(El),e&&o(F),e&&o(wl),e&&o(Ce),e&&o($l),e&&o(no),e&&o(kl),e&&o(N),e&&o(bl),v(jt,e),e&&o(jl),e&&o(R),e&&o(Sl),v(St,e),e&&o(Dl),e&&o(Te),e&&o(ql),v(Dt,e),e&&o(xl),e&&o(Oe),e&&o(Cl),e&&o(re),v(xt),e&&o(Tl),e&&o(b),e&&o(Ol),v(Ct,e),e&&o(Ml),e&&o(U),e&&o(Al),e&&o(j),e&&o(Il),e&&o(D),e&&o(Hl),v(Mt,e),e&&o(Pl),e&&o(B),e&&o(zl),v(At,e)}}}const sm={local:"deploy-models-to-amazon-sagemaker",sections:[{local:"installation-and-setup",title:"Installation and setup"},{local:"deploy-a-transformers-model-trained-in-sagemaker",sections:[{local:"deploy-after-training",title:"Deploy after training"},{local:"deploy-with-modeldata",title:"Deploy with `model_data`"},{local:"create-a-model-artifact-for-deployment",title:"Create a model artifact for deployment"}],title:"Deploy a \u{1F917} Transformers model trained in SageMaker"},{local:"deploy-a-model-from-the-hub",title:"Deploy a model from the \u{1F917} Hub"},{local:"run-batch-transform-with-transformers-and-sagemaker",title:"Run batch transform with \u{1F917} Transformers and SageMaker"},{local:"user-defined-code-and-modules",title:"User defined code and modules"}],title:"Deploy models to Amazon SageMaker"};function lm(pd){return om(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class pm extends Zu{constructor(K){super();Vu(this,K,lm,am,Xu,{})}}export{pm as default,sm as metadata};
