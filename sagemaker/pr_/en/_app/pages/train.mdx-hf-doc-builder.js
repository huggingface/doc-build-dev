import{S as Lu,i as zu,s as Ru,e as o,k as h,w as m,t as s,M as Uu,c as n,d as a,m as f,a as l,x as u,h as r,b as c,N as Gu,G as t,g as p,y as d,L as Wu,q as g,o as _,B as v,v as Bu}from"../chunks/vendor-hf-doc-builder.js";import{I as D}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as O}from"../chunks/CodeBlock-hf-doc-builder.js";function Xu(Uh){let X,xr,J,pe,Ta,Ke,kn,Ca,$n,jr,M,Gh,Sr,ce,xn,Da,jn,Sn,Ar,y,Vt,Yt,An,Mn,Pn,Qt,Zt,Tn,Cn,Dn,ea,ta,On,qn,In,aa,he,Nn,Oa,Hn,Fn,Ln,zn,sa,ra,Rn,Un,Gn,oa,na,Wn,Bn,Xn,la,ia,Jn,Kn,Vn,pa,ca,Yn,Qn,Zn,ha,fa,el,tl,Mr,K,fe,qa,Ve,al,Ia,sl,Pr,me,rl,Ye,ol,nl,Tr,ma,ll,Cr,L,Na,Qe,il,pl,Ha,Ze,cl,hl,Fa,fl,Dr,ue,ml,et,ul,dl,Or,de,gl,La,_l,vl,qr,tt,Ir,ua,za,yl,Nr,da,El,Hr,at,Fr,ga,V,bl,Ra,wl,kl,Ua,$l,xl,Lr,_a,Ga,jl,zr,va,Sl,Rr,st,Ur,Y,ge,Wa,rt,Al,Ba,Ml,Gr,_e,Pl,ot,Tl,Cl,Wr,z,Xa,R,Ja,Dl,Ol,Ka,ql,Il,Va,Nl,Hl,Fl,Ya,ya,Qa,Ll,zl,Rl,Za,x,es,Ul,Gl,ts,Wl,Bl,as,Xl,Jl,ss,Kl,Vl,rs,Yl,Ql,os,Zl,ei,Br,q,ti,ns,ai,si,Ea,ri,oi,ls,ni,li,Xr,nt,Jr,ba,P,ii,is,pi,ci,ps,hi,fi,cs,mi,ui,hs,di,gi,Kr,ve,_i,lt,vi,yi,Vr,Q,ye,fs,it,Ei,ms,bi,Yr,E,wi,us,ki,$i,ds,xi,ji,gs,Si,Ai,_s,Mi,Pi,pt,Ti,Ci,vs,Di,Oi,ys,qi,Ii,Es,Ni,Hi,Qr,b,Fi,ct,Li,zi,ht,Ri,Ui,bs,Gi,Wi,ws,Bi,Xi,ks,Ji,Ki,$s,Vi,Yi,T,Qi,xs,Zi,ep,js,tp,ap,Ss,sp,rp,As,op,np,Zr,Z,Ee,Ms,ft,lp,Ps,ip,eo,be,pp,mt,cp,hp,to,U,wa,Ts,fp,mp,up,we,Cs,dp,gp,ut,_p,vp,yp,ke,Ds,Ep,bp,dt,wp,kp,ao,S,$p,Os,xp,jp,qs,Sp,Ap,Is,Mp,Pp,Ns,Tp,Cp,so,gt,ro,I,Dp,Hs,Op,qp,Fs,Ip,Np,Ls,Hp,Fp,oo,ee,$e,zs,_t,Lp,Rs,zp,no,N,Rp,Us,Up,Gp,Gs,Wp,Bp,Ws,Xp,Jp,lo,xe,vt,Kp,Bs,Vp,Yp,Qp,je,Xs,Zp,ec,yt,tc,ac,io,Se,sc,Js,rc,oc,po,Et,co,Ae,nc,Ks,lc,ic,ho,bt,fo,te,Me,Vs,wt,pc,Ys,cc,mo,Pe,hc,kt,fc,mc,uo,$t,go,ae,Te,Qs,xt,uc,Zs,dc,_o,ka,gc,vo,se,Ce,er,jt,_c,tr,vc,yo,De,yc,St,Ec,bc,Eo,At,bo,Oe,wc,Mt,kc,$c,wo,re,qe,ar,Pt,xc,sr,jc,ko,Ie,Sc,Tt,Ac,Mc,$o,Ct,xo,Ne,Pc,Dt,Tc,Cc,jo,oe,He,rr,Ot,Dc,or,Oc,So,Fe,qc,qt,Ic,Nc,Ao,$a,ne,Hc,It,Fc,Lc,nr,zc,Rc,Mo,H,Uc,lr,Gc,Wc,ir,Bc,Xc,pr,Jc,Kc,Po,Nt,To,Le,Vc,Ht,Yc,Qc,Co,le,ze,cr,Ft,Zc,hr,eh,Do,F,th,Lt,ah,sh,fr,rh,oh,mr,nh,lh,Oo,w,ih,ur,ph,ch,zt,hh,fh,dr,mh,uh,gr,dh,gh,_r,_h,vh,vr,yh,Eh,qo,xa,Rt,bh,yr,wh,kh,Io,Ut,No,ie,Re,Er,Gt,$h,br,xh,Ho,Wt,Bt,jh,Sh,Fo,Xt,Lo,Ue,Ah,Jt,Mh,Ph,zo;return Ke=new D({}),Ve=new D({}),tt=new O({props:{code:"pip install sagemaker --upgrade",highlighted:"pip install sagemaker --upgrade"}}),at=new O({props:{code:`import sagemaker
sess = sagemaker.Session()
role = sagemaker.get_execution_role()`,highlighted:`<span class="hljs-keyword">import</span> sagemaker
sess = sagemaker.Session()
role = sagemaker.get_execution_role()`}}),st=new O({props:{code:"",highlighted:`<span class="hljs-keyword">import</span> sagemaker
<span class="hljs-keyword">import</span> boto3

iam_client = boto3.client(<span class="hljs-string">&#x27;iam&#x27;</span>)
role = iam_client.get_role(RoleName=<span class="hljs-string">&#x27;role-name-of-your-iam-role-with-right-permissions&#x27;</span>)[<span class="hljs-string">&#x27;Role&#x27;</span>][<span class="hljs-string">&#x27;Arn&#x27;</span>]
sess = sagemaker.Session()`}}),rt=new D({}),nt=new O({props:{code:`


`,highlighted:`<span class="hljs-keyword">import</span> transformers
<span class="hljs-keyword">import</span> datasets
<span class="hljs-keyword">import</span> argparse
<span class="hljs-keyword">import</span> os

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:

    parser = argparse.ArgumentParser()

    <span class="hljs-comment"># hyperparameters sent by the client are passed as command-line arguments to the script</span>
    parser.add_argument(<span class="hljs-string">&quot;--epochs&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">3</span>)
    parser.add_argument(<span class="hljs-string">&quot;--per_device_train_batch_size&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">32</span>)
    parser.add_argument(<span class="hljs-string">&quot;--model_name_or_path&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>)

    <span class="hljs-comment"># data, model, and output directories</span>
    parser.add_argument(<span class="hljs-string">&quot;--model-dir&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=os.environ[<span class="hljs-string">&quot;SM_MODEL_DIR&quot;</span>])
    parser.add_argument(<span class="hljs-string">&quot;--training_dir&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=os.environ[<span class="hljs-string">&quot;SM_CHANNEL_TRAIN&quot;</span>])
    parser.add_argument(<span class="hljs-string">&quot;--test_dir&quot;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=os.environ[<span class="hljs-string">&quot;SM_CHANNEL_TEST&quot;</span>])`}}),it=new D({}),ft=new D({}),gt=new O({props:{code:`

`,highlighted:`<span class="hljs-keyword">from</span> sagemaker.huggingface <span class="hljs-keyword">import</span> HuggingFace


<span class="hljs-comment"># hyperparameters which are passed to the training job</span>
hyperparameters={<span class="hljs-string">&#x27;epochs&#x27;</span>: <span class="hljs-number">1</span>,
                 <span class="hljs-string">&#x27;per_device_train_batch_size&#x27;</span>: <span class="hljs-number">32</span>,
                 <span class="hljs-string">&#x27;model_name_or_path&#x27;</span>: <span class="hljs-string">&#x27;distilbert-base-uncased&#x27;</span>
                 }

<span class="hljs-comment"># create the Estimator</span>
huggingface_estimator = HuggingFace(
        entry_point=<span class="hljs-string">&#x27;train.py&#x27;</span>,
        source_dir=<span class="hljs-string">&#x27;./scripts&#x27;</span>,
        instance_type=<span class="hljs-string">&#x27;ml.p3.2xlarge&#x27;</span>,
        instance_count=<span class="hljs-number">1</span>,
        role=role,
        transformers_version=<span class="hljs-string">&#x27;4.4&#x27;</span>,
        pytorch_version=<span class="hljs-string">&#x27;1.6&#x27;</span>,
        py_version=<span class="hljs-string">&#x27;py36&#x27;</span>,
        hyperparameters = hyperparameters
)`}}),_t=new D({}),Et=new O({props:{code:`huggingface_estimator.fit(
  {'train': 's3://sagemaker-us-east-1-558105141721/samples/datasets/imdb/train',
   'test': 's3://sagemaker-us-east-1-558105141721/samples/datasets/imdb/test'}
)`,highlighted:`huggingface_estimator.fit(
  {<span class="hljs-string">&#x27;train&#x27;</span>: <span class="hljs-string">&#x27;s3://sagemaker-us-east-1-558105141721/samples/datasets/imdb/train&#x27;</span>,
   <span class="hljs-string">&#x27;test&#x27;</span>: <span class="hljs-string">&#x27;s3://sagemaker-us-east-1-558105141721/samples/datasets/imdb/test&#x27;</span>}
)`}}),bt=new O({props:{code:"/opt/conda/bin/python train.py --epochs 1 --model_name_or_path distilbert-base-uncased --per_device_train_batch_size 32",highlighted:"/opt/conda/bin/python train.py --epochs 1 --model_name_or_path distilbert-base-uncased --per_device_train_batch_size 32"}}),wt=new D({}),$t=new O({props:{code:"",highlighted:`<span class="hljs-keyword">from</span> sagemaker.s3 <span class="hljs-keyword">import</span> S3Downloader

S3Downloader.download(
    s3_uri=huggingface_estimator.model_data, <span class="hljs-comment"># S3 URI where the trained model is located</span>
    local_path=<span class="hljs-string">&#x27;.&#x27;</span>,                          <span class="hljs-comment"># local path where *.targ.gz is saved</span>
    sagemaker_session=sess                   <span class="hljs-comment"># SageMaker session used for training the model</span>
)`}}),xt=new D({}),jt=new D({}),At=new O({props:{code:"",highlighted:`<span class="hljs-comment"># configuration for running training on smdistributed data parallel</span>
distribution = {<span class="hljs-string">&#x27;smdistributed&#x27;</span>:{<span class="hljs-string">&#x27;dataparallel&#x27;</span>:{ <span class="hljs-string">&#x27;enabled&#x27;</span>: <span class="hljs-literal">True</span> }}}

<span class="hljs-comment"># create the Estimator</span>
huggingface_estimator = HuggingFace(
        entry_point=<span class="hljs-string">&#x27;train.py&#x27;</span>,
        source_dir=<span class="hljs-string">&#x27;./scripts&#x27;</span>,
        instance_type=<span class="hljs-string">&#x27;ml.p3dn.24xlarge&#x27;</span>,
        instance_count=<span class="hljs-number">2</span>,
        role=role,
        transformers_version=<span class="hljs-string">&#x27;4.4.2&#x27;</span>,
        pytorch_version=<span class="hljs-string">&#x27;1.6.0&#x27;</span>,
        py_version=<span class="hljs-string">&#x27;py36&#x27;</span>,
        hyperparameters = hyperparameters
        distribution = distribution
)`}}),Pt=new D({}),Ct=new O({props:{code:`

`,highlighted:`<span class="hljs-comment"># configuration for running training on smdistributed model parallel</span>
mpi_options = {
    <span class="hljs-string">&quot;enabled&quot;</span> : <span class="hljs-literal">True</span>,
    <span class="hljs-string">&quot;processes_per_host&quot;</span> : <span class="hljs-number">8</span>
}

smp_options = {
    <span class="hljs-string">&quot;enabled&quot;</span>:<span class="hljs-literal">True</span>,
    <span class="hljs-string">&quot;parameters&quot;</span>: {
        <span class="hljs-string">&quot;microbatches&quot;</span>: <span class="hljs-number">4</span>,
        <span class="hljs-string">&quot;placement_strategy&quot;</span>: <span class="hljs-string">&quot;spread&quot;</span>,
        <span class="hljs-string">&quot;pipeline&quot;</span>: <span class="hljs-string">&quot;interleaved&quot;</span>,
        <span class="hljs-string">&quot;optimize&quot;</span>: <span class="hljs-string">&quot;speed&quot;</span>,
        <span class="hljs-string">&quot;partitions&quot;</span>: <span class="hljs-number">4</span>,
        <span class="hljs-string">&quot;ddp&quot;</span>: <span class="hljs-literal">True</span>,
    }
}

distribution={
    <span class="hljs-string">&quot;smdistributed&quot;</span>: {<span class="hljs-string">&quot;modelparallel&quot;</span>: smp_options},
    <span class="hljs-string">&quot;mpi&quot;</span>: mpi_options
}

 <span class="hljs-comment"># create the Estimator</span>
huggingface_estimator = HuggingFace(
        entry_point=<span class="hljs-string">&#x27;train.py&#x27;</span>,
        source_dir=<span class="hljs-string">&#x27;./scripts&#x27;</span>,
        instance_type=<span class="hljs-string">&#x27;ml.p3dn.24xlarge&#x27;</span>,
        instance_count=<span class="hljs-number">2</span>,
        role=role,
        transformers_version=<span class="hljs-string">&#x27;4.4.2&#x27;</span>,
        pytorch_version=<span class="hljs-string">&#x27;1.6.0&#x27;</span>,
        py_version=<span class="hljs-string">&#x27;py36&#x27;</span>,
        hyperparameters = hyperparameters,
        distribution = distribution
)`}}),Ot=new D({}),Nt=new O({props:{code:`
`,highlighted:`<span class="hljs-comment"># hyperparameters which are passed to the training job</span>
hyperparameters={<span class="hljs-string">&#x27;epochs&#x27;</span>: <span class="hljs-number">1</span>,
                 <span class="hljs-string">&#x27;train_batch_size&#x27;</span>: <span class="hljs-number">32</span>,
                 <span class="hljs-string">&#x27;model_name&#x27;</span>:<span class="hljs-string">&#x27;distilbert-base-uncased&#x27;</span>,
                 <span class="hljs-string">&#x27;output_dir&#x27;</span>:<span class="hljs-string">&#x27;/opt/ml/checkpoints&#x27;</span>
                 }

<span class="hljs-comment"># create the Estimator</span>
huggingface_estimator = HuggingFace(
        entry_point=<span class="hljs-string">&#x27;train.py&#x27;</span>,
        source_dir=<span class="hljs-string">&#x27;./scripts&#x27;</span>,
        instance_type=<span class="hljs-string">&#x27;ml.p3.2xlarge&#x27;</span>,
        instance_count=<span class="hljs-number">1</span>,
	    checkpoint_s3_uri=<span class="hljs-string">f&#x27;s3://<span class="hljs-subst">{sess.default_bucket()}</span>/checkpoints&#x27;</span>
        use_spot_instances=<span class="hljs-literal">True</span>,
        <span class="hljs-comment"># max_wait should be equal to or greater than max_run in seconds</span>
        max_wait=<span class="hljs-number">3600</span>,
        max_run=<span class="hljs-number">1000</span>,
        role=role,
        transformers_version=<span class="hljs-string">&#x27;4.4&#x27;</span>,
        pytorch_version=<span class="hljs-string">&#x27;1.6&#x27;</span>,
        py_version=<span class="hljs-string">&#x27;py36&#x27;</span>,
        hyperparameters = hyperparameters
)

<span class="hljs-comment"># Training seconds: 874</span>
<span class="hljs-comment"># Billable seconds: 262</span>
<span class="hljs-comment"># Managed Spot Training savings: 70.0%</span>`}}),Ft=new D({}),Ut=new O({props:{code:"",highlighted:`<span class="hljs-comment"># configure git settings</span>
git_config = {<span class="hljs-string">&#x27;repo&#x27;</span>: <span class="hljs-string">&#x27;https://github.com/huggingface/transformers.git&#x27;</span>,<span class="hljs-string">&#x27;branch&#x27;</span>: <span class="hljs-string">&#x27;v4.4.2&#x27;</span>} <span class="hljs-comment"># v4.4.2 refers to the transformers_version you use in the estimator</span>

 <span class="hljs-comment"># create the Estimator</span>
huggingface_estimator = HuggingFace(
        entry_point=<span class="hljs-string">&#x27;run_glue.py&#x27;</span>,
        source_dir=<span class="hljs-string">&#x27;./examples/pytorch/text-classification&#x27;</span>,
        git_config=git_config,
        instance_type=<span class="hljs-string">&#x27;ml.p3.2xlarge&#x27;</span>,
        instance_count=<span class="hljs-number">1</span>,
        role=role,
        transformers_version=<span class="hljs-string">&#x27;4.4&#x27;</span>,
        pytorch_version=<span class="hljs-string">&#x27;1.6&#x27;</span>,
        py_version=<span class="hljs-string">&#x27;py36&#x27;</span>,
        hyperparameters=hyperparameters
)`}}),Gt=new D({}),Xt=new O({props:{code:"",highlighted:`<span class="hljs-comment"># define metrics definitions</span>
metric_definitions = [
    {<span class="hljs-string">&quot;Name&quot;</span>: <span class="hljs-string">&quot;train_runtime&quot;</span>, <span class="hljs-string">&quot;Regex&quot;</span>: <span class="hljs-string">&quot;train_runtime.*=\\D*(.*?)$&quot;</span>},
    {<span class="hljs-string">&quot;Name&quot;</span>: <span class="hljs-string">&quot;eval_accuracy&quot;</span>, <span class="hljs-string">&quot;Regex&quot;</span>: <span class="hljs-string">&quot;eval_accuracy.*=\\D*(.*?)$&quot;</span>},
    {<span class="hljs-string">&quot;Name&quot;</span>: <span class="hljs-string">&quot;eval_loss&quot;</span>, <span class="hljs-string">&quot;Regex&quot;</span>: <span class="hljs-string">&quot;eval_loss.*=\\D*(.*?)$&quot;</span>},
]

<span class="hljs-comment"># create the Estimator</span>
huggingface_estimator = HuggingFace(
        entry_point=<span class="hljs-string">&#x27;train.py&#x27;</span>,
        source_dir=<span class="hljs-string">&#x27;./scripts&#x27;</span>,
        instance_type=<span class="hljs-string">&#x27;ml.p3.2xlarge&#x27;</span>,
        instance_count=<span class="hljs-number">1</span>,
        role=role,
        transformers_version=<span class="hljs-string">&#x27;4.4&#x27;</span>,
        pytorch_version=<span class="hljs-string">&#x27;1.6&#x27;</span>,
        py_version=<span class="hljs-string">&#x27;py36&#x27;</span>,
        metric_definitions=metric_definitions,
        hyperparameters = hyperparameters)`}}),{c(){X=o("meta"),xr=h(),J=o("h1"),pe=o("a"),Ta=o("span"),m(Ke.$$.fragment),kn=h(),Ca=o("span"),$n=s("Run training on Amazon SageMaker"),jr=h(),M=o("iframe"),Sr=h(),ce=o("p"),xn=s("This guide will show you how to train a \u{1F917} Transformers model with the "),Da=o("code"),jn=s("HuggingFace"),Sn=s(" SageMaker Python SDK. Learn how to:"),Ar=h(),y=o("ul"),Vt=o("li"),Yt=o("a"),An=s("Install and setup your training environment"),Mn=s("."),Pn=h(),Qt=o("li"),Zt=o("a"),Tn=s("Prepare a training script"),Cn=s("."),Dn=h(),ea=o("li"),ta=o("a"),On=s("Create a Hugging Face Estimator"),qn=s("."),In=h(),aa=o("li"),he=o("a"),Nn=s("Run training with the "),Oa=o("code"),Hn=s("fit"),Fn=s(" method"),Ln=s("."),zn=h(),sa=o("li"),ra=o("a"),Rn=s("Access your trained model"),Un=s("."),Gn=h(),oa=o("li"),na=o("a"),Wn=s("Perform distributed training"),Bn=s("."),Xn=h(),la=o("li"),ia=o("a"),Jn=s("Create a spot instance"),Kn=s("."),Vn=h(),pa=o("li"),ca=o("a"),Yn=s("Load a training script from a GitHub repository"),Qn=s("."),Zn=h(),ha=o("li"),fa=o("a"),el=s("Collect training metrics"),tl=s("."),Mr=h(),K=o("h2"),fe=o("a"),qa=o("span"),m(Ve.$$.fragment),al=h(),Ia=o("span"),sl=s("Installation and setup"),Pr=h(),me=o("p"),rl=s("Before you can train a \u{1F917} Transformers model with SageMaker, you need to sign up for an AWS account. If you don\u2019t have an AWS account yet, learn more "),Ye=o("a"),ol=s("here"),nl=s("."),Tr=h(),ma=o("p"),ll=s("Once you have an AWS account, get started using one of the following:"),Cr=h(),L=o("ul"),Na=o("li"),Qe=o("a"),il=s("SageMaker Studio"),pl=h(),Ha=o("li"),Ze=o("a"),cl=s("SageMaker notebook instance"),hl=h(),Fa=o("li"),fl=s("Local environment"),Dr=h(),ue=o("p"),ml=s("To start training locally, you need to setup an appropriate "),et=o("a"),ul=s("IAM role"),dl=s("."),Or=h(),de=o("p"),gl=s("Upgrade to the latest "),La=o("code"),_l=s("sagemaker"),vl=s(" version:"),qr=h(),m(tt.$$.fragment),Ir=h(),ua=o("p"),za=o("strong"),yl=s("SageMaker environment"),Nr=h(),da=o("p"),El=s("Setup your SageMaker environment as shown below:"),Hr=h(),m(at.$$.fragment),Fr=h(),ga=o("p"),V=o("em"),bl=s("Note: The execution role is only available when running a notebook within SageMaker. If you run "),Ra=o("code"),wl=s("get_execution_role"),kl=s(" in a notebook not on SageMaker, expect a "),Ua=o("code"),$l=s("region"),xl=s(" error."),Lr=h(),_a=o("p"),Ga=o("strong"),jl=s("Local environment"),zr=h(),va=o("p"),Sl=s("Setup your local environment as shown below:"),Rr=h(),m(st.$$.fragment),Ur=h(),Y=o("h2"),ge=o("a"),Wa=o("span"),m(rt.$$.fragment),Al=h(),Ba=o("span"),Ml=s("Prepare a \u{1F917} Transformers fine-tuning script"),Gr=h(),_e=o("p"),Pl=s("Our training script is very similar to a training script you might run outside of SageMaker. However, you can access useful properties about the training environment through various environment variables (see "),ot=o("a"),Tl=s("here"),Cl=s(" for a complete list), such as:"),Wr=h(),z=o("ul"),Xa=o("li"),R=o("p"),Ja=o("code"),Dl=s("SM_MODEL_DIR"),Ol=s(": A string representing the path to which the training job writes the model artifacts. After training, artifacts in this directory are uploaded to S3 for model hosting. "),Ka=o("code"),ql=s("SM_MODEL_DIR"),Il=s(" is always set to "),Va=o("code"),Nl=s("/opt/ml/model"),Hl=s("."),Fl=h(),Ya=o("li"),ya=o("p"),Qa=o("code"),Ll=s("SM_NUM_GPUS"),zl=s(": An integer representing the number of GPUs available to the host."),Rl=h(),Za=o("li"),x=o("p"),es=o("code"),Ul=s("SM_CHANNEL_XXXX:"),Gl=s(" A string representing the path to the directory that contains the input data for the specified channel. For example, when you specify "),ts=o("code"),Wl=s("train"),Bl=s(" and "),as=o("code"),Xl=s("test"),Jl=s(" in the Hugging Face Estimator "),ss=o("code"),Kl=s("fit"),Vl=s(" method, the environment variables are set to "),rs=o("code"),Yl=s("SM_CHANNEL_TRAIN"),Ql=s(" and "),os=o("code"),Zl=s("SM_CHANNEL_TEST"),ei=s("."),Br=h(),q=o("p"),ti=s("The "),ns=o("code"),ai=s("hyperparameters"),si=s(" defined in the "),Ea=o("a"),ri=s("Hugging Face Estimator"),oi=s(" are passed as named arguments and processed by "),ls=o("code"),ni=s("ArgumentParser()"),li=s("."),Xr=h(),m(nt.$$.fragment),Jr=h(),ba=o("p"),P=o("em"),ii=s("Note that SageMaker doesn\u2019t support argparse actions. For example, if you want to use a boolean hyperparameter, specify "),is=o("code"),pi=s("type"),ci=s(" as "),ps=o("code"),hi=s("bool"),fi=s(" in your script and provide an explicit "),cs=o("code"),mi=s("True"),ui=s(" or "),hs=o("code"),di=s("False"),gi=s(" value."),Kr=h(),ve=o("p"),_i=s("Look "),lt=o("a"),vi=s("here"),yi=s(" for a complete example of a \u{1F917} Transformers training script."),Vr=h(),Q=o("h2"),ye=o("a"),fs=o("span"),m(it.$$.fragment),Ei=h(),ms=o("span"),bi=s("Training Output Management"),Yr=h(),E=o("p"),wi=s("If "),us=o("code"),ki=s("output_dir"),$i=s(" in the "),ds=o("code"),xi=s("TrainingArguments"),ji=s(" is set to \u2018/opt/ml/model\u2019 the Trainer saves all training artifacts, including logs, checkpoints, and models. Amazon SageMaker archives the whole \u2018/opt/ml/model\u2019 directory as "),gs=o("code"),Si=s("model.tar.gz"),Ai=s(" and uploads it at the end of the training job to Amazon S3. Depending on your Hyperparameters and "),_s=o("code"),Mi=s("TrainingArguments"),Pi=s(` this could lead to a large artifact (> 5GB), which can slow down deployment for Amazon SageMaker Inference.
You can control how checkpoints, logs, and artifacts are saved by customization the `),pt=o("a"),Ti=s("TrainingArguments"),Ci=s(". For example by providing "),vs=o("code"),Di=s("save_total_limit"),Oi=s(" as "),ys=o("code"),qi=s("TrainingArgument"),Ii=s(" you can control the limit of the total amount of checkpoints. Deletes the older checkpoints in "),Es=o("code"),Ni=s("output_dir"),Hi=s(" if new ones are saved and the maximum limit is reached."),Qr=h(),b=o("p"),Fi=s("In addition to the options already mentioned above, there is another option to save the training artifacts during the training session. Amazon SageMaker supports "),ct=o("a"),Li=s("Checkpointing"),zi=s(", which allows you to continuously save your artifacts during training to Amazon S3 rather than at the end of your training. To enable "),ht=o("a"),Ri=s("Checkpointing"),Ui=s(" you need to provide the "),bs=o("code"),Gi=s("checkpoint_s3_uri"),Wi=s(" parameter pointing to an Amazon S3 location in the "),ws=o("code"),Bi=s("HuggingFace"),Xi=s(" estimator and set "),ks=o("code"),Ji=s("output_dir"),Ki=s(" to "),$s=o("code"),Vi=s("/opt/ml/checkpoints"),Yi=s(`.
`),T=o("em"),Qi=s("Note: If you set "),xs=o("code"),Zi=s("output_dir"),ep=s(" to "),js=o("code"),tp=s("/opt/ml/checkpoints"),ap=s(" make sure to call "),Ss=o("code"),sp=s('trainer.save_model("/opt/ml/model")'),rp=s(" or model.save_pretrained(\u201C/opt/ml/model\u201D)/"),As=o("code"),op=s('tokenizer.save_pretrained("/opt/ml/model")'),np=s(" at the end of your training to be able to deploy your model seamlessly to Amazon SageMaker for Inference."),Zr=h(),Z=o("h2"),Ee=o("a"),Ms=o("span"),m(ft.$$.fragment),lp=h(),Ps=o("span"),ip=s("Create a Hugging Face Estimator"),eo=h(),be=o("p"),pp=s("Run \u{1F917} Transformers training scripts on SageMaker by creating a "),mt=o("a"),cp=s("Hugging Face Estimator"),hp=s(". The Estimator handles end-to-end SageMaker training. There are several parameters you should define in the Estimator:"),to=h(),U=o("ol"),wa=o("li"),Ts=o("code"),fp=s("entry_point"),mp=s(" specifies which fine-tuning script to use."),up=h(),we=o("li"),Cs=o("code"),dp=s("instance_type"),gp=s(" specifies an Amazon instance to launch. Refer "),ut=o("a"),_p=s("here"),vp=s(" for a complete list of instance types."),yp=h(),ke=o("li"),Ds=o("code"),Ep=s("hyperparameters"),bp=s(" specifies training hyperparameters. View additional available hyperparameters "),dt=o("a"),wp=s("here"),kp=s("."),ao=h(),S=o("p"),$p=s("The following code sample shows how to train with a custom script "),Os=o("code"),xp=s("train.py"),jp=s(" with three hyperparameters ("),qs=o("code"),Sp=s("epochs"),Ap=s(", "),Is=o("code"),Mp=s("per_device_train_batch_size"),Pp=s(", and "),Ns=o("code"),Tp=s("model_name_or_path"),Cp=s("):"),so=h(),m(gt.$$.fragment),ro=h(),I=o("p"),Dp=s("If you are running a "),Hs=o("code"),Op=s("TrainingJob"),qp=s(" locally, define "),Fs=o("code"),Ip=s("instance_type='local'"),Np=s(" or "),Ls=o("code"),Hp=s("instance_type='local-gpu'"),Fp=s(" for GPU usage. Note that this will not work with SageMaker Studio."),oo=h(),ee=o("h2"),$e=o("a"),zs=o("span"),m(_t.$$.fragment),Lp=h(),Rs=o("span"),zp=s("Execute training"),no=h(),N=o("p"),Rp=s("Start your "),Us=o("code"),Up=s("TrainingJob"),Gp=s(" by calling "),Gs=o("code"),Wp=s("fit"),Bp=s(" on a Hugging Face Estimator. Specify your input training data in "),Ws=o("code"),Xp=s("fit"),Jp=s(". The input training data can be a:"),lo=h(),xe=o("ul"),vt=o("li"),Kp=s("S3 URI such as "),Bs=o("code"),Vp=s("s3://my-bucket/my-training-data"),Yp=s("."),Qp=h(),je=o("li"),Xs=o("code"),Zp=s("FileSystemInput"),ec=s(" for Amazon Elastic File System or FSx for Lustre. See "),yt=o("a"),tc=s("here"),ac=s(" for more details about using these file systems as input."),io=h(),Se=o("p"),sc=s("Call "),Js=o("code"),rc=s("fit"),oc=s(" to begin training:"),po=h(),m(Et.$$.fragment),co=h(),Ae=o("p"),nc=s("SageMaker starts and manages all the required EC2 instances and initiates the "),Ks=o("code"),lc=s("TrainingJob"),ic=s(" by running:"),ho=h(),m(bt.$$.fragment),fo=h(),te=o("h2"),Me=o("a"),Vs=o("span"),m(wt.$$.fragment),pc=h(),Ys=o("span"),cc=s("Access trained model"),mo=h(),Pe=o("p"),hc=s("Once training is complete, you can access your model through the "),kt=o("a"),fc=s("AWS console"),mc=s(" or download it directly from S3."),uo=h(),m($t.$$.fragment),go=h(),ae=o("h2"),Te=o("a"),Qs=o("span"),m(xt.$$.fragment),uc=h(),Zs=o("span"),dc=s("Distributed training"),_o=h(),ka=o("p"),gc=s("SageMaker provides two strategies for distributed training: data parallelism and model parallelism. Data parallelism splits a training set across several GPUs, while model parallelism splits a model across several GPUs."),vo=h(),se=o("h3"),Ce=o("a"),er=o("span"),m(jt.$$.fragment),_c=h(),tr=o("span"),vc=s("Data parallelism"),yo=h(),De=o("p"),yc=s("The Hugging Face "),St=o("a"),Ec=s("Trainer"),bc=s(" supports SageMaker\u2019s data parallelism library. If your training script uses the Trainer API, you only need to define the distribution parameter in the Hugging Face Estimator:"),Eo=h(),m(At.$$.fragment),bo=h(),Oe=o("p"),wc=s("\u{1F4D3} Open the "),Mt=o("a"),kc=s("notebook"),$c=s(" for an example of how to run the data parallelism library with TensorFlow."),wo=h(),re=o("h3"),qe=o("a"),ar=o("span"),m(Pt.$$.fragment),xc=h(),sr=o("span"),jc=s("Model parallelism"),ko=h(),Ie=o("p"),Sc=s("The Hugging Face [Trainer] also supports SageMaker\u2019s model parallelism library. If your training script uses the Trainer API, you only need to define the distribution parameter in the Hugging Face Estimator (see "),Tt=o("a"),Ac=s("here"),Mc=s(" for more detailed information about using model parallelism):"),$o=h(),m(Ct.$$.fragment),xo=h(),Ne=o("p"),Pc=s("\u{1F4D3} Open the "),Dt=o("a"),Tc=s("notebook"),Cc=s(" for an example of how to run the model parallelism library."),jo=h(),oe=o("h2"),He=o("a"),rr=o("span"),m(Ot.$$.fragment),Dc=h(),or=o("span"),Oc=s("Spot instances"),So=h(),Fe=o("p"),qc=s("The Hugging Face extension for the SageMaker Python SDK means we can benefit from "),qt=o("a"),Ic=s("fully-managed EC2 spot instances"),Nc=s(". This can help you save up to 90% of training costs!"),Ao=h(),$a=o("p"),ne=o("em"),Hc=s("Note: Unless your training job completes quickly, we recommend you use "),It=o("a"),Fc=s("checkpointing"),Lc=s(" with managed spot training. In this case, you need to define the "),nr=o("code"),zc=s("checkpoint_s3_uri"),Rc=s("."),Mo=h(),H=o("p"),Uc=s("Set "),lr=o("code"),Gc=s("use_spot_instances=True"),Wc=s(" and define your "),ir=o("code"),Bc=s("max_wait"),Xc=s(" and "),pr=o("code"),Jc=s("max_run"),Kc=s(" time in the Estimator to use spot instances:"),Po=h(),m(Nt.$$.fragment),To=h(),Le=o("p"),Vc=s("\u{1F4D3} Open the "),Ht=o("a"),Yc=s("notebook"),Qc=s(" for an example of how to use spot instances."),Co=h(),le=o("h2"),ze=o("a"),cr=o("span"),m(Ft.$$.fragment),Zc=h(),hr=o("span"),eh=s("Git repository"),Do=h(),F=o("p"),th=s("The Hugging Face Estimator can load a training script "),Lt=o("a"),ah=s("stored in a GitHub repository"),sh=s(". Provide the relative path to the training script in "),fr=o("code"),rh=s("entry_point"),oh=s(" and the relative path to the directory in "),mr=o("code"),nh=s("source_dir"),lh=s("."),Oo=h(),w=o("p"),ih=s("If you are using "),ur=o("code"),ph=s("git_config"),ch=s(" to run the "),zt=o("a"),hh=s("\u{1F917} Transformers example scripts"),fh=s(", you need to configure the correct "),dr=o("code"),mh=s("'branch'"),uh=s(" in "),gr=o("code"),dh=s("transformers_version"),gh=s(" (e.g. if you use "),_r=o("code"),_h=s("transformers_version='4.4.2"),vh=s(" you have to use "),vr=o("code"),yh=s("'branch':'v4.4.2'"),Eh=s(")."),qo=h(),xa=o("p"),Rt=o("em"),bh=s("Tip: Save your model to S3 by setting "),yr=o("code"),wh=s("output_dir=/opt/ml/model"),kh=s(" in the hyperparameter of your training script."),Io=h(),m(Ut.$$.fragment),No=h(),ie=o("h2"),Re=o("a"),Er=o("span"),m(Gt.$$.fragment),$h=h(),br=o("span"),xh=s("SageMaker metrics"),Ho=h(),Wt=o("p"),Bt=o("a"),jh=s("SageMaker metrics"),Sh=s(" automatically parses training job logs for metrics and sends them to CloudWatch. If you want SageMaker to parse the logs, you must specify the metric\u2019s name and a regular expression for SageMaker to use to find the metric."),Fo=h(),m(Xt.$$.fragment),Lo=h(),Ue=o("p"),Ah=s("\u{1F4D3} Open the "),Jt=o("a"),Mh=s("notebook"),Ph=s(" for an example of how to capture metrics in SageMaker."),this.h()},l(e){const i=Uu('[data-svelte="svelte-1phssyn"]',document.head);X=n(i,"META",{name:!0,content:!0}),i.forEach(a),xr=f(e),J=n(e,"H1",{class:!0});var Ro=l(J);pe=n(Ro,"A",{id:!0,class:!0,href:!0});var Wh=l(pe);Ta=n(Wh,"SPAN",{});var Bh=l(Ta);u(Ke.$$.fragment,Bh),Bh.forEach(a),Wh.forEach(a),kn=f(Ro),Ca=n(Ro,"SPAN",{});var Xh=l(Ca);$n=r(Xh,"Run training on Amazon SageMaker"),Xh.forEach(a),Ro.forEach(a),jr=f(e),M=n(e,"IFRAME",{width:!0,height:!0,src:!0,title:!0,frameborder:!0,allow:!0}),l(M).forEach(a),Sr=f(e),ce=n(e,"P",{});var Uo=l(ce);xn=r(Uo,"This guide will show you how to train a \u{1F917} Transformers model with the "),Da=n(Uo,"CODE",{});var Jh=l(Da);jn=r(Jh,"HuggingFace"),Jh.forEach(a),Sn=r(Uo," SageMaker Python SDK. Learn how to:"),Uo.forEach(a),Ar=f(e),y=n(e,"UL",{});var k=l(y);Vt=n(k,"LI",{});var Th=l(Vt);Yt=n(Th,"A",{href:!0});var Kh=l(Yt);An=r(Kh,"Install and setup your training environment"),Kh.forEach(a),Mn=r(Th,"."),Th.forEach(a),Pn=f(k),Qt=n(k,"LI",{});var Ch=l(Qt);Zt=n(Ch,"A",{href:!0});var Vh=l(Zt);Tn=r(Vh,"Prepare a training script"),Vh.forEach(a),Cn=r(Ch,"."),Ch.forEach(a),Dn=f(k),ea=n(k,"LI",{});var Dh=l(ea);ta=n(Dh,"A",{href:!0});var Yh=l(ta);On=r(Yh,"Create a Hugging Face Estimator"),Yh.forEach(a),qn=r(Dh,"."),Dh.forEach(a),In=f(k),aa=n(k,"LI",{});var Oh=l(aa);he=n(Oh,"A",{href:!0});var Go=l(he);Nn=r(Go,"Run training with the "),Oa=n(Go,"CODE",{});var Qh=l(Oa);Hn=r(Qh,"fit"),Qh.forEach(a),Fn=r(Go," method"),Go.forEach(a),Ln=r(Oh,"."),Oh.forEach(a),zn=f(k),sa=n(k,"LI",{});var qh=l(sa);ra=n(qh,"A",{href:!0});var Zh=l(ra);Rn=r(Zh,"Access your trained model"),Zh.forEach(a),Un=r(qh,"."),qh.forEach(a),Gn=f(k),oa=n(k,"LI",{});var Ih=l(oa);na=n(Ih,"A",{href:!0});var ef=l(na);Wn=r(ef,"Perform distributed training"),ef.forEach(a),Bn=r(Ih,"."),Ih.forEach(a),Xn=f(k),la=n(k,"LI",{});var Nh=l(la);ia=n(Nh,"A",{href:!0});var tf=l(ia);Jn=r(tf,"Create a spot instance"),tf.forEach(a),Kn=r(Nh,"."),Nh.forEach(a),Vn=f(k),pa=n(k,"LI",{});var Hh=l(pa);ca=n(Hh,"A",{href:!0});var af=l(ca);Yn=r(af,"Load a training script from a GitHub repository"),af.forEach(a),Qn=r(Hh,"."),Hh.forEach(a),Zn=f(k),ha=n(k,"LI",{});var Fh=l(ha);fa=n(Fh,"A",{href:!0});var sf=l(fa);el=r(sf,"Collect training metrics"),sf.forEach(a),tl=r(Fh,"."),Fh.forEach(a),k.forEach(a),Mr=f(e),K=n(e,"H2",{class:!0});var Wo=l(K);fe=n(Wo,"A",{id:!0,class:!0,href:!0});var rf=l(fe);qa=n(rf,"SPAN",{});var of=l(qa);u(Ve.$$.fragment,of),of.forEach(a),rf.forEach(a),al=f(Wo),Ia=n(Wo,"SPAN",{});var nf=l(Ia);sl=r(nf,"Installation and setup"),nf.forEach(a),Wo.forEach(a),Pr=f(e),me=n(e,"P",{});var Bo=l(me);rl=r(Bo,"Before you can train a \u{1F917} Transformers model with SageMaker, you need to sign up for an AWS account. If you don\u2019t have an AWS account yet, learn more "),Ye=n(Bo,"A",{href:!0,rel:!0});var lf=l(Ye);ol=r(lf,"here"),lf.forEach(a),nl=r(Bo,"."),Bo.forEach(a),Tr=f(e),ma=n(e,"P",{});var pf=l(ma);ll=r(pf,"Once you have an AWS account, get started using one of the following:"),pf.forEach(a),Cr=f(e),L=n(e,"UL",{});var ja=l(L);Na=n(ja,"LI",{});var cf=l(Na);Qe=n(cf,"A",{href:!0,rel:!0});var hf=l(Qe);il=r(hf,"SageMaker Studio"),hf.forEach(a),cf.forEach(a),pl=f(ja),Ha=n(ja,"LI",{});var ff=l(Ha);Ze=n(ff,"A",{href:!0,rel:!0});var mf=l(Ze);cl=r(mf,"SageMaker notebook instance"),mf.forEach(a),ff.forEach(a),hl=f(ja),Fa=n(ja,"LI",{});var uf=l(Fa);fl=r(uf,"Local environment"),uf.forEach(a),ja.forEach(a),Dr=f(e),ue=n(e,"P",{});var Xo=l(ue);ml=r(Xo,"To start training locally, you need to setup an appropriate "),et=n(Xo,"A",{href:!0,rel:!0});var df=l(et);ul=r(df,"IAM role"),df.forEach(a),dl=r(Xo,"."),Xo.forEach(a),Or=f(e),de=n(e,"P",{});var Jo=l(de);gl=r(Jo,"Upgrade to the latest "),La=n(Jo,"CODE",{});var gf=l(La);_l=r(gf,"sagemaker"),gf.forEach(a),vl=r(Jo," version:"),Jo.forEach(a),qr=f(e),u(tt.$$.fragment,e),Ir=f(e),ua=n(e,"P",{});var _f=l(ua);za=n(_f,"STRONG",{});var vf=l(za);yl=r(vf,"SageMaker environment"),vf.forEach(a),_f.forEach(a),Nr=f(e),da=n(e,"P",{});var yf=l(da);El=r(yf,"Setup your SageMaker environment as shown below:"),yf.forEach(a),Hr=f(e),u(at.$$.fragment,e),Fr=f(e),ga=n(e,"P",{});var Ef=l(ga);V=n(Ef,"EM",{});var Sa=l(V);bl=r(Sa,"Note: The execution role is only available when running a notebook within SageMaker. If you run "),Ra=n(Sa,"CODE",{});var bf=l(Ra);wl=r(bf,"get_execution_role"),bf.forEach(a),kl=r(Sa," in a notebook not on SageMaker, expect a "),Ua=n(Sa,"CODE",{});var wf=l(Ua);$l=r(wf,"region"),wf.forEach(a),xl=r(Sa," error."),Sa.forEach(a),Ef.forEach(a),Lr=f(e),_a=n(e,"P",{});var kf=l(_a);Ga=n(kf,"STRONG",{});var $f=l(Ga);jl=r($f,"Local environment"),$f.forEach(a),kf.forEach(a),zr=f(e),va=n(e,"P",{});var xf=l(va);Sl=r(xf,"Setup your local environment as shown below:"),xf.forEach(a),Rr=f(e),u(st.$$.fragment,e),Ur=f(e),Y=n(e,"H2",{class:!0});var Ko=l(Y);ge=n(Ko,"A",{id:!0,class:!0,href:!0});var jf=l(ge);Wa=n(jf,"SPAN",{});var Sf=l(Wa);u(rt.$$.fragment,Sf),Sf.forEach(a),jf.forEach(a),Al=f(Ko),Ba=n(Ko,"SPAN",{});var Af=l(Ba);Ml=r(Af,"Prepare a \u{1F917} Transformers fine-tuning script"),Af.forEach(a),Ko.forEach(a),Gr=f(e),_e=n(e,"P",{});var Vo=l(_e);Pl=r(Vo,"Our training script is very similar to a training script you might run outside of SageMaker. However, you can access useful properties about the training environment through various environment variables (see "),ot=n(Vo,"A",{href:!0,rel:!0});var Mf=l(ot);Tl=r(Mf,"here"),Mf.forEach(a),Cl=r(Vo," for a complete list), such as:"),Vo.forEach(a),Wr=f(e),z=n(e,"UL",{});var Aa=l(z);Xa=n(Aa,"LI",{});var Pf=l(Xa);R=n(Pf,"P",{});var Kt=l(R);Ja=n(Kt,"CODE",{});var Tf=l(Ja);Dl=r(Tf,"SM_MODEL_DIR"),Tf.forEach(a),Ol=r(Kt,": A string representing the path to which the training job writes the model artifacts. After training, artifacts in this directory are uploaded to S3 for model hosting. "),Ka=n(Kt,"CODE",{});var Cf=l(Ka);ql=r(Cf,"SM_MODEL_DIR"),Cf.forEach(a),Il=r(Kt," is always set to "),Va=n(Kt,"CODE",{});var Df=l(Va);Nl=r(Df,"/opt/ml/model"),Df.forEach(a),Hl=r(Kt,"."),Kt.forEach(a),Pf.forEach(a),Fl=f(Aa),Ya=n(Aa,"LI",{});var Of=l(Ya);ya=n(Of,"P",{});var Lh=l(ya);Qa=n(Lh,"CODE",{});var qf=l(Qa);Ll=r(qf,"SM_NUM_GPUS"),qf.forEach(a),zl=r(Lh,": An integer representing the number of GPUs available to the host."),Lh.forEach(a),Of.forEach(a),Rl=f(Aa),Za=n(Aa,"LI",{});var If=l(Za);x=n(If,"P",{});var C=l(x);es=n(C,"CODE",{});var Nf=l(es);Ul=r(Nf,"SM_CHANNEL_XXXX:"),Nf.forEach(a),Gl=r(C," A string representing the path to the directory that contains the input data for the specified channel. For example, when you specify "),ts=n(C,"CODE",{});var Hf=l(ts);Wl=r(Hf,"train"),Hf.forEach(a),Bl=r(C," and "),as=n(C,"CODE",{});var Ff=l(as);Xl=r(Ff,"test"),Ff.forEach(a),Jl=r(C," in the Hugging Face Estimator "),ss=n(C,"CODE",{});var Lf=l(ss);Kl=r(Lf,"fit"),Lf.forEach(a),Vl=r(C," method, the environment variables are set to "),rs=n(C,"CODE",{});var zf=l(rs);Yl=r(zf,"SM_CHANNEL_TRAIN"),zf.forEach(a),Ql=r(C," and "),os=n(C,"CODE",{});var Rf=l(os);Zl=r(Rf,"SM_CHANNEL_TEST"),Rf.forEach(a),ei=r(C,"."),C.forEach(a),If.forEach(a),Aa.forEach(a),Br=f(e),q=n(e,"P",{});var Ge=l(q);ti=r(Ge,"The "),ns=n(Ge,"CODE",{});var Uf=l(ns);ai=r(Uf,"hyperparameters"),Uf.forEach(a),si=r(Ge," defined in the "),Ea=n(Ge,"A",{href:!0});var Gf=l(Ea);ri=r(Gf,"Hugging Face Estimator"),Gf.forEach(a),oi=r(Ge," are passed as named arguments and processed by "),ls=n(Ge,"CODE",{});var Wf=l(ls);ni=r(Wf,"ArgumentParser()"),Wf.forEach(a),li=r(Ge,"."),Ge.forEach(a),Xr=f(e),u(nt.$$.fragment,e),Jr=f(e),ba=n(e,"P",{});var Bf=l(ba);P=n(Bf,"EM",{});var G=l(P);ii=r(G,"Note that SageMaker doesn\u2019t support argparse actions. For example, if you want to use a boolean hyperparameter, specify "),is=n(G,"CODE",{});var Xf=l(is);pi=r(Xf,"type"),Xf.forEach(a),ci=r(G," as "),ps=n(G,"CODE",{});var Jf=l(ps);hi=r(Jf,"bool"),Jf.forEach(a),fi=r(G," in your script and provide an explicit "),cs=n(G,"CODE",{});var Kf=l(cs);mi=r(Kf,"True"),Kf.forEach(a),ui=r(G," or "),hs=n(G,"CODE",{});var Vf=l(hs);di=r(Vf,"False"),Vf.forEach(a),gi=r(G," value."),G.forEach(a),Bf.forEach(a),Kr=f(e),ve=n(e,"P",{});var Yo=l(ve);_i=r(Yo,"Look "),lt=n(Yo,"A",{href:!0,rel:!0});var Yf=l(lt);vi=r(Yf,"here"),Yf.forEach(a),yi=r(Yo," for a complete example of a \u{1F917} Transformers training script."),Yo.forEach(a),Vr=f(e),Q=n(e,"H2",{class:!0});var Qo=l(Q);ye=n(Qo,"A",{id:!0,class:!0,href:!0});var Qf=l(ye);fs=n(Qf,"SPAN",{});var Zf=l(fs);u(it.$$.fragment,Zf),Zf.forEach(a),Qf.forEach(a),Ei=f(Qo),ms=n(Qo,"SPAN",{});var em=l(ms);bi=r(em,"Training Output Management"),em.forEach(a),Qo.forEach(a),Yr=f(e),E=n(e,"P",{});var $=l(E);wi=r($,"If "),us=n($,"CODE",{});var tm=l(us);ki=r(tm,"output_dir"),tm.forEach(a),$i=r($," in the "),ds=n($,"CODE",{});var am=l(ds);xi=r(am,"TrainingArguments"),am.forEach(a),ji=r($," is set to \u2018/opt/ml/model\u2019 the Trainer saves all training artifacts, including logs, checkpoints, and models. Amazon SageMaker archives the whole \u2018/opt/ml/model\u2019 directory as "),gs=n($,"CODE",{});var sm=l(gs);Si=r(sm,"model.tar.gz"),sm.forEach(a),Ai=r($," and uploads it at the end of the training job to Amazon S3. Depending on your Hyperparameters and "),_s=n($,"CODE",{});var rm=l(_s);Mi=r(rm,"TrainingArguments"),rm.forEach(a),Pi=r($,` this could lead to a large artifact (> 5GB), which can slow down deployment for Amazon SageMaker Inference.
You can control how checkpoints, logs, and artifacts are saved by customization the `),pt=n($,"A",{href:!0,rel:!0});var om=l(pt);Ti=r(om,"TrainingArguments"),om.forEach(a),Ci=r($,". For example by providing "),vs=n($,"CODE",{});var nm=l(vs);Di=r(nm,"save_total_limit"),nm.forEach(a),Oi=r($," as "),ys=n($,"CODE",{});var lm=l(ys);qi=r(lm,"TrainingArgument"),lm.forEach(a),Ii=r($," you can control the limit of the total amount of checkpoints. Deletes the older checkpoints in "),Es=n($,"CODE",{});var im=l(Es);Ni=r(im,"output_dir"),im.forEach(a),Hi=r($," if new ones are saved and the maximum limit is reached."),$.forEach(a),Qr=f(e),b=n(e,"P",{});var j=l(b);Fi=r(j,"In addition to the options already mentioned above, there is another option to save the training artifacts during the training session. Amazon SageMaker supports "),ct=n(j,"A",{href:!0,rel:!0});var pm=l(ct);Li=r(pm,"Checkpointing"),pm.forEach(a),zi=r(j,", which allows you to continuously save your artifacts during training to Amazon S3 rather than at the end of your training. To enable "),ht=n(j,"A",{href:!0,rel:!0});var cm=l(ht);Ri=r(cm,"Checkpointing"),cm.forEach(a),Ui=r(j," you need to provide the "),bs=n(j,"CODE",{});var hm=l(bs);Gi=r(hm,"checkpoint_s3_uri"),hm.forEach(a),Wi=r(j," parameter pointing to an Amazon S3 location in the "),ws=n(j,"CODE",{});var fm=l(ws);Bi=r(fm,"HuggingFace"),fm.forEach(a),Xi=r(j," estimator and set "),ks=n(j,"CODE",{});var mm=l(ks);Ji=r(mm,"output_dir"),mm.forEach(a),Ki=r(j," to "),$s=n(j,"CODE",{});var um=l($s);Vi=r(um,"/opt/ml/checkpoints"),um.forEach(a),Yi=r(j,`.
`),T=n(j,"EM",{});var W=l(T);Qi=r(W,"Note: If you set "),xs=n(W,"CODE",{});var dm=l(xs);Zi=r(dm,"output_dir"),dm.forEach(a),ep=r(W," to "),js=n(W,"CODE",{});var gm=l(js);tp=r(gm,"/opt/ml/checkpoints"),gm.forEach(a),ap=r(W," make sure to call "),Ss=n(W,"CODE",{});var _m=l(Ss);sp=r(_m,'trainer.save_model("/opt/ml/model")'),_m.forEach(a),rp=r(W," or model.save_pretrained(\u201C/opt/ml/model\u201D)/"),As=n(W,"CODE",{});var vm=l(As);op=r(vm,'tokenizer.save_pretrained("/opt/ml/model")'),vm.forEach(a),np=r(W," at the end of your training to be able to deploy your model seamlessly to Amazon SageMaker for Inference."),W.forEach(a),j.forEach(a),Zr=f(e),Z=n(e,"H2",{class:!0});var Zo=l(Z);Ee=n(Zo,"A",{id:!0,class:!0,href:!0});var ym=l(Ee);Ms=n(ym,"SPAN",{});var Em=l(Ms);u(ft.$$.fragment,Em),Em.forEach(a),ym.forEach(a),lp=f(Zo),Ps=n(Zo,"SPAN",{});var bm=l(Ps);ip=r(bm,"Create a Hugging Face Estimator"),bm.forEach(a),Zo.forEach(a),eo=f(e),be=n(e,"P",{});var en=l(be);pp=r(en,"Run \u{1F917} Transformers training scripts on SageMaker by creating a "),mt=n(en,"A",{href:!0,rel:!0});var wm=l(mt);cp=r(wm,"Hugging Face Estimator"),wm.forEach(a),hp=r(en,". The Estimator handles end-to-end SageMaker training. There are several parameters you should define in the Estimator:"),en.forEach(a),to=f(e),U=n(e,"OL",{});var Ma=l(U);wa=n(Ma,"LI",{});var zh=l(wa);Ts=n(zh,"CODE",{});var km=l(Ts);fp=r(km,"entry_point"),km.forEach(a),mp=r(zh," specifies which fine-tuning script to use."),zh.forEach(a),up=f(Ma),we=n(Ma,"LI",{});var wr=l(we);Cs=n(wr,"CODE",{});var $m=l(Cs);dp=r($m,"instance_type"),$m.forEach(a),gp=r(wr," specifies an Amazon instance to launch. Refer "),ut=n(wr,"A",{href:!0,rel:!0});var xm=l(ut);_p=r(xm,"here"),xm.forEach(a),vp=r(wr," for a complete list of instance types."),wr.forEach(a),yp=f(Ma),ke=n(Ma,"LI",{});var kr=l(ke);Ds=n(kr,"CODE",{});var jm=l(Ds);Ep=r(jm,"hyperparameters"),jm.forEach(a),bp=r(kr," specifies training hyperparameters. View additional available hyperparameters "),dt=n(kr,"A",{href:!0,rel:!0});var Sm=l(dt);wp=r(Sm,"here"),Sm.forEach(a),kp=r(kr,"."),kr.forEach(a),Ma.forEach(a),ao=f(e),S=n(e,"P",{});var B=l(S);$p=r(B,"The following code sample shows how to train with a custom script "),Os=n(B,"CODE",{});var Am=l(Os);xp=r(Am,"train.py"),Am.forEach(a),jp=r(B," with three hyperparameters ("),qs=n(B,"CODE",{});var Mm=l(qs);Sp=r(Mm,"epochs"),Mm.forEach(a),Ap=r(B,", "),Is=n(B,"CODE",{});var Pm=l(Is);Mp=r(Pm,"per_device_train_batch_size"),Pm.forEach(a),Pp=r(B,", and "),Ns=n(B,"CODE",{});var Tm=l(Ns);Tp=r(Tm,"model_name_or_path"),Tm.forEach(a),Cp=r(B,"):"),B.forEach(a),so=f(e),u(gt.$$.fragment,e),ro=f(e),I=n(e,"P",{});var We=l(I);Dp=r(We,"If you are running a "),Hs=n(We,"CODE",{});var Cm=l(Hs);Op=r(Cm,"TrainingJob"),Cm.forEach(a),qp=r(We," locally, define "),Fs=n(We,"CODE",{});var Dm=l(Fs);Ip=r(Dm,"instance_type='local'"),Dm.forEach(a),Np=r(We," or "),Ls=n(We,"CODE",{});var Om=l(Ls);Hp=r(Om,"instance_type='local-gpu'"),Om.forEach(a),Fp=r(We," for GPU usage. Note that this will not work with SageMaker Studio."),We.forEach(a),oo=f(e),ee=n(e,"H2",{class:!0});var tn=l(ee);$e=n(tn,"A",{id:!0,class:!0,href:!0});var qm=l($e);zs=n(qm,"SPAN",{});var Im=l(zs);u(_t.$$.fragment,Im),Im.forEach(a),qm.forEach(a),Lp=f(tn),Rs=n(tn,"SPAN",{});var Nm=l(Rs);zp=r(Nm,"Execute training"),Nm.forEach(a),tn.forEach(a),no=f(e),N=n(e,"P",{});var Be=l(N);Rp=r(Be,"Start your "),Us=n(Be,"CODE",{});var Hm=l(Us);Up=r(Hm,"TrainingJob"),Hm.forEach(a),Gp=r(Be," by calling "),Gs=n(Be,"CODE",{});var Fm=l(Gs);Wp=r(Fm,"fit"),Fm.forEach(a),Bp=r(Be," on a Hugging Face Estimator. Specify your input training data in "),Ws=n(Be,"CODE",{});var Lm=l(Ws);Xp=r(Lm,"fit"),Lm.forEach(a),Jp=r(Be,". The input training data can be a:"),Be.forEach(a),lo=f(e),xe=n(e,"UL",{});var an=l(xe);vt=n(an,"LI",{});var sn=l(vt);Kp=r(sn,"S3 URI such as "),Bs=n(sn,"CODE",{});var zm=l(Bs);Vp=r(zm,"s3://my-bucket/my-training-data"),zm.forEach(a),Yp=r(sn,"."),sn.forEach(a),Qp=f(an),je=n(an,"LI",{});var $r=l(je);Xs=n($r,"CODE",{});var Rm=l(Xs);Zp=r(Rm,"FileSystemInput"),Rm.forEach(a),ec=r($r," for Amazon Elastic File System or FSx for Lustre. See "),yt=n($r,"A",{href:!0,rel:!0});var Um=l(yt);tc=r(Um,"here"),Um.forEach(a),ac=r($r," for more details about using these file systems as input."),$r.forEach(a),an.forEach(a),io=f(e),Se=n(e,"P",{});var rn=l(Se);sc=r(rn,"Call "),Js=n(rn,"CODE",{});var Gm=l(Js);rc=r(Gm,"fit"),Gm.forEach(a),oc=r(rn," to begin training:"),rn.forEach(a),po=f(e),u(Et.$$.fragment,e),co=f(e),Ae=n(e,"P",{});var on=l(Ae);nc=r(on,"SageMaker starts and manages all the required EC2 instances and initiates the "),Ks=n(on,"CODE",{});var Wm=l(Ks);lc=r(Wm,"TrainingJob"),Wm.forEach(a),ic=r(on," by running:"),on.forEach(a),ho=f(e),u(bt.$$.fragment,e),fo=f(e),te=n(e,"H2",{class:!0});var nn=l(te);Me=n(nn,"A",{id:!0,class:!0,href:!0});var Bm=l(Me);Vs=n(Bm,"SPAN",{});var Xm=l(Vs);u(wt.$$.fragment,Xm),Xm.forEach(a),Bm.forEach(a),pc=f(nn),Ys=n(nn,"SPAN",{});var Jm=l(Ys);cc=r(Jm,"Access trained model"),Jm.forEach(a),nn.forEach(a),mo=f(e),Pe=n(e,"P",{});var ln=l(Pe);hc=r(ln,"Once training is complete, you can access your model through the "),kt=n(ln,"A",{href:!0,rel:!0});var Km=l(kt);fc=r(Km,"AWS console"),Km.forEach(a),mc=r(ln," or download it directly from S3."),ln.forEach(a),uo=f(e),u($t.$$.fragment,e),go=f(e),ae=n(e,"H2",{class:!0});var pn=l(ae);Te=n(pn,"A",{id:!0,class:!0,href:!0});var Vm=l(Te);Qs=n(Vm,"SPAN",{});var Ym=l(Qs);u(xt.$$.fragment,Ym),Ym.forEach(a),Vm.forEach(a),uc=f(pn),Zs=n(pn,"SPAN",{});var Qm=l(Zs);dc=r(Qm,"Distributed training"),Qm.forEach(a),pn.forEach(a),_o=f(e),ka=n(e,"P",{});var Zm=l(ka);gc=r(Zm,"SageMaker provides two strategies for distributed training: data parallelism and model parallelism. Data parallelism splits a training set across several GPUs, while model parallelism splits a model across several GPUs."),Zm.forEach(a),vo=f(e),se=n(e,"H3",{class:!0});var cn=l(se);Ce=n(cn,"A",{id:!0,class:!0,href:!0});var eu=l(Ce);er=n(eu,"SPAN",{});var tu=l(er);u(jt.$$.fragment,tu),tu.forEach(a),eu.forEach(a),_c=f(cn),tr=n(cn,"SPAN",{});var au=l(tr);vc=r(au,"Data parallelism"),au.forEach(a),cn.forEach(a),yo=f(e),De=n(e,"P",{});var hn=l(De);yc=r(hn,"The Hugging Face "),St=n(hn,"A",{href:!0,rel:!0});var su=l(St);Ec=r(su,"Trainer"),su.forEach(a),bc=r(hn," supports SageMaker\u2019s data parallelism library. If your training script uses the Trainer API, you only need to define the distribution parameter in the Hugging Face Estimator:"),hn.forEach(a),Eo=f(e),u(At.$$.fragment,e),bo=f(e),Oe=n(e,"P",{});var fn=l(Oe);wc=r(fn,"\u{1F4D3} Open the "),Mt=n(fn,"A",{href:!0,rel:!0});var ru=l(Mt);kc=r(ru,"notebook"),ru.forEach(a),$c=r(fn," for an example of how to run the data parallelism library with TensorFlow."),fn.forEach(a),wo=f(e),re=n(e,"H3",{class:!0});var mn=l(re);qe=n(mn,"A",{id:!0,class:!0,href:!0});var ou=l(qe);ar=n(ou,"SPAN",{});var nu=l(ar);u(Pt.$$.fragment,nu),nu.forEach(a),ou.forEach(a),xc=f(mn),sr=n(mn,"SPAN",{});var lu=l(sr);jc=r(lu,"Model parallelism"),lu.forEach(a),mn.forEach(a),ko=f(e),Ie=n(e,"P",{});var un=l(Ie);Sc=r(un,"The Hugging Face [Trainer] also supports SageMaker\u2019s model parallelism library. If your training script uses the Trainer API, you only need to define the distribution parameter in the Hugging Face Estimator (see "),Tt=n(un,"A",{href:!0,rel:!0});var iu=l(Tt);Ac=r(iu,"here"),iu.forEach(a),Mc=r(un," for more detailed information about using model parallelism):"),un.forEach(a),$o=f(e),u(Ct.$$.fragment,e),xo=f(e),Ne=n(e,"P",{});var dn=l(Ne);Pc=r(dn,"\u{1F4D3} Open the "),Dt=n(dn,"A",{href:!0,rel:!0});var pu=l(Dt);Tc=r(pu,"notebook"),pu.forEach(a),Cc=r(dn," for an example of how to run the model parallelism library."),dn.forEach(a),jo=f(e),oe=n(e,"H2",{class:!0});var gn=l(oe);He=n(gn,"A",{id:!0,class:!0,href:!0});var cu=l(He);rr=n(cu,"SPAN",{});var hu=l(rr);u(Ot.$$.fragment,hu),hu.forEach(a),cu.forEach(a),Dc=f(gn),or=n(gn,"SPAN",{});var fu=l(or);Oc=r(fu,"Spot instances"),fu.forEach(a),gn.forEach(a),So=f(e),Fe=n(e,"P",{});var _n=l(Fe);qc=r(_n,"The Hugging Face extension for the SageMaker Python SDK means we can benefit from "),qt=n(_n,"A",{href:!0,rel:!0});var mu=l(qt);Ic=r(mu,"fully-managed EC2 spot instances"),mu.forEach(a),Nc=r(_n,". This can help you save up to 90% of training costs!"),_n.forEach(a),Ao=f(e),$a=n(e,"P",{});var uu=l($a);ne=n(uu,"EM",{});var Pa=l(ne);Hc=r(Pa,"Note: Unless your training job completes quickly, we recommend you use "),It=n(Pa,"A",{href:!0,rel:!0});var du=l(It);Fc=r(du,"checkpointing"),du.forEach(a),Lc=r(Pa," with managed spot training. In this case, you need to define the "),nr=n(Pa,"CODE",{});var gu=l(nr);zc=r(gu,"checkpoint_s3_uri"),gu.forEach(a),Rc=r(Pa,"."),Pa.forEach(a),uu.forEach(a),Mo=f(e),H=n(e,"P",{});var Xe=l(H);Uc=r(Xe,"Set "),lr=n(Xe,"CODE",{});var _u=l(lr);Gc=r(_u,"use_spot_instances=True"),_u.forEach(a),Wc=r(Xe," and define your "),ir=n(Xe,"CODE",{});var vu=l(ir);Bc=r(vu,"max_wait"),vu.forEach(a),Xc=r(Xe," and "),pr=n(Xe,"CODE",{});var yu=l(pr);Jc=r(yu,"max_run"),yu.forEach(a),Kc=r(Xe," time in the Estimator to use spot instances:"),Xe.forEach(a),Po=f(e),u(Nt.$$.fragment,e),To=f(e),Le=n(e,"P",{});var vn=l(Le);Vc=r(vn,"\u{1F4D3} Open the "),Ht=n(vn,"A",{href:!0,rel:!0});var Eu=l(Ht);Yc=r(Eu,"notebook"),Eu.forEach(a),Qc=r(vn," for an example of how to use spot instances."),vn.forEach(a),Co=f(e),le=n(e,"H2",{class:!0});var yn=l(le);ze=n(yn,"A",{id:!0,class:!0,href:!0});var bu=l(ze);cr=n(bu,"SPAN",{});var wu=l(cr);u(Ft.$$.fragment,wu),wu.forEach(a),bu.forEach(a),Zc=f(yn),hr=n(yn,"SPAN",{});var ku=l(hr);eh=r(ku,"Git repository"),ku.forEach(a),yn.forEach(a),Do=f(e),F=n(e,"P",{});var Je=l(F);th=r(Je,"The Hugging Face Estimator can load a training script "),Lt=n(Je,"A",{href:!0,rel:!0});var $u=l(Lt);ah=r($u,"stored in a GitHub repository"),$u.forEach(a),sh=r(Je,". Provide the relative path to the training script in "),fr=n(Je,"CODE",{});var xu=l(fr);rh=r(xu,"entry_point"),xu.forEach(a),oh=r(Je," and the relative path to the directory in "),mr=n(Je,"CODE",{});var ju=l(mr);nh=r(ju,"source_dir"),ju.forEach(a),lh=r(Je,"."),Je.forEach(a),Oo=f(e),w=n(e,"P",{});var A=l(w);ih=r(A,"If you are using "),ur=n(A,"CODE",{});var Su=l(ur);ph=r(Su,"git_config"),Su.forEach(a),ch=r(A," to run the "),zt=n(A,"A",{href:!0,rel:!0});var Au=l(zt);hh=r(Au,"\u{1F917} Transformers example scripts"),Au.forEach(a),fh=r(A,", you need to configure the correct "),dr=n(A,"CODE",{});var Mu=l(dr);mh=r(Mu,"'branch'"),Mu.forEach(a),uh=r(A," in "),gr=n(A,"CODE",{});var Pu=l(gr);dh=r(Pu,"transformers_version"),Pu.forEach(a),gh=r(A," (e.g. if you use "),_r=n(A,"CODE",{});var Tu=l(_r);_h=r(Tu,"transformers_version='4.4.2"),Tu.forEach(a),vh=r(A," you have to use "),vr=n(A,"CODE",{});var Cu=l(vr);yh=r(Cu,"'branch':'v4.4.2'"),Cu.forEach(a),Eh=r(A,")."),A.forEach(a),qo=f(e),xa=n(e,"P",{});var Du=l(xa);Rt=n(Du,"EM",{});var En=l(Rt);bh=r(En,"Tip: Save your model to S3 by setting "),yr=n(En,"CODE",{});var Ou=l(yr);wh=r(Ou,"output_dir=/opt/ml/model"),Ou.forEach(a),kh=r(En," in the hyperparameter of your training script."),En.forEach(a),Du.forEach(a),Io=f(e),u(Ut.$$.fragment,e),No=f(e),ie=n(e,"H2",{class:!0});var bn=l(ie);Re=n(bn,"A",{id:!0,class:!0,href:!0});var qu=l(Re);Er=n(qu,"SPAN",{});var Iu=l(Er);u(Gt.$$.fragment,Iu),Iu.forEach(a),qu.forEach(a),$h=f(bn),br=n(bn,"SPAN",{});var Nu=l(br);xh=r(Nu,"SageMaker metrics"),Nu.forEach(a),bn.forEach(a),Ho=f(e),Wt=n(e,"P",{});var Rh=l(Wt);Bt=n(Rh,"A",{href:!0,rel:!0});var Hu=l(Bt);jh=r(Hu,"SageMaker metrics"),Hu.forEach(a),Sh=r(Rh," automatically parses training job logs for metrics and sends them to CloudWatch. If you want SageMaker to parse the logs, you must specify the metric\u2019s name and a regular expression for SageMaker to use to find the metric."),Rh.forEach(a),Fo=f(e),u(Xt.$$.fragment,e),Lo=f(e),Ue=n(e,"P",{});var wn=l(Ue);Ah=r(wn,"\u{1F4D3} Open the "),Jt=n(wn,"A",{href:!0,rel:!0});var Fu=l(Jt);Mh=r(Fu,"notebook"),Fu.forEach(a),Ph=r(wn," for an example of how to capture metrics in SageMaker."),wn.forEach(a),this.h()},h(){c(X,"name","hf:doc:metadata"),c(X,"content",JSON.stringify(Ju)),c(pe,"id","run-training-on-amazon-sagemaker"),c(pe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(pe,"href","#run-training-on-amazon-sagemaker"),c(J,"class","relative group"),c(M,"width","700"),c(M,"height","394"),Gu(M.src,Gh="https://www.youtube.com/embed/ok3hetb42gU")||c(M,"src",Gh),c(M,"title","YouTube video player"),c(M,"frameborder","0"),c(M,"allow","accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"),M.allowFullscreen=!0,c(Yt,"href","#installation-and-setup"),c(Zt,"href","#prepare-a-transformers-fine-tuning-script"),c(ta,"href","#create-a-hugging-face-estimator"),c(he,"href","#execute-training"),c(ra,"href","#access-trained-model"),c(na,"href","#distributed-training"),c(ia,"href","#spot-instances"),c(ca,"href","#git-repository"),c(fa,"href","#sagemaker-metrics"),c(fe,"id","installation-and-setup"),c(fe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(fe,"href","#installation-and-setup"),c(K,"class","relative group"),c(Ye,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/gs-set-up.html"),c(Ye,"rel","nofollow"),c(Qe,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/gs-studio-onboard.html"),c(Qe,"rel","nofollow"),c(Ze,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/gs-console.html"),c(Ze,"rel","nofollow"),c(et,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html"),c(et,"rel","nofollow"),c(ge,"id","prepare-a-transformers-finetuning-script"),c(ge,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ge,"href","#prepare-a-transformers-finetuning-script"),c(Y,"class","relative group"),c(ot,"href","https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md"),c(ot,"rel","nofollow"),c(Ea,"href","#create-an-huggingface-estimator"),c(lt,"href","https://github.com/huggingface/notebooks/blob/main/sagemaker/01_getting_started_pytorch/scripts/train.py"),c(lt,"rel","nofollow"),c(ye,"id","training-output-management"),c(ye,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ye,"href","#training-output-management"),c(Q,"class","relative group"),c(pt,"href","https://huggingface.co/docs/transformers/master/en/main_classes/trainer#transformers.TrainingArguments"),c(pt,"rel","nofollow"),c(ct,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/model-checkpoints.html"),c(ct,"rel","nofollow"),c(ht,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/model-checkpoints.html"),c(ht,"rel","nofollow"),c(Ee,"id","create-a-hugging-face-estimator"),c(Ee,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ee,"href","#create-a-hugging-face-estimator"),c(Z,"class","relative group"),c(mt,"href","https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html#huggingface-estimator"),c(mt,"rel","nofollow"),c(ut,"href","https://aws.amazon.com/sagemaker/pricing/"),c(ut,"rel","nofollow"),c(dt,"href","https://github.com/huggingface/notebooks/blob/main/sagemaker/01_getting_started_pytorch/scripts/train.py"),c(dt,"rel","nofollow"),c($e,"id","execute-training"),c($e,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c($e,"href","#execute-training"),c(ee,"class","relative group"),c(yt,"href","https://sagemaker.readthedocs.io/en/stable/overview.html?highlight=FileSystemInput#use-file-systems-as-training-inputs"),c(yt,"rel","nofollow"),c(Me,"id","access-trained-model"),c(Me,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Me,"href","#access-trained-model"),c(te,"class","relative group"),c(kt,"href","https://console.aws.amazon.com/console/home?nc2=h_ct&src=header-signin"),c(kt,"rel","nofollow"),c(Te,"id","distributed-training"),c(Te,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Te,"href","#distributed-training"),c(ae,"class","relative group"),c(Ce,"id","data-parallelism"),c(Ce,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Ce,"href","#data-parallelism"),c(se,"class","relative group"),c(St,"href","https://huggingface.co/transformers/main_classes/trainer.html"),c(St,"rel","nofollow"),c(Mt,"href","https://github.com/huggingface/notebooks/blob/main/sagemaker/07_tensorflow_distributed_training_data_parallelism/sagemaker-notebook.ipynb"),c(Mt,"rel","nofollow"),c(qe,"id","model-parallelism"),c(qe,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(qe,"href","#model-parallelism"),c(re,"class","relative group"),c(Tt,"href","https://sagemaker.readthedocs.io/en/stable/api/training/smd_model_parallel_general.html?highlight=modelparallel#required-sagemaker-python-sdk-parameters"),c(Tt,"rel","nofollow"),c(Dt,"href","https://github.com/huggingface/notebooks/blob/main/sagemaker/04_distributed_training_model_parallelism/sagemaker-notebook.ipynb"),c(Dt,"rel","nofollow"),c(He,"id","spot-instances"),c(He,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(He,"href","#spot-instances"),c(oe,"class","relative group"),c(qt,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html"),c(qt,"rel","nofollow"),c(It,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/model-checkpoints.html"),c(It,"rel","nofollow"),c(Ht,"href","https://github.com/huggingface/notebooks/blob/main/sagemaker/05_spot_instances/sagemaker-notebook.ipynb"),c(Ht,"rel","nofollow"),c(ze,"id","git-repository"),c(ze,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(ze,"href","#git-repository"),c(le,"class","relative group"),c(Lt,"href","https://sagemaker.readthedocs.io/en/stable/overview.html#use-scripts-stored-in-a-git-repository"),c(Lt,"rel","nofollow"),c(zt,"href","https://github.com/huggingface/transformers/tree/master/examples"),c(zt,"rel","nofollow"),c(Re,"id","sagemaker-metrics"),c(Re,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),c(Re,"href","#sagemaker-metrics"),c(ie,"class","relative group"),c(Bt,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/training-metrics.html#define-train-metrics"),c(Bt,"rel","nofollow"),c(Jt,"href","https://github.com/huggingface/notebooks/blob/main/sagemaker/06_sagemaker_metrics/sagemaker-notebook.ipynb"),c(Jt,"rel","nofollow")},m(e,i){t(document.head,X),p(e,xr,i),p(e,J,i),t(J,pe),t(pe,Ta),d(Ke,Ta,null),t(J,kn),t(J,Ca),t(Ca,$n),p(e,jr,i),p(e,M,i),p(e,Sr,i),p(e,ce,i),t(ce,xn),t(ce,Da),t(Da,jn),t(ce,Sn),p(e,Ar,i),p(e,y,i),t(y,Vt),t(Vt,Yt),t(Yt,An),t(Vt,Mn),t(y,Pn),t(y,Qt),t(Qt,Zt),t(Zt,Tn),t(Qt,Cn),t(y,Dn),t(y,ea),t(ea,ta),t(ta,On),t(ea,qn),t(y,In),t(y,aa),t(aa,he),t(he,Nn),t(he,Oa),t(Oa,Hn),t(he,Fn),t(aa,Ln),t(y,zn),t(y,sa),t(sa,ra),t(ra,Rn),t(sa,Un),t(y,Gn),t(y,oa),t(oa,na),t(na,Wn),t(oa,Bn),t(y,Xn),t(y,la),t(la,ia),t(ia,Jn),t(la,Kn),t(y,Vn),t(y,pa),t(pa,ca),t(ca,Yn),t(pa,Qn),t(y,Zn),t(y,ha),t(ha,fa),t(fa,el),t(ha,tl),p(e,Mr,i),p(e,K,i),t(K,fe),t(fe,qa),d(Ve,qa,null),t(K,al),t(K,Ia),t(Ia,sl),p(e,Pr,i),p(e,me,i),t(me,rl),t(me,Ye),t(Ye,ol),t(me,nl),p(e,Tr,i),p(e,ma,i),t(ma,ll),p(e,Cr,i),p(e,L,i),t(L,Na),t(Na,Qe),t(Qe,il),t(L,pl),t(L,Ha),t(Ha,Ze),t(Ze,cl),t(L,hl),t(L,Fa),t(Fa,fl),p(e,Dr,i),p(e,ue,i),t(ue,ml),t(ue,et),t(et,ul),t(ue,dl),p(e,Or,i),p(e,de,i),t(de,gl),t(de,La),t(La,_l),t(de,vl),p(e,qr,i),d(tt,e,i),p(e,Ir,i),p(e,ua,i),t(ua,za),t(za,yl),p(e,Nr,i),p(e,da,i),t(da,El),p(e,Hr,i),d(at,e,i),p(e,Fr,i),p(e,ga,i),t(ga,V),t(V,bl),t(V,Ra),t(Ra,wl),t(V,kl),t(V,Ua),t(Ua,$l),t(V,xl),p(e,Lr,i),p(e,_a,i),t(_a,Ga),t(Ga,jl),p(e,zr,i),p(e,va,i),t(va,Sl),p(e,Rr,i),d(st,e,i),p(e,Ur,i),p(e,Y,i),t(Y,ge),t(ge,Wa),d(rt,Wa,null),t(Y,Al),t(Y,Ba),t(Ba,Ml),p(e,Gr,i),p(e,_e,i),t(_e,Pl),t(_e,ot),t(ot,Tl),t(_e,Cl),p(e,Wr,i),p(e,z,i),t(z,Xa),t(Xa,R),t(R,Ja),t(Ja,Dl),t(R,Ol),t(R,Ka),t(Ka,ql),t(R,Il),t(R,Va),t(Va,Nl),t(R,Hl),t(z,Fl),t(z,Ya),t(Ya,ya),t(ya,Qa),t(Qa,Ll),t(ya,zl),t(z,Rl),t(z,Za),t(Za,x),t(x,es),t(es,Ul),t(x,Gl),t(x,ts),t(ts,Wl),t(x,Bl),t(x,as),t(as,Xl),t(x,Jl),t(x,ss),t(ss,Kl),t(x,Vl),t(x,rs),t(rs,Yl),t(x,Ql),t(x,os),t(os,Zl),t(x,ei),p(e,Br,i),p(e,q,i),t(q,ti),t(q,ns),t(ns,ai),t(q,si),t(q,Ea),t(Ea,ri),t(q,oi),t(q,ls),t(ls,ni),t(q,li),p(e,Xr,i),d(nt,e,i),p(e,Jr,i),p(e,ba,i),t(ba,P),t(P,ii),t(P,is),t(is,pi),t(P,ci),t(P,ps),t(ps,hi),t(P,fi),t(P,cs),t(cs,mi),t(P,ui),t(P,hs),t(hs,di),t(P,gi),p(e,Kr,i),p(e,ve,i),t(ve,_i),t(ve,lt),t(lt,vi),t(ve,yi),p(e,Vr,i),p(e,Q,i),t(Q,ye),t(ye,fs),d(it,fs,null),t(Q,Ei),t(Q,ms),t(ms,bi),p(e,Yr,i),p(e,E,i),t(E,wi),t(E,us),t(us,ki),t(E,$i),t(E,ds),t(ds,xi),t(E,ji),t(E,gs),t(gs,Si),t(E,Ai),t(E,_s),t(_s,Mi),t(E,Pi),t(E,pt),t(pt,Ti),t(E,Ci),t(E,vs),t(vs,Di),t(E,Oi),t(E,ys),t(ys,qi),t(E,Ii),t(E,Es),t(Es,Ni),t(E,Hi),p(e,Qr,i),p(e,b,i),t(b,Fi),t(b,ct),t(ct,Li),t(b,zi),t(b,ht),t(ht,Ri),t(b,Ui),t(b,bs),t(bs,Gi),t(b,Wi),t(b,ws),t(ws,Bi),t(b,Xi),t(b,ks),t(ks,Ji),t(b,Ki),t(b,$s),t($s,Vi),t(b,Yi),t(b,T),t(T,Qi),t(T,xs),t(xs,Zi),t(T,ep),t(T,js),t(js,tp),t(T,ap),t(T,Ss),t(Ss,sp),t(T,rp),t(T,As),t(As,op),t(T,np),p(e,Zr,i),p(e,Z,i),t(Z,Ee),t(Ee,Ms),d(ft,Ms,null),t(Z,lp),t(Z,Ps),t(Ps,ip),p(e,eo,i),p(e,be,i),t(be,pp),t(be,mt),t(mt,cp),t(be,hp),p(e,to,i),p(e,U,i),t(U,wa),t(wa,Ts),t(Ts,fp),t(wa,mp),t(U,up),t(U,we),t(we,Cs),t(Cs,dp),t(we,gp),t(we,ut),t(ut,_p),t(we,vp),t(U,yp),t(U,ke),t(ke,Ds),t(Ds,Ep),t(ke,bp),t(ke,dt),t(dt,wp),t(ke,kp),p(e,ao,i),p(e,S,i),t(S,$p),t(S,Os),t(Os,xp),t(S,jp),t(S,qs),t(qs,Sp),t(S,Ap),t(S,Is),t(Is,Mp),t(S,Pp),t(S,Ns),t(Ns,Tp),t(S,Cp),p(e,so,i),d(gt,e,i),p(e,ro,i),p(e,I,i),t(I,Dp),t(I,Hs),t(Hs,Op),t(I,qp),t(I,Fs),t(Fs,Ip),t(I,Np),t(I,Ls),t(Ls,Hp),t(I,Fp),p(e,oo,i),p(e,ee,i),t(ee,$e),t($e,zs),d(_t,zs,null),t(ee,Lp),t(ee,Rs),t(Rs,zp),p(e,no,i),p(e,N,i),t(N,Rp),t(N,Us),t(Us,Up),t(N,Gp),t(N,Gs),t(Gs,Wp),t(N,Bp),t(N,Ws),t(Ws,Xp),t(N,Jp),p(e,lo,i),p(e,xe,i),t(xe,vt),t(vt,Kp),t(vt,Bs),t(Bs,Vp),t(vt,Yp),t(xe,Qp),t(xe,je),t(je,Xs),t(Xs,Zp),t(je,ec),t(je,yt),t(yt,tc),t(je,ac),p(e,io,i),p(e,Se,i),t(Se,sc),t(Se,Js),t(Js,rc),t(Se,oc),p(e,po,i),d(Et,e,i),p(e,co,i),p(e,Ae,i),t(Ae,nc),t(Ae,Ks),t(Ks,lc),t(Ae,ic),p(e,ho,i),d(bt,e,i),p(e,fo,i),p(e,te,i),t(te,Me),t(Me,Vs),d(wt,Vs,null),t(te,pc),t(te,Ys),t(Ys,cc),p(e,mo,i),p(e,Pe,i),t(Pe,hc),t(Pe,kt),t(kt,fc),t(Pe,mc),p(e,uo,i),d($t,e,i),p(e,go,i),p(e,ae,i),t(ae,Te),t(Te,Qs),d(xt,Qs,null),t(ae,uc),t(ae,Zs),t(Zs,dc),p(e,_o,i),p(e,ka,i),t(ka,gc),p(e,vo,i),p(e,se,i),t(se,Ce),t(Ce,er),d(jt,er,null),t(se,_c),t(se,tr),t(tr,vc),p(e,yo,i),p(e,De,i),t(De,yc),t(De,St),t(St,Ec),t(De,bc),p(e,Eo,i),d(At,e,i),p(e,bo,i),p(e,Oe,i),t(Oe,wc),t(Oe,Mt),t(Mt,kc),t(Oe,$c),p(e,wo,i),p(e,re,i),t(re,qe),t(qe,ar),d(Pt,ar,null),t(re,xc),t(re,sr),t(sr,jc),p(e,ko,i),p(e,Ie,i),t(Ie,Sc),t(Ie,Tt),t(Tt,Ac),t(Ie,Mc),p(e,$o,i),d(Ct,e,i),p(e,xo,i),p(e,Ne,i),t(Ne,Pc),t(Ne,Dt),t(Dt,Tc),t(Ne,Cc),p(e,jo,i),p(e,oe,i),t(oe,He),t(He,rr),d(Ot,rr,null),t(oe,Dc),t(oe,or),t(or,Oc),p(e,So,i),p(e,Fe,i),t(Fe,qc),t(Fe,qt),t(qt,Ic),t(Fe,Nc),p(e,Ao,i),p(e,$a,i),t($a,ne),t(ne,Hc),t(ne,It),t(It,Fc),t(ne,Lc),t(ne,nr),t(nr,zc),t(ne,Rc),p(e,Mo,i),p(e,H,i),t(H,Uc),t(H,lr),t(lr,Gc),t(H,Wc),t(H,ir),t(ir,Bc),t(H,Xc),t(H,pr),t(pr,Jc),t(H,Kc),p(e,Po,i),d(Nt,e,i),p(e,To,i),p(e,Le,i),t(Le,Vc),t(Le,Ht),t(Ht,Yc),t(Le,Qc),p(e,Co,i),p(e,le,i),t(le,ze),t(ze,cr),d(Ft,cr,null),t(le,Zc),t(le,hr),t(hr,eh),p(e,Do,i),p(e,F,i),t(F,th),t(F,Lt),t(Lt,ah),t(F,sh),t(F,fr),t(fr,rh),t(F,oh),t(F,mr),t(mr,nh),t(F,lh),p(e,Oo,i),p(e,w,i),t(w,ih),t(w,ur),t(ur,ph),t(w,ch),t(w,zt),t(zt,hh),t(w,fh),t(w,dr),t(dr,mh),t(w,uh),t(w,gr),t(gr,dh),t(w,gh),t(w,_r),t(_r,_h),t(w,vh),t(w,vr),t(vr,yh),t(w,Eh),p(e,qo,i),p(e,xa,i),t(xa,Rt),t(Rt,bh),t(Rt,yr),t(yr,wh),t(Rt,kh),p(e,Io,i),d(Ut,e,i),p(e,No,i),p(e,ie,i),t(ie,Re),t(Re,Er),d(Gt,Er,null),t(ie,$h),t(ie,br),t(br,xh),p(e,Ho,i),p(e,Wt,i),t(Wt,Bt),t(Bt,jh),t(Wt,Sh),p(e,Fo,i),d(Xt,e,i),p(e,Lo,i),p(e,Ue,i),t(Ue,Ah),t(Ue,Jt),t(Jt,Mh),t(Ue,Ph),zo=!0},p:Wu,i(e){zo||(g(Ke.$$.fragment,e),g(Ve.$$.fragment,e),g(tt.$$.fragment,e),g(at.$$.fragment,e),g(st.$$.fragment,e),g(rt.$$.fragment,e),g(nt.$$.fragment,e),g(it.$$.fragment,e),g(ft.$$.fragment,e),g(gt.$$.fragment,e),g(_t.$$.fragment,e),g(Et.$$.fragment,e),g(bt.$$.fragment,e),g(wt.$$.fragment,e),g($t.$$.fragment,e),g(xt.$$.fragment,e),g(jt.$$.fragment,e),g(At.$$.fragment,e),g(Pt.$$.fragment,e),g(Ct.$$.fragment,e),g(Ot.$$.fragment,e),g(Nt.$$.fragment,e),g(Ft.$$.fragment,e),g(Ut.$$.fragment,e),g(Gt.$$.fragment,e),g(Xt.$$.fragment,e),zo=!0)},o(e){_(Ke.$$.fragment,e),_(Ve.$$.fragment,e),_(tt.$$.fragment,e),_(at.$$.fragment,e),_(st.$$.fragment,e),_(rt.$$.fragment,e),_(nt.$$.fragment,e),_(it.$$.fragment,e),_(ft.$$.fragment,e),_(gt.$$.fragment,e),_(_t.$$.fragment,e),_(Et.$$.fragment,e),_(bt.$$.fragment,e),_(wt.$$.fragment,e),_($t.$$.fragment,e),_(xt.$$.fragment,e),_(jt.$$.fragment,e),_(At.$$.fragment,e),_(Pt.$$.fragment,e),_(Ct.$$.fragment,e),_(Ot.$$.fragment,e),_(Nt.$$.fragment,e),_(Ft.$$.fragment,e),_(Ut.$$.fragment,e),_(Gt.$$.fragment,e),_(Xt.$$.fragment,e),zo=!1},d(e){a(X),e&&a(xr),e&&a(J),v(Ke),e&&a(jr),e&&a(M),e&&a(Sr),e&&a(ce),e&&a(Ar),e&&a(y),e&&a(Mr),e&&a(K),v(Ve),e&&a(Pr),e&&a(me),e&&a(Tr),e&&a(ma),e&&a(Cr),e&&a(L),e&&a(Dr),e&&a(ue),e&&a(Or),e&&a(de),e&&a(qr),v(tt,e),e&&a(Ir),e&&a(ua),e&&a(Nr),e&&a(da),e&&a(Hr),v(at,e),e&&a(Fr),e&&a(ga),e&&a(Lr),e&&a(_a),e&&a(zr),e&&a(va),e&&a(Rr),v(st,e),e&&a(Ur),e&&a(Y),v(rt),e&&a(Gr),e&&a(_e),e&&a(Wr),e&&a(z),e&&a(Br),e&&a(q),e&&a(Xr),v(nt,e),e&&a(Jr),e&&a(ba),e&&a(Kr),e&&a(ve),e&&a(Vr),e&&a(Q),v(it),e&&a(Yr),e&&a(E),e&&a(Qr),e&&a(b),e&&a(Zr),e&&a(Z),v(ft),e&&a(eo),e&&a(be),e&&a(to),e&&a(U),e&&a(ao),e&&a(S),e&&a(so),v(gt,e),e&&a(ro),e&&a(I),e&&a(oo),e&&a(ee),v(_t),e&&a(no),e&&a(N),e&&a(lo),e&&a(xe),e&&a(io),e&&a(Se),e&&a(po),v(Et,e),e&&a(co),e&&a(Ae),e&&a(ho),v(bt,e),e&&a(fo),e&&a(te),v(wt),e&&a(mo),e&&a(Pe),e&&a(uo),v($t,e),e&&a(go),e&&a(ae),v(xt),e&&a(_o),e&&a(ka),e&&a(vo),e&&a(se),v(jt),e&&a(yo),e&&a(De),e&&a(Eo),v(At,e),e&&a(bo),e&&a(Oe),e&&a(wo),e&&a(re),v(Pt),e&&a(ko),e&&a(Ie),e&&a($o),v(Ct,e),e&&a(xo),e&&a(Ne),e&&a(jo),e&&a(oe),v(Ot),e&&a(So),e&&a(Fe),e&&a(Ao),e&&a($a),e&&a(Mo),e&&a(H),e&&a(Po),v(Nt,e),e&&a(To),e&&a(Le),e&&a(Co),e&&a(le),v(Ft),e&&a(Do),e&&a(F),e&&a(Oo),e&&a(w),e&&a(qo),e&&a(xa),e&&a(Io),v(Ut,e),e&&a(No),e&&a(ie),v(Gt),e&&a(Ho),e&&a(Wt),e&&a(Fo),v(Xt,e),e&&a(Lo),e&&a(Ue)}}}const Ju={local:"run-training-on-amazon-sagemaker",sections:[{local:"installation-and-setup",title:"Installation and setup"},{local:"prepare-a-transformers-finetuning-script",title:"Prepare a \u{1F917} Transformers fine-tuning script"},{local:"training-output-management",title:"Training Output Management"},{local:"create-a-hugging-face-estimator",title:"Create a Hugging Face Estimator"},{local:"execute-training",title:"Execute training"},{local:"access-trained-model",title:"Access trained model"},{local:"distributed-training",sections:[{local:"data-parallelism",title:"Data parallelism"},{local:"model-parallelism",title:"Model parallelism"}],title:"Distributed training"},{local:"spot-instances",title:"Spot instances"},{local:"git-repository",title:"Git repository"},{local:"sagemaker-metrics",title:"SageMaker metrics"}],title:"Run training on Amazon SageMaker"};function Ku(Uh){return Bu(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Zu extends Lu{constructor(X){super();zu(this,X,Ku,Xu,Ru,{})}}export{Zu as default,Ju as metadata};
