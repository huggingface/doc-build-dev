import{S as qn,i as En,s as Sn,e as n,k as h,w as c,t as l,M as An,c as r,d as t,m as f,a as o,x as d,h as i,b as p,N as xn,G as a,g as u,y as m,L as Pn,q as g,o as _,B as y,v as Tn}from"../chunks/vendor-hf-doc-builder.js";import{I as Ee}from"../chunks/IconCopyLink-hf-doc-builder.js";import{C as q}from"../chunks/CodeBlock-hf-doc-builder.js";function Mn(xs){let E,pt,S,z,Oe,V,la,Le,ia,ut,Se,pa,ht,N,ua,X,ha,fa,ft,w,Ps,ct,F,ca,Z,da,ma,dt,A,D,Ye,ee,ga,Ue,_a,mt,k,ya,te,wa,ka,ae,va,ba,gt,se,_t,v,$a,ne,ja,qa,re,Ea,Sa,yt,oe,wt,H,Aa,le,xa,Pa,kt,b,Ta,We,Ma,Ia,ie,za,Na,vt,C,Fa,Be,Da,Ha,bt,pe,$t,x,O,Ge,ue,Ca,Re,Oa,jt,L,La,he,Ya,Ua,qt,fe,Et,P,Y,Je,ce,Wa,Ke,Ba,St,U,Ga,de,Ra,Ja,At,me,xt,T,W,Qe,ge,Ka,Ve,Qa,Pt,Ae,Va,Tt,$,B,Xe,Xa,Za,_e,es,ts,as,G,Ze,ss,ns,ye,rs,os,ls,xe,et,is,ps,Mt,we,It,Pe,us,zt,ke,Nt,M,R,tt,ve,hs,at,fs,Ft,J,cs,st,ds,ms,Dt,be,Ht,K,gs,nt,_s,ys,Ct,$e,Ot,Te,ws,Lt,je,Yt,I,Q,rt,qe,ks,ot,vs,Ut,Me,bs,Wt,j,$s,Ie,js,qs,ze,Es,Ss,Bt;return V=new Ee({}),ee=new Ee({}),se=new q({props:{code:'pip install "sagemaker>=2.48.0" "transformers==4.6.1" "datasets[s3]==1.6.2" --upgrade',highlighted:'pip install <span class="hljs-string">&quot;sagemaker&gt;=2.48.0&quot;</span> <span class="hljs-string">&quot;transformers==4.6.1&quot;</span> <span class="hljs-string">&quot;datasets[s3]==1.6.2&quot;</span> --upgrade'}}),oe=new q({props:{code:`%%capture
import IPython
!conda install -c conda-forge ipywidgets -y
IPython.Application.instance().kernel.do_shutdown(True)`,highlighted:`%%capture
<span class="hljs-keyword">import</span> IPython
!conda install -c conda-forge ipywidgets -y
IPython.Application.instance().kernel.do_shutdown(<span class="hljs-literal">True</span>)`}}),pe=new q({props:{code:`
`,highlighted:`<span class="hljs-keyword">import</span> sagemaker

sess = sagemaker.Session()
sagemaker_session_bucket = <span class="hljs-literal">None</span>
<span class="hljs-keyword">if</span> sagemaker_session_bucket <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> sess <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:
    sagemaker_session_bucket = sess.default_bucket()

role = sagemaker.get_execution_role()
sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)`}}),ue=new Ee({}),fe=new q({props:{code:`



`,highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-comment"># load dataset</span>
train_dataset, test_dataset = load_dataset(<span class="hljs-string">&quot;imdb&quot;</span>, split=[<span class="hljs-string">&quot;train&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>])

<span class="hljs-comment"># load tokenizer</span>
tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>)

<span class="hljs-comment"># create tokenization function</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize</span>(<span class="hljs-params">batch</span>):
    <span class="hljs-keyword">return</span> tokenizer(batch[<span class="hljs-string">&quot;text&quot;</span>], padding=<span class="hljs-string">&quot;max_length&quot;</span>, truncation=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># tokenize train and test datasets</span>
train_dataset = train_dataset.<span class="hljs-built_in">map</span>(tokenize, batched=<span class="hljs-literal">True</span>)
test_dataset = test_dataset.<span class="hljs-built_in">map</span>(tokenize, batched=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># set dataset format for PyTorch</span>
train_dataset =  train_dataset.rename_column(<span class="hljs-string">&quot;label&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>)
train_dataset.set_format(<span class="hljs-string">&quot;torch&quot;</span>, columns=[<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>])
test_dataset = test_dataset.rename_column(<span class="hljs-string">&quot;label&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>)
test_dataset.set_format(<span class="hljs-string">&quot;torch&quot;</span>, columns=[<span class="hljs-string">&quot;input_ids&quot;</span>, <span class="hljs-string">&quot;attention_mask&quot;</span>, <span class="hljs-string">&quot;labels&quot;</span>])`}}),ce=new Ee({}),me=new q({props:{code:`

`,highlighted:`<span class="hljs-keyword">import</span> botocore
<span class="hljs-keyword">from</span> datasets.filesystems <span class="hljs-keyword">import</span> S3FileSystem

s3_prefix = <span class="hljs-string">&#x27;samples/datasets/imdb&#x27;</span>
s3 = S3FileSystem()

<span class="hljs-comment"># save train_dataset to S3</span>
training_input_path = <span class="hljs-string">f&#x27;s3://<span class="hljs-subst">{sess.default_bucket()}</span>/<span class="hljs-subst">{s3_prefix}</span>/train&#x27;</span>
train_dataset.save_to_disk(training_input_path,fs=s3)

<span class="hljs-comment"># save test_dataset to S3</span>
test_input_path = <span class="hljs-string">f&#x27;s3://<span class="hljs-subst">{sess.default_bucket()}</span>/<span class="hljs-subst">{s3_prefix}</span>/test&#x27;</span>
test_dataset.save_to_disk(test_input_path,fs=s3)`}}),ge=new Ee({}),we=new q({props:{code:`
`,highlighted:`<span class="hljs-keyword">from</span> sagemaker.huggingface <span class="hljs-keyword">import</span> HuggingFace

hyperparameters={
    <span class="hljs-string">&quot;epochs&quot;</span>: <span class="hljs-number">1</span>,                            <span class="hljs-comment"># number of training epochs</span>
    <span class="hljs-string">&quot;train_batch_size&quot;</span>: <span class="hljs-number">32</span>,                 <span class="hljs-comment"># training batch size</span>
    <span class="hljs-string">&quot;model_name&quot;</span>:<span class="hljs-string">&quot;distilbert-base-uncased&quot;</span>  <span class="hljs-comment"># name of pretrained model</span>
}

huggingface_estimator = HuggingFace(
    entry_point=<span class="hljs-string">&quot;train.py&quot;</span>,                 <span class="hljs-comment"># fine-tuning script to use in training job</span>
    source_dir=<span class="hljs-string">&quot;./scripts&quot;</span>,                 <span class="hljs-comment"># directory where fine-tuning script is stored</span>
    instance_type=<span class="hljs-string">&quot;ml.p3.2xlarge&quot;</span>,          <span class="hljs-comment"># instance type</span>
    instance_count=<span class="hljs-number">1</span>,                       <span class="hljs-comment"># number of instances</span>
    role=role,                              <span class="hljs-comment"># IAM role used in training job to acccess AWS resources (S3)</span>
    transformers_version=<span class="hljs-string">&quot;4.6&quot;</span>,             <span class="hljs-comment"># Transformers version</span>
    pytorch_version=<span class="hljs-string">&quot;1.7&quot;</span>,                  <span class="hljs-comment"># PyTorch version</span>
    py_version=<span class="hljs-string">&quot;py36&quot;</span>,                      <span class="hljs-comment"># Python version</span>
    hyperparameters=hyperparameters         <span class="hljs-comment"># hyperparameters to use in training job</span>
)`}}),ke=new q({props:{code:'huggingface_estimator.fit({"train": training_input_path, "test": test_input_path})',highlighted:'huggingface_estimator.fit({<span class="hljs-string">&quot;train&quot;</span>: training_input_path, <span class="hljs-string">&quot;test&quot;</span>: test_input_path})'}}),ve=new Ee({}),be=new q({props:{code:'predictor = huggingface_estimator.deploy(initial_instance_count=1,"ml.g4dn.xlarge")',highlighted:'predictor = huggingface_estimator.deploy(initial_instance_count=<span class="hljs-number">1</span>,<span class="hljs-string">&quot;ml.g4dn.xlarge&quot;</span>)'}}),$e=new q({props:{code:"",highlighted:`sentiment_input = {<span class="hljs-string">&quot;inputs&quot;</span>: <span class="hljs-string">&quot;It feels like a curtain closing...there was an elegance in the way they moved toward conclusion. No fan is going to watch and feel short-changed.&quot;</span>}

predictor.predict(sentiment_input)`}}),je=new q({props:{code:"predictor.delete_endpoint()",highlighted:"predictor.delete_endpoint()"}}),qe=new Ee({}),{c(){E=n("meta"),pt=h(),S=n("h1"),z=n("a"),Oe=n("span"),c(V.$$.fragment),la=h(),Le=n("span"),ia=l("Train and deploy Hugging Face on Amazon SageMaker"),ut=h(),Se=n("p"),pa=l("The get started guide will show you how to quickly use Hugging Face on Amazon SageMaker. Learn how to fine-tune and deploy a pretrained \u{1F917} Transformers model on SageMaker for a binary text classification task."),ht=h(),N=n("p"),ua=l("\u{1F4A1} If you are new to Hugging Face, we recommend first reading the \u{1F917} Transformers "),X=n("a"),ha=l("quick tour"),fa=l("."),ft=h(),w=n("iframe"),ct=h(),F=n("p"),ca=l("\u{1F4D3} Open the "),Z=n("a"),da=l("notebook"),ma=l(" to follow along!"),dt=h(),A=n("h2"),D=n("a"),Ye=n("span"),c(ee.$$.fragment),ga=h(),Ue=n("span"),_a=l("Installation and setup"),mt=h(),k=n("p"),ya=l("Get started by installing the necessary Hugging Face libraries and SageMaker. You will also need to install "),te=n("a"),wa=l("PyTorch"),ka=l(" and "),ae=n("a"),va=l("TensorFlow"),ba=l(" if you don\u2019t already have it installed."),gt=h(),c(se.$$.fragment),_t=h(),v=n("p"),$a=l("If you want to run this example in "),ne=n("a"),ja=l("SageMaker Studio"),qa=l(", upgrade "),re=n("a"),Ea=l("ipywidgets"),Sa=l(" for the \u{1F917} Datasets library and restart the kernel:"),yt=h(),c(oe.$$.fragment),wt=h(),H=n("p"),Aa=l("Next, you should set up your environment: a SageMaker session and an S3 bucket. The S3 bucket will store data, models, and logs. You will need access to an "),le=n("a"),xa=l("IAM execution role"),Pa=l(" with the required permissions."),kt=h(),b=n("p"),Ta=l("If you are planning on using SageMaker in a local environment, you need to provide the "),We=n("code"),Ma=l("role"),Ia=l(" yourself. Learn more about how to set this up "),ie=n("a"),za=l("here"),Na=l("."),vt=h(),C=n("p"),Fa=l("\u26A0\uFE0F The execution role is only available when you run a notebook within SageMaker. If you try to run "),Be=n("code"),Da=l("get_execution_role"),Ha=l(" in a notebook not on SageMaker, you will get a region error."),bt=h(),c(pe.$$.fragment),$t=h(),x=n("h2"),O=n("a"),Ge=n("span"),c(ue.$$.fragment),Ca=h(),Re=n("span"),Oa=l("Preprocess"),jt=h(),L=n("p"),La=l("The \u{1F917} Datasets library makes it easy to download and preprocess a dataset for training. Download and tokenize the "),he=n("a"),Ya=l("IMDb"),Ua=l(" dataset:"),qt=h(),c(fe.$$.fragment),Et=h(),P=n("h2"),Y=n("a"),Je=n("span"),c(ce.$$.fragment),Wa=h(),Ke=n("span"),Ba=l("Upload dataset to S3 bucket"),St=h(),U=n("p"),Ga=l("Next, upload the preprocessed dataset to your S3 session bucket with \u{1F917} Datasets S3 "),de=n("a"),Ra=l("filesystem"),Ja=l(" implementation:"),At=h(),c(me.$$.fragment),xt=h(),T=n("h2"),W=n("a"),Qe=n("span"),c(ge.$$.fragment),Ka=h(),Ve=n("span"),Qa=l("Start a training job"),Pt=h(),Ae=n("p"),Va=l("Create a Hugging Face Estimator to handle end-to-end SageMaker training and deployment. The most important parameters to pay attention to are:"),Tt=h(),$=n("ul"),B=n("li"),Xe=n("code"),Xa=l("entry_point"),Za=l(" refers to the fine-tuning script which you can find "),_e=n("a"),es=l("here"),ts=l("."),as=h(),G=n("li"),Ze=n("code"),ss=l("instance_type"),ns=l(" refers to the SageMaker instance that will be launched. Take a look "),ye=n("a"),rs=l("here"),os=l(" for a complete list of instance types."),ls=h(),xe=n("li"),et=n("code"),is=l("hyperparameters"),ps=l(" refers to the training hyperparameters the model will be fine-tuned with."),Mt=h(),c(we.$$.fragment),It=h(),Pe=n("p"),us=l("Begin training with one line of code:"),zt=h(),c(ke.$$.fragment),Nt=h(),M=n("h2"),R=n("a"),tt=n("span"),c(ve.$$.fragment),hs=h(),at=n("span"),fs=l("Deploy model"),Ft=h(),J=n("p"),cs=l("Once the training job is complete, deploy your fine-tuned model by calling "),st=n("code"),ds=l("deploy()"),ms=l(" with the number of instances and instance type:"),Dt=h(),c(be.$$.fragment),Ht=h(),K=n("p"),gs=l("Call "),nt=n("code"),_s=l("predict()"),ys=l(" on your data:"),Ct=h(),c($e.$$.fragment),Ot=h(),Te=n("p"),ws=l("After running your request, delete the endpoint:"),Lt=h(),c(je.$$.fragment),Yt=h(),I=n("h2"),Q=n("a"),rt=n("span"),c(qe.$$.fragment),ks=h(),ot=n("span"),vs=l("What's next?"),Ut=h(),Me=n("p"),bs=l("Congratulations, you\u2019ve just fine-tuned and deployed a pretrained \u{1F917} Transformers model on SageMaker! \u{1F389}"),Wt=h(),j=n("p"),$s=l("For your next steps, keep reading our documentation for more details about training and deployment. There are many interesting features such as "),Ie=n("a"),js=l("distributed training"),qs=l(" and "),ze=n("a"),Es=l("Spot instances"),Ss=l("."),this.h()},l(e){const s=An('[data-svelte="svelte-1phssyn"]',document.head);E=r(s,"META",{name:!0,content:!0}),s.forEach(t),pt=f(e),S=r(e,"H1",{class:!0});var Gt=o(S);z=r(Gt,"A",{id:!0,class:!0,href:!0});var Ts=o(z);Oe=r(Ts,"SPAN",{});var Ms=o(Oe);d(V.$$.fragment,Ms),Ms.forEach(t),Ts.forEach(t),la=f(Gt),Le=r(Gt,"SPAN",{});var Is=o(Le);ia=i(Is,"Train and deploy Hugging Face on Amazon SageMaker"),Is.forEach(t),Gt.forEach(t),ut=f(e),Se=r(e,"P",{});var zs=o(Se);pa=i(zs,"The get started guide will show you how to quickly use Hugging Face on Amazon SageMaker. Learn how to fine-tune and deploy a pretrained \u{1F917} Transformers model on SageMaker for a binary text classification task."),zs.forEach(t),ht=f(e),N=r(e,"P",{});var Rt=o(N);ua=i(Rt,"\u{1F4A1} If you are new to Hugging Face, we recommend first reading the \u{1F917} Transformers "),X=r(Rt,"A",{href:!0,rel:!0});var Ns=o(X);ha=i(Ns,"quick tour"),Ns.forEach(t),fa=i(Rt,"."),Rt.forEach(t),ft=f(e),w=r(e,"IFRAME",{width:!0,height:!0,src:!0,title:!0,frameborder:!0,allow:!0}),o(w).forEach(t),ct=f(e),F=r(e,"P",{});var Jt=o(F);ca=i(Jt,"\u{1F4D3} Open the "),Z=r(Jt,"A",{href:!0,rel:!0});var Fs=o(Z);da=i(Fs,"notebook"),Fs.forEach(t),ma=i(Jt," to follow along!"),Jt.forEach(t),dt=f(e),A=r(e,"H2",{class:!0});var Kt=o(A);D=r(Kt,"A",{id:!0,class:!0,href:!0});var Ds=o(D);Ye=r(Ds,"SPAN",{});var Hs=o(Ye);d(ee.$$.fragment,Hs),Hs.forEach(t),Ds.forEach(t),ga=f(Kt),Ue=r(Kt,"SPAN",{});var Cs=o(Ue);_a=i(Cs,"Installation and setup"),Cs.forEach(t),Kt.forEach(t),mt=f(e),k=r(e,"P",{});var Ne=o(k);ya=i(Ne,"Get started by installing the necessary Hugging Face libraries and SageMaker. You will also need to install "),te=r(Ne,"A",{href:!0,rel:!0});var Os=o(te);wa=i(Os,"PyTorch"),Os.forEach(t),ka=i(Ne," and "),ae=r(Ne,"A",{href:!0,rel:!0});var Ls=o(ae);va=i(Ls,"TensorFlow"),Ls.forEach(t),ba=i(Ne," if you don\u2019t already have it installed."),Ne.forEach(t),gt=f(e),d(se.$$.fragment,e),_t=f(e),v=r(e,"P",{});var Fe=o(v);$a=i(Fe,"If you want to run this example in "),ne=r(Fe,"A",{href:!0,rel:!0});var Ys=o(ne);ja=i(Ys,"SageMaker Studio"),Ys.forEach(t),qa=i(Fe,", upgrade "),re=r(Fe,"A",{href:!0,rel:!0});var Us=o(re);Ea=i(Us,"ipywidgets"),Us.forEach(t),Sa=i(Fe," for the \u{1F917} Datasets library and restart the kernel:"),Fe.forEach(t),yt=f(e),d(oe.$$.fragment,e),wt=f(e),H=r(e,"P",{});var Qt=o(H);Aa=i(Qt,"Next, you should set up your environment: a SageMaker session and an S3 bucket. The S3 bucket will store data, models, and logs. You will need access to an "),le=r(Qt,"A",{href:!0,rel:!0});var Ws=o(le);xa=i(Ws,"IAM execution role"),Ws.forEach(t),Pa=i(Qt," with the required permissions."),Qt.forEach(t),kt=f(e),b=r(e,"P",{});var De=o(b);Ta=i(De,"If you are planning on using SageMaker in a local environment, you need to provide the "),We=r(De,"CODE",{});var Bs=o(We);Ma=i(Bs,"role"),Bs.forEach(t),Ia=i(De," yourself. Learn more about how to set this up "),ie=r(De,"A",{href:!0,rel:!0});var Gs=o(ie);za=i(Gs,"here"),Gs.forEach(t),Na=i(De,"."),De.forEach(t),vt=f(e),C=r(e,"P",{});var Vt=o(C);Fa=i(Vt,"\u26A0\uFE0F The execution role is only available when you run a notebook within SageMaker. If you try to run "),Be=r(Vt,"CODE",{});var Rs=o(Be);Da=i(Rs,"get_execution_role"),Rs.forEach(t),Ha=i(Vt," in a notebook not on SageMaker, you will get a region error."),Vt.forEach(t),bt=f(e),d(pe.$$.fragment,e),$t=f(e),x=r(e,"H2",{class:!0});var Xt=o(x);O=r(Xt,"A",{id:!0,class:!0,href:!0});var Js=o(O);Ge=r(Js,"SPAN",{});var Ks=o(Ge);d(ue.$$.fragment,Ks),Ks.forEach(t),Js.forEach(t),Ca=f(Xt),Re=r(Xt,"SPAN",{});var Qs=o(Re);Oa=i(Qs,"Preprocess"),Qs.forEach(t),Xt.forEach(t),jt=f(e),L=r(e,"P",{});var Zt=o(L);La=i(Zt,"The \u{1F917} Datasets library makes it easy to download and preprocess a dataset for training. Download and tokenize the "),he=r(Zt,"A",{href:!0,rel:!0});var Vs=o(he);Ya=i(Vs,"IMDb"),Vs.forEach(t),Ua=i(Zt," dataset:"),Zt.forEach(t),qt=f(e),d(fe.$$.fragment,e),Et=f(e),P=r(e,"H2",{class:!0});var ea=o(P);Y=r(ea,"A",{id:!0,class:!0,href:!0});var Xs=o(Y);Je=r(Xs,"SPAN",{});var Zs=o(Je);d(ce.$$.fragment,Zs),Zs.forEach(t),Xs.forEach(t),Wa=f(ea),Ke=r(ea,"SPAN",{});var en=o(Ke);Ba=i(en,"Upload dataset to S3 bucket"),en.forEach(t),ea.forEach(t),St=f(e),U=r(e,"P",{});var ta=o(U);Ga=i(ta,"Next, upload the preprocessed dataset to your S3 session bucket with \u{1F917} Datasets S3 "),de=r(ta,"A",{href:!0,rel:!0});var tn=o(de);Ra=i(tn,"filesystem"),tn.forEach(t),Ja=i(ta," implementation:"),ta.forEach(t),At=f(e),d(me.$$.fragment,e),xt=f(e),T=r(e,"H2",{class:!0});var aa=o(T);W=r(aa,"A",{id:!0,class:!0,href:!0});var an=o(W);Qe=r(an,"SPAN",{});var sn=o(Qe);d(ge.$$.fragment,sn),sn.forEach(t),an.forEach(t),Ka=f(aa),Ve=r(aa,"SPAN",{});var nn=o(Ve);Qa=i(nn,"Start a training job"),nn.forEach(t),aa.forEach(t),Pt=f(e),Ae=r(e,"P",{});var rn=o(Ae);Va=i(rn,"Create a Hugging Face Estimator to handle end-to-end SageMaker training and deployment. The most important parameters to pay attention to are:"),rn.forEach(t),Tt=f(e),$=r(e,"UL",{});var He=o($);B=r(He,"LI",{});var lt=o(B);Xe=r(lt,"CODE",{});var on=o(Xe);Xa=i(on,"entry_point"),on.forEach(t),Za=i(lt," refers to the fine-tuning script which you can find "),_e=r(lt,"A",{href:!0,rel:!0});var ln=o(_e);es=i(ln,"here"),ln.forEach(t),ts=i(lt,"."),lt.forEach(t),as=f(He),G=r(He,"LI",{});var it=o(G);Ze=r(it,"CODE",{});var pn=o(Ze);ss=i(pn,"instance_type"),pn.forEach(t),ns=i(it," refers to the SageMaker instance that will be launched. Take a look "),ye=r(it,"A",{href:!0,rel:!0});var un=o(ye);rs=i(un,"here"),un.forEach(t),os=i(it," for a complete list of instance types."),it.forEach(t),ls=f(He),xe=r(He,"LI",{});var As=o(xe);et=r(As,"CODE",{});var hn=o(et);is=i(hn,"hyperparameters"),hn.forEach(t),ps=i(As," refers to the training hyperparameters the model will be fine-tuned with."),As.forEach(t),He.forEach(t),Mt=f(e),d(we.$$.fragment,e),It=f(e),Pe=r(e,"P",{});var fn=o(Pe);us=i(fn,"Begin training with one line of code:"),fn.forEach(t),zt=f(e),d(ke.$$.fragment,e),Nt=f(e),M=r(e,"H2",{class:!0});var sa=o(M);R=r(sa,"A",{id:!0,class:!0,href:!0});var cn=o(R);tt=r(cn,"SPAN",{});var dn=o(tt);d(ve.$$.fragment,dn),dn.forEach(t),cn.forEach(t),hs=f(sa),at=r(sa,"SPAN",{});var mn=o(at);fs=i(mn,"Deploy model"),mn.forEach(t),sa.forEach(t),Ft=f(e),J=r(e,"P",{});var na=o(J);cs=i(na,"Once the training job is complete, deploy your fine-tuned model by calling "),st=r(na,"CODE",{});var gn=o(st);ds=i(gn,"deploy()"),gn.forEach(t),ms=i(na," with the number of instances and instance type:"),na.forEach(t),Dt=f(e),d(be.$$.fragment,e),Ht=f(e),K=r(e,"P",{});var ra=o(K);gs=i(ra,"Call "),nt=r(ra,"CODE",{});var _n=o(nt);_s=i(_n,"predict()"),_n.forEach(t),ys=i(ra," on your data:"),ra.forEach(t),Ct=f(e),d($e.$$.fragment,e),Ot=f(e),Te=r(e,"P",{});var yn=o(Te);ws=i(yn,"After running your request, delete the endpoint:"),yn.forEach(t),Lt=f(e),d(je.$$.fragment,e),Yt=f(e),I=r(e,"H2",{class:!0});var oa=o(I);Q=r(oa,"A",{id:!0,class:!0,href:!0});var wn=o(Q);rt=r(wn,"SPAN",{});var kn=o(rt);d(qe.$$.fragment,kn),kn.forEach(t),wn.forEach(t),ks=f(oa),ot=r(oa,"SPAN",{});var vn=o(ot);vs=i(vn,"What's next?"),vn.forEach(t),oa.forEach(t),Ut=f(e),Me=r(e,"P",{});var bn=o(Me);bs=i(bn,"Congratulations, you\u2019ve just fine-tuned and deployed a pretrained \u{1F917} Transformers model on SageMaker! \u{1F389}"),bn.forEach(t),Wt=f(e),j=r(e,"P",{});var Ce=o(j);$s=i(Ce,"For your next steps, keep reading our documentation for more details about training and deployment. There are many interesting features such as "),Ie=r(Ce,"A",{href:!0});var $n=o(Ie);js=i($n,"distributed training"),$n.forEach(t),qs=i(Ce," and "),ze=r(Ce,"A",{href:!0});var jn=o(ze);Es=i(jn,"Spot instances"),jn.forEach(t),Ss=i(Ce,"."),Ce.forEach(t),this.h()},h(){p(E,"name","hf:doc:metadata"),p(E,"content",JSON.stringify(In)),p(z,"id","train-and-deploy-hugging-face-on-amazon-sagemaker"),p(z,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(z,"href","#train-and-deploy-hugging-face-on-amazon-sagemaker"),p(S,"class","relative group"),p(X,"href","https://huggingface.co/transformers/quicktour.html"),p(X,"rel","nofollow"),p(w,"width","560"),p(w,"height","315"),xn(w.src,Ps="https://www.youtube.com/embed/pYqjCzoyWyo")||p(w,"src",Ps),p(w,"title","YouTube video player"),p(w,"frameborder","0"),p(w,"allow","accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"),w.allowFullscreen=!0,p(Z,"href","https://github.com/huggingface/notebooks/blob/main/sagemaker/01_getting_started_pytorch/sagemaker-notebook.ipynb"),p(Z,"rel","nofollow"),p(D,"id","installation-and-setup"),p(D,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(D,"href","#installation-and-setup"),p(A,"class","relative group"),p(te,"href","https://pytorch.org/get-started/locally/"),p(te,"rel","nofollow"),p(ae,"href","https://www.tensorflow.org/install/pip#tensorflow-2-packages-are-available"),p(ae,"rel","nofollow"),p(ne,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/studio.html"),p(ne,"rel","nofollow"),p(re,"href","https://ipywidgets.readthedocs.io/en/latest/"),p(re,"rel","nofollow"),p(le,"href","https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html"),p(le,"rel","nofollow"),p(ie,"href","https://huggingface.co/docs/sagemaker/train#installation-and-setup"),p(ie,"rel","nofollow"),p(O,"id","preprocess"),p(O,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(O,"href","#preprocess"),p(x,"class","relative group"),p(he,"href","https://huggingface.co/datasets/imdb"),p(he,"rel","nofollow"),p(Y,"id","upload-dataset-to-s3-bucket"),p(Y,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Y,"href","#upload-dataset-to-s3-bucket"),p(P,"class","relative group"),p(de,"href","https://huggingface.co/docs/datasets/filesystems.html"),p(de,"rel","nofollow"),p(W,"id","start-a-training-job"),p(W,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(W,"href","#start-a-training-job"),p(T,"class","relative group"),p(_e,"href","https://github.com/huggingface/notebooks/blob/main/sagemaker/01_getting_started_pytorch/scripts/train.py"),p(_e,"rel","nofollow"),p(ye,"href","https://aws.amazon.com/sagemaker/pricing/"),p(ye,"rel","nofollow"),p(R,"id","deploy-model"),p(R,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(R,"href","#deploy-model"),p(M,"class","relative group"),p(Q,"id","whats-next"),p(Q,"class","header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full"),p(Q,"href","#whats-next"),p(I,"class","relative group"),p(Ie,"href","/docs/sagemaker/train#distributed-training"),p(ze,"href","/docs/sagemaker/train#spot-instances")},m(e,s){a(document.head,E),u(e,pt,s),u(e,S,s),a(S,z),a(z,Oe),m(V,Oe,null),a(S,la),a(S,Le),a(Le,ia),u(e,ut,s),u(e,Se,s),a(Se,pa),u(e,ht,s),u(e,N,s),a(N,ua),a(N,X),a(X,ha),a(N,fa),u(e,ft,s),u(e,w,s),u(e,ct,s),u(e,F,s),a(F,ca),a(F,Z),a(Z,da),a(F,ma),u(e,dt,s),u(e,A,s),a(A,D),a(D,Ye),m(ee,Ye,null),a(A,ga),a(A,Ue),a(Ue,_a),u(e,mt,s),u(e,k,s),a(k,ya),a(k,te),a(te,wa),a(k,ka),a(k,ae),a(ae,va),a(k,ba),u(e,gt,s),m(se,e,s),u(e,_t,s),u(e,v,s),a(v,$a),a(v,ne),a(ne,ja),a(v,qa),a(v,re),a(re,Ea),a(v,Sa),u(e,yt,s),m(oe,e,s),u(e,wt,s),u(e,H,s),a(H,Aa),a(H,le),a(le,xa),a(H,Pa),u(e,kt,s),u(e,b,s),a(b,Ta),a(b,We),a(We,Ma),a(b,Ia),a(b,ie),a(ie,za),a(b,Na),u(e,vt,s),u(e,C,s),a(C,Fa),a(C,Be),a(Be,Da),a(C,Ha),u(e,bt,s),m(pe,e,s),u(e,$t,s),u(e,x,s),a(x,O),a(O,Ge),m(ue,Ge,null),a(x,Ca),a(x,Re),a(Re,Oa),u(e,jt,s),u(e,L,s),a(L,La),a(L,he),a(he,Ya),a(L,Ua),u(e,qt,s),m(fe,e,s),u(e,Et,s),u(e,P,s),a(P,Y),a(Y,Je),m(ce,Je,null),a(P,Wa),a(P,Ke),a(Ke,Ba),u(e,St,s),u(e,U,s),a(U,Ga),a(U,de),a(de,Ra),a(U,Ja),u(e,At,s),m(me,e,s),u(e,xt,s),u(e,T,s),a(T,W),a(W,Qe),m(ge,Qe,null),a(T,Ka),a(T,Ve),a(Ve,Qa),u(e,Pt,s),u(e,Ae,s),a(Ae,Va),u(e,Tt,s),u(e,$,s),a($,B),a(B,Xe),a(Xe,Xa),a(B,Za),a(B,_e),a(_e,es),a(B,ts),a($,as),a($,G),a(G,Ze),a(Ze,ss),a(G,ns),a(G,ye),a(ye,rs),a(G,os),a($,ls),a($,xe),a(xe,et),a(et,is),a(xe,ps),u(e,Mt,s),m(we,e,s),u(e,It,s),u(e,Pe,s),a(Pe,us),u(e,zt,s),m(ke,e,s),u(e,Nt,s),u(e,M,s),a(M,R),a(R,tt),m(ve,tt,null),a(M,hs),a(M,at),a(at,fs),u(e,Ft,s),u(e,J,s),a(J,cs),a(J,st),a(st,ds),a(J,ms),u(e,Dt,s),m(be,e,s),u(e,Ht,s),u(e,K,s),a(K,gs),a(K,nt),a(nt,_s),a(K,ys),u(e,Ct,s),m($e,e,s),u(e,Ot,s),u(e,Te,s),a(Te,ws),u(e,Lt,s),m(je,e,s),u(e,Yt,s),u(e,I,s),a(I,Q),a(Q,rt),m(qe,rt,null),a(I,ks),a(I,ot),a(ot,vs),u(e,Ut,s),u(e,Me,s),a(Me,bs),u(e,Wt,s),u(e,j,s),a(j,$s),a(j,Ie),a(Ie,js),a(j,qs),a(j,ze),a(ze,Es),a(j,Ss),Bt=!0},p:Pn,i(e){Bt||(g(V.$$.fragment,e),g(ee.$$.fragment,e),g(se.$$.fragment,e),g(oe.$$.fragment,e),g(pe.$$.fragment,e),g(ue.$$.fragment,e),g(fe.$$.fragment,e),g(ce.$$.fragment,e),g(me.$$.fragment,e),g(ge.$$.fragment,e),g(we.$$.fragment,e),g(ke.$$.fragment,e),g(ve.$$.fragment,e),g(be.$$.fragment,e),g($e.$$.fragment,e),g(je.$$.fragment,e),g(qe.$$.fragment,e),Bt=!0)},o(e){_(V.$$.fragment,e),_(ee.$$.fragment,e),_(se.$$.fragment,e),_(oe.$$.fragment,e),_(pe.$$.fragment,e),_(ue.$$.fragment,e),_(fe.$$.fragment,e),_(ce.$$.fragment,e),_(me.$$.fragment,e),_(ge.$$.fragment,e),_(we.$$.fragment,e),_(ke.$$.fragment,e),_(ve.$$.fragment,e),_(be.$$.fragment,e),_($e.$$.fragment,e),_(je.$$.fragment,e),_(qe.$$.fragment,e),Bt=!1},d(e){t(E),e&&t(pt),e&&t(S),y(V),e&&t(ut),e&&t(Se),e&&t(ht),e&&t(N),e&&t(ft),e&&t(w),e&&t(ct),e&&t(F),e&&t(dt),e&&t(A),y(ee),e&&t(mt),e&&t(k),e&&t(gt),y(se,e),e&&t(_t),e&&t(v),e&&t(yt),y(oe,e),e&&t(wt),e&&t(H),e&&t(kt),e&&t(b),e&&t(vt),e&&t(C),e&&t(bt),y(pe,e),e&&t($t),e&&t(x),y(ue),e&&t(jt),e&&t(L),e&&t(qt),y(fe,e),e&&t(Et),e&&t(P),y(ce),e&&t(St),e&&t(U),e&&t(At),y(me,e),e&&t(xt),e&&t(T),y(ge),e&&t(Pt),e&&t(Ae),e&&t(Tt),e&&t($),e&&t(Mt),y(we,e),e&&t(It),e&&t(Pe),e&&t(zt),y(ke,e),e&&t(Nt),e&&t(M),y(ve),e&&t(Ft),e&&t(J),e&&t(Dt),y(be,e),e&&t(Ht),e&&t(K),e&&t(Ct),y($e,e),e&&t(Ot),e&&t(Te),e&&t(Lt),y(je,e),e&&t(Yt),e&&t(I),y(qe),e&&t(Ut),e&&t(Me),e&&t(Wt),e&&t(j)}}}const In={local:"train-and-deploy-hugging-face-on-amazon-sagemaker",sections:[{local:"installation-and-setup",title:"Installation and setup"},{local:"preprocess",title:"Preprocess"},{local:"upload-dataset-to-s3-bucket",title:"Upload dataset to S3 bucket"},{local:"start-a-training-job",title:"Start a training job"},{local:"deploy-model",title:"Deploy model"},{local:"whats-next",title:"What's next?"}],title:"Train and deploy Hugging Face on Amazon SageMaker"};function zn(xs){return Tn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Hn extends qn{constructor(E){super();En(this,E,zn,Mn,Sn,{})}}export{Hn as default,In as metadata};
